<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-04-27) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新320篇论文，其中：  75篇计算机视觉（cs.CV） 27篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 60篇人工智能（cs.AI）  计算机视觉    1. 标题：A Control-Centric Benchmark for Video">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-04-27)">
<meta property="og:url" content="http://louishsu.xyz/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新320篇论文，其中：  75篇计算机视觉（cs.CV） 27篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 60篇人工智能（cs.AI）  计算机视觉    1. 标题：A Control-Centric Benchmark for Video">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-04-27T00:41:00.509Z">
<meta property="article:modified_time" content="2023-04-27T00:43:00.766Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-27 08:43:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-04-27)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-04-27T00:41:00.509Z" title="发表于 2023-04-27 08:41:00">2023-04-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-27T00:43:00.766Z" title="更新于 2023-04-27 08:43:00">2023-04-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">17.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>102分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新320篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">75篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">27篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">102篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">60篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：A Control-Centric Benchmark for Video Prediction</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13723</p>
  <p><b>作者</b>：Stephen Tian,  Chelsea Finn,  Jiajun Wu</p>
  <p><b>备注</b>：ICLR 2023</p>
  <p><b>关键词</b>：world dynamics, promising source, source of knowledge, knowledge for embodied, embodied agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video is a promising source of knowledge for embodied agents to learn models
of the world's dynamics. Large deep networks have become increasingly effective
at modeling complex video data in a self-supervised manner, as evaluated by
metrics based on human perceptual similarity or pixel-wise comparison. However,
it remains unclear whether current metrics are accurate indicators of
performance on downstream tasks. We find empirically that for planning robotic
manipulation, existing metrics can be unreliable at predicting execution
success. To address this, we propose a benchmark for action-conditioned video
prediction in the form of a control benchmark that evaluates a given model for
simulated robotic manipulation through sampling-based planning. Our benchmark,
Video Prediction for Visual Planning ($VP^2$), includes simulated environments
with 11 task categories and 310 task instance definitions, a full planning
implementation, and training datasets containing scripted interaction
trajectories for each task category. A central design goal of our benchmark is
to expose a simple interface -- a single forward prediction call -- so it is
straightforward to evaluate almost any action-conditioned video prediction
model. We then leverage our benchmark to study the effects of scaling model
size, quantity of training data, and model ensembling by analyzing five
highly-performant video prediction models, finding that while scale can improve
perceptual quality when modeling visually diverse settings, other attributes
such as uncertainty awareness can also aid planning performance.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Controllable Image Generation via Collage Representations</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13722</p>
  <p><b>作者</b>：Arantxa Casanova,  Marlène Careil,  Adriana Romero-Soriano,  Christopher J. Pal,  Jakob Verbeek,  Michal Drozdzal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enabled impressive results, impressive results, enabled impressive, text-based conditional models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in conditional generative image models have enabled
impressive results. On the one hand, text-based conditional models have
achieved remarkable generation quality, by leveraging large-scale datasets of
image-text pairs. To enable fine-grained controllability, however, text-based
models require long prompts, whose details may be ignored by the model. On the
other hand, layout-based conditional models have also witnessed significant
advances. These models rely on bounding boxes or segmentation maps for precise
spatial conditioning in combination with coarse semantic labels. The semantic
labels, however, cannot be used to express detailed appearance characteristics.
In this paper, we approach fine-grained scene controllability through image
collages which allow a rich visual description of the desired scene as well as
the appearance and location of the objects therein, without the need of class
nor attribute labels. We introduce "mixing and matching scenes" (M&Ms), an
approach that consists of an adversarially trained generative image model which
is conditioned on appearance features and spatial positions of the different
elements in a collage, and integrates these into a coherent image. We train our
model on the OpenImages (OI) dataset and evaluate it on collages derived from
OI and MS-COCO datasets. Our experiments on the OI dataset show that M&Ms
outperforms baselines in terms of fine-grained scene controllability while
being very competitive in terms of image quality and sample diversity. On the
MS-COCO dataset, we highlight the generalization ability of our model by
outperforming DALL-E in terms of the zero-shot FID metric, despite using two
magnitudes fewer parameters and data. Collage based generative models have the
potential to advance content creation in an efficient and effective way as they
are intuitive to use and yield high quality generations.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：UniNeXt: Exploring A Unified Architecture for Vision Recognition</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13700</p>
  <p><b>作者</b>：Fangjian Lin,  Jianlong Yuan,  Sitong Wu,  Fan Wang,  Zhibin Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, spatial token mixer, Transformers have shown, spatial token, computer vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision Transformers have shown great potential in computer vision tasks. Most
recent works have focused on elaborating the spatial token mixer for
performance gains. However, we observe that a well-designed general
architecture can significantly improve the performance of the entire backbone,
regardless of which spatial token mixer is equipped. In this paper, we propose
UniNeXt, an improved general architecture for the vision backbone. To verify
its effectiveness, we instantiate the spatial token mixer with various typical
and modern designs, including both convolution and attention modules. Compared
with the architecture in which they are first proposed, our UniNeXt
architecture can steadily boost the performance of all the spatial token
mixers, and narrows the performance gap among them. Surprisingly, our UniNeXt
equipped with naive local window attention even outperforms the previous
state-of-the-art. Interestingly, the ranking of these spatial token mixers also
changes under our UniNeXt, suggesting that an excellent spatial token mixer may
be stifled due to a suboptimal general architecture, which further shows the
importance of the study on the general architecture of vision backbone. All
models and codes will be publicly available.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Ray Conditioning: Trading Photo-consistency for Photo-realism in  Multi-view Image Generation</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13681</p>
  <p><b>作者</b>：Eric Ming Chen,  Sidhanth Holalkere,  Ruyu Yan,  Kai Zhang,  Abe Davis</p>
  <p><b>备注</b>：Project page at this https URL</p>
  <p><b>关键词</b>：image generation attracts, generation attracts, attracts particular attention, attention these days, days due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-view image generation attracts particular attention these days due to
its promising 3D-related applications, e.g., image viewpoint editing. Most
existing methods follow a paradigm where a 3D representation is first
synthesized, and then rendered into 2D images to ensure photo-consistency
across viewpoints. However, such explicit bias for photo-consistency sacrifices
photo-realism, causing geometry artifacts and loss of fine-scale details when
these methods are applied to edit real images. To address this issue, we
propose ray conditioning, a geometry-free alternative that relaxes the
photo-consistency constraint. Our method generates multi-view images by
conditioning a 2D GAN on a light field prior. With explicit viewpoint control,
state-of-the-art photo-realism and identity consistency, our method is
particularly suited for the viewpoint editing task.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A marker-less human motion analysis system for motion-based biomarker  discovery in knee disorders</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13678</p>
  <p><b>作者</b>：Kai Armstrong,  Lei Zhang,  Yan Wen,  Alexander P. Willmott,  Paul Lee,  Xujioing Ye</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：years the NHS, low-risk patients, suspected osteoarthritis, recent years, limited to suspected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years the NHS has been having increased difficulty seeing all
low-risk patients, this includes but not limited to suspected osteoarthritis
(OA) patients. To help address the increased waiting lists and shortages of
staff, we propose a novel method of automated biomarker identification for
diagnosis of knee disorders and the monitoring of treatment progression. The
proposed method allows for the measurement and analysis of biomechanics and
analyse their clinical significance, in both a cheap and sensitive alternative
to the currently available commercial alternatives. These methods and results
validate the capabilities of standard RGB cameras in clinical environments to
capture motion and show that when compared to alternatives such as depth
cameras there is a comparable accuracy in the clinical environment. Biomarker
identification using Principal Component Analysis (PCA) allows the reduction of
the dimensionality to produce the most representative features from motion
data, these new biomarkers can then be used to assess the success of treatment
and track the progress of rehabilitation. This was validated by applying these
techniques on a case study utilising the exploratory use of local anaesthetic
applied on knee pain, this allows these new representative biomarkers to be
validated as statistically significant (p-value < 0.05).</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain  Adaptation of Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13672</p>
  <p><b>作者</b>：Yan Wang,  Jian Cheng,  Yixin Chen,  Shuai Shao,  Lanyun Zhu,  Zhenzhou Wu,  Tao Liu,  Haogang Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Medical image segmentation, domain shift, Unsupervised Domain Adaptation, Medical image, domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image segmentation methods normally perform poorly when there is a
domain shift between training and testing data. Unsupervised Domain Adaptation
(UDA) addresses the domain shift problem by training the model using both
labeled data from the source domain and unlabeled data from the target domain.
Source-Free UDA (SFUDA) was recently proposed for UDA without requiring the
source data during the adaptation, due to data privacy or data transmission
issues, which normally adapts the pre-trained deep model in the testing stage.
However, in real clinical scenarios of medical image segmentation, the trained
model is normally frozen in the testing stage. In this paper, we propose
Fourier Visual Prompting (FVP) for SFUDA of medical image segmentation.
Inspired by prompting learning in natural language processing, FVP steers the
frozen pre-trained model to perform well in the target domain by adding a
visual prompt to the input target data. In FVP, the visual prompt is
parameterized using only a small amount of low-frequency learnable parameters
in the input frequency space, and is learned by minimizing the segmentation
loss between the predicted segmentation of the prompted target image and
reliable pseudo segmentation label of the target image under the frozen model.
To our knowledge, FVP is the first work to apply visual prompts to SFUDA for
medical image segmentation. The proposed FVP is validated using three public
datasets, and experiments demonstrate that FVP yields better segmentation
results, compared with various existing methods.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：What Happened 3 Seconds Ago? Inferring the Past with Thermal Imaging</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13651</p>
  <p><b>作者</b>：Zitian Tang,  Wenjie Ye,  Wei-Chiu Ma,  Hang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inferring past human, RGB images, prediction problem, challenging due, inherent uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inferring past human motion from RGB images is challenging due to the
inherent uncertainty of the prediction problem. Thermal images, on the other
hand, encode traces of past human-object interactions left in the environment
via thermal radiation measurement. Based on this observation, we collect the
first RGB-Thermal dataset for human motion analysis, dubbed Thermal-IM. Then we
develop a three-stage neural network model for accurate past human pose
estimation. Comprehensive experiments show that thermal cues significantly
reduce the ambiguities of this task, and the proposed model achieves remarkable
performance. The dataset is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：A Symmetric Dual Encoding Dense Retrieval Framework for  Knowledge-Intensive Visual Question Answering</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13649</p>
  <p><b>作者</b>：Alireza Salemi,  Juan Altmayer Pizzorno,  Hamed Zamani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge-Intensive Visual Question, Knowledge-Intensive Visual, Visual Question Answering, Visual Question, OK-VQA and FVQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a
question about an image whose answer does not lie in the image. This paper
presents a new pipeline for KI-VQA tasks, consisting of a retriever and a
reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval
framework in which documents and queries are encoded into a shared embedding
space using uni-modal (textual) and multi-modal encoders. We introduce an
iterative knowledge distillation approach that bridges the gap between the
representation spaces in these two encoders. Extensive evaluation on two
well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR
outperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA,
respectively. Utilizing the passages retrieved by DEDR, we further introduce
MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating
a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and
each retrieved passage separately and uses all passages jointly in its decoder.
Compared to competitive baselines in the literature, this approach leads to
5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA
and FVQA, respectively.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：PVP: Pre-trained Visual Parameter-Efficient Tuning</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13639</p>
  <p><b>作者</b>：Zhao Song,  Ke Yang,  Naiyang Guan,  Junjie Zhu,  Peng Qiao,  Qingyong Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated remarkable success, computer vision tasks, Large-scale pre-trained transformers, demonstrated remarkable, remarkable success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale pre-trained transformers have demonstrated remarkable success in
various computer vision tasks. However, it is still highly challenging to fully
fine-tune these models for downstream tasks due to their high computational and
storage costs. Recently, Parameter-Efficient Tuning (PETuning) techniques,
e.g., Visual Prompt Tuning (VPT) and Low-Rank Adaptation (LoRA), have
significantly reduced the computation and storage cost by inserting lightweight
prompt modules into the pre-trained models and tuning these prompt modules with
a small number of trainable parameters, while keeping the transformer backbone
frozen. Although only a few parameters need to be adjusted, most PETuning
methods still require a significant amount of downstream task training data to
achieve good results. The performance is inadequate on low-data regimes,
especially when there are only one or two examples per class. To this end, we
first empirically identify the poor performance is mainly due to the
inappropriate way of initializing prompt modules, which has also been verified
in the pre-trained language models. Next, we propose a Pre-trained Visual
Parameter-efficient (PVP) Tuning framework, which pre-trains the
parameter-efficient tuning modules first and then leverages the pre-trained
modules along with the pre-trained transformer backbone to perform
parameter-efficient tuning on downstream tasks. Experiment results on five
Fine-Grained Visual Classification (FGVC) and VTAB-1k datasets demonstrate that
our proposed method significantly outperforms state-of-the-art PETuning
methods.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Non-rigid Point Cloud Registration for Middle Ear Diagnostics with  Endoscopic Optical Coherence Tomography</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13618</p>
  <p><b>作者</b>：Peng Liu,  Jonas Golde,  Joseph Morgenstern,  Sebastian Bodenstedt,  Chenpan Li,  Yujia Hu,  Zhaoyu Chen,  Edmund Koch,  Marcus Neudert,  Stefanie Speidel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prevalent inflammatory disease, OCT, Middle ear, inflammatory disease, pediatric population</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: Middle ear infection is the most prevalent inflammatory disease,
especially among the pediatric population. Current diagnostic methods are
subjective and depend on visual cues from an otoscope, which is limited for
otologists to identify pathology. To address this shortcoming, endoscopic
optical coherence tomography (OCT) provides both morphological and functional
in-vivo measurements of the middle ear. However, due to the shadow of prior
structures, interpretation of OCT images is challenging and time-consuming. To
facilitate fast diagnosis and measurement, improvement in the readability of
OCT data is achieved by merging morphological knowledge from ex-vivo middle ear
models with OCT volumetric data, so that OCT applications can be further
promoted in daily clinical settings. Methods: We propose C2P-Net: a two-staged
non-rigid registration pipeline for complete to partial point clouds, which are
sampled from ex-vivo and in-vivo OCT models, respectively. To overcome the lack
of labeled training data, a fast and effective generation pipeline in Blender3D
is designed to simulate middle ear shapes and extract in-vivo noisy and partial
point clouds. Results: We evaluate the performance of C2P-Net through
experiments on both synthetic and real OCT datasets. The results demonstrate
that C2P-Net is generalized to unseen middle ear point clouds and capable of
handling realistic noise and incompleteness in synthetic and real OCT data.
Conclusion: In this work, we aim to enable diagnosis of middle ear structures
with the assistance of OCT images. We propose C2P-Net: a two-staged non-rigid
registration pipeline for point clouds to support the interpretation of in-vivo
noisy and partial OCT images for the first time. Code is available at:
this https URL\_tso\_public/c2p-net.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Domain Adaptive and Generalizable Network Architectures and Training  Strategies for Semantic Image Segmentation</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13615</p>
  <p><b>作者</b>：Lukas Hoyer,  Dengxin Dai,  Luc Van Gool</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unsupervised domain adaptation, enable machine learning, unseen target domains, Rare Class Sampling, UDA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised domain adaptation (UDA) and domain generalization (DG) enable
machine learning models trained on a source domain to perform well on unlabeled
or even unseen target domains. As previous UDA&DG semantic segmentation methods
are mostly based on outdated networks, we benchmark more recent architectures,
reveal the potential of Transformers, and design the DAFormer network tailored
for UDA&DG. It is enabled by three training strategies to avoid overfitting to
the source domain: While (1) Rare Class Sampling mitigates the bias toward
common source domain classes, (2) a Thing-Class ImageNet Feature Distance and
(3) a learning rate warmup promote feature transfer from ImageNet pretraining.
As UDA&DG are usually GPU memory intensive, most previous methods downscale or
crop images. However, low-resolution predictions often fail to preserve fine
details while models trained with cropped images fall short in capturing
long-range, domain-robust context information. Therefore, we propose HRDA, a
multi-resolution framework for UDA&DG, that combines the strengths of small
high-resolution crops to preserve fine segmentation details and large
low-resolution crops to capture long-range context dependencies with a learned
scale attention. DAFormer and HRDA significantly improve the state-of-the-art
UDA&DG by more than 10 mIoU on 5 different benchmarks. The implementation is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Multi-View Stereo Representation Revist: Region-Aware MVSNet</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13614</p>
  <p><b>作者</b>：Yisu Zhang,  Jianke Zhu,  Lixiang Lin</p>
  <p><b>备注</b>：CVPR 2023</p>
  <p><b>关键词</b>：complete geometrically-detailed objects, powerful paradigm, paradigm for reconstructing, geometrically-detailed objects, Deep learning-based multi-view</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning-based multi-view stereo has emerged as a powerful paradigm for
reconstructing the complete geometrically-detailed objects from multi-views.
Most of the existing approaches only estimate the pixel-wise depth value by
minimizing the gap between the predicted point and the intersection of ray and
surface, which usually ignore the surface topology. It is essential to the
textureless regions and surface boundary that cannot be properly reconstructed.
To address this issue, we suggest to take advantage of point-to-surface
distance so that the model is able to perceive a wider range of surfaces. To
this end, we predict the distance volume from cost volume to estimate the
signed distance of points around the surface. Our proposed RA-MVSNet is
patch-awared, since the perception range is enhanced by associating
hypothetical planes with a patch of surface. Therefore, it could increase the
completion of textureless regions and reduce the outliers at the boundary.
Moreover, the mesh topologies with fine details can be generated by the
introduced distance volume. Comparing to the conventional deep learning-based
multi-view stereo methods, our proposed RA-MVSNet approach obtains more
complete reconstruction results by taking advantage of signed distance
supervision. The experiments on both the DTU and Tanks \& Temples datasets
demonstrate that our proposed approach achieves the state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：SIMARA: a database for key-value information extraction from full pages</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13606</p>
  <p><b>作者</b>：Solène Tarride,  Mélodie Boillet,  Jean-François Moufflet,  Christopher Kermorvant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：historical handwritten documents, finding aids, historical handwritten, information extraction, handwritten documents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new database for information extraction from historical
handwritten documents. The corpus includes 5,393 finding aids from six
different series, dating from the 18th-20th centuries. Finding aids are
handwritten documents that contain metadata describing older archives. They are
stored in the National Archives of France and are used by archivists to
identify and find archival documents. Each document is annotated at page-level,
and contains seven fields to retrieve. The localization of each field is not
available in such a way that this dataset encourages research on
segmentation-free systems for information extraction. We propose a model based
on the Transformer architecture trained for end-to-end information extraction
and provide three sets for training, validation and testing, to ensure fair
comparison with future works. The database is freely accessible at
this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Video Frame Interpolation with Densely Queried Bilateral Correlation</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13596</p>
  <p><b>作者</b>：Chang Zhou,  Jie Liu,  Jie Tang,  Gangshan Wu</p>
  <p><b>备注</b>：Accepted by IJCAI 2023</p>
  <p><b>关键词</b>：Video Frame Interpolation, Frame Interpolation, motion fields, non-existent intermediate frames, motion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video Frame Interpolation (VFI) aims to synthesize non-existent intermediate
frames between existent frames. Flow-based VFI algorithms estimate intermediate
motion fields to warp the existent frames. Real-world motions' complexity and
the reference frame's absence make motion estimation challenging. Many
state-of-the-art approaches explicitly model the correlations between two
neighboring frames for more accurate motion estimation. In common approaches,
the receptive field of correlation modeling at higher resolution depends on the
motion fields estimated beforehand. Such receptive field dependency makes
common motion estimation approaches poor at coping with small and fast-moving
objects. To better model correlations and to produce more accurate motion
fields, we propose the Densely Queried Bilateral Correlation (DQBC) that gets
rid of the receptive field dependency problem and thus is more friendly to
small and fast-moving objects. The motion fields generated with the help of
DQBC are further refined and up-sampled with context features. After the motion
fields are fixed, a CNN-based SynthNet synthesizes the final interpolated
frame. Experiments show that our approach enjoys higher accuracy and less
inference time than the state-of-the-art. Source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Synthetic Aperture Anomaly Imaging</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13590</p>
  <p><b>作者</b>：Rakesh John Amala Arokia Nathan,  Oliver Bimber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conventional aerial images, synthetic aperture imaging, aperture imaging compared, integral images resulting, anomaly detection performs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Previous research has shown that in the presence of foliage occlusion,
anomaly detection performs significantly better in integral images resulting
from synthetic aperture imaging compared to applying it to conventional aerial
images. In this article, we hypothesize and demonstrate that integrating
detected anomalies is even more effective than detecting anomalies in
integrals. This results in enhanced occlusion removal, outlier suppression, and
higher chances of visually as well as computationally detecting targets that
are otherwise occluded. Our hypothesis was validated through both: simulations
and field experiments. We also present a real-time application that makes our
findings practically available for blue-light organizations and others using
commercial drone platforms. It is designed to address use-cases that suffer
from strong occlusion caused by vegetation, such as search and rescue, wildlife
observation, early wildfire detection, and sur-veillance.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Key-value information extraction from full handwritten pages</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13530</p>
  <p><b>作者</b>：Solène Tarride,  Mélodie Boillet,  Christopher Kermorvant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：digitized handwritten documents, propose a Transformer-based, Transformer-based approach, handwritten documents, digitized handwritten</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a Transformer-based approach for information extraction from
digitized handwritten documents. Our approach combines, in a single model, the
different steps that were so far performed by separate models: feature
extraction, handwriting recognition and named entity recognition. We compare
this integrated approach with traditional two-stage methods that perform
handwriting recognition before named entity recognition, and present results at
different levels: line, paragraph, and page. Our experiments show that
attention-based models are especially interesting when applied on full pages,
as they do not require any prior segmentation step. Finally, we show that they
are able to learn from key-value annotations: a list of important words with
their corresponding named entities. We compare our models to state-of-the-art
methods on three public databases (IAM, ESPOSALLES, and POPP) and outperform
previous performances on all three datasets.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Super-NeRF: View-consistent Detail Generation for NeRF super-resolution</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13518</p>
  <p><b>作者</b>：Yuqi Han,  Tao Yu,  Xiaohang Yu,  Yuwang Wang,  Qionghai Dai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural radiance field, achieved remarkable success, radiance field, achieved remarkable, success in modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The neural radiance field (NeRF) achieved remarkable success in modeling 3D
scenes and synthesizing high-fidelity novel views. However, existing NeRF-based
methods focus more on the make full use of the image resolution to generate
novel views, but less considering the generation of details under the limited
input resolution. In analogy to the extensive usage of image super-resolution,
NeRF super-resolution is an effective way to generate the high-resolution
implicit representation of 3D scenes and holds great potential applications. Up
to now, such an important topic is still under-explored. In this paper, we
propose a NeRF super-resolution method, named Super-NeRF, to generate
high-resolution NeRF from only low-resolution inputs. Given multi-view
low-resolution images, Super-NeRF constructs a consistency-controlling
super-resolution module to generate view-consistent high-resolution details for
NeRF. Specifically, an optimizable latent code is introduced for each
low-resolution input image to control the 2D super-resolution images to
converge to the view-consistent output. The latent codes of each low-resolution
image are optimized synergistically with the target Super-NeRF representation
to fully utilize the view consistency constraint inherent in NeRF construction.
We verify the effectiveness of Super-NeRF on synthetic, real-world, and
AI-generated NeRF datasets. Super-NeRF achieves state-of-the-art NeRF
super-resolution performance on high-resolution detail generation and
cross-view consistency.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Cluster Entropy: Active Domain Adaptation in Pathological Image  Segmentation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13513</p>
  <p><b>作者</b>：Xiaoqing Liu,  Kengo Araki,  Shota Harada,  Akihiko Yoshizawa,  Kazuhiro Terada,  Mariyo Kurata,  Naoki Nakajima,  Hiroyuki Abe,  Tetsuo Ushiku,  Ryoma Bise</p>
  <p><b>备注</b>：Accepted by IEEE ISBI'23</p>
  <p><b>关键词</b>：target domain, domain, domain adaptation, shift in pathological, pathological segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The domain shift in pathological segmentation is an important problem, where
a network trained by a source domain (collected at a specific hospital) does
not work well in the target domain (from different hospitals) due to the
different image features. Due to the problems of class imbalance and different
class prior of pathology, typical unsupervised domain adaptation methods do not
work well by aligning the distribution of source domain and target domain. In
this paper, we propose a cluster entropy for selecting an effective whole slide
image (WSI) that is used for semi-supervised domain adaptation. This approach
can measure how the image features of the WSI cover the entire distribution of
the target domain by calculating the entropy of each cluster and can
significantly improve the performance of domain adaptation. Our approach
achieved competitive results against the prior arts on datasets collected from
two hospitals.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：EasyPortrait -- Face Parsing and Portrait Segmentation Dataset</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13509</p>
  <p><b>作者</b>：Alexander Kapitanov,  Karina Kvanchiani,  Sofia Kirillova</p>
  <p><b>备注</b>：portrait segmentation, face parsing, image segmentation dataset</p>
  <p><b>关键词</b>：video conferencing apps, remote work, growing demand, demand for remote, conferencing apps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, due to COVID-19 and the growing demand for remote work, video
conferencing apps have become especially widespread. The most valuable features
of video chats are real-time background removal and face beautification. While
solving these tasks, computer vision researchers face the problem of having
relevant data for the training stage. There is no large dataset with
high-quality labeled and diverse images of people in front of a laptop or
smartphone camera to train a lightweight model without additional approaches.
To boost the progress in this area, we provide a new image dataset,
EasyPortrait, for portrait segmentation and face parsing tasks. It contains
20,000 primarily indoor photos of 8,377 unique users, and fine-grained
segmentation masks separated into 9 classes. Images are collected and labeled
from crowdsourcing platforms. Unlike most face parsing datasets, in
EasyPortrait, the beard is not considered part of the skin mask, and the inside
area of the mouth is separated from the teeth. These features allow using
EasyPortrait for skin enhancement and teeth whitening tasks. This paper
describes the pipeline for creating a large-scale and clean image segmentation
dataset using crowdsourcing platforms without additional synthetic data.
Moreover, we trained several models on EasyPortrait and showed experimental
results. Proposed dataset and trained models are publicly available.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Cloud-Based Deep Learning: End-To-End Full-Stack Handwritten Digit  Recognition</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13506</p>
  <p><b>作者</b>：Ruida Zeng,  Aadarsh Jha,  Ashwin Kumar,  Terry Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：present Stratus, Deep Neural Network, deep learning, Stratus, learning application deployed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Herein, we present Stratus, an end-to-end full-stack deep learning
application deployed on the cloud. The rise of productionized deep learning
necessitates infrastructure in the cloud that can provide such service (IaaS).
In this paper, we explore the use of modern cloud infrastructure and
micro-services to deliver accurate and high-speed predictions to an end-user,
using a Deep Neural Network (DNN) to predict handwritten digit input,
interfaced via a full-stack application. We survey tooling from Spark ML,
Apache Kafka, Chameleon Cloud, Ansible, Vagrant, Python Flask, Docker, and
Kubernetes in order to realize this machine learning pipeline. Through our
cloud-based approach, we are able to demonstrate benchmark performance on the
MNIST dataset with a deep learning model.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Effect of latent space distribution on the segmentation of images with  multiple annotations</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13476</p>
  <p><b>作者</b>：Ishaan Bhat,  Josien P.W. Pluim,  Max A. Viergever,  Hugo J. Kuijf</p>
  <p><b>备注</b>：Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL arXiv admin note: text overlap with arXiv:2207.12872</p>
  <p><b>关键词</b>：Generalized Probabilistic U-Net, Generalized Probabilistic, propose the Generalized, Probabilistic U-Net, latent space distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the Generalized Probabilistic U-Net, which extends the
Probabilistic U-Net by allowing more general forms of the Gaussian distribution
as the latent space distribution that can better approximate the uncertainty in
the reference segmentations. We study the effect the choice of latent space
distribution has on capturing the variation in the reference segmentations for
lung tumors and white matter hyperintensities in the brain. We show that the
choice of distribution affects the sample diversity of the predictions and
their overlap with respect to the reference segmentations. We have made our
implementation available at
this https URL</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：From Chaos Comes Order: Ordering Event Representations for Object  Detection</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13455</p>
  <p><b>作者</b>：Nikola Zubić,  Daniel Gehrig,  Mathias Gehrig,  Davide Scaramuzza</p>
  <p><b>备注</b>：Submitted to ICCV 2023</p>
  <p><b>关键词</b>：deep neural networks, grid-like input representations, neural network, grid-like input, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Today, state-of-the-art deep neural networks that process events first
convert them into dense, grid-like input representations before using an
off-the-shelf network. However, selecting the appropriate representation for
the task traditionally requires training a neural network for each
representation and selecting the best one based on the validation score, which
is very time-consuming. In this work, we eliminate this bottleneck by selecting
the best representation based on the Gromov-Wasserstein Discrepancy (GWD)
between the raw events and their representation. It is approximately 200 times
faster to compute than training a neural network and preserves the task
performance ranking of event representations across multiple representations,
network backbones, and datasets. This means that finding a representation with
a high task score is equivalent to finding a representation with a low GWD. We
use this insight to, for the first time, perform a hyperparameter search on a
large family of event representations, revealing new and powerful
representations that exceed the state-of-the-art. On object detection, our
optimized representation outperforms existing representations by 1.9% mAP on
the 1 Mpx dataset and 8.6% mAP on the Gen1 dataset and even outperforms the
state-of-the-art by 1.8% mAP on Gen1 and state-of-the-art feed-forward methods
by 6.0% mAP on the 1 Mpx dataset. This work opens a new unexplored field of
explicit representation optimization for event-based learning methods.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Neural-PBIR Reconstruction of Shape, Material, and Illumination</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13445</p>
  <p><b>作者</b>：Cheng Sun,  Guangyan Cai,  Zhengqin Li,  Kai Yan,  Cheng Zhang,  Carl Marshall,  Jia-Bin Huang,  Shuang Zhao,  Zhao Dong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spatially varying surface, varying surface appearances, vision and graphics, surrounding illumination based, spatially varying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing the shape and spatially varying surface appearances of a
physical-world object as well as its surrounding illumination based on 2D
images (e.g., photographs) of the object has been a long-standing problem in
computer vision and graphics. In this paper, we introduce a robust object
reconstruction pipeline combining neural based object reconstruction and
physics-based inverse rendering (PBIR). Specifically, our pipeline firstly
leverages a neural stage to produce high-quality but potentially imperfect
predictions of object shape, reflectance, and illumination. Then, in the later
stage, initialized by the neural predictions, we perform PBIR to refine the
initial results and obtain the final high-quality reconstruction. Experimental
results demonstrate our pipeline significantly outperforms existing
reconstruction methods quality-wise and performance-wise.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Compensation Learning in Semantic Segmentation</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13428</p>
  <p><b>作者</b>：Timo Kaiser,  Christoph Reinders,  Bodo Rosenhahn</p>
  <p><b>备注</b>：8 pages, 6 figures, 4 tables, Vision Datasets Understanding Workshop on CVPR23</p>
  <p><b>关键词</b>：semantic segmentation, Label noise, similar classes, problems in developing, developing new models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label noise and ambiguities between similar classes are challenging problems
in developing new models and annotating new data for semantic segmentation. In
this paper, we propose Compensation Learning in Semantic Segmentation, a
framework to identify and compensate ambiguities as well as label noise. More
specifically, we add a ground truth depending and globally learned bias to the
classification logits and introduce a novel uncertainty branch for neural
networks to induce the compensation bias only to relevant regions. Our method
is employed into state-of-the-art segmentation frameworks and several
experiments demonstrate that our proposed compensation learns inter-class
relations that allow global identification of challenging ambiguities as well
as the exact localization of subsequent label noise. Additionally, it enlarges
robustness against label noise during training and allows target-oriented
manipulation during inference. We evaluate the proposed method on %the widely
used datasets Cityscapes, KITTI-STEP, ADE20k, and COCO-stuff10k.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Training-Free Location-Aware Text-to-Image Synthesis</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13427</p>
  <p><b>作者</b>：Jiafeng Mao,  Xueting Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Current large-scale generative, generating high-quality images, high-quality images based, Current large-scale, text prompts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current large-scale generative models have impressive efficiency in
generating high-quality images based on text prompts. However, they lack the
ability to precisely control the size and position of objects in the generated
image. In this study, we analyze the generative mechanism of the stable
diffusion model and propose a new interactive generation paradigm that allows
users to specify the position of generated objects without additional training.
Moreover, we propose an object detection-based evaluation metric to assess the
control capability of location aware generation task. Our experimental results
show that our method outperforms state-of-the-art methods on both control
capacity and image quality.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Learnable Ophthalmology SAM</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13425</p>
  <p><b>作者</b>：Zhongxi Qiu,  Yan Hu,  Heng Li,  Jiang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ophthalmology image analysis, Learnable Ophthalmology Segment, image analysis, SAM, based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Segmentation is vital for ophthalmology image analysis. But its various modal
images hinder most of the existing segmentation algorithms applications, as
they rely on training based on a large number of labels or hold weak
generalization ability. Based on Segment Anything (SAM), we propose a simple
but effective learnable prompt layer suitable for multiple target segmentation
in ophthalmology multi-modal images, named Learnable Ophthalmology Segment
Anything (SAM). The learnable prompt layer learns medical prior knowledge from
each transformer layer. During training, we only train the prompt layer and
task head based on a one-shot mechanism. We demonstrate the effectiveness of
our thought based on four medical segmentation tasks based on nine publicly
available datasets. Moreover, we only provide a new improvement thought for
applying the existing fundamental CV models in the medical field. Our codes are
available at \href{this https URL}{website}.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Are Explainability Tools Gender Biased? A Case Study on Face  Presentation Attack Detection</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13419</p>
  <p><b>作者</b>：Marco Huber,  Meiling Fang,  Fadi Boutros,  Naser Damer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning, continue to spread, daily lives, increasing demand, demand for higher</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face recognition (FR) systems continue to spread in our daily lives with an
increasing demand for higher explainability and interpretability of FR systems
that are mainly based on deep learning. While bias across demographic groups in
FR systems has already been studied, the bias of explainability tools has not
yet been investigated. As such tools aim at steering further development and
enabling a better understanding of computer vision problems, the possible
existence of bias in their outcome can lead to a chain of biased decisions. In
this paper, we explore the existence of bias in the outcome of explainability
tools by investigating the use case of face presentation attack detection. By
utilizing two different explainability tools on models with different levels of
bias, we investigate the bias in the outcome of such tools. Our study shows
that these tools show clear signs of gender bias in the quality of their
explanations.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：DiffuseExpand: Expanding dataset for 2D medical image segmentation using  diffusion models</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13416</p>
  <p><b>作者</b>：Shitong Shao,  Xiaohan Yuan,  Zhen Huang,  Ziming Qiu,  Shuai Wang,  Kevin Zhou</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：Diffusion Probabilistic Models, labeling difficulties, effectively alleviate, alleviate the problem, privacy concerns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dataset expansion can effectively alleviate the problem of data scarcity for
medical image segmentation, due to privacy concerns and labeling difficulties.
However, existing expansion algorithms still face great challenges due to their
inability of guaranteeing the diversity of synthesized images with paired
segmentation masks. In recent years, Diffusion Probabilistic Models (DPMs) have
shown powerful image synthesis performance, even better than Generative
Adversarial Networks. Based on this insight, we propose an approach called
DiffuseExpand for expanding datasets for 2D medical image segmentation using
DPM, which first samples a variety of masks from Gaussian noise to ensure the
diversity, and then synthesizes images to ensure the alignment of images and
masks. After that, DiffuseExpand chooses high-quality samples to further
enhance the effectiveness of data expansion. Our comparison and ablation
experiments on COVID-19 and CGMH Pelvis datasets demonstrate the effectiveness
of DiffuseExpand. Our code is released at
https://anonymous.4open.science/r/DiffuseExpand.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Improving Adversarial Transferability by Intermediate-level Perturbation  Decay</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13410</p>
  <p><b>作者</b>：Qizhang Li,  Yiwen Guo,  Wangmeng Zuo,  Hao Chen</p>
  <p><b>备注</b>：Revision of ICML '23 submission for better clarity</p>
  <p><b>关键词</b>：shown favorable performance, perturb feature representations, crafting transferable adversarial, attempt to perturb, drastically have shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intermediate-level attacks that attempt to perturb feature representations
following an adversarial direction drastically have shown favorable performance
in crafting transferable adversarial examples. Existing methods in this
category are normally formulated with two separate stages, where a directional
guide is required to be determined at first and the scalar projection of the
intermediate-level perturbation onto the directional guide is enlarged
thereafter. The obtained perturbation deviates from the guide inevitably in the
feature space, and it is revealed in this paper that such a deviation may lead
to sub-optimal attack. To address this issue, we develop a novel
intermediate-level method that crafts adversarial examples within a single
stage of optimization. In particular, the proposed method, named
intermediate-level perturbation decay (ILPD), encourages the intermediate-level
perturbation to be in an effective adversarial direction and to possess a great
magnitude simultaneously. In-depth discussion verifies the effectiveness of our
method. Experimental results show that it outperforms state-of-the-arts by
large margins in attacking various victim models on ImageNet (+10.07% on
average) and CIFAR-10 (+3.88% on average). Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Efficient Explainable Face Verification based on Similarity Score  Argument Backpropagation</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13409</p>
  <p><b>作者</b>：Marco Huber,  Anh Thi Luu,  Philipp Terhörst,  Naser Damer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gaining growing attention, Explainable Face Recognition, Face Recognition, gaining growing, technology is gaining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable Face Recognition is gaining growing attention as the use of the
technology is gaining ground in security-critical applications. Understanding
why two faces images are matched or not matched by a given face recognition
system is important to operators, users, anddevelopers to increase trust,
accountability, develop better systems, and highlight unfair behavior. In this
work, we propose xSSAB, an approach to back-propagate similarity score-based
arguments that support or oppose the face matching decision to visualize
spatial maps that indicate similar and dissimilar areas as interpreted by the
underlying FR model. Furthermore, we present Patch-LFW, a new explainable face
verification benchmark that enables along with a novel evaluation protocol, the
first quantitative evaluation of the validity of similarity and dissimilarity
maps in explainable face recognition approaches. We compare our efficient
approach to state-of-the-art approaches demonstrating a superior trade-off
between efficiency and performance. The code as well as the proposed Patch-LFW
is publicly available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Development of a Realistic Crowd Simulation Environment for Fine-grained  Validation of People Tracking Methods</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13403</p>
  <p><b>作者</b>：Paweł Foszner,  Agnieszka Szczęsna,  Luca Ciampi,  Nicola Messina,  Adam Cygan,  Bartosz Bizoń,  Michał Cogiel,  Dominik Golba,  Elżbieta Macioszek,  Michał Staniszewski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthetic sources, crowd datasets, scenario-specific crowd datasets, validate generated dataset, real or synthetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generally, crowd datasets can be collected or generated from real or
synthetic sources. Real data is generated by using infrastructure-based sensors
(such as static cameras or other sensors). The use of simulation tools can
significantly reduce the time required to generate scenario-specific crowd
datasets, facilitate data-driven research, and next build functional machine
learning models. The main goal of this work was to develop an extension of
crowd simulation (named CrowdSim2) and prove its usability in the application
of people-tracking algorithms. The simulator is developed using the very
popular Unity 3D engine with particular emphasis on the aspects of realism in
the environment, weather conditions, traffic, and the movement and models of
individual agents. Finally, three methods of tracking were used to validate
generated dataset: IOU-Tracker, Deep-Sort, and Deep-TAMA.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Filter Pruning via Filters Similarity in Consecutive Layers</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13397</p>
  <p><b>作者</b>：Xiaorui Wang,  Jun Wang,  Xin Tang,  Peng Gao,  Rui Fang,  Guotong Xie</p>
  <p><b>备注</b>：Accepted by ICASSP 2023 (oral)</p>
  <p><b>关键词</b>：accelerate the Convolutional, widely adopted, adopted to compress, compress and accelerate, Convolutional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Filter pruning is widely adopted to compress and accelerate the Convolutional
Neural Networks (CNNs), but most previous works ignore the relationship between
filters and channels in different layers. Processing each layer independently
fails to utilize the collaborative relationship across layers. In this paper,
we intuitively propose a novel pruning method by explicitly leveraging the
Filters Similarity in Consecutive Layers (FSCL). FSCL compresses models by
pruning filters whose corresponding features are more worthless in the model.
The extensive experiments demonstrate the effectiveness of FSCL, and it yields
remarkable improvement over state-of-the-art on accuracy, FLOPs and parameter
reduction on several benchmark models and datasets.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：STIR: Siamese Transformer for Image Retrieval Postprocessing</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13393</p>
  <p><b>作者</b>：Aleksei Shabanov,  Aleksei Tarasov,  Sergey Nikolenko</p>
  <p><b>备注</b>：14 pages, 3 figures</p>
  <p><b>关键词</b>：metric learning approaches, Current metric learning, informative latent representations, learning approaches, image retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current metric learning approaches for image retrieval are usually based on
learning a space of informative latent representations where simple approaches
such as the cosine distance will work well. Recent state of the art methods
such as HypViT move to more complex embedding spaces that may yield better
results but are harder to scale to production environments. In this work, we
first construct a simpler model based on triplet loss with hard negatives
mining that performs at the state of the art level but does not have these
drawbacks. Second, we introduce a novel approach for image retrieval
postprocessing called Siamese Transformer for Image Retrieval (STIR) that
reranks several top outputs in a single forward pass. Unlike previously
proposed Reranking Transformers, STIR does not rely on global/local feature
extraction and directly compares a query image and a retrieved candidate on
pixel level with the usage of attention mechanism. The resulting approach
defines a new state of the art on standard image retrieval datasets: Stanford
Online Products and DeepFashion In-shop. We also release the source code at
this https URL
and an interactive demo of our approach at
https://dapladoc-oml-postprocessing-demo-srcappmain-pfh2g0.streamlit.app/.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Group Equivariant BEV for 3D Object Detection</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13390</p>
  <p><b>作者</b>：Hongwei Liu,  Jian Yang,  Jianfeng Zhang,  Dongheng Shao,  Jielong Guo,  Shaobo Li,  Xuan Tang,  Xian Wei</p>
  <p><b>备注</b>：8 pages,3 figures,accepted by International Joint Conference on Neural Networks (IJCNN)2023</p>
  <p><b>关键词</b>：attracted significant attention, achieved continuous improvement, real road scenarios, object detection, group equivariant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, 3D object detection has attracted significant attention and
achieved continuous improvement in real road scenarios. The environmental
information is collected from a single sensor or multi-sensor fusion to detect
interested objects. However, most of the current 3D object detection approaches
focus on developing advanced network architectures to improve the detection
precision of the object rather than considering the dynamic driving scenes,
where data collected from sensors equipped in the vehicle contain various
perturbation features. As a result, existing work cannot still tackle the
perturbation issue. In order to solve this problem, we propose a group
equivariant bird's eye view network (GeqBevNet) based on the group equivariant
theory, which introduces the concept of group equivariant into the BEV fusion
object detection network. The group equivariant network is embedded into the
fused BEV feature map to facilitate the BEV-level rotational equivariant
feature extraction, thus leading to lower average orientation error. In order
to demonstrate the effectiveness of the GeqBevNet, the network is verified on
the nuScenes validation dataset in which mAOE can be decreased to 0.325.
Experimental results demonstrate that GeqBevNet can extract more rotational
equivariant features in the 3D object detection of the actual road scene and
improve the performance of object orientation prediction.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：VGOS: Voxel Grid Optimization for View Synthesis from Sparse Inputs</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13386</p>
  <p><b>作者</b>：Jiakai Sun,  Zhanjie Zhang,  Jiafu Chen,  Guangyuan Li,  Boyan Ji,  Lei Zhao,  Wei Xing</p>
  <p><b>备注</b>：IJCAI 2023 Accepted (Main Track)</p>
  <p><b>关键词</b>：shown great success, view synthesis due, Neural Radiance Fields, quality and flexibility, radiance field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) has shown great success in novel view synthesis
due to its state-of-the-art quality and flexibility. However, NeRF requires
dense input views (tens to hundreds) and a long training time (hours to days)
for a single scene to generate high-fidelity images. Although using the voxel
grids to represent the radiance field can significantly accelerate the
optimization process, we observe that for sparse inputs, the voxel grids are
more prone to overfitting to the training views and will have holes and
floaters, which leads to artifacts. In this paper, we propose VGOS, an approach
for fast (3-5 minutes) radiance field reconstruction from sparse inputs (3-10
views) to address these issues. To improve the performance of voxel-based
radiance field in sparse input scenarios, we propose two methods: (a) We
introduce an incremental voxel training strategy, which prevents overfitting by
suppressing the optimization of peripheral voxels in the early stage of
reconstruction. (b) We use several regularization techniques to smooth the
voxels, which avoids degenerate solutions. Experiments demonstrate that VGOS
achieves state-of-the-art performance for sparse inputs with super-fast
convergence. Code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Streamlined Global and Local Features Combinator (SGLC) for High  Resolution Image Dehazing</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13375</p>
  <p><b>作者</b>：Bilel Benjdira,  Anas M. Ali,  Anis Koubaa</p>
  <p><b>备注</b>：Accepted in CVPR 2023 Workshops</p>
  <p><b>关键词</b>：remove atmospheric fog, Image Dehazing aims, local features, global features, Local Features Enhancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image Dehazing aims to remove atmospheric fog or haze from an image. Although
the Dehazing models have evolved a lot in recent years, few have precisely
tackled the problem of High-Resolution hazy images. For this kind of image, the
model needs to work on a downscaled version of the image or on cropped patches
from it. In both cases, the accuracy will drop. This is primarily due to the
inherent failure to combine global and local features when the image size
increases. The Dehazing model requires global features to understand the
general scene peculiarities and the local features to work better with fine and
pixel details. In this study, we propose the Streamlined Global and Local
Features Combinator (SGLC) to solve these issues and to optimize the
application of any Dehazing model to High-Resolution images. The SGLC contains
two successive blocks. The first is the Global Features Generator (GFG) which
generates the first version of the Dehazed image containing strong global
features. The second block is the Local Features Enhancer (LFE) which improves
the local feature details inside the previously generated image. When tested on
the Uformer architecture for Dehazing, SGLC increased the PSNR metric by a
significant margin. Any other model can be incorporated inside the SGLC process
to improve its efficiency on High-Resolution input data.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：SEAL: Simultaneous Label Hierarchy Exploration And Learning</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13374</p>
  <p><b>作者</b>：Zhiquan Tan,  Zihao Wang,  Yifan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enhance classification performance, classification performance, important source, source of external, external knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label hierarchy is an important source of external knowledge that can enhance
classification performance. However, most existing methods rely on predefined
label hierarchies that may not match the data distribution. To address this
issue, we propose Simultaneous label hierarchy Exploration And Learning (SEAL),
a new framework that explores the label hierarchy by augmenting the observed
labels with latent labels that follow a prior hierarchical structure. Our
approach uses a 1-Wasserstein metric over the tree metric space as an objective
function, which enables us to simultaneously learn a data-driven label
hierarchy and perform (semi-)supervised learning. We evaluate our method on
several datasets and show that it achieves superior results in both supervised
and semi-supervised scenarios and reveals insightful label structures. Our
implementation is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Deep Lifelong Cross-modal Hashing</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13357</p>
  <p><b>作者</b>：Liming Xu,  Hanqi Li,  Bochuan Zheng,  Weisheng Li,  Jiancheng Lv</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low storage cost, made significant progress, fast query speed, storage cost, made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hashing methods have made significant progress in cross-modal retrieval tasks
with fast query speed and low storage cost. Among them, deep learning-based
hashing achieves better performance on large-scale data due to its excellent
extraction and representation ability for nonlinear heterogeneous features.
However, there are still two main challenges in catastrophic forgetting when
data with new categories arrive continuously, and time-consuming for
non-continuous hashing retrieval to retrain for updating. To this end, we, in
this paper, propose a novel deep lifelong cross-modal hashing to achieve
lifelong hashing retrieval instead of re-training hash function repeatedly when
new data arrive. Specifically, we design lifelong learning strategy to update
hash functions by directly training the incremental data instead of retraining
new hash functions using all the accumulated data, which significantly reduce
training time. Then, we propose lifelong hashing loss to enable original hash
codes participate in lifelong learning but remain invariant, and further
preserve the similarity and dis-similarity among original and incremental hash
codes to maintain performance. Additionally, considering distribution
heterogeneity when new data arriving continuously, we introduce multi-label
semantic similarity to supervise hash learning, and it has been proven that the
similarity improves performance with detailed analysis. Experimental results on
benchmark datasets show that the proposed methods achieves comparative
performance comparing with recent state-of-the-art cross-modal hashing methods,
and it yields substantial average increments over 20\% in retrieval accuracy
and almost reduces over 80\% training time when new data arrives continuously.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Discrepancy-Guided Reconstruction Learning for Image Forgery Detection</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13349</p>
  <p><b>作者</b>：Zenan Shi,  Haipeng Chen,  Long Chen,  Dong Zhang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：model learning capacity, compact visual patterns, paradigm for boosting, boosting the model, model learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel image forgery detection paradigm for
boosting the model learning capacity on both forgery-sensitive and genuine
compact visual patterns. Compared to the existing methods that only focus on
the discrepant-specific patterns (\eg, noises, textures, and frequencies), our
method has a greater generalization. Specifically, we first propose a
Discrepancy-Guided Encoder (DisGE) to extract forgery-sensitive visual
patterns. DisGE consists of two branches, where the mainstream backbone branch
is used to extract general semantic features, and the accessorial discrepant
external attention branch is used to extract explicit forgery cues. Besides, a
Double-Head Reconstruction (DouHR) module is proposed to enhance genuine
compact visual patterns in different granular spaces. Under DouHR, we further
introduce a Discrepancy-Aggregation Detector (DisAD) to aggregate these genuine
compact visual patterns, such that the forgery detection capability on unknown
patterns can be improved. Extensive experimental results on four challenging
datasets validate the effectiveness of our proposed method against
state-of-the-art competitors.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：TextDeformer: Geometry Manipulation using Text Guidance</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13348</p>
  <p><b>作者</b>：William Gao,  Noam Aigerman,  Thibault Groueix,  Vladimir G. Kim,  Rana Hanocka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：input triangle mesh, guided solely, present a technique, technique for automatically, automatically producing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a technique for automatically producing a deformation of an input
triangle mesh, guided solely by a text prompt. Our framework is capable of
deformations that produce both large, low-frequency shape changes, and small
high-frequency details. Our framework relies on differentiable rendering to
connect geometry to powerful pre-trained image encoders, such as CLIP and DINO.
Notably, updating mesh geometry by taking gradient steps through differentiable
rendering is notoriously challenging, commonly resulting in deformed meshes
with significant artifacts. These difficulties are amplified by noisy and
inconsistent gradients from CLIP. To overcome this limitation, we opt to
represent our mesh deformation through Jacobians, which updates deformations in
a global, smooth manner (rather than locally-sub-optimal steps). Our key
observation is that Jacobians are a representation that favors smoother, large
deformations, leading to a global relation between vertices and pixels, and
avoiding localized noisy gradients. Additionally, to ensure the resulting shape
is coherent from all 3D viewpoints, we encourage the deep features computed on
the 2D encoding of the rendering to be consistent for a given vertex from all
viewpoints. We demonstrate that our method is capable of smoothly-deforming a
wide variety of source mesh and target text prompts, achieving both large
modifications to, e.g., body proportions of animals, as well as adding fine
semantic details, such as shoe laces on an army boot and fine details of a
face.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Concept-Monitor: Understanding DNN training through individual neurons</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13346</p>
  <p><b>作者</b>：Mohammad Ali Khan,  Tuomas Oikarinen,  Tsui-Wei Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general framework called, unified embedding space, DNN training processes, concept diversity metric, framework called Concept-Monitor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a general framework called Concept-Monitor to help
demystify the black-box DNN training processes automatically using a novel
unified embedding space and concept diversity metric. Concept-Monitor enables
human-interpretable visualization and indicators of the DNN training processes
and facilitates transparency as well as deeper understanding on how DNNs
develop along the during training. Inspired by these findings, we also propose
a new training regularizer that incentivizes hidden neurons to learn diverse
concepts, which we show to improve training performance. Finally, we apply
Concept-Monitor to conduct several case studies on different training paradigms
including adversarial training, fine-tuning and network pruning via the Lottery
Ticket Hypothesis</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Technical Note: Defining and Quantifying AND-OR Interactions for  Faithful and Concise Explanation of DNNs</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13312</p>
  <p><b>作者</b>：Mingjie Li,  Quanshi Zhang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2111.06206</p>
  <p><b>关键词</b>：deep neural network, technical note, neural network, aim to explain, explain a deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this technical note, we aim to explain a deep neural network (DNN) by
quantifying the encoded interactions between input variables, which reflects
the DNN's inference logic. Specifically, we first rethink the definition of
interactions, and then formally define faithfulness and conciseness for
interaction-based explanation. To this end, we propose two kinds of
interactions, i.e., the AND interaction and the OR interaction. For
faithfulness, we prove the uniqueness of the AND (OR) interaction in
quantifying the effect of the AND (OR) relationship between input variables.
Besides, based on AND-OR interactions, we design techniques to boost the
conciseness of the explanation, while not hurting the faithfulness. In this
way, the inference logic of a DNN can be faithfully and concisely explained by
a set of symbolic concepts.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving  Few-Shot Learning</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13287</p>
  <p><b>作者</b>：Yi Rong,  Xiongbo Lu,  Zhaoyang Sun,  Yaxiong Chen,  Shengwu Xiong</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：shown promising results, existing SSL approaches, techniques have recently, FSL, recently been integrated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) techniques have recently been integrated into
the few-shot learning (FSL) framework and have shown promising results in
improving the few-shot image classification performance. However, existing SSL
approaches used in FSL typically seek the supervision signals from the global
embedding of every single image. Therefore, during the episodic training of
FSL, these methods cannot capture and fully utilize the local visual
information in image samples and the data structure information of the whole
episode, which are beneficial to FSL. To this end, we propose to augment the
few-shot learning objective with a novel self-supervised Episodic Spatial
Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its
corresponding transformed episode by applying a random geometric transformation
to all the images in it. Based on these, our ESPT objective is defined as
maximizing the local spatial relationship consistency between the original
episode and the transformed one. With this definition, the ESPT-augmented FSL
objective promotes learning more transferable feature representations that
capture the local spatial features of different images and their
inter-relational structural information in each input episode, thus enabling
the model to generalize better to new categories with only a few samples.
Extensive experiments indicate that our ESPT method achieves new
state-of-the-art performance for few-shot image classification on three
mainstay benchmark datasets. The source code will be available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：From Association to Generation: Text-only Captioning by Unsupervised  Cross-modal Mapping</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13273</p>
  <p><b>作者</b>：Junyang Wang,  Ming Yan,  Yi Zhang,  Ming Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：association-based visual tasks, Vision-Language Pre-training Models, significant breakthroughs, CLIP, development of Vision-Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of Vision-Language Pre-training Models (VLPMs)
represented by CLIP and ALIGN, significant breakthroughs have been achieved for
association-based visual tasks such as image classification and image-text
retrieval by the zero-shot capability of CLIP without fine-tuning. However,
CLIP is hard to apply to generation-based tasks. This is due to the lack of
decoder architecture and pre-training tasks for generation. Although previous
works have created generation capacity for CLIP through additional language
models, a modality gap between the CLIP representations of different modalities
and the inability of CLIP to model the offset of this gap, which fails the
concept to transfer across modalities. To solve the problem, we try to map
images/videos to the language modality and generate captions from the language
modality. In this paper, we propose the K-nearest-neighbor Cross-modality
Mapping (Knight), a zero-shot method from association to generation. With
text-only unsupervised training, Knight achieves state-of-the-art performance
in zero-shot methods for image captioning and video captioning. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：StepFormer: Self-supervised Step Discovery and Localization in  Instructional Videos</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13265</p>
  <p><b>作者</b>：Nikita Dvornik,  Isma Hadji,  Ran Zhang,  Konstantinos G. Derpanis,  Animesh Garg,  Richard P. Wildes,  Allan D. Jepson</p>
  <p><b>备注</b>：CVPR'23</p>
  <p><b>关键词</b>：learn procedural tasks, important resource, resource to learn, learn procedural, instruction steps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instructional videos are an important resource to learn procedural tasks from
human demonstrations. However, the instruction steps in such videos are
typically short and sparse, with most of the video being irrelevant to the
procedure. This motivates the need to temporally localize the instruction steps
in such videos, i.e. the task called key-step localization. Traditional methods
for key-step localization require video-level human annotations and thus do not
scale to large datasets. In this work, we tackle the problem with no human
supervision and introduce StepFormer, a self-supervised model that discovers
and localizes instruction steps in a video. StepFormer is a transformer decoder
that attends to the video with learnable queries, and produces a sequence of
slots capturing the key-steps in the video. We train our system on a large
dataset of instructional videos, using their automatically-generated subtitles
as the only source of supervision. In particular, we supervise our system with
a sequence of text narrations using an order-aware loss function that filters
out irrelevant phrases. We show that our model outperforms all previous
unsupervised and weakly-supervised approaches on step detection and
localization by a large margin on three challenging benchmarks. Moreover, our
model demonstrates an emergent property to solve zero-shot multi-step
localization and outperforms all relevant baselines at this task.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Learning to Predict Navigational Patterns from Partial Observations</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13242</p>
  <p><b>作者</b>：Robin Karlsson,  Alexander Carballo,  Francisco Lepe-Salazar,  Keisuke Fujii,  Kento Ohtani,  Kazuya Takeda</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：cooperatively navigate rule-constrained, navigate rule-constrained environments, navigational patterns, Human beings cooperatively, cooperatively navigate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human beings cooperatively navigate rule-constrained environments by adhering
to mutually known navigational patterns, which may be represented as
directional pathways or road lanes. Inferring these navigational patterns from
incompletely observed environments is required for intelligent mobile robots
operating in unmapped locations. However, algorithmically defining these
navigational patterns is nontrivial. This paper presents the first
self-supervised learning (SSL) method for learning to infer navigational
patterns in real-world environments from partial observations only. We explain
how geometric data augmentation, predictive world modeling, and an
information-theoretic regularizer enables our model to predict an unbiased
local directional soft lane probability (DSLP) field in the limit of infinite
data. We demonstrate how to infer global navigational patterns by fitting a
maximum likelihood graph to the DSLP field. Experiments show that our SSL model
outperforms two SOTA supervised lane graph prediction models on the nuScenes
dataset. We propose our SSL method as a scalable and interpretable continual
learning paradigm for navigation by perception. Code released upon publication.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Structure Diagram Recognition in Financial Announcements</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13240</p>
  <p><b>作者</b>：Meixuan Qiao,  Jun Wang,  Junfu Xiang,  Qiyu Hou,  Ruixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Accurately extracting structured, extracting structured data, great practical importance, building financial knowledge, financial knowledge graphs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately extracting structured data from structure diagrams in financial
announcements is of great practical importance for building financial knowledge
graphs and further improving the efficiency of various financial applications.
First, we proposed a new method for recognizing structure diagrams in financial
announcements, which can better detect and extract different types of
connecting lines, including straight lines, curves, and polylines of different
orientations and angles. Second, we developed a two-stage method to efficiently
generate the industry's first benchmark of structure diagrams from Chinese
financial announcements, where a large number of diagrams were synthesized and
annotated using an automated tool to train a preliminary recognition model with
fairly good performance, and then a high-quality benchmark can be obtained by
automatically annotating the real-world structure diagrams using the
preliminary model and then making few manual corrections. Finally, we
experimentally verified the significant performance advantage of our structure
diagram recognition method over previous methods.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Generating Adversarial Examples with Task Oriented Multi-Objective  Optimization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13229</p>
  <p><b>作者</b>：Anh Bui,  Trung Le,  He Zhao,  Quan Tran,  Paul Montague,  Dinh Phung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning models, Deep learning, adversarial, highly vulnerable, Adversarial training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models, even the-state-of-the-art ones, are highly vulnerable
to adversarial examples. Adversarial training is one of the most efficient
methods to improve the model's robustness. The key factor for the success of
adversarial training is the capability to generate qualified and divergent
adversarial examples which satisfy some objectives/goals (e.g., finding
adversarial examples that maximize the model losses for simultaneously
attacking multiple models). Therefore, multi-objective optimization (MOO) is a
natural tool for adversarial example generation to achieve multiple
objectives/goals simultaneously. However, we observe that a naive application
of MOO tends to maximize all objectives/goals equally, without caring if an
objective/goal has been achieved yet. This leads to useless effort to further
improve the goal-achieved tasks, while putting less focus on the
goal-unachieved tasks. In this paper, we propose \emph{Task Oriented MOO} to
address this issue, in the context where we can explicitly define the goal
achievement for a task. Our principle is to only maintain the goal-achieved
tasks, while letting the optimizer spend more effort on improving the
goal-unachieved tasks. We conduct comprehensive experiments for our Task
Oriented MOO on various adversarial example generation schemes. The
experimental results firmly demonstrate the merit of our proposed approach. Our
code is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：ZRG: A High Resolution 3D Residential Rooftop Geometry Dataset for  Machine Learning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13219</p>
  <p><b>作者</b>：Isaac Corley,  Jonathan Lwowski,  Peyman Najafirad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Zeitview Rooftop Geometry, residential rooftop geometry, present the Zeitview, Zeitview Rooftop, Rooftop Geometry</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present the Zeitview Rooftop Geometry (ZRG) dataset. ZRG
contains thousands of samples of high resolution orthomosaics of aerial imagery
of residential rooftops with corresponding digital surface models (DSM), 3D
rooftop wireframes, and multiview imagery generated point clouds for the
purpose of residential rooftop geometry and scene understanding. We perform
thorough benchmarks to illustrate the numerous applications unlocked by this
dataset and provide baselines for the tasks of roof outline extraction,
monocular height estimation, and planar roof structure extraction.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Exploiting CNNs for Semantic Segmentation with Pascal VOC</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13216</p>
  <p><b>作者</b>：Sourabh Prakash,  Priyanshi Shah,  Ashrya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pixel accuracy, Pascal VOC dataset, Fully Convolution Network, Pascal VOC, accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a comprehensive study on semantic segmentation with
the Pascal VOC dataset. Here, we have to label each pixel with a class which in
turn segments the entire image based on the objects/entities present. To tackle
this, we firstly use a Fully Convolution Network (FCN) baseline which gave
71.31% pixel accuracy and 0.0527 mean IoU. We analyze its performance and
working and subsequently address the issues in the baseline with three
improvements: a) cosine annealing learning rate scheduler(pixel accuracy:
72.86%, IoU: 0.0529), b) data augmentation(pixel accuracy: 69.88%, IoU: 0.0585)
c) class imbalance weights(pixel accuracy: 68.98%, IoU: 0.0596). Apart from
these changes in training pipeline, we also explore three different
architectures: a) Our proposed model -- Advanced FCN (pixel accuracy: 67.20%,
IoU: 0.0602) b) Transfer Learning with ResNet (Best performance) (pixel
accuracy: 71.33%, IoU: 0.0926 ) c) U-Net(pixel accuracy: 72.15%, IoU: 0.0649).
We observe that the improvements help in greatly improving the performance, as
reflected both, in metrics and segmentation maps. Interestingly, we observe
that among the improvements, dataset augmentation has the greatest
contribution. Also, note that transfer learning model performs the best on the
pascal dataset. We analyse the performance of these using loss, accuracy and
IoU plots along with segmentation maps, which help us draw valuable insights
about the working of the models.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Single-View Height Estimation with Conditional Diffusion Probabilistic  Models</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13214</p>
  <p><b>作者</b>：Isaac Corley,  Peyman Najafirad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding the Earth, Earth surface, offer a wealth, man-made structures, information for understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Digital Surface Models (DSM) offer a wealth of height information for
understanding the Earth's surface as well as monitoring the existence or change
in natural and man-made structures. Classical height estimation requires
multi-view geospatial imagery or LiDAR point clouds which can be expensive to
acquire. Single-view height estimation using neural network based models shows
promise however it can struggle with reconstructing high resolution features.
The latest advancements in diffusion models for high resolution image synthesis
and editing have yet to be utilized for remote sensing imagery, particularly
height estimation. Our approach involves training a generative diffusion model
to learn the joint distribution of optical and DSM images across both domains
as a Markov chain. This is accomplished by minimizing a denoising score
matching objective while being conditioned on the source image to generate
realistic high resolution 3D surfaces. In this paper we experiment with
conditional denoising diffusion probabilistic models (DDPM) for height
estimation from a single remotely sensed image and show promising results on
the Vaihingen benchmark dataset.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：EverLight: Indoor-Outdoor Editable HDR Lighting Estimation</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13207</p>
  <p><b>作者</b>：Mohammad Reza Karimi Dastjerdi,  Yannick Hold-Geoffroy,  Jonathan Eisenmann,  Jean-François Lalonde</p>
  <p><b>备注</b>：11 pages, 7 figures</p>
  <p><b>关键词</b>：existing illumination estimation, illumination estimation techniques, estimation techniques, designed explicitly, lighting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Because of the diversity in lighting environments, existing illumination
estimation techniques have been designed explicitly on indoor or outdoor
environments. Methods have focused specifically on capturing accurate energy
(e.g., through parametric lighting models), which emphasizes shading and strong
cast shadows; or producing plausible texture (e.g., with GANs), which
prioritizes plausible reflections. Approaches which provide editable lighting
capabilities have been proposed, but these tend to be with simplified lighting
models, offering limited realism. In this work, we propose to bridge the gap
between these recent trends in the literature, and propose a method which
combines a parametric light model with 360° panoramas, ready to use as
HDRI in rendering engines. We leverage recent advances in GAN-based LDR
panorama extrapolation from a regular image, which we extend to HDR using
parametric spherical gaussians. To achieve this, we introduce a novel lighting
co-modulation method that injects lighting-related features throughout the
generator, tightly coupling the original or edited scene illumination within
the panorama generation process. In our representation, users can easily edit
light direction, intensity, number, etc. to impact shading while providing
rich, complex reflections while seamlessly blending with the edits.
Furthermore, our method encompasses indoor and outdoor environments,
demonstrating state-of-the-art results even when compared to domain-specific
methods.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Graph-CoVis: GNN-based Multi-view Panorama Global Pose Estimation</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13201</p>
  <p><b>作者</b>：Negar Nejatishahidin,  Will Hutchcroft,  Manjunath Narayana,  Ivaylo Boyadzhiev,  Yuguang Li,  Naji Khosravan,  Jana Kosecka,  Sing Bing Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：camera pose estimation, upright-camera assumption, address the problem, camera pose, pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we address the problem of wide-baseline camera pose estimation
from a group of 360$^\circ$ panoramas under upright-camera assumption. Recent
work has demonstrated the merit of deep-learning for end-to-end direct relative
pose regression in 360$^\circ$ panorama pairs [11]. To exploit the benefits of
multi-view logic in a learning-based framework, we introduce Graph-CoVis, which
non-trivially extends CoVisPose [11] from relative two-view to global
multi-view spherical camera pose estimation. Graph-CoVis is a novel Graph
Neural Network based architecture that jointly learns the co-visible structure
and global motion in an end-to-end and fully-supervised approach. Using the
ZInD [4] dataset, which features real homes presenting wide-baselines,
occlusion, and limited visual overlap, we show that our model performs
competitively to state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Towards Reliable Colorectal Cancer Polyps Classification via Vision  Based Tactile Sensing and Confidence-Calibrated Neural Networks</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13192</p>
  <p><b>作者</b>：Siddhartha Kapuria,  Tarunraj G. Mohanraj,  Nethra Venkatayogi,  Ozdemir Can Kara,  Yuki Hirata,  Patrick Minot,  Ariel Kapusta,  Naruhiko Ikoma,  Farshid Alambeigi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligence-based colorectal cancer, existing artificial intelligence-based, artificial intelligence-based colorectal, polyp classification techniques, CRC polyps classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, toward addressing the over-confident outputs of existing
artificial intelligence-based colorectal cancer (CRC) polyp classification
techniques, we propose a confidence-calibrated residual neural network.
Utilizing a novel vision-based tactile sensing (VS-TS) system and unique CRC
polyp phantoms, we demonstrate that traditional metrics such as accuracy and
precision are not sufficient to encapsulate model performance for handling a
sensitive CRC polyp diagnosis. To this end, we develop a residual neural
network classifier and address its over-confident outputs for CRC polyps
classification via the post-processing method of temperature scaling. To
evaluate the proposed method, we introduce noise and blur to the obtained
textural images of the VS-TS and test the model's reliability for non-ideal
inputs through reliability diagrams and other statistical metrics.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Sample-Specific Debiasing for Better Image-Text Models</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13181</p>
  <p><b>作者</b>：Peiqi Wang,  Yingcheng Liu,  Ching-Yun Ko,  William M. Wells,  Seth Berkowitz,  Steven Horng,  Polina Golland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial medical applications, facilitates crucial medical, data facilitates crucial, visual grounding, medical applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised representation learning on image-text data facilitates
crucial medical applications, such as image classification, visual grounding,
and cross-modal retrieval. One common approach involves contrasting
semantically similar (positive) and dissimilar (negative) pairs of data points.
Drawing negative samples uniformly from the training data set introduces false
negatives, i.e., samples that are treated as dissimilar but belong to the same
class. In healthcare data, the underlying class distribution is nonuniform,
implying that false negatives occur at a highly variable rate. To improve the
quality of learned representations, we develop a novel approach that corrects
for false negatives. Our method can be viewed as a variant of debiased
constrastive learning that uses estimated sample-specific class probabilities.
We provide theoretical analysis of the objective function and demonstrate the
proposed approach on both image and paired image-text data sets. Our
experiments demonstrate empirical advantages of sample-specific debiasing.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13166</p>
  <p><b>作者</b>：Sheng Liu,  Cong Phuoc Huynh,  Cong Chen,  Maxim Arap,  Raffay Hamid</p>
  <p><b>备注</b>：Accepted by CVPR'23, 19 pages</p>
  <p><b>关键词</b>：leverage large-scale unannotated, effective self-supervised pre-training, large-scale unannotated image, Masked Region Transform, present a simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a simple yet effective self-supervised pre-training method for
image harmonization which can leverage large-scale unannotated image datasets.
To achieve this goal, we first generate pre-training data online with our
Label-Efficient Masked Region Transform (LEMaRT) pipeline. Given an image,
LEMaRT generates a foreground mask and then applies a set of transformations to
perturb various visual attributes, e.g., defocus blur, contrast, saturation, of
the region specified by the generated mask. We then pre-train image
harmonization models by recovering the original image from the perturbed image.
Secondly, we introduce an image harmonization model, namely SwinIH, by
retrofitting the Swin Transformer [27] with a combination of local and global
self-attention mechanisms. Pre-training SwinIH with LEMaRT results in a new
state of the art for image harmonization, while being label-efficient, i.e.,
consuming less annotated data for fine-tuning than existing methods. Notably,
on iHarmony4 dataset [8], SwinIH outperforms the state of the art, i.e., SCS-Co
[16] by a margin of 0.4 dB when it is fine-tuned on only 50% of the training
data, and by 1.0 dB when it is trained on the full training dataset.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：LumiGAN: Unconditional Generation of Relightable 3D Human Faces</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13153</p>
  <p><b>作者</b>：Boyang Deng,  Yifan Wang,  Gordon Wetzstein</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：active research area, Unsupervised learning, research area, Generative Adversarial Network, active research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised learning of 3D human faces from unstructured 2D image data is an
active research area. While recent works have achieved an impressive level of
photorealism, they commonly lack control of lighting, which prevents the
generated assets from being deployed in novel environments. To this end, we
introduce LumiGAN, an unconditional Generative Adversarial Network (GAN) for 3D
human faces with a physically based lighting module that enables relighting
under novel illumination at inference time. Unlike prior work, LumiGAN can
create realistic shadow effects using an efficient visibility formulation that
is learned in a self-supervised manner. LumiGAN generates plausible physical
properties for relightable faces, including surface normals, diffuse albedo,
and specular tint without any ground truth data. In addition to relightability,
we demonstrate significantly improved geometry generation compared to
state-of-the-art non-relightable 3D GANs and notably better photorealism than
existing relightable GANs.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Self-Supervised Multi-Object Tracking From Consistency Across Timescales</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13147</p>
  <p><b>作者</b>：Christopher Lang,  Alexander Braun,  Lars Schillingmann,  Abhinav Valada</p>
  <p><b>备注</b>：8 pages, 3 figures, 5 tables</p>
  <p><b>关键词</b>：data recorded worldwide, raw data recorded, recorded worldwide, potential to leverage, leverage the vast</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised multi-object trackers have the potential to leverage the vast
amounts of raw data recorded worldwide. However, they still fall short in
re-identification accuracy compared to their supervised counterparts. We
hypothesize that this deficiency results from restricting self-supervised
objectives to single frames or frame pairs. Such designs lack sufficient visual
appearance variations during training to learn consistent re-identification
features. Therefore, we propose a training objective that learns
re-identification features over a sequence of frames by enforcing consistent
association scores across short and long timescales. Extensive evaluations on
the BDD100K and MOT17 benchmarks demonstrate that our learned ReID features
significantly reduce ID switches compared to other self-supervised methods,
setting the new state of the art for self-supervised multi-object tracking and
even performing on par with supervised methods on the BDD100k benchmark.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Self-Supervised Temporal Analysis of Spatiotemporal Data</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13143</p>
  <p><b>作者</b>：Yi Cao,  Swetava Ganguli,  Vipul Pandey</p>
  <p><b>备注</b>：Accepted for oral presentation at the 43rd IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2023, Pasadena, California. 4 pages and 7 figures</p>
  <p><b>关键词</b>：exists a correlation, type of land, time series, time, series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There exists a correlation between geospatial activity temporal patterns and
type of land use. A novel self-supervised approach is proposed to stratify
landscape based on mobility activity time series. First, the time series signal
is transformed to the frequency domain and then compressed into task-agnostic
temporal embeddings by a contractive autoencoder, which preserves cyclic
temporal patterns observed in time series. The pixel-wise embeddings are
converted to image-like channels that can be used for task-based, multimodal
modeling of downstream geospatial tasks using deep semantic segmentation.
Experiments show that temporal embeddings are semantically meaningful
representations of time series data and are effective across different tasks
such as classifying residential area and commercial areas.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：CN-DHF: Compact Neural Double Height-Field Representations of 3D Shapes</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13141</p>
  <p><b>作者</b>：Eric Hedlin,  Jinfan Yang,  Nicholas Vining,  Kwang Moo Yi,  Alla Sheffer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hybrid neural implicit, Compact Neural, introduce CN-DHF, current state, dramatically more compact</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce CN-DHF (Compact Neural Double-Height-Field), a novel hybrid
neural implicit 3D shape representation that is dramatically more compact than
the current state of the art. Our representation leverages Double-Height-Field
(DHF) geometries, defined as closed shapes bounded by a pair of oppositely
oriented height-fields that share a common axis, and leverages the following
key observations: DHFs can be compactly encoded as 2D neural implicits that
capture the maximal and minimal heights along the DHF axis; and typical closed
3D shapes are well represented as intersections of a very small number (three
or fewer) of DHFs. We represent input geometries as CNDHFs by first computing
the set of DHFs whose intersection well approximates each input shape, and then
encoding these DHFs via neural fields. Our approach delivers high-quality
reconstructions, and reduces the reconstruction error by a factor of 2:5 on
average compared to the state-of-the-art, given the same parameter count or
storage capacity. Compared to the best-performing alternative, our method
produced higher accuracy models on 94% of the 400 input shape and parameter
count combinations tested.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Hypernymization of named entity-rich captions for grounding-based  multi-modal pretraining</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13130</p>
  <p><b>作者</b>：Giacomo Nebbia,  Adriana Kovashka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：naturally accompanies images, Wikipedia articles, Named entities, ubiquitous in text, text that naturally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Named entities are ubiquitous in text that naturally accompanies images,
especially in domains such as news or Wikipedia articles. In previous work,
named entities have been identified as a likely reason for low performance of
image-text retrieval models pretrained on Wikipedia and evaluated on named
entities-free benchmark datasets. Because they are rarely mentioned, named
entities could be challenging to model. They also represent missed learning
opportunities for self-supervised models: the link between named entity and
object in the image may be missed by the model, but it would not be if the
object were mentioned using a more common term. In this work, we investigate
hypernymization as a way to deal with named entities for pretraining
grounding-based multi-modal models and for fine-tuning on open-vocabulary
detection. We propose two ways to perform hypernymization: (1) a ``manual''
pipeline relying on a comprehensive ontology of concepts, and (2) a ``learned''
approach where we train a language model to learn to perform hypernymization.
We run experiments on data from Wikipedia and from The New York Times. We
report improved pretraining performance on objects of interest following
hypernymization, and we show the promise of hypernymization on open-vocabulary
detection, specifically on classes not seen during training.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：AVFace: Towards Detailed Audio-Visual 4D Face Reconstruction</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13115</p>
  <p><b>作者</b>：Aggelina Chatziagapi,  Dimitris Samaras</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：face reconstruction, present a multimodal, multimodal solution, reconstruction from monocular, face</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we present a multimodal solution to the problem of 4D face
reconstruction from monocular videos. 3D face reconstruction from 2D images is
an under-constrained problem due to the ambiguity of depth. State-of-the-art
methods try to solve this problem by leveraging visual information from a
single image or video, whereas 3D mesh animation approaches rely more on audio.
However, in most cases (e.g. AR/VR applications), videos include both visual
and speech information. We propose AVFace that incorporates both modalities and
accurately reconstructs the 4D facial and lip motion of any speaker, without
requiring any 3D ground truth for training. A coarse stage estimates the
per-frame parameters of a 3D morphable model, followed by a lip refinement, and
then a fine stage recovers facial geometric details. Due to the temporal audio
and video information captured by transformer-based modules, our method is
robust in cases when either modality is insufficient (e.g. face occlusions).
Extensive qualitative and quantitative evaluation demonstrates the superiority
of our method over the current state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：BO-ICP: Initialization of Iterative Closest Point Based on Bayesian  Optimization</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13114</p>
  <p><b>作者</b>：Harel Biggie,  Andrew Beathard,  Christoffer Heckman</p>
  <p><b>备注</b>：IEEE International Conference on Robotics and Automation 2023</p>
  <p><b>关键词</b>：Iterative Closest, Closest, point cloud registration, Iterative, point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Typical algorithms for point cloud registration such as Iterative Closest
Point (ICP) require a favorable initial transform estimate between two point
clouds in order to perform a successful registration. State-of-the-art methods
for choosing this starting condition rely on stochastic sampling or global
optimization techniques such as branch and bound. In this work, we present a
new method based on Bayesian optimization for finding the critical initial ICP
transform. We provide three different configurations for our method which
highlights the versatility of the algorithm to both find rapid results and
refine them in situations where more runtime is available such as offline map
building. Experiments are run on popular data sets and we show that our
approach outperforms state-of-the-art methods when given similar computation
time. Furthermore, it is compatible with other improvements to ICP, as it
focuses solely on the selection of an initial transform, a starting point for
all ICP-based methods.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Objectives Matter: Understanding the Impact of Self-Supervised  Objectives on Vision Transformer Representations</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13089</p>
  <p><b>作者</b>：Shashank Shekhar,  Florian Bordes,  Pascal Vincent,  Ari Morcos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joint-embedding based learning, vision transformers, leading paradigms, paradigms for self-supervised, differ substantially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Joint-embedding based learning (e.g., SimCLR, MoCo, DINO) and
reconstruction-based learning (e.g., BEiT, SimMIM, MAE) are the two leading
paradigms for self-supervised learning of vision transformers, but they differ
substantially in their transfer performance. Here, we aim to explain these
differences by analyzing the impact of these objectives on the structure and
transferability of the learned representations. Our analysis reveals that
reconstruction-based learning features are significantly dissimilar to
joint-embedding based learning features and that models trained with similar
objectives learn similar features even across architectures. These differences
arise early in the network and are primarily driven by attention and
normalization layers. We find that joint-embedding features yield better linear
probe transfer for classification because the different objectives drive
different distributions of information and invariances in the learned
representation. These differences explain opposite trends in transfer
performance for downstream tasks that require spatial specificity in features.
Finally, we address how fine-tuning changes reconstructive representations to
enable better transfer, showing that fine-tuning re-organizes the information
to be more similar to pre-trained joint embedding models.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：iMixer: hierarchical Hopfield network implies an invertible, implicit  and iterative MLP-Mixer</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13061</p>
  <p><b>作者</b>：Toshihiro Ota,  Masato Taki</p>
  <p><b>备注</b>：12 pages, 3 figures</p>
  <p><b>关键词</b>：computer vision, vision has stimulated, stimulated the discovery, Hopfield networks, alternative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last few years, the success of Transformers in computer vision has
stimulated the discovery of many alternative models that compete with
Transformers, such as the MLP-Mixer. Despite their weak induced bias, these
models have achieved performance comparable to well-studied convolutional
neural networks. Recent studies on modern Hopfield networks suggest the
correspondence between certain energy-based associative memory models and
Transformers or MLP-Mixer, and shed some light on the theoretical background of
the Transformer-type architectures design. In this paper we generalize the
correspondence to the recently introduced hierarchical Hopfield network, and
find iMixer, a novel generalization of MLP-Mixer model. Unlike ordinary
feedforward neural networks, iMixer involves MLP layers that propagate forward
from the output side to the input side. We characterize the module as an
example of invertible, implicit, and iterative mixing module. We evaluate the
model performance with various datasets on image classification tasks, and find
that iMixer reasonably achieves the improvement compared to the baseline
vanilla MLP-Mixer. The results imply that the correspondence between the
Hopfield networks and the Mixer models serves as a principle for understanding
a broader class of Transformer-like architecture designs.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：HDR-VDP-3: A multi-metric for predicting image differences, quality and  contrast distortions in high dynamic range and regular content</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13625</p>
  <p><b>作者</b>：Rafal K. Mantiuk,  Dounia Hammou,  Param Hanji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video quality assessment, HDR Video Quality, Video Quality Measurement, Quality Measurement Grand, Measurement Grand Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-Dynamic-Range Visual-Difference-Predictor version 3, or HDR-VDP-3, is a
visual metric that can fulfill several tasks, such as full-reference
image/video quality assessment, prediction of visual differences between a pair
of images, or prediction of contrast distortions. Here we present a high-level
overview of the metric, position it with respect to related work, explain the
main differences compared to version 2.2, and describe how the metric was
adapted for the HDR Video Quality Measurement Grand Challenge 2023.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Energy-Based Sliced Wasserstein Distance</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13586</p>
  <p><b>作者</b>：Khai Nguyen,  Nhat Ho</p>
  <p><b>备注</b>：36 pages, 7 figures, 6 tables</p>
  <p><b>关键词</b>：computationally efficient metric, widely recognized, statistically effective, effective and computationally, computationally efficient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The sliced Wasserstein (SW) distance has been widely recognized as a
statistically effective and computationally efficient metric between two
probability measures. A key component of the SW distance is the slicing
distribution. There are two existing approaches for choosing this distribution.
The first approach is using a fixed prior distribution. The second approach is
optimizing for the best distribution which belongs to a parametric family of
distributions and can maximize the expected distance. However, both approaches
have their limitations. A fixed prior distribution is non-informative in terms
of highlighting projecting directions that can discriminate two general
probability measures. Doing optimization for the best distribution is often
expensive and unstable. Moreover, designing the parametric family of the
candidate distribution could be easily misspecified. To address the issues, we
propose to design the slicing distribution as an energy-based distribution that
is parameter-free and has the density proportional to an energy function of the
projected one-dimensional Wasserstein distance. We then derive a novel sliced
Wasserstein metric, energy-based sliced Waserstein (EBSW) distance, and
investigate its topological, statistical, and computational properties via
importance sampling, sampling importance resampling, and Markov Chain methods.
Finally, we conduct experiments on point-cloud gradient flow, color transfer,
and point-cloud reconstruction to show the favorable performance of the EBSW.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Multi-Modality Deep Network for Extreme Learned Image Compression</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13583</p>
  <p><b>作者</b>：Xuhao Jiang,  Weimin Tan,  Tian Tan,  Bo Yan,  Liquan Shen</p>
  <p><b>备注</b>：13 pages, 14 figures, accepted by AAAI 2023</p>
  <p><b>关键词</b>：demonstrated exceptionally powerful, exceptionally powerful encoding, Image-based single-modality compression, compression learning approaches, single-modality compression learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-based single-modality compression learning approaches have demonstrated
exceptionally powerful encoding and decoding capabilities in the past few years
, but suffer from blur and severe semantics loss at extremely low bitrates. To
address this issue, we propose a multimodal machine learning method for
text-guided image compression, in which the semantic information of text is
used as prior information to guide image compression for better compression
performance. We fully study the role of text description in different
components of the codec, and demonstrate its effectiveness. In addition, we
adopt the image-text attention module and image-request complement module to
better fuse image and text features, and propose an improved multimodal
semantic-consistent loss to produce semantically complete reconstructions.
Extensive experiments, including a user study, prove that our method can obtain
visually pleasing results at extremely low bitrates, and achieves a comparable
or even better performance than state-of-the-art methods, even though these
methods are at 2x to 4x bitrates of ours.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Tissue Classification During Needle Insertion Using Self-Supervised  Contrastive Learning and Optical Coherence Tomography</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13574</p>
  <p><b>作者</b>：Debayan Bhattacharya,  Sarah Latus,  Finn Behrendt,  Florin Thimm,  Dennis Eggert,  Christian Betz,  Alexander Schlaefer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：positioning is essential, medical applications, epidural anaesthesia, Needle positioning, phase and intensity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Needle positioning is essential for various medical applications such as
epidural anaesthesia. Physicians rely on their instincts while navigating the
needle in epidural spaces. Thereby, identifying the tissue structures may be
helpful to the physician as they can provide additional feedback in the needle
insertion process. To this end, we propose a deep neural network that
classifies the tissues from the phase and intensity data of complex OCT signals
acquired at the needle tip. We investigate the performance of the deep neural
network in a limited labelled dataset scenario and propose a novel contrastive
pretraining strategy that learns invariant representation for phase and
intensity data. We show that with 10% of the training set, our proposed
pretraining strategy helps the model achieve an F1 score of 0.84 whereas the
model achieves an F1 score of 0.60 without it. Further, we analyse the
importance of phase and intensity individually towards tissue classification.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Mixing Data Augmentation with Preserving Foreground Regions in Medical  Image Segmentation</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13490</p>
  <p><b>作者</b>：Xiaoqing Liu,  Kenji Ono,  Ryoma Bise</p>
  <p><b>备注</b>：Accepted by IEEE ISBI'23</p>
  <p><b>关键词</b>：support doctors' diagnoses, significantly support doctors', medical image segmentation, medical image, image segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of medical image segmentation using deep learning can
significantly support doctors' diagnoses. Deep learning needs large amounts of
data for training, which also requires data augmentation to extend diversity
for preventing overfitting. However, the existing methods for data augmentation
of medical image segmentation are mainly based on models which need to update
parameters and cost extra computing resources. We proposed data augmentation
methods designed to train a high accuracy deep learning network for medical
image segmentation. The proposed data augmentation approaches are called
KeepMask and KeepMix, which can create medical images by better identifying the
boundary of the organ with no more parameters. Our methods achieved better
performance and obtained more precise boundaries for medical image segmentation
on datasets. The dice coefficient of our methods achieved 94.15% (3.04% higher
than baseline) on CHAOS and 74.70% (5.25% higher than baseline) on MSD spleen
with Unet.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：OPDN: Omnidirectional Position-aware Deformable Network for  Omnidirectional Image Super-Resolution</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13471</p>
  <p><b>作者</b>：Xiaopeng Sun,  Weiqi Li,  Zhenyu Zhang,  Qiufang Ma,  Xuhan Sheng,  Ming Cheng,  Haoyu Ma,  Shijie Zhao,  Jian Zhang,  Junlin Li,  Li Zhang</p>
  <p><b>备注</b>：Accepted to CVPRW 2023</p>
  <p><b>关键词</b>：gained research attention, research attention due, interactive experience, gained research, research attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>360° omnidirectional images have gained research attention due to their
immersive and interactive experience, particularly in AR/VR applications.
However, they suffer from lower angular resolution due to being captured by
fisheye lenses with the same sensor size for capturing planar images. To solve
the above issues, we propose a two-stage framework for 360°
omnidirectional image superresolution. The first stage employs two branches:
model A, which incorporates omnidirectional position-aware deformable blocks
(OPDB) and Fourier upsampling, and model B, which adds a spatial frequency
fusion module (SFF) to model A. Model A aims to enhance the feature extraction
ability of 360° image positional information, while Model B further
focuses on the high-frequency information of 360° images. The second stage
performs same-resolution enhancement based on the structure of model A with a
pixel unshuffle operation. In addition, we collected data from YouTube to
improve the fitting ability of the transformer, and created pseudo
low-resolution images using a degradation network. Our proposed method achieves
superior performance and wins the NTIRE 2023 challenge of 360°
omnidirectional image super-resolution.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Low-field magnetic resonance image enhancement via stochastic image  quality transfer</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13385</p>
  <p><b>作者</b>：Hongxiang Lin,  Matteo Figini,  Felice D'Arco,  Godwin Ogbole,  Ryutaro Tanno,  Stefano B. Blumberg,  Lisa Ronan,  Biobele J. Brown,  David W. Carmichael,  Ikeoluwa Lagunju,  Judith Helen Cross,  Delmiro Fernandez-Reyes,  Daniel C. Alexander</p>
  <p><b>备注</b>：Accepted in Medical Image Analysis</p>
  <p><b>关键词</b>：higher income countries, magnetic resonance imaging, small child patients, middle-income countries, income countries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-field (<1T) magnetic resonance imaging (mri) scanners remain in widespread use low- and middle-income countries (lmics) are commonly used for some applications higher income e.g. small child patients with obesity, claustrophobia, implants, or tattoos. however, low-field mr images have lower resolution poorer contrast than from high field (1.5t, 3t, above). here, we present image quality transfer (iqt) to enhance structural mri by estimating a the would obtained same subject at field. our approach uses (i) stochastic simulator as forward model capture uncertainty variation of corresponding particular high-field image, (ii) an anisotropic u-net variant specifically designed iqt inverse problem. evaluate proposed algorithm both simulation using multi-contrast (t1-weighted, t2-weighted, fluid attenuated inversion recovery (flair)) clinical data lmic hospital. show efficacy improving images. demonstrate that iqt-enhanced potential enhancing visualisation anatomical structures pathological lesions relevance perspective radiologists. is proved capability boosting diagnostic value mri, especially low-resource settings.< p>
  </1T)></p></details>
</details>
<details>
  <summary>73. <b>标题：HDR or SDR? A Subjective and Objective Study of Scaled and Compressed  Videos</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13162</p>
  <p><b>作者</b>：Joshua P. Ebenezer,  Zaixi Shang,  Yixu Chen,  Yongjun Wu,  Hai Wei,  Sriram Sethuraman,  Alan C. Bovik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Standard Dynamic Range, High Dynamic Range, Dynamic Range, human perceptual quality, perceptual quality judgments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We conducted a large-scale study of human perceptual quality judgments of
High Dynamic Range (HDR) and Standard Dynamic Range (SDR) videos subjected to
scaling and compression levels and viewed on three different display devices.
HDR videos are able to present wider color gamuts, better contrasts, and
brighter whites and darker blacks than SDR videos. While conventional
expectations are that HDR quality is better than SDR quality, we have found
subject preference of HDR versus SDR depends heavily on the display device, as
well as on resolution scaling and bitrate. To study this question, we collected
more than 23,000 quality ratings from 67 volunteers who watched 356 videos on
OLED, QLED, and LCD televisions. Since it is of interest to be able to measure
the quality of videos under these scenarios, e.g. to inform decisions regarding
scaling, compression, and SDR vs HDR, we tested several well-known
full-reference and no-reference video quality models on the new database.
Towards advancing progress on this problem, we also developed a novel
no-reference model called HDRPatchMAX, that uses both classical and bit-depth
sensitive distortion statistics more accurately than existing metrics.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：HDR-ChipQA: No-Reference Quality Assessment on High Dynamic Range Videos</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13156</p>
  <p><b>作者</b>：Joshua P. Ebenezer,  Zaixi Shang,  Yongjun Wu,  Hai Wei,  Sriram Sethuraman,  Alan C. Bovik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：High Dynamic Range, High Dynamic, Dynamic Range, Standard Dynamic Range, delivers standout performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a no-reference video quality model and algorithm that delivers
standout performance for High Dynamic Range (HDR) videos, which we call
HDR-ChipQA. HDR videos represent wider ranges of luminances, details, and
colors than Standard Dynamic Range (SDR) videos. The growing adoption of HDR in
massively scaled video networks has driven the need for video quality
assessment (VQA) algorithms that better account for distortions on HDR content.
In particular, standard VQA models may fail to capture conspicuous distortions
at the extreme ends of the dynamic range, because the features that drive them
may be dominated by distortions {that pervade the mid-ranges of the signal}. We
introduce a new approach whereby a local expansive nonlinearity emphasizes
distortions occurring at the higher and lower ends of the {local} luma range,
allowing for the definition of additional quality-aware features that are
computed along a separate path. These features are not HDR-specific, and also
improve VQA on SDR video contents, albeit to a reduced degree. We show that
this preprocessing step significantly boosts the power of distortion-sensitive
natural video statistics (NVS) features when used to predict the quality of HDR
content. In similar manner, we separately compute novel wide-gamut color
features using the same nonlinear processing steps. We have found that our
model significantly outperforms SDR VQA algorithms on the only publicly
available, comprehensive HDR database, while also attaining state-of-the-art
performance on SDR content.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：MEDNC: Multi-ensemble deep neural network for COVID-19 diagnosis</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13135</p>
  <p><b>作者</b>：Lin Yang,  Shuihua Wang,  Yudong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Coronavirus disease, medical facilities, MEDNC, limited medical resources, medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Coronavirus disease 2019 (COVID-19) has spread all over the world for three
years, but medical facilities in many areas still aren't adequate. There is a
need for rapid COVID-19 diagnosis to identify high-risk patients and maximize
the use of limited medical resources. Motivated by this fact, we proposed the
deep learning framework MEDNC for automatic prediction and diagnosis of
COVID-19 using computed tomography (CT) images. Our model was trained using two
publicly available sets of COVID-19 data. And it was built with the inspiration
of transfer learning. Results indicated that the MEDNC greatly enhanced the
detection of COVID-19 infections, reaching an accuracy of 98.79% and 99.82%
respectively. We tested MEDNC on a brain tumor and a blood cell dataset to show
that our model applies to a wide range of problems. The outcomes demonstrated
that our proposed models attained an accuracy of 99.39% and 99.28%,
respectively. This COVID-19 recognition tool could help optimize healthcare
resources and reduce clinicians' workload when screening for the virus.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Evaluation of GPT-3.5 and GPT-4 for supporting real-world information  needs in healthcare delivery</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13714</p>
  <p><b>作者</b>：Debadutta Dash,  Rahul Thapa,  Juan M. Banda,  Akshay Swaminathan,  Morgan Cheatham,  Mehr Kashyap,  Nikesh Kotecha,  Jonathan H. Chen,  Saurabh Gombar,  Lance Downing,  Rachel Pedreira,  Ethan Goh,  Angel Arnaout,  Garret Kenn Morris,  Honor Magon,  Matthew P Lungren,  Eric Horvitz,  Nigam H. Shah</p>
  <p><b>备注</b>：27 pages including supplemental information</p>
  <p><b>关键词</b>：informatics consultation service, large language models, informatics consultation, current explorations, growing interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite growing interest in using large language models (LLMs) in healthcare,
current explorations do not assess the real-world utility and safety of LLMs in
clinical settings. Our objective was to determine whether two LLMs can serve
information needs submitted by physicians as questions to an informatics
consultation service in a safe and concordant manner. Sixty six questions from
an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple
prompts. 12 physicians assessed the LLM responses' possibility of patient harm
and concordance with existing reports from an informatics consultation service.
Physician assessments were summarized based on majority vote. For no questions
did a majority of physicians deem either LLM response as harmful. For GPT-3.5,
responses to 8 questions were concordant with the informatics consult report,
20 discordant, and 9 were unable to be assessed. There were 29 responses with
no majority on "Agree", "Disagree", and "Unable to assess". For GPT-4,
responses to 13 questions were concordant, 15 discordant, and 3 were unable to
be assessed. There were 35 responses with no majority. Responses from both LLMs
were largely devoid of overt harm, but less than 20% of the responses agreed
with an answer from an informatics consultation service, responses contained
hallucinated references, and physicians were divided on what constitutes harm.
These results suggest that while general purpose LLMs are able to provide safe
and credible responses, they often do not meet the specific information need of
a given question. A definitive evaluation of the usefulness of LLMs in
healthcare settings will likely require additional research on prompt
engineering, calibration, and custom-tailoring of general purpose models.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13712</p>
  <p><b>作者</b>：Jingfeng Yang,  Hongye Jin,  Ruixiang Tang,  Xiaotian Han,  Qizhang Feng,  Haoming Jiang,  Bing Yin,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, natural language, natural language processing, downstream natural language, Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：HeySQuAD: A Spoken Question Answering Dataset</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13689</p>
  <p><b>作者</b>：Yijing Wu,  SaiKrishna Rallabandi,  Ravisutha Srinivasamurthy,  Parag Pravin Dakle,  Alolika Gon,  Preethi Raghavan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including digital assistants, cases including digital, systems that serve, digital assistants, community-shared SQA dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-spoken questions are critical to evaluating the performance of spoken
question answering (SQA) systems that serve several real-world use cases
including digital assistants. We present a new large-scale community-shared SQA
dataset, HeySQuAD that consists of 76k human-spoken questions and 97k
machine-generated questions and corresponding textual answers derived from the
SQuAD QA dataset. The goal of HeySQuAD is to measure the ability of machines to
understand noisy spoken questions and answer the questions accurately. To this
end, we run extensive benchmarks on the human-spoken and machine-generated
questions to quantify the differences in noise from both sources and its
subsequent impact on the model and answering accuracy. Importantly, for the
task of SQA, where we want to answer human-spoken questions, we observe that
training using the transcribed human-spoken and original SQuAD questions leads
to significant improvements (12.51%) over training using only the original
SQuAD textual questions.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Using Implicit Feedback to Improve Question Generation</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13664</p>
  <p><b>作者</b>：Hugo Rodrigues,  Eric Nyberg,  Luisa Coheur</p>
  <p><b>备注</b>：27 pages, 8 figures</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Question Generation, automatically generating questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question Generation (QG) is a task of Natural Language Processing (NLP) that
aims at automatically generating questions from text. Many applications can
benefit from automatically generated questions, but often it is necessary to
curate those questions, either by selecting or editing them. This task is
informative on its own, but it is typically done post-generation, and, thus,
the effort is wasted. In addition, most existing systems cannot incorporate
this feedback back into them easily. In this work, we present a system, GEN,
that learns from such (implicit) feedback. Following a pattern-based approach,
it takes as input a small set of sentence/question pairs and creates patterns
which are then applied to new unseen sentences. Each generated question, after
being corrected by the user, is used as a new seed in the next iteration, so
more patterns are created each time. We also take advantage of the corrections
made by the user to score the patterns and therefore rank the generated
questions. Results show that GEN is able to improve by learning from both
levels of implicit feedback when compared to the version with no learning,
considering the top 5, 10, and 20 questions. Improvements go up from 10%,
depending on the metric and strategy used.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Symmetric Dual Encoding Dense Retrieval Framework for  Knowledge-Intensive Visual Question Answering</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13649</p>
  <p><b>作者</b>：Alireza Salemi,  Juan Altmayer Pizzorno,  Hamed Zamani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge-Intensive Visual Question, Knowledge-Intensive Visual, Visual Question Answering, Visual Question, OK-VQA and FVQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a
question about an image whose answer does not lie in the image. This paper
presents a new pipeline for KI-VQA tasks, consisting of a retriever and a
reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval
framework in which documents and queries are encoded into a shared embedding
space using uni-modal (textual) and multi-modal encoders. We introduce an
iterative knowledge distillation approach that bridges the gap between the
representation spaces in these two encoders. Extensive evaluation on two
well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR
outperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA,
respectively. Utilizing the passages retrieved by DEDR, we further introduce
MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating
a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and
each retrieved passage separately and uses all passages jointly in its decoder.
Compared to competitive baselines in the literature, this approach leads to
5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA
and FVQA, respectively.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource  TweetData for Sentiment Analysis</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13634</p>
  <p><b>作者</b>：Saheed Abdullahi Salahudeen,  Falalu Ibrahim Lawan,  Ahmad Mustapha Wali,  Amina Abubakar Imam,  Aliyu Rabiu Shuaibu,  Aliyu Yusuf,  Nur Bala Rabiu,  Musa Bello,  Shamsuddeen Umaru Adamu,  Saminu Mohammad Aliyu,  Murja Sani Gadanya,  Sanah Abdullahi Muaz,  Mahmoud Said Ahmad,  Abdulkadir Abdullahi,  Abdulmalik Yusuf Jamoh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sentiment classification, subtask, shared task, sentiment, languages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the findings of SemEval-2023 Task 12, a shared task on sentiment
analysis for low-resource African languages using Twitter dataset. The task
featured three subtasks; subtask A is monolingual sentiment classification with
12 tracks which are all monolingual languages, subtask B is multilingual
sentiment classification using the tracks in subtask A and subtask C is a
zero-shot sentiment classification. We present the results and findings of
subtask A, subtask B and subtask C. We also release the code on github. Our
goal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,
AfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),
Multilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African
languages. The datasets for these subtasks consists of a gold standard
multi-class labeled Twitter datasets from these languages. Our results
demonstrate that Afro-xlmr-large model performed better compared to the other
models in most of the languages datasets. Similarly, Nigerian languages: Hausa,
Igbo, and Yoruba achieved better performance compared to other languages and
this can be attributed to the higher volume of data present in the languages.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization  of Long and Short Summaries</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13620</p>
  <p><b>作者</b>：Raian Rahman,  Rizvi Hasan,  Abdullah Al Farhad,  Md Tahmid Rahman Laskar,  Md. Hamjajul Ashmafee,  Abu Raihan Mostofa Kamal</p>
  <p><b>备注</b>：Accepted as a long paper at the Canadian AI 2023</p>
  <p><b>关键词</b>：visually impaired people, providing precise insights, text summarization, visually impaired, impaired people</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic chart to text summarization is an effective tool for the visually
impaired people along with providing precise insights of tabular data in
natural language to the user. A large and well-structured dataset is always a
key part for data driven models. In this paper, we propose ChartSumm: a
large-scale benchmark dataset consisting of a total of 84,363 charts along with
their metadata and descriptions covering a wide range of topics and chart types
to generate short and long summaries. Extensive experiments with strong
baseline models show that even though these models generate fluent and
informative summaries by achieving decent scores in various automatic
evaluation metrics, they often face issues like suffering from hallucination,
missing out important data points, in addition to incorrect explanation of
complex trends in the charts. We also investigated the potential of expanding
ChartSumm to other languages using automated translation tools. These make our
dataset a challenging benchmark for future research.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Shades of meaning: Uncovering the geometry of ambiguous word  representations through contextualised language models</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13597</p>
  <p><b>作者</b>：Benedetta Cevoli,  Chris Watkins,  Yang Gao,  Kathleen Rastle</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Lexical ambiguity presents, presents a profound, profound and enduring, Lexical ambiguity, language sciences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lexical ambiguity presents a profound and enduring challenge to the language
sciences. Researchers for decades have grappled with the problem of how
language users learn, represent and process words with more than one meaning.
Our work offers new insight into psychological understanding of lexical
ambiguity through a series of simulations that capitalise on recent advances in
contextual language models. These models have no grounded understanding of the
meanings of words at all; they simply learn to predict words based on the
surrounding context provided by other words. Yet, our analyses show that their
representations capture fine-grained meaningful distinctions between
unambiguous, homonymous, and polysemous words that align with lexicographic
classifications and psychological theorising. These findings provide
quantitative support for modern psychological conceptualisations of lexical
ambiguity and raise new challenges for understanding of the way that contextual
information shapes the meanings of words across different timescales.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Toxic comments reduce the activity of volunteer editors on Wikipedia</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13568</p>
  <p><b>作者</b>：Ivan Smirnov,  Camelia Oprea,  Markus Strohmaier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Wikipedia, successful collaborative projects, Wikipedia relies solely, toxic comments, successful collaborative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Wikipedia is one of the most successful collaborative projects in history. It
is the largest encyclopedia ever created, with millions of users worldwide
relying on it as the first source of information as well as for fact-checking
and in-depth research. As Wikipedia relies solely on the efforts of its
volunteer-editors, its success might be particularly affected by toxic speech.
In this paper, we analyze all 57 million comments made on user talk pages of
8.5 million editors across the six most active language editions of Wikipedia
to study the potential impact of toxicity on editors' behaviour. We find that
toxic comments consistently reduce the activity of editors, leading to an
estimated loss of 0.5-2 active days per user in the short term. This amounts to
multiple human-years of lost productivity when considering the number of active
contributors to Wikipedia. The effects of toxic comments are even greater in
the long term, as they significantly increase the risk of editors leaving the
project altogether. Using an agent-based model, we demonstrate that toxicity
attacks on Wikipedia have the potential to impede the progress of the entire
project. Our results underscore the importance of mitigating toxic speech on
collaborative platforms such as Wikipedia to ensure their continued success.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Impact of Position Bias on Language Models in Token Classification</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13567</p>
  <p><b>作者</b>：Mehdi Ben Amor,  Michael Granitzer,  Jelena Mitrović</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural, Language Processing, Named Entity, Language Models, performance in Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) have shown state-of-the-art performance in Natural
Language Processing (NLP) tasks. Downstream tasks such as Named Entity
Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data
imbalance issues, specifically in terms of the ratio of positive to negative
examples, and class imbalance. In this paper, we investigate an additional
specific issue for language models, namely the position bias of positive
examples in token classification tasks. Therefore, we conduct an in-depth
evaluation of the impact of position bias on the performance of LMs when
fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and
OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We
propose an evaluation approach to investigate position bias in Transformer
models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as
GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in
their performance. To mitigate this effect, we propose two methods: Random
Position Shifting and Context Perturbation, that we apply on batches during the
training process. The results show an improvement of $\approx$ 2\% in the
performance of the model on CoNLL03, UD_en, and TweeBank.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13559</p>
  <p><b>作者</b>：Matthias Urban,  Carsten Binnig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：seamlessly query text, propose Multi-Modal Databases, seamlessly query, database systems, SQL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose Multi-Modal Databases (MMDBs), which is a new class
of database systems that can seamlessly query text and tables using SQL. To
enable seamless querying of textual data using SQL in an MMDB, we propose to
extend relational databases with so-called multi-modal operators (MMOps) which
are based on the advances of recent large language models such as GPT-3. The
main idea of MMOps is that they allow text collections to be treated as tables
without the need to manually transform the data. As we show in our evaluation,
our MMDB prototype can not only outperform state-of-the-art approaches such as
text-to-table in terms of accuracy and performance but it also requires
significantly less training data to fine-tune the model for an unseen text
collection.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题："I'm" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13557</p>
  <p><b>作者</b>：Katie Seaborn,  Yeongdae Kim</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：virtual assistants continue, virtual assistants, assistants continue, speech-based systems, systems to communicate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As virtual assistants continue to be taken up globally, there is an
ever-greater need for these speech-based systems to communicate naturally in a
variety of languages. Crowdsourcing initiatives have focused on multilingual
translation of big, open data sets for use in natural language processing
(NLP). Yet, language translation is often not one-to-one, and biases can
trickle in. In this late-breaking work, we focus on the case of pronouns
translated between English and Japanese in the crowdsourced Tatoeba database.
We found that masculine pronoun biases were present overall, even though
plurality in language was accounted for in other ways. Importantly, we detected
biases in the translation process that reflect nuanced reactions to the
presence of feminine, neutral, and/or non-binary pronouns. We raise the issue
of translation bias for pronouns and offer a practical solution to embed
plurality in NLP data sets.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Multidimensional Evaluation for Text Style Transfer Using ChatGPT</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13462</p>
  <p><b>作者</b>：Huiyuan Lai,  Antonio Toral,  Malvina Nissim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Text Style Transfer, Text Style, Style Transfer, style transfer evaluation, investigate the potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the potential of ChatGPT as a multidimensional evaluator for
the task of \emph{Text Style Transfer}, alongside, and in comparison to,
existing automatic metrics as well as human judgements. We focus on a zero-shot
setting, i.e. prompting ChatGPT with specific task instructions, and test its
performance on three commonly-used dimensions of text style transfer
evaluation: style strength, content preservation, and fluency. We perform a
comprehensive correlation analysis for two transfer directions (and overall) at
different levels. Compared to existing automatic metrics, ChatGPT achieves
competitive correlations with human judgments. These preliminary results are
expected to provide a first glimpse into the role of large language models in
the multidimensional evaluation of stylized text generation.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Unleashing Infinite-Length Input Capacity for Large-scale Language  Models with Self-Controlled Memory System</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13343</p>
  <p><b>作者</b>：Xinnian Liang,  Bing Wang,  Hui Huang,  Shuangzhi Wu,  Peihao Wu,  Lu Lu,  Zejun Ma,  Zhoujun Li</p>
  <p><b>备注</b>：Working in progress</p>
  <p><b>关键词</b>：Large-scale Language Models, language model agent, Memory, SCM system, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale Language Models (LLMs) are constrained by their inability to
process lengthy inputs. To address this limitation, we propose the
Self-Controlled Memory (SCM) system to unleash infinite-length input capacity
for large-scale language models. Our SCM system is composed of three key
modules: the language model agent, the memory stream, and the memory
controller. The language model agent iteratively processes ultra-long inputs
and stores all historical information in the memory stream. The memory
controller provides the agent with both long-term memory (archived memory) and
short-term memory (flash memory) to generate precise and coherent responses.
The controller determines which memories from archived memory should be
activated and how to incorporate them into the model input. Our SCM system can
be integrated with any LLMs to enable them to process ultra-long texts without
any modification or fine-tuning. Experimental results show that our SCM system
enables LLMs, which are not optimized for multi-turn dialogue, to achieve
multi-turn dialogue capabilities that are comparable to ChatGPT, and to
outperform ChatGPT in scenarios involving ultra-long document summarization or
long-term conversations. Additionally, we will supply a test set, which covers
common long-text input scenarios, for evaluating the abilities of LLMs in
processing long documents.~\footnote{Working in
progress.}\footnote{\url{this https URL}}</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Nominal Topology for Data Languages</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13337</p>
  <p><b>作者</b>：Henning Urbat,  Stefan Milius,  Fabian Birkmann</p>
  <p><b>备注</b>：Extended version of the corresponding paper accepted for ICALP 2023</p>
  <p><b>关键词</b>：orbit-finite nominal monoids, topological perspective, nominal monoids, nominal, data languages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel topological perspective on data languages recognizable by
orbit-finite nominal monoids. For this purpose, we introduce pro-orbit-finite
nominal topological spaces. Assuming globally bounded support sizes, they
coincide with nominal Stone spaces and are shown to be dually equivalent to a
subcategory of nominal boolean algebras. Recognizable data languages are
characterized as topologically clopen sets of pro-orbit-finite words. In
addition, we explore the expressive power of pro-orbit-finite equations by
establishing a nominal version of Reiterman's pseudovariety theorem.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain  Text-to-SQL</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13301</p>
  <p><b>作者</b>：Chunxi Guo,  Zhiliang Tian,  Jintao Tang,  Pancheng Wang,  Zhihua Wen,  Kang Yang,  Ting Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, advancements in Large, Recent advancements, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Large Language Models (LLMs), such as Codex, ChatGPT
and GPT-4 have significantly impacted the AI community, including Text-to-SQL
tasks. Some evaluations and analyses on LLMs show their potential to generate
SQL queries but they point out poorly designed prompts (e.g. simplistic
construction or random sampling) limit LLMs' performance and may cause
unnecessary or irrelevant outputs. To address these issues, we propose
CBR-ApSQL, a Case-Based Reasoning (CBR)-based framework combined with GPT-3.5
for precise control over case-relevant and case-irrelevant knowledge in
Text-to-SQL tasks. We design adaptive prompts for flexibly adjusting inputs for
GPT-3.5, which involves (1) adaptively retrieving cases according to the
question intention by de-semantizing the input question, and (2) an adaptive
fallback mechanism to ensure the informativeness of the prompt, as well as the
relevance between cases and the prompt. In the de-semanticization phase, we
designed Semantic Domain Relevance Evaluator(SDRE), combined with Poincaré
detector(mining implicit semantics in hyperbolic space), TextAlign(discovering
explicit matches), and Positector (part-of-speech detector). SDRE semantically
and syntactically generates in-context exemplar annotations for the new case.
On the three cross-domain datasets, our framework outperforms the
state-of-the-art(SOTA) model in execution accuracy by 3.7\%, 2.5\%, and 8.2\%,
respectively.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Zero-Shot Slot and Intent Detection in Low-Resource Languages</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13292</p>
  <p><b>作者</b>：Sang Yun Kwon,  Gagan Bhatia,  El Moatez Billah Nagoudi,  Alcides Alcoba Inciarte,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：VarDial @ EACL</p>
  <p><b>关键词</b>：task-oriented dialog systems, natural language understanding, Intent detection, dialog systems, filling are critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intent detection and slot filling are critical tasks in spoken and natural
language understanding for task-oriented dialog systems. In this work we
describe our participation in the slot and intent detection for low-resource
language varieties (SID4LR; Aepli et al. (2023)). We investigate the slot and
intent detection (SID) tasks using a wide range of models and settings. Given
the recent success of multitask-prompted finetuning of large language models,
we also test the generalization capability of the recent encoder-decoder model
mT0 (Muennighoff et al., 2022) on new tasks (i.e., SID) in languages they have
never intentionally seen. We show that our best model outperforms the baseline
by a large margin (up to +30 F1 points) in both SID tasks</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：The Closeness of In-Context Learning and Weight Shifting for Softmax  Regression</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13276</p>
  <p><b>作者</b>：Shuai Li,  Zhao Song,  Yu Xia,  Tong Yu,  Tianyi Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Large language models, Large language, language processing, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) are known for their exceptional performance in
natural language processing, making them highly effective in many human
life-related or even job-related tasks. The attention mechanism in the
Transformer architecture is a critical component of LLMs, as it allows the
model to selectively focus on specific input parts. The softmax unit, which is
a key part of the attention mechanism, normalizes the attention scores. Hence,
the performance of LLMs in various NLP tasks depends significantly on the
crucial role played by the attention mechanism with the softmax unit.
In-context learning, as one of the celebrated abilities of recent LLMs, is an
important concept in querying LLMs such as ChatGPT. Without further parameter
updates, Transformers can learn to predict based on few in-context examples.
However, the reason why Transformers becomes in-context learners is not well
understood. Recently, several works [ASA+22,GTLV22,ONR+22] have studied the
in-context learning from a mathematical perspective based on a linear
regression formulation $\min_x\| Ax - b \|_2$, which show Transformers'
capability of learning linear functions in context.
In this work, we study the in-context learning based on a softmax regression
formulation $\min_{x} \| \langle \exp(Ax), {\bf 1}_n \rangle^{-1} \exp(Ax) - b
\|_2$ of Transformer's attention mechanism. We show the upper bounds of the
data transformations induced by a single self-attention layer and by
gradient-descent on a $\ell_2$ regression loss for softmax prediction function,
which imply that when training self-attention-only Transformers for fundamental
regression tasks, the models learned by gradient-descent and Transformers show
great similarity.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：From Association to Generation: Text-only Captioning by Unsupervised  Cross-modal Mapping</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13273</p>
  <p><b>作者</b>：Junyang Wang,  Ming Yan,  Yi Zhang,  Ming Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：association-based visual tasks, Vision-Language Pre-training Models, significant breakthroughs, CLIP, development of Vision-Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of Vision-Language Pre-training Models (VLPMs)
represented by CLIP and ALIGN, significant breakthroughs have been achieved for
association-based visual tasks such as image classification and image-text
retrieval by the zero-shot capability of CLIP without fine-tuning. However,
CLIP is hard to apply to generation-based tasks. This is due to the lack of
decoder architecture and pre-training tasks for generation. Although previous
works have created generation capacity for CLIP through additional language
models, a modality gap between the CLIP representations of different modalities
and the inability of CLIP to model the offset of this gap, which fails the
concept to transfer across modalities. To solve the problem, we try to map
images/videos to the language modality and generate captions from the language
modality. In this paper, we propose the K-nearest-neighbor Cross-modality
Mapping (Knight), a zero-shot method from association to generation. With
text-only unsupervised training, Knight achieves state-of-the-art performance
in zero-shot methods for image captioning and video captioning. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Exploring the Curious Case of Code Prompts</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13250</p>
  <p><b>作者</b>：Li Zhang,  Liam Dugan,  Hainiu Xu,  Chris Callison-Burch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：structured reasoning tasks, shown that prompting, code-like representations, improvements on structured, structured reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work has shown that prompting language models with code-like
representations of natural language leads to performance improvements on
structured reasoning tasks. However, such tasks comprise only a small subset of
all natural language tasks. In our work, we seek to answer whether or not
code-prompting is the preferred way of interacting with language models in
general. We compare code and text prompts across three popular GPT models
(davinci, code-davinci-002, and text-davinci-002) on a broader selection of
tasks (e.g., QA, sentiment, summarization) and find that with few exceptions,
code prompts do not consistently outperform text prompts. Furthermore, we show
that the style of code prompt has a large effect on performance for some but
not all tasks and that fine-tuning on text instructions leads to better
relative performance of code prompts.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Towards Explainable and Safe Conversational Agents for Mental Health: A  Survey</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13191</p>
  <p><b>作者</b>：Surjodeep Sarkar,  Manas Gaur,  L. Chen,  Muskan Garg,  Biplav Srivastava,  Bhaktee Dongaonkar</p>
  <p><b>备注</b>：10 pages, 3 figures, 2 tables</p>
  <p><b>关键词</b>：million Emergency Room, Emergency Room, million primary care, primary care visits, Mental Health Assistants</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：TABLET: Learning From Instructions For Tabular Data</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13188</p>
  <p><b>作者</b>：Dylan Slack,  Sameer Singh</p>
  <p><b>备注</b>：Please find the TABLET demo and code at this https URL</p>
  <p><b>关键词</b>：Acquiring high-quality data, training machine learning, Acquiring high-quality, medicine and finance, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Acquiring high-quality data is often a significant challenge in training
machine learning (ML) models for tabular prediction, particularly in
privacy-sensitive and costly domains like medicine and finance. Providing
natural language instructions to large language models (LLMs) offers an
alternative solution. However, it is unclear how effectively instructions
leverage the knowledge in LLMs for solving tabular prediction problems. To
address this gap, we introduce TABLET, a benchmark of 20 diverse tabular
datasets annotated with instructions that vary in their phrasing, granularity,
and technicality. Additionally, TABLET includes the instructions' logic and
structured modifications to the instructions. We find in-context instructions
increase zero-shot F1 performance for Flan-T5 11b by 44% on average and 13% for
ChatGPT on TABLET. Also, we explore the limitations of using LLMs for tabular
prediction in our benchmark by evaluating instruction faithfulness. We find
LLMs often ignore instructions and fail to predict specific instances
correctly, even with examples. Our analysis on TABLET shows that, while
instructions help LLM performance, learning from instructions for tabular data
requires new capabilities.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Sebis at SemEval-2023 Task 7: A Joint System for Natural Language  Inference and Evidence Retrieval from Clinical Trial Reports</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13180</p>
  <p><b>作者</b>：Juraj Vladika,  Florian Matthes</p>
  <p><b>备注</b>：6 pages, SemEval 2023</p>
  <p><b>关键词</b>：evidence-based healthcare recommendations, inform evidence-based healthcare, trial reports generated, generated every day, healthcare recommendations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing number of clinical trial reports generated every day, it
is becoming hard to keep up with novel discoveries that inform evidence-based
healthcare recommendations. To help automate this process and assist medical
experts, NLP solutions are being developed. This motivated the SemEval-2023
Task 7, where the goal was to develop an NLP system for two tasks: evidence
retrieval and natural language inference from clinical trial data. In this
paper, we describe our two developed systems. The first one is a pipeline
system that models the two tasks separately, while the second one is a joint
system that learns the two tasks simultaneously with a shared representation
and a multi-task learning approach. The final system combines their outputs in
an ensemble system. We formalize the models, present their characteristics and
challenges, and provide an analysis of achieved results.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Modeling Spoken Information Queries for Virtual Assistants: Open  Problems, Challenges and Opportunities</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13149</p>
  <p><b>作者</b>：Christophe Van Gysel</p>
  <p><b>备注</b>：SIGIR '23. The 46th International ACM SIGIR Conference on Research & Development in Information Retrieval</p>
  <p><b>关键词</b>：increasingly important speech-driven, important speech-driven, increasingly important, Information Retrieval, Information Retrieval platforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Virtual assistants are becoming increasingly important speech-driven
Information Retrieval platforms that assist users with various tasks.
We discuss open problems and challenges with respect to modeling spoken
information queries for virtual assistants, and list opportunities where
Information Retrieval methods and research can be applied to improve the
quality of virtual assistant speech recognition.
We discuss how query domain classification, knowledge graphs and user
interaction data, and query personalization can be helpful to improve the
accurate recognition of spoken information domain queries. Finally, we also
provide a brief overview of current problems and challenges in speech
recognition.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：ESimCSE Unsupervised Contrastive Learning Jointly with UDA  Semi-Supervised Learning for Large Label System Text Classification Mode</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13140</p>
  <p><b>作者</b>：Ruan Lu,  Zhou HangCheng,  Ran Meng,  Zhao Jin,  Qin JiaoYu,  Wei Feng,  Wang ChenZi</p>
  <p><b>备注</b>：This paper contains 14 pages,4 figures,4 tables</p>
  <p><b>关键词</b>：large tag systems, multiple tag systems, include multiple tag, uneven data distribution, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenges faced by text classification with large tag systems in natural
language processing tasks include multiple tag systems, uneven data
distribution, and high noise. To address these problems, the ESimCSE
unsupervised comparative learning and UDA semi-supervised comparative learning
models are combined through the use of joint training techniques in the
models.The ESimCSE model efficiently learns text vector representations using
unlabeled data to achieve better classification results, while UDA is trained
using unlabeled data through semi-supervised learning methods to improve the
prediction performance of the models and stability, and further improve the
generalization ability of the model. In addition, adversarial training
techniques FGM and PGD are used in the model training process to improve the
robustness and reliability of the model. The experimental results show that
there is an 8% and 10% accuracy improvement relative to Baseline on the public
dataset Ruesters as well as on the operational dataset, respectively, and a 15%
improvement in manual validation accuracy can be achieved on the operational
dataset, indicating that the method is effective.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：LAST: Scalable Lattice-Based Speech Modelling in JAX</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13134</p>
  <p><b>作者</b>：Ke Wu,  Ehsan Variani,  Tom Bagby,  Michael Riley</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Speech Transducer library, LAttice-based Speech Transducer, Speech Transducer, library in JAX, LAttice-based Speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce LAST, a LAttice-based Speech Transducer library in JAX. With an
emphasis on flexibility, ease-of-use, and scalability, LAST implements
differentiable weighted finite state automaton (WFSA) algorithms needed for
training \& inference that scale to a large WFSA such as a recognition lattice
over the entire utterance. Despite these WFSA algorithms being well-known in
the literature, new challenges arise from performance characteristics of modern
architectures, and from nuances in automatic differentiation. We describe a
suite of generally applicable techniques employed in LAST to address these
challenges, and demonstrate their effectiveness with benchmarks on TPUv3 and
V100 GPU.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Pretrain on just structure: Understanding linguistic inductive biases  using transfer learning</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13060</p>
  <p><b>作者</b>：Isabel Papadimitriou,  Dan Jurafsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explicit structural supervision, inductive bias, inductive, bias, inductive learning biases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Both humans and transformer language models are able to learn language
without explicit structural supervision. What inductive learning biases make
this learning possible? In this study, we examine the effect of different
inductive learning biases by predisposing language models with structural
biases through pretraining on artificial structured data, and then evaluating
by fine-tuning on English. Our experimental setup gives us the ability to
actively control the inductive bias of language models. With our experiments,
we investigate the comparative success of three types of inductive bias: 1) an
inductive bias for recursive, hierarchical processing 2) an inductive bias for
unrestricted token-token dependencies that can't be modeled by context-free
grammars, and 3) an inductive bias for a Zipfian power-law vocabulary
distribution. We show that complex token-token interactions form the best
inductive biases, and that this is strongest in the non-context-free case. We
also show that a Zipfian vocabulary distribution forms a good inductive bias
independently from grammatical structure. Our study leverages the capabilities
of transformer models to run controlled language learning experiments that are
not possible to run in humans, and surfaces hypotheses about the structures
that facilitate language learning in both humans and machines.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：A Control-Centric Benchmark for Video Prediction</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13723</p>
  <p><b>作者</b>：Stephen Tian,  Chelsea Finn,  Jiajun Wu</p>
  <p><b>备注</b>：ICLR 2023</p>
  <p><b>关键词</b>：world dynamics, promising source, source of knowledge, knowledge for embodied, embodied agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video is a promising source of knowledge for embodied agents to learn models
of the world's dynamics. Large deep networks have become increasingly effective
at modeling complex video data in a self-supervised manner, as evaluated by
metrics based on human perceptual similarity or pixel-wise comparison. However,
it remains unclear whether current metrics are accurate indicators of
performance on downstream tasks. We find empirically that for planning robotic
manipulation, existing metrics can be unreliable at predicting execution
success. To address this, we propose a benchmark for action-conditioned video
prediction in the form of a control benchmark that evaluates a given model for
simulated robotic manipulation through sampling-based planning. Our benchmark,
Video Prediction for Visual Planning ($VP^2$), includes simulated environments
with 11 task categories and 310 task instance definitions, a full planning
implementation, and training datasets containing scripted interaction
trajectories for each task category. A central design goal of our benchmark is
to expose a simple interface -- a single forward prediction call -- so it is
straightforward to evaluate almost any action-conditioned video prediction
model. We then leverage our benchmark to study the effects of scaling model
size, quantity of training data, and model ensembling by analyzing five
highly-performant video prediction models, finding that while scale can improve
perceptual quality when modeling visually diverse settings, other attributes
such as uncertainty awareness can also aid planning performance.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Sparsified Model Zoo Twins: Investigating Populations of Sparsified  Neural Network Models</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13718</p>
  <p><b>作者</b>：Dominik Honegger,  Konstantin Schürholt,  Damian Borth</p>
  <p><b>备注</b>：Accepted at ICLR 2023 Workshop on Sparsity in Neural Networks</p>
  <p><b>关键词</b>：Neural Networks, size of Neural, research and production, growing size, reduce the computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With growing size of Neural Networks (NNs), model sparsification to reduce
the computational cost and memory demand for model inference has become of
vital interest for both research and production. While many sparsification
methods have been proposed and successfully applied on individual models, to
the best of our knowledge their behavior and robustness has not yet been
studied on large populations of models. With this paper, we address that gap by
applying two popular sparsification methods on populations of models (so called
model zoos) to create sparsified versions of the original zoos. We investigate
the performance of these two methods for each zoo, compare sparsification
layer-wise, and analyse agreement between original and sparsified populations.
We find both methods to be very robust with magnitude pruning able outperform
variational dropout with the exception of high sparsification ratios above 80%.
Further, we find sparsified models agree to a high degree with their original
non-sparsified counterpart, and that the performance of original and sparsified
model is highly correlated. Finally, all models of the model zoos and their
sparsified model twins are publicly available: this http URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Association Rules Mining with Auto-Encoders</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13717</p>
  <p><b>作者</b>：Théophile Berteloot,  Richard Khoury,  Audrey Durand</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：studied research fields, explainable classification systems, grocery basket problems, Association rule mining, studied research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Association rule mining is one of the most studied research fields of data
mining, with applications ranging from grocery basket problems to explainable
classification systems. Classical association rule mining algorithms have
several limitations, especially with regards to their high execution times and
number of rules produced. Over the past decade, neural network solutions have
been used to solve various optimization problems, such as classification,
regression or clustering. However there are still no efficient way association
rules using neural networks. In this paper, we present an auto-encoder solution
to mine association rule called ARM-AE. We compare our algorithm to FP-Growth
and NSGAII on three categorical datasets, and show that our algorithm discovers
high support and confidence rule set and has a better execution time than
classical methods while preserving the quality of the rule set produced.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13712</p>
  <p><b>作者</b>：Jingfeng Yang,  Hongye Jin,  Ruixiang Tang,  Xiaotian Han,  Qizhang Feng,  Haoming Jiang,  Bing Yin,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, natural language, natural language processing, downstream natural language, Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13705</p>
  <p><b>作者</b>：Tony Z. Zhao,  Vikash Kumar,  Sergey Levine,  Chelsea Finn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：closed-loop visual feedback, threading cable ties, Fine manipulation tasks, contact forces, visual feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine manipulation tasks, such as threading cable ties or slotting a battery,
are notoriously difficult for robots because they require precision, careful
coordination of contact forces, and closed-loop visual feedback. Performing
these tasks typically requires high-end robots, accurate sensors, or careful
calibration, which can be expensive and difficult to set up. Can learning
enable low-cost and imprecise hardware to perform these fine manipulation
tasks? We present a low-cost system that performs end-to-end imitation learning
directly from real demonstrations, collected with a custom teleoperation
interface. Imitation learning, however, presents its own challenges,
particularly in high-precision domains: errors in the policy can compound over
time, and human demonstrations can be non-stationary. To address these
challenges, we develop a simple yet novel algorithm, Action Chunking with
Transformers (ACT), which learns a generative model over action sequences. ACT
allows the robot to learn 6 difficult tasks in the real world, such as opening
a translucent condiment cup and slotting a battery with 80-90% success, with
only 10 minutes worth of demonstrations. Project website:
this https URL</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Measuring Bias in AI Models with Application to Face Biometrics: An  Statistical Approach</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13680</p>
  <p><b>作者</b>：Daniel DeAlcala,  Ignacio Serna,  Aythami Morales,  Julian Fierrez,  Javier Ortega-Garcia</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：European Commission establishes, Artificial Intelligence, European Commission, Commission establishes, risk-based legal approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The new regulatory framework proposal on Artificial Intelligence (AI)
published by the European Commission establishes a new risk-based legal
approach. The proposal highlights the need to develop adequate risk assessments
for the different uses of AI. This risk assessment should address, among
others, the detection and mitigation of bias in AI. In this work we analyze
statistical approaches to measure biases in automatic decision-making systems.
We focus our experiments in face recognition technologies. We propose a novel
way to measure the biases in machine learning models using a statistical
approach based on the N-Sigma method. N-Sigma is a popular statistical approach
used to validate hypotheses in general science such as physics and social areas
and its application to machine learning is yet unexplored. In this work we
study how to apply this methodology to develop new risk assessment frameworks
based on bias analysis and we discuss the main advantages and drawbacks with
respect to other popular statistical tests.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Learning battery model parameter dynamics from data with recursive  Gaussian process regression</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13666</p>
  <p><b>作者</b>：Antti Aitio,  Dominik Jöst,  Dirk Uwe Sauer,  David A. Howey</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remains challenging due, battery management system, management system, system but remains, remains challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating state of health is a critical function of a battery management
system but remains challenging due to the variability of operating conditions
and usage requirements of real applications. As a result, techniques based on
fitting equivalent circuit models may exhibit inaccuracy at extremes of
performance and over long-term ageing, or instability of parameter estimates.
Pure data-driven techniques, on the other hand, suffer from lack of generality
beyond their training dataset. In this paper, we propose a hybrid approach
combining data- and model-driven techniques for battery health estimation.
Specifically, we demonstrate a Bayesian data-driven method, Gaussian process
regression, to estimate model parameters as functions of states, operating
conditions, and lifetime. Computational efficiency is ensured through a
recursive approach yielding a unified joint state-parameter estimator that
learns parameter dynamics from data and is robust to gaps and varying operating
conditions. Results show the efficacy of the method, on both simulated and
measured data, including accurate estimates and forecasts of battery capacity
and internal resistance. This opens up new opportunities to understand battery
ageing in real applications.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13653</p>
  <p><b>作者</b>：Tuomas Haarnoja,  Ben Moran,  Guy Lever,  Sandy H. Huang,  Dhruva Tirumala,  Markus Wulfmeier,  Jan Humplik,  Saran Tunyasuvunakool,  Noah Y. Siegel,  Roland Hafner,  Michael Bloesch,  Kristian Hartikainen,  Arunkumar Byravan,  Leonard Hasenclever,  Yuval Tassa,  Fereshteh Sadeghi,  Nathan Batchelor,  Federico Casarini,  Stefano Saliceti,  Charles Game,  Neil Sreendra,  Kushal Patel,  Marlon Gwira,  Andrea Huber,  Nicole Hurley,  Francesco Nori,  Raia Hadsell,  Nicolas Heess</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, complex behavioral strategies, Deep Reinforcement, miniature humanoid robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate whether Deep Reinforcement Learning (Deep RL) is able to
synthesize sophisticated and safe movement skills for a low-cost, miniature
humanoid robot that can be composed into complex behavioral strategies in
dynamic environments. We used Deep RL to train a humanoid robot with 20
actuated joints to play a simplified one-versus-one (1v1) soccer game. We first
trained individual skills in isolation and then composed those skills
end-to-end in a self-play setting. The resulting policy exhibits robust and
dynamic movement skills such as rapid fall recovery, walking, turning, kicking
and more; and transitions between them in a smooth, stable, and efficient
manner - well beyond what is intuitively expected from the robot. The agents
also developed a basic strategic understanding of the game, and learned, for
instance, to anticipate ball movements and to block opponent shots. The full
range of behaviors emerged from a small set of simple rewards. Our agents were
trained in simulation and transferred to real robots zero-shot. We found that a
combination of sufficiently high-frequency control, targeted dynamics
randomization, and perturbations during training in simulation enabled
good-quality transfer, despite significant unmodeled effects and variations
across robot instances. Although the robots are inherently fragile, minor
hardware modifications together with basic regularization of the behavior
during training led the robots to learn safe and effective movements while
still performing in a dynamic and agile way. Indeed, even though the agents
were optimized for scoring, in experiments they walked 156% faster, took 63%
less time to get up, and kicked 24% faster than a scripted baseline, while
efficiently combining the skills to achieve the longer term objectives.
Examples of the emergent behaviors and full 1v1 matches are available on the
supplementary website.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：PVP: Pre-trained Visual Parameter-Efficient Tuning</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13639</p>
  <p><b>作者</b>：Zhao Song,  Ke Yang,  Naiyang Guan,  Junjie Zhu,  Peng Qiao,  Qingyong Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated remarkable success, computer vision tasks, Large-scale pre-trained transformers, demonstrated remarkable, remarkable success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale pre-trained transformers have demonstrated remarkable success in
various computer vision tasks. However, it is still highly challenging to fully
fine-tune these models for downstream tasks due to their high computational and
storage costs. Recently, Parameter-Efficient Tuning (PETuning) techniques,
e.g., Visual Prompt Tuning (VPT) and Low-Rank Adaptation (LoRA), have
significantly reduced the computation and storage cost by inserting lightweight
prompt modules into the pre-trained models and tuning these prompt modules with
a small number of trainable parameters, while keeping the transformer backbone
frozen. Although only a few parameters need to be adjusted, most PETuning
methods still require a significant amount of downstream task training data to
achieve good results. The performance is inadequate on low-data regimes,
especially when there are only one or two examples per class. To this end, we
first empirically identify the poor performance is mainly due to the
inappropriate way of initializing prompt modules, which has also been verified
in the pre-trained language models. Next, we propose a Pre-trained Visual
Parameter-efficient (PVP) Tuning framework, which pre-trains the
parameter-efficient tuning modules first and then leverages the pre-trained
modules along with the pre-trained transformer backbone to perform
parameter-efficient tuning on downstream tasks. Experiment results on five
Fine-Grained Visual Classification (FGVC) and VTAB-1k datasets demonstrate that
our proposed method significantly outperforms state-of-the-art PETuning
methods.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization  of Long and Short Summaries</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13620</p>
  <p><b>作者</b>：Raian Rahman,  Rizvi Hasan,  Abdullah Al Farhad,  Md Tahmid Rahman Laskar,  Md. Hamjajul Ashmafee,  Abu Raihan Mostofa Kamal</p>
  <p><b>备注</b>：Accepted as a long paper at the Canadian AI 2023</p>
  <p><b>关键词</b>：visually impaired people, providing precise insights, text summarization, visually impaired, impaired people</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic chart to text summarization is an effective tool for the visually
impaired people along with providing precise insights of tabular data in
natural language to the user. A large and well-structured dataset is always a
key part for data driven models. In this paper, we propose ChartSumm: a
large-scale benchmark dataset consisting of a total of 84,363 charts along with
their metadata and descriptions covering a wide range of topics and chart types
to generate short and long summaries. Extensive experiments with strong
baseline models show that even though these models generate fluent and
informative summaries by achieving decent scores in various automatic
evaluation metrics, they often face issues like suffering from hallucination,
missing out important data points, in addition to incorrect explanation of
complex trends in the charts. We also investigated the potential of expanding
ChartSumm to other languages using automated translation tools. These make our
dataset a challenging benchmark for future research.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：CROP: Towards Distributional-Shift Robust Reinforcement Learning using  Compact Reshaped Observation Processing</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13616</p>
  <p><b>作者</b>：Philipp Altmann,  Fabian Ritz,  Leonard Feuchtinger,  Jonas Nüßlein,  Claudia Linnhoff-Popien,  Thomy Phan</p>
  <p><b>备注</b>：9 pages, 5 figures, accepted for publication at IJCAI 2023</p>
  <p><b>关键词</b>：reinforcement learning, safe application, application of reinforcement, limited training data, requires generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The safe application of reinforcement learning (RL) requires generalization
from limited training data to unseen scenarios. Yet, fulfilling tasks under
changing circumstances is a key challenge in RL. Current state-of-the-art
approaches for generalization apply data augmentation techniques to increase
the diversity of training data. Even though this prevents overfitting to the
training environment(s), it hinders policy optimization. Crafting a suitable
observation, only containing crucial information, has been shown to be a
challenging task itself. To improve data efficiency and generalization
capabilities, we propose Compact Reshaped Observation Processing (CROP) to
reduce the state information used for policy optimization. By providing only
relevant information, overfitting to a specific training layout is precluded
and generalization to unseen environments is improved. We formulate three CROPs
that can be applied to fully observable observation- and action-spaces and
provide methodical foundation. We empirically show the improvements of CROP in
a distributionally shifted safety gridworld. We furthermore provide benchmark
comparisons to full observability and data-augmentation in two different-sized
procedurally generated mazes.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Diffsurv: Differentiable sorting for censored time-to-event data</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13594</p>
  <p><b>作者</b>：Andre Vauvelle,  Benjamin Wild,  Aylin Cakiroglu,  Roland Eils,  Spiros Denaxas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Cox partial likelihood, numerous real-world applications, crucial semi-supervised task, Survival analysis, Cox partial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Survival analysis is a crucial semi-supervised task in machine learning with
numerous real-world applications, particularly in healthcare. Currently, the
most common approach to survival analysis is based on Cox's partial likelihood,
which can be interpreted as a ranking model optimized on a lower bound of the
concordance index. This relation between ranking models and Cox's partial
likelihood considers only pairwise comparisons. Recent work has developed
differentiable sorting methods which relax this pairwise independence
assumption, enabling the ranking of sets of samples. However, current
differentiable sorting methods cannot account for censoring, a key factor in
many real-world datasets. To address this limitation, we propose a novel method
called Diffsurv. We extend differentiable sorting methods to handle censored
tasks by predicting matrices of possible permutations that take into account
the label uncertainty introduced by censored samples. We contrast this approach
with methods derived from partial likelihood and ranking losses. Our
experiments show that Diffsurv outperforms established baselines in various
simulated and real-world risk prediction scenarios. Additionally, we
demonstrate the benefits of the algorithmic supervision enabled by Diffsurv by
presenting a novel method for top-k risk prediction that outperforms current
methods.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题："I'm" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13557</p>
  <p><b>作者</b>：Katie Seaborn,  Yeongdae Kim</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：virtual assistants continue, virtual assistants, assistants continue, speech-based systems, systems to communicate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As virtual assistants continue to be taken up globally, there is an
ever-greater need for these speech-based systems to communicate naturally in a
variety of languages. Crowdsourcing initiatives have focused on multilingual
translation of big, open data sets for use in natural language processing
(NLP). Yet, language translation is often not one-to-one, and biases can
trickle in. In this late-breaking work, we focus on the case of pronouns
translated between English and Japanese in the crowdsourced Tatoeba database.
We found that masculine pronoun biases were present overall, even though
plurality in language was accounted for in other ways. Importantly, we detected
biases in the translation process that reflect nuanced reactions to the
presence of feminine, neutral, and/or non-binary pronouns. We raise the issue
of translation bias for pronouns and offer a practical solution to embed
plurality in NLP data sets.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：FLCC: Efficient Distributed Federated Learning on IoMT over CSMA/CA</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13549</p>
  <p><b>作者</b>：Abdelaziz Salama,  Syed Ali Zaidi,  Des McLernon,  Mohammed M. H. Qazzaz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：raw local data, privacy preservation, allowing sharing, local data, raw local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) has emerged as a promising approach for privacy
preservation, allowing sharing of the model parameters between users and the
cloud server rather than the raw local data. FL approaches have been adopted as
a cornerstone of distributed machine learning (ML) to solve several complex use
cases. FL presents an interesting interplay between communication and ML
performance when implemented over distributed wireless nodes. Both the dynamics
of networking and learning play an important role. In this article, we
investigate the performance of FL on an application that might be used to
improve a remote healthcare system over ad hoc networks which employ CSMA/CA to
schedule its transmissions. Our FL over CSMA/CA (FLCC) model is designed to
eliminate untrusted devices and harness frequency reuse and spatial clustering
techniques to improve the throughput required for coordinating a distributed
implementation of FL in the wireless network.
In our proposed model, frequency allocation is performed on the basis of
spatial clustering performed using virtual cells. Each cell assigns a FL server
and dedicated carrier frequencies to exchange the updated model's parameters
within the cell. We present two metrics to evaluate the network performance: 1)
probability of successful transmission while minimizing the interference, and
2) performance of distributed FL model in terms of accuracy and loss while
considering the networking dynamics.
We benchmark the proposed approach using a well-known MNIST dataset for
performance evaluation. We demonstrate that the proposed approach outperforms
the baseline FL algorithms in terms of explicitly defining the chosen users'
criteria and achieving high accuracy in a robust network.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Killing Two Birds with One Stone: Quantization Achieves Privacy in  Distributed Learning</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13545</p>
  <p><b>作者</b>：Guangfeng Yan,  Tan Li,  Kui Wu,  Linqi Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Communication efficiency, distributed machine learning, critical issues, privacy, privacy protection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication efficiency and privacy protection are two critical issues in
distributed machine learning. Existing methods tackle these two issues
separately and may have a high implementation complexity that constrains their
application in a resource-limited environment. We propose a comprehensive
quantization-based solution that could simultaneously achieve communication
efficiency and privacy protection, providing new insights into the correlated
nature of communication and privacy. Specifically, we demonstrate the
effectiveness of our proposed solutions in the distributed stochastic gradient
descent (SGD) framework by adding binomial noise to the uniformly quantized
gradients to reach the desired differential privacy level but with a minor
sacrifice in communication efficiency. We theoretically capture the new
trade-offs between communication, privacy, and learning performance.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Byzantine-Resilient Learning Beyond Gradients: Distributing Evolutionary  Search</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13540</p>
  <p><b>作者</b>：Andrei Kucharavy,  Matteo Monti,  Rachid Guerraoui,  Ljiljana Dolamic</p>
  <p><b>备注</b>：10 pages, 4 listings, 2 theorems</p>
  <p><b>关键词</b>：Modern machine learning, Modern machine, models are capable, impressive performances, capable of impressive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern machine learning (ML) models are capable of impressive performances.
However, their prowess is not due only to the improvements in their
architecture and training algorithms but also to a drastic increase in
computational power used to train them.
Such a drastic increase led to a growing interest in distributed ML, which in
turn made worker failures and adversarial attacks an increasingly pressing
concern. While distributed byzantine resilient algorithms have been proposed in
a differentiable setting, none exist in a gradient-free setting.
The goal of this work is to address this shortcoming. For that, we introduce
a more general definition of byzantine-resilience in ML - the
\textit{model-consensus}, that extends the definition of the classical
distributed consensus. We then leverage this definition to show that a general
class of gradient-free ML algorithms - ($1,\lambda$)-Evolutionary Search - can
be combined with classical distributed consensus algorithms to generate
gradient-free byzantine-resilient distributed learning algorithms. We provide
proofs and pseudo-code for two specific cases - the Total Order Broadcast and
proof-of-work leader election.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Tensor Decomposition for Model Reduction in Neural Networks: A Review</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13539</p>
  <p><b>作者</b>：Xingyi Liu,  Keshab K. Parhi</p>
  <p><b>备注</b>：IEEE Circuits and Systems Magazine, 2023</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, computer vision, revolutionized the fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern neural networks have revolutionized the fields of computer vision (CV)
and Natural Language Processing (NLP). They are widely used for solving complex
CV tasks and NLP tasks such as image classification, image generation, and
machine translation. Most state-of-the-art neural networks are
over-parameterized and require a high computational cost. One straightforward
solution is to replace the layers of the networks with their low-rank tensor
approximations using different tensor decomposition methods. This paper reviews
six tensor decomposition methods and illustrates their ability to compress
model parameters of convolutional neural networks (CNNs), recurrent neural
networks (RNNs) and Transformers. The accuracy of some compressed models can be
higher than the original versions. Evaluations indicate that tensor
decompositions can achieve significant reductions in model size, run-time and
energy consumption, and are well suited for implementing neural networks on
edge devices.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Bridging the Gap: Gaze Events as Interpretable Concepts to Explain Deep  Neural Sequence Models</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13536</p>
  <p><b>作者</b>：Daniel G. Krakowczyk,  Paul Prasse,  David R. Reich,  Sebastian Lapuschkin,  Tobias Scheffer,  Lena A. Jäger</p>
  <p><b>备注</b>：Preprint for ETRA '23: 2023 Symposium on Eye Tracking Research and Applications</p>
  <p><b>关键词</b>：oculomotric biometric identification, eye tracking data, deep neural sequence, neural sequence models, feature attribution methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work in XAI for eye tracking data has evaluated the suitability of
feature attribution methods to explain the output of deep neural sequence
models for the task of oculomotric biometric identification. These methods
provide saliency maps to highlight important input features of a specific eye
gaze sequence. However, to date, its localization analysis has been lacking a
quantitative approach across entire datasets. In this work, we employ
established gaze event detection algorithms for fixations and saccades and
quantitatively evaluate the impact of these events by determining their concept
influence. Input features that belong to saccades are shown to be substantially
more important than features that belong to fixations. By dissecting saccade
events into sub-events, we are able to show that gaze samples that are close to
the saccadic peak velocity are most influential. We further investigate the
effect of event properties like saccadic amplitude or fixational dispersion on
the resulting concept influence.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Cluster Entropy: Active Domain Adaptation in Pathological Image  Segmentation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13513</p>
  <p><b>作者</b>：Xiaoqing Liu,  Kengo Araki,  Shota Harada,  Akihiko Yoshizawa,  Kazuhiro Terada,  Mariyo Kurata,  Naoki Nakajima,  Hiroyuki Abe,  Tetsuo Ushiku,  Ryoma Bise</p>
  <p><b>备注</b>：Accepted by IEEE ISBI'23</p>
  <p><b>关键词</b>：target domain, domain, domain adaptation, shift in pathological, pathological segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The domain shift in pathological segmentation is an important problem, where
a network trained by a source domain (collected at a specific hospital) does
not work well in the target domain (from different hospitals) due to the
different image features. Due to the problems of class imbalance and different
class prior of pathology, typical unsupervised domain adaptation methods do not
work well by aligning the distribution of source domain and target domain. In
this paper, we propose a cluster entropy for selecting an effective whole slide
image (WSI) that is used for semi-supervised domain adaptation. This approach
can measure how the image features of the WSI cover the entire distribution of
the target domain by calculating the entropy of each cluster and can
significantly improve the performance of domain adaptation. Our approach
achieved competitive results against the prior arts on datasets collected from
two hospitals.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Fundamental Tradeoffs in Learning with Prior Information</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13479</p>
  <p><b>作者</b>：Anirudha Majumdar</p>
  <p><b>备注</b>：Proceedings of the 40th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023</p>
  <p><b>关键词</b>：understand fundamental tradeoffs, seek to understand, fundamental tradeoffs, understand fundamental, prioritized risk</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We seek to understand fundamental tradeoffs between the accuracy of prior
information that a learner has on a given problem and its learning performance.
We introduce the notion of prioritized risk, which differs from traditional
notions of minimax and Bayes risk by allowing us to study such fundamental
tradeoffs in settings where reality does not necessarily conform to the
learner's prior. We present a general reduction-based approach for extending
classical minimax lower-bound techniques in order to lower bound the
prioritized risk for statistical estimation problems. We also introduce a novel
generalization of Fano's inequality (which may be of independent interest) for
lower bounding the prioritized risk in more general settings involving
unbounded losses. We illustrate the ability of our framework to provide
insights into tradeoffs between prior information and learning performance for
problems in estimation, regression, and reinforcement learning.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Effect of latent space distribution on the segmentation of images with  multiple annotations</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13476</p>
  <p><b>作者</b>：Ishaan Bhat,  Josien P.W. Pluim,  Max A. Viergever,  Hugo J. Kuijf</p>
  <p><b>备注</b>：Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL arXiv admin note: text overlap with arXiv:2207.12872</p>
  <p><b>关键词</b>：Generalized Probabilistic U-Net, Generalized Probabilistic, propose the Generalized, Probabilistic U-Net, latent space distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the Generalized Probabilistic U-Net, which extends the
Probabilistic U-Net by allowing more general forms of the Gaussian distribution
as the latent space distribution that can better approximate the uncertainty in
the reference segmentations. We study the effect the choice of latent space
distribution has on capturing the variation in the reference segmentations for
lung tumors and white matter hyperintensities in the brain. We show that the
choice of distribution affects the sample diversity of the predictions and
their overlap with respect to the reference segmentations. We have made our
implementation available at
this https URL</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：A Comparative Analysis of Multiple Methods for Predicting a Specific  Type of Crime in the City of Chicago</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13464</p>
  <p><b>作者</b>：Deborah Djon,  Jitesh Jhawar,  Kieron Drumm,  Vincent Tran</p>
  <p><b>备注</b>：9 pages, 1 figure</p>
  <p><b>关键词</b>：Researchers regard crime, Researchers regard, economic factors, social phenomenon, social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Researchers regard crime as a social phenomenon that is influenced by several
physical, social, and economic factors. Different types of crimes are said to
have different motivations. Theft, for instance, is a crime that is based on
opportunity, whereas murder is driven by emotion. In accordance with this, we
examine how well a model can perform with only spatiotemporal information at
hand when it comes to predicting a single crime. More specifically, we aim at
predicting theft, as this is a crime that should be predictable using
spatiotemporal information. We aim to answer the question: "How well can we
predict theft using spatial and temporal features?". To answer this question,
we examine the effectiveness of support vector machines, linear regression,
XGBoost, Random Forest, and k-nearest neighbours, using different imbalanced
techniques and hyperparameters. XGBoost showed the best results with an
F1-score of 0.86.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：From Chaos Comes Order: Ordering Event Representations for Object  Detection</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13455</p>
  <p><b>作者</b>：Nikola Zubić,  Daniel Gehrig,  Mathias Gehrig,  Davide Scaramuzza</p>
  <p><b>备注</b>：Submitted to ICCV 2023</p>
  <p><b>关键词</b>：deep neural networks, grid-like input representations, neural network, grid-like input, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Today, state-of-the-art deep neural networks that process events first
convert them into dense, grid-like input representations before using an
off-the-shelf network. However, selecting the appropriate representation for
the task traditionally requires training a neural network for each
representation and selecting the best one based on the validation score, which
is very time-consuming. In this work, we eliminate this bottleneck by selecting
the best representation based on the Gromov-Wasserstein Discrepancy (GWD)
between the raw events and their representation. It is approximately 200 times
faster to compute than training a neural network and preserves the task
performance ranking of event representations across multiple representations,
network backbones, and datasets. This means that finding a representation with
a high task score is equivalent to finding a representation with a low GWD. We
use this insight to, for the first time, perform a hyperparameter search on a
large family of event representations, revealing new and powerful
representations that exceed the state-of-the-art. On object detection, our
optimized representation outperforms existing representations by 1.9% mAP on
the 1 Mpx dataset and 8.6% mAP on the Gen1 dataset and even outperforms the
state-of-the-art by 1.8% mAP on Gen1 and state-of-the-art feed-forward methods
by 6.0% mAP on the 1 Mpx dataset. This work opens a new unexplored field of
explicit representation optimization for event-based learning methods.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Implicit Counterfactual Data Augmentation for Deep Neural Networks</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13431</p>
  <p><b>作者</b>：Xiaoling Zhou,  Ou Wu</p>
  <p><b>备注</b>：17 pages, 16 figures</p>
  <p><b>关键词</b>：counterfactual data augmentation, counterfactual data, Machine-learning models, attributes and classes, models are prone</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine-learning models are prone to capturing the spurious correlations
between non-causal attributes and classes, with counterfactual data
augmentation being a promising direction for breaking these spurious
associations. However, explicitly generating counterfactual data is
challenging, with the training efficiency declining. Therefore, this study
proposes an implicit counterfactual data augmentation (ICDA) method to remove
spurious correlations and make stable predictions. Specifically, first, a novel
sample-wise augmentation strategy is developed that generates semantically and
counterfactually meaningful deep features with distinct augmentation strength
for each sample. Second, we derive an easy-to-compute surrogate loss on the
augmented feature set when the number of augmented samples becomes infinite.
Third, two concrete schemes are proposed, including direct quantification and
meta-learning, to derive the key parameters for the robust loss. In addition,
ICDA is explained from a regularization aspect, with extensive experiments
indicating that our method consistently improves the generalization performance
of popular depth networks on multiple typical learning scenarios that require
out-of-distribution generalization.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：GENIE-NF-AI: Identifying Neurofibromatosis Tumors using Liquid Neural  Network (LTC) trained on AACR GENIE Datasets</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13429</p>
  <p><b>作者</b>：Michael Bidollahkhani,  Ferhat Atasoy,  Elnaz Abedini,  Ali Davar,  Omid Hamza,  Fırat Sefaoğlu,  Amin Jafari,  Muhammed Nadir Yalçın,  Hamdan Abdellatef</p>
  <p><b>备注</b>：The authors would like to acknowledge the American Association for Cancer Research and its financial and material support in the development of the AACR Project GENIE registry, as well as members of the consortium for their commitment to data sharing. Interpretations are the responsibility of study authors</p>
  <p><b>关键词</b>：adopting artificial intelligence, accurate disease detection, increasingly adopting artificial, recent years, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, the field of medicine has been increasingly adopting
artificial intelligence (AI) technologies to provide faster and more accurate
disease detection, prediction, and assessment. In this study, we propose an
interpretable AI approach to diagnose patients with neurofibromatosis using
blood tests and pathogenic variables. We evaluated the proposed method using a
dataset from the AACR GENIE project and compared its performance with modern
approaches. Our proposed approach outperformed existing models with 99.86%
accuracy. We also conducted NF1 and interpretable AI tests to validate our
approach. Our work provides an explainable approach model using logistic
regression and explanatory stimulus as well as a black-box model. The
explainable models help to explain the predictions of black-box models while
the glass-box models provide information about the best-fit features. Overall,
our study presents an interpretable AI approach for diagnosing patients with
neurofibromatosis and demonstrates the potential of AI in the medical field.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13426</p>
  <p><b>作者</b>：Matthieu Blanke,  Marc Lelarge</p>
  <p><b>备注</b>：Accepted at ICML 2023</p>
  <p><b>关键词</b>：powerful tool, collecting data, data to fit, fit an accurate, Model-based reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model-based reinforcement learning is a powerful tool, but collecting data to
fit an accurate model of the system can be costly. Exploring an unknown
environment in a sample-efficient manner is hence of great importance. However,
the complexity of dynamics and the computational limitations of real systems
make this task challenging. In this work, we introduce FLEX, an exploration
algorithm for nonlinear dynamics based on optimal experimental design. Our
policy maximizes the information of the next step and results in an adaptive
exploration algorithm, compatible with generic parametric learning models and
requiring minimal resources. We test our method on a number of nonlinear
environments covering different settings, including time-varying dynamics.
Keeping in mind that exploration is intended to serve an exploitation
objective, we also test our algorithm on downstream model-based classical
control tasks and compare it to other state-of-the-art model-based and
model-free approaches. The performance achieved by FLEX is competitive and its
computational cost is low.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Can Agents Run Relay Race with Strangers? Generalization of RL to  Out-of-Distribution Trajectories</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13424</p>
  <p><b>作者</b>：Li-Cheng Lan,  Huan Zhang,  Cho-Jui Hsieh</p>
  <p><b>备注</b>：ICRL 2023</p>
  <p><b>关键词</b>：reinforcement learning, controllable states, agent, controllable, states</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we define, evaluate, and improve the ``relay-generalization''
performance of reinforcement learning (RL) agents on the out-of-distribution
``controllable'' states. Ideally, an RL agent that generally masters a task
should reach its goal starting from any controllable state of the environment
instead of memorizing a small set of trajectories. For example, a self-driving
system should be able to take over the control from humans in the middle of
driving and must continue to drive the car safely. To practically evaluate this
type of generalization, we start the test agent from the middle of other
independently well-trained \emph{stranger} agents' trajectories. With extensive
experimental evaluation, we show the prevalence of \emph{generalization
failure} on controllable states from stranger agents. For example, in the
Humanoid environment, we observed that a well-trained Proximal Policy
Optimization (PPO) agent, with only 3.9\% failure rate during regular testing,
failed on 81.6\% of the states generated by well-trained stranger PPO agents.
To improve "relay generalization," we propose a novel method called
Self-Trajectory Augmentation (STA), which will reset the environment to the
agent's old states according to the Q function during training. After applying
STA to the Soft Actor Critic's (SAC) training procedure, we reduced the failure
rate of SAC under relay-evaluation by more than three times in most settings
without impacting agent performance and increasing the needed number of
environment interactions. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Regression with Sensor Data Containing Incomplete Observations</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13415</p>
  <p><b>作者</b>：Takayuki Katsuki,  Takayuki Osogami</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper addresses, addresses a regression, regression problem, results of sensing, incomplete observations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses a regression problem in which output label values are
the results of sensing the magnitude of a phenomenon. A low value of such
labels can mean either that the actual magnitude of the phenomenon was low or
that the sensor made an incomplete observation. This leads to a bias toward
lower values in labels and its resultant learning because labels may have lower
values due to incomplete observations, even if the actual magnitude of the
phenomenon was high. Moreover, because an incomplete observation does not
provide any tags indicating incompleteness, we cannot eliminate or impute them.
To address this issue, we propose a learning algorithm that explicitly models
incomplete observations corrupted with an asymmetric noise that always has a
negative value. We show that our algorithm is unbiased as if it were learned
from uncorrupted data that does not involve incomplete observations. We
demonstrate the advantages of our algorithm through numerical experiments.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Secure Communication Model For Quantum Federated Learning: A Post  Quantum Cryptography (PQC) Framework</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13413</p>
  <p><b>作者</b>：Dev Gurung,  Shiva Raj Pokhrel,  Gang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Post Quantum Cryptography, Quantum Cryptography, Quantum Federated, Post Quantum, model of Post</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We design a model of Post Quantum Cryptography (PQC) Quantum Federated
Learning (QFL). We develop a framework with a dynamic server selection and
study convergence and security conditions. The implementation and results are
publicly available1.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Improving Adversarial Transferability by Intermediate-level Perturbation  Decay</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13410</p>
  <p><b>作者</b>：Qizhang Li,  Yiwen Guo,  Wangmeng Zuo,  Hao Chen</p>
  <p><b>备注</b>：Revision of ICML '23 submission for better clarity</p>
  <p><b>关键词</b>：shown favorable performance, perturb feature representations, crafting transferable adversarial, attempt to perturb, drastically have shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intermediate-level attacks that attempt to perturb feature representations
following an adversarial direction drastically have shown favorable performance
in crafting transferable adversarial examples. Existing methods in this
category are normally formulated with two separate stages, where a directional
guide is required to be determined at first and the scalar projection of the
intermediate-level perturbation onto the directional guide is enlarged
thereafter. The obtained perturbation deviates from the guide inevitably in the
feature space, and it is revealed in this paper that such a deviation may lead
to sub-optimal attack. To address this issue, we develop a novel
intermediate-level method that crafts adversarial examples within a single
stage of optimization. In particular, the proposed method, named
intermediate-level perturbation decay (ILPD), encourages the intermediate-level
perturbation to be in an effective adversarial direction and to possess a great
magnitude simultaneously. In-depth discussion verifies the effectiveness of our
method. Experimental results show that it outperforms state-of-the-arts by
large margins in attacking various victim models on ImageNet (+10.07% on
average) and CIFAR-10 (+3.88% on average). Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated  Learning for Split Models</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13407</p>
  <p><b>作者</b>：Songze Li,  Duanyi Yao,  Jin Liu</p>
  <p><b>备注</b>：This paper was accepted to ICML 2023</p>
  <p><b>关键词</b>：vertical federated learning, federated learning, system consisting, vertical federated, vertically partitioned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a vertical federated learning (VFL) system consisting of a central server
and many distributed clients, the training data are vertically partitioned such
that different features are privately stored on different clients. The problem
of split VFL is to train a model split between the server and the clients. This
paper aims to address two major challenges in split VFL: 1) performance
degradation due to straggling clients during training; and 2) data and model
privacy leakage from clients' uploaded data embeddings. We propose FedVS to
simultaneously address these two challenges. The key idea of FedVS is to design
secret sharing schemes for the local data and models, such that
information-theoretical privacy against colluding clients and curious server is
guaranteed, and the aggregation of all clients' embeddings is reconstructed
losslessly, via decrypting computation shares from the non-straggling clients.
Extensive experiments on various types of VFL datasets (including tabular, CV,
and multi-view) demonstrate the universal advantages of FedVS in straggler
mitigation and privacy protection over baseline protocols.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：SEAL: Simultaneous Label Hierarchy Exploration And Learning</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13374</p>
  <p><b>作者</b>：Zhiquan Tan,  Zihao Wang,  Yifan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enhance classification performance, classification performance, important source, source of external, external knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label hierarchy is an important source of external knowledge that can enhance
classification performance. However, most existing methods rely on predefined
label hierarchies that may not match the data distribution. To address this
issue, we propose Simultaneous label hierarchy Exploration And Learning (SEAL),
a new framework that explores the label hierarchy by augmenting the observed
labels with latent labels that follow a prior hierarchical structure. Our
approach uses a 1-Wasserstein metric over the tree metric space as an objective
function, which enables us to simultaneously learn a data-driven label
hierarchy and perform (semi-)supervised learning. We evaluate our method on
several datasets and show that it achieves superior results in both supervised
and semi-supervised scenarios and reveals insightful label structures. Our
implementation is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Feed-Forward Optimization With Delayed Feedback for Neural Networks</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13372</p>
  <p><b>作者</b>：Katharina Flügel,  Daniel Coquelin,  Marie Weiel,  Charlotte Debus,  Achim Streit,  Markus Götz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural learning processes, relying on concepts, learning processes, long been criticized, viable in natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Backpropagation has long been criticized for being biologically implausible,
relying on concepts that are not viable in natural learning processes. This
paper proposes an alternative approach to solve two core issues, i.e., weight
transport and update locking, for biological plausibility and computational
efficiency. We introduce Feed-Forward with delayed Feedback (F$^3$), which
improves upon prior work by utilizing delayed error information as a
sample-wise scaling factor to approximate gradients more accurately. We find
that F$^3$ reduces the gap in predictive performance between biologically
plausible training algorithms and backpropagation by up to 96%. This
demonstrates the applicability of biologically plausible training and opens up
promising new avenues for low-energy training and parallelization.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：LoRaWAN-enabled Smart Campus: The Dataset and a People Counter Use Case</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13366</p>
  <p><b>作者</b>：Eslam Eldeeb,  Hirley Alves</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smart campus, Smart Campus dataset, significant role, Campus dataset based, smart</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>IoT has a significant role in the smart campus. This paper presents a
detailed description of the Smart Campus dataset based on LoRaWAN. LoRaWAN is
an emerging technology that enables serving hundreds of IoT devices. First, we
describe the LoRa network that connects the devices to the server. Afterward,
we analyze the missing transmissions and propose a k-nearest neighbor solution
to handle the missing values. Then, we predict future readings using a long
short-term memory (LSTM). Finally, as one example application, we build a deep
neural network to predict the number of people inside a room based on the
selected sensor's readings. Our results show that our model achieves an
accuracy of $95 \: \%$ in predicting the number of people. Moreover, the
dataset is openly available and described in detail, which is opportunity for
exploration of other features and applications.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Concept-Monitor: Understanding DNN training through individual neurons</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13346</p>
  <p><b>作者</b>：Mohammad Ali Khan,  Tuomas Oikarinen,  Tsui-Wei Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general framework called, unified embedding space, DNN training processes, concept diversity metric, framework called Concept-Monitor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a general framework called Concept-Monitor to help
demystify the black-box DNN training processes automatically using a novel
unified embedding space and concept diversity metric. Concept-Monitor enables
human-interpretable visualization and indicators of the DNN training processes
and facilitates transparency as well as deeper understanding on how DNNs
develop along the during training. Inspired by these findings, we also propose
a new training regularizer that incentivizes hidden neurons to learn diverse
concepts, which we show to improve training performance. Finally, we apply
Concept-Monitor to conduct several case studies on different training paradigms
including adversarial training, fine-tuning and network pruning via the Lottery
Ticket Hypothesis</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：OpenBox: A Python Toolkit for Generalized Black-box Optimization</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13339</p>
  <p><b>作者</b>：Huaijun Jiang,  Yu Shen,  Yang Li,  Wentao Zhang,  Ce Zhang,  Bin Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including automatic machine, automatic machine learning, database knob tuning, Black-box optimization, range of applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Black-box optimization (BBO) has a broad range of applications, including
automatic machine learning, experimental design, and database knob tuning.
However, users still face challenges when applying BBO methods to their
problems at hand with existing software packages in terms of applicability,
performance, and efficiency. This paper presents OpenBox, an open-source BBO
toolkit with improved usability. It implements user-friendly inferfaces and
visualization for users to define and manage their tasks. The modular design
behind OpenBox facilitates its flexible deployment in existing systems.
Experimental results demonstrate the effectiveness and efficiency of OpenBox
over existing systems. The source code of OpenBox is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Technical Note: Defining and Quantifying AND-OR Interactions for  Faithful and Concise Explanation of DNNs</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13312</p>
  <p><b>作者</b>：Mingjie Li,  Quanshi Zhang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2111.06206</p>
  <p><b>关键词</b>：deep neural network, technical note, neural network, aim to explain, explain a deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this technical note, we aim to explain a deep neural network (DNN) by
quantifying the encoded interactions between input variables, which reflects
the DNN's inference logic. Specifically, we first rethink the definition of
interactions, and then formally define faithfulness and conciseness for
interaction-based explanation. To this end, we propose two kinds of
interactions, i.e., the AND interaction and the OR interaction. For
faithfulness, we prove the uniqueness of the AND (OR) interaction in
quantifying the effect of the AND (OR) relationship between input variables.
Besides, based on AND-OR interactions, we design techniques to boost the
conciseness of the explanation, while not hurting the faithfulness. In this
way, the inference logic of a DNN can be faithfully and concisely explained by
a set of symbolic concepts.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：HiQ -- A Declarative, Non-intrusive, Dynamic and Transparent  Observability and Optimization System</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13302</p>
  <p><b>作者</b>：Fuheng Wu,  Ivan Davchev,  Jun Qian</p>
  <p><b>备注</b>：7 pages, 12 figures, opensource</p>
  <p><b>关键词</b>：track Python program, Python program runtime, program runtime information, transparent system called, run-time system performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a non-intrusive, declarative, dynamic and transparent
system called `HiQ` to track Python program runtime information without
compromising on the run-time system performance and losing insight. HiQ can be
used for monolithic and distributed systems, offline and online applications.
HiQ is developed when we optimize our large deep neural network (DNN) models
which are written in Python, but it can be generalized to any Python program or
distributed system, or even other languages like Java. We have implemented the
system and adopted it in our deep learning model life cycle management system
to catch the bottleneck while keeping our production code clean and highly
performant. The implementation is open-sourced at:
[this https URL](this https URL).</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Membrane Potential Distribution Adjustment and Parametric Surrogate  Gradient in Spiking Neural Networks</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13289</p>
  <p><b>作者</b>：Siqi Wang,  Tee Hiang Cheng,  Meng-Hiot Lim</p>
  <p><b>备注</b>：10 pages, 8 figures</p>
  <p><b>关键词</b>：emerging network model, aroused significant research, significant research attentions, spiking neural networks, network model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an emerging network model, spiking neural networks (SNNs) have aroused
significant research attentions in recent years. However, the energy-efficient
binary spikes do not augur well with gradient descent-based training
approaches. Surrogate gradient (SG) strategy is investigated and applied to
circumvent this issue and train SNNs from scratch. Due to the lack of
well-recognized SG selection rule, most SGs are chosen intuitively. We propose
the parametric surrogate gradient (PSG) method to iteratively update SG and
eventually determine an optimal surrogate gradient parameter, which calibrates
the shape of candidate SGs. In SNNs, neural potential distribution tends to
deviate unpredictably due to quantization error. We evaluate such potential
shift and propose methodology for potential distribution adjustment (PDA) to
minimize the loss of undesired pre-activations. Experimental results
demonstrate that the proposed methods can be readily integrated with
backpropagation through time (BPTT) algorithm and help modulated SNNs to
achieve state-of-the-art performance on both static and dynamic dataset with
fewer timesteps.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：The Closeness of In-Context Learning and Weight Shifting for Softmax  Regression</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13276</p>
  <p><b>作者</b>：Shuai Li,  Zhao Song,  Yu Xia,  Tong Yu,  Tianyi Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Large language models, Large language, language processing, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) are known for their exceptional performance in
natural language processing, making them highly effective in many human
life-related or even job-related tasks. The attention mechanism in the
Transformer architecture is a critical component of LLMs, as it allows the
model to selectively focus on specific input parts. The softmax unit, which is
a key part of the attention mechanism, normalizes the attention scores. Hence,
the performance of LLMs in various NLP tasks depends significantly on the
crucial role played by the attention mechanism with the softmax unit.
In-context learning, as one of the celebrated abilities of recent LLMs, is an
important concept in querying LLMs such as ChatGPT. Without further parameter
updates, Transformers can learn to predict based on few in-context examples.
However, the reason why Transformers becomes in-context learners is not well
understood. Recently, several works [ASA+22,GTLV22,ONR+22] have studied the
in-context learning from a mathematical perspective based on a linear
regression formulation $\min_x\| Ax - b \|_2$, which show Transformers'
capability of learning linear functions in context.
In this work, we study the in-context learning based on a softmax regression
formulation $\min_{x} \| \langle \exp(Ax), {\bf 1}_n \rangle^{-1} \exp(Ax) - b
\|_2$ of Transformer's attention mechanism. We show the upper bounds of the
data transformations induced by a single self-attention layer and by
gradient-descent on a $\ell_2$ regression loss for softmax prediction function,
which imply that when training self-attention-only Transformers for fundamental
regression tasks, the models learned by gradient-descent and Transformers show
great similarity.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Federated Learning with Uncertainty-Based Client Clustering for  Fleet-Wide Fault Diagnosis</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13275</p>
  <p><b>作者</b>：Hao Lu,  Adam Thelen,  Olga Fink,  Chao Hu,  Simon Laflamme</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：wireless sensing nodes, warning maintenance engineers, sizeable condition monitoring, identifying current system, current system health</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Operators from various industries have been pushing the adoption of wireless
sensing nodes for industrial monitoring, and such efforts have produced
sizeable condition monitoring datasets that can be used to build diagnosis
algorithms capable of warning maintenance engineers of impending failure or
identifying current system health conditions. However, single operators may not
have sufficiently large fleets of systems or component units to collect
sufficient data to develop data-driven algorithms. Collecting a satisfactory
quantity of fault patterns for safety-critical systems is particularly
difficult due to the rarity of faults. Federated learning (FL) has emerged as a
promising solution to leverage datasets from multiple operators to train a
decentralized asset fault diagnosis model while maintaining data
confidentiality. However, there are still considerable obstacles to overcome
when it comes to optimizing the federation strategy without leaking sensitive
data and addressing the issue of client dataset heterogeneity. This is
particularly prevalent in fault diagnosis applications due to the high
diversity of operating conditions and system configurations. To address these
two challenges, we propose a novel clustering-based FL algorithm where clients
are clustered for federating based on dataset similarity. To quantify dataset
similarity between clients without explicitly sharing data, each client sets
aside a local test dataset and evaluates the other clients' model prediction
accuracy and uncertainty on this test dataset. Clients are then clustered for
FL based on relative prediction accuracy and uncertainty.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Making Models Shallow Again: Jointly Learning to Reduce Non-Linearity  and Depth for Latency-Efficient Private Inference</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13274</p>
  <p><b>作者</b>：Souvik Kundu,  Yuke Zhang,  Dake Chen,  Peter A. Beerel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, compute-efficient private inference, neural networks make, Deep neural, Large number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large number of ReLU and MAC operations of Deep neural networks make them
ill-suited for latency and compute-efficient private inference. In this paper,
we present a model optimization method that allows a model to learn to be
shallow. In particular, we leverage the ReLU sensitivity of a convolutional
block to remove a ReLU layer and merge its succeeding and preceding convolution
layers to a shallow block. Unlike existing ReLU reduction methods, our joint
reduction method can yield models with improved reduction of both ReLUs and
linear operations by up to 1.73x and 1.47x, respectively, evaluated with
ResNet18 on CIFAR-100 without any significant accuracy-drop.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：From Association to Generation: Text-only Captioning by Unsupervised  Cross-modal Mapping</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13273</p>
  <p><b>作者</b>：Junyang Wang,  Ming Yan,  Yi Zhang,  Ming Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：association-based visual tasks, Vision-Language Pre-training Models, significant breakthroughs, CLIP, development of Vision-Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of Vision-Language Pre-training Models (VLPMs)
represented by CLIP and ALIGN, significant breakthroughs have been achieved for
association-based visual tasks such as image classification and image-text
retrieval by the zero-shot capability of CLIP without fine-tuning. However,
CLIP is hard to apply to generation-based tasks. This is due to the lack of
decoder architecture and pre-training tasks for generation. Although previous
works have created generation capacity for CLIP through additional language
models, a modality gap between the CLIP representations of different modalities
and the inability of CLIP to model the offset of this gap, which fails the
concept to transfer across modalities. To solve the problem, we try to map
images/videos to the language modality and generate captions from the language
modality. In this paper, we propose the K-nearest-neighbor Cross-modality
Mapping (Knight), a zero-shot method from association to generation. With
text-only unsupervised training, Knight achieves state-of-the-art performance
in zero-shot methods for image captioning and video captioning. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Bayesian Federated Learning: A Survey</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13267</p>
  <p><b>作者</b>：Longbing Cao,  Hui Chen,  Xuhui Fan,  Joao Gama,  Yew-Soon Ong,  Vipin Kumar</p>
  <p><b>备注</b>：Accepted by IJCAI 2023 Survey Track, copyright is owned to IJCAI</p>
  <p><b>关键词</b>：integrating distributed infrastructure, demonstrates its advantages, distributed infrastructure, privacy-preserving manner, advantages in integrating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) demonstrates its advantages in integrating
distributed infrastructure, communication, computing and learning in a
privacy-preserving manner. However, the robustness and capabilities of existing
FL methods are challenged by limited and dynamic data and conditions,
complexities including heterogeneities and uncertainties, and analytical
explainability. Bayesian federated learning (BFL) has emerged as a promising
approach to address these issues. This survey presents a critical overview of
BFL, including its basic concepts, its relations to Bayesian learning in the
context of FL, and a taxonomy of BFL from both Bayesian and federated
perspectives. We categorize and discuss client- and server-side and FL-based
BFL methods and their pros and cons. The limitations of the existing BFL
methods and the future directions of BFL research further address the intricate
requirements of real-life FL applications.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：SHIELD: Thwarting Code Authorship Attribution</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13255</p>
  <p><b>作者</b>：Mohammed Abuhamad,  Changhun Jung,  David Mohaisen,  DaeHun Nyang</p>
  <p><b>备注</b>：12 pages, 13 figures</p>
  <p><b>关键词</b>：Authorship attribution, authorship attribution methods, attribution, increasingly accurate, remain anonymous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Authorship attribution has become increasingly accurate, posing a serious
privacy risk for programmers who wish to remain anonymous. In this paper, we
introduce SHIELD to examine the robustness of different code authorship
attribution approaches against adversarial code examples. We define four
attacks on attribution techniques, which include targeted and non-targeted
attacks, and realize them using adversarial code perturbation. We experiment
with a dataset of 200 programmers from the Google Code Jam competition to
validate our methods targeting six state-of-the-art authorship attribution
methods that adopt a variety of techniques for extracting authorship traits
from source-code, including RNN, CNN, and code stylometry. Our experiments
demonstrate the vulnerability of current authorship attribution methods against
adversarial attacks. For the non-targeted attack, our experiments demonstrate
the vulnerability of current authorship attribution methods against the attack
with an attack success rate exceeds 98.5\% accompanied by a degradation of the
identification confidence that exceeds 13\%. For the targeted attacks, we show
the possibility of impersonating a programmer using targeted-adversarial
perturbations with a success rate ranging from 66\% to 88\% for different
authorship attribution techniques under several adversarial scenarios.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Analyzing In-browser Cryptojacking</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13253</p>
  <p><b>作者</b>：Muhammad Saad,  David Mohaisen</p>
  <p><b>备注</b>：14 pages, 11 tables, 8 figures, and 69 references. arXiv admin note: substantial text overlap with arXiv:1809.02152</p>
  <p><b>关键词</b>：covertly mine cryptocurrencies, mine cryptocurrencies, target device, device to covertly, covertly mine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cryptojacking is the permissionless use of a target device to covertly mine
cryptocurrencies. With cryptojacking, attackers use malicious JavaScript codes
to force web browsers into solving proof-of-work puzzles, thus making money by
exploiting the resources of the website visitors. To understand and counter
such attacks, we systematically analyze the static, dynamic, and economic
aspects of in-browser cryptojacking. For static analysis, we perform content,
currency, and code-based categorization of cryptojacking samples to 1) measure
their distribution across websites, 2) highlight their platform affinities, and
3) study their code complexities. We apply machine learning techniques to
distinguish cryptojacking scripts from benign and malicious JavaScript samples
with 100\% accuracy. For dynamic analysis, we analyze the effect of
cryptojacking on critical system resources, such as CPU and battery usage. We
also perform web browser fingerprinting to analyze the information exchange
between the victim node and the dropzone cryptojacking server. We also build an
analytical model to empirically evaluate the feasibility of cryptojacking as an
alternative to online advertisement. Our results show a sizeable negative
profit and loss gap, indicating that the model is economically infeasible.
Finally, leveraging insights from our analyses, we build countermeasures for
in-browser cryptojacking that improve the existing remedies.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：A Security Verification Framework of Cryptographic Protocols Using  Machine Learning</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13249</p>
  <p><b>作者</b>：Kentaro Ohno,  Misato Nakabayashi</p>
  <p><b>备注</b>：14 pages, 5 figures</p>
  <p><b>关键词</b>：verification, cryptographic protocols, protocols, security verification framework, formal verification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a security verification framework for cryptographic protocols
using machine learning. In recent years, as cryptographic protocols have become
more complex, research on automatic verification techniques has been focused
on. The main technique is formal verification. However, the formal verification
has two problems: it requires a large amount of computational time and does not
guarantee decidability. We propose a method that allows security verification
with computational time on the order of linear with respect to the size of the
protocol using machine learning. In training machine learning models for
security verification of cryptographic protocols, a sufficient amount of data,
i.e., a set of protocol data with security labels, is difficult to collect from
academic papers and other sources. To overcome this issue, we propose a way to
create arbitrarily large datasets by automatically generating random protocols
and assigning security labels to them using formal verification tools.
Furthermore, to exploit structural features of protocols, we construct a neural
network that processes a protocol along its series and tree structures. We
evaluate the proposed method by applying it to verification of practical
cryptographic protocols.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning to Predict Navigational Patterns from Partial Observations</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13242</p>
  <p><b>作者</b>：Robin Karlsson,  Alexander Carballo,  Francisco Lepe-Salazar,  Keisuke Fujii,  Kento Ohtani,  Kazuya Takeda</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：cooperatively navigate rule-constrained, navigate rule-constrained environments, navigational patterns, Human beings cooperatively, cooperatively navigate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human beings cooperatively navigate rule-constrained environments by adhering
to mutually known navigational patterns, which may be represented as
directional pathways or road lanes. Inferring these navigational patterns from
incompletely observed environments is required for intelligent mobile robots
operating in unmapped locations. However, algorithmically defining these
navigational patterns is nontrivial. This paper presents the first
self-supervised learning (SSL) method for learning to infer navigational
patterns in real-world environments from partial observations only. We explain
how geometric data augmentation, predictive world modeling, and an
information-theoretic regularizer enables our model to predict an unbiased
local directional soft lane probability (DSLP) field in the limit of infinite
data. We demonstrate how to infer global navigational patterns by fitting a
maximum likelihood graph to the DSLP field. Experiments show that our SSL model
outperforms two SOTA supervised lane graph prediction models on the nuScenes
dataset. We propose our SSL method as a scalable and interpretable continual
learning paradigm for navigation by perception. Code released upon publication.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Structure Diagram Recognition in Financial Announcements</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13240</p>
  <p><b>作者</b>：Meixuan Qiao,  Jun Wang,  Junfu Xiang,  Qiyu Hou,  Ruixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Accurately extracting structured, extracting structured data, great practical importance, building financial knowledge, financial knowledge graphs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately extracting structured data from structure diagrams in financial
announcements is of great practical importance for building financial knowledge
graphs and further improving the efficiency of various financial applications.
First, we proposed a new method for recognizing structure diagrams in financial
announcements, which can better detect and extract different types of
connecting lines, including straight lines, curves, and polylines of different
orientations and angles. Second, we developed a two-stage method to efficiently
generate the industry's first benchmark of structure diagrams from Chinese
financial announcements, where a large number of diagrams were synthesized and
annotated using an automated tool to train a preliminary recognition model with
fairly good performance, and then a high-quality benchmark can be obtained by
automatically annotating the real-world structure diagrams using the
preliminary model and then making few manual corrections. Finally, we
experimentally verified the significant performance advantage of our structure
diagram recognition method over previous methods.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Multi-criteria Hardware Trojan Detection: A Reinforcement Learning  Approach</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13232</p>
  <p><b>作者</b>：Amin Sarihi,  Peter Jamieson,  Ahmad Patooghy,  Abdel-Hameed A. Badawy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：digital integrated circuits, Hardware Trojans, nets switching activity, integrated circuits, manufacturing modifications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hardware Trojans (HTs) are undesired design or manufacturing modifications
that can severely alter the security and functionality of digital integrated
circuits. HTs can be inserted according to various design criteria, e.g., nets
switching activity, observability, controllability, etc. However, to our
knowledge, most HT detection methods are only based on a single criterion,
i.e., nets switching activity. This paper proposes a multi-criteria
reinforcement learning (RL) HT detection tool that features a tunable reward
function for different HT detection scenarios. The tool allows for exploring
existing detection strategies and can adapt new detection scenarios with
minimal effort. We also propose a generic methodology for comparing HT
detection methods fairly. Our preliminary results show an average of 84.2%
successful HT detection in ISCAS-85 benchmark</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Generating Adversarial Examples with Task Oriented Multi-Objective  Optimization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13229</p>
  <p><b>作者</b>：Anh Bui,  Trung Le,  He Zhao,  Quan Tran,  Paul Montague,  Dinh Phung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning models, Deep learning, adversarial, highly vulnerable, Adversarial training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models, even the-state-of-the-art ones, are highly vulnerable
to adversarial examples. Adversarial training is one of the most efficient
methods to improve the model's robustness. The key factor for the success of
adversarial training is the capability to generate qualified and divergent
adversarial examples which satisfy some objectives/goals (e.g., finding
adversarial examples that maximize the model losses for simultaneously
attacking multiple models). Therefore, multi-objective optimization (MOO) is a
natural tool for adversarial example generation to achieve multiple
objectives/goals simultaneously. However, we observe that a naive application
of MOO tends to maximize all objectives/goals equally, without caring if an
objective/goal has been achieved yet. This leads to useless effort to further
improve the goal-achieved tasks, while putting less focus on the
goal-unachieved tasks. In this paper, we propose \emph{Task Oriented MOO} to
address this issue, in the context where we can explicitly define the goal
achievement for a task. Our principle is to only maintain the goal-achieved
tasks, while letting the optimizer spend more effort on improving the
goal-unachieved tasks. We conduct comprehensive experiments for our Task
Oriented MOO on various adversarial example generation schemes. The
experimental results firmly demonstrate the merit of our proposed approach. Our
code is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Score-based Generative Modeling Through Backward Stochastic Differential  Equations: Inversion and Generation</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13224</p>
  <p><b>作者</b>：Zihao Wang</p>
  <p><b>备注</b>：Preliminary Preprint</p>
  <p><b>关键词</b>：stochastic differential equations, proposed BSDE-based diffusion, BSDE-based diffusion model, differential equations, proposed BSDE-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The proposed BSDE-based diffusion model represents a novel approach to
diffusion modeling, which extends the application of stochastic differential
equations (SDEs) in machine learning. Unlike traditional SDE-based diffusion
models, our model can determine the initial conditions necessary to reach a
desired terminal distribution by adapting an existing score function. We
demonstrate the theoretical guarantees of the model, the benefits of using
Lipschitz networks for score matching, and its potential applications in
various areas such as diffusion inversion, conditional diffusion, and
uncertainty quantification. Our work represents a contribution to the field of
score-based generative learning and offers a promising direction for solving
real-world problems.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Reinforcement Learning with Partial Parametric Model Knowledge</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13223</p>
  <p><b>作者</b>：Shuyuan Wang,  Philip D. Loewen,  Nathan P. Lawrence,  Michael G. Forbes,  R. Bhushan Gopaluni</p>
  <p><b>备注</b>：IFAC World Congress 2023</p>
  <p><b>关键词</b>：adapt reinforcement learning, Squares Policy Iteration, reinforcement learning, adapt reinforcement, bridge the gap</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We adapt reinforcement learning (RL) methods for continuous control to bridge
the gap between complete ignorance and perfect knowledge of the environment.
Our method, Partial Knowledge Least Squares Policy Iteration (PLSPI), takes
inspiration from both model-free RL and model-based control. It uses incomplete
information from a partial model and retains RL's data-driven adaption towards
optimal performance. The linear quadratic regulator provides a case study;
numerical experiments demonstrate the effectiveness and resulting benefits of
the proposed method.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：The Nonlocal Neural Operator: Universal Approximation</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13221</p>
  <p><b>作者</b>：Samuel Lanthaler,  Zongyi Li,  Andrew M. Stuart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：infinite-dimensional Banach spaces, infinite-dimensional Banach, Banach spaces, Fourier neural operator, Neural operator architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural operator architectures approximate operators between
infinite-dimensional Banach spaces of functions. They are gaining increased
attention in computational science and engineering, due to their potential both
to accelerate traditional numerical methods and to enable data-driven
discovery. A popular variant of neural operators is the Fourier neural operator
(FNO). Previous analysis proving universal operator approximation theorems for
FNOs resorts to use of an unbounded number of Fourier modes and limits the
basic form of the method to problems with periodic geometry. Prior work relies
on intuition from traditional numerical methods, and interprets the FNO as a
nonstandard and highly nonlinear spectral method. The present work challenges
this point of view in two ways: (i) the work introduces a new broad class of
operator approximators, termed nonlocal neural operators (NNOs), which allow
for operator approximation between functions defined on arbitrary geometries,
and includes the FNO as a special case; and (ii) analysis of the NNOs shows
that, provided this architecture includes computation of a spatial average
(corresponding to retaining only a single Fourier mode in the special case of
the FNO) it benefits from universal approximation. It is demonstrated that this
theoretical result unifies the analysis of a wide range of neural operator
architectures. Furthermore, it sheds new light on the role of nonlocality, and
its interaction with nonlinearity, thereby paving the way for a more systematic
exploration of nonlocality, both through the development of new operator
learning architectures and the analysis of existing and new architectures.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：ZRG: A High Resolution 3D Residential Rooftop Geometry Dataset for  Machine Learning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13219</p>
  <p><b>作者</b>：Isaac Corley,  Jonathan Lwowski,  Peyman Najafirad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Zeitview Rooftop Geometry, residential rooftop geometry, present the Zeitview, Zeitview Rooftop, Rooftop Geometry</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present the Zeitview Rooftop Geometry (ZRG) dataset. ZRG
contains thousands of samples of high resolution orthomosaics of aerial imagery
of residential rooftops with corresponding digital surface models (DSM), 3D
rooftop wireframes, and multiview imagery generated point clouds for the
purpose of residential rooftop geometry and scene understanding. We perform
thorough benchmarks to illustrate the numerous applications unlocked by this
dataset and provide baselines for the tasks of roof outline extraction,
monocular height estimation, and planar roof structure extraction.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Single-View Height Estimation with Conditional Diffusion Probabilistic  Models</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13214</p>
  <p><b>作者</b>：Isaac Corley,  Peyman Najafirad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding the Earth, Earth surface, offer a wealth, man-made structures, information for understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Digital Surface Models (DSM) offer a wealth of height information for
understanding the Earth's surface as well as monitoring the existence or change
in natural and man-made structures. Classical height estimation requires
multi-view geospatial imagery or LiDAR point clouds which can be expensive to
acquire. Single-view height estimation using neural network based models shows
promise however it can struggle with reconstructing high resolution features.
The latest advancements in diffusion models for high resolution image synthesis
and editing have yet to be utilized for remote sensing imagery, particularly
height estimation. Our approach involves training a generative diffusion model
to learn the joint distribution of optical and DSM images across both domains
as a Markov chain. This is accomplished by minimizing a denoising score
matching objective while being conditioned on the source image to generate
realistic high resolution 3D surfaces. In this paper we experiment with
conditional denoising diffusion probabilistic models (DDPM) for height
estimation from a single remotely sensed image and show promising results on
the Vaihingen benchmark dataset.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Splitting physics-informed neural networks for inferring the dynamics of  integer- and fractional-order neuron models</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13205</p>
  <p><b>作者</b>：Simin Shekarpaz,  Fanhai Zeng,  George Karniadakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：physics-informed neural networks, neural networks, differential equations, physics-informed neural, neuron models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new approach for solving forward systems of differential
equations using a combination of splitting methods and physics-informed neural
networks (PINNs). The proposed method, splitting PINN, effectively addresses
the challenge of applying PINNs to forward dynamical systems and demonstrates
improved accuracy through its application to neuron models. Specifically, we
apply operator splitting to decompose the original neuron model into
sub-problems that are then solved using PINNs. Moreover, we develop an $L^1$
scheme for discretizing fractional derivatives in fractional neuron models,
leading to improved accuracy and efficiency. The results of this study
highlight the potential of splitting PINNs in solving both integer- and
fractional-order neuron models, as well as other similar systems in
computational science and engineering.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Connector 0.5: A unified framework for graph representation learning</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13195</p>
  <p><b>作者</b>：Thanh Sang Nguyen,  Jooho Lee,  Van Thuy Hoang,  O-Joun Lee</p>
  <p><b>备注</b>：An unified framework for graph representation learning</p>
  <p><b>关键词</b>：graph embedding models, embedding models, graph embedding, representation learning models, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph representation learning models aim to represent the graph structure and
its features into low-dimensional vectors in a latent space, which can benefit
various downstream tasks, such as node classification and link prediction. Due
to its powerful graph data modelling capabilities, various graph embedding
models and libraries have been proposed to learn embeddings and help
researchers ease conducting experiments. In this paper, we introduce a novel
graph representation framework covering various graph embedding models, ranging
from shallow to state-of-the-art models, namely Connector. First, we consider
graph generation by constructing various types of graphs with different
structural relations, including homogeneous, signed, heterogeneous, and
knowledge graphs. Second, we introduce various graph representation learning
models, ranging from shallow to deep graph embedding models. Finally, we plan
to build an efficient open-source framework that can provide deep graph
embedding models to represent structural relations in graphs. The framework is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Towards Reliable Colorectal Cancer Polyps Classification via Vision  Based Tactile Sensing and Confidence-Calibrated Neural Networks</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13192</p>
  <p><b>作者</b>：Siddhartha Kapuria,  Tarunraj G. Mohanraj,  Nethra Venkatayogi,  Ozdemir Can Kara,  Yuki Hirata,  Patrick Minot,  Ariel Kapusta,  Naruhiko Ikoma,  Farshid Alambeigi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligence-based colorectal cancer, existing artificial intelligence-based, artificial intelligence-based colorectal, polyp classification techniques, CRC polyps classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, toward addressing the over-confident outputs of existing
artificial intelligence-based colorectal cancer (CRC) polyp classification
techniques, we propose a confidence-calibrated residual neural network.
Utilizing a novel vision-based tactile sensing (VS-TS) system and unique CRC
polyp phantoms, we demonstrate that traditional metrics such as accuracy and
precision are not sufficient to encapsulate model performance for handling a
sensitive CRC polyp diagnosis. To this end, we develop a residual neural
network classifier and address its over-confident outputs for CRC polyps
classification via the post-processing method of temperature scaling. To
evaluate the proposed method, we introduce noise and blur to the obtained
textural images of the VS-TS and test the model's reliability for non-ideal
inputs through reliability diagrams and other statistical metrics.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：TABLET: Learning From Instructions For Tabular Data</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13188</p>
  <p><b>作者</b>：Dylan Slack,  Sameer Singh</p>
  <p><b>备注</b>：Please find the TABLET demo and code at this https URL</p>
  <p><b>关键词</b>：Acquiring high-quality data, training machine learning, Acquiring high-quality, medicine and finance, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Acquiring high-quality data is often a significant challenge in training
machine learning (ML) models for tabular prediction, particularly in
privacy-sensitive and costly domains like medicine and finance. Providing
natural language instructions to large language models (LLMs) offers an
alternative solution. However, it is unclear how effectively instructions
leverage the knowledge in LLMs for solving tabular prediction problems. To
address this gap, we introduce TABLET, a benchmark of 20 diverse tabular
datasets annotated with instructions that vary in their phrasing, granularity,
and technicality. Additionally, TABLET includes the instructions' logic and
structured modifications to the instructions. We find in-context instructions
increase zero-shot F1 performance for Flan-T5 11b by 44% on average and 13% for
ChatGPT on TABLET. Also, we explore the limitations of using LLMs for tabular
prediction in our benchmark by evaluating instruction faithfulness. We find
LLMs often ignore instructions and fail to predict specific instances
correctly, even with examples. Our analysis on TABLET shows that, while
instructions help LLM performance, learning from instructions for tabular data
requires new capabilities.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Sample-Specific Debiasing for Better Image-Text Models</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13181</p>
  <p><b>作者</b>：Peiqi Wang,  Yingcheng Liu,  Ching-Yun Ko,  William M. Wells,  Seth Berkowitz,  Steven Horng,  Polina Golland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial medical applications, facilitates crucial medical, data facilitates crucial, visual grounding, medical applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised representation learning on image-text data facilitates
crucial medical applications, such as image classification, visual grounding,
and cross-modal retrieval. One common approach involves contrasting
semantically similar (positive) and dissimilar (negative) pairs of data points.
Drawing negative samples uniformly from the training data set introduces false
negatives, i.e., samples that are treated as dissimilar but belong to the same
class. In healthcare data, the underlying class distribution is nonuniform,
implying that false negatives occur at a highly variable rate. To improve the
quality of learned representations, we develop a novel approach that corrects
for false negatives. Our method can be viewed as a variant of debiased
constrastive learning that uses estimated sample-specific class probabilities.
We provide theoretical analysis of the objective function and demonstrate the
proposed approach on both image and paired image-text data sets. Our
experiments demonstrate empirical advantages of sample-specific debiasing.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Robust Non-Linear Feedback Coding via Power-Constrained Deep Learning</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13178</p>
  <p><b>作者</b>：Junghoon Kim,  Taejoon Kim,  David Love,  Christopher Brinton</p>
  <p><b>备注</b>：To appear in International Conference on Machine Learning (ICML) 2023</p>
  <p><b>关键词</b>：long-standing open problem, open problem, long-standing open, codes, feedback-enabled communications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design of codes for feedback-enabled communications has been a
long-standing open problem. Recent research on non-linear, deep learning-based
coding schemes have demonstrated significant improvements in communication
reliability over linear codes, but are still vulnerable to the presence of
forward and feedback noise over the channel. In this paper, we develop a new
family of non-linear feedback codes that greatly enhance robustness to channel
noise. Our autoencoder-based architecture is designed to learn codes based on
consecutive blocks of bits, which obtains de-noising advantages over bit-by-bit
processing to help overcome the physical separation between the encoder and
decoder over a noisy channel. Moreover, we develop a power control layer at the
encoder to explicitly incorporate hardware constraints into the learning
optimization, and prove that the resulting average power constraint is
satisfied asymptotically. Numerical experiments demonstrate that our scheme
outperforms state-of-the-art feedback codes by wide margins over practical
forward and feedback noise regimes, and provide information-theoretic insights
on the behavior of our non-linear codes. Moreover, we observe that, in a long
blocklength regime, canonical error correction codes are still preferable to
feedback codes when the feedback noise becomes high.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Dynamic Datasets and Market Environments for Financial Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13174</p>
  <p><b>作者</b>：Xiao-Yang Liu,  Ziyi Xia,  Hongyang Yang,  Jiechao Gao,  Daochen Zha,  Ming Zhu,  Christina Dan Wang,  Zhaoran Wang,  Jian Guo</p>
  <p><b>备注</b>：49 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2211.03107</p>
  <p><b>关键词</b>：deep reinforcement learning, reinforcement learning due, financial reinforcement learning, reinforcement learning, challenging playground</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The financial market is a particularly challenging playground for deep
reinforcement learning due to its unique feature of dynamic datasets. Building
high-quality market environments for training financial reinforcement learning
(FinRL) agents is difficult due to major factors such as the low
signal-to-noise ratio of financial data, survivorship bias of historical data,
and model overfitting. In this paper, we present FinRL-Meta, a data-centric and
openly accessible library that processes dynamic datasets from real-world
markets into gym-style market environments and has been actively maintained by
the AI4Finance community. First, following a DataOps paradigm, we provide
hundreds of market environments through an automatic data curation pipeline.
Second, we provide homegrown examples and reproduce popular research papers as
stepping stones for users to design new trading strategies. We also deploy the
library on cloud platforms so that users can visualize their own results and
assess the relative performance via community-wise competitions. Third, we
provide dozens of Jupyter/Python demos organized into a curriculum and a
documentation website to serve the rapidly growing community. The open-source
codes for the data curation pipeline are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：SAFE: Machine Unlearning With Shard Graphs</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13169</p>
  <p><b>作者</b>：Yonatan Dukler,  Benjamin Bowman,  Alessandro Achille,  Aditya Golatkar,  Ashwin Swaminathan,  Stefano Soatto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：present Synergy Aware, Aware Forgetting Ensemble, Synergy Aware Forgetting, Synergy Aware, adapt large models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Synergy Aware Forgetting Ensemble (SAFE), a method to adapt large
models on a diverse collection of data while minimizing the expected cost to
remove the influence of training samples from the trained model. This process,
also known as selective forgetting or unlearning, is often conducted by
partitioning a dataset into shards, training fully independent models on each,
then ensembling the resulting models. Increasing the number of shards reduces
the expected cost to forget but at the same time it increases inference cost
and reduces the final accuracy of the model since synergistic information
between samples is lost during the independent model training. Rather than
treating each shard as independent, SAFE introduces the notion of a shard
graph, which allows incorporating limited information from other shards during
training, trading off a modest increase in expected forgetting cost with a
significant increase in accuracy, all while still attaining complete removal of
residual influence after forgetting. SAFE uses a lightweight system of adapters
which can be trained while reusing most of the computations. This allows SAFE
to be trained on shards an order-of-magnitude smaller than current
state-of-the-art methods (thus reducing the forgetting costs) while also
maintaining high accuracy, as we demonstrate empirically on fine-grained
computer vision datasets.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Towards Compute-Optimal Transfer Learning</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13164</p>
  <p><b>作者</b>：Massimo Caccia,  Alexandre Galashov,  Arthur Douillard,  Amal Rannen-Triki,  Dushyant Rao,  Michela Paganini,  Laurent Charlin,  Marc'Aurelio Ranzato,  Razvan Pascanu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong adaptability, large pretrained models, downstream tasks, undergoing a significant, significant shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of transfer learning is undergoing a significant shift with the
introduction of large pretrained models which have demonstrated strong
adaptability to a variety of downstream tasks. However, the high computational
and memory requirements to finetune or use these models can be a hindrance to
their widespread use. In this study, we present a solution to this issue by
proposing a simple yet effective way to trade computational efficiency for
asymptotic performance which we define as the performance a learning algorithm
achieves as compute tends to infinity. Specifically, we argue that zero-shot
structured pruning of pretrained models allows them to increase compute
efficiency with minimal reduction in performance. We evaluate our method on the
Nevis'22 continual learning benchmark that offers a diverse set of transfer
scenarios. Our results show that pruning convolutional filters of pretrained
models can lead to more than 20% performance improvement in low computational
regimes.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Autoencoder-based Radio Frequency Interference Mitigation For SMAP  Passive Radiometer</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13158</p>
  <p><b>作者</b>：Ali Owfi,  Fatemeh Afghah</p>
  <p><b>备注</b>：To be published in IEEE IGARSS 2023</p>
  <p><b>关键词</b>：1400-1427 MHz protected, space-borne radiometers operating, radio frequency interference, MHz protected frequency, face radio frequency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Passive space-borne radiometers operating in the 1400-1427 MHz protected
frequency band face radio frequency interference (RFI) from terrestrial
sources. With the growth of wireless devices and the appearance of new
technologies, the possibility of sharing this spectrum with other technologies
would introduce more RFI to these radiometers. This band could be an ideal
mid-band frequency for 5G and Beyond, as it offers high capacity and good
coverage. Current RFI detection and mitigation techniques at SMAP (Soil
Moisture Active Passive) depend on correctly detecting and discarding or
filtering the contaminated data leading to the loss of valuable information,
especially in severe RFI cases. In this paper, we propose an autoencoder-based
RFI mitigation method to remove the dominant RFI caused by potential coexistent
terrestrial users (i.e., 5G base station) from the received contaminated signal
at the passive receiver side, potentially preserving valuable information and
preventing the contaminated data from being discarded.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：LumiGAN: Unconditional Generation of Relightable 3D Human Faces</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13153</p>
  <p><b>作者</b>：Boyang Deng,  Yifan Wang,  Gordon Wetzstein</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：active research area, Unsupervised learning, research area, Generative Adversarial Network, active research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised learning of 3D human faces from unstructured 2D image data is an
active research area. While recent works have achieved an impressive level of
photorealism, they commonly lack control of lighting, which prevents the
generated assets from being deployed in novel environments. To this end, we
introduce LumiGAN, an unconditional Generative Adversarial Network (GAN) for 3D
human faces with a physically based lighting module that enables relighting
under novel illumination at inference time. Unlike prior work, LumiGAN can
create realistic shadow effects using an efficient visibility formulation that
is learned in a self-supervised manner. LumiGAN generates plausible physical
properties for relightable faces, including surface normals, diffuse albedo,
and specular tint without any ground truth data. In addition to relightability,
we demonstrate significantly improved geometry generation compared to
state-of-the-art non-relightable 3D GANs and notably better photorealism than
existing relightable GANs.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：T Cell Receptor Protein Sequences and Sparse Coding: A Novel Approach to  Cancer Classification</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13145</p>
  <p><b>作者</b>：Zahra Tayebi,  Sarwan Ali,  Prakash Chourasia,  Taslim Murad,  Murray Patterson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uncontrolled cell growth, TCR protein sequences, TCR sequences, complex disease characterized, TCR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cancer is a complex disease characterized by uncontrolled cell growth and
proliferation. T cell receptors (TCRs) are essential proteins for the adaptive
immune system, and their specific recognition of antigens plays a crucial role
in the immune response against diseases, including cancer. The diversity and
specificity of TCRs make them ideal for targeting cancer cells, and recent
advancements in sequencing technologies have enabled the comprehensive
profiling of TCR repertoires. This has led to the discovery of TCRs with potent
anti-cancer activity and the development of TCR-based immunotherapies. In this
study, we investigate the use of sparse coding for the multi-class
classification of TCR protein sequences with cancer categories as target
labels. Sparse coding is a popular technique in machine learning that enables
the representation of data with a set of informative features and can capture
complex relationships between amino acids and identify subtle patterns in the
sequence that might be missed by low-dimensional methods. We first compute the
k-mers from the TCR sequences and then apply sparse coding to capture the
essential features of the data. To improve the predictive performance of the
final embeddings, we integrate domain knowledge regarding different types of
cancer properties. We then train different machine learning (linear and
non-linear) classifiers on the embeddings of TCR sequences for the purpose of
supervised analysis. Our proposed embedding method on a benchmark dataset of
TCR sequences significantly outperforms the baselines in terms of predictive
performance, achieving an accuracy of 99.8\%. Our study highlights the
potential of sparse coding for the analysis of TCR protein sequences in cancer
research and other related fields.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Self-Supervised Temporal Analysis of Spatiotemporal Data</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13143</p>
  <p><b>作者</b>：Yi Cao,  Swetava Ganguli,  Vipul Pandey</p>
  <p><b>备注</b>：Accepted for oral presentation at the 43rd IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2023, Pasadena, California. 4 pages and 7 figures</p>
  <p><b>关键词</b>：exists a correlation, type of land, time series, time, series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There exists a correlation between geospatial activity temporal patterns and
type of land use. A novel self-supervised approach is proposed to stratify
landscape based on mobility activity time series. First, the time series signal
is transformed to the frequency domain and then compressed into task-agnostic
temporal embeddings by a contractive autoencoder, which preserves cyclic
temporal patterns observed in time series. The pixel-wise embeddings are
converted to image-like channels that can be used for task-based, multimodal
modeling of downstream geospatial tasks using deep semantic segmentation.
Experiments show that temporal embeddings are semantically meaningful
representations of time series data and are effective across different tasks
such as classifying residential area and commercial areas.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：ESimCSE Unsupervised Contrastive Learning Jointly with UDA  Semi-Supervised Learning for Large Label System Text Classification Mode</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13140</p>
  <p><b>作者</b>：Ruan Lu,  Zhou HangCheng,  Ran Meng,  Zhao Jin,  Qin JiaoYu,  Wei Feng,  Wang ChenZi</p>
  <p><b>备注</b>：This paper contains 14 pages,4 figures,4 tables</p>
  <p><b>关键词</b>：large tag systems, multiple tag systems, include multiple tag, uneven data distribution, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenges faced by text classification with large tag systems in natural
language processing tasks include multiple tag systems, uneven data
distribution, and high noise. To address these problems, the ESimCSE
unsupervised comparative learning and UDA semi-supervised comparative learning
models are combined through the use of joint training techniques in the
models.The ESimCSE model efficiently learns text vector representations using
unlabeled data to achieve better classification results, while UDA is trained
using unlabeled data through semi-supervised learning methods to improve the
prediction performance of the models and stability, and further improve the
generalization ability of the model. In addition, adversarial training
techniques FGM and PGD are used in the model training process to improve the
robustness and reliability of the model. The experimental results show that
there is an 8% and 10% accuracy improvement relative to Baseline on the public
dataset Ruesters as well as on the operational dataset, respectively, and a 15%
improvement in manual validation accuracy can be achieved on the operational
dataset, indicating that the method is effective.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：The Update Equivalence Framework for Decision-Time Planning</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13138</p>
  <p><b>作者</b>：Samuel Sokota,  Gabriele Farina,  David J. Wu,  Hengyuan Hu,  Kevin A. Wang,  J. Zico Kolter,  Noam Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy immediately prior, achieving superhuman performance, decision-time planning, process of revising, prior to execution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The process of revising (or constructing) a policy immediately prior to
execution -- known as decision-time planning -- is key to achieving superhuman
performance in perfect-information settings like chess and Go. A recent line of
work has extended decision-time planning to more general imperfect-information
settings, leading to superhuman performance in poker. However, these methods
requires considering subgames whose sizes grow quickly in the amount of
non-public information, making them unhelpful when the amount of non-public
information is large. Motivated by this issue, we introduce an alternative
framework for decision-time planning that is not based on subgames but rather
on the notion of update equivalence. In this framework, decision-time planning
algorithms simulate updates of synchronous learning algorithms. This framework
enables us to introduce a new family of principled decision-time planning
algorithms that do not rely on public information, opening the door to sound
and effective decision-time planning in settings with large amounts of
non-public information. In experiments, members of this family produce
comparable or superior results compared to state-of-the-art approaches in
Hanabi and improve performance in 3x3 Abrupt Dark Hex and Phantom Tic-Tac-Toe.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Directed Chain Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13131</p>
  <p><b>作者</b>：Ming Min,  Ruimeng Hu,  Tomoyuki Ichiba</p>
  <p><b>备注</b>：Publish at ICML 2023</p>
  <p><b>关键词</b>：oscillators natural frequencies, time series, Generating multimodal distributed, interspike interval distribution, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world data can be multimodal distributed, e.g., data describing the
opinion divergence in a community, the interspike interval distribution of
neurons, and the oscillators natural frequencies. Generating multimodal
distributed real-world data has become a challenge to existing generative
adversarial networks (GANs). For example, neural stochastic differential
equations (Neural SDEs), treated as infinite-dimensional GANs, have
demonstrated successful performance mainly in generating unimodal time series
data. In this paper, we propose a novel time series generator, named directed
chain GANs (DC-GANs), which inserts a time series dataset (called a
neighborhood process of the directed chain or input) into the drift and
diffusion coefficients of the directed chain SDEs with distributional
constraints. DC-GANs can generate new time series of the same distribution as
the neighborhood process, and the neighborhood process will provide the key
step in learning and generating multimodal distributed time series. The
proposed DC-GANs are examined on four datasets, including two stochastic models
from social sciences and computational neuroscience, and two real-world
datasets on stock prices and energy consumption. To our best knowledge, DC-GANs
are the first work that can generate multimodal time series data and
consistently outperforms state-of-the-art benchmarks with respect to measures
of distribution, data similarity, and predictive ability.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Application of Transformers for Nonlinear Channel Compensation in  Optical Systems</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13119</p>
  <p><b>作者</b>：Behnam Behinaein Hamgini,  Hossein Najafi,  Ali Bakhshali,  Zhuhong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：coherent long-haul transmission, long-haul transmission based, channel equalization method, coherent long-haul, long-haul transmission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new nonlinear channel equalization method for
the coherent long-haul transmission based on Transformers. We show that due to
their capability to attend directly to the memory across a sequence of symbols,
Transformers can be used effectively with a parallelized structure. We present
an implementation of encoder part of Transformer for nonlinear equalization and
analyze its performance over a wide range of different hyper-parameters. It is
shown that by processing blocks of symbols at each iteration and carefully
selecting subsets of the encoder's output to be processed together, an
efficient nonlinear compensation can be achieved. We also propose the use of a
physic-informed mask inspired by nonlinear perturbation theory for reducing the
computational complexity of Transformer nonlinear equalization.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Federated Deep Reinforcement Learning for THz-Beam Search with Limited  CSI</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13109</p>
  <p><b>作者</b>：Po-Chun Hsu,  Li-Hsiang Shen,  Chun-Hung Liu,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high data rate, severe propagation attenuation, attenuation significantly hinders, propagation attenuation significantly, next-generation wireless networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Terahertz (THz) communication with ultra-wide available spectrum is a
promising technique that can achieve the stringent requirement of high data
rate in the next-generation wireless networks, yet its severe propagation
attenuation significantly hinders its implementation in practice. Finding beam
directions for a large-scale antenna array to effectively overcome severe
propagation attenuation of THz signals is a pressing need. This paper proposes
a novel approach of federated deep reinforcement learning (FDRL) to swiftly
perform THz-beam search for multiple base stations (BSs) coordinated by an edge
server in a cellular network. All the BSs conduct deep deterministic policy
gradient (DDPG)-based DRL to obtain THz beamforming policy with limited channel
state information (CSI). They update their DDPG models with hidden information
in order to mitigate inter-cell interference. We demonstrate that the cell
network can achieve higher throughput as more THz CSI and hidden neurons of
DDPG are adopted. We also show that FDRL with partial model update is able to
nearly achieve the same performance of FDRL with full model update, which
indicates an effective means to reduce communication load between the edge
server and the BSs by partial model uploading. Moreover, the proposed FDRL
outperforms conventional non-learning-based and existing non-FDRL benchmark
optimization methods.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Time-Selective RNN for Device-Free Multi-Room Human Presence Detection  Using WiFi CSI</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13107</p>
  <p><b>作者</b>：Fang-Yu Chu,  Li-Hsiang Shen,  An-Hung Hsiao,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including home automation, including home, home automation, Human presence detection, crucial technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human presence detection is a crucial technology for various applications,
including home automation, security, and healthcare. While camera-based systems
have traditionally been used for this purpose, they raise privacy concerns. To
address this issue, recent research has explored the use of channel state
information (CSI) approaches that can be extracted from commercial WiFi access
points (APs) and provide detailed channel characteristics. In this thesis, we
propose a device-free human presence detection system for multi-room scenarios
using a time-selective conditional dual feature extract recurrent Network
(TCD-FERN). Our system is designed to capture significant time features with
the condition on current human features using a dynamic and static (DaS) data
preprocessing technique to extract moving and spatial features of people and
differentiate between line-of-sight (LoS) path blocking and non-blocking cases.
To mitigate the feature attenuation problem caused by room partitions, we
employ a voting scheme. We conduct evaluation and real-time experiments to
demonstrate that our proposed TCD-FERN system can achieve human presence
detection for multi-room scenarios using fewer commodity WiFi APs.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Attention-Enhanced Deep Learning for Device-Free Through-the-Wall  Presence Detection Using Indoor WiFi System</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13105</p>
  <p><b>作者</b>：Li-Hsiang Shen,  Kuan-I Lu,  An-Hung Hsiao,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human presence detection, human presence, presence detection, management and security, indoor environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate detection of human presence in indoor environments is important for
various applications, such as energy management and security. In this paper, we
propose a novel system for human presence detection using the channel state
information (CSI) of WiFi signals. Our system named attention-enhanced deep
learning for presence detection (ALPD) employs an attention mechanism to
automatically select informative subcarriers from the CSI data and a
bidirectional long short-term memory (LSTM) network to capture temporal
dependencies in CSI. Additionally, we utilize a static feature to improve the
accuracy of human presence detection in static states. We evaluate the proposed
ALPD system by deploying a pair of WiFi access points (APs) for collecting CSI
dataset, which is further compared with several benchmarks. The results
demonstrate that our ALPD system outperforms the benchmarks in terms of
accuracy, especially in the presence of interference. Moreover, bidirectional
transmission data is beneficial to training improving stability and accuracy,
as well as reducing the costs of data collection for training. Overall, our
proposed ALPD system shows promising results for human presence detection using
WiFi CSI signals.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：LSTM-based Load Forecasting Robustness Against Noise Injection Attack in  Microgrid</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13104</p>
  <p><b>作者</b>：Amirhossein Nazeri,  Pierluigi Pisu</p>
  <p><b>备注</b>：6 pages, 9 figures</p>
  <p><b>关键词</b>：LSTM neural network, LSTM model, electric load forecasting, LSTM, LSTM neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the robustness of an LSTM neural network
against noise injection attacks for electric load forecasting in an ideal
microgrid. The performance of the LSTM model is investigated under a black-box
Gaussian noise attack with different SNRs. It is assumed that attackers have
just access to the input data of the LSTM model. The results show that the
noise attack affects the performance of the LSTM model. The load prediction
means absolute error (MAE) is 0.047 MW for a healthy prediction, while this
value increases up to 0.097 MW for a Gaussian noise insertion with SNR= 6 dB.
To robustify the LSTM model against noise attack, a low-pass filter with
optimal cut-off frequency is applied at the model's input to remove the noise
attack. The filter performs better in case of noise with lower SNR and is less
promising for small noises.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Uncovering the Representation of Spiking Neural Networks Trained with  Surrogate Gradient</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13098</p>
  <p><b>作者</b>：Yuhang Li,  Youngeun Kim,  Hyoungseob Park,  Priyadarshini Panda</p>
  <p><b>备注</b>：Published in Transactions on Machine Learning Research (TMLR)</p>
  <p><b>关键词</b>：Spiking Neural Networks, next-generation neural networks, neural networks due, Artificial Neural Networks, Neural Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Networks (SNNs) are recognized as the candidate for the
next-generation neural networks due to their bio-plausibility and energy
efficiency. Recently, researchers have demonstrated that SNNs are able to
achieve nearly state-of-the-art performance in image recognition tasks using
surrogate gradient training. However, some essential questions exist pertaining
to SNNs that are little studied: Do SNNs trained with surrogate gradient learn
different representations from traditional Artificial Neural Networks (ANNs)?
Does the time dimension in SNNs provide unique representation power? In this
paper, we aim to answer these questions by conducting a representation
similarity analysis between SNNs and ANNs using Centered Kernel Alignment
(CKA). We start by analyzing the spatial dimension of the networks, including
both the width and the depth. Furthermore, our analysis of residual connections
shows that SNNs learn a periodic pattern, which rectifies the representations
in SNNs to be ANN-like. We additionally investigate the effect of the time
dimension on SNN representation, finding that deeper layers encourage more
dynamics along the time dimension. We also investigate the impact of input data
such as event-stream data and adversarial attacks. Our work uncovers a host of
new findings of representations in SNNs. We hope this work will inspire future
research to fully comprehend the representation power of SNNs. Code is released
at this https URL.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Model Extraction Attacks Against Reinforcement Learning Based  Controllers</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13090</p>
  <p><b>作者</b>：Momina Sajid,  Yanning Shen,  Yasser Shoukry</p>
  <p><b>备注</b>：8 pages, 8 figures</p>
  <p><b>关键词</b>：unknown DNN, unknown DNN controller, introduce the problem, problem of model-extraction, Deep Neural Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the problem of model-extraction attacks in cyber-physical
systems in which an attacker attempts to estimate (or extract) the feedback
controller of the system. Extracting (or estimating) the controller provides an
unmatched edge to attackers since it allows them to predict the future control
actions of the system and plan their attack accordingly. Hence, it is important
to understand the ability of the attackers to perform such an attack. In this
paper, we focus on the setting when a Deep Neural Network (DNN) controller is
trained using Reinforcement Learning (RL) algorithms and is used to control a
stochastic system. We play the role of the attacker that aims to estimate such
an unknown DNN controller, and we propose a two-phase algorithm. In the first
phase, also called the offline phase, the attacker uses side-channel
information about the RL-reward function and the system dynamics to identify a
set of candidate estimates of the unknown DNN. In the second phase, also called
the online phase, the attacker observes the behavior of the unknown DNN and
uses these observations to shortlist the set of final policy estimates. We
provide theoretical analysis of the error between the unknown DNN and the
estimated one. We also provide numerical results showing the effectiveness of
the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Objectives Matter: Understanding the Impact of Self-Supervised  Objectives on Vision Transformer Representations</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13089</p>
  <p><b>作者</b>：Shashank Shekhar,  Florian Bordes,  Pascal Vincent,  Ari Morcos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joint-embedding based learning, vision transformers, leading paradigms, paradigms for self-supervised, differ substantially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Joint-embedding based learning (e.g., SimCLR, MoCo, DINO) and
reconstruction-based learning (e.g., BEiT, SimMIM, MAE) are the two leading
paradigms for self-supervised learning of vision transformers, but they differ
substantially in their transfer performance. Here, we aim to explain these
differences by analyzing the impact of these objectives on the structure and
transferability of the learned representations. Our analysis reveals that
reconstruction-based learning features are significantly dissimilar to
joint-embedding based learning features and that models trained with similar
objectives learn similar features even across architectures. These differences
arise early in the network and are primarily driven by attention and
normalization layers. We find that joint-embedding features yield better linear
probe transfer for classification because the different objectives drive
different distributions of information and invariances in the learned
representation. These differences explain opposite trends in transfer
performance for downstream tasks that require spatial specificity in features.
Finally, we address how fine-tuning changes reconstructive representations to
enable better transfer, showing that fine-tuning re-organizes the information
to be more similar to pre-trained joint embedding models.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Organizational Governance of Emerging Technologies: AI Adoption in  Healthcare</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13081</p>
  <p><b>作者</b>：Jee Young Kim,  William Boag,  Freya Gulamali,  Alifia Hasan,  Henry David Jeffry Hogg,  Mark Lifson,  Deirdre Mulligan,  Manesh Patel,  Inioluwa Deborah Raji,  Ajai Sehgal,  Keo Shaw,  Danny Tobey,  Alexandra Valladares,  David Vidal,  Suresh Balu,  Mark Sendak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：public sector structures, Private and public, public sector, norms refine, adoption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Private and public sector structures and norms refine how emerging technology
is used in practice. In healthcare, despite a proliferation of AI adoption, the
organizational governance surrounding its use and integration is often poorly
understood. What the Health AI Partnership (HAIP) aims to do in this research
is to better define the requirements for adequate organizational governance of
AI systems in healthcare settings and support health system leaders to make
more informed decisions around AI adoption. To work towards this understanding,
we first identify how the standards for the AI adoption in healthcare may be
designed to be used easily and efficiently. Then, we map out the precise
decision points involved in the practical institutional adoption of AI
technology within specific health systems. Practically, we achieve this through
a multi-organizational collaboration with leaders from major health systems
across the United States and key informants from related fields. Working with
the consultancy this http URL, we were able to conduct usability-testing sessions
with healthcare and AI ethics professionals. Usability analysis revealed a
prototype structured around mock key decision points that align with how
organizational leaders approach technology adoption. Concurrently, we conducted
semi-structured interviews with 89 professionals in healthcare and other
relevant fields. Using a modified grounded theory approach, we were able to
identify 8 key decision points and comprehensive procedures throughout the AI
adoption lifecycle. This is one of the most detailed qualitative analyses to
date of the current governance structures and processes involved in AI adoption
by health systems in the United States. We hope these findings can inform
future efforts to build capabilities to promote the safe, effective, and
responsible adoption of emerging technologies in healthcare.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：iMixer: hierarchical Hopfield network implies an invertible, implicit  and iterative MLP-Mixer</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13061</p>
  <p><b>作者</b>：Toshihiro Ota,  Masato Taki</p>
  <p><b>备注</b>：12 pages, 3 figures</p>
  <p><b>关键词</b>：computer vision, vision has stimulated, stimulated the discovery, Hopfield networks, alternative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last few years, the success of Transformers in computer vision has
stimulated the discovery of many alternative models that compete with
Transformers, such as the MLP-Mixer. Despite their weak induced bias, these
models have achieved performance comparable to well-studied convolutional
neural networks. Recent studies on modern Hopfield networks suggest the
correspondence between certain energy-based associative memory models and
Transformers or MLP-Mixer, and shed some light on the theoretical background of
the Transformer-type architectures design. In this paper we generalize the
correspondence to the recently introduced hierarchical Hopfield network, and
find iMixer, a novel generalization of MLP-Mixer model. Unlike ordinary
feedforward neural networks, iMixer involves MLP layers that propagate forward
from the output side to the input side. We characterize the module as an
example of invertible, implicit, and iterative mixing module. We evaluate the
model performance with various datasets on image classification tasks, and find
that iMixer reasonably achieves the improvement compared to the baseline
vanilla MLP-Mixer. The results imply that the correspondence between the
Hopfield networks and the Mixer models serves as a principle for understanding
a broader class of Transformer-like architecture designs.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：GULP: Solar-Powered Smart Garbage Segregation Bins with SMS Notification  and Machine Learning Image Processing</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13040</p>
  <p><b>作者</b>：Jerome B. Sigongan,  Hamer P. Sinodlay,  Shahida Xerxy P. Cuizon,  Joanna S. Redondo,  Maricel G. Macapulay,  Charlene O. Bulahan-Undag,  Kenn Migan Vincent C. Gumonan</p>
  <p><b>备注</b>：19 pages, 6 figures, International Research Conference on Computer Engineering and Technology Education2023 (IRCCETE 2023)</p>
  <p><b>关键词</b>：segregates solid waste, study intends, intends to build, build a smartbin, smartbin that segregates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study intends to build a smartbin that segregates solid waste into its
respective bins. To make the waste management process more interesting for the
end-users; to notify the utility staff when the smart bin needs to be unloaded;
to encourage an environment-friendly smart bin by utilizing renewable solar
energy source. The researchers employed an Agile Development approach because
it enables teams to manage their workloads successfully and create the
highest-quality product while staying within their allocated budget. The six
fundamental phases are planning, design, development, test, release, and
feedback. The Overall quality testing result that was provided through the
ISO/IEC 25010 evaluation which concludes a positive outcome. The overall
average was 4.55, which is verbally interpreted as excellent. Additionally, the
application can also independently run with its solar energy source. Users were
able to enjoy the whole process of waste disposal through its interesting
mechanisms. Based on the findings, a compressor is recommended to compress the
trash when the trash level reaches its maximum point to create more rooms for
more garbage. An algorithm to determine multiple garbage at a time is also
recommended. Adding a solar tracker coupled with solar panel will help produce
more renewable energy for the smart bin.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Optimizing Deep Learning Models For Raspberry Pi</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13039</p>
  <p><b>作者</b>：Salem Ameen,  Kangaranmulle Siriwardana,  Theo Theodoridis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning models, including computer vision, natural language processing, Deep learning, learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have become increasingly popular for a wide range of
applications, including computer vision, natural language processing, and
speech recognition. However, these models typically require large amounts of
computational resources, making them challenging to run on low-power devices
such as the Raspberry Pi. One approach to addressing this challenge is to use
pruning techniques to reduce the size of the deep learning models. Pruning
involves removing unimportant weights and connections from the model, resulting
in a smaller and more efficient model. Pruning can be done during training or
after the model has been trained. Another approach is to optimize the deep
learning models specifically for the Raspberry Pi architecture. This can
include optimizing the model's architecture and parameters to take advantage of
the Raspberry Pi's hardware capabilities, such as its CPU and GPU.
Additionally, the model can be optimized for energy efficiency by minimizing
the amount of computation required. Pruning and optimizing deep learning models
for the Raspberry Pi can help overcome the computational and energy constraints
of low-power devices, making it possible to run deep learning models on a wider
range of devices. In the following sections, we will explore these approaches
in more detail and discuss their effectiveness for optimizing deep learning
models for the Raspberry Pi.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Diffusion Probabilistic Model Based Accurate and High-Degree-of-Freedom  Metasurface Inverse Design</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13038</p>
  <p><b>作者</b>：Zezhou Zhang,  Chuanchuan Yang,  Yifeng Qin,  Hao Feng,  Jiqiang Feng,  Hongbin Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：researchers' prior knowledge, designs rely heavily, searches using full-wave, full-wave simulations, resulting in time-consuming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional meta-atom designs rely heavily on researchers' prior knowledge
and trial-and-error searches using full-wave simulations, resulting in
time-consuming and inefficient processes. Inverse design methods based on
optimization algorithms, such as evolutionary algorithms, and topological
optimizations, have been introduced to design metamaterials. However, none of
these algorithms are general enough to fulfill multi-objective tasks. Recently,
deep learning methods represented by Generative Adversarial Networks (GANs)
have been applied to inverse design of metamaterials, which can directly
generate high-degree-of-freedom meta-atoms based on S-parameter requirements.
However, the adversarial training process of GANs makes the network unstable
and results in high modeling costs. This paper proposes a novel metamaterial
inverse design method based on the diffusion probability theory. By learning
the Markov process that transforms the original structure into a Gaussian
distribution, the proposed method can gradually remove the noise starting from
the Gaussian distribution and generate new high-degree-of-freedom meta-atoms
that meet S-parameter conditions, which avoids the model instability introduced
by the adversarial training process of GANs and ensures more accurate and
high-quality generation results. Experiments have proven that our method is
superior to representative methods of GANs in terms of model convergence speed,
generation accuracy, and quality.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：VeML: An End-to-End Machine Learning Lifecycle for Large-scale and  High-dimensional Data</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13037</p>
  <p><b>作者</b>：Van-Duc Le</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, iterative processes, deploying the trained, data, lifecycle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An end-to-end machine learning (ML) lifecycle consists of many iterative
processes, from data preparation and ML model design to model training and then
deploying the trained model for inference. When building an end-to-end
lifecycle for an ML problem, many ML pipelines must be designed and executed
that produce a huge number of lifecycle versions. Therefore, this paper
introduces VeML, a Version management system dedicated to end-to-end ML
Lifecycle. Our system tackles several crucial problems that other systems have
not solved. First, we address the high cost of building an ML lifecycle,
especially for large-scale and high-dimensional dataset. We solve this problem
by proposing to transfer the lifecycle of similar datasets managed in our
system to the new training data. We design an algorithm based on the core set
to compute similarity for large-scale, high-dimensional data efficiently.
Another critical issue is the model accuracy degradation by the difference
between training data and testing data during the ML lifetime, which leads to
lifecycle rebuild. Our system helps to detect this mismatch without getting
labeled data from testing data and rebuild the ML lifecycle for a new data
version. To demonstrate our contributions, we conduct experiments on
real-world, large-scale datasets of driving images and spatiotemporal sensor
data and show promising results.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：SmartChoices: Augmenting Software with Learned Implementations</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13033</p>
  <p><b>作者</b>：Daniel Golovin,  Gabor Bartok,  Eric Chen,  Emily Donahue,  Tzu-Kuo Huang,  Efi Kokiopoulou,  Ruoyan Qin,  Nikhil Sarda,  Justin Sybrandt,  Vincent Tjeng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：golden age, software, machine learning, living, golden</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are living in a golden age of machine learning. Powerful models are being
trained to perform many tasks far better than is possible using traditional
software engineering approaches alone. However, developing and deploying those
models in existing software systems remains difficult. In this paper we present
SmartChoices, a novel approach to incorporating machine learning into mature
software stacks easily, safely, and effectively. We explain the overall design
philosophy and present case studies using SmartChoices within large scale
industrial systems.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：A Unified Active Learning Framework for Annotating Graph Data with  Application to Software Source Code Performance Prediction</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13032</p>
  <p><b>作者</b>：Peter Samoaa,  Linus Aronsson,  Antonio Longa,  Philipp Leitner,  Morteza Haghir Chehreghani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including performance engineering, data analytics applications, analytics applications, large number, source code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most machine learning and data analytics applications, including performance
engineering in software systems, require a large number of annotations and
labelled data, which might not be available in advance. Acquiring annotations
often requires significant time, effort, and computational resources, making it
challenging. We develop a unified active learning framework, specializing in
software performance prediction, to address this task. We begin by parsing the
source code to an Abstract Syntax Tree (AST) and augmenting it with data and
control flow edges. Then, we convert the tree representation of the source code
to a Flow Augmented-AST graph (FA-AST) representation. Based on the graph
representation, we construct various graph embeddings (unsupervised and
supervised) into a latent space. Given such an embedding, the framework becomes
task agnostic since active learning can be performed using any regression
method and query strategy suited for regression. Within this framework, we
investigate the impact of using different levels of information for active and
passive learning, e.g., partially available labels and unlabeled test data. Our
approach aims to improve the investment in AI models for different software
performance predictions (execution time) based on the structure of the source
code. Our real-world experiments reveal that respectable performance can be
achieved by querying labels for only a small subset of all the data.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Hopfield model with planted patterns: a teacher-student self-supervised  learning model</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13710</p>
  <p><b>作者</b>：Francesco Alemanno,  Luca Camanzi,  Gianluca Manzan,  Daniele Tantari</p>
  <p><b>备注</b>：26 pages, 5 figures</p>
  <p><b>关键词</b>：modern artificial intelligence, machine learning paradigm, artificial intelligence systems, Hopfield networks, modern artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Hopfield networks are known as paradigmatic models for memory storage
and retrieval, modern artificial intelligence systems mainly stand on the
machine learning paradigm. We show that it is possible to formulate a
teacher-student self-supervised learning problem with Boltzmann machines in
terms of a suitable generalization of the Hopfield model with structured
patterns, where the spin variables are the machine weights and patterns
correspond to the training set's examples. We analyze the learning performance
by studying the phase diagram in terms of the training set size, the dataset
noise and the inference temperature (i.e. the weight regularization). With a
small but informative dataset the machine can learn by memorization. With a
noisy dataset, an extensive number of examples above a critical threshold is
needed. In this regime the memory storage limits of the system becomes an
opportunity for the occurrence of a learning regime in which the system can
generalize.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Data-driven Piecewise Affine Decision Rules for Stochastic Programming  with Covariate Information</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13646</p>
  <p><b>作者</b>：Yiyang Zhang,  Junyi Liu,  Xiaobo Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：affine decision rule, empirical risk minimization, piecewise affine decision, nonconvex piecewise affine, decision rule</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Focusing on stochastic programming (SP) with covariate information, this
paper proposes an empirical risk minimization (ERM) method embedded within a
nonconvex piecewise affine decision rule (PADR), which aims to learn the direct
mapping from features to optimal decisions. We establish the nonasymptotic
consistency result of our PADR-based ERM model for unconstrained problems and
asymptotic consistency result for constrained ones. To solve the nonconvex and
nondifferentiable ERM problem, we develop an enhanced stochastic
majorization-minimization algorithm and establish the asymptotic convergence to
(composite strong) directional stationarity along with complexity analysis. We
show that the proposed PADR-based ERM method applies to a broad class of
nonconvex SP problems with theoretical consistency guarantees and computational
tractability. Our numerical study demonstrates the superior performance of
PADR-based ERM methods compared to state-of-the-art approaches under various
settings, with significantly lower costs, less computation time, and robustness
to feature dimensions and nonlinearity of the underlying dependency.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian  rewards</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13593</p>
  <p><b>作者</b>：Amaury Gouverneur,  Borja Rodríguez-Gálvez,  Tobias J. Oechtering,  Mikael Skoglund</p>
  <p><b>备注</b>：8 pages: 5 of the main text, 1 of references, and 2 of appendices. Accepted to ISIT 2023</p>
  <p><b>关键词</b>：Thompson Sampling algorithm, Thompson Sampling, Thompson Sampling expected, Sampling algorithm, study the performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we study the performance of the Thompson Sampling algorithm for
Contextual Bandit problems based on the framework introduced by Neu et al. and
their concept of lifted information ratio. First, we prove a comprehensive
bound on the Thompson Sampling expected cumulative regret that depends on the
mutual information of the environment parameters and the history. Then, we
introduce new bounds on the lifted information ratio that hold for sub-Gaussian
rewards, thus generalizing the results from Neu et al. which analysis requires
binary rewards. Finally, we provide explicit regret bounds for the special
cases of unstructured bounded contextual bandits, structured bounded contextual
bandits with Laplace likelihood, structured Bernoulli bandits, and bounded
linear contextual bandits.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Energy-Based Sliced Wasserstein Distance</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13586</p>
  <p><b>作者</b>：Khai Nguyen,  Nhat Ho</p>
  <p><b>备注</b>：36 pages, 7 figures, 6 tables</p>
  <p><b>关键词</b>：computationally efficient metric, widely recognized, statistically effective, effective and computationally, computationally efficient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The sliced Wasserstein (SW) distance has been widely recognized as a
statistically effective and computationally efficient metric between two
probability measures. A key component of the SW distance is the slicing
distribution. There are two existing approaches for choosing this distribution.
The first approach is using a fixed prior distribution. The second approach is
optimizing for the best distribution which belongs to a parametric family of
distributions and can maximize the expected distance. However, both approaches
have their limitations. A fixed prior distribution is non-informative in terms
of highlighting projecting directions that can discriminate two general
probability measures. Doing optimization for the best distribution is often
expensive and unstable. Moreover, designing the parametric family of the
candidate distribution could be easily misspecified. To address the issues, we
propose to design the slicing distribution as an energy-based distribution that
is parameter-free and has the density proportional to an energy function of the
projected one-dimensional Wasserstein distance. We then derive a novel sliced
Wasserstein metric, energy-based sliced Waserstein (EBSW) distance, and
investigate its topological, statistical, and computational properties via
importance sampling, sampling importance resampling, and Markov Chain methods.
Finally, we conduct experiments on point-cloud gradient flow, color transfer,
and point-cloud reconstruction to show the favorable performance of the EBSW.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A mean-field games laboratory for generative modeling</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13534</p>
  <p><b>作者</b>：Benjamin J. Zhang,  Markos A. Katsoulakis</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：generative models, diffusion-based generative models, designing generative models, generative, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we demonstrate the versatility of mean-field games (MFGs) as a
mathematical framework for explaining, enhancing, and designing generative
models. There is a pervasive sense in the generative modeling community that
the various flow and diffusion-based generative models have some foundational
common structure and interrelationships. We establish connections between MFGs
and major classes of flow and diffusion-based generative models including
continuous-time normalizing flows, score-based models, and Wasserstein gradient
flows. We derive these three classes of generative models through different
choices of particle dynamics and cost functions. Furthermore, we study the
mathematical structure and properties of each generative model by studying
their associated MFG's optimality condition, which is a set of coupled
nonlinear partial differential equations (PDEs). The theory of MFGs, therefore,
enables the study of generative models through the theory of nonlinear PDEs.
Through this perspective, we investigate the well-posedness and structure of
normalizing flows, unravel the mathematical structure of score-based generative
modeling, and derive a mean-field game formulation of the Wasserstein gradient
flow. From an algorithmic perspective, the optimality conditions of MFGs also
allow us to introduce HJB regularizers for enhanced training a broader class of
generative models. We present this framework as an MFG laboratory which serves
as a platform for revealing new avenues of experimentation and invention of
generative models. This laboratory will give rise to a multitude of well-posed
generative modeling formulations, providing a consistent theoretical framework
upon which numerical and algorithmic tools may be developed.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Mixing Data Augmentation with Preserving Foreground Regions in Medical  Image Segmentation</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13490</p>
  <p><b>作者</b>：Xiaoqing Liu,  Kenji Ono,  Ryoma Bise</p>
  <p><b>备注</b>：Accepted by IEEE ISBI'23</p>
  <p><b>关键词</b>：support doctors' diagnoses, significantly support doctors', medical image segmentation, medical image, image segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of medical image segmentation using deep learning can
significantly support doctors' diagnoses. Deep learning needs large amounts of
data for training, which also requires data augmentation to extend diversity
for preventing overfitting. However, the existing methods for data augmentation
of medical image segmentation are mainly based on models which need to update
parameters and cost extra computing resources. We proposed data augmentation
methods designed to train a high accuracy deep learning network for medical
image segmentation. The proposed data augmentation approaches are called
KeepMask and KeepMix, which can create medical images by better identifying the
boundary of the organ with no more parameters. Our methods achieved better
performance and obtained more precise boundaries for medical image segmentation
on datasets. The dice coefficient of our methods achieved 94.15% (3.04% higher
than baseline) on CHAOS and 74.70% (5.25% higher than baseline) on MSD spleen
with Unet.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Unsupervised classification of fully kinetic simulations of plasmoid  instability using Self-Organizing Maps (SOMs)</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13469</p>
  <p><b>作者</b>：Sophia Köhne,  Elisabetta Boella,  Maria Elena Innocenti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine Learning, rooted in Machine, physics processes encourages, physical discovery, growing amount</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The growing amount of data produced by simulations and observations of space
physics processes encourages the use of methods rooted in Machine Learning for
data analysis and physical discovery. We apply a clustering method based on
Self-Organizing Maps (SOM) to fully kinetic simulations of plasmoid
instability, with the aim of assessing its suitability as a reliable analysis
tool for both simulated and observed data. We obtain clusters that map well, a
posteriori, to our knowledge of the process: the clusters clearly identify the
inflow region, the inner plasmoid region, the separatrices, and regions
associated with plasmoid merging. SOM-specific analysis tools, such as feature
maps and Unified Distance Matrix, provide one with valuable insights into both
the physics at work and specific spatial regions of interest. The method
appears as a promising option for the analysis of data, both from simulations
and from observations, and could also potentially be used to trigger the switch
to different simulation models or resolution in coupled codes for space
simulations.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Polynomial-Time Solvers for the Discrete $\infty$-Optimal Transport  Problems</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13467</p>
  <p><b>作者</b>：Meyer Scetbon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose polynomial-time algorithms, polynomial-time algorithms solving, solving the Monge, propose polynomial-time, polynomial-time algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this note, we propose polynomial-time algorithms solving the Monge and
Kantorovich formulations of the $\infty$-optimal transport problem in the
discrete and finite setting. It is the first time, to the best of our
knowledge, that efficient numerical methods for these problems have been
proposed.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：UNADON: Transformer-based model to predict genome-wide chromosome  spatial position</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13230</p>
  <p><b>作者</b>：Muyu Yang,  Jian Ma</p>
  <p><b>备注</b>：To appear in ISMB 2023</p>
  <p><b>关键词</b>：spatial positioning, chromosomes relative, relative to functional, intertwined with genome, chromatin spatial positioning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The spatial positioning of chromosomes relative to functional nuclear bodies
is intertwined with genome functions such as transcription. However, the
sequence patterns and epigenomic features that collectively influence chromatin
spatial positioning in a genome-wide manner are not well understood. Here, we
develop a new transformer-based deep learning model called UNADON, which
predicts the genome-wide cytological distance to a specific type of nuclear
body, as measured by TSA-seq, using both sequence features and epigenomic
signals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116)
show high accuracy in predicting chromatin spatial positioning to nuclear
bodies when trained on a single cell line. UNADON also performed well in an
unseen cell type. Importantly, we reveal potential sequence and epigenomic
factors that affect large-scale chromatin compartmentalization to nuclear
bodies. Together, UNADON provides new insights into the principles between
sequence features and large-scale chromatin spatial localization, which has
important implications for understanding nuclear structure and function.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Kernel Methods are Competitive for Operator Learning</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13202</p>
  <p><b>作者</b>：Pau Batlle,  Matthieu Darcy,  Bamdad Hosseini,  Houman Owhadi</p>
  <p><b>备注</b>：35 pages, 10 figures</p>
  <p><b>关键词</b>：mathcal, Deep Operator Net, Fourier Neural Operator, mathbb, general kernel-based framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a general kernel-based framework for learning operators between
Banach spaces along with a priori error analysis and comprehensive numerical
comparisons with popular neural net (NN) approaches such as Deep Operator Net
(DeepONet) [Lu et al.] and Fourier Neural Operator (FNO) [Li et al.]. We
consider the setting where the input/output spaces of target operator
$\mathcal{G}^\dagger\,:\, \mathcal{U}\to \mathcal{V}$ are reproducing kernel
Hilbert spaces (RKHS), the data comes in the form of partial observations
$\phi(u_i), \varphi(v_i)$ of input/output functions
$v_i=\mathcal{G}^\dagger(u_i)$ ($i=1,\ldots,N$), and the measurement operators
$\phi\,:\, \mathcal{U}\to \mathbb{R}^n$ and $\varphi\,:\, \mathcal{V} \to
\mathbb{R}^m$ are linear. Writing $\psi\,:\, \mathbb{R}^n \to \mathcal{U}$ and
$\chi\,:\, \mathbb{R}^m \to \mathcal{V}$ for the optimal recovery maps
associated with $\phi$ and $\varphi$, we approximate $\mathcal{G}^\dagger$ with
$\bar{\mathcal{G}}=\chi \circ \bar{f} \circ \phi$ where $\bar{f}$ is an optimal
recovery approximation of $f^\dagger:=\varphi \circ \mathcal{G}^\dagger \circ
\psi\,:\,\mathbb{R}^n \to \mathbb{R}^m$. We show that, even when using vanilla
kernels (e.g., linear or Matérn), our approach is competitive in terms of
cost-accuracy trade-off and either matches or beats the performance of NN
methods on a majority of benchmarks. Additionally, our framework offers several
advantages inherited from kernel methods: simplicity, interpretability,
convergence guarantees, a priori error estimates, and Bayesian uncertainty
quantification. As such, it can serve as a natural benchmark for operator
learning.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Quantum Machine Learning Approach for the Prediction of Surface  Roughness in Additive Manufactured Specimens</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13142</p>
  <p><b>作者</b>：Akshansh Mishra,  Vijaykumar S. Jatti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial factor influencing, Surface roughness, predicting surface roughness, additive manufactured components, crucial factor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surface roughness is a crucial factor influencing the performance and
functionality of additive manufactured components. Accurate prediction of
surface roughness is vital for optimizing manufacturing processes and ensuring
the quality of the final product. Quantum computing has recently gained
attention as a potential solution for tackling complex problems and creating
precise predictive models. In this research paper, we conduct an in-depth
comparison of three quantum algorithms i.e. the Quantum Neural Network (QNN),
Quantum Forest (Q-Forest), and Variational Quantum Classifier (VQC) adapted for
regression for predicting surface roughness in additive manufactured specimens
for the first time. We assess the algorithms performance using Mean Squared
Error (MSE), Mean Absolute Error (MAE), and Explained Variance Score (EVS) as
evaluation metrics. Our findings show that the Q-Forest algorithm surpasses the
other algorithms, achieving an MSE of 56.905, MAE of 7.479, and an EVS of
0.2957. In contrast, the QNN algorithm displays a higher MSE of 60.840 and MAE
of 7.671, coupled with a negative EVS of -0.444, indicating that it may not be
appropriate for predicting surface roughness in this application. The VQC
adapted for regression exhibits an MSE of 59.121, MAE of 7.597, and an EVS of
-0.0106, suggesting its performance is also inferior to the Q-Forest algorithm.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：MEDNC: Multi-ensemble deep neural network for COVID-19 diagnosis</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13135</p>
  <p><b>作者</b>：Lin Yang,  Shuihua Wang,  Yudong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Coronavirus disease, medical facilities, MEDNC, limited medical resources, medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Coronavirus disease 2019 (COVID-19) has spread all over the world for three
years, but medical facilities in many areas still aren't adequate. There is a
need for rapid COVID-19 diagnosis to identify high-risk patients and maximize
the use of limited medical resources. Motivated by this fact, we proposed the
deep learning framework MEDNC for automatic prediction and diagnosis of
COVID-19 using computed tomography (CT) images. Our model was trained using two
publicly available sets of COVID-19 data. And it was built with the inspiration
of transfer learning. Results indicated that the MEDNC greatly enhanced the
detection of COVID-19 infections, reaching an accuracy of 98.79% and 99.82%
respectively. We tested MEDNC on a brain tumor and a blood cell dataset to show
that our model applies to a wide range of problems. The outcomes demonstrated
that our proposed models attained an accuracy of 99.39% and 99.28%,
respectively. This COVID-19 recognition tool could help optimize healthcare
resources and reduce clinicians' workload when screening for the virus.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Precision Spectroscopy of Fast, Hot Exotic Isotopes Using Machine  Learning Assisted Event-by-Event Doppler Correction</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13120</p>
  <p><b>作者</b>：Silviu-Marian Udrescu,  Diego Alejandro Torres,  Ronald Fernando Garcia Ruiz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-precision laser spectroscopy, fast exotic isotopes, laser spectroscopy studies, performing sensitive, high-precision laser</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an experimental scheme for performing sensitive, high-precision
laser spectroscopy studies on fast exotic isotopes. By inducing a step-wise
resonant ionization of the atoms travelling inside an electric field and
subsequently detecting the ion and the corresponding electron, time- and
position-sensitive measurements of the resulting particles can be performed.
Using a Mixture Density Network (MDN), we can leverage this information to
predict the initial energy of individual atoms and thus apply a Doppler
correction of the observed transition frequencies on an event-by-event basis.
We conduct numerical simulations of the proposed experimental scheme and show
that kHz-level uncertainties can be achieved for ion beams produced at extreme
temperatures ($> 10^8$ K), with energy spreads as large as $10$ keV and
non-uniform velocity distributions. The ability to perform in-flight
spectroscopy, directly on highly energetic beams, offers unique opportunities
to studying short-lived isotopes with lifetimes in the millisecond range and
below, produced in low quantities, in hot and highly contaminated environments,
without the need for cooling techniques. Such species are of marked interest
for nuclear structure, astrophysics, and new physics searches.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Making Video Quality Assessment Models Robust to Bit Depth</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13092</p>
  <p><b>作者</b>：Joshua P. Ebenezer,  Zaixi Shang,  Yongjun Wu,  Hai Wei,  Sriram Sethuraman,  Alan C. Bovik</p>
  <p><b>备注</b>：Published in IEEE Signal Processing Letters 2023</p>
  <p><b>关键词</b>：Video Quality Assessment, Quality Assessment, designed for Standard, Video Quality, call HDRMAX features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel feature set, which we call HDRMAX features, that when
included into Video Quality Assessment (VQA) algorithms designed for Standard
Dynamic Range (SDR) videos, sensitizes them to distortions of High Dynamic
Range (HDR) videos that are inadequately accounted for by these algorithms.
While these features are not specific to HDR, and also augment the equality
prediction performances of VQA models on SDR content, they are especially
effective on HDR. HDRMAX features modify powerful priors drawn from Natural
Video Statistics (NVS) models by enhancing their measurability where they
visually impact the brightest and darkest local portions of videos, thereby
capturing distortions that are often poorly accounted for by existing VQA
models. As a demonstration of the efficacy of our approach, we show that, while
current state-of-the-art VQA models perform poorly on 10-bit HDR databases,
their performances are greatly improved by the inclusion of HDRMAX features
when tested on HDR and 10-bit distorted videos.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：A Control-Centric Benchmark for Video Prediction</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13723</p>
  <p><b>作者</b>：Stephen Tian,  Chelsea Finn,  Jiajun Wu</p>
  <p><b>备注</b>：ICLR 2023</p>
  <p><b>关键词</b>：world dynamics, promising source, source of knowledge, knowledge for embodied, embodied agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video is a promising source of knowledge for embodied agents to learn models
of the world's dynamics. Large deep networks have become increasingly effective
at modeling complex video data in a self-supervised manner, as evaluated by
metrics based on human perceptual similarity or pixel-wise comparison. However,
it remains unclear whether current metrics are accurate indicators of
performance on downstream tasks. We find empirically that for planning robotic
manipulation, existing metrics can be unreliable at predicting execution
success. To address this, we propose a benchmark for action-conditioned video
prediction in the form of a control benchmark that evaluates a given model for
simulated robotic manipulation through sampling-based planning. Our benchmark,
Video Prediction for Visual Planning ($VP^2$), includes simulated environments
with 11 task categories and 310 task instance definitions, a full planning
implementation, and training datasets containing scripted interaction
trajectories for each task category. A central design goal of our benchmark is
to expose a simple interface -- a single forward prediction call -- so it is
straightforward to evaluate almost any action-conditioned video prediction
model. We then leverage our benchmark to study the effects of scaling model
size, quantity of training data, and model ensembling by analyzing five
highly-performant video prediction models, finding that while scale can improve
perceptual quality when modeling visually diverse settings, other attributes
such as uncertainty awareness can also aid planning performance.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Evaluation of GPT-3.5 and GPT-4 for supporting real-world information  needs in healthcare delivery</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13714</p>
  <p><b>作者</b>：Debadutta Dash,  Rahul Thapa,  Juan M. Banda,  Akshay Swaminathan,  Morgan Cheatham,  Mehr Kashyap,  Nikesh Kotecha,  Jonathan H. Chen,  Saurabh Gombar,  Lance Downing,  Rachel Pedreira,  Ethan Goh,  Angel Arnaout,  Garret Kenn Morris,  Honor Magon,  Matthew P Lungren,  Eric Horvitz,  Nigam H. Shah</p>
  <p><b>备注</b>：27 pages including supplemental information</p>
  <p><b>关键词</b>：informatics consultation service, large language models, informatics consultation, current explorations, growing interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite growing interest in using large language models (LLMs) in healthcare,
current explorations do not assess the real-world utility and safety of LLMs in
clinical settings. Our objective was to determine whether two LLMs can serve
information needs submitted by physicians as questions to an informatics
consultation service in a safe and concordant manner. Sixty six questions from
an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple
prompts. 12 physicians assessed the LLM responses' possibility of patient harm
and concordance with existing reports from an informatics consultation service.
Physician assessments were summarized based on majority vote. For no questions
did a majority of physicians deem either LLM response as harmful. For GPT-3.5,
responses to 8 questions were concordant with the informatics consult report,
20 discordant, and 9 were unable to be assessed. There were 29 responses with
no majority on "Agree", "Disagree", and "Unable to assess". For GPT-4,
responses to 13 questions were concordant, 15 discordant, and 3 were unable to
be assessed. There were 35 responses with no majority. Responses from both LLMs
were largely devoid of overt harm, but less than 20% of the responses agreed
with an answer from an informatics consultation service, responses contained
hallucinated references, and physicians were divided on what constitutes harm.
These results suggest that while general purpose LLMs are able to provide safe
and credible responses, they often do not meet the specific information need of
a given question. A definitive evaluation of the usefulness of LLMs in
healthcare settings will likely require additional research on prompt
engineering, calibration, and custom-tailoring of general purpose models.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13712</p>
  <p><b>作者</b>：Jingfeng Yang,  Hongye Jin,  Ruixiang Tang,  Xiaotian Han,  Qizhang Feng,  Haoming Jiang,  Bing Yin,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, natural language, natural language processing, downstream natural language, Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：HeySQuAD: A Spoken Question Answering Dataset</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13689</p>
  <p><b>作者</b>：Yijing Wu,  SaiKrishna Rallabandi,  Ravisutha Srinivasamurthy,  Parag Pravin Dakle,  Alolika Gon,  Preethi Raghavan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including digital assistants, cases including digital, systems that serve, digital assistants, community-shared SQA dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-spoken questions are critical to evaluating the performance of spoken
question answering (SQA) systems that serve several real-world use cases
including digital assistants. We present a new large-scale community-shared SQA
dataset, HeySQuAD that consists of 76k human-spoken questions and 97k
machine-generated questions and corresponding textual answers derived from the
SQuAD QA dataset. The goal of HeySQuAD is to measure the ability of machines to
understand noisy spoken questions and answer the questions accurately. To this
end, we run extensive benchmarks on the human-spoken and machine-generated
questions to quantify the differences in noise from both sources and its
subsequent impact on the model and answering accuracy. Importantly, for the
task of SQA, where we want to answer human-spoken questions, we observe that
training using the transcribed human-spoken and original SQuAD questions leads
to significant improvements (12.51%) over training using only the original
SQuAD textual questions.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Unlocking the Potential of Collaborative AI -- On the Socio-technical  Challenges of Federated Machine Learning</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13688</p>
  <p><b>作者</b>：Tobias Müller,  Milena Zahn,  Florian Matthes</p>
  <p><b>备注</b>：Accepted for Publication at the 31st European Conference on Information Systems (ECIS 2023)</p>
  <p><b>关键词</b>：Federated Machine Learning, Machine Learning, Federated Machine, systems roots, emergence of big</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The disruptive potential of AI systems roots in the emergence of big data.
Yet, a significant portion is scattered and locked in data silos, leaving its
potential untapped. Federated Machine Learning is a novel AI paradigm enabling
the creation of AI models from decentralized, potentially siloed data. Hence,
Federated Machine Learning could technically open data silos and therefore
unlock economic potential. However, this requires collaboration between
multiple parties owning data silos. Setting up collaborative business models is
complex and often a reason for failure. Current literature lacks guidelines on
which aspects must be considered to successfully realize collaborative AI
projects. This research investigates the challenges of prevailing collaborative
business models and distinct aspects of Federated Machine Learning. Through a
systematic literature review, focus group, and expert interviews, we provide a
systemized collection of socio-technical challenges and an extended Business
Model Canvas for the initial viability assessment of collaborative AI projects.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Using Implicit Feedback to Improve Question Generation</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13664</p>
  <p><b>作者</b>：Hugo Rodrigues,  Eric Nyberg,  Luisa Coheur</p>
  <p><b>备注</b>：27 pages, 8 figures</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Question Generation, automatically generating questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question Generation (QG) is a task of Natural Language Processing (NLP) that
aims at automatically generating questions from text. Many applications can
benefit from automatically generated questions, but often it is necessary to
curate those questions, either by selecting or editing them. This task is
informative on its own, but it is typically done post-generation, and, thus,
the effort is wasted. In addition, most existing systems cannot incorporate
this feedback back into them easily. In this work, we present a system, GEN,
that learns from such (implicit) feedback. Following a pattern-based approach,
it takes as input a small set of sentence/question pairs and creates patterns
which are then applied to new unseen sentences. Each generated question, after
being corrected by the user, is used as a new seed in the next iteration, so
more patterns are created each time. We also take advantage of the corrections
made by the user to score the patterns and therefore rank the generated
questions. Results show that GEN is able to improve by learning from both
levels of implicit feedback when compared to the version with no learning,
considering the top 5, 10, and 20 questions. Improvements go up from 10%,
depending on the metric and strategy used.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13653</p>
  <p><b>作者</b>：Tuomas Haarnoja,  Ben Moran,  Guy Lever,  Sandy H. Huang,  Dhruva Tirumala,  Markus Wulfmeier,  Jan Humplik,  Saran Tunyasuvunakool,  Noah Y. Siegel,  Roland Hafner,  Michael Bloesch,  Kristian Hartikainen,  Arunkumar Byravan,  Leonard Hasenclever,  Yuval Tassa,  Fereshteh Sadeghi,  Nathan Batchelor,  Federico Casarini,  Stefano Saliceti,  Charles Game,  Neil Sreendra,  Kushal Patel,  Marlon Gwira,  Andrea Huber,  Nicole Hurley,  Francesco Nori,  Raia Hadsell,  Nicolas Heess</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, complex behavioral strategies, Deep Reinforcement, miniature humanoid robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate whether Deep Reinforcement Learning (Deep RL) is able to
synthesize sophisticated and safe movement skills for a low-cost, miniature
humanoid robot that can be composed into complex behavioral strategies in
dynamic environments. We used Deep RL to train a humanoid robot with 20
actuated joints to play a simplified one-versus-one (1v1) soccer game. We first
trained individual skills in isolation and then composed those skills
end-to-end in a self-play setting. The resulting policy exhibits robust and
dynamic movement skills such as rapid fall recovery, walking, turning, kicking
and more; and transitions between them in a smooth, stable, and efficient
manner - well beyond what is intuitively expected from the robot. The agents
also developed a basic strategic understanding of the game, and learned, for
instance, to anticipate ball movements and to block opponent shots. The full
range of behaviors emerged from a small set of simple rewards. Our agents were
trained in simulation and transferred to real robots zero-shot. We found that a
combination of sufficiently high-frequency control, targeted dynamics
randomization, and perturbations during training in simulation enabled
good-quality transfer, despite significant unmodeled effects and variations
across robot instances. Although the robots are inherently fragile, minor
hardware modifications together with basic regularization of the behavior
during training led the robots to learn safe and effective movements while
still performing in a dynamic and agile way. Indeed, even though the agents
were optimized for scoring, in experiments they walked 156% faster, took 63%
less time to get up, and kicked 24% faster than a scripted baseline, while
efficiently combining the skills to achieve the longer term objectives.
Examples of the emergent behaviors and full 1v1 matches are available on the
supplementary website.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：PVP: Pre-trained Visual Parameter-Efficient Tuning</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13639</p>
  <p><b>作者</b>：Zhao Song,  Ke Yang,  Naiyang Guan,  Junjie Zhu,  Peng Qiao,  Qingyong Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated remarkable success, computer vision tasks, Large-scale pre-trained transformers, demonstrated remarkable, remarkable success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale pre-trained transformers have demonstrated remarkable success in
various computer vision tasks. However, it is still highly challenging to fully
fine-tune these models for downstream tasks due to their high computational and
storage costs. Recently, Parameter-Efficient Tuning (PETuning) techniques,
e.g., Visual Prompt Tuning (VPT) and Low-Rank Adaptation (LoRA), have
significantly reduced the computation and storage cost by inserting lightweight
prompt modules into the pre-trained models and tuning these prompt modules with
a small number of trainable parameters, while keeping the transformer backbone
frozen. Although only a few parameters need to be adjusted, most PETuning
methods still require a significant amount of downstream task training data to
achieve good results. The performance is inadequate on low-data regimes,
especially when there are only one or two examples per class. To this end, we
first empirically identify the poor performance is mainly due to the
inappropriate way of initializing prompt modules, which has also been verified
in the pre-trained language models. Next, we propose a Pre-trained Visual
Parameter-efficient (PVP) Tuning framework, which pre-trains the
parameter-efficient tuning modules first and then leverages the pre-trained
modules along with the pre-trained transformer backbone to perform
parameter-efficient tuning on downstream tasks. Experiment results on five
Fine-Grained Visual Classification (FGVC) and VTAB-1k datasets demonstrate that
our proposed method significantly outperforms state-of-the-art PETuning
methods.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：AutoCure: Automated Tabular Data Curation Technique for ML Pipelines</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13636</p>
  <p><b>作者</b>：Mohamed Abdelaal,  Rashmi Koparde,  Harald Schoening</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autonomous driving, increasingly prevalent, prevalent in multiple, data, data curation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning algorithms have become increasingly prevalent in multiple
domains, such as autonomous driving, healthcare, and finance. In such domains,
data preparation remains a significant challenge in developing accurate models,
requiring significant expertise and time investment to search the huge search
space of well-suited data curation and transformation tools. To address this
challenge, we present AutoCure, a novel and configuration-free data curation
pipeline that improves the quality of tabular data. Unlike traditional data
curation methods, AutoCure synthetically enhances the density of the clean data
fraction through an adaptive ensemble-based error detection method and a data
augmentation module. In practice, AutoCure can be integrated with open source
tools, e.g., Auto-sklearn, H2O, and TPOT, to promote the democratization of
machine learning. As a proof of concept, we provide a comparative evaluation of
AutoCure against 28 combinations of traditional data curation tools,
demonstrating superior performance and predictive accuracy without user
intervention. Our evaluation shows that AutoCure is an effective approach to
automating data preparation and improving the accuracy of machine learning
models.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：The Roles of Symbols in Neural-based AI: They are Not What You Think!</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13626</p>
  <p><b>作者</b>：Daniel L. Silver,  Tom M. Mitchell</p>
  <p><b>备注</b>：28 pages</p>
  <p><b>关键词</b>：foremost external communication, external communication tools, foremost external, external communication, communication tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose that symbols are first and foremost external communication tools
used between intelligent agents that allow knowledge to be transferred in a
more efficient and effective manner than having to experience the world
directly. But, they are also used internally within an agent through a form of
self-communication to help formulate, describe and justify subsymbolic patterns
of neural activity that truly implement thinking. Symbols, and our languages
that make use of them, not only allow us to explain our thinking to others and
ourselves, but also provide beneficial constraints (inductive bias) on learning
about the world. In this paper we present relevant insights from neuroscience
and cognitive science, about how the human brain represents symbols and the
concepts they refer to, and how today's artificial neural networks can do the
same. We then present a novel neuro-symbolic hypothesis and a plausible
architecture for intelligent agents that combines subsymbolic representations
for symbols and concepts for learning and reasoning. Our hypothesis and
associated architecture imply that symbols will remain critical to the future
of intelligent systems NOT because they are the fundamental building blocks of
thought, but because they are characterizations of subsymbolic processes that
constitute thought.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Impact of Position Bias on Language Models in Token Classification</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13567</p>
  <p><b>作者</b>：Mehdi Ben Amor,  Michael Granitzer,  Jelena Mitrović</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural, Language Processing, Named Entity, Language Models, performance in Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) have shown state-of-the-art performance in Natural
Language Processing (NLP) tasks. Downstream tasks such as Named Entity
Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data
imbalance issues, specifically in terms of the ratio of positive to negative
examples, and class imbalance. In this paper, we investigate an additional
specific issue for language models, namely the position bias of positive
examples in token classification tasks. Therefore, we conduct an in-depth
evaluation of the impact of position bias on the performance of LMs when
fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and
OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We
propose an evaluation approach to investigate position bias in Transformer
models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as
GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in
their performance. To mitigate this effect, we propose two methods: Random
Position Shifting and Context Perturbation, that we apply on batches during the
training process. The results show an improvement of $\approx$ 2\% in the
performance of the model on CoNLL03, UD_en, and TweeBank.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Killing Two Birds with One Stone: Quantization Achieves Privacy in  Distributed Learning</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13545</p>
  <p><b>作者</b>：Guangfeng Yan,  Tan Li,  Kui Wu,  Linqi Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Communication efficiency, distributed machine learning, critical issues, privacy, privacy protection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication efficiency and privacy protection are two critical issues in
distributed machine learning. Existing methods tackle these two issues
separately and may have a high implementation complexity that constrains their
application in a resource-limited environment. We propose a comprehensive
quantization-based solution that could simultaneously achieve communication
efficiency and privacy protection, providing new insights into the correlated
nature of communication and privacy. Specifically, we demonstrate the
effectiveness of our proposed solutions in the distributed stochastic gradient
descent (SGD) framework by adding binomial noise to the uniformly quantized
gradients to reach the desired differential privacy level but with a minor
sacrifice in communication efficiency. We theoretically capture the new
trade-offs between communication, privacy, and learning performance.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Tensor Decomposition for Model Reduction in Neural Networks: A Review</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13539</p>
  <p><b>作者</b>：Xingyi Liu,  Keshab K. Parhi</p>
  <p><b>备注</b>：IEEE Circuits and Systems Magazine, 2023</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, computer vision, revolutionized the fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern neural networks have revolutionized the fields of computer vision (CV)
and Natural Language Processing (NLP). They are widely used for solving complex
CV tasks and NLP tasks such as image classification, image generation, and
machine translation. Most state-of-the-art neural networks are
over-parameterized and require a high computational cost. One straightforward
solution is to replace the layers of the networks with their low-rank tensor
approximations using different tensor decomposition methods. This paper reviews
six tensor decomposition methods and illustrates their ability to compress
model parameters of convolutional neural networks (CNNs), recurrent neural
networks (RNNs) and Transformers. The accuracy of some compressed models can be
higher than the original versions. Evaluations indicate that tensor
decompositions can achieve significant reductions in model size, run-time and
energy consumption, and are well suited for implementing neural networks on
edge devices.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：ElegansNet: a brief scientific report and initial experiments</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13538</p>
  <p><b>作者</b>：Francesco Bardozzo,  Andrea Terlizzi,  Pietro Liò,  Roberto Tagliaferri</p>
  <p><b>备注</b>：4 pages, short report before full paper submission</p>
  <p><b>关键词</b>：research report introduces, deep learning systems, mimics real-world neuronal, report introduces ElegansNet, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research report introduces ElegansNet, a neural network that mimics
real-world neuronal network circuitry, with the goal of better understanding
the interplay between connectome topology and deep learning systems. The
proposed approach utilizes the powerful representational capabilities of living
beings' neuronal circuitry to design and generate improved deep learning
systems with a topology similar to natural networks. The Caenorhabditis elegans
connectome is used as a reference due to its completeness, reasonable size, and
functional neuron classes annotations. It is demonstrated that the connectome
of simple organisms exhibits specific functional relationships between neurons,
and once transformed into learnable tensor networks and integrated into modern
architectures, it offers bio-plausible structures that efficiently solve
complex tasks. The performance of the models is demonstrated against randomly
wired networks and compared to artificial networks ranked on global benchmarks.
In the first case, ElegansNet outperforms randomly wired networks.
Interestingly, ElegansNet models show slightly similar performance with only
those based on the Watts-Strogatz small-world property. When compared to
state-of-the-art artificial neural networks, such as transformers or
attention-based autoencoders, ElegansNet outperforms well-known deep learning
and traditional models in both supervised image classification tasks and
unsupervised hand-written digits reconstruction, achieving top-1 accuracy of
99.99% on Cifar10 and 99.84% on MNIST Unsup on the validation sets.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Key-value information extraction from full handwritten pages</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13530</p>
  <p><b>作者</b>：Solène Tarride,  Mélodie Boillet,  Christopher Kermorvant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：digitized handwritten documents, propose a Transformer-based, Transformer-based approach, handwritten documents, digitized handwritten</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a Transformer-based approach for information extraction from
digitized handwritten documents. Our approach combines, in a single model, the
different steps that were so far performed by separate models: feature
extraction, handwriting recognition and named entity recognition. We compare
this integrated approach with traditional two-stage methods that perform
handwriting recognition before named entity recognition, and present results at
different levels: line, paragraph, and page. Our experiments show that
attention-based models are especially interesting when applied on full pages,
as they do not require any prior segmentation step. Finally, we show that they
are able to learn from key-value annotations: a list of important words with
their corresponding named entities. We compare our models to state-of-the-art
methods on three public databases (IAM, ESPOSALLES, and POPP) and outperform
previous performances on all three datasets.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Sequential decomposition of propositional logic programs</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13522</p>
  <p><b>作者</b>：Christian Antić</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2109.05300, arXiv:2009.05774</p>
  <p><b>关键词</b>：recently introduced, composition of propositional, studying Green relations, propositional logic programs, sequential composition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The sequential composition of propositional logic programs has been recently
introduced. This paper studies the sequential {\em decomposition} of programs
by studying Green's relations $\mathcal{L,R,J}$ -- well-known in semigroup
theory -- between programs. In a broader sense, this paper is a further step
towards an algebraic theory of logic programming.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Cluster Entropy: Active Domain Adaptation in Pathological Image  Segmentation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13513</p>
  <p><b>作者</b>：Xiaoqing Liu,  Kengo Araki,  Shota Harada,  Akihiko Yoshizawa,  Kazuhiro Terada,  Mariyo Kurata,  Naoki Nakajima,  Hiroyuki Abe,  Tetsuo Ushiku,  Ryoma Bise</p>
  <p><b>备注</b>：Accepted by IEEE ISBI'23</p>
  <p><b>关键词</b>：target domain, domain, domain adaptation, shift in pathological, pathological segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The domain shift in pathological segmentation is an important problem, where
a network trained by a source domain (collected at a specific hospital) does
not work well in the target domain (from different hospitals) due to the
different image features. Due to the problems of class imbalance and different
class prior of pathology, typical unsupervised domain adaptation methods do not
work well by aligning the distribution of source domain and target domain. In
this paper, we propose a cluster entropy for selecting an effective whole slide
image (WSI) that is used for semi-supervised domain adaptation. This approach
can measure how the image features of the WSI cover the entire distribution of
the target domain by calculating the entropy of each cluster and can
significantly improve the performance of domain adaptation. Our approach
achieved competitive results against the prior arts on datasets collected from
two hospitals.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Towards clinical AI fairness: A translational perspective</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13493</p>
  <p><b>作者</b>：Mingxuan Liu,  Yilin Ning,  Salinelat Teixayavong,  Mayli Mertens,  Jie Xu,  Daniel Shu Wei Ting,  Lionel Tim-Ee Cheng,  Jasmine Chiat Ling Ong,  Zhen Ling Teo,  Ting Fang Tan,  Ravi Chandran Narrendar,  Fei Wang,  Leo Anthony Celi,  Marcus Eng Hock Ong,  Nan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial intelligence, insights from data, demonstrated the ability, ability to extract, extract insights</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) has demonstrated the ability to extract insights
from data, but the issue of fairness remains a concern in high-stakes fields
such as healthcare. Despite extensive discussion and efforts in algorithm
development, AI fairness and clinical concerns have not been adequately
addressed. In this paper, we discuss the misalignment between technical and
clinical perspectives of AI fairness, highlight the barriers to AI fairness'
translation to healthcare, advocate multidisciplinary collaboration to bridge
the knowledge gap, and provide possible solutions to address the clinical
concerns pertaining to AI fairness.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Fundamental Tradeoffs in Learning with Prior Information</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13479</p>
  <p><b>作者</b>：Anirudha Majumdar</p>
  <p><b>备注</b>：Proceedings of the 40th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023</p>
  <p><b>关键词</b>：understand fundamental tradeoffs, seek to understand, fundamental tradeoffs, understand fundamental, prioritized risk</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We seek to understand fundamental tradeoffs between the accuracy of prior
information that a learner has on a given problem and its learning performance.
We introduce the notion of prioritized risk, which differs from traditional
notions of minimax and Bayes risk by allowing us to study such fundamental
tradeoffs in settings where reality does not necessarily conform to the
learner's prior. We present a general reduction-based approach for extending
classical minimax lower-bound techniques in order to lower bound the
prioritized risk for statistical estimation problems. We also introduce a novel
generalization of Fano's inequality (which may be of independent interest) for
lower bounding the prioritized risk in more general settings involving
unbounded losses. We illustrate the ability of our framework to provide
insights into tradeoffs between prior information and learning performance for
problems in estimation, regression, and reinforcement learning.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Optimizing Energy Efficiency in Metro Systems Under Uncertainty  Disturbances Using Reinforcement Learning</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13443</p>
  <p><b>作者</b>：Haiqin Xie,  Cheng Wang,  Shicheng Li,  Yue Zhang,  Shanshan Wang,  Xiaoping Lu</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：metro systems serve, serve as crucial, crucial and sustainable, metro systems, systems serve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of urban transportation, metro systems serve as crucial and
sustainable means of public transit. However, their substantial energy
consumption poses a challenge to the goal of sustainability. Disturbances such
as delays and passenger flow changes can further exacerbate this issue by
negatively affecting energy efficiency in metro systems. To tackle this
problem, we propose a policy-based reinforcement learning approach that
reschedules the metro timetable and optimizes energy efficiency in metro
systems under disturbances by adjusting the dwell time and cruise speed of
trains. Our experiments conducted in a simulation environment demonstrate the
superiority of our method over baseline methods, achieving a traction energy
consumption reduction of up to 10.9% and an increase in regenerative braking
energy utilization of up to 47.9%. This study provides an effective solution to
the energy-saving problem of urban rail transit.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Can Agents Run Relay Race with Strangers? Generalization of RL to  Out-of-Distribution Trajectories</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13424</p>
  <p><b>作者</b>：Li-Cheng Lan,  Huan Zhang,  Cho-Jui Hsieh</p>
  <p><b>备注</b>：ICRL 2023</p>
  <p><b>关键词</b>：reinforcement learning, controllable states, agent, controllable, states</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we define, evaluate, and improve the ``relay-generalization''
performance of reinforcement learning (RL) agents on the out-of-distribution
``controllable'' states. Ideally, an RL agent that generally masters a task
should reach its goal starting from any controllable state of the environment
instead of memorizing a small set of trajectories. For example, a self-driving
system should be able to take over the control from humans in the middle of
driving and must continue to drive the car safely. To practically evaluate this
type of generalization, we start the test agent from the middle of other
independently well-trained \emph{stranger} agents' trajectories. With extensive
experimental evaluation, we show the prevalence of \emph{generalization
failure} on controllable states from stranger agents. For example, in the
Humanoid environment, we observed that a well-trained Proximal Policy
Optimization (PPO) agent, with only 3.9\% failure rate during regular testing,
failed on 81.6\% of the states generated by well-trained stranger PPO agents.
To improve "relay generalization," we propose a novel method called
Self-Trajectory Augmentation (STA), which will reset the environment to the
agent's old states according to the Q function during training. After applying
STA to the Soft Actor Critic's (SAC) training procedure, we reduced the failure
rate of SAC under relay-evaluation by more than three times in most settings
without impacting agent performance and increasing the needed number of
environment interactions. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Conjunctive Query Based Constraint Solving For Feature Model  Configuration</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13422</p>
  <p><b>作者</b>：Alexander Felfernig,  Viet-Man Le,  Sebastian Lubos</p>
  <p><b>备注</b>：to be presented at The 12th Conference on Information Technology and Its Application, CITA 2023, July 28-29, 2023, Da Nang, Vietnam, and to be published in the volume of the Lecture Notes in Network and Systems series (Springer)</p>
  <p><b>关键词</b>：Feature model configuration, types of reasoning, Feature model, SAT solving, model configuration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature model configuration can be supported on the basis of various types of
reasoning approaches. Examples thereof are SAT solving, constraint solving, and
answer set programming (ASP). Using these approaches requires technical
expertise of how to define and solve the underlying configuration problem. In
this paper, we show how to apply conjunctive queries typically supported by
today's relational database systems to solve constraint satisfaction problems
(CSP) and -- more specifically -- feature model configuration tasks. This
approach allows the application of a wide-spread database technology to solve
configuration tasks and also allows for new algorithmic approaches when it
comes to the identification and resolution of inconsistencies.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Filter Pruning via Filters Similarity in Consecutive Layers</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13397</p>
  <p><b>作者</b>：Xiaorui Wang,  Jun Wang,  Xin Tang,  Peng Gao,  Rui Fang,  Guotong Xie</p>
  <p><b>备注</b>：Accepted by ICASSP 2023 (oral)</p>
  <p><b>关键词</b>：accelerate the Convolutional, widely adopted, adopted to compress, compress and accelerate, Convolutional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Filter pruning is widely adopted to compress and accelerate the Convolutional
Neural Networks (CNNs), but most previous works ignore the relationship between
filters and channels in different layers. Processing each layer independently
fails to utilize the collaborative relationship across layers. In this paper,
we intuitively propose a novel pruning method by explicitly leveraging the
Filters Similarity in Consecutive Layers (FSCL). FSCL compresses models by
pruning filters whose corresponding features are more worthless in the model.
The extensive experiments demonstrate the effectiveness of FSCL, and it yields
remarkable improvement over state-of-the-art on accuracy, FLOPs and parameter
reduction on several benchmark models and datasets.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：VGOS: Voxel Grid Optimization for View Synthesis from Sparse Inputs</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13386</p>
  <p><b>作者</b>：Jiakai Sun,  Zhanjie Zhang,  Jiafu Chen,  Guangyuan Li,  Boyan Ji,  Lei Zhao,  Wei Xing</p>
  <p><b>备注</b>：IJCAI 2023 Accepted (Main Track)</p>
  <p><b>关键词</b>：shown great success, view synthesis due, Neural Radiance Fields, quality and flexibility, radiance field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) has shown great success in novel view synthesis
due to its state-of-the-art quality and flexibility. However, NeRF requires
dense input views (tens to hundreds) and a long training time (hours to days)
for a single scene to generate high-fidelity images. Although using the voxel
grids to represent the radiance field can significantly accelerate the
optimization process, we observe that for sparse inputs, the voxel grids are
more prone to overfitting to the training views and will have holes and
floaters, which leads to artifacts. In this paper, we propose VGOS, an approach
for fast (3-5 minutes) radiance field reconstruction from sparse inputs (3-10
views) to address these issues. To improve the performance of voxel-based
radiance field in sparse input scenarios, we propose two methods: (a) We
introduce an incremental voxel training strategy, which prevents overfitting by
suppressing the optimization of peripheral voxels in the early stage of
reconstruction. (b) We use several regularization techniques to smooth the
voxels, which avoids degenerate solutions. Experiments demonstrate that VGOS
achieves state-of-the-art performance for sparse inputs with super-fast
convergence. Code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Blockchain-based Access Control for Secure Smart Industry Management  Systems</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13379</p>
  <p><b>作者</b>：Aditya Pribadi Kalapaaking,  Ibrahim Khalil,  Mohammad Saidur Rahman,  Abdelaziz Bouras</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interconnected devices resulting, manufacturing systems involve, massive data generation, Smart manufacturing systems, Smart manufacturing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Smart manufacturing systems involve a large number of interconnected devices
resulting in massive data generation. Cloud computing technology has recently
gained increasing attention in smart manufacturing systems for facilitating
cost-effective service provisioning and massive data management. In a
cloud-based manufacturing system, ensuring authorized access to the data is
crucial. A cloud platform is operated under a single authority. Hence, a cloud
platform is prone to a single point of failure and vulnerable to adversaries.
An internal or external adversary can easily modify users' access to allow
unauthorized users to access the data. This paper proposes a role-based access
control to prevent modification attacks by leveraging blockchain and smart
contracts in a cloud-based smart manufacturing system. The role-based access
control is developed to determine users' roles and rights in smart contracts.
The smart contracts are then deployed to the private blockchain network. We
evaluate our solution by utilizing Ethereum private blockchain network to
deploy the smart contract. The experimental results demonstrate the feasibility
and evaluation of the proposed framework's performance.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Feed-Forward Optimization With Delayed Feedback for Neural Networks</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13372</p>
  <p><b>作者</b>：Katharina Flügel,  Daniel Coquelin,  Marie Weiel,  Charlotte Debus,  Achim Streit,  Markus Götz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural learning processes, relying on concepts, learning processes, long been criticized, viable in natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Backpropagation has long been criticized for being biologically implausible,
relying on concepts that are not viable in natural learning processes. This
paper proposes an alternative approach to solve two core issues, i.e., weight
transport and update locking, for biological plausibility and computational
efficiency. We introduce Feed-Forward with delayed Feedback (F$^3$), which
improves upon prior work by utilizing delayed error information as a
sample-wise scaling factor to approximate gradients more accurately. We find
that F$^3$ reduces the gap in predictive performance between biologically
plausible training algorithms and backpropagation by up to 96%. This
demonstrates the applicability of biologically plausible training and opens up
promising new avenues for low-energy training and parallelization.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：LoRaWAN-enabled Smart Campus: The Dataset and a People Counter Use Case</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13366</p>
  <p><b>作者</b>：Eslam Eldeeb,  Hirley Alves</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smart campus, Smart Campus dataset, significant role, Campus dataset based, smart</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>IoT has a significant role in the smart campus. This paper presents a
detailed description of the Smart Campus dataset based on LoRaWAN. LoRaWAN is
an emerging technology that enables serving hundreds of IoT devices. First, we
describe the LoRa network that connects the devices to the server. Afterward,
we analyze the missing transmissions and propose a k-nearest neighbor solution
to handle the missing values. Then, we predict future readings using a long
short-term memory (LSTM). Finally, as one example application, we build a deep
neural network to predict the number of people inside a room based on the
selected sensor's readings. Our results show that our model achieves an
accuracy of $95 \: \%$ in predicting the number of people. Moreover, the
dataset is openly available and described in detail, which is opportunity for
exploration of other features and applications.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Neuro-symbolic Zero-Shot Code Cloning with Cross-Language Intermediate  Representation</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13350</p>
  <p><b>作者</b>：Krishnam Hasija,  Shrishti Pradhan,  Manasi Patwardhan,  Raveendra Kumar Medicherla,  Lovekesh Vig,  Ravindra Naik</p>
  <p><b>备注</b>：10 pages, 4 tables, 2 figures</p>
  <p><b>关键词</b>：finding semantically similar, semantically similar clones, legacy programming language, programming language COBOL, training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we define a neuro-symbolic approach to address the task of
finding semantically similar clones for the codes of the legacy programming
language COBOL, without training data. We define a meta-model that is
instantiated to have an Intermediate Representation (IR) in the form of
Abstract Syntax Trees (ASTs) common across codes in C and COBOL. We linearize
the IRs using Structure Based Traversal (SBT) to create sequential inputs. We
further fine-tune UnixCoder, the best-performing model for zero-shot
cross-programming language code search, for the Code Cloning task with the SBT
IRs of C code-pairs, available in the CodeNet dataset. This allows us to learn
latent representations for the IRs of the C codes, which are transferable to
the IRs of the COBOL codes. With this fine-tuned UnixCoder, we get a
performance improvement of 12.85 MAP@2 over the pre-trained UniXCoder model, in
a zero-shot setting, on the COBOL test split synthesized from the CodeNet
dataset. This demonstrates the efficacy of our meta-model based approach to
facilitate cross-programming language transfer.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Discrepancy-Guided Reconstruction Learning for Image Forgery Detection</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13349</p>
  <p><b>作者</b>：Zenan Shi,  Haipeng Chen,  Long Chen,  Dong Zhang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：model learning capacity, compact visual patterns, paradigm for boosting, boosting the model, model learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel image forgery detection paradigm for
boosting the model learning capacity on both forgery-sensitive and genuine
compact visual patterns. Compared to the existing methods that only focus on
the discrepant-specific patterns (\eg, noises, textures, and frequencies), our
method has a greater generalization. Specifically, we first propose a
Discrepancy-Guided Encoder (DisGE) to extract forgery-sensitive visual
patterns. DisGE consists of two branches, where the mainstream backbone branch
is used to extract general semantic features, and the accessorial discrepant
external attention branch is used to extract explicit forgery cues. Besides, a
Double-Head Reconstruction (DouHR) module is proposed to enhance genuine
compact visual patterns in different granular spaces. Under DouHR, we further
introduce a Discrepancy-Aggregation Detector (DisAD) to aggregate these genuine
compact visual patterns, such that the forgery detection capability on unknown
patterns can be improved. Extensive experimental results on four challenging
datasets validate the effectiveness of our proposed method against
state-of-the-art competitors.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Evaluation of Regularization-based Continual Learning Approaches:  Application to HAR</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13327</p>
  <p><b>作者</b>：Bonpagna Kann (UGA, M-PSI),  Sandra Castellanos-Paez (UGA, M-PSI),  Philippe Lalanda (UGA, M-PSI)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Human Activity Recognition, Pervasive computing, important areas, including the relevant, health and well-being</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pervasive computing allows the provision of services in many important areas,
including the relevant and dynamic field of health and well-being. In this
domain, Human Activity Recognition (HAR) has gained a lot of attention in
recent years. Current solutions rely on Machine Learning (ML) models and
achieve impressive results. However, the evolution of these models remains
difficult, as long as a complete retraining is not performed. To overcome this
problem, the concept of Continual Learning is very promising today and, more
particularly, the techniques based on regularization. These techniques are
particularly interesting for their simplicity and their low cost. Initial
studies have been conducted and have shown promising outcomes. However, they
remain very specific and difficult to compare. In this paper, we provide a
comprehensive comparison of three regularization-based methods that we adapted
to the HAR domain, highlighting their strengths and limitations. Our
experiments were conducted on the UCI HAR dataset and the results showed that
no single technique outperformed all others in all scenarios considered.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Portrait of Emotion: Empowering Self-Expression through AI-Generated  Art</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13324</p>
  <p><b>作者</b>：Yoon Kyung Lee,  Yong-Ha Park,  Sowon Hahn</p>
  <p><b>备注</b>：Accepted CogSci 2023</p>
  <p><b>关键词</b>：authors' cognitive processes, generative artificial intelligence, artificial intelligence, creative expression, investigated the potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigated the potential and limitations of generative artificial
intelligence (AI) in reflecting the authors' cognitive processes through
creative expression. The focus is on the AI-generated artwork's ability to
understand human intent (alignment) and visually represent emotions based on
criteria such as creativity, aesthetic, novelty, amusement, and depth. Results
show a preference for images based on the descriptions of the authors' emotions
over the main events. We also found that images that overrepresent specific
elements or stereotypes negatively impact AI alignment. Our findings suggest
that AI could facilitate creativity and the self-expression of emotions. Our
research framework with generative AIs can help design AI-based interventions
in related fields (e.g., mental health education, therapy, and counseling).</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Technical Note: Defining and Quantifying AND-OR Interactions for  Faithful and Concise Explanation of DNNs</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13312</p>
  <p><b>作者</b>：Mingjie Li,  Quanshi Zhang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2111.06206</p>
  <p><b>关键词</b>：deep neural network, technical note, neural network, aim to explain, explain a deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this technical note, we aim to explain a deep neural network (DNN) by
quantifying the encoded interactions between input variables, which reflects
the DNN's inference logic. Specifically, we first rethink the definition of
interactions, and then formally define faithfulness and conciseness for
interaction-based explanation. To this end, we propose two kinds of
interactions, i.e., the AND interaction and the OR interaction. For
faithfulness, we prove the uniqueness of the AND (OR) interaction in
quantifying the effect of the AND (OR) relationship between input variables.
Besides, based on AND-OR interactions, we design techniques to boost the
conciseness of the explanation, while not hurting the faithfulness. In this
way, the inference logic of a DNN can be faithfully and concisely explained by
a set of symbolic concepts.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：HiQ -- A Declarative, Non-intrusive, Dynamic and Transparent  Observability and Optimization System</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13302</p>
  <p><b>作者</b>：Fuheng Wu,  Ivan Davchev,  Jun Qian</p>
  <p><b>备注</b>：7 pages, 12 figures, opensource</p>
  <p><b>关键词</b>：track Python program, Python program runtime, program runtime information, transparent system called, run-time system performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a non-intrusive, declarative, dynamic and transparent
system called `HiQ` to track Python program runtime information without
compromising on the run-time system performance and losing insight. HiQ can be
used for monolithic and distributed systems, offline and online applications.
HiQ is developed when we optimize our large deep neural network (DNN) models
which are written in Python, but it can be generalized to any Python program or
distributed system, or even other languages like Java. We have implemented the
system and adopted it in our deep learning model life cycle management system
to catch the bottleneck while keeping our production code clean and highly
performant. The implementation is open-sourced at:
[this https URL](this https URL).</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain  Text-to-SQL</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13301</p>
  <p><b>作者</b>：Chunxi Guo,  Zhiliang Tian,  Jintao Tang,  Pancheng Wang,  Zhihua Wen,  Kang Yang,  Ting Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, advancements in Large, Recent advancements, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Large Language Models (LLMs), such as Codex, ChatGPT
and GPT-4 have significantly impacted the AI community, including Text-to-SQL
tasks. Some evaluations and analyses on LLMs show their potential to generate
SQL queries but they point out poorly designed prompts (e.g. simplistic
construction or random sampling) limit LLMs' performance and may cause
unnecessary or irrelevant outputs. To address these issues, we propose
CBR-ApSQL, a Case-Based Reasoning (CBR)-based framework combined with GPT-3.5
for precise control over case-relevant and case-irrelevant knowledge in
Text-to-SQL tasks. We design adaptive prompts for flexibly adjusting inputs for
GPT-3.5, which involves (1) adaptively retrieving cases according to the
question intention by de-semantizing the input question, and (2) an adaptive
fallback mechanism to ensure the informativeness of the prompt, as well as the
relevance between cases and the prompt. In the de-semanticization phase, we
designed Semantic Domain Relevance Evaluator(SDRE), combined with Poincaré
detector(mining implicit semantics in hyperbolic space), TextAlign(discovering
explicit matches), and Positector (part-of-speech detector). SDRE semantically
and syntactically generates in-context exemplar annotations for the new case.
On the three cross-domain datasets, our framework outperforms the
state-of-the-art(SOTA) model in execution accuracy by 3.7\%, 2.5\%, and 8.2\%,
respectively.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving  Few-Shot Learning</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13287</p>
  <p><b>作者</b>：Yi Rong,  Xiongbo Lu,  Zhaoyang Sun,  Yaxiong Chen,  Shengwu Xiong</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：shown promising results, existing SSL approaches, techniques have recently, FSL, recently been integrated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) techniques have recently been integrated into
the few-shot learning (FSL) framework and have shown promising results in
improving the few-shot image classification performance. However, existing SSL
approaches used in FSL typically seek the supervision signals from the global
embedding of every single image. Therefore, during the episodic training of
FSL, these methods cannot capture and fully utilize the local visual
information in image samples and the data structure information of the whole
episode, which are beneficial to FSL. To this end, we propose to augment the
few-shot learning objective with a novel self-supervised Episodic Spatial
Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its
corresponding transformed episode by applying a random geometric transformation
to all the images in it. Based on these, our ESPT objective is defined as
maximizing the local spatial relationship consistency between the original
episode and the transformed one. With this definition, the ESPT-augmented FSL
objective promotes learning more transferable feature representations that
capture the local spatial features of different images and their
inter-relational structural information in each input episode, thus enabling
the model to generalize better to new categories with only a few samples.
Extensive experiments indicate that our ESPT method achieves new
state-of-the-art performance for few-shot image classification on three
mainstay benchmark datasets. The source code will be available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Game-based Platforms for Artificial Intelligence Research</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13269</p>
  <p><b>作者</b>：Chengpeng Hu,  Yunlong Zhao,  Ziqi Wang,  Haocheng Du,  Jialin Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial intelligence research, artificial intelligence, perfect test-beds, characteristics that widely, widely exist</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Games have been the perfect test-beds for artificial intelligence research
for the characteristics that widely exist in real-world scenarios. Learning and
optimisation, decision making in dynamic and uncertain environments, game
theory, planning and scheduling, design and education are common research areas
shared between games and real-world problems. Numerous open-sourced games or
game-based environments have been implemented for studying artificial
intelligence. In addition to single- or multi-player, collaborative or
adversarial games, there has also been growing interest in implementing
platforms for creative design in recent years. Those platforms provide ideal
benchmarks for exploring and comparing artificial intelligence ideas and
techniques. This paper reviews the game-based platforms for artificial
intelligence research, discusses the research trend induced by the evolution of
those platforms, and gives an outlook.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Bayesian Federated Learning: A Survey</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13267</p>
  <p><b>作者</b>：Longbing Cao,  Hui Chen,  Xuhui Fan,  Joao Gama,  Yew-Soon Ong,  Vipin Kumar</p>
  <p><b>备注</b>：Accepted by IJCAI 2023 Survey Track, copyright is owned to IJCAI</p>
  <p><b>关键词</b>：integrating distributed infrastructure, demonstrates its advantages, distributed infrastructure, privacy-preserving manner, advantages in integrating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) demonstrates its advantages in integrating
distributed infrastructure, communication, computing and learning in a
privacy-preserving manner. However, the robustness and capabilities of existing
FL methods are challenged by limited and dynamic data and conditions,
complexities including heterogeneities and uncertainties, and analytical
explainability. Bayesian federated learning (BFL) has emerged as a promising
approach to address these issues. This survey presents a critical overview of
BFL, including its basic concepts, its relations to Bayesian learning in the
context of FL, and a taxonomy of BFL from both Bayesian and federated
perspectives. We categorize and discuss client- and server-side and FL-based
BFL methods and their pros and cons. The limitations of the existing BFL
methods and the future directions of BFL research further address the intricate
requirements of real-life FL applications.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Score-based Generative Modeling Through Backward Stochastic Differential  Equations: Inversion and Generation</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13224</p>
  <p><b>作者</b>：Zihao Wang</p>
  <p><b>备注</b>：Preliminary Preprint</p>
  <p><b>关键词</b>：stochastic differential equations, proposed BSDE-based diffusion, BSDE-based diffusion model, differential equations, proposed BSDE-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The proposed BSDE-based diffusion model represents a novel approach to
diffusion modeling, which extends the application of stochastic differential
equations (SDEs) in machine learning. Unlike traditional SDE-based diffusion
models, our model can determine the initial conditions necessary to reach a
desired terminal distribution by adapting an existing score function. We
demonstrate the theoretical guarantees of the model, the benefits of using
Lipschitz networks for score matching, and its potential applications in
various areas such as diffusion inversion, conditional diffusion, and
uncertainty quantification. Our work represents a contribution to the field of
score-based generative learning and offers a promising direction for solving
real-world problems.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Reinforcement Learning with Partial Parametric Model Knowledge</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13223</p>
  <p><b>作者</b>：Shuyuan Wang,  Philip D. Loewen,  Nathan P. Lawrence,  Michael G. Forbes,  R. Bhushan Gopaluni</p>
  <p><b>备注</b>：IFAC World Congress 2023</p>
  <p><b>关键词</b>：adapt reinforcement learning, Squares Policy Iteration, reinforcement learning, adapt reinforcement, bridge the gap</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We adapt reinforcement learning (RL) methods for continuous control to bridge
the gap between complete ignorance and perfect knowledge of the environment.
Our method, Partial Knowledge Least Squares Policy Iteration (PLSPI), takes
inspiration from both model-free RL and model-based control. It uses incomplete
information from a partial model and retains RL's data-driven adaption towards
optimal performance. The linear quadratic regulator provides a case study;
numerical experiments demonstrate the effectiveness and resulting benefits of
the proposed method.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Exploiting CNNs for Semantic Segmentation with Pascal VOC</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13216</p>
  <p><b>作者</b>：Sourabh Prakash,  Priyanshi Shah,  Ashrya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pixel accuracy, Pascal VOC dataset, Fully Convolution Network, Pascal VOC, accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a comprehensive study on semantic segmentation with
the Pascal VOC dataset. Here, we have to label each pixel with a class which in
turn segments the entire image based on the objects/entities present. To tackle
this, we firstly use a Fully Convolution Network (FCN) baseline which gave
71.31% pixel accuracy and 0.0527 mean IoU. We analyze its performance and
working and subsequently address the issues in the baseline with three
improvements: a) cosine annealing learning rate scheduler(pixel accuracy:
72.86%, IoU: 0.0529), b) data augmentation(pixel accuracy: 69.88%, IoU: 0.0585)
c) class imbalance weights(pixel accuracy: 68.98%, IoU: 0.0596). Apart from
these changes in training pipeline, we also explore three different
architectures: a) Our proposed model -- Advanced FCN (pixel accuracy: 67.20%,
IoU: 0.0602) b) Transfer Learning with ResNet (Best performance) (pixel
accuracy: 71.33%, IoU: 0.0926 ) c) U-Net(pixel accuracy: 72.15%, IoU: 0.0649).
We observe that the improvements help in greatly improving the performance, as
reflected both, in metrics and segmentation maps. Interestingly, we observe
that among the improvements, dataset augmentation has the greatest
contribution. Also, note that transfer learning model performs the best on the
pascal dataset. We analyse the performance of these using loss, accuracy and
IoU plots along with segmentation maps, which help us draw valuable insights
about the working of the models.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Towards Explainable and Safe Conversational Agents for Mental Health: A  Survey</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13191</p>
  <p><b>作者</b>：Surjodeep Sarkar,  Manas Gaur,  L. Chen,  Muskan Garg,  Biplav Srivastava,  Bhaktee Dongaonkar</p>
  <p><b>备注</b>：10 pages, 3 figures, 2 tables</p>
  <p><b>关键词</b>：million Emergency Room, Emergency Room, million primary care, primary care visits, Mental Health Assistants</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：AI-assisted coding: Experiments with GPT-4</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13187</p>
  <p><b>作者</b>：Russell A Poldrack,  Thomas Lu,  Gašper Beguš</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, computer programming tasks, acheived human-level performance, Artificial intelligence, programming tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) tools based on large language models have
acheived human-level performance on some computer programming tasks. We report
several experiments using GPT-4 to generate computer code. These experiments
demonstrate that AI code generation using the current generation of tools,
while powerful, requires substantial human validation to ensure accurate
performance. We also demonstrate that GPT-4 refactoring of existing code can
significantly improve that code along several established metrics for code
quality, and we show that GPT-4 can generate tests with substantial coverage,
but that many of the tests fail when applied to the associated code. These
findings suggest that while AI coding tools are very powerful, they still
require humans in the loop to ensure validity and accuracy of the results.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Dynamic Datasets and Market Environments for Financial Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13174</p>
  <p><b>作者</b>：Xiao-Yang Liu,  Ziyi Xia,  Hongyang Yang,  Jiechao Gao,  Daochen Zha,  Ming Zhu,  Christina Dan Wang,  Zhaoran Wang,  Jian Guo</p>
  <p><b>备注</b>：49 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2211.03107</p>
  <p><b>关键词</b>：deep reinforcement learning, reinforcement learning due, financial reinforcement learning, reinforcement learning, challenging playground</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The financial market is a particularly challenging playground for deep
reinforcement learning due to its unique feature of dynamic datasets. Building
high-quality market environments for training financial reinforcement learning
(FinRL) agents is difficult due to major factors such as the low
signal-to-noise ratio of financial data, survivorship bias of historical data,
and model overfitting. In this paper, we present FinRL-Meta, a data-centric and
openly accessible library that processes dynamic datasets from real-world
markets into gym-style market environments and has been actively maintained by
the AI4Finance community. First, following a DataOps paradigm, we provide
hundreds of market environments through an automatic data curation pipeline.
Second, we provide homegrown examples and reproduce popular research papers as
stepping stones for users to design new trading strategies. We also deploy the
library on cloud platforms so that users can visualize their own results and
assess the relative performance via community-wise competitions. Third, we
provide dozens of Jupyter/Python demos organized into a curriculum and a
documentation website to serve the rapidly growing community. The open-source
codes for the data curation pipeline are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Towards Compute-Optimal Transfer Learning</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13164</p>
  <p><b>作者</b>：Massimo Caccia,  Alexandre Galashov,  Arthur Douillard,  Amal Rannen-Triki,  Dushyant Rao,  Michela Paganini,  Laurent Charlin,  Marc'Aurelio Ranzato,  Razvan Pascanu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong adaptability, large pretrained models, downstream tasks, undergoing a significant, significant shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of transfer learning is undergoing a significant shift with the
introduction of large pretrained models which have demonstrated strong
adaptability to a variety of downstream tasks. However, the high computational
and memory requirements to finetune or use these models can be a hindrance to
their widespread use. In this study, we present a solution to this issue by
proposing a simple yet effective way to trade computational efficiency for
asymptotic performance which we define as the performance a learning algorithm
achieves as compute tends to infinity. Specifically, we argue that zero-shot
structured pruning of pretrained models allows them to increase compute
efficiency with minimal reduction in performance. We evaluate our method on the
Nevis'22 continual learning benchmark that offers a diverse set of transfer
scenarios. Our results show that pruning convolutional filters of pretrained
models can lead to more than 20% performance improvement in low computational
regimes.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Roll-Drop: accounting for observation noise with a single parameter</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13150</p>
  <p><b>作者</b>：Luigi Campanaro,  Daniele De Martini,  Siddhant Gangapurwala,  Wolfgang Merkt,  Ioannis Havoutis</p>
  <p><b>备注</b>：Accepted at Learning for Dynamics & Control Conference 2023 (L4DC), 10 pages, 7 figures</p>
  <p><b>关键词</b>：paper proposes, proposes a simple, simple strategy, DRL, noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a simple strategy for sim-to-real in Deep-Reinforcement
Learning (DRL) -- called Roll-Drop -- that uses dropout during simulation to
account for observation noise during deployment without explicitly modelling
its distribution for each state. DRL is a promising approach to control robots
for highly dynamic and feedback-based manoeuvres, and accurate simulators are
crucial to providing cheap and abundant data to learn the desired behaviour.
Nevertheless, the simulated data are noiseless and generally show a
distributional shift that challenges the deployment on real machines where
sensor readings are affected by noise. The standard solution is modelling the
latter and injecting it during training; while this requires a thorough system
identification, Roll-Drop enhances the robustness to sensor noise by tuning
only a single parameter. We demonstrate an 80% success rate when up to 25%
noise is injected in the observations, with twice higher robustness than the
baselines. We deploy the controller trained in simulation on a Unitree A1
platform and assess this improved robustness on the physical system.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Introducing MBIB -- the first Media Bias Identification Benchmark Task  and Dataset Collection</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13148</p>
  <p><b>作者</b>：Martin Wessel,  Tomáš Horych,  Terry Ruas,  Akiko Aizawa,  Bela Gipp,  Timo Spinde</p>
  <p><b>备注</b>：To be published in Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '23)</p>
  <p><b>关键词</b>：complex multi-task problem, media bias, media bias detection, bias, multi-task problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although media bias detection is a complex multi-task problem, there is, to
date, no unified benchmark grouping these evaluation tasks. We introduce the
Media Bias Identification Benchmark (MBIB), a comprehensive benchmark that
groups different types of media bias (e.g., linguistic, cognitive, political)
under a common framework to test how prospective detection techniques
generalize. After reviewing 115 datasets, we select nine tasks and carefully
propose 22 associated datasets for evaluating media bias detection techniques.
We evaluate MBIB using state-of-the-art Transformer techniques (e.g., T5,
BART). Our results suggest that while hate speech, racial bias, and gender bias
are easier to detect, models struggle to handle certain bias types, e.g.,
cognitive and political bias. However, our results show that no single
technique can outperform all the others significantly. We also find an uneven
distribution of research interest and resource allocation to the individual
tasks in media bias. A unified benchmark encourages the development of more
robust systems and shifts the current paradigm in media bias detection
evaluation towards solutions that tackle not one but multiple media bias types
simultaneously.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Self-Supervised Temporal Analysis of Spatiotemporal Data</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13143</p>
  <p><b>作者</b>：Yi Cao,  Swetava Ganguli,  Vipul Pandey</p>
  <p><b>备注</b>：Accepted for oral presentation at the 43rd IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2023, Pasadena, California. 4 pages and 7 figures</p>
  <p><b>关键词</b>：exists a correlation, type of land, time series, time, series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There exists a correlation between geospatial activity temporal patterns and
type of land use. A novel self-supervised approach is proposed to stratify
landscape based on mobility activity time series. First, the time series signal
is transformed to the frequency domain and then compressed into task-agnostic
temporal embeddings by a contractive autoencoder, which preserves cyclic
temporal patterns observed in time series. The pixel-wise embeddings are
converted to image-like channels that can be used for task-based, multimodal
modeling of downstream geospatial tasks using deep semantic segmentation.
Experiments show that temporal embeddings are semantically meaningful
representations of time series data and are effective across different tasks
such as classifying residential area and commercial areas.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：The Update Equivalence Framework for Decision-Time Planning</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13138</p>
  <p><b>作者</b>：Samuel Sokota,  Gabriele Farina,  David J. Wu,  Hengyuan Hu,  Kevin A. Wang,  J. Zico Kolter,  Noam Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy immediately prior, achieving superhuman performance, decision-time planning, process of revising, prior to execution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The process of revising (or constructing) a policy immediately prior to
execution -- known as decision-time planning -- is key to achieving superhuman
performance in perfect-information settings like chess and Go. A recent line of
work has extended decision-time planning to more general imperfect-information
settings, leading to superhuman performance in poker. However, these methods
requires considering subgames whose sizes grow quickly in the amount of
non-public information, making them unhelpful when the amount of non-public
information is large. Motivated by this issue, we introduce an alternative
framework for decision-time planning that is not based on subgames but rather
on the notion of update equivalence. In this framework, decision-time planning
algorithms simulate updates of synchronous learning algorithms. This framework
enables us to introduce a new family of principled decision-time planning
algorithms that do not rely on public information, opening the door to sound
and effective decision-time planning in settings with large amounts of
non-public information. In experiments, members of this family produce
comparable or superior results compared to state-of-the-art approaches in
Hanabi and improve performance in 3x3 Abrupt Dark Hex and Phantom Tic-Tac-Toe.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Federated Deep Reinforcement Learning for THz-Beam Search with Limited  CSI</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13109</p>
  <p><b>作者</b>：Po-Chun Hsu,  Li-Hsiang Shen,  Chun-Hung Liu,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high data rate, severe propagation attenuation, attenuation significantly hinders, propagation attenuation significantly, next-generation wireless networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Terahertz (THz) communication with ultra-wide available spectrum is a
promising technique that can achieve the stringent requirement of high data
rate in the next-generation wireless networks, yet its severe propagation
attenuation significantly hinders its implementation in practice. Finding beam
directions for a large-scale antenna array to effectively overcome severe
propagation attenuation of THz signals is a pressing need. This paper proposes
a novel approach of federated deep reinforcement learning (FDRL) to swiftly
perform THz-beam search for multiple base stations (BSs) coordinated by an edge
server in a cellular network. All the BSs conduct deep deterministic policy
gradient (DDPG)-based DRL to obtain THz beamforming policy with limited channel
state information (CSI). They update their DDPG models with hidden information
in order to mitigate inter-cell interference. We demonstrate that the cell
network can achieve higher throughput as more THz CSI and hidden neurons of
DDPG are adopted. We also show that FDRL with partial model update is able to
nearly achieve the same performance of FDRL with full model update, which
indicates an effective means to reduce communication load between the edge
server and the BSs by partial model uploading. Moreover, the proposed FDRL
outperforms conventional non-learning-based and existing non-FDRL benchmark
optimization methods.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Time-Selective RNN for Device-Free Multi-Room Human Presence Detection  Using WiFi CSI</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13107</p>
  <p><b>作者</b>：Fang-Yu Chu,  Li-Hsiang Shen,  An-Hung Hsiao,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including home automation, including home, home automation, Human presence detection, crucial technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human presence detection is a crucial technology for various applications,
including home automation, security, and healthcare. While camera-based systems
have traditionally been used for this purpose, they raise privacy concerns. To
address this issue, recent research has explored the use of channel state
information (CSI) approaches that can be extracted from commercial WiFi access
points (APs) and provide detailed channel characteristics. In this thesis, we
propose a device-free human presence detection system for multi-room scenarios
using a time-selective conditional dual feature extract recurrent Network
(TCD-FERN). Our system is designed to capture significant time features with
the condition on current human features using a dynamic and static (DaS) data
preprocessing technique to extract moving and spatial features of people and
differentiate between line-of-sight (LoS) path blocking and non-blocking cases.
To mitigate the feature attenuation problem caused by room partitions, we
employ a voting scheme. We conduct evaluation and real-time experiments to
demonstrate that our proposed TCD-FERN system can achieve human presence
detection for multi-room scenarios using fewer commodity WiFi APs.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Attention-Enhanced Deep Learning for Device-Free Through-the-Wall  Presence Detection Using Indoor WiFi System</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13105</p>
  <p><b>作者</b>：Li-Hsiang Shen,  Kuan-I Lu,  An-Hung Hsiao,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human presence detection, human presence, presence detection, management and security, indoor environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate detection of human presence in indoor environments is important for
various applications, such as energy management and security. In this paper, we
propose a novel system for human presence detection using the channel state
information (CSI) of WiFi signals. Our system named attention-enhanced deep
learning for presence detection (ALPD) employs an attention mechanism to
automatically select informative subcarriers from the CSI data and a
bidirectional long short-term memory (LSTM) network to capture temporal
dependencies in CSI. Additionally, we utilize a static feature to improve the
accuracy of human presence detection in static states. We evaluate the proposed
ALPD system by deploying a pair of WiFi access points (APs) for collecting CSI
dataset, which is further compared with several benchmarks. The results
demonstrate that our ALPD system outperforms the benchmarks in terms of
accuracy, especially in the presence of interference. Moreover, bidirectional
transmission data is beneficial to training improving stability and accuracy,
as well as reducing the costs of data collection for training. Overall, our
proposed ALPD system shows promising results for human presence detection using
WiFi CSI signals.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：LSTM-based Load Forecasting Robustness Against Noise Injection Attack in  Microgrid</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13104</p>
  <p><b>作者</b>：Amirhossein Nazeri,  Pierluigi Pisu</p>
  <p><b>备注</b>：6 pages, 9 figures</p>
  <p><b>关键词</b>：LSTM neural network, LSTM model, electric load forecasting, LSTM, LSTM neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the robustness of an LSTM neural network
against noise injection attacks for electric load forecasting in an ideal
microgrid. The performance of the LSTM model is investigated under a black-box
Gaussian noise attack with different SNRs. It is assumed that attackers have
just access to the input data of the LSTM model. The results show that the
noise attack affects the performance of the LSTM model. The load prediction
means absolute error (MAE) is 0.047 MW for a healthy prediction, while this
value increases up to 0.097 MW for a Gaussian noise insertion with SNR= 6 dB.
To robustify the LSTM model against noise attack, a low-pass filter with
optimal cut-off frequency is applied at the model's input to remove the noise
attack. The filter performs better in case of noise with lower SNR and is less
promising for small noises.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：HyMo: Vulnerability Detection in Smart Contracts using a Novel  Multi-Modal Hybrid Model</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13103</p>
  <p><b>作者</b>：Mohammad Khodadadi,  Jafar Tahmoresnezhad (1) ((1) Department of IT & Computer Engineering, Urmia University of Technology, Orūmīyeh, Iran)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：technology rapidly progress, industries including finance, blockchain technology rapidly, smart contract, smart contract vulnerabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With blockchain technology rapidly progress, the smart contracts have become
a common tool in a number of industries including finance, healthcare,
insurance and gaming. The number of smart contracts has multiplied, and at the
same time, the security of smart contracts has drawn considerable attention due
to the monetary losses brought on by smart contract vulnerabilities. Existing
analysis techniques are capable of identifying a large number of smart contract
security flaws, but they rely too much on rigid criteria established by
specialists, where the detection process takes much longer as the complexity of
the smart contract rises. In this paper, we propose HyMo as a multi-modal
hybrid deep learning model, which intelligently considers various input
representations to consider multimodality and FastText word embedding
technique, which represents each word as an n-gram of characters with BiGRU
deep learning technique, as a sequence processing model that consists of two
GRUs to achieve higher accuracy in smart contract vulnerability detection. The
model gathers features using various deep learning models to identify the smart
contract vulnerabilities. Through a series of studies on the currently publicly
accessible dataset such as ScrawlD, we show that our hybrid HyMo model has
excellent smart contract vulnerability detection performance. Therefore, HyMo
performs better detection of smart contract vulnerabilities against other
approaches.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Organizational Governance of Emerging Technologies: AI Adoption in  Healthcare</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13081</p>
  <p><b>作者</b>：Jee Young Kim,  William Boag,  Freya Gulamali,  Alifia Hasan,  Henry David Jeffry Hogg,  Mark Lifson,  Deirdre Mulligan,  Manesh Patel,  Inioluwa Deborah Raji,  Ajai Sehgal,  Keo Shaw,  Danny Tobey,  Alexandra Valladares,  David Vidal,  Suresh Balu,  Mark Sendak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：public sector structures, Private and public, public sector, norms refine, adoption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Private and public sector structures and norms refine how emerging technology
is used in practice. In healthcare, despite a proliferation of AI adoption, the
organizational governance surrounding its use and integration is often poorly
understood. What the Health AI Partnership (HAIP) aims to do in this research
is to better define the requirements for adequate organizational governance of
AI systems in healthcare settings and support health system leaders to make
more informed decisions around AI adoption. To work towards this understanding,
we first identify how the standards for the AI adoption in healthcare may be
designed to be used easily and efficiently. Then, we map out the precise
decision points involved in the practical institutional adoption of AI
technology within specific health systems. Practically, we achieve this through
a multi-organizational collaboration with leaders from major health systems
across the United States and key informants from related fields. Working with
the consultancy this http URL, we were able to conduct usability-testing sessions
with healthcare and AI ethics professionals. Usability analysis revealed a
prototype structured around mock key decision points that align with how
organizational leaders approach technology adoption. Concurrently, we conducted
semi-structured interviews with 89 professionals in healthcare and other
relevant fields. Using a modified grounded theory approach, we were able to
identify 8 key decision points and comprehensive procedures throughout the AI
adoption lifecycle. This is one of the most detailed qualitative analyses to
date of the current governance structures and processes involved in AI adoption
by health systems in the United States. We hope these findings can inform
future efforts to build capabilities to promote the safe, effective, and
responsible adoption of emerging technologies in healthcare.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Optimizing Deep Learning Models For Raspberry Pi</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13039</p>
  <p><b>作者</b>：Salem Ameen,  Kangaranmulle Siriwardana,  Theo Theodoridis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning models, including computer vision, natural language processing, Deep learning, learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have become increasingly popular for a wide range of
applications, including computer vision, natural language processing, and
speech recognition. However, these models typically require large amounts of
computational resources, making them challenging to run on low-power devices
such as the Raspberry Pi. One approach to addressing this challenge is to use
pruning techniques to reduce the size of the deep learning models. Pruning
involves removing unimportant weights and connections from the model, resulting
in a smaller and more efficient model. Pruning can be done during training or
after the model has been trained. Another approach is to optimize the deep
learning models specifically for the Raspberry Pi architecture. This can
include optimizing the model's architecture and parameters to take advantage of
the Raspberry Pi's hardware capabilities, such as its CPU and GPU.
Additionally, the model can be optimized for energy efficiency by minimizing
the amount of computation required. Pruning and optimizing deep learning models
for the Raspberry Pi can help overcome the computational and energy constraints
of low-power devices, making it possible to run deep learning models on a wider
range of devices. In the following sections, we will explore these approaches
in more detail and discuss their effectiveness for optimizing deep learning
models for the Raspberry Pi.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A Unified Active Learning Framework for Annotating Graph Data with  Application to Software Source Code Performance Prediction</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13032</p>
  <p><b>作者</b>：Peter Samoaa,  Linus Aronsson,  Antonio Longa,  Philipp Leitner,  Morteza Haghir Chehreghani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including performance engineering, data analytics applications, analytics applications, large number, source code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most machine learning and data analytics applications, including performance
engineering in software systems, require a large number of annotations and
labelled data, which might not be available in advance. Acquiring annotations
often requires significant time, effort, and computational resources, making it
challenging. We develop a unified active learning framework, specializing in
software performance prediction, to address this task. We begin by parsing the
source code to an Abstract Syntax Tree (AST) and augmenting it with data and
control flow edges. Then, we convert the tree representation of the source code
to a Flow Augmented-AST graph (FA-AST) representation. Based on the graph
representation, we construct various graph embeddings (unsupervised and
supervised) into a latent space. Given such an embedding, the framework becomes
task agnostic since active learning can be performed using any regression
method and query strategy suited for regression. Within this framework, we
investigate the impact of using different levels of information for active and
passive learning, e.g., partially available labels and unlabeled test data. Our
approach aims to improve the investment in AI models for different software
performance predictions (execution time) based on the structure of the source
code. Our real-world experiments reveal that respectable performance can be
achieved by querying labels for only a small subset of all the data.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Multiobjective Logistics Optimization for Automated ATM Cash  Replenishment Process</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13671</p>
  <p><b>作者</b>：Bui Tien Thanh,  Dinh Van Tuan,  Tuan Anh Chi,  Nguyen Van Dai,  Nguyen Tai Quang Dinh,  Nguyen Thu Thuy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：digital transformation era, integrating digital technology, improves process automation, service level improvement, banking operations improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the digital transformation era, integrating digital technology into every
aspect of banking operations improves process automation, cost efficiency, and
service level improvement. Although logistics for ATM cash is a crucial task
that impacts operating costs and consumer satisfaction, there has been little
effort to enhance it. Specifically, in Vietnam, with a market of more than
20,000 ATMs nationally, research and technological solutions that can resolve
this issue remain scarce. In this paper, we generalized the vehicle routing
problem for ATM cash replenishment, suggested a mathematical model and then
offered a tool to evaluate various situations. When being evaluated on the
simulated dataset, our proposed model and method produced encouraging results
with the benefits of cutting ATM cash operating costs.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Onboard Science Instrument Autonomy for the Detection of Microscopy  Biosignatures on the Ocean Worlds Life Surveyor</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13189</p>
  <p><b>作者</b>：Mark Wronkiewicz,  Jake Lee,  Lukas Mandrake,  Jack Lightholder,  Gary Doran,  Steffen Mauceri,  Taewoo Kim,  Nathan Oborny,  Thomas Schibler,  Jay Nadeau,  James K. Wallace,  Eshaan Moorjani,  Chris Lindensmith</p>
  <p><b>备注</b>：49 pages, 18 figures, submitted to The Planetary Science Journal on 2023-04-20</p>
  <p><b>关键词</b>：critical scientific endeavor, find extraterrestrial life, civilization-level implications, quest to find, find extraterrestrial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The quest to find extraterrestrial life is a critical scientific endeavor
with civilization-level implications. Icy moons in our solar system are
promising targets for exploration because their liquid oceans make them
potential habitats for microscopic life. However, the lack of a precise
definition of life poses a fundamental challenge to formulating detection
strategies. To increase the chances of unambiguous detection, a suite of
complementary instruments must sample multiple independent biosignatures (e.g.,
composition, motility/behavior, and visible structure). Such an instrument
suite could generate 10,000x more raw data than is possible to transmit from
distant ocean worlds like Enceladus or Europa. To address this bandwidth
limitation, Onboard Science Instrument Autonomy (OSIA) is an emerging
discipline of flight systems capable of evaluating, summarizing, and
prioritizing observational instrument data to maximize science return. We
describe two OSIA implementations developed as part of the Ocean Worlds Life
Surveyor (OWLS) prototype instrument suite at the Jet Propulsion Laboratory.
The first identifies life-like motion in digital holographic microscopy videos,
and the second identifies cellular structure and composition via innate and
dye-induced fluorescence. Flight-like requirements and computational
constraints were used to lower barriers to infusion, similar to those available
on the Mars helicopter, "Ingenuity." We evaluated the OSIA's performance using
simulated and laboratory data and conducted a live field test at the
hypersaline Mono Lake planetary analog site. Our study demonstrates the
potential of OSIA for enabling biosignature detection and provides insights and
lessons learned for future mission concepts aimed at exploring the outer solar
system.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Quantum Machine Learning Approach for the Prediction of Surface  Roughness in Additive Manufactured Specimens</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13142</p>
  <p><b>作者</b>：Akshansh Mishra,  Vijaykumar S. Jatti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial factor influencing, Surface roughness, predicting surface roughness, additive manufactured components, crucial factor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surface roughness is a crucial factor influencing the performance and
functionality of additive manufactured components. Accurate prediction of
surface roughness is vital for optimizing manufacturing processes and ensuring
the quality of the final product. Quantum computing has recently gained
attention as a potential solution for tackling complex problems and creating
precise predictive models. In this research paper, we conduct an in-depth
comparison of three quantum algorithms i.e. the Quantum Neural Network (QNN),
Quantum Forest (Q-Forest), and Variational Quantum Classifier (VQC) adapted for
regression for predicting surface roughness in additive manufactured specimens
for the first time. We assess the algorithms performance using Mean Squared
Error (MSE), Mean Absolute Error (MAE), and Explained Variance Score (EVS) as
evaluation metrics. Our findings show that the Q-Forest algorithm surpasses the
other algorithms, achieving an MSE of 56.905, MAE of 7.479, and an EVS of
0.2957. In contrast, the QNN algorithm displays a higher MSE of 60.840 and MAE
of 7.671, coupled with a negative EVS of -0.444, indicating that it may not be
appropriate for predicting surface roughness in this application. The VQC
adapted for regression exhibits an MSE of 59.121, MAE of 7.597, and an EVS of
-0.0106, suggesting its performance is also inferior to the Q-Forest algorithm.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Precision Spectroscopy of Fast, Hot Exotic Isotopes Using Machine  Learning Assisted Event-by-Event Doppler Correction</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2304.13120</p>
  <p><b>作者</b>：Silviu-Marian Udrescu,  Diego Alejandro Torres,  Ronald Fernando Garcia Ruiz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-precision laser spectroscopy, fast exotic isotopes, laser spectroscopy studies, performing sensitive, high-precision laser</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an experimental scheme for performing sensitive, high-precision
laser spectroscopy studies on fast exotic isotopes. By inducing a step-wise
resonant ionization of the atoms travelling inside an electric field and
subsequently detecting the ion and the corresponding electron, time- and
position-sensitive measurements of the resulting particles can be performed.
Using a Mixture Density Network (MDN), we can leverage this information to
predict the initial energy of individual atoms and thus apply a Doppler
correction of the observed transition frequencies on an event-by-event basis.
We conduct numerical simulations of the proposed experimental scheme and show
that kHz-level uncertainties can be achieved for ion beams produced at extreme
temperatures ($> 10^8$ K), with energy spreads as large as $10$ keV and
non-uniform velocity distributions. The ability to perform in-flight
spectroscopy, directly on highly energetic beams, offers unique opportunities
to studying short-lived isotopes with lifetimes in the millisecond range and
below, produced in low quantities, in hot and highly contaminated environments,
without the need for cooling techniques. Such species are of marked interest
for nuclear structure, astrophysics, and new physics searches.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/04/08/transformers.generation.GenerationMixin.html"><img class="next-cover" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">transformers.generation.GenerationMixin</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-04-27)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-04-27)"/></a><div class="content"><a class="title" href="/2023/04/27/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-04-27)">Arxiv每日速递(2023-04-27)</a><time datetime="2023-04-27T00:41:00.509Z" title="发表于 2023-04-27 08:41:00">2023-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformers.generation.GenerationMixin"/></a><div class="content"><a class="title" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin">transformers.generation.GenerationMixin</a><time datetime="2023-04-08T13:42:45.000Z" title="发表于 2023-04-08 21:42:45">2023-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/27/ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="ChatGPT 标注指南：任务、数据与规范"><img src="https://openaicom.imgix.net/8d14e8f0-e267-4b8b-a9f2-a79120808f5a/chatgpt.jpg?auto=compress%2Cformat&amp;fit=min&amp;fm=jpg&amp;q=80&amp;rect=0%2C0%2C2048%2C2048&amp;w=3200" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ChatGPT 标注指南：任务、数据与规范"/></a><div class="content"><a class="title" href="/2023/03/27/ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="ChatGPT 标注指南：任务、数据与规范">ChatGPT 标注指南：任务、数据与规范</a><time datetime="2023-03-27T14:35:45.000Z" title="发表于 2023-03-27 22:35:45">2023-03-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/26/%E9%80%9A%E5%90%91AGI%E4%B9%8B%E8%B7%AF%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E6%8A%80%E6%9C%AF%E7%B2%BE%E8%A6%81.html" title="通向AGI之路：大型语言模型（LLM）技术精要"><img src="https://picx.zhimg.com/v2-8eab4d7521252501ef5d836e786c45c6_1440w.jpg?source=172ae18b" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="通向AGI之路：大型语言模型（LLM）技术精要"/></a><div class="content"><a class="title" href="/2023/03/26/%E9%80%9A%E5%90%91AGI%E4%B9%8B%E8%B7%AF%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89%E6%8A%80%E6%9C%AF%E7%B2%BE%E8%A6%81.html" title="通向AGI之路：大型语言模型（LLM）技术精要">通向AGI之路：大型语言模型（LLM）技术精要</a><time datetime="2023-03-26T14:55:45.000Z" title="发表于 2023-03-26 22:55:45">2023-03-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/11/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html" title="强化学习"><img src="https://img0.baidu.com/it/u=3005164807,267475947&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=804&amp;h=500" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="强化学习"/></a><div class="content"><a class="title" href="/2023/03/11/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html" title="强化学习">强化学习</a><time datetime="2023-03-11T13:45:45.000Z" title="发表于 2023-03-11 21:45:45">2023-03-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>