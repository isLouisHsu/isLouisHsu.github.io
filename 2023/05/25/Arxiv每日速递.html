<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-05-25) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新597篇论文，其中：  124篇计算机视觉（cs.CV） 283篇自然语言处理（cs.CL） 176篇机器学习（cs.LG） 149篇人工智能（cs.AI）  计算机视觉    1. 标题：NCHO: Unsupervised Learning for Ne">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-05-25)">
<meta property="og:url" content="http://louishsu.xyz/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新597篇论文，其中：  124篇计算机视觉（cs.CV） 283篇自然语言处理（cs.CL） 176篇机器学习（cs.LG） 149篇人工智能（cs.AI）  计算机视觉    1. 标题：NCHO: Unsupervised Learning for Ne">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-05-25T00:41:53.413Z">
<meta property="article:modified_time" content="2023-05-25T00:43:30.534Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-25 08:43:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-05-25)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-25T00:41:53.413Z" title="发表于 2023-05-25 08:41:53">2023-05-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-25T00:43:30.534Z" title="更新于 2023-05-25 08:43:30">2023-05-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">100.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>600分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新597篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">124篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">283篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">176篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">149篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：NCHO: Unsupervised Learning for Neural 3D Composition of Humans and  Objects</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14345</p>
  <p><b>作者</b>：Taeksoo Kim,  Shunsuke Saito,  Hanbyul Joo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extended to synthesizing, recently extended, objects, Deep generative models, humans</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep generative models have been recently extended to synthesizing 3D digital
humans. However, previous approaches treat clothed humans as a single chunk of
geometry without considering the compositionality of clothing and accessories.
As a result, individual items cannot be naturally composed into novel
identities, leading to limited expressiveness and controllability of generative
3D avatars. While several methods attempt to address this by leveraging
synthetic data, the interaction between humans and objects is not authentic due
to the domain gap, and manual asset creation is difficult to scale for a wide
variety of objects. In this work, we present a novel framework for learning a
compositional generative model of humans and objects (backpacks, coats,
scarves, and more) from real-world 3D scans. Our compositional model is
interaction-aware, meaning the spatial relationship between humans and objects,
and the mutual shape change by physical contact is fully incorporated. The key
challenge is that, since humans and objects are in contact, their 3D scans are
merged into a single piece. To decompose them without manual annotations, we
propose to leverage two sets of 3D scans of a single person with and without
objects. Our approach learns to decompose objects and naturally compose them
back into a generative human model in an unsupervised manner. Despite our
simple setup requiring only the capture of a single subject with objects, our
experiments demonstrate the strong generalization of our model by enabling the
natural composition of objects to diverse identities in various poses and the
composition of multiple objects, which is unseen in training data.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Siamese Masked Autoencoders</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14344</p>
  <p><b>作者</b>：Agrim Gupta,  Jiajun Wu,  Jia Deng,  Li Fei-Fei</p>
  <p><b>备注</b>：Project page this https URL</p>
  <p><b>关键词</b>：varying object appearances, computer vision, present Siamese Masked, images or scenes, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Establishing correspondence between images or scenes is a significant
challenge in computer vision, especially given occlusions, viewpoint changes,
and varying object appearances. In this paper, we present Siamese Masked
Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for
learning visual correspondence from videos. SiamMAE operates on pairs of
randomly sampled video frames and asymmetrically masks them. These frames are
processed independently by an encoder network, and a decoder composed of a
sequence of cross-attention layers is tasked with predicting the missing
patches in the future frame. By masking a large fraction ($95\%$) of patches in
the future frame while leaving the past frame unchanged, SiamMAE encourages the
network to focus on object motion and learn object-centric representations.
Despite its conceptual simplicity, features learned via SiamMAE outperform
state-of-the-art self-supervised methods on video object segmentation, pose
keypoint propagation, and semantic part propagation tasks. SiamMAE achieves
competitive results without relying on data augmentation, handcrafted
tracking-based pretext tasks, or other techniques to prevent representational
collapse.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Video Prediction Models as Rewards for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14343</p>
  <p><b>作者</b>：Alejandro Escontrela,  Ademi Adeniji,  Wilson Yan,  Ajay Jain,  Xue Bin Peng,  Ken Goldberg,  Youngwoon Lee,  Danijar Hafner,  Pieter Abbeel</p>
  <p><b>备注</b>：20 pages, 15 figures, 4 tables. under review</p>
  <p><b>关键词</b>：learn complex behaviors, Video Prediction, learn complex, long-standing challenge, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Specifying reward signals that allow agents to learn complex behaviors is a
long-standing challenge in reinforcement learning. A promising approach is to
extract preferences for behaviors from unlabeled videos, which are widely
available on the internet. We present Video Prediction Rewards (VIPER), an
algorithm that leverages pretrained video prediction models as action-free
reward signals for reinforcement learning. Specifically, we first train an
autoregressive transformer on expert videos and then use the video prediction
likelihoods as reward signals for a reinforcement learning agent. VIPER enables
expert-level control without programmatic task rewards across a wide range of
DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction
model allows us to derive rewards for an out-of-distribution environment where
no expert data is available, enabling cross-embodiment generalization for
tabletop manipulation. We see our work as starting point for scalable reward
specification from unlabeled videos that will benefit from the rapid advances
in generative modeling. Source code and datasets are available on the project
website: this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Prototype Adaption and Projection for Few- and Zero-shot 3D Point Cloud  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14335</p>
  <p><b>作者</b>：Shuting He,  Xudong Jiang,  Wei Jiang,  Henghui Ding</p>
  <p><b>备注</b>：IEEE TIP</p>
  <p><b>关键词</b>：point cloud, point cloud segmentation, point cloud semantic, cloud semantic segmentation, point clouds feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we address the challenging task of few-shot and zero-shot 3D
point cloud semantic segmentation. The success of few-shot semantic
segmentation in 2D computer vision is mainly driven by the pre-training on
large-scale datasets like imagenet. The feature extractor pre-trained on
large-scale 2D datasets greatly helps the 2D few-shot learning. However, the
development of 3D deep learning is hindered by the limited volume and instance
modality of datasets due to the significant cost of 3D data collection and
annotation. This results in less representative features and large intra-class
feature variation for few-shot 3D point cloud segmentation. As a consequence,
directly extending existing popular prototypical methods of 2D few-shot
classification/segmentation into 3D point cloud segmentation won't work as well
as in 2D domain. To address this issue, we propose a Query-Guided Prototype
Adaption (QGPA) module to adapt the prototype from support point clouds feature
space to query point clouds feature space. With such prototype adaption, we
greatly alleviate the issue of large feature intra-class variation in point
cloud and significantly improve the performance of few-shot 3D segmentation.
Besides, to enhance the representation of prototypes, we introduce a
Self-Reconstruction (SR) module that enables prototype to reconstruct the
support mask as well as possible. Moreover, we further consider zero-shot 3D
point cloud semantic segmentation where there is no support sample. To this
end, we introduce category words as semantic information and propose a
semantic-visual projection model to bridge the semantic and visual spaces. Our
proposed method surpasses state-of-the-art algorithms by a considerable 7.90%
and 14.82% under the 2-way 1-shot setting on S3DIS and ScanNet benchmarks,
respectively. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Diffusion Hyperfeatures: Searching Through Time and Space for Semantic  Correspondence</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14334</p>
  <p><b>作者</b>：Grace Luo,  Lisa Dunlap,  Dong Huk Park,  Aleksander Holynski,  Trevor Darrell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meaningful internal representations, generating high-quality images, diffusion model internal, Diffusion Hyperfeatures, capable of generating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have been shown to be capable of generating high-quality
images, suggesting that they could contain meaningful internal representations.
Unfortunately, the feature maps that encode a diffusion model's internal
information are spread not only over layers of the network, but also over
diffusion timesteps, making it challenging to extract useful descriptors. We
propose Diffusion Hyperfeatures, a framework for consolidating multi-scale and
multi-timestep feature maps into per-pixel feature descriptors that can be used
for downstream tasks. These descriptors can be extracted for both synthetic and
real images using the generation and inversion processes. We evaluate the
utility of our Diffusion Hyperfeatures on the task of semantic keypoint
correspondence: our method achieves superior performance on the SPair-71k real
image benchmark. We also demonstrate that our method is flexible and
transferable: our feature aggregation network trained on the inversion features
of real image pairs can be used on the generation features of synthetic image
pairs with unseen objects and compositions. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Large Language Models are Frame-level Directors for Zero-shot  Text-to-Video Generation</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14330</p>
  <p><b>作者</b>：Susung Hong,  Junyoung Seo,  Sunghwan Hong,  Heeseong Shin,  Seungryong Kim</p>
  <p><b>备注</b>：The code and demo will be available at this https URL</p>
  <p><b>关键词</b>：extending pre-trained, paradigm of AI-generated, increasing attention, attention in extending, AIGC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the paradigm of AI-generated content (AIGC), there has been increasing
attention in extending pre-trained text-to-image (T2I) models to text-to-video
(T2V) generation. Despite their effectiveness, these frameworks face challenges
in maintaining consistent narratives and handling rapid shifts in scene
composition or object placement from a single user prompt. This paper
introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned
large language models (LLMs) to generate frame-by-frame descriptions from a
single abstract user prompt. DirecT2V utilizes LLM directors to divide user
inputs into separate prompts for each frame, enabling the inclusion of
time-varying content and facilitating consistent video generation. To maintain
temporal consistency and prevent object collapse, we propose a novel value
mapping method and dual-softmax filtering. Extensive experimental results
validate the effectiveness of the DirecT2V framework in producing visually
coherent and consistent videos from abstract user prompts, addressing the
challenges of zero-shot video generation.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Improving Factuality and Reasoning in Language Models through Multiagent  Debate</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14325</p>
  <p><b>作者</b>：Yilun Du,  Shuang Li,  Antonio Torralba,  Joshua B. Tenenbaum,  Igor Mordatch</p>
  <p><b>备注</b>：Project Webpage and Code: this https URL</p>
  <p><b>关键词</b>：demonstrated remarkable capabilities, recent years, Large language models, demonstrated remarkable, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
"society of minds" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Mitigating Biased Activation in Weakly-supervised Object Localization  via Counterfactual Learning</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15354</p>
  <p><b>作者</b>：Feifei Shao,  Yawei Luo,  Lei Chen,  Ping Liu,  Yi Yang,  Jun Xiao</p>
  <p><b>备注</b>：13 pages, 5 figures, 4 tables</p>
  <p><b>关键词</b>：based on Class, prior weakly-supervised object, localization methods based, Class Activation, under-explored issue</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we focus on an under-explored issue of biased activation in
prior weakly-supervised object localization methods based on Class Activation
Mapping (CAM). We analyze the cause of this problem from a causal view and
attribute it to the co-occurring background confounders. Following this
insight, we propose a novel Counterfactual Co-occurring Learning (CCL) paradigm
to synthesize the counterfactual representations via coupling constant
foreground and unrealized backgrounds in order to cut off their co-occurring
relationship. Specifically, we design a new network structure called
Counterfactual-CAM, which embeds the counterfactual representation perturbation
mechanism into the vanilla CAM-based model. This mechanism is responsible for
decoupling foreground as well as background and synthesizing the counterfactual
representations. By training the detection model with these synthesized
representations, we compel the model to focus on the constant foreground
content while minimizing the influence of distracting co-occurring background.
To our best knowledge, it is the first attempt in this direction. Extensive
experiments on several benchmarks demonstrate that Counterfactual-CAM
successfully mitigates the biased activation problem, achieving improved object
localization accuracy.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot  Semantic Correspondence</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15347</p>
  <p><b>作者</b>：Junyi Zhang,  Charles Herrmann,  Junhwa Hur,  Luisa Polania Cabrera,  Varun Jampani,  Deqing Sun,  Ming-Hsuan Yang</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：made significant advances, advances in generating, generating and editing, diffusion model features, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-image diffusion models have made significant advances in generating
and editing high-quality images. As a result, numerous approaches have explored
the ability of diffusion model features to understand and process single images
for downstream tasks, e.g., classification, semantic segmentation, and
stylization. However, significantly less is known about what these features
reveal across multiple, different images and objects. In this work, we exploit
Stable Diffusion (SD) features for semantic and dense correspondence and
discover that with simple post-processing, SD features can perform
quantitatively similar to SOTA representations. Interestingly, the qualitative
analysis reveals that SD features have very different properties compared to
existing representation learning features, such as the recently released
DINOv2: while DINOv2 provides sparse but accurate matches, SD features provide
high-quality spatial information but sometimes inaccurate semantic matches. We
demonstrate that a simple fusion of these two features works surprisingly well,
and a zero-shot evaluation using nearest neighbors on these fused features
provides a significant performance gain over state-of-the-art methods on
benchmark datasets, e.g., SPair-71k, PF-Pascal, and TSS. We also show that
these correspondences can enable interesting applications such as instance
swapping in two images.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Visual Programming for Text-to-Image Generation and Evaluation</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15328</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：18 pages; Project website: this https URL</p>
  <p><b>关键词</b>：demonstrated impressive performance, large language models, adopted language models, generation, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models have demonstrated impressive performance in many
domains, recent works have adopted language models (LMs) as controllers of
visual modules for vision-and-language tasks. While existing work focuses on
equipping LMs with visual understanding, we propose two novel
interpretable/explainable visual programming frameworks for text-to-image (T2I)
generation and evaluation. First, we introduce VPGen, an interpretable
step-by-step T2I generation framework that decomposes T2I generation into three
steps: object/count generation, layout generation, and image generation. We
employ an LM to handle the first two steps (object/count generation and layout
generation), by finetuning it on text-layout pairs. Our step-by-step T2I
generation framework provides stronger spatial control than end-to-end models,
the dominant approach for this task. Furthermore, we leverage the world
knowledge of pretrained LMs, overcoming the limitation of previous
layout-guided T2I works that can only handle predefined object classes. We
demonstrate that our VPGen has improved control in counts/spatial
relations/scales of objects than state-of-the-art T2I generation models.
Second, we introduce VPEval, an interpretable and explainable evaluation
framework for T2I generation based on visual programming. Unlike previous T2I
evaluations with a single scoring model that is accurate in some skills but
unreliable in others, VPEval produces evaluation programs that invoke a set of
visual modules that are experts in different skills, and also provides
visual+textual explanations of the evaluation results. Our analysis shows
VPEval provides a more human-correlated evaluation for skill-specific and
open-ended prompts than widely used single model-based evaluation. We hope our
work encourages future progress on interpretable/explainable generation and
evaluation for T2I models. Website: this https URL</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Training on Thin Air: Improve Image Classification with Generated Data</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15316</p>
  <p><b>作者</b>：Yongchao Zhou,  Hshmat Sahak,  Jimmy Ba</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective predictive systems, building effective predictive, present Diffusion Inversion, Acquiring high-quality data, Stable Diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Acquiring high-quality data for training discriminative models is a crucial
yet challenging aspect of building effective predictive systems. In this paper,
we present Diffusion Inversion, a simple yet effective method that leverages
the pre-trained generative model, Stable Diffusion, to generate diverse,
high-quality training data for image classification. Our approach captures the
original data distribution and ensures data coverage by inverting images to the
latent space of Stable Diffusion, and generates diverse novel training images
by conditioning the generative model on noisy versions of these vectors. We
identify three key components that allow our generated images to successfully
supplant the original dataset, leading to a 2-3x enhancement in sample
complexity and a 6.5x decrease in sampling time. Moreover, our approach
consistently outperforms generic prompt-based steering methods and KNN
retrieval baseline across a wide range of datasets. Additionally, we
demonstrate the compatibility of our approach with widely-used data
augmentation techniques, as well as the reliability of the generated data in
supporting various neural architectures and enhancing few-shot learning.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Personalized Dictionary Learning for Heterogeneous Datasets</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15311</p>
  <p><b>作者</b>：Geyu Liang,  Naichen Shi,  Raed Al Kontar,  Salar Fattahi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging problem named, named Personalized Dictionary, introduce a relevant, relevant yet challenging, global and local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a relevant yet challenging problem named Personalized Dictionary
Learning (PerDL), where the goal is to learn sparse linear representations from
heterogeneous datasets that share some commonality. In PerDL, we model each
dataset's shared and unique features as global and local dictionaries.
Challenges for PerDL not only are inherited from classical dictionary learning
(DL), but also arise due to the unknown nature of the shared and unique
features. In this paper, we rigorously formulate this problem and provide
conditions under which the global and local dictionaries can be provably
disentangled. Under these conditions, we provide a meta-algorithm called
Personalized Matching and Averaging (PerMA) that can recover both global and
local dictionaries from heterogeneous datasets. PerMA is highly efficient; it
converges to the ground truth at a linear rate under suitable conditions.
Moreover, it automatically borrows strength from strong learners to improve the
prediction of weak learners. As a general framework for extracting global and
local dictionaries, we show the application of PerDL in different learning
tasks, such as training with imbalanced datasets and video surveillance.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Multi-Modal Mutual Attention and Iterative Interaction for Referring  Image Segmentation</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15302</p>
  <p><b>作者</b>：Chang Liu,  Henghui Ding,  Yulun Zhang,  Xudong Jiang</p>
  <p><b>备注</b>：IEEE TIP</p>
  <p><b>关键词</b>：natural language expression, aims to generate, mathrm, Multi-Modal Mutual Attention, Multi-Modal Mutual Decoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the problem of referring image segmentation that aims to generate
a mask for the object specified by a natural language expression. Many recent
works utilize Transformer to extract features for the target object by
aggregating the attended visual regions. However, the generic attention
mechanism in Transformer only uses the language input for attention weight
calculation, which does not explicitly fuse language features in its output.
Thus, its output feature is dominated by vision information, which limits the
model to comprehensively understand the multi-modal information, and brings
uncertainty for the subsequent mask decoder to extract the output mask. To
address this issue, we propose Multi-Modal Mutual Attention ($\mathrm{M^3Att}$)
and Multi-Modal Mutual Decoder ($\mathrm{M^3Dec}$) that better fuse information
from the two input modalities. Based on {$\mathrm{M^3Dec}$}, we further propose
Iterative Multi-modal Interaction ($\mathrm{IMI}$) to allow continuous and
in-depth interactions between language and vision features. Furthermore, we
introduce Language Feature Reconstruction ($\mathrm{LFR}$) to prevent the
language information from being lost or distorted in the extracted feature.
Extensive experiments show that our proposed approach significantly improves
the baseline and outperforms state-of-the-art referring image segmentation
methods on RefCOCO series datasets consistently.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal  Image Generation</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15296</p>
  <p><b>作者</b>：Marco Bellagente,  Manuel Brack,  Hannah Teufel,  Felix Friedrich,  Björn Deiseroth,  Constantin Eichenberg,  Andrew Dai,  Robert Baldock,  Souradeep Nanda,  Koen Oostermeijer,  Andres Felipe Cruz-Salinas,  Patrick Schramowski,  Kristian Kersting,  Samuel Weinbach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide to users, recent popularity, largely be attributed, intuitive interface, interface they provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent popularity of text-to-image diffusion models (DM) can largely be
attributed to the intuitive interface they provide to users. The intended
generation can be expressed in natural language, with the model producing
faithful interpretations of text prompts. However, expressing complex or
nuanced ideas in text alone can be difficult. To ease image generation, we
propose MultiFusion that allows one to express complex and nuanced concepts
with arbitrarily interleaved inputs of multiple modalities and languages.
MutliFusion leverages pre-trained models and aligns them for integration into a
cohesive system, thereby avoiding the need for extensive training from scratch.
Our experimental results demonstrate the efficient transfer of capabilities
from individual modules to the downstream model. Specifically, the fusion of
all independent components allows the image generation module to utilize
multilingual, interleaved multimodal inputs despite being trained solely on
monomodal data in a single language.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：High Speed Human Action Recognition using a Photonic Reservoir Computer</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15283</p>
  <p><b>作者</b>：Enrico Picco,  Piotr Antonik,  Serge Massar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：active research fields, active research, research fields, recognition of human, human actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recognition of human actions in videos is one of the most active research
fields in computer vision. The canonical approach consists in a more or less
complex preprocessing stages of the raw video data, followed by a relatively
simple classification algorithm. Here we address recognition of human actions
using the reservoir computing algorithm, which allows us to focus on the
classifier stage. We introduce a new training method for the reservoir
computer, based on "Timesteps Of Interest", which combines in a simple way
short and long time scales. We study the performance of this algorithm using
both numerical simulations and a photonic implementation based on a single
non-linear node and a delay line on the well known KTH dataset. We solve the
task with high accuracy and speed, to the point of allowing for processing
multiple video streams in real time. The present work is thus an important step
towards developing efficient dedicated hardware for video processing.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：ViTMatte: Boosting Image Matting with Pretrained Plain Vision  Transformers</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15272</p>
  <p><b>作者</b>：Jingfeng Yao,  Xinggang Wang,  Shusheng Yang,  Baoyuan Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：plain vision Transformers, vision Transformers, strong modeling capacity, computer vision tasks, plain vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, plain vision Transformers (ViTs) have shown impressive performance
on various computer vision tasks, thanks to their strong modeling capacity and
large-scale pretraining. However, they have not yet conquered the problem of
image matting. We hypothesize that image matting could also be boosted by ViTs
and present a new efficient and robust ViT-based matting system, named
ViTMatte. Our method utilizes (i) a hybrid attention mechanism combined with a
convolution neck to help ViTs achieve an excellent performance-computation
trade-off in matting tasks. (ii) Additionally, we introduce the detail capture
module, which just consists of simple lightweight convolutions to complement
the detailed information required by matting. To the best of our knowledge,
ViTMatte is the first work to unleash the potential of ViT on image matting
with concise adaptation. It inherits many superior properties from ViT to
matting, including various pretraining strategies, concise architecture design,
and flexible inference strategies. We evaluate ViTMatte on Composition-1k and
Distinctions-646, the most commonly used benchmark for image matting, our
method achieves state-of-the-art performance and outperforms prior matting
works by a large margin.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15270</p>
  <p><b>作者</b>：Tong Xu,  Micol Spitale,  Hao Tang,  Lu Liu,  Hatice Gunes,  Siyang Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facial reaction, human-human dyadic interaction, facial, facial reaction generation, facial reaction distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating facial reactions in a human-human dyadic interaction is complex
and highly dependent on the context since more than one facial reactions can be
appropriate for the speaker's behaviour. This has challenged existing machine
learning (ML) methods, whose training strategies enforce models to reproduce a
specific (not multiple) facial reaction from each input speaker behaviour. This
paper proposes the first multiple appropriate facial reaction generation
framework that re-formulates the one-to-many mapping facial reaction generation
problem as a one-to-one mapping problem. This means that we approach this
problem by considering the generation of a distribution of the listener's
appropriate facial reactions instead of multiple different appropriate facial
reactions, i.e., 'many' appropriate facial reaction labels are summarised as
'one' distribution label during training. Our model consists of a perceptual
processor, a cognitive processor, and a motor processor. The motor processor is
implemented with a novel Reversible Multi-dimensional Edge Graph Neural Network
(REGNN). This allows us to obtain a distribution of appropriate real facial
reactions during the training process, enabling the cognitive processor to be
trained to predict the appropriate facial reaction distribution. At the
inference stage, the REGNN decodes an appropriate facial reaction by using this
distribution as input. Experimental results demonstrate that our approach
outperforms existing models in generating more appropriate, realistic, and
synchronized facial reactions. The improved performance is largely attributed
to the proposed appropriate facial reaction distribution learning strategy and
the use of a REGNN. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Rethinking the Evaluation Protocol of Domain Generalization</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15253</p>
  <p><b>作者</b>：Han Yu,  Xingxuan Zhang,  Renzhe Xu,  Jiashuo Liu,  Yue He,  Peng Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging common knowledge, common knowledge learned, OOD generalization ability, test data information, OOD generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain generalization aims to solve the challenge of Out-of-Distribution
(OOD) generalization by leveraging common knowledge learned from multiple
training domains to generalize to unseen test domains. To accurately evaluate
the OOD generalization ability, it is necessary to ensure that test data
information is unavailable. However, the current domain generalization protocol
may still have potential test data information leakage. This paper examines the
potential risks of test data information leakage in two aspects of the current
protocol: pretraining on ImageNet and oracle model selection. We propose that
training from scratch and using multiple test domains would result in a more
precise evaluation of OOD generalization ability. We also rerun the algorithms
with the modified protocol and introduce a new leaderboard to encourage future
research in domain generalization with a fairer comparison.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Delving Deeper into Data Scaling in Masked Image Modeling</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15248</p>
  <p><b>作者</b>：Cheng-Ze Lu,  Xiaojie Jin,  Qibin Hou,  Jun Hao Liew,  Ming-Ming Cheng,  Jiashi Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：self-supervised learning methods, Understanding whether self-supervised, self-supervised learning, learning methods, training large-scale models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding whether self-supervised learning methods can scale with
unlimited data is crucial for training large-scale models. In this work, we
conduct an empirical study on the scaling capability of masked image modeling
(MIM) methods (e.g., MAE) for visual recognition. Unlike most previous works
that depend on the widely-used ImageNet dataset, which is manually curated and
object-centric, we take a step further and propose to investigate this problem
in a more practical setting. Specifically, we utilize the web-collected
Coyo-700M dataset. We randomly sample varying numbers of training images from
the Coyo dataset and construct a series of sub-datasets, containing 0.5M, 1M,
5M, 10M, and 100M images, for pre-training. Our goal is to investigate how the
performance changes on downstream tasks when scaling with different sizes of
data and models. The study reveals that: 1) MIM can be viewed as an effective
method to improve the model capacity when the scale of the training data is
relatively small; 2) Strong reconstruction targets can endow the models with
increased capacities on downstream tasks; 3) MIM pre-training is data-agnostic
under most scenarios, which means that the strategy of sampling pre-training
data is non-critical. We hope these observations could provide valuable
insights for future research on MIM.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Robust Classification via a Single Diffusion Model</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15241</p>
  <p><b>作者</b>：Huanran Chen,  Yinpeng Dong,  Zhengyi Wang,  Xiao Yang,  Chengqi Duan,  Hang Su,  Jun Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating realistic data, diffusion models, successfully applied, applied to improving, noises or generating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, diffusion models have been successfully applied to improving
adversarial robustness of image classifiers by purifying the adversarial noises
or generating realistic data for adversarial training. However, the
diffusion-based purification can be evaded by stronger adaptive attacks while
adversarial training does not perform well under unseen threats, exhibiting
inevitable limitations of these methods. To better harness the expressive power
of diffusion models, in this paper we propose Robust Diffusion Classifier
(RDC), a generative classifier that is constructed from a pre-trained diffusion
model to be adversarially robust. Our method first maximizes the data
likelihood of a given input and then predicts the class probabilities of the
optimized input using the conditional likelihood of the diffusion model through
Bayes' theorem. Since our method does not require training on particular
adversarial attacks, we demonstrate that it is more generalizable to defend
against multiple unseen threats. In particular, RDC achieves $73.24\%$ robust
accuracy against $\ell_\infty$ norm-bounded perturbations with
$\epsilon_\infty=8/255$ on CIFAR-10, surpassing the previous state-of-the-art
adversarial training models by $+2.34\%$. The findings highlight the potential
of generative classifiers by employing diffusion models for adversarial
robustness compared with the commonly studied discriminative classifiers.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Real time dense anomaly detection by learning on synthetic negative data</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15227</p>
  <p><b>作者</b>：Anja Delić,  Matej Grcić,  Siniša Šegvić</p>
  <p><b>备注</b>：3 pages</p>
  <p><b>关键词</b>：dense anomaly detection, anomaly detection rely, approaches to dense, dense anomaly, anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most approaches to dense anomaly detection rely on generative modeling or on
discriminative methods that train with negative data. We consider a recent
hybrid method that optimizes the same shared representation according to
cross-entropy of the discriminative predictions, and negative log likelihood of
the predicted energy-based density. We extend that work with a jointly trained
generative flow that samples synthetic negatives at the border of the inlier
distribution. The proposed extension provides potential to learn the hybrid
method without real negative data. Our experiments analyze the impact of
training with synthetic negative data and validate contribution of the
energy-based density during training and evaluation.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：DynStatF: An Efficient Feature Fusion Strategy for LiDAR 3D Object  Detection</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15219</p>
  <p><b>作者</b>：Yao Rong,  Xiangyu Wei,  Tianwei Lin,  Yueyu Wang,  Enkelejda Kasneci</p>
  <p><b>备注</b>：Accepted to CVPR2023 Workshop on End-to-End Autonomous Driving</p>
  <p><b>关键词</b>：Augmenting LiDAR input, multiple previous frames, richer semantic information, inaccurate point projection, precise position information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Augmenting LiDAR input with multiple previous frames provides richer semantic
information and thus boosts performance in 3D object detection, However,
crowded point clouds in multi-frames can hurt the precise position information
due to the motion blur and inaccurate point projection. In this work, we
propose a novel feature fusion strategy, DynStaF (Dynamic-Static Fusion), which
enhances the rich semantic information provided by the multi-frame (dynamic
branch) with the accurate location information from the current single-frame
(static branch). To effectively extract and aggregate complimentary features,
DynStaF contains two modules, Neighborhood Cross Attention (NCA) and
Dynamic-Static Interaction (DSI), operating through a dual pathway
architecture. NCA takes the features in the static branch as queries and the
features in the dynamic branch as keys (values). When computing the attention,
we address the sparsity of point clouds and take only neighborhood positions
into consideration. NCA fuses two features at different feature map scales,
followed by DSI providing the comprehensive interaction. To analyze our
proposed strategy DynStaF, we conduct extensive experiments on the nuScenes
dataset. On the test set, DynStaF increases the performance of PointPillars in
NDS by a large margin from 57.7% to 61.6%. When combined with CenterPoint, our
framework achieves 61.0% mAP and 67.7% NDS, leading to state-of-the-art
performance without bells and whistles.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Multi-modal Machine Learning for Vehicle Rating Predictions Using Image,  Text, and Parametric Data</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15218</p>
  <p><b>作者</b>：Hanqi Su,  Binyang Song,  Faez Ahmed</p>
  <p><b>备注</b>：The paper submitted to IDETC/CIE2023, the International Design Engineering Technical Conferences & Computers and Information in Engineering Conference, has been accepted</p>
  <p><b>关键词</b>：configuring good vehicles, facilitate designing, designing and configuring, configuring good, Accurate vehicle rating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate vehicle rating prediction can facilitate designing and configuring
good vehicles. This prediction allows vehicle designers and manufacturers to
optimize and improve their designs in a timely manner, enhance their product
performance, and effectively attract consumers. However, most of the existing
data-driven methods rely on data from a single mode, e.g., text, image, or
parametric data, which results in a limited and incomplete exploration of the
available information. These methods lack comprehensive analyses and
exploration of data from multiple modes, which probably leads to inaccurate
conclusions and hinders progress in this field. To overcome this limitation, we
propose a multi-modal learning model for more comprehensive and accurate
vehicle rating predictions. Specifically, the model simultaneously learns
features from the parametric specifications, text descriptions, and images of
vehicles to predict five vehicle rating scores, including the total score,
critics score, performance score, safety score, and interior score. We compare
the multi-modal learning model to the corresponding unimodal models and find
that the multi-modal model's explanatory power is 4% - 12% higher than that of
the unimodal models. On this basis, we conduct sensitivity analyses using SHAP
to interpret our model and provide design and optimization directions to
designers and manufacturers. Our study underscores the importance of the
data-driven multi-modal learning approach for vehicle design, evaluation, and
optimization. We have made the code publicly available at
this http URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：L-CAD: Language-based Colorization with Any-level Descriptions</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15217</p>
  <p><b>作者</b>：Zheng Chang,  Shuchen Weng,  Peixuan Zhang,  Yu Li,  Si Li,  Boxin Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visually pleasing colors, user-friendly natural language, colorization produces plausible, produces plausible, plausible and visually</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language-based colorization produces plausible and visually pleasing colors
under the guidance of user-friendly natural language descriptions. Previous
methods implicitly assume that users provide comprehensive color descriptions
for most of the objects in the image, which leads to suboptimal performance. In
this paper, we propose a unified model to perform language-based colorization
with any-level descriptions. We leverage the pretrained cross-modality
generative model for its robust language understanding and rich color priors to
handle the inherent ambiguity of any-level descriptions. We further design
modules to align with input conditions to preserve local spatial structures and
prevent the ghosting effect. With the proposed novel sampling strategy, our
model achieves instance-aware colorization in diverse and complex scenarios.
Extensive experimental results demonstrate our advantages of effectively
handling any-level descriptions and outperforming both language-based and
automatic colorization methods. The code and pretrained models are available
at: this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：GTNet: Graph Transformer Network for 3D Point Cloud Classification and  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15213</p>
  <p><b>作者</b>：Wei Zhou,  Qian Wang,  Weiwei Jin,  Xinzhe Shi,  Dekui Wang,  Xingxing Hao,  Yongxiang Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated excellent performances, Local Transformer, Transformer, Transformer-based deep learning, local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, graph-based and Transformer-based deep learning networks have
demonstrated excellent performances on various point cloud tasks. Most of the
existing graph methods are based on static graph, which take a fixed input to
establish graph relations. Moreover, many graph methods apply maximization and
averaging to aggregate neighboring features, so that only a single neighboring
point affects the feature of centroid or different neighboring points have the
same influence on the centroid's feature, which ignoring the correlation and
difference between points. Most Transformer-based methods extract point cloud
features based on global attention and lack the feature learning on local
neighbors. To solve the problems of these two types of models, we propose a new
feature extraction block named Graph Transformer and construct a 3D point point
cloud learning network called GTNet to learn features of point clouds on local
and global patterns. Graph Transformer integrates the advantages of graph-based
and Transformer-based methods, and consists of Local Transformer and Global
Transformer modules. Local Transformer uses a dynamic graph to calculate all
neighboring point weights by intra-domain cross-attention with dynamically
updated graph relations, so that every neighboring point could affect the
features of centroid with different weights; Global Transformer enlarges the
receptive field of Local Transformer by a global self-attention. In addition,
to avoid the disappearance of the gradient caused by the increasing depth of
network, we conduct residual connection for centroid features in GTNet; we also
adopt the features of centroid and neighbors to generate the local geometric
descriptors in Local Transformer to strengthen the local information learning
capability of the model. Finally, we use GTNet for shape classification, part
segmentation and semantic segmentation tasks in this paper.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Promoting Generalization in Cross-Dataset Remote Photoplethysmography</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15199</p>
  <p><b>作者</b>：Nathan Vance,  Jeremy Speth,  Benjamin Sporrer,  Patrick Flynn</p>
  <p><b>备注</b>：8 pages, accepted for publication at CVPM 2023</p>
  <p><b>关键词</b>：Remote Photoplethysmography, deep learning models, subject heart rate, remote monitoring, shift from handcrafted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remote Photoplethysmography (rPPG), or the remote monitoring of a subject's
heart rate using a camera, has seen a shift from handcrafted techniques to deep
learning models. While current solutions offer substantial performance gains,
we show that these models tend to learn a bias to pulse wave features inherent
to the training dataset. We develop augmentations to mitigate this learned bias
by expanding both the range and variability of heart rates that the model sees
while training, resulting in improved model convergence when training and
cross-dataset generalization at test time. Through a 3-way cross dataset
analysis we demonstrate a reduction in mean absolute error from over 13 beats
per minute to below 3 beats per minute. We compare our method with other recent
rPPG systems, finding similar performance under a variety of evaluation
parameters.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion  Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15194</p>
  <p><b>作者</b>：Sungnyun Kim,  Junsoo Lee,  Kibeom Hong,  Daesik Kim,  Namhyuk Ahn</p>
  <p><b>备注</b>：18 pages, 16 figures, and 3 tables</p>
  <p><b>关键词</b>：significantly expanded generative, expanded generative capabilities, progress in diffusion-based, recent progress, significantly expanded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent progress in diffusion-based text-to-image generation models has
significantly expanded generative capabilities via conditioning the text
descriptions. However, since relying solely on text prompts is still
restrictive for fine-grained customization, we aim to extend the boundaries of
conditional generation to incorporate diverse types of modalities, e.g.,
sketch, box, and style embedding, simultaneously. We thus design a multimodal
text-to-image diffusion model, coined as DiffBlender, that achieves the
aforementioned goal in a single model by training only a few small
hypernetworks. DiffBlender facilitates a convenient scaling of input
modalities, without altering the parameters of an existing large-scale
generative model to retain its well-established knowledge. Furthermore, our
study sets new standards for multimodal generation by conducting quantitative
and qualitative comparisons with existing approaches. By diversifying the
channels of conditioning modalities, DiffBlender faithfully reflects the
provided information or, in its absence, creates imaginative generation.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Deceptive-NeRF: Enhancing NeRF Reconstruction using Pseudo-Observations  from Diffusion Models</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15171</p>
  <p><b>作者</b>：Xinhang Liu,  Shiu-hong Kao,  Jiaben Chen,  Yu-Wing Tai,  Chi-Keung Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper introduces Deceptive-NeRF, removing floater artifacts, synthetically generated pseudo-observations, handling sparse input, introduces Deceptive-NeRF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces Deceptive-NeRF, a new method for enhancing the quality
of reconstructed NeRF models using synthetically generated pseudo-observations,
capable of handling sparse input and removing floater artifacts. Our proposed
method involves three key steps: 1) reconstruct a coarse NeRF model from sparse
inputs; 2) generate pseudo-observations based on the coarse model; 3) refine
the NeRF model using pseudo-observations to produce a high-quality
reconstruction. To generate photo-realistic pseudo-observations that faithfully
preserve the identity of the reconstructed scene while remaining consistent
with the sparse inputs, we develop a rectification latent diffusion model that
generates images conditional on a coarse RGB image and depth map, which are
derived from the coarse NeRF and latent text embedding from input images.
Extensive experiments show that our method is effective and can generate
perceptually high-quality NeRF even with very sparse inputs.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Clinically Labeled Contrastive Learning for OCT Biomarker Classification</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15154</p>
  <p><b>作者</b>：Kiran Kokilepersaud,  Stephanie Trejo Corona,  Mohit Prabhushankar,  Ghassan AlRegib,  Charles Wykoff</p>
  <p><b>备注</b>：Accepted in IEEE Journal of Biomedical and Health Informatics. arXiv admin note: text overlap with arXiv:2211.05092</p>
  <p><b>关键词</b>：set selection strategy, medical images based, negative set selection, paper presents, set selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel positive and negative set selection strategy for
contrastive learning of medical images based on labels that can be extracted
from clinical data. In the medical field, there exists a variety of labels for
data that serve different purposes at different stages of a diagnostic and
treatment process. Clinical labels and biomarker labels are two examples. In
general, clinical labels are easier to obtain in larger quantities because they
are regularly collected during routine clinical care, while biomarker labels
require expert analysis and interpretation to obtain. Within the field of
ophthalmology, previous work has shown that clinical values exhibit
correlations with biomarker structures that manifest within optical coherence
tomography (OCT) scans. We exploit this relationship by using the clinical data
as pseudo-labels for our data without biomarker labels in order to choose
positive and negative instances for training a backbone network with a
supervised contrastive loss. In this way, a backbone network learns a
representation space that aligns with the clinical data distribution available.
Afterwards, we fine-tune the network trained in this manner with the smaller
amount of biomarker labeled data with a cross-entropy loss in order to classify
these key indicators of disease directly from OCT scans. We also expand on this
concept by proposing a method that uses a linear combination of clinical
contrastive losses. We benchmark our methods against state of the art
self-supervised methods in a novel setting with biomarkers of varying
granularity. We show performance improvements by as much as 5\% in total
biomarker detection AUROC.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Reliability Scores from Saliency Map Clusters for Improved Image-based  Harvest-Readiness Prediction in Cauliflower</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15149</p>
  <p><b>作者</b>：Jana Kierdorf,  Ribana Roscher</p>
  <p><b>备注</b>：Preprint, 8 pages, 6 figures</p>
  <p><b>关键词</b>：fulfill high-quality standards, harvest important, hand-harvested crop, fulfill high-quality, high-quality standards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cauliflower is a hand-harvested crop that must fulfill high-quality standards
in sales making the timing of harvest important. However, accurately
determining harvest-readiness can be challenging due to the cauliflower head
being covered by its canopy. While deep learning enables automated
harvest-readiness estimation, errors can occur due to field-variability and
limited training data. In this paper, we analyze the reliability of a
harvest-readiness classifier with interpretable machine learning. By
identifying clusters of saliency maps, we derive reliability scores for each
classification result using knowledge about the domain and the image
properties. For unseen data, the reliability can be used to (i) inform farmers
to improve their decision-making and (ii) increase the model prediction
accuracy. Using RGB images of single cauliflower plants at different
developmental stages from the GrowliFlower dataset, we investigate various
saliency mapping approaches and find that they result in different quality of
reliability scores. With the most suitable interpretation tool, we adjust the
classification result and achieve a 15.72% improvement of the overall accuracy
to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for
the GrowliFlower dataset.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Networks are Slacking Off: Understanding Generalization Problem in Image  Deraining</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15134</p>
  <p><b>作者</b>：Jinjin Gu,  Xianzheng Ma,  Xiangtao Kong,  Yu Qiao,  Chao Dong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consistently encounter substantial, encounter substantial generalization, substantial generalization issues, laboratory benchmarks, consistently encounter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep deraining networks, while successful in laboratory benchmarks,
consistently encounter substantial generalization issues when deployed in
real-world applications. A prevailing perspective in deep learning encourages
the use of highly complex training data, with the expectation that a richer
image content knowledge will facilitate overcoming the generalization problem.
However, through comprehensive and systematic experimentation, we discovered
that this strategy does not enhance the generalization capability of these
networks. On the contrary, it exacerbates the tendency of networks to overfit
to specific degradations. Our experiments reveal that better generalization in
a deraining network can be achieved by simplifying the complexity of the
training data. This is due to the networks are slacking off during training,
that is, learning the least complex elements in the image content and
degradation to minimize training loss. When the complexity of the background
image is less than that of the rain streaks, the network will prioritize the
reconstruction of the background, thereby avoiding overfitting to the rain
patterns and resulting in improved generalization performance. Our research not
only offers a valuable perspective and methodology for better understanding the
generalization problem in low-level vision tasks, but also displays promising
practical potential.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Thinking Twice: Clinical-Inspired Thyroid Ultrasound Lesion Detection  Based on Feature Feedback</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15114</p>
  <p><b>作者</b>：Lingtao Wang,  Jianrui Ding,  Fenghe Tang,  Chunping Ning</p>
  <p><b>备注</b>：20 pages, 11 figures, released code for this https URL</p>
  <p><b>关键词</b>：critical aspect, aspect of computer-aided, feature, feature feedback, feedback feature selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate detection of thyroid lesions is a critical aspect of computer-aided
diagnosis. However, most existing detection methods perform only one feature
extraction process and then fuse multi-scale features, which can be affected by
noise and blurred features in ultrasound images. In this study, we propose a
novel detection network based on a feature feedback mechanism inspired by
clinical diagnosis. The mechanism involves first roughly observing the overall
picture and then focusing on the details of interest. It comprises two parts: a
feedback feature selection module and a feature feedback pyramid. The feedback
feature selection module efficiently selects the features extracted in the
first phase in both space and channel dimensions to generate high semantic
prior knowledge, which is similar to coarse observation. The feature feedback
pyramid then uses this high semantic prior knowledge to enhance feature
extraction in the second phase and adaptively fuses the two features, similar
to fine observation. Additionally, since radiologists often focus on the shape
and size of lesions for diagnosis, we propose an adaptive detection head
strategy to aggregate multi-scale features. Our proposed method achieves an AP
of 70.3% and AP50 of 99.0% on the thyroid ultrasound dataset and meets the
real-time requirement. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Computer Vision for Construction Progress Monitoring: A Real-Time Object  Detection Approach</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15097</p>
  <p><b>作者</b>：Jiesheng Yang,  Andreas Wilde,  Karsten Menzel,  Md Zubair Sheikh,  Boris Kuznetsov</p>
  <p><b>备注</b>：15 Pages</p>
  <p><b>关键词</b>：effective project management, ensuring on-time, on-budget delivery, essential for effective, on-time and on-budget</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Construction progress monitoring (CPM) is essential for effective project
management, ensuring on-time and on-budget delivery. Traditional CPM methods
often rely on manual inspection and reporting, which are time-consuming and
prone to errors. This paper proposes a novel approach for automated CPM using
state-of-the-art object detection algorithms. The proposed method leverages
e.g. YOLOv8's real-time capabilities and high accuracy to identify and track
construction elements within site images and videos. A dataset was created,
consisting of various building elements and annotated with relevant objects for
training and validation. The performance of the proposed approach was evaluated
using standard metrics, such as precision, recall, and F1-score, demonstrating
significant improvement over existing methods. The integration of Computer
Vision into CPM provides stakeholders with reliable, efficient, and
cost-effective means to monitor project progress, facilitating timely
decision-making and ultimately contributing to the successful completion of
construction projects.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance  Fields</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15094</p>
  <p><b>作者</b>：Dongqing Wang,  Tong Zhang,  Alaa Abboud,  Sabine Süsstrunk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate highly realistic, Neural Radiance Fields, generate highly, highly realistic, Radiance Fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) can generate highly realistic novel views.
However, editing 3D scenes represented by NeRF across 360-degree views,
particularly removing objects while preserving geometric and photometric
consistency, remains a challenging problem due to NeRF's implicit scene
representation. In this paper, we propose InpaintNeRF360, a unified framework
that utilizes natural language instructions as guidance for inpainting
NeRF-based 3D scenes.Our approach employs a promptable segmentation model by
generating multi-modal prompts from the encoded text for multiview
segmentation. We apply depth-space warping to enforce viewing consistency in
the segmentations, and further refine the inpainted NeRF model using perceptual
priors to ensure visual plausibility. InpaintNeRF360 is capable of
simultaneously removing multiple objects or modifying object appearance based
on text instructions while synthesizing 3D viewing-consistent and
photo-realistic inpainting. Through extensive experiments on both unbounded and
frontal-facing scenes trained through NeRF, we demonstrate the effectiveness of
our approach and showcase its potential to enhance the editability of implicit
radiance fields.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Modeling Complex Object Changes in Satellite Image Time-Series: Approach  based on CSP and Spatiotemporal Graph</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15091</p>
  <p><b>作者</b>：Zouhayra Ayadi,  Wadii Boulila,  Imed Riadh Farah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex geographic objects, spatiotemporal graph, complex objects, spatiotemporal, constraint network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a method for automatically monitoring and analyzing the
evolution of complex geographic objects. The objects are modeled as a
spatiotemporal graph, which separates filiation relations, spatial relations,
and spatiotemporal relations, and is analyzed by detecting frequent sub-graphs
using constraint satisfaction problems (CSP). The process is divided into four
steps: first, the identification of complex objects in each satellite image;
second, the construction of a spatiotemporal graph to model the spatiotemporal
changes of the complex objects; third, the creation of sub-graphs to be
detected in the base spatiotemporal graph; and fourth, the analysis of the
spatiotemporal graph by detecting the sub-graphs and solving a constraint
network to determine relevant sub-graphs. The final step is further broken down
into two sub-steps: (i) the modeling of the constraint network with defined
variables and constraints, and (ii) the solving of the constraint network to
find relevant sub-graphs in the spatiotemporal graph. Experiments were
conducted using real-world satellite images representing several cities in
Saudi Arabia, and the results demonstrate the effectiveness of the proposed
approach.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Pento-DIARef: A Diagnostic Dataset for Learning the Incremental  Algorithm for Referring Expression Generation from Examples</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15087</p>
  <p><b>作者</b>：Philipp Sadler,  David Schlangen</p>
  <p><b>备注</b>：9 pages, Accepted to EACL 2023</p>
  <p><b>关键词</b>：typically defined extensionally, NLP tasks, pairs of image, recognised and understood, typically defined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>NLP tasks are typically defined extensionally through datasets containing
example instantiations (e.g., pairs of image i and text t), but motivated
intensionally through capabilities invoked in verbal descriptions of the task
(e.g., "t is a description of i, for which the content of i needs to be
recognised and understood"). We present Pento-DIARef, a diagnostic dataset in a
visual domain of puzzle pieces where referring expressions are generated by a
well-known symbolic algorithm (the "Incremental Algorithm"), which itself is
motivated by appeal to a hypothesised capability (eliminating distractors
through application of Gricean maxims). Our question then is whether the
extensional description (the dataset) is sufficient for a neural model to pick
up the underlying regularity and exhibit this capability given the simple task
definition of producing expressions from visual inputs. We find that a model
supported by a vision detection step and a targeted data generation scheme
achieves an almost perfect BLEU@1 score and sentence accuracy, whereas simpler
baselines do not.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Unpaired Image-to-Image Translation via Neural Schrödinger Bridge</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15086</p>
  <p><b>作者</b>：Beomsu Kim,  Gihyun Kwon,  Kwanyoung Kim,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic differential equations, simulate stochastic differential, differential equations, powerful class, class of generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models are a powerful class of generative models which simulate
stochastic differential equations (SDEs) to generate data from noise. Although
diffusion models have achieved remarkable progress in recent years, they have
limitations in the unpaired image-to-image translation tasks due to the
Gaussian prior assumption. Schrödinger Bridge (SB), which learns an SDE to
translate between two arbitrary distributions, have risen as an attractive
solution to this problem. However, none of SB models so far have been
successful at unpaired translation between high-resolution images. In this
work, we propose the Unpaired Neural Schrödinger Bridge (UNSB), which
combines SB with adversarial training and regularization to learn a SB between
unpaired data. We demonstrate that UNSB is scalable, and that it successfully
solves various unpaired image-to-image translation tasks. Code:
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Audio-Visual Dataset and Method for Anomaly Detection in Traffic Videos</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15084</p>
  <p><b>作者</b>：Błażej Leporowski,  Arian Bakhtiarnia,  Nicole Bonnici,  Adrian Muscat,  Luca Zanella,  Yiming Wang,  Alexandros Iosifidis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traffic anomaly detection, called MAVAD, real-world scenes, illumination conditions, audio-visual dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the first audio-visual dataset for traffic anomaly detection
taken from real-world scenes, called MAVAD, with a diverse range of weather and
illumination conditions. In addition, we propose a novel method named AVACA
that combines visual and audio features extracted from video sequences by means
of cross-attention to detect anomalies. We demonstrate that the addition of
audio improves the performance of AVACA by up to 5.2%. We also evaluate the
impact of image anonymization, showing only a minor decrease in performance
averaging at 1.7%.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Learning INR for Event-guided Rolling Shutter Frame Correction, Deblur,  and Interpolation</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15078</p>
  <p><b>作者</b>：Yunfan Lu,  Guoqiang Liang,  Lin Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feasible solutions exist, fast camera motion, obvious image distortions, frame interpolation Taking, rolling shutter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Images captured by rolling shutter (RS) cameras under fast camera motion
often contain obvious image distortions and blur, which can be modeled as a
row-wise combination of a sequence of global shutter (GS) frames within the
exposure time naturally, recovering high-frame-rate GS sharp frames from an RS
blur image needs to simultaneously consider RS correction, deblur, and frame
interpolation Taking this task is nontrivial, and to our knowledge, no feasible
solutions exist by far. A naive way is to decompose the complete process into
separate tasks and simply cascade existing methods; however, this results in
cumulative errors and noticeable artifacts. Event cameras enjoy many
advantages, e.g., high temporal resolution, making them potential for our
problem. To this end, we make the first attempt to recover high-frame-rate
sharp GS frames from an RS blur image and paired event data. Our key idea is to
learn an implicit neural representation (INR) to directly map the position and
time coordinates to RGB values to address the interlocking degradations in the
image restoration process. Specifically, we introduce spatial-temporal implicit
encoding (STE) to convert an RS blur image and events into a spatial-temporal
representation (STR). To query a specific sharp frame (GS or RS), we embed the
exposure time into STR and decode the embedded features to recover a sharp
frame. Moreover, we propose an RS blur image-guided integral loss to better
train the network. Our method is relatively lightweight as it contains only
0.379M parameters and demonstrates high efficiency as the STE is called only
once for any number of interpolation frames. Extensive experiments show that
our method significantly outperforms prior methods addressing only one or two
of the tasks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：PathAsst: Redefining Pathology through Generative Foundation AI  Assistant for Pathology</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15072</p>
  <p><b>作者</b>：Yuxuan Sun,  Chenglu Zhu,  Sunyi Zheng,  Kai Zhang,  Zhongyi Shui,  Xiaoxuan Yu,  Yizhi Zhao,  Honglin Li,  Yunlong Zhang,  Ruojia Zhao,  Xinheng Lyu,  Lin Yang</p>
  <p><b>备注</b>：13 pages, 5 figures, conference</p>
  <p><b>关键词</b>：general-purpose multimodal large, multimodal techniques continue, multimodal large language, large language models, multimodal large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As advances in large language models (LLMs) and multimodal techniques
continue to mature, the development of general-purpose multimodal large
language models (MLLMs) has surged, with significant applications in natural
image interpretation. However, the field of pathology has largely remained
untapped in this regard, despite the growing need for accurate, timely, and
personalized diagnostics. To bridge the gap in pathology MLLMs, we present the
PathAsst in this study, which is a generative foundation AI assistant to
revolutionize diagnostic and predictive analytics in pathology. To develop
PathAsst, we collect over 142K high-quality pathology image-text pairs from a
variety of reliable sources, including PubMed, comprehensive pathology
textbooks, reputable pathology websites, and private data annotated by
pathologists. Leveraging the advanced capabilities of ChatGPT/GPT-4, we
generate over 180K instruction-following samples. Furthermore, we devise
additional instruction-following data, specifically tailored for the invocation
of the pathology-specific models, allowing the PathAsst to effectively interact
with these models based on the input image and user intent, consequently
enhancing the model's diagnostic capabilities. Subsequently, our PathAsst is
trained based on Vicuna-13B language model in coordination with the CLIP vision
encoder. The results of PathAsst show the potential of harnessing the
AI-powered generative foundation model to improve pathology diagnosis and
treatment processes. We are committed to open-sourcing our meticulously curated
dataset, as well as a comprehensive toolkit designed to aid researchers in the
extensive collection and preprocessing of their own datasets. Resources can be
obtained at
this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Jointly Optimizing Image Compression with Low-light Image Enhancement</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15030</p>
  <p><b>作者</b>：Shilv Cai,  Xu Zou,  Liqun Chen,  Luxin Yan,  Sheng Zhong</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2303.06705 by other authors</p>
  <p><b>关键词</b>：made great progress, low-light images, Learning-based image compression, image compression, low-light image enhancement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning-based image compression methods have made great progress. Most of
them are designed for generic natural images. In fact, low-light images
frequently occur due to unavoidable environmental influences or technical
limitations, such as insufficient lighting or limited exposure time. %When
general-purpose image compression algorithms compress low-light images, useful
detail information is lost, resulting in a dramatic decrease in image
enhancement. Once low-light images are compressed by existing general image
compression approaches, useful information(e.g., texture details) would be lost
resulting in a dramatic performance decrease in low-light image enhancement. To
simultaneously achieve a higher compression rate and better enhancement
performance for low-light images, we propose a novel image compression
framework with joint optimization of low-light image enhancement. We design an
end-to-end trainable two-branch architecture with lower computational cost,
which includes the main enhancement branch and the signal-to-noise ratio~(SNR)
aware branch. Experimental results show that our proposed joint optimization
framework achieves a significant improvement over existing ``Compress before
Enhance" or ``Enhance before Compress" sequential solutions for low-light
images. Source codes are included in the supplementary material.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet  Categories</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15028</p>
  <p><b>作者</b>：Heming Xia,  Qingxiu Dong,  Lei Li,  Jingjing Xu,  Ziwei Qin,  Zhifang Sui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual commonsense knowledge, Pretrained Language Models, Pretrained Language, commonsense knowledge, visual commonsense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Pretrained Language Models (PLMs) have been serving as
general-purpose interfaces, posing a significant demand for comprehensive
visual knowledge. However, it remains unclear how well current PLMs and their
visually augmented counterparts (VaLMs) can master visual commonsense
knowledge. To investigate this, we propose ImageNetVC, a fine-grained,
human-annotated dataset specifically designed for zero-shot visual commonsense
evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we delve
into the fundamental visual commonsense knowledge of both unimodal PLMs and
VaLMs, uncovering the scaling law and the influence of the backbone model on
VaLMs. Furthermore, we investigate the factors affecting the visual commonsense
knowledge of large-scale models, providing insights into the development of
language models enriched with visual commonsense knowledge. Our code and
dataset are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Transferring Visual Attributes from Natural Language to Verified Image  Generation</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15026</p>
  <p><b>作者</b>：Rodrigo Valerio,  Joao Bordalo,  Michal Yarom,  Yonattan Bitton,  Idan Szpektor,  Joao Magalhaes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image generation, widely popular, popular in generating, image, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text to image generation methods (T2I) are widely popular in generating art
and other creative artifacts. While visual hallucinations can be a positive
factor in scenarios where creativity is appreciated, such artifacts are poorly
suited for cases where the generated image needs to be grounded in complex
natural language without explicit visual elements. In this paper, we propose to
strengthen the consistency property of T2I methods in the presence of natural
complex language, which often breaks the limits of T2I methods by including
non-visual information, and textual elements that require knowledge for
accurate generation. To address these phenomena, we propose a Natural Language
to Verified Image generation approach (NL2VI) that converts a natural prompt
into a visual prompt, which is more suitable for image generation. A T2I model
then generates an image for the visual prompt, which is then verified with VQA
algorithms. Experimentally, aligning natural prompts with image generation can
improve the consistency of the generated images by up to 11% over the state of
the art. Moreover, improvements can generalize to challenging domains like
cooking and DIY tasks, where the correctness of the generated image is crucial
to illustrate actions.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large  Language Models</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15023</p>
  <p><b>作者</b>：Gen Luo,  Yiyi Zhou,  Tianhe Ren,  Shengxin Chen,  Xiaoshuai Sun,  Rongrong Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial general intelligence, growing interest, general intelligence, aroused in extending, milestone of artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, growing interest has been aroused in extending the multimodal
capability of large language models (LLMs), e.g., vision-language (VL)
learning, which is regarded as the next milestone of artificial general
intelligence. However, existing solutions are prohibitively expensive, which
not only need to optimize excessive parameters, but also require another
large-scale pre-training before VL instruction tuning. In this paper, we
propose a novel and affordable solution for the effective VL adaption of LLMs,
called Mixture-of-Modality Adaptation (MMA). Instead of using large neural
networks to connect the image encoder and LLM, MMA adopts lightweight modules,
i.e., adapters, to bridge the gap between LLMs and VL tasks, which also enables
the joint optimization of the image and language models. Meanwhile, MMA is also
equipped with a routing algorithm to help LLMs achieve an automatic shift
between single- and multi-modal instructions without compromising their ability
of natural language understanding. To validate MMA, we apply it to a recent LLM
called LLaMA and term this formed large vision-language instructed model as
LaVIN. To validate MMA and LaVIN, we conduct extensive experiments under two
setups, namely multimodal science question answering and multimodal dialogue.
The experimental results not only demonstrate the competitive performance and
the superior training efficiency of LaVIN than existing multimodal LLMs, but
also confirm its great potential as a general-purpose chatbot. More
importantly, the actual expenditure of LaVIN is extremely cheap, e.g., only 1.4
training hours with 3.8M trainable parameters, greatly confirming the
effectiveness of MMA. Our project is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15021</p>
  <p><b>作者</b>：Yao Mu,  Qinglong Zhang,  Mengkang Hu,  Wenhai Wang,  Mingyu Ding,  Jun Jin,  Bin Wang,  Jifeng Dai,  Yu Qiao,  Ping Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：executing action sequences, accomplish long-horizon tasks, frontier in robotics, physical environments, Embodied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied AI is a crucial frontier in robotics, capable of planning and
executing action sequences for robots to accomplish long-horizon tasks in
physical environments. In this work, we introduce EmbodiedGPT, an end-to-end
multi-modal foundation model for embodied AI, empowering embodied agents with
multi-modal understanding and execution capabilities. To achieve this, we have
made the following efforts: (i) We craft a large-scale embodied planning
dataset, termed EgoCOT. The dataset consists of carefully selected videos from
the Ego4D dataset, along with corresponding high-quality language instructions.
Specifically, we generate a sequence of sub-goals with the "Chain of Thoughts"
mode for effective embodied planning. (ii) We introduce an efficient training
approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B
large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We
introduce a paradigm for extracting task-related features from LLM-generated
planning queries to form a closed loop between high-level planning and
low-level control. Extensive experiments show the effectiveness of EmbodiedGPT
on embodied tasks, including embodied planning, embodied control, visual
captioning, and visual question answering. Notably, EmbodiedGPT significantly
enhances the success rate of the embodied control task by extracting more
effective features. It has achieved a remarkable 1.6 times increase in success
rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World
benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Measuring Faithful and Plausible Visual Grounding in VQA</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15015</p>
  <p><b>作者</b>：Daniel Reich,  Felix Putze,  Tanja Schultz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Visual Question Answering, Question Answering, systems primarily aim, Visual Question, Visual Grounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Metrics for Visual Grounding (VG) in Visual Question Answering (VQA) systems
primarily aim to measure a system's reliance on relevant parts of the image
when inferring an answer to the given question. Lack of VG has been a common
problem among state-of-the-art VQA systems and can manifest in over-reliance on
irrelevant image parts or a disregard for the visual modality entirely.
Although inference capabilities of VQA models are often illustrated by a few
qualitative illustrations, most systems are not quantitatively assessed for
their VG properties. We believe, an easily calculated criterion for
meaningfully measuring a system's VG can help remedy this shortcoming, as well
as add another valuable dimension to model evaluations and analysis. To this
end, we propose a new VG metric that captures if a model a) identifies
question-relevant objects in the scene, and b) actually relies on the
information contained in the relevant objects when producing its answer, i.e.,
if its visual grounding is both "faithful" and "plausible". Our metric, called
"Faithful and Plausible Visual Grounding" (FPVG), is straightforward to
determine for most VQA model designs.
We give a detailed description of FPVG and evaluate several reference systems
spanning various VQA architectures. Code to support the metric calculations on
the GQA data set is available on GitHub.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Contrastive Training of Complex-Valued Autoencoders for Object Discovery</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15001</p>
  <p><b>作者</b>：Aleksandar Stanić,  Anand Gopalakrishnan,  Kazuki Irie,  Jürgen Schmidhuber</p>
  <p><b>备注</b>：26 pages, 14 figures</p>
  <p><b>关键词</b>：attention-based routing, object-centric models, slots, Synchrony-based models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current state-of-the-art object-centric models use slots and attention-based
routing for binding. However, this class of models has several conceptual
limitations: the number of slots is hardwired; all slots have equal capacity;
training has high computational cost; there are no object-level relational
factors within slots. Synchrony-based models in principle can address these
limitations by using complex-valued activations which store binding information
in their phase components. However, working examples of such synchrony-based
models have been developed only very recently, and are still limited to toy
grayscale datasets and simultaneous storage of less than three objects in
practice. Here we introduce architectural modifications and a novel contrastive
learning method that greatly improve the state-of-the-art synchrony-based
model. For the first time, we obtain a class of synchrony-based models capable
of discovering objects in an unsupervised manner in multi-object color datasets
and simultaneously representing more than three objects</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14998</p>
  <p><b>作者</b>：Saba Ahmadi,  Aishwarya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：UMIC, Hessel, CLIPScore, human judgment, correlation with human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and
UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image
captions, demonstrating a high correlation with human judgment. In this work,
our focus lies in evaluating the robustness of these metrics in scenarios that
require distinguishing between two captions with high lexical overlap but very
different meanings. Our findings reveal that despite their high correlation
with human judgment, both CLIPScore and UMIC struggle to identify fine-grained
errors in captions. However, when comparing different types of fine-grained
errors, both metrics exhibit limited sensitivity to implausibility of captions
and strong sensitivity to lack of sufficient visual grounding. Probing further
into the visual grounding aspect, we found that both CLIPScore and UMIC are
impacted by the size of image-relevant objects mentioned in the caption, and
that CLIPScore is also sensitive to the number of mentions of image-relevant
objects in the caption. In terms of linguistic aspects of a caption, we found
that both metrics lack the ability to comprehend negation, UMIC is sensitive to
caption lengths, and CLIPScore is insensitive to the structure of the sentence.
We hope our findings will serve as a valuable guide towards improving
reference-free evaluation in image captioning.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Non-adversarial Robustness of Deep Learning Methods for Computer Vision</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14986</p>
  <p><b>作者</b>：Gorana Gojić,  Vladimir Vincan,  Ognjen Kundačina,  Dragiša Mišković,  Dinu Dragan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distribution shifts caused, distribution shifts, natural variations, data distribution shifts, shifts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-adversarial robustness, also known as natural robustness, is a property
of deep learning models that enables them to maintain performance even when
faced with distribution shifts caused by natural variations in data. However,
achieving this property is challenging because it is difficult to predict in
advance the types of distribution shifts that may occur. To address this
challenge, researchers have proposed various approaches, some of which
anticipate potential distribution shifts, while others utilize knowledge about
the shifts that have already occurred to enhance model generalizability. In
this paper, we present a brief overview of the most recent techniques for
improving the robustness of computer vision methods, as well as a summary of
commonly used robustness benchmark datasets for evaluating the model's
performance under data distribution shifts. Finally, we examine the strengths
and limitations of the approaches reviewed and identify general trends in deep
learning robustness improvement for computer vision.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：IdealGPT: Iteratively Decomposing Vision and Language Reasoning via  Large Language Models</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14985</p>
  <p><b>作者</b>：Haoxuan You,  Rui Sun,  Zhecan Wang,  Long Chen,  Gengyu Wang,  Hammad A. Ayyubi,  Kai-Wei Chang,  Shih-Fu Chang</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：made unprecedented progress, understanding has made, made unprecedented, unprecedented progress, final answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of vision-and-language (VL) understanding has made unprecedented
progress with end-to-end large pre-trained VL models (VLMs). However, they
still fall short in zero-shot reasoning tasks that require multi-step
inferencing. To achieve this goal, previous works resort to a
divide-and-conquer pipeline. In this paper, we argue that previous efforts have
several inherent shortcomings: 1) They rely on domain-specific sub-question
decomposing models. 2) They force models to predict the final answer even if
the sub-questions or sub-answers provide insufficient information. We address
these limitations via IdealGPT, a framework that iteratively decomposes VL
reasoning using large language models (LLMs). Specifically, IdealGPT utilizes
an LLM to generate sub-questions, a VLM to provide corresponding sub-answers,
and another LLM to reason to achieve the final answer. These three modules
perform the divide-and-conquer procedure iteratively until the model is
confident about the final answer to the main question. We evaluate IdealGPT on
multiple challenging VL reasoning tasks under a zero-shot setting. In
particular, our IdealGPT outperforms the best existing GPT-4-like models by an
absolute 10% on VCR and 15% on SNLI-VE. Code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Scale Matters: Attribution Meets the Wavelet Domain to Explain Model  Sensitivity to Image Corruptions</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14979</p>
  <p><b>作者</b>：Gabriel Kasmi,  Laurent Dubus,  Yves-Marie Saint Drenan,  Philippe Blanc</p>
  <p><b>备注</b>：main: 9 pages, appendix 19 pages, 32 figures, 5 tables</p>
  <p><b>关键词</b>：shown remarkable performance, image corruptions, Neural networks, computer vision, networks have shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have shown remarkable performance in computer vision, but
their deployment in real-world scenarios is challenging due to their
sensitivity to image corruptions. Existing attribution methods are
uninformative for explaining the sensitivity to image corruptions, while the
literature on robustness only provides model-based explanations. However, the
ability to scrutinize models' behavior under image corruptions is crucial to
increase the user's trust. Towards this end, we introduce the Wavelet sCale
Attribution Method (WCAM), a generalization of attribution from the pixel
domain to the space-scale domain. Attribution in the space-scale domain reveals
where and on what scales the model focuses. We show that the WCAM explains
models' failures under image corruptions, identifies sufficient information for
prediction, and explains how zoom-in increases accuracy.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Sampling-based Uncertainty Estimation for an Instance Segmentation  Network</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14977</p>
  <p><b>作者</b>：Florian Heidecker,  Ahmad El-Khateeb,  Bernhard Sick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：receiving increasing attention, machine learning, increasing attention, receiving increasing, Bayesian Gaussian Mixture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The examination of uncertainty in the predictions of machine learning (ML)
models is receiving increasing attention. One uncertainty modeling technique
used for this purpose is Monte-Carlo (MC)-Dropout, where repeated predictions
are generated for a single input. Therefore, clustering is required to describe
the resulting uncertainty, but only through efficient clustering is it possible
to describe the uncertainty from the model attached to each object. This
article uses Bayesian Gaussian Mixture (BGM) to solve this problem. In
addition, we investigate different values for the dropout rate and other
techniques, such as focal loss and calibration, which we integrate into the
Mask-RCNN model to obtain the most accurate uncertainty approximation of each
instance and showcase it graphically.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：MMNet: Multi-Mask Network for Referring Image Segmentation</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14969</p>
  <p><b>作者</b>：Yichen Yan,  Xingjian He,  Wenxuan Wan,  Jing Liu</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：natural language expression, image segmentation aims, language expression, Referring image segmentation, aims to segment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Referring image segmentation aims to segment an object referred to by natural
language expression from an image. However, this task is challenging due to the
distinct data properties between text and image, and the randomness introduced
by diverse objects and unrestricted language expression. Most of previous work
focus on improving cross-modal feature fusion while not fully addressing the
inherent uncertainty caused by diverse objects and unrestricted language. To
tackle these problems, we propose an end-to-end Multi-Mask Network for
referring image segmentation(MMNet). we first combine picture and language and
then employ an attention mechanism to generate multiple queries that represent
different aspects of the language expression. We then utilize these queries to
produce a series of corresponding segmentation masks, assigning a score to each
mask that reflects its importance. The final result is obtained through the
weighted sum of all masks, which greatly reduces the randomness of the language
expression. Our proposed framework demonstrates superior performance compared
to state-of-the-art approaches on the two most commonly used datasets, RefCOCO,
RefCOCO+ and G-Ref, without the need for any post-processing. This further
validates the efficacy of our proposed framework.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：ICDAR 2023 Competition on Robust Layout Segmentation in Corporate  Documents</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14962</p>
  <p><b>作者</b>：Christoph Auer,  Ahmed Nassar,  Maksym Lysak,  Michele Dolfi,  Nikolaos Livathinos,  Peter Staar</p>
  <p><b>备注</b>：ICDAR 2023, 10 pages, 4 figures</p>
  <p><b>关键词</b>：challenging task due, variability in formats, document layout understanding, machine-processable representations, complex structures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transforming documents into machine-processable representations is a
challenging task due to their complex structures and variability in formats.
Recovering the layout structure and content from PDF files or scanned material
has remained a key problem for decades. ICDAR has a long tradition in hosting
competitions to benchmark the state-of-the-art and encourage the development of
novel solutions to document layout understanding. In this report, we present
the results of our \textit{ICDAR 2023 Competition on Robust Layout Segmentation
in Corporate Documents}, which posed the challenge to accurately segment the
page layout in a broad range of document styles and domains, including
corporate reports, technical literature and patents. To raise the bar over
previous competitions, we engineered a hard competition dataset and proposed
the recent DocLayNet dataset for training. We recorded 45 team registrations
and received official submissions from 21 teams. In the presented solutions, we
recognize interesting combinations of recent computer vision models, data
augmentation strategies and ensemble methods to achieve remarkable accuracy in
the task we posed. A clear trend towards adoption of vision-transformer based
methods is evident. The results demonstrate substantial progress towards
achieving robust and highly generalizing methods for document layout
understanding.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：DC-Net: Divide-and-Conquer for Salient Object Detection</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14955</p>
  <p><b>作者</b>：Jiayi Zhu,  Xuebin Qin,  Abdulmotaleb Elsaddik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learn prior knowledge, final saliency map, salient object detection, saliency map, task to enable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce Divide-and-Conquer into the salient object
detection (SOD) task to enable the model to learn prior knowledge that is for
predicting the saliency map. We design a novel network, Divide-and-Conquer
Network (DC-Net) which uses two encoders to solve different subtasks that are
conducive to predicting the final saliency map, here is to predict the edge
maps with width 4 and location maps of salient objects and then aggregate the
feature maps with different semantic information into the decoder to predict
the final saliency map. The decoder of DC-Net consists of our newly designed
two-level Residual nested-ASPP (ResASPP$^{2}$) modules, which have the ability
to capture a large number of different scale features with a small number of
convolution operations and have the advantages of maintaining high resolution
all the time and being able to obtain a large and compact effective receptive
field (ERF). Based on the advantage of Divide-and-Conquer's parallel computing,
we use Parallel Acceleration to speed up DC-Net, allowing it to achieve
competitive performance on six LR-SOD and five HR-SOD datasets under high
efficiency (60 FPS and 55 FPS). Codes and results are available:
this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Dual-Side Feature Fusion 3D Pose Transfer</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14951</p>
  <p><b>作者</b>：Jue Liu,  Feipeng Da</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pose transfer, traditional deformation transfer, pose transfer solves, pose, Fusion Pose Transfer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D pose transfer solves the problem of additional input and correspondence of
traditional deformation transfer, only the source and target meshes need to be
input, and the pose of the source mesh can be transferred to the target mesh.
Some lightweight methods proposed in recent years consume less memory but cause
spikes and distortions for some unseen poses, while others are costly in
training due to the inclusion of large matrix multiplication and adversarial
networks. In addition, the meshes with different numbers of vertices also
increase the difficulty of pose transfer. In this work, we propose a Dual-Side
Feature Fusion Pose Transfer Network to improve the pose transfer accuracy of
the lightweight method. Our method takes the pose features as one of the side
inputs to the decoding network and fuses them into the target mesh layer by
layer at multiple scales. Our proposed Feature Fusion Adaptive Instance
Normalization has the characteristic of having two side input channels that
fuse pose features and identity features as denormalization parameters, thus
enhancing the pose transfer capability of the network. Extensive experimental
results show that our proposed method has stronger pose transfer capability
than state-of-the-art methods while maintaining a lightweight network
structure, and can converge faster.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Incremental Dense Reconstruction from Monocular Video with Guided Sparse  Feature Volume Fusion</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14918</p>
  <p><b>作者</b>：Xingxing Zuo,  Nan Yang,  Nathaniel Merrill,  Binbin Xu,  Stefan Leutenegger</p>
  <p><b>备注</b>：8 pages, 5 figures, RA-L 2023</p>
  <p><b>关键词</b>：Signed Distance Function, Truncated Signed Distance, Incrementally recovering, structures from monocular, monocular videos</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incrementally recovering 3D dense structures from monocular videos is of
paramount importance since it enables various robotics and AR applications.
Feature volumes have recently been shown to enable efficient and accurate
incremental dense reconstruction without the need to first estimate depth, but
they are not able to achieve as high of a resolution as depth-based methods due
to the large memory consumption of high-resolution feature volumes. This letter
proposes a real-time feature volume-based dense reconstruction method that
predicts TSDF (Truncated Signed Distance Function) values from a novel
sparsified deep feature volume, which is able to achieve higher resolutions
than previous feature volume-based methods, and is favorable in large-scale
outdoor scenarios where the majority of voxels are empty. An uncertainty-aware
multi-view stereo (MVS) network is leveraged to infer initial voxel locations
of the physical surface in a sparse feature volume. Then for refining the
recovered 3D geometry, deep features are attentively aggregated from multiview
images at potential surface locations, and temporally fused. Besides achieving
higher resolutions than before, our method is shown to produce more complete
reconstructions with finer detail in many cases. Extensive evaluations on both
public and self-collected datasets demonstrate a very competitive real-time
reconstruction result for our method compared to state-of-the-art
reconstruction methods in both indoor and outdoor settings.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：GAMUS: A Geometry-aware Multi-modal Semantic Segmentation Benchmark for  Remote Sensing Data</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14914</p>
  <p><b>作者</b>：Zhitong Xiong,  Sining Chen,  Yi Wang,  Lichao Mou,  Xiao Xiang Zhu</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：normalized digital surface, digital surface models, remote sensing data, Geometric information, land cover</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geometric information in the normalized digital surface models (nDSM) is
highly correlated with the semantic class of the land cover. Exploiting two
modalities (RGB and nDSM (height)) jointly has great potential to improve the
segmentation performance. However, it is still an under-explored field in
remote sensing due to the following challenges. First, the scales of existing
datasets are relatively small and the diversity of existing datasets is
limited, which restricts the ability of validation. Second, there is a lack of
unified benchmarks for performance assessment, which leads to difficulties in
comparing the effectiveness of different models. Last, sophisticated
multi-modal semantic segmentation methods have not been deeply explored for
remote sensing data. To cope with these challenges, in this paper, we introduce
a new remote-sensing benchmark dataset for multi-modal semantic segmentation
based on RGB-Height (RGB-H) data. Towards a fair and comprehensive analysis of
existing methods, the proposed benchmark consists of 1) a large-scale dataset
including co-registered RGB and nDSM pairs and pixel-wise semantic labels; 2) a
comprehensive evaluation and analysis of existing multi-modal fusion strategies
for both convolutional and Transformer-based networks on remote sensing data.
Furthermore, we propose a novel and effective Transformer-based intermediary
multi-modal fusion (TIMF) module to improve the semantic segmentation
performance through adaptive token-level multi-modal fusion.The designed
benchmark can foster future research on developing new methods for multi-modal
learning on remote sensing data. Extensive analyses of those methods are
conducted and valuable insights are provided through the experimental results.
Code for the benchmark and baselines can be accessed at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Text encoders are performance bottlenecks in contrastive vision-language  models</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14897</p>
  <p><b>作者</b>：Amita Kamath,  Jack Hessel,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Performant vision-language, CLIP represent captions, CLIP represent, single vector, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Performant vision-language (VL) models like CLIP represent captions using a
single vector. How much information about language is lost in this bottleneck?
We first curate CompPrompts, a set of increasingly compositional image captions
that VL models should be able to capture (e.g., single object, to
object+property, to multiple interacting objects). Then, we train text-only
recovery probes that aim to reconstruct captions from single-vector text
representations produced by several VL models. This approach doesn't require
images, allowing us to test on a broader range of scenes compared to prior
work. We find that: 1) CLIP's text encoder falls short on object relationships,
attribute-object association, counting, and negations; 2) some text encoders
work significantly better than others; and 3) text-only recovery performance
predicts multi-modal matching performance on ControlledImCaps: a new evaluation
benchmark we collect+release consisting of fine-grained compositional
images+captions. Specifically -- our results suggest text-only recoverability
is a necessary (but not sufficient) condition for modeling compositional
factors in contrastive vision+language models. We release data+code.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：HARD: Hard Augmentations for Robust Distillation</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14890</p>
  <p><b>作者</b>：Arne F. Nix,  Max F. Burg,  Fabian H. Sinz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model solely based, functional activity, transfer knowledge, Knowledge distillation, solely based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation (KD) is a simple and successful method to transfer
knowledge from a teacher to a student model solely based on functional
activity. However, current KD has a few shortcomings: it has recently been
shown that this method is unsuitable to transfer simple inductive biases like
shift equivariance, struggles to transfer out of domain generalization, and
optimization time is magnitudes longer compared to default non-KD model
training. To improve these aspects of KD, we propose Hard Augmentations for
Robust Distillation (HARD), a generally applicable data augmentation framework,
that generates synthetic data points for which the teacher and the student
disagree. We show in a simple toy example that our augmentation framework
solves the problem of transferring simple equivariances with KD. We then apply
our framework in real-world tasks for a variety of augmentation models, ranging
from simple spatial transformations to unconstrained image manipulations with a
pretrained variational autoencoder. We find that our learned augmentations
significantly improve KD performance on in-domain and out-of-domain evaluation.
Moreover, our method outperforms even state-of-the-art data augmentations and
since the augmented training inputs can be visualized, they offer a qualitative
insight into the properties that are transferred from the teacher to the
student. Thus HARD represents a generally applicable, dynamically optimized
data augmentation technique tailored to improve the generalization and
convergence speed of models trained with KD.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Towards View-invariant and Accurate Loop Detection Based on Scene Graph</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14885</p>
  <p><b>作者</b>：Chuhao Liu,  Shaojie Shen</p>
  <p><b>备注</b>：Accepted by ICRA2023</p>
  <p><b>关键词</b>：visual Simultaneous Localization, Simultaneous Localization, Loop detection, visual Simultaneous, Loop detection plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Loop detection plays a key role in visual Simultaneous Localization and
Mapping (SLAM) by correcting the accumulated pose drift. In indoor scenarios,
the richly distributed semantic landmarks are view-point invariant and hold
strong descriptive power in loop detection. The current semantic-aided loop
detection embeds the topology between semantic instances to search a loop.
However, current semantic-aided loop detection methods face challenges in
dealing with ambiguous semantic instances and drastic viewpoint differences,
which are not fully addressed in the literature. This paper introduces a novel
loop detection method based on an incrementally created scene graph, targeting
the visual SLAM at indoor scenes. It jointly considers the macro-view topology,
micro-view topology, and occupancy of semantic instances to find correct
correspondences. Experiments using handheld RGB-D sequence show our method is
able to accurately detect loops in drastically changed viewpoints. It maintains
a high precision in observing objects with similar topology and appearance. Our
method also demonstrates that it is robust in changed indoor scenes.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Interpretable by Design Visual Question Answering</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14882</p>
  <p><b>作者</b>：Xingyu Fu,  Ben Zhou,  Sihao Chen,  Mark Yatskar,  Dan Roth</p>
  <p><b>备注</b>：Multimodal, Vision and Language</p>
  <p><b>关键词</b>：Visual Question Answering, vision and language, aligned and reasoned, multimodal setting, Question Answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model interpretability has long been a hard problem for the AI community
especially in the multimodal setting, where vision and language need to be
aligned and reasoned at the same time. In this paper, we specifically focus on
the problem of Visual Question Answering (VQA). While previous researches try
to probe into the network structures of black-box multimodal models, we propose
to tackle the problem from a different angle -- to treat interpretability as an
explicit additional goal.
Given an image and question, we argue that an interpretable VQA model should
be able to tell what conclusions it can get from which part of the image, and
show how each statement help to arrive at an answer. We introduce InterVQA:
Interpretable-by-design VQA, where we design an explicit intermediate dynamic
reasoning structure for VQA problems and enforce symbolic reasoning that only
use the structure for final answer prediction to take place. InterVQA produces
high-quality explicit intermediate reasoning steps, while maintaining similar
to the state-of-the-art (sota) end-task performance.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Multiresolution Feature Guidance Based Transformer for Anomaly Detection</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14880</p>
  <p><b>作者</b>：Shuting Yan,  Pingping Chen,  Honghui Chen,  Huan Mao,  Feng Chen,  Zhijian Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify deviated images, Anomaly detection, deviated images, unsupervised anomaly detection, learning to identify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection is represented as an unsupervised learning to identify
deviated images from normal images. In general, there are two main challenges
of anomaly detection tasks, i.e., the class imbalance and the unexpectedness of
anomalies. In this paper, we propose a multiresolution feature guidance method
based on Transformer named GTrans for unsupervised anomaly detection and
localization. In GTrans, an Anomaly Guided Network (AGN) pre-trained on
ImageNet is developed to provide surrogate labels for features and tokens.
Under the tacit knowledge guidance of the AGN, the anomaly detection network
named Trans utilizes Transformer to effectively establish a relationship
between features with multiresolution, enhancing the ability of the Trans in
fitting the normal data manifold. Due to the strong generalization ability of
AGN, GTrans locates anomalies by comparing the differences in spatial distance
and direction of multi-scale features extracted from the AGN and the Trans. Our
experiments demonstrate that the proposed GTrans achieves state-of-the-art
performance in both detection and localization on the MVTec AD dataset. GTrans
achieves image-level and pixel-level anomaly detection AUROC scores of 99.0%
and 97.9% on the MVTec AD dataset, respectively.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Optimization-Based Improvement of Face Image Quality Assessment  Techniques</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14856</p>
  <p><b>作者</b>：Žiga Babnik,  Naser Damer,  Vitomir Štruc</p>
  <p><b>备注</b>：In proceedings of the International Workshop on Biometrics and Forensics (IWBF) 2023</p>
  <p><b>关键词</b>：achieve near-ideal recognition, Contemporary face recognition, near-ideal recognition performance, models achieve near-ideal, achieve near-ideal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contemporary face recognition (FR) models achieve near-ideal recognition
performance in constrained settings, yet do not fully translate the performance
to unconstrained (realworld) scenarios. To help improve the performance and
stability of FR systems in such unconstrained settings, face image quality
assessment (FIQA) techniques try to infer sample-quality information from the
input face images that can aid with the recognition process. While existing
FIQA techniques are able to efficiently capture the differences between high
and low quality images, they typically cannot fully distinguish between images
of similar quality, leading to lower performance in many scenarios. To address
this issue, we present in this paper a supervised quality-label optimization
approach, aimed at improving the performance of existing FIQA techniques. The
developed optimization procedure infuses additional information (computed with
a selected FR model) into the initial quality scores generated with a given
FIQA technique to produce better estimates of the "actual" image quality. We
evaluate the proposed approach in comprehensive experiments with six
state-of-the-art FIQA approaches (CR-FIQA, FaceQAN, SER-FIQ, PCNet, MagFace,
SDD-FIQA) on five commonly used benchmarks (LFW, CFPFP, CPLFW, CALFW, XQLFW)
using three targeted FR models (ArcFace, ElasticFace, CurricularFace) with
highly encouraging results.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion</b></summary>
  <p><b>编号</b>：[323]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14849</p>
  <p><b>作者</b>：Taesun Yeom,  Minhyeok Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high intra-class variation, generative adversarial networks, mode collapse, intra-class variation, generative adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class-conditional image generation using generative adversarial networks
(GANs) has been investigated through various techniques; however, it continues
to face challenges such as mode collapse, training instability, and low-quality
output in cases of datasets with high intra-class variation. Furthermore, most
GANs often converge in larger iterations, resulting in poor iteration efficacy
in training procedures. While Diffusion-GAN has shown potential in generating
realistic samples, it has a critical limitation in generating class-conditional
samples. To overcome these limitations, we propose a novel approach for
class-conditional image generation using GANs called DuDGAN, which incorporates
a dual diffusion-based noise injection process. Our method consists of three
unique networks: a discriminator, a generator, and a classifier. During the
training process, Gaussian-mixture noises are injected into the two noise-aware
networks, the discriminator and the classifier, in distinct ways. This noisy
data helps to prevent overfitting by gradually introducing more challenging
tasks, leading to improved model performance. As a result, our method
outperforms state-of-the-art conditional GAN models for image generation in
terms of performance. We evaluated our method using the AFHQ, Food-101, and
CIFAR-10 datasets and observed superior results across metrics such as FID,
KID, Precision, and Recall score compared with comparison models, highlighting
the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Introducing Competition to Boost the Transferability of Targeted  Adversarial Examples through Clean Feature Mixup</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14846</p>
  <p><b>作者</b>：Junyoung Byun,  Myung-Joon Kwon,  Seungju Cho,  Yoonji Kim,  Changick Kim</p>
  <p><b>备注</b>：CVPR 2023 camera-ready</p>
  <p><b>关键词</b>：subtle input modifications, Deep neural networks, Deep neural, input modifications, incorrect predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks are widely known to be susceptible to adversarial
examples, which can cause incorrect predictions through subtle input
modifications. These adversarial examples tend to be transferable between
models, but targeted attacks still have lower attack success rates due to
significant variations in decision boundaries. To enhance the transferability
of targeted adversarial examples, we propose introducing competition into the
optimization process. Our idea is to craft adversarial perturbations in the
presence of two new types of competitor noises: adversarial perturbations
towards different target classes and friendly perturbations towards the correct
class. With these competitors, even if an adversarial example deceives a
network to extract specific features leading to the target class, this
disturbance can be suppressed by other competitors. Therefore, within this
competition, adversarial examples should take different attack strategies by
leveraging more diverse features to overwhelm their interference, leading to
improving their transferability to different models. Considering the
computational complexity, we efficiently simulate various interference from
these two types of competitors in feature space by randomly mixing up stored
clean features in the model inference and named this method Clean Feature Mixup
(CFM). Our extensive experimental results on the ImageNet-Compatible and
CIFAR-10 datasets show that the proposed method outperforms the existing
baselines with a clear margin. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Predicting Token Impact Towards Efficient Vision Transformer</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14840</p>
  <p><b>作者</b>：Hong Wang,  Su Yang,  Xiaoke Huang,  Weishan Zhang</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：efficient vision Transformer, reduce irrelevant tokens, vision Transformer, Token filtering, Token</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Token filtering to reduce irrelevant tokens prior to self-attention is a
straightforward way to enable efficient vision Transformer. This is the first
work to view token filtering from a feature selection perspective, where we
weigh the importance of a token according to how much it can change the loss
once masked. If the loss changes greatly after masking a token of interest, it
means that such a token has a significant impact on the final decision and is
thus relevant. Otherwise, the token is less important for the final decision,
so it can be filtered out. After applying the token filtering module
generalized from the whole training data, the token number fed to the
self-attention module can be obviously reduced in the inference phase, leading
to much fewer computations in all the subsequent self-attention layers. The
token filter can be realized using a very simple network, where we utilize
multi-layer perceptron. Except for the uniqueness of performing token filtering
only once from the very beginning prior to self-attention, the other core
feature making our method different from the other token filters lies in the
predictability of token impact from a feature selection point of view. The
experiments show that the proposed method provides an efficient way to approach
a light weighted model after optimized with a backbone by means of fine tune,
which is easy to be deployed in comparison with the existing methods based on
training from scratch.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and  Compositional Experts</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14839</p>
  <p><b>作者</b>：Yunshui Li,  Binyuan Hui,  ZhiChao Yin,  Min Yang,  Fei Huang,  Yongbin Li</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：Perceiving multi-modal information, multi-modal dialogue, artificial intelligence, multi-modal, information and fulfilling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perceiving multi-modal information and fulfilling dialogues with humans is a
long-term goal of artificial intelligence. Pre-training is commonly regarded as
an effective approach for multi-modal dialogue. However, due to the limited
availability of multi-modal dialogue data, there is still scarce research on
multi-modal dialogue pre-training. Yet another intriguing challenge emerges
from the encompassing nature of multi-modal dialogue, which involves various
modalities and tasks. Moreover, new forms of tasks may arise at unpredictable
points in the future. Hence, it is essential for designed multi-modal dialogue
models to possess sufficient flexibility to adapt to such scenarios. This paper
proposes \textbf{PaCE}, a unified, structured, compositional multi-modal
dialogue pre-training framework. It utilizes a combination of several
fundamental experts to accommodate multiple dialogue-related tasks and can be
pre-trained using limited dialogue and extensive non-dialogue multi-modal data.
Furthermore, we propose a progressive training method where old experts from
the past can assist new experts, facilitating the expansion of their
capabilities. Experimental results demonstrate that PaCE achieves
state-of-the-art results on eight multi-modal dialog benchmarks.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for  Autonomous Driving Scenario</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14836</p>
  <p><b>作者</b>：Tianwen Qian,  Jingjing Chen,  Linhai Zhuo,  Yang Jiao,  Yu-Gang Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：answer natural language, autonomous driving scenario, autonomous driving, natural language questions, aiming to answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel visual question answering (VQA) task in the context of
autonomous driving, aiming to answer natural language questions based on
street-view clues. Compared to traditional VQA tasks, VQA in autonomous driving
scenario presents more challenges. Firstly, the raw visual data are
multi-modal, including images and point clouds captured by camera and LiDAR,
respectively. Secondly, the data are multi-frame due to the continuous,
real-time acquisition. Thirdly, the outdoor scenes exhibit both moving
foreground and static background. Existing VQA benchmarks fail to adequately
address these complexities. To bridge this gap, we propose NuScenes-QA, the
first benchmark for VQA in the autonomous driving scenario, encompassing 34K
visual scenes and 460K question-answer pairs. Specifically, we leverage
existing 3D detection annotations to generate scene graphs and design question
templates manually. Subsequently, the question-answer pairs are generated
programmatically based on these templates. Comprehensive statistics prove that
our NuScenes-QA is a balanced large-scale benchmark with diverse question
formats. Built upon it, we develop a series of baselines that employ advanced
3D detection and VQA techniques. Our extensive experiments highlight the
challenges posed by this new task. Codes and dataset are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：OD-NeRF: Efficient Training of On-the-Fly Dynamic Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14831</p>
  <p><b>作者</b>：Zhiwen Yan,  Chen Li,  Gim Hee Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated impressive results, dynamic scenes, Dynamic neural radiance, view synthesis, Dynamic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamic neural radiance fields (dynamic NeRFs) have demonstrated impressive
results in novel view synthesis on 3D dynamic scenes. However, they often
require complete video sequences for training followed by novel view synthesis,
which is similar to playing back the recording of a dynamic 3D scene. In
contrast, we propose OD-NeRF to efficiently train and render dynamic NeRFs
on-the-fly which instead is capable of streaming the dynamic scene. When
training on-the-fly, the training frames become available sequentially and the
model is trained and rendered frame-by-frame. The key challenge of efficient
on-the-fly training is how to utilize the radiance field estimated from the
previous frames effectively. To tackle this challenge, we propose: 1) a NeRF
model conditioned on the multi-view projected colors to implicitly track
correspondence between the current and previous frames, and 2) a transition and
update algorithm that leverages the occupancy grid from the last frame to
sample efficiently at the current frame. Our algorithm can achieve an
interactive speed of 6FPS training and rendering on synthetic dynamic scenes
on-the-fly, and a significant speed-up compared to the state-of-the-art on
real-world dynamic scenes.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：On Correlated Knowledge Distillation for Monitoring Human Pose with  Radios</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14829</p>
  <p><b>作者</b>：Shiva Raj Pokhrel,  Jonathan Kua,  Deol Satish,  Phil Williams,  Arkady Zaslavsky,  Seng W. Loke,  Jinho Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Correlated Knowledge Distillation, coupling radio frequency, pose monitoring systems, Knowledge Distillation, precise human pose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose and develop a simple experimental testbed to study
the feasibility of a novel idea by coupling radio frequency (RF) sensing
technology with Correlated Knowledge Distillation (CKD) theory towards
designing lightweight, near real-time and precise human pose monitoring
systems. The proposed CKD framework transfers and fuses pose knowledge from a
robust "Teacher" model to a parameterized "Student" model, which can be a
promising technique for obtaining accurate yet lightweight pose estimates. To
assure its efficacy, we implemented CKD for distilling logits in our integrated
Software Defined Radio (SDR)-based experimental setup and investigated the
RF-visual signal correlation. Our CKD-RF sensing technique is characterized by
two modes -- a camera-fed Teacher Class Network (e.g., images, videos) with an
SDR-fed Student Class Network (e.g., RF signals). Specifically, our CKD model
trains a dual multi-branch teacher and student network by distilling and fusing
knowledge bases. The resulting CKD models are then subsequently used to
identify the multimodal correlation and teach the student branch in reverse.
Instead of simply aggregating their learnings, CKD training comprised multiple
parallel transformations with the two domains, i.e., visual images and RF
signals. Once trained, our CKD model can efficiently preserve privacy and
utilize the multimodal correlated logits from the two different neural networks
for estimating poses without using visual signals/video frames (by using only
the RF signals).</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Towards Few-shot Entity Recognition in Document Images: A Graph Neural  Network Approach Robust to Image Manipulation</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14828</p>
  <p><b>作者</b>：Prashant Krishnan,  Zilong Wang,  Yangkun Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved significant performance, incorporating layout information, typically bounding box, bounding box coordinates, document images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances of incorporating layout information, typically bounding box
coordinates, into pre-trained language models have achieved significant
performance in entity recognition from document images. Using coordinates can
easily model the absolute position of each token, but they might be sensitive
to manipulations in document images (e.g., shifting, rotation or scaling),
especially when the training data is limited in few-shot settings. In this
paper, we propose to further introduce the topological adjacency relationship
among the tokens, emphasizing their relative position information.
Specifically, we consider the tokens in the documents as nodes and formulate
the edges based on the topological heuristics from the k-nearest bounding
boxes. Such adjacency graphs are invariant to affine transformations including
shifting, rotations and scaling. We incorporate these graphs into the
pre-trained language model by adding graph neural network layers on top of the
language model embeddings, leading to a novel model LAGER. Extensive
experiments on two benchmark datasets show that LAGER significantly outperforms
strong baselines under different few-shot settings and also demonstrate better
robustness to manipulations.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Semi-Supervised and Long-Tailed Object Detection with CascadeMatch</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14813</p>
  <p><b>作者</b>：Yuhang Zang,  Kaiyang Zhou,  Chen Huang,  Chen Change Loy</p>
  <p><b>备注</b>：International Journal of Computer Vision (IJCV), 2023</p>
  <p><b>关键词</b>：poses realistic challenges, semi-supervised learning setting, learning setting, realistic challenges, paper focuses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper focuses on long-tailed object detection in the semi-supervised
learning setting, which poses realistic challenges, but has rarely been studied
in the literature. We propose a novel pseudo-labeling-based detector called
CascadeMatch. Our detector features a cascade network architecture, which has
multi-stage detection heads with progressive confidence thresholds. To avoid
manually tuning the thresholds, we design a new adaptive pseudo-label mining
mechanism to automatically identify suitable values from data. To mitigate
confirmation bias, where a model is negatively reinforced by incorrect
pseudo-labels produced by itself, each detection head is trained by the
ensemble pseudo-labels of all detection heads. Experiments on two long-tailed
datasets, i.e., LVIS and COCO-LT, demonstrate that CascadeMatch surpasses
existing state-of-the-art semi-supervised approaches -- across a wide range of
detection architectures -- in handling long-tailed object detection. For
instance, CascadeMatch outperforms Unbiased Teacher by 1.9 AP Fix on LVIS when
using a ResNet50-based Cascade R-CNN structure, and by 1.7 AP Fix when using
Sparse R-CNN with a Transformer encoder. We also show that CascadeMatch can
even handle the challenging sparsely annotated object detection problem.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Exploring Diverse In-Context Configurations for Image Captioning</b></summary>
  <p><b>编号</b>：[356]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14800</p>
  <p><b>作者</b>：Xu Yang,  Yongliang Wu,  Mingzhuo Yang,  Haokun Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Language Models, discovering that Language, optimize in-context sequence, in-context few-shot learners, good in-context few-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>After discovering that Language Models (LMs) can be good in-context few-shot
learners, numerous strategies have been proposed to optimize in-context
sequence configurations. Recently, researchers in Vision-Language (VL) domains
also develop their few-shot learners, while they only use the simplest way,
\ie, randomly sampling, to configure in-context image-text pairs. In order to
explore the effects of varying configurations on VL in-context learning, we
devised four strategies for image selection and four for caption assignment to
configure in-context image-text pairs for image captioning. Here Image
Captioning is used as the case study since it can be seen as the
visually-conditioned LM. Our comprehensive experiments yield two
counter-intuitive but valuable insights, highlighting the distinct
characteristics of VL in-context learning due to multi-modal synergy, as
compared to the NLP case.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Polarimetric Imaging for Perception</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14787</p>
  <p><b>作者</b>：Michael Baltaxe,  Tomer Pe'er,  Dan Levi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced driver-assistance systems, driver-assistance systems rely, Autonomous driving, driving scene, advanced driver-assistance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous driving and advanced driver-assistance systems rely on a set of
sensors and algorithms to perform the appropriate actions and provide alerts as
a function of the driving scene. Typically, the sensors include color cameras,
radar, lidar and ultrasonic sensors. Strikingly however, although light
polarization is a fundamental property of light, it is seldom harnessed for
perception tasks. In this work we analyze the potential for improvement in
perception tasks when using an RGB-polarimetric camera, as compared to an RGB
camera. We examine monocular depth estimation and free space detection during
the middle of the day, when polarization is independent of subject heading, and
show that a quantifiable improvement can be achieved for both of them using
state-of-the-art deep neural networks, with a minimum of architectural changes.
We also present a new dataset composed of RGB-polarimetric images, lidar scans,
GNSS / IMU readings and free space segmentations that further supports
developing perception algorithms that take advantage of light polarization.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Text Conditional Alt-Text Generation for Twitter Images</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14779</p>
  <p><b>作者</b>：Nikita Srivatsan,  Sofia Samaniego,  Omar Florez,  Taylor Berg-Kirkpatrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating alternative text, generating alternative, specifically Twitter, images shared, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we present an approach for generating alternative text (or
alt-text) descriptions for images shared on social media, specifically Twitter.
This task is more than just a special case of image captioning, as alt-text is
both more literally descriptive and context-specific. Also critically, images
posted to Twitter are often accompanied by user-written text that despite not
necessarily describing the image may provide useful context that if properly
leveraged can be informative -- e.g. the tweet may name an uncommon object in
the image that the model has not previously seen. We address this with a CLIP
prefix model that extracts an embedding of the image and passes it to a mapping
network that outputs a short sequence in word embedding space, or a ``prefix'',
to which we also concatenate the text from the tweet itself. This lets the
model condition on both visual and textual information from the post. The
combined multimodal prefix is then fed as a prompt to a pretrained language
model which autoregressively completes the sequence to generate the alt-text.
While prior work has used similar methods for captioning, ours is the first to
our knowledge that incorporates textual information from the associated social
media post into the prefix as well, and we further demonstrate through
ablations that utility of these two information sources stacks. We put forward
a new dataset scraped from Twitter and evaluate on it across a variety of
automated metrics as well as human evaluation, and show that our approach of
conditioning on both tweet text and visual information significantly
outperforms prior work.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Generative Modeling through the Semi-dual Formulation of Unbalanced  Optimal Transport</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14777</p>
  <p><b>作者</b>：Jaemoo Choi,  Jaewoong Choi,  Myungjoo Kang</p>
  <p><b>备注</b>：23 pages, 15 figures</p>
  <p><b>关键词</b>：problem investigates, cost function, map that bridges, transport map, UOT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimal Transport (OT) problem investigates a transport map that bridges two
distributions while minimizing a given cost function. In this regard, OT
between tractable prior distribution and data has been utilized for generative
modeling tasks. However, OT-based methods are susceptible to outliers and face
optimization challenges during training. In this paper, we propose a novel
generative model based on the semi-dual formulation of Unbalanced Optimal
Transport (UOT). Unlike OT, UOT relaxes the hard constraint on distribution
matching. This approach provides better robustness against outliers, stability
during training, and faster convergence. We validate these properties
empirically through experiments. Moreover, we study the theoretical upper-bound
of divergence between distributions in UOT. Our model outperforms existing
OT-based generative models, achieving FID scores of 2.97 on CIFAR-10 and 5.80
on CelebA-HQ-256.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Dual Path Transformer with Partition Attention</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14768</p>
  <p><b>作者</b>：Zhengkai Jiang,  Liang Liu,  Jiangning Zhang,  Yabiao Wang,  Mingang Chen,  Chengjie Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attention, dual attention, efficient and effective, Convolutional Neural, dual attention mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a novel attention mechanism, called dual attention,
which is both efficient and effective. The dual attention mechanism consists of
two parallel components: local attention generated by Convolutional Neural
Networks (CNNs) and long-range attention generated by Vision Transformers
(ViTs). To address the high computational complexity and memory footprint of
vanilla Multi-Head Self-Attention (MHSA), we introduce a novel Multi-Head
Partition-wise Attention (MHPA) mechanism. The partition-wise attention
approach models both intra-partition and inter-partition attention
simultaneously. Building on the dual attention block and partition-wise
attention mechanism, we present a hierarchical vision backbone called
DualFormer. We evaluate the effectiveness of our model on several computer
vision tasks, including image classification on ImageNet, object detection on
COCO, and semantic segmentation on Cityscapes. Specifically, the proposed
DualFormer-XS achieves 81.5\% top-1 accuracy on ImageNet, outperforming the
recent state-of-the-art MPViT-XS by 0.6\% top-1 accuracy with much higher
throughput.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：MRN: Multiplexed Routing Network for Incremental Multilingual Text  Recognition</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14758</p>
  <p><b>作者</b>：Tianlun Zheng,  Zhineng Chen,  BingChen Huang,  Wei Zhang,  Yu-Gang Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multilingual Text Recognition, Traditional Multilingual Text, handle newly added, Text Recognition, Multilingual Text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional Multilingual Text Recognition (MLTR) usually targets a fixed set
of languages and thus struggles to handle newly added languages or adapt to
ever-changing class distributions. In this paper, we introduce the Incremental
Multilingual Text Recognition (IMLTR) task in the incremental learning setting,
where new language data comes in batches. Compared to generic incremental
learning, IMLTR is even more challenging as it suffers from rehearsal-imbalance
(uneven distribution of sample characters in the rehearsal set). To address
this issue, we propose a Multiplexed Routing Network (MRN), where a series of
recognizers is trained for each language. Subsequently, a language predictor is
adopted to weigh the recognizers for voting. Since the recognizers are derived
from the original model, MRN effectively reduces the reliance on older data and
is better suited for rehearsal-imbalance. We extensively evaluate MRN on MLT17
and MLT19 datasets, outperforming existing state-of-the-art methods by a large
margin, i.e., accuracy improvement ranging from 10.3% to 27.4% under different
settings.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：SUVR: A Search-based Approach to Unsupervised Visual Representation  Learning</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14754</p>
  <p><b>作者</b>：Yi-Zhan Xu,  Chih-Yao Chen,  Cheng-Te Li</p>
  <p><b>备注</b>：ICASSP 2023</p>
  <p><b>关键词</b>：collecting annotated data, annotated data, unlabeled data, grown in popularity, difficulty of collecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised learning has grown in popularity because of the difficulty of
collecting annotated data and the development of modern frameworks that allow
us to learn from unlabeled data. Existing studies, however, either disregard
variations at different levels of similarity or only consider negative samples
from one batch. We argue that image pairs should have varying degrees of
similarity, and the negative samples should be allowed to be drawn from the
entire dataset. In this work, we propose Search-based Unsupervised Visual
Representation Learning (SUVR) to learn better image representations in an
unsupervised manner. We first construct a graph from the image dataset by the
similarity between images, and adopt the concept of graph traversal to explore
positive samples. In the meantime, we make sure that negative samples can be
drawn from the full dataset. Quantitative experiments on five benchmark image
classification datasets demonstrate that SUVR can significantly outperform
strong competing methods on unsupervised embedding learning. Qualitative
experiments also show that SUVR can produce better representations in which
similar images are clustered closer together than unrelated images in the
latent space.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space  Manipulation</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14742</p>
  <p><b>作者</b>：Dongxu Yue,  Qin Guo,  Munan Ning,  Jiaxi Cui,  Yuesheng Zhu,  Li Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real facial images, crucial task, task in computer, computer vision, vision with significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Editing real facial images is a crucial task in computer vision with
significant demand in various real-world applications. While GAN-based methods
have showed potential in manipulating images especially when combined with
CLIP, these methods are limited in their ability to reconstruct real images due
to challenging GAN inversion capability. Despite the successful image
reconstruction achieved by diffusion-based methods, there are still challenges
in effectively manipulating fine-gained facial attributes with textual
this http URL address these issues and facilitate convenient manipulation of
real facial images, we propose a novel approach that conduct text-driven image
editing in the semantic latent space of diffusion model. By aligning the
temporal feature of the diffusion model with the semantic condition at
generative process, we introduce a stable manipulation strategy, which perform
precise zero-shot manipulation effectively. Furthermore, we develop an
interactive system named ChatFace, which combines the zero-shot reasoning
ability of large language models to perform efficient manipulations in
diffusion semantic latent space. This system enables users to perform complex
multi-attribute manipulations through dialogue, opening up new possibilities
for interactive image editing. Extensive experiments confirmed that our
approach outperforms previous methods and enables precise editing of real
facial images, making it a promising candidate for real-world applications.
Project page: this https URL</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：ECHo: Event Causality Inference via Human-centric Reasoning</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14740</p>
  <p><b>作者</b>：Yuxi Xie,  Guanzhen Li,  Min-Yen Kan</p>
  <p><b>备注</b>：Please find data and code at this https URL</p>
  <p><b>关键词</b>：event causality inference, causality inference grounded, event causality, causality inference, inference grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce ECHo, a diagnostic dataset of event causality inference grounded
in visual-and-linguistic social scenarios. ECHo employs real-world
human-centric deductive information collected from crime drama, bridging the
gap in multimodal reasoning towards higher social intelligence through the
elicitation of intermediate Theory-of-Mind (ToM). We propose a unified
framework aligned with the Chain-of-Thought (CoT) paradigm to assess the
reasoning capability of current AI systems. This ToM-enhanced CoT pipeline can
accommodate and integrate various large foundation models in zero-shot
visual-and-linguistic understanding. With this framework, we scrutinize the
advanced large language and multimodal models via three complementary
human-centric ECHo tasks. Further analysis demonstrates ECHo as a challenging
dataset to expose imperfections and inconsistencies in reasoning.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：AutoDepthNet: High Frame Rate Depth Map Reconstruction using Commodity  Depth and RGB Cameras</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14731</p>
  <p><b>作者</b>：Peyman Gholami,  Robert Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Depth, Depth cameras, artificial intelligence, diverse fields, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depth cameras have found applications in diverse fields, such as computer
vision, artificial intelligence, and video gaming. However, the high latency
and low frame rate of existing commodity depth cameras impose limitations on
their applications. We propose a fast and accurate depth map reconstruction
technique to reduce latency and increase the frame rate in depth cameras. Our
approach uses only a commodity depth camera and color camera in a hybrid camera
setup; our prototype is implemented using a Kinect Azure depth camera at 30 fps
and a high-speed RGB iPhone 11 Pro camera captured at 240 fps. The proposed
network, AutoDepthNet, is an encoder-decoder model that captures frames from
the high-speed RGB camera and combines them with previous depth frames to
reconstruct a stream of high frame rate depth maps. On GPU, with a 480 x 270
output resolution, our system achieves an inference time of 8 ms, enabling
real-time use at up to 200 fps with parallel processing. AutoDepthNet can
estimate depth values with an average RMS error of 0.076, a 44.5% improvement
compared to an optical flow-based comparison method. Our method can also
improve depth map quality by estimating depth values for missing and
invalidated pixels. The proposed method can be easily applied to existing depth
cameras and facilitates the use of depth cameras in applications that require
high-speed depth estimation. We also showcase the effectiveness of the
framework in upsampling different sparse datasets e.g. video object
segmentation. As a demonstration of our method, we integrated our framework
into existing body tracking systems and demonstrated the robustness of the
proposed method in such applications.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：BinaryViT: Towards Efficient and Accurate Binary Vision Transformers</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14730</p>
  <p><b>作者</b>：Junrui Xiao,  Zhikai Li,  Lianwei Yang,  Qingyi Gu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision fields, Vision Transformers, computation costs hinders, Convolutional Neural Networks, vision fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision Transformers (ViTs) have emerged as the fundamental architecture for
most computer vision fields, but the considerable memory and computation costs
hinders their application on resource-limited devices. As one of the most
powerful compression methods, binarization reduces the computation of the
neural network by quantizing the weights and activation values as $\pm$1.
Although existing binarization methods have demonstrated excellent performance
on Convolutional Neural Networks (CNNs), the full binarization of ViTs is still
under-studied and suffering a significant performance drop. In this paper, we
first argue empirically that the severe performance degradation is mainly
caused by the weight oscillation in the binarization training and the
information distortion in the activation of ViTs. Based on these analyses, we
propose $\textbf{BinaryViT}$, an accurate full binarization scheme for ViTs,
which pushes the quantization of ViTs to the limit. Specifically, we propose a
novel gradient regularization scheme (GRS) for driving a bimodal distribution
of the weights to reduce oscillation in binarization training. Moreover, we
design an activation shift module (ASM) to adaptively tune the activation
distribution to reduce the information distortion caused by binarization.
Extensive experiments on ImageNet dataset show that our BinaryViT consistently
surpasses the strong baseline by 2.05% and improve the accuracy of fully
binarized ViTs to a usable level. Furthermore, our method achieves impressive
savings of 16.2$\times$ and 17.7$\times$ in model size and OPs compared to the
full-precision DeiT-S. The codes and models will be released on github.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create  Visual Metaphors</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14724</p>
  <p><b>作者</b>：Tuhin Chakrabarty,  Arkadiy Saakyan,  Olivia Winn,  Artemis Panagopoulou,  Yue Yang,  Marianna Apidianaki,  Smaranda Muresan</p>
  <p><b>备注</b>：ACL 2023 (Findings)</p>
  <p><b>关键词</b>：powerful rhetorical devices, communicate creative ideas, linguistic metaphors, ideas through images, powerful rhetorical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual metaphors are powerful rhetorical devices used to persuade or
communicate creative ideas through images. Similar to linguistic metaphors,
they convey meaning implicitly through symbolism and juxtaposition of the
symbols. We propose a new task of generating visual metaphors from linguistic
metaphors. This is a challenging task for diffusion-based text-to-image models,
such as DALL$\cdot$E 2, since it requires the ability to model implicit meaning
and compositionality. We propose to solve the task through the collaboration
between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3
(davinci-002) with Chain-of-Thought prompting generates text that represents a
visual elaboration of the linguistic metaphor containing the implicit meaning
and relevant objects, which is then used as input to the diffusion-based
text-to-image models.Using a human-AI collaboration framework, where humans
interact both with the LLM and the top-performing diffusion model, we create a
high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic
metaphors and their associated visual elaborations. Evaluation by professional
illustrators shows the promise of LLM-Diffusion Model collaboration for this
this http URL evaluate the utility of our Human-AI collaboration framework and the
quality of our dataset, we perform both an intrinsic human-based evaluation and
an extrinsic evaluation using visual entailment as a downstream task.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Remote Sensing Image Change Detection Towards Continuous Bitemporal  Resolution Differences</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14722</p>
  <p><b>作者</b>：Hao Chen,  Haotian Zhang,  Keyan Chen,  Chenyao Zhou,  Song Chen,  Zhengxia Zhou,  Zhenwei Shi</p>
  <p><b>备注</b>：19 pages, 11 figures. Submitted to the IEEE for a possible publication</p>
  <p><b>关键词</b>：supervised Remote Sensing, contemporary supervised Remote, Remote Sensing, supervised Remote, image Change Detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most contemporary supervised Remote Sensing (RS) image Change Detection (CD)
approaches are customized for equal-resolution bitemporal images. Real-world
applications raise the need for cross-resolution change detection, aka, CD
based on bitemporal images with different spatial resolutions. Current
cross-resolution methods that are trained with samples of a fixed resolution
difference (resolution ratio between the high-resolution (HR) image and the
low-resolution (LR) one) may fit a certain ratio but lack adaptation to other
resolution differences. Toward continuous cross-resolution CD, we propose
scale-invariant learning to enforce the model consistently predicting HR
results given synthesized samples of varying bitemporal resolution differences.
Concretely, we synthesize blurred versions of the HR image by random
downsampled reconstructions to reduce the gap between HR and LR images. We
introduce coordinate-based representations to decode per-pixel predictions by
feeding the coordinate query and corresponding multi-level embedding features
into an MLP that implicitly learns the shape of land cover changes, therefore
benefiting recognizing blurred objects in the LR image. Moreover, considering
that spatial resolution mainly affects the local textures, we apply
local-window self-attention to align bitemporal features during the early
stages of the encoder. Extensive experiments on two synthesized and one
real-world different-resolution CD datasets verify the effectiveness of the
proposed method. Our method significantly outperforms several vanilla CD
methods and two cross-resolution CD methods on the three datasets both in
in-distribution and out-of-distribution settings. The empirical results suggest
that our method could yield relatively consistent HR change predictions
regardless of varying resolution difference ratios. Our code will be public.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：BLIP-Diffusion: Pre-trained Subject Representation for Controllable  Text-to-Image Generation and Editing</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14720</p>
  <p><b>作者</b>：Dongxu Li,  Junnan Li,  Steven C.H. Hoi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subject, generation, text prompts, subject-driven generation, Subject-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subject-driven text-to-image generation models create novel renditions of an
input subject based on text prompts. Existing models suffer from lengthy
fine-tuning and difficulties preserving the subject fidelity. To overcome these
limitations, we introduce BLIP-Diffusion, a new subject-driven image generation
model that supports multimodal control which consumes inputs of subject images
and text prompts. Unlike other subject-driven generation models, BLIP-Diffusion
introduces a new multimodal encoder which is pre-trained to provide subject
representation. We first pre-train the multimodal encoder following BLIP-2 to
produce visual representation aligned with the text. Then we design a subject
representation learning task which enables a diffusion model to leverage such
visual representation and generates new subject renditions. Compared with
previous methods such as DreamBooth, our model enables zero-shot subject-driven
generation, and efficient fine-tuning for customized subject with up to 20x
speedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with
existing techniques such as ControlNet and prompt-to-prompt to enable novel
subject-driven generation and editing applications. Code and models will be
released at
this https URL. Project
page at this https URL.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Leveraging Future Relationship Reasoning for Vehicle Trajectory  Prediction</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14715</p>
  <p><b>作者</b>：Daehee Park,  Hobin Ryu,  Yunseo Yang,  Jegyeong Cho,  Jiwon Kim,  Kuk-Jin Yoon</p>
  <p><b>备注</b>：ICLR 2023</p>
  <p><b>关键词</b>：crucial for realistic, realistic vehicle trajectory, agents, interaction, future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the interaction between multiple agents is crucial for
realistic vehicle trajectory prediction. Existing methods have attempted to
infer the interaction from the observed past trajectories of agents using
pooling, attention, or graph-based methods, which rely on a deterministic
approach. However, these methods can fail under complex road structures, as
they cannot predict various interactions that may occur in the future. In this
paper, we propose a novel approach that uses lane information to predict a
stochastic future relationship among agents. To obtain a coarse future motion
of agents, our method first predicts the probability of lane-level waypoint
occupancy of vehicles. We then utilize the temporal probability of passing
adjacent lanes for each agent pair, assuming that agents passing adjacent lanes
will highly interact. We also model the interaction using a probabilistic
distribution, which allows for multiple possible future interactions. The
distribution is learned from the posterior distribution of interaction obtained
from ground truth future trajectories. We validate our method on popular
trajectory prediction datasets: nuScenes and Argoverse. The results show that
the proposed method brings remarkable performance gain in prediction accuracy,
and achieves state-of-the-art performance in long-term prediction benchmark
dataset.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Streaming Object Detection on Fisheye Cameras for Automatic Parking</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14713</p>
  <p><b>作者</b>：Yixiong Yan,  Liangzhu Cheng,  Yongxu Li,  Xinjuan Tuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video stream object, fundamental perception function, stream object detection, fisheye camera, widely employed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fisheye cameras are widely employed in automatic parking, and the video
stream object detection (VSOD) of the fisheye camera is a fundamental
perception function to ensure the safe operation of vehicles. In past research
work, the difference between the output of the deep learning model and the
actual situation at the current moment due to the existence of delay of the
perception system is generally ignored. But the environment will inevitably
change within the delay time which may cause a potential safety hazard. In this
paper, we propose a real-time detection framework equipped with a dual-flow
perception module (dynamic and static flows) that can predict the future and
alleviate the time-lag problem. Meanwhile, we use a new scheme to evaluate
latency and accuracy. The standard bounding box is unsuitable for the object in
fisheye camera images due to the strong radial distortion of the fisheye camera
and the primary detection objects of parking perception are vehicles and
pedestrians, so we adopt the rotate bounding box and propose a new periodic
angle loss function to regress the angle of the box, which is the simple and
accurate representation method of objects. The instance segmentation ground
truth is used to supervise the training. Experiments demonstrate the
effectiveness of our approach. Code is released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：EgoVSR: Towards High-Quality Egocentric Video Super-Resolution</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14708</p>
  <p><b>作者</b>：Yichen Chi,  Junhao Gu,  Jiamiao Zhang,  Wenming Yang,  Yapeng Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low visual quality, egocentric videos, egocentric videos frequently, egocentric, videos</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the limitations of capture devices and scenarios, egocentric videos
frequently have low visual quality, mainly caused by high compression and
severe motion blur. With the increasing application of egocentric videos, there
is an urgent need to enhance the quality of these videos through
super-resolution. However, existing Video Super-Resolution (VSR) works,
focusing on third-person view videos, are actually unsuitable for handling
blurring artifacts caused by rapid ego-motion and object motion in egocentric
videos. To this end, we propose EgoVSR, a VSR framework specifically designed
for egocentric videos. We explicitly tackle motion blurs in egocentric videos
using a Dual Branch Deblur Network (DB$^2$Net) in the VSR framework. Meanwhile,
a blurring mask is introduced to guide the DB$^2$Net learning, and can be used
to localize blurred areas in video frames. We also design a MaskNet to predict
the mask, as well as a mask loss to optimize the mask estimation. Additionally,
an online motion blur synthesis model for common VSR training data is proposed
to simulate motion blurs as in egocentric videos. In order to validate the
effectiveness of our proposed method, we introduce an EgoVSR dataset containing
a large amount of fast-motion egocentric video sequences. Extensive experiments
demonstrate that our EgoVSR model can efficiently super-resolve low-quality
egocentric videos and outperform strong comparison baselines. Our code,
pre-trained models, and data will be released.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14700</p>
  <p><b>作者</b>：Ziuhi Wu,  Haichang Gao,  Bingqian Zhou,  Ping Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：implementing knowledge distillation, receive identical inputs, function matching task, models receive identical, function matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>\emph{Consistent teaching} is an effective paradigm for implementing
knowledge distillation (KD), where both student and teacher models receive
identical inputs, and KD is treated as a function matching task (FunMatch).
However, one limitation of FunMatch is that it does not account for the
transfer of adversarial robustness, a model's resistance to adversarial
attacks. To tackle this problem, we propose a simple but effective strategy
called Adversarial Function Matching (AdvFunMatch), which aims to match
distributions for all data points within the $\ell_p$-norm ball of the training
data, in accordance with consistent teaching. Formulated as a min-max
optimization problem, AdvFunMatch identifies the worst-case instances that
maximizes the KL-divergence between teacher and student model outputs, which we
refer to as "mismatched examples," and then matches the outputs on these
mismatched examples. Our experimental results show that AdvFunMatch effectively
produces student models with both high clean accuracy and robustness.
Furthermore, we reveal that strong data augmentations (\emph{e.g.},
AutoAugment) are beneficial in AdvFunMatch, whereas prior works have found them
less effective in adversarial training. Code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Label-Efficient Learning in Agriculture: A Comprehensive Review</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14691</p>
  <p><b>作者</b>：Jiajia Li,  Dong Chen,  Xinda Qi,  Zhaojian Li,  Yanbo Huang,  Daniel Morris,  Xiaobo Tan</p>
  <p><b>备注</b>：34 pages, 23 figures</p>
  <p><b>关键词</b>：including weed control, plant disease diagnosis, precision livestock management, weed control, disease diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The past decade has witnessed many great successes of machine learning (ML)
and deep learning (DL) applications in agricultural systems, including weed
control, plant disease diagnosis, agricultural robotics, and precision
livestock management. Despite tremendous progresses, one downside of such ML/DL
models is that they generally rely on large-scale labeled datasets for
training, and the performance of such models is strongly influenced by the size
and quality of available labeled data samples. In addition, collecting,
processing, and labeling such large-scale datasets is extremely costly and
time-consuming, partially due to the rising cost in human labor. Therefore,
developing label-efficient ML/DL methods for agricultural applications has
received significant interests among researchers and practitioners. In fact,
there are more than 50 papers on developing and applying deep-learning-based
label-efficient techniques to address various agricultural problems since 2016,
which motivates the authors to provide a timely and comprehensive review of
recent label-efficient ML/DL methods in agricultural applications. To this end,
we first develop a principled taxonomy to organize these methods according to
the degree of supervision, including weak supervision (i.e., active learning
and semi-/weakly- supervised learning), and no supervision (i.e., un-/self-
supervised learning), supplemented by representative state-of-the-art
label-efficient ML/DL methods. In addition, a systematic review of various
agricultural applications exploiting these label-efficient algorithms, such as
precision agriculture, plant phenotyping, and postharvest quality assessment,
is presented. Finally, we discuss the current problems and challenges, as well
as future research directions. A well-classified paper list can be accessed at
this https URL.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Collaborative Auto-encoding for Blind Image Quality Assessment</b></summary>
  <p><b>编号</b>：[441]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14684</p>
  <p><b>作者</b>：Zehong Zhou,  Fei Zhou,  Guoping Qiu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important real-world applications, real-world applications, Blind image quality, image quality assessment, challenging problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Blind image quality assessment (BIQA) is a challenging problem with important
real-world applications. Recent efforts attempting to exploit powerful
representations by deep neural networks (DNN) are hindered by the lack of
subjectively annotated data. This paper presents a novel BIQA method which
overcomes this fundamental obstacle. Specifically, we design a pair of
collaborative autoencoders (COAE) consisting of a content autoencoder (CAE) and
a distortion autoencoder (DAE) that work together to extract content and
distortion representations, which are shown to be highly descriptive of image
quality. While the CAE follows a standard codec procedure, we introduce the
CAE-encoded feature as an extra input to the DAE's decoder for reconstructing
distorted images, thus effectively forcing DAE's encoder to extract distortion
representations. The self-supervised learning framework allows the COAE
including two feature extractors to be trained by almost unlimited amount of
data, thus leaving limited samples with annotations to finetune a BIQA model.
We will show that the proposed BIQA method achieves state-of-the-art
performance and has superior generalization capability over other learning
based models. The codes are available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Optimal Linear Subspace Search: Learning to Construct Fast and  High-Quality Schedulers for Diffusion Models</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14677</p>
  <p><b>作者</b>：Zhongjie Duan,  Chengyu Wang,  Cen Chen,  Jun Huang,  Weining Qian</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：rivaling human artists, generation process, diffusion models, process, recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, diffusion models have become the most popular and powerful
methods in the field of image synthesis, even rivaling human artists in
artistic creativity. However, the key issue currently limiting the application
of diffusion models is its extremely slow generation process. Although several
methods were proposed to speed up the generation process, there still exists a
trade-off between efficiency and quality. In this paper, we first provide a
detailed theoretical and empirical analysis of the generation process of the
diffusion models based on schedulers. We transform the designing problem of
schedulers into the determination of several parameters, and further transform
the accelerated generation process into an expansion process of the linear
subspace. Based on these analyses, we consequently propose a novel method
called Optimal Linear Subspace Search (OLSS), which accelerates the generation
process by searching for the optimal approximation process of the complete
generation process in the linear subspaces spanned by latent variables. OLSS is
able to generate high-quality images with a very small number of steps. To
demonstrate the effectiveness of our method, we conduct extensive comparative
experiments on open-source diffusion models. Experimental results show that
with a given number of steps, OLSS can significantly improve the quality of
generated images. Using an NVIDIA A100 GPU, we make it possible to generate a
high-quality image by Stable Diffusion within only one second without other
optimization techniques.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：T1: Scaling Diffusion Probabilistic Fields to High-Resolution on Unified  Visual Modalities</b></summary>
  <p><b>编号</b>：[450]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14674</p>
  <p><b>作者</b>：Kangfu Mei,  Mo Zhou,  Vishal M. Patel</p>
  <p><b>备注</b>：for project page, see this https URL</p>
  <p><b>关键词</b>：Diffusion Probabilistic Field, Probabilistic Field, continuous functions defined, Diffusion Probabilistic, metric spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion Probabilistic Field (DPF) models the distribution of continuous
functions defined over metric spaces. While DPF shows great potential for
unifying data generation of various modalities including images, videos, and 3D
geometry, it does not scale to a higher data resolution. This can be attributed
to the ``scaling property'', where it is difficult for the model to capture
local structures through uniform sampling. To this end, we propose a new model
comprising of a view-wise sampling algorithm to focus on local structure
learning, and incorporating additional guidance, e.g., text description, to
complement the global geometry. The model can be scaled to generate
high-resolution data while unifying multiple modalities. Experimental results
on data generation in various modalities demonstrate the effectiveness of our
model, as well as its potential as a foundation framework for scalable
modality-unified visual content generation.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Quantifying Character Similarity with Vision Transformers</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14672</p>
  <p><b>作者</b>：Xinmei Yang,  Abhishek Arora,  Shao-Yu Jheng,  Melissa Dell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantitative social science, require linking data, noisy sources, social science, data from multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Record linkage is a bedrock of quantitative social science, as analyses often
require linking data from multiple, noisy sources. Off-the-shelf string
matching methods are widely used, as they are straightforward and cheap to
implement and scale. Not all character substitutions are equally probable, and
for some settings there are widely used handcrafted lists denoting which string
substitutions are more likely, that improve the accuracy of string matching.
However, such lists do not exist for many settings, skewing research with
linked datasets towards a few high-resource contexts that are not
representative of the diversity of human societies. This study develops an
extensible way to measure character substitution costs for OCR'ed documents, by
employing large-scale self-supervised training of vision transformers (ViT)
with augmented digital fonts. For each language written with the CJK script, we
contrastively learn a metric space where different augmentations of the same
character are represented nearby. In this space, homoglyphic characters - those
with similar appearance such as ``O'' and ``0'' - have similar vector
representations. Using the cosine distance between characters' representations
as the substitution cost in an edit distance matching algorithm significantly
improves record linkage compared to other widely used string matching methods,
as OCR errors tend to be homoglyphic in nature. Homoglyphs can plausibly
capture character visual similarity across any script, including low-resource
settings. We illustrate this by creating homoglyph sets for 3,000 year old
ancient Chinese characters, which are highly pictorial. Fascinatingly, a ViT is
able to capture relationships in how different abstract concepts were
conceptualized by ancient societies, that have been noted in the archaeological
literature.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：NegVSR: Augmenting Negatives for Generalized Noise Modeling in  Real-World Video Super-Resolution</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14669</p>
  <p><b>作者</b>：Yexing Song,  Meilin Wang,  Xiaoyu Xian,  Zhijing Yang,  Yuming Fan,  Yukai Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：VSR, synthesize high-resolution, VSR model, noise, video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The capability of video super-resolution (VSR) to synthesize high-resolution
(HR) video from ideal datasets has been demonstrated in many works. However,
applying the VSR model to real-world video with unknown and complex degradation
remains a challenging task. First, existing degradation metrics in most VSR
methods are not able to effectively simulate real-world noise and blur. On the
contrary, simple combinations of classical degradation are used for real-world
noise modeling, which led to the VSR model often being violated by
out-of-distribution noise. Second, many SR models focus on noise simulation and
transfer. Nevertheless, the sampled noise is monotonous and limited. To address
the aforementioned problems, we propose a Negatives augmentation strategy for
generalized noise modeling in Video Super-Resolution (NegVSR) task.
Specifically, we first propose sequential noise generation toward real-world
data to extract practical noise sequences. Then, the degeneration domain is
widely expanded by negative augmentation to build up various yet challenging
real-world noise sets. We further propose the augmented negative guidance loss
to learn robust features among augmented negatives effectively. Extensive
experiments on real-world datasets (e.g., VideoLQ and FLIR) show that our
method outperforms state-of-the-art methods with clear margins, especially in
visual quality.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Robust 3D-aware Object Classification via Discriminative  Render-and-Compare</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14668</p>
  <p><b>作者</b>：Artur Jesslen,  Guofeng Zhang,  Angtian Wang,  Alan Yuille,  Adam Kortylewski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classification.While current approaches, respective single-task models, single-task models, real-world applications, classification.While current</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world applications, it is essential to jointly estimate the 3D object
pose and class label of objects, i.e., to perform 3D-aware classification.While
current approaches for either image classification or pose estimation can be
extended to 3D-aware classification, we observe that they are inherently
limited: 1) Their performance is much lower compared to the respective
single-task models, and 2) they are not robust in out-of-distribution (OOD)
scenarios. Our main contribution is a novel architecture for 3D-aware
classification, which builds upon a recent work and performs comparably to
single-task models while being highly robust. In our method, an object category
is represented as a 3D cuboid mesh composed of feature vectors at each mesh
vertex. Using differentiable rendering, we estimate the 3D object pose by
minimizing the reconstruction error between the mesh and the feature
representation of the target image. Object classification is then performed by
comparing the reconstruction losses across object categories. Notably, the
neural texture of the mesh is trained in a discriminative manner to enhance the
classification performance while also avoiding local optima in the
reconstruction loss. Furthermore, we show how our method and feed-forward
neural networks can be combined to scale the render-and-compare approach to
larger numbers of categories. Our experiments on PASCAL3D+, occluded-PASCAL3D+,
and OOD-CV show that our method outperforms all baselines at 3D-aware
classification by a wide margin in terms of performance and robustness.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Dealing with Cross-Task Class Discrimination in Online Continual  Learning</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14657</p>
  <p><b>作者</b>：Yiduo Guo,  Bing Liu,  Dongyan Zhao</p>
  <p><b>备注</b>：Accepted by CVPR2023</p>
  <p><b>关键词</b>：Existing continual learning, replay data, Existing continual, research regards catastrophic, catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing continual learning (CL) research regards catastrophic forgetting
(CF) as almost the only challenge. This paper argues for another challenge in
class-incremental learning (CIL), which we call cross-task class discrimination
(CTCD),~i.e., how to establish decision boundaries between the classes of the
new task and old tasks with no (or limited) access to the old task data. CTCD
is implicitly and partially dealt with by replay-based methods. A replay method
saves a small amount of data (replay data) from previous tasks. When a batch of
current task data arrives, the system jointly trains the new data and some
sampled replay data. The replay data enables the system to partially learn the
decision boundaries between the new classes and the old classes as the amount
of the saved data is small. However, this paper argues that the replay approach
also has a dynamic training bias issue which reduces the effectiveness of the
replay data in solving the CTCD problem. A novel optimization objective with a
gradient-based adaptive method is proposed to dynamically deal with the problem
in the online CL process. Experimental results show that the new method
achieves much better results in online CL.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code  Generation</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14637</p>
  <p><b>作者</b>：Davit Soselia,  Khalid Saifullah,  Tianyi Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CSS code generation, development and design, Automated HTML, CSS code, important yet challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated HTML/CSS code generation from screenshots is an important yet
challenging problem with broad applications in website development and design.
In this paper, we present a novel vision-code transformer approach that
leverages an Encoder-Decoder architecture as well as explore actor-critic
fine-tuning as a method for improving upon the baseline. For this purpose, two
image encoders are compared: Vision Transformer (ViT) and Document Image
Transformer (DiT).
We propose an end-to-end pipeline that can generate high-quality code
snippets directly from screenshots, streamlining the website creation process
for developers. To train and evaluate our models, we created a synthetic
dataset of 30,000 unique pairs of code and corresponding screenshots.
We evaluate the performance of our approach using a combination of automated
metrics such as MSE, BLEU, IoU, and a novel htmlBLEU score, where our models
demonstrated strong performance. We establish a strong baseline with the
DiT-GPT2 model and show that actor-critic can be used to improve IoU score from
the baseline of 0.64 to 0.79 and lower MSE from 12.25 to 9.02. We achieved
similar performance as when using larger models, with much lower computational
cost.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Realistically distributing object placements in synthetic training data  improves the performance of vision-based object detection models</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14621</p>
  <p><b>作者</b>：Setareh Dabiri,  Vasileios Lioutas,  Berend Zwartsenberg,  Yunpeng Liu,  Matthew Niedoba,  Xiaoxuan Liang,  Dylan Green,  Justice Sefas,  Jonathan Wilder Lavington,  Frank Wood,  Adam Scibior</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthetic data, object placement distribution, important to make, synthetic data fixed, distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When training object detection models on synthetic data, it is important to
make the distribution of synthetic data as close as possible to the
distribution of real data. We investigate specifically the impact of object
placement distribution, keeping all other aspects of synthetic data fixed. Our
experiment, training a 3D vehicle detection model in CARLA and testing on
KITTI, demonstrates a substantial improvement resulting from improving the
object placement distribution.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Exploring the Grounding Issues in Image Caption</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14616</p>
  <p><b>作者</b>：Pin-Er Chen,  Hsin-Yu Chou,  Po-Ya Angela Wang,  Yu-Hsiang Tseng,  Shu-Kai Hsieh</p>
  <p><b>备注</b>：10 pages, 10 figures</p>
  <p><b>关键词</b>：computational cognitive-linguistic view, Ecological Niche Association, cognitive-linguistic view, paper explores, computational cognitive-linguistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the grounding issue concerning multimodal semantic
representation from a computational cognitive-linguistic view. Five perceptual
properties of groundedness are annotated and analyzed: Affordance, Perceptual
salience, Object number, Gaze cueing, and Ecological Niche Association (ENA).
We annotated selected images from the Flickr30k dataset with exploratory
analyses and statistical modeling of their captions. Our findings suggest that
a comprehensive understanding of an object or event requires cognitive
attention, semantic distinctions in linguistic expression, and multimodal
construction. During this construction process, viewers integrate situated
meaning and affordance into multimodal semantics, which is consolidated into
image captions used in the image-text dataset incorporating visual and textual
elements. Our findings suggest that situated meaning and affordance grounding
are critical for grounded natural language understanding systems to generate
appropriate responses and show the potential to advance the understanding of
human construal in diverse situations.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Assessment of Anterior Cruciate Ligament Injury Risk Based on Human Key  Points Detection Algorithm</b></summary>
  <p><b>编号</b>：[487]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14612</p>
  <p><b>作者</b>：Ziyu Gong,  Xiong Zhao,  Chen Yang</p>
  <p><b>备注</b>：17 pages,and 6 figures</p>
  <p><b>关键词</b>：anterior cruciate ligament, human body detected, ACL potential injury, computer vision technology, key points data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper aims to detect the potential injury risk of the anterior cruciate
ligament (ACL) by proposing an ACL potential injury risk assessment algorithm
based on key points of the human body detected using computer vision
technology. To obtain the key points data of the human body in each frame,
OpenPose, an open source computer vision algorithm, was employed. The obtained
data underwent preprocessing and were then fed into an ACL potential injury
feature extraction model based on the Landing Error Evaluation System (LESS).
This model extracted several important parameters, including the knee flexion
angle, the trunk flexion on the sagittal plane, trunk flexion angle on the
frontal plane, the ankle knee horizontal distance, and the ankle shoulder
horizontal distance. Each of these features was assigned a threshold interval,
and a segmented evaluation function was utilized to score them accordingly. To
calculate the final score of the participant, the score values were input into
a weighted scoring model designed based on the Analytic Hierarchy Process
(AHP). The AHP based model takes into account the relative importance of each
feature in the overall assessment. The results demonstrate that the proposed
algorithm effectively detects the potential risk of ACL injury. The proposed
algorithm demonstrates its effectiveness in detecting ACL injury risk, offering
valuable insights for injury prevention and intervention strategies in sports
and related fields. Code is available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：FaceFusion: Exploiting Full Spectrum of Multiple Datasets</b></summary>
  <p><b>编号</b>：[493]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14601</p>
  <p><b>作者</b>：Chiyoung Song,  Dongjae Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-performance face recognition, recognition embedding model, training high-performance face, face recognition embedding, dominating aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The size of training dataset is known to be among the most dominating aspects
of training high-performance face recognition embedding model. Building a large
dataset from scratch could be cumbersome and time-intensive, while combining
multiple already-built datasets poses the risk of introducing large amount of
label noise. We present a novel training method, named FaceFusion. It creates a
fused view of different datasets that is untainted by identity conflicts, while
concurrently training an embedding network using the view in an end-to-end
fashion. Using the unified view of combined datasets enables the embedding
network to be trained against the entire spectrum of the datasets, leading to a
noticeable performance boost. Extensive experiments confirm superiority of our
method, whose performance in public evaluation datasets surpasses not only that
of using a single training dataset, but also that of previously known methods
under various training circumstances.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Vision + Language Applications: A Survey</b></summary>
  <p><b>编号</b>：[496]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14598</p>
  <p><b>作者</b>：Yutong Zhou,  Nobutaka Shimada</p>
  <p><b>备注</b>：Accepted by GCV @CVPR2023</p>
  <p><b>关键词</b>：attracted significant interest, recent years due, generation has attracted, attracted significant, significant interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-image generation has attracted significant interest from researchers
and practitioners in recent years due to its widespread and diverse
applications across various industries. Despite the progress made in the domain
of vision and language research, the existing literature remains relatively
limited, particularly with regard to advancements and applications in this
field. This paper explores a relevant research track within multimodal
applications, including text, vision, audio, and others. In addition to the
studies discussed in this paper, we are also committed to continually updating
the latest relevant papers, datasets, application projects and corresponding
information at this https URL</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Real-Time Idling Vehicles Detection Using Combined Audio-Visual Deep  Learning</b></summary>
  <p><b>编号</b>：[512]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14579</p>
  <p><b>作者</b>：Xiwen Li,  Tristalee Mangin,  Surojit Saha,  Evan Blanchard,  Dillon Tang,  Henry Poppe,  Nathan Searle,  Ouk Choi,  Kerry Kelly,  Ross Whitaker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adverse health effects, poor air quality, release greenhouse gases, numerous adverse health, Combustion vehicle emissions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combustion vehicle emissions contribute to poor air quality and release
greenhouse gases into the atmosphere, and vehicle pollution has been associated
with numerous adverse health effects. Roadways with extensive waiting and/or
passenger drop off, such as schools and hospital drop-off zones, can result in
high incidence and density of idling vehicles. This can produce micro-climates
of increased vehicle pollution. Thus, the detection of idling vehicles can be
helpful in monitoring and responding to unnecessary idling and be integrated
into real-time or off-line systems to address the resulting pollution. In this
paper we present a real-time, dynamic vehicle idling detection algorithm. The
proposed idle detection algorithm and notification rely on an algorithm to
detect these idling vehicles. The proposed method relies on a multi-sensor,
audio-visual, machine-learning workflow to detect idling vehicles visually
under three conditions: moving, static with the engine on, and static with the
engine off. The visual vehicle motion detector is built in the first stage, and
then a contrastive-learning-based latent space is trained for classifying
static vehicle engine sound. We test our system in real-time at a hospital
drop-off point in Salt Lake City. This in-situ dataset was collected and
annotated, and it includes vehicles of varying models and types. The
experiments show that the method can detect engine switching on or off
instantly and achieves 71.01 mean average precision (mAP).</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Towards Early Prediction of Human iPSC Reprogramming Success</b></summary>
  <p><b>编号</b>：[516]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14575</p>
  <p><b>作者</b>：Abhineet Singh,  Ila Jasra,  Omar Mouhammed,  Nidheesh Dadheech,  Nilanjan Ray,  James Shapiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：therapies.The minuscule success, minuscule success rate, paper presents advancements, automated early-stage prediction, reprogramming human induced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents advancements in automated early-stage prediction of the
success of reprogramming human induced pluripotent stem cells (iPSCs) as a
potential source for regenerative cell therapies.The minuscule success rate of
iPSC-reprogramming of around $ 0.01% $ to $ 0.1% $ makes it labor-intensive,
time-consuming, and exorbitantly expensive to generate a stable iPSC line.
Since that requires culturing of millions of cells and intense biological
scrutiny of multiple clones to identify a single optimal clone. The ability to
reliably predict which cells are likely to establish as an optimal iPSC line at
an early stage of pluripotency would therefore be ground-breaking in rendering
this a practical and cost-effective approach to personalized medicine. Temporal
information about changes in cellular appearance over time is crucial for
predicting its future growth outcomes. In order to generate this data, we first
performed continuous time-lapse imaging of iPSCs in culture using an ultra-high
resolution microscope. We then annotated the locations and identities of cells
in late-stage images where reliable manual identification is possible. Next, we
propagated these labels backwards in time using a semi-automated tracking
system to obtain labels for early stages of growth. Finally, we used this data
to train deep neural networks to perform automatic cell segmentation and
classification. Our code and data are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：GO-LDA: Generalised Optimal Linear Discriminant Analysis</b></summary>
  <p><b>编号</b>：[521]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14568</p>
  <p><b>作者</b>：Jiahui Liu,  Xiaohao Cai,  Mahesan Niranjan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：LDA, multiclass LDA, data analysis research, research and practice, Generalised Optimal LDA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear discriminant analysis (LDA) has been a useful tool in pattern
recognition and data analysis research and practice. While linearity of class
boundaries cannot always be expected, nonlinear projections through pre-trained
deep neural networks have served to map complex data onto feature spaces in
which linear discrimination has served well. The solution to binary LDA is
obtained by eigenvalue analysis of within-class and between-class scatter
matrices. It is well known that the multiclass LDA is solved by an extension to
the binary LDA, a generalised eigenvalue problem, from which the largest
subspace that can be extracted is of dimension one lower than the number of
classes in the given problem. In this paper, we show that, apart from the first
of the discriminant directions, the generalised eigenanalysis solution to
multiclass LDA does neither yield orthogonal discriminant directions nor
maximise discrimination of projected data along them. Surprisingly, to the best
of our knowledge, this has not been noted in decades of literature on LDA. To
overcome this drawback, we present a derivation with a strict theoretical
support for sequentially obtaining discriminant directions that are orthogonal
to previously computed ones and maximise in each step the Fisher criterion. We
show distributions of projections along these axes and demonstrate that
discrimination of data projected onto these discriminant directions has optimal
separation, which is much higher than those from the generalised eigenvectors
of the multiclass LDA. Using a wide range of benchmark tasks, we present a
comprehensive empirical demonstration that on a number of pattern recognition
and classification problems, the optimal discriminant subspaces obtained by the
proposed method, referred to as GO-LDA (Generalised Optimal LDA), can offer
superior accuracy.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Constant Memory Attentive Neural Processes</b></summary>
  <p><b>编号</b>：[522]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14567</p>
  <p><b>作者</b>：Leo Feng,  Frederick Tung,  Hossein Hajimirsadeghi,  Yoshua Bengio,  Mohamed Osama Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：estimating predictive uncertainties, Attentive Neural Processes, Neural Processes, predictive uncertainties, Constant Memory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Processes (NPs) are efficient methods for estimating predictive
uncertainties. NPs comprise of a conditioning phase where a context dataset is
encoded, a querying phase where the model makes predictions using the context
dataset encoding, and an updating phase where the model updates its encoding
with newly received datapoints. However, state-of-the-art methods require
additional memory which scales linearly or quadratically with the size of the
dataset, limiting their applications, particularly in low-resource settings. In
this work, we propose Constant Memory Attentive Neural Processes (CMANPs), an
NP variant which only requires constant memory for the conditioning, querying,
and updating phases. In building CMANPs, we propose Constant Memory Attention
Block (CMAB), a novel general-purpose attention block that can compute its
output in constant memory and perform updates in constant computation.
Empirically, we show CMANPs achieve state-of-the-art results on meta-regression
and image completion tasks while being (1) significantly more memory efficient
than prior methods and (2) more scalable to harder settings.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Exploring Semantic Variations in GAN Latent Spaces via Matrix  Factorization</b></summary>
  <p><b>编号</b>：[530]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14551</p>
  <p><b>作者</b>：Andrey Palaev,  Rustam A. Lukmanov,  Adil Khan</p>
  <p><b>备注</b>：Accepted at ICLR 2023 Tiny Papers</p>
  <p><b>关键词</b>：Controlled data generation, Controlled data, data generation, desirable but challenging, challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlled data generation with GANs is desirable but challenging due to the
nonlinearity and high dimensionality of their latent spaces. In this work, we
explore image manipulations learned by GANSpace, a state-of-the-art method
based on PCA. Through quantitative and qualitative assessments we show: (a)
GANSpace produces a wide range of high-quality image manipulations, but they
can be highly entangled, limiting potential use cases; (b) Replacing PCA with
ICA improves the quality and disentanglement of manipulations; (c) The quality
of the generated images can be sensitive to the size of GANs, but regardless of
their complexity, fundamental controlling directions can be observed in their
latent spaces.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Slovo: Russian Sign Language Dataset</b></summary>
  <p><b>编号</b>：[545]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14527</p>
  <p><b>作者</b>：Alexander Kapitanov,  Karina Kvanchiani,  Alexander Nagaev,  Elizaveta Petrova</p>
  <p><b>备注</b>：russian sign language recognition dataset, open-source</p>
  <p><b>关键词</b>：language recognition task, sign language recognition, Russian Sign Language, sign language, suitable dataset due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the main challenges of the sign language recognition task is the
difficulty of collecting a suitable dataset due to the gap between deaf and
hearing society. In addition, the sign language in each country differs
significantly, which obliges the creation of new data for each of them. This
paper presents the Russian Sign Language (RSL) video dataset Slovo, produced
using crowdsourcing platforms. The dataset contains 20,000 FullHD recordings,
divided into 1,000 classes of RSL gestures received by 194 signers. We also
provide the entire dataset creation pipeline, from data collection to video
annotation, with the following demo application. Several neural networks are
trained and evaluated on the Slovo to demonstrate its teaching ability.
Proposed data and pre-trained models are publicly available.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Design a Delicious Lunchbox in Style</b></summary>
  <p><b>编号</b>：[547]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14522</p>
  <p><b>作者</b>：Yutong Zhou</p>
  <p><b>备注</b>：Accepted by WiCV @CVPR2023 (In Progress). Dataset: this https URL</p>
  <p><b>关键词</b>：channel-wise attention modules, generative adversarial network, cyclic generative adversarial, generative adversarial, adversarial network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a cyclic generative adversarial network with spatial-wise and
channel-wise attention modules for text-to-image synthesis. To accurately
depict and design scenes with multiple occluded objects, we design a
pre-trained ordering recovery model and a generative adversarial network to
predict layout and composite novel box lunch presentations. In the experiments,
we devise the Bento800 dataset to evaluate the performance of the text-to-image
synthesis model and the layout generation & image composition model. This paper
is the continuation of our previous paper works. We also present additional
experiments and qualitative performance comparisons to verify the effectiveness
of our proposed method. Bento800 dataset is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Eliminating Spurious Correlations from Pre-trained Models via Data  Mixing</b></summary>
  <p><b>编号</b>：[548]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14521</p>
  <p><b>作者</b>：Yihao Xue,  Ali Payani,  Yu Yang,  Baharan Mirzasoleiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable convergence, Machine learning models, Machine learning, robustness properties, spurious correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models pre-trained on large datasets have achieved
remarkable convergence and robustness properties. However, these models often
exploit spurious correlations between certain attributes and labels, which are
prevalent in the majority of examples within specific categories but are not
predictive of these categories in general. The learned spurious correlations
may persist even after fine-tuning on new data, which degrades models'
performance on examples that do not exhibit the spurious correlation. In this
work, we propose a simple and highly effective method to eliminate spurious
correlations from pre-trained models. The key idea of our method is to leverage
a small set of examples with spurious attributes, and balance the spurious
attributes across all classes via data mixing. We theoretically confirm the
effectiveness of our method, and empirically demonstrate its state-of-the-art
performance on various vision and NLP tasks, including eliminating spurious
correlations from pre-trained ResNet50 on Waterbirds and CelebA, adversarially
pre-trained ResNet50 on ImageNet, and BERT pre-trained on CivilComments.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Windscreen Optical Quality for AI Algorithms: Refractive Power and MTF  not Sufficient</b></summary>
  <p><b>编号</b>：[551]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14513</p>
  <p><b>作者</b>：Dominik Werner Wolf,  Markus Ulrich,  Alexander Braun</p>
  <p><b>备注</b>：Submitted to IEEE ITSC-2023</p>
  <p><b>关键词</b>：future autonomous driving, advanced driver assistance, optical quality, driver assistance system, Windscreen optical quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Windscreen optical quality is an important aspect of any advanced driver
assistance system, and also for future autonomous driving, as today at least
some cameras of the sensor suite are situated behind the windscreen. Automotive
mass production processes require measurement systems that characterize the
optical quality of the windscreens in a meaningful way, which for modern
perception stacks implies meaningful for artificial intelligence (AI)
algorithms. The measured optical quality needs to be linked to the performance
of these algorithms, such that performance limits - and thus production
tolerance limits - can be defined. In this article we demonstrate that the main
metric established in the industry - refractive power - is fundamentally not
capable of capturing relevant optical properties of windscreens. Further, as
the industry is moving towards the modulation transfer function (MTF) as an
alternative, we mathematically show that this metric cannot be used on
windscreens alone, but that the windscreen forms a novel optical system
together with the optics of the camera system. Hence, the required goal of a
qualification system that is installed at the windscreen supplier and
independently measures the optical quality cannot be achieved using MTF. We
propose a novel concept to determine the optical quality of windscreens and to
use simulation to link this optical quality to the performance of AI
algorithms, which can hopefully lead to novel inspection systems.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Point2SSM: Learning Morphological Variations of Anatomies from Point  Cloud</b></summary>
  <p><b>编号</b>：[562]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14486</p>
  <p><b>作者</b>：Jadie Adams,  Shireen Elhabian</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：accurately construct correspondence-based, construct correspondence-based statistical, statistical shape models, correspondence-based statistical shape, accurately construct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Point2SSM, a novel unsupervised learning approach that can
accurately construct correspondence-based statistical shape models (SSMs) of
anatomy directly from point clouds. SSMs are crucial in clinical research for
analyzing the population-level morphological variation in bones and organs.
However, traditional methods for creating SSMs have limitations that hinder
their widespread adoption, such as the need for noise-free surface meshes or
binary volumes, reliance on assumptions or predefined templates, and
simultaneous optimization of the entire cohort leading to lengthy inference
times given new data. Point2SSM overcomes these barriers by providing a
data-driven solution that infers SSMs directly from raw point clouds, reducing
inference burdens and increasing applicability as point clouds are more easily
acquired. Deep learning on 3D point clouds has seen recent success in
unsupervised representation learning, point-to-point matching, and shape
correspondence; however, their application to constructing SSMs of anatomies is
largely unexplored. In this work, we benchmark state-of-the-art point cloud
deep networks on the task of SSM and demonstrate that they are not robust to
the challenges of anatomical SSM, such as noisy, sparse, or incomplete input
and significantly limited training data. Point2SSM addresses these challenges
via an attention-based module that provides correspondence mappings from
learned point features. We demonstrate that the proposed method significantly
outperforms existing networks in terms of both accurate surface sampling and
correspondence, better capturing population-level statistics.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Integrated Object Deformation and Contact Patch Estimation from  Visuo-Tactile Feedback</b></summary>
  <p><b>编号</b>：[570]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14470</p>
  <p><b>作者</b>：Mark Van der Merwe,  Youngsun Wi,  Dmitry Berenson,  Nima Fazeli</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：Deforming Contact Field, Neural Deforming Contact, contact, force transmission, manipulation of compliant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reasoning over the interplay between object deformation and force
transmission through contact is central to the manipulation of compliant
objects. In this paper, we propose Neural Deforming Contact Field (NDCF), a
representation that jointly models object deformations and contact patches from
visuo-tactile feedback using implicit representations. Representing the object
geometry and contact with the environment implicitly allows a single model to
predict contact patches of varying complexity. Additionally, learning geometry
and contact simultaneously allows us to enforce physical priors, such as
ensuring contacts lie on the surface of the object. We propose a neural network
architecture to learn a NDCF, and train it using simulated data. We then
demonstrate that the learned NDCF transfers directly to the real-world without
the need for fine-tuning. We benchmark our proposed approach against a baseline
representing geometry and contact patches with point clouds. We find that NDCF
performs better on simulated data and in transfer to the real-world.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Run Like a Girl! Sports-Related Gender Bias in Language and Vision</b></summary>
  <p><b>编号</b>：[571]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14468</p>
  <p><b>作者</b>：Sophia Harrison,  Eleonora Gualdoni,  Gemma Boleda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Language and Vision, perpetuate harmful stereotypes, Vision datasets, stereotypes and discrimination, potential to perpetuate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gender bias in Language and Vision datasets and models has the potential to
perpetuate harmful stereotypes and discrimination. We analyze gender bias in
two Language and Vision datasets. Consistent with prior work, we find that both
datasets underrepresent women, which promotes their invisibilization. Moreover,
we hypothesize and find that a bias affects human naming choices for people
playing sports: speakers produce names indicating the sport (e.g. 'tennis
player' or 'surfer') more often when it is a man or a boy participating in the
sport than when it is a woman or a girl, with an average of 46% vs. 35% of
sports-related names for each gender. A computational model trained on these
naming data reproduces the bias. We argue that both the data and the model
result in representational harm against women.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：FLAIR #2: textural and temporal information for semantic segmentation  from multi-source optical imagery</b></summary>
  <p><b>编号</b>：[572]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14467</p>
  <p><b>作者</b>：Anatol Garioud,  Apolline De Wit,  Marc Poupée,  Marion Valette,  Sébastien Giordano,  Boris Wattrelos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mapping land cover, semantic segmentation task, segmentation task aimed, high spatial resolution, land cover</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The FLAIR #2 dataset hereby presented includes two very distinct types of
data, which are exploited for a semantic segmentation task aimed at mapping
land cover. The data fusion workflow proposes the exploitation of the fine
spatial and textural information of very high spatial resolution (VHR)
mono-temporal aerial imagery and the temporal and spectral richness of high
spatial resolution (HR) time series of Copernicus Sentinel-2 satellite images.
The French National Institute of Geographical and Forest Information (IGN), in
response to the growing availability of high-quality Earth Observation (EO)
data, is actively exploring innovative strategies to integrate these data with
heterogeneous characteristics. IGN is therefore offering this dataset to
promote innovation and improve our knowledge of our territories.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Sorted Convolutional Network for Achieving Continuous Rotational  Invariance</b></summary>
  <p><b>编号</b>：[574]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14462</p>
  <p><b>作者</b>：Hanlin Mo,  Guoying Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：considerable attention recently, gained considerable attention, convolutional neural networks, computer vision tasks, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topic of achieving rotational invariance in convolutional neural networks
(CNNs) has gained considerable attention recently, as this invariance is
crucial for many computer vision tasks such as image classification and
matching. In this letter, we propose a Sorting Convolution (SC) inspired by
some hand-crafted features of texture images, which achieves continuous
rotational invariance without requiring additional learnable parameters or data
augmentation. Further, SC can directly replace the conventional convolution
operations in a classic CNN model to achieve its rotational invariance. Based
on MNIST-rot dataset, we first analyze the impact of convolutional kernel
sizes, different sampling and sorting strategies on SC's rotational invariance,
and compare our method with previous rotation-invariant CNN models. Then, we
combine SC with VGG, ResNet and DenseNet, and conduct classification
experiments on popular texture and remote sensing image datasets. Our results
demonstrate that SC achieves the best performance in the aforementioned tasks.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Prompting Language-Informed Distribution for Compositional Zero-Shot  Learning</b></summary>
  <p><b>编号</b>：[587]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14428</p>
  <p><b>作者</b>：Wentao Bao,  Lichang Chen,  Heng Huang,  Yu Kong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sliced tomatoes, compositional visual concepts, sliced potatoes, red tomatoes, recognize unseen compositional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The compositional zero-shot learning (CZSL) task aims to recognize unseen
compositional visual concepts (i.e., sliced tomatoes), where the models are
learned only from the seen compositions (i.e., sliced potatoes and red
tomatoes). Thanks to the prompt tuning on large pre-trained visual language
models such as CLIP, recent literature shows impressively better CZSL
performance than traditional vision-based methods. However, the key aspects
that impact the generalization to unseen compositions, including the diversity
and informativeness of class context, and the entanglement between visual
primitives (i.e., states and objects), are not properly addressed in existing
CLIP-based CZSL literature. In this paper, we propose a model by prompting the
language-informed distribution, aka., PLID, for the CZSL task. Specifically,
the PLID leverages pre-trained large language models (LLM) to 1) formulate the
language-informed class distribution, and 2) enhance the compositionality of
the softly prompted class embedding. Moreover, a stochastic logit mixup
strategy is proposed to dynamically fuse the decisions from the predictions in
the compositional and the primitive logit space. Orthogonal to the existing
literature of soft, hard, or distributional prompts, our method advocates
prompting the LLM-supported class distribution that leads to a better
compositional zero-shot generalization. Experimental results on MIT-States,
UT-Zappos, and C-GQA datasets show the superior performance of the PLID to the
prior arts. The code and models will be publicly released.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Image Manipulation via Multi-Hop Instructions -- A New Dataset and  Weakly-Supervised Neuro-Symbolic Approach</b></summary>
  <p><b>编号</b>：[588]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14410</p>
  <p><b>作者</b>：Harman Singh,  Poorva Garg,  Mohit Gupta,  Kevin Shah,  Arnab Kumar Mondal,  Dinesh Khandelwal,  Parag Singla,  Dinesh Garg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Symbolic Concept Learning, natural language text, Neuro Symbolic Concept, multi-modal spaces, multiple AI applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are interested in image manipulation via natural language text -- a task
that is useful for multiple AI applications but requires complex reasoning over
multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning
(NSCL), which has been quite effective for the task of Visual Question
Answering (VQA), for the task of image manipulation. Our system referred to as
NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and
only requires weak supervision in the form of annotated data for VQA. NeuroSIM
parses an instruction into a symbolic program, based on a Domain Specific
Language (DSL) comprising of object attributes and manipulation operations,
that guides its execution. We create a new dataset for the task, and extensive
experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA
baselines that make use of supervised data for manipulation.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Evolution: A Unified Formula for Feature Operators from a High-level  Perspective</b></summary>
  <p><b>编号</b>：[589]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14409</p>
  <p><b>作者</b>：Zhicheng Cai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feature operators, self-attention and involution, Evolution, operators, feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, different types of feature operators (e.g., convolution,
self-attention and involution) utilize different approaches to extract and
aggregate the features. Resemblance can be hardly discovered from their
mathematical formulas. However, these three operators all serve the same
paramount purpose and bear no difference in essence. Hence we probe into the
essence of various feature operators from a high-level perspective, transformed
their components equivalently, and explored their mathematical expressions
within higher dimensions. We raise one clear and concrete unified formula for
different feature operators termed as Evolution. Evolution utilizes the
Evolution Function to generate the Evolution Kernel, which extracts and
aggregates the features in certain positions of the input feature map. We
mathematically deduce the equivalent transformation from the traditional
formulas of these feature operators to Evolution and prove the unification. In
addition, we discuss the forms of Evolution Functions and the properties of
generated Evolution Kernels, intending to give inspirations to the further
research and innovations of powerful feature operators.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Layer-adaptive Structured Pruning Guided by Latency</b></summary>
  <p><b>编号</b>：[592]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14403</p>
  <p><b>作者</b>：Siyuan Pan,  Linna Zhang,  Jie Zhang,  Xiaoshuang Li,  Liang Hou,  Xiaobing Tu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2010.07611, arXiv:2110.10811 by other authors</p>
  <p><b>关键词</b>：simplify network architecture, improve inference speed, pruning, inference speed, Structured pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured pruning can simplify network architecture and improve inference
speed. Combined with the underlying hardware and inference engine in which the
final model is deployed, better results can be obtained by using latency
collaborative loss function to guide network pruning together. Existing pruning
methods that optimize latency have demonstrated leading performance, however,
they often overlook the hardware features and connection in the network. To
address this problem, we propose a global importance score SP-LAMP(Structured
Pruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance
score LAMP from unstructured pruning to structured pruning. In SP-LAMP, each
layer includes a filter with an SP-LAMP score of 1, and the remaining filters
are grouped. We utilize a group knapsack solver to maximize the SP-LAMP score
under latency constraints. In addition, we improve the strategy of collect the
latency to make it more accurate. In particular, for ResNet50/ResNet18 on
ImageNet and CIFAR10, SP-LAMP is 1.28x/8.45x faster with +1.7%/-1.57% top-1
accuracy changed, respectively. Experimental results in ResNet56 on CIFAR10
demonstrate that our algorithm achieves lower latency compared to alternative
approaches while ensuring accuracy and FLOPs.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Towards credible visual model interpretation with path attribution</b></summary>
  <p><b>编号</b>：[596]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14395</p>
  <p><b>作者</b>：Naveed Akhtar,  Muhammad A. A. K. Jalwana</p>
  <p><b>备注</b>：ICML'23 paper (text improved for CV community)</p>
  <p><b>关键词</b>：visual model interpretation, interpretation tools due, post-hoc model interpretation, model interpretation tools, attribution framework stands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originally inspired by game-theory, path attribution framework stands out
among the post-hoc model interpretation tools due to its axiomatic nature.
However, recent developments show that this framework can still suffer from
counter-intuitive results. Moreover, specifically for deep visual models, the
existing path-based methods also fall short on conforming to the original
intuitions that are the basis of the claimed axiomatic properties of this
framework. We address these problems with a systematic investigation, and
pinpoint the conditions in which the counter-intuitive results can be avoided
for deep visual model interpretation with the path attribution strategy. We
also devise a scheme to preclude the conditions in which visual model
interpretation can invalidate the axiomatic properties of path attribution.
These insights are combined into a method that enables reliable visual model
interpretation. Our findings are establish empirically with multiple datasets,
models and evaluation metrics. Extensive experiments show a consistent
performance gain of our method over the baselines.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Sophia: A Scalable Stochastic Second-order Optimizer for Language Model  Pre-training</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14342</p>
  <p><b>作者</b>：Hong Liu,  Zhiyuan Li,  David Hall,  Percy Liang,  Tengyu Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cost of training, massive cost, Clipped Stochastic Optimization, non-trivial improvement, algorithm would lead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the massive cost of language model pre-training, a non-trivial
improvement of the optimization algorithm would lead to a material reduction on
the time and cost of training. Adam and its variants have been state-of-the-art
for years, and more sophisticated second-order (Hessian-based) optimizers often
incur too much per-step overhead. In this paper, we propose Sophia,
Second-order Clipped Stochastic Optimization, a simple scalable second-order
optimizer that uses a light-weight estimate of the diagonal Hessian as the
pre-conditioner. The update is the moving average of the gradients divided by
the moving average of the estimated Hessian, followed by element-wise clipping.
The clipping controls the worst-case update size and tames the negative impact
of non-convexity and rapid change of Hessian along the trajectory. Sophia only
estimates the diagonal Hessian every handful of iterations, which has
negligible average per-step time and memory overhead. On language modeling with
GPT-2 models of sizes ranging from 125M to 770M, Sophia achieves a 2x speed-up
compared with Adam in the number of steps, total compute, and wall-clock time.
Theoretically, we show that Sophia adapts to the curvature in different
components of the parameters, which can be highly heterogeneous for language
modeling tasks. Our run-time bound does not depend on the condition number of
the loss.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：APPLS: A Meta-evaluation Testbed for Plain Language Summarization</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14341</p>
  <p><b>作者</b>：Yue Guo,  Tal August,  Gondy Leroy,  Trevor Cohen,  Lucy Lu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PLS, significant development, development of models, Plain Language, metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While there has been significant development of models for Plain Language
Summarization (PLS), evaluation remains a challenge. This is in part because
PLS involves multiple, interrelated language transformations (e.g., adding
background explanations, removing specialized terminology). No metrics are
explicitly engineered for PLS, and the suitability of other text generation
evaluation metrics remains unclear. To address these concerns, our study
presents a granular meta-evaluation testbed, APPLS, designed to evaluate
existing metrics for PLS. Drawing on insights from previous research, we define
controlled perturbations for our testbed along four criteria that a metric of
plain language should capture: informativeness, simplification, coherence, and
faithfulness. Our analysis of metrics using this testbed reveals that current
metrics fail to capture simplification, signaling a crucial gap. In response,
we introduce POMME, a novel metric designed to assess text simplification in
PLS. We demonstrate its correlation with simplification perturbations and
validate across a variety of datasets. Our research contributes the first
meta-evaluation testbed for PLS and a comprehensive evaluation of existing
metrics, offering insights with relevance to other text generation tasks.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Anchor Prediction: Automatic Refinement of Internet Links</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14337</p>
  <p><b>作者</b>：Nelson F. Liu,  Kenton Lee,  Kristina Toutanova</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：providing convenient access, Internet links enable, links enable users, target webpage, enable users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet links enable users to deepen their understanding of a topic by
providing convenient access to related information. However, the majority of
links are unanchored -- they link to a target webpage as a whole, and readers
may expend considerable effort localizing the specific parts of the target
webpage that enrich their understanding of the link's source context. To help
readers effectively find information in linked webpages, we introduce the task
of anchor prediction, where the goal is to identify the specific part of the
linked target webpage that is most related to the source linking context. We
release the AuthorAnchors dataset, a collection of 34K naturally-occurring
anchored links, which reflect relevance judgments by the authors of the source
article. To model reader relevance judgments, we annotate and release
ReaderAnchors, an evaluation set of anchors that readers find useful. Our
analysis shows that effective anchor prediction often requires jointly
reasoning over lengthy source and target webpages to determine their implicit
relations and identify parts of the target webpage that are related but not
redundant. We benchmark a performant T5-based ranking approach to establish
baseline performance on the task, finding ample room for improvement.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Schema-Driven Information Extraction from Heterogeneous Tables</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14336</p>
  <p><b>作者</b>：Fan Bai,  Junmo Kang,  Gabriel Stanovsky,  Dayne Freitag,  Alan Ritter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explore the question, support cost-efficient information, extraction, information extraction, table extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the question of whether language models (LLMs) can
support cost-efficient information extraction from complex tables. We introduce
schema-driven information extraction, a new task that uses LLMs to transform
tabular data into structured records following a human-authored schema. To
assess various LLM's capabilities on this task, we develop a benchmark composed
of tables from three diverse domains: machine learning papers, chemistry
tables, and webpages. Accompanying the benchmark, we present InstrucTE, a table
extraction method based on instruction-tuned LLMs. This method necessitates
only a human-constructed extraction schema, and incorporates an error-recovery
strategy. Notably, InstrucTE demonstrates competitive performance without
task-specific labels, achieving an F1 score ranging from 72.3 to 95.7.
Moreover, we validate the feasibility of distilling more compact table
extraction models to minimize extraction costs and reduce API reliance. This
study paves the way for the future development of instruction-following models
for cost-efficient table extraction.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Automatic Model Selection with Large Language Models for Reasoning</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14333</p>
  <p><b>作者</b>：Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Qizhe Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Program-Aided Language Models, Language Models represent, strengths and weaknesses, large language model, Program-Aided Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chain-of-Thought and Program-Aided Language Models represent two distinct
reasoning methods, each with its own strengths and weaknesses. We demonstrate
that it is possible to combine the best of both worlds by using different
models for different problems, employing a large language model (LLM) to
perform model selection. Through a theoretical analysis, we discover that the
performance improvement is determined by the differences between the combined
methods and the success rate of choosing the correct model. On eight reasoning
datasets, our proposed approach shows significant improvements. Furthermore, we
achieve new state-of-the-art results on GSM8K and SVAMP with accuracies of
96.5% and 93.7%, respectively. Our code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Evaluating and Modeling Attribution for Cross-Lingual Question Answering</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14332</p>
  <p><b>作者</b>：Benjamin Muller,  John Wieting,  Jonathan H. Clark,  Tom Kwiatkowski,  Sebastian Ruder,  Livio Baldini Soares,  Roee Aharoni,  Jonathan Herzig,  Xinyi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Trustworthy answer content, instantly accessible, hard to access, attribution, answer content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trustworthy answer content is abundant in many high-resource languages and is
instantly accessible through question answering systems, yet this content can
be hard to access for those that do not speak these languages. The leap forward
in cross-lingual modeling quality offered by generative language models offers
much promise, yet their raw generations often fall short in factuality. To
improve trustworthiness in these systems, a promising direction is to attribute
the answer to a retrieved source, possibly in a content-rich language different
from the query. Our work is the first to study attribution for cross-lingual
question answering. First, we collect data in 5 languages to assess the
attribution level of a state-of-the-art cross-lingual QA system. To our
surprise, we find that a substantial portion of the answers is not attributable
to any retrieved passages (up to 50% of answers exactly matching a gold
reference) despite the system being able to attend directly to the retrieved
text. Second, to address this poor attribution level, we experiment with a wide
range of attribution detection techniques. We find that Natural Language
Inference models and PaLM 2 fine-tuned on a very small amount of attribution
data can accurately detect attribution. Based on these models, we improve the
attribution level of a cross-lingual question-answering system. Overall, we
show that current academic generative cross-lingual QA systems have substantial
shortcomings in attribution and we build tooling to mitigate these issues.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：What Else Do I Need to Know? The Effect of Background Information on  Users' Reliance on AI Systems</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14331</p>
  <p><b>作者</b>：Navita Goyal,  Eleftheria Briakou,  Amanda Liu,  Connor Baumler,  Claire Bonial,  Jeffrey Micher,  Clare R. Voss,  Marine Carpuat,  Hal Daumé III</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：shown impressive performance, retrieving relevant context, shown impressive, impressive performance, performance at answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI systems have shown impressive performance at answering questions by
retrieving relevant context. However, with the increasingly large models, it is
impossible and often undesirable to constrain models' knowledge or reasoning to
only the retrieved context. This leads to a mismatch between the information
that these models access to derive the answer and the information available to
the user consuming the AI predictions to assess the AI predicted answer. In
this work, we study how users interact with AI systems in absence of sufficient
information to assess AI predictions. Further, we ask the question of whether
adding the requisite background alleviates the concerns around over-reliance in
AI predictions. Our study reveals that users rely on AI predictions even in the
absence of sufficient information needed to assess its correctness. Providing
the relevant background, however, helps users catch AI errors better, reducing
over-reliance on incorrect AI predictions. On the flip side, background
information also increases users' confidence in their correct as well as
incorrect judgments. Contrary to common expectation, aiding a user's perusal of
the context and the background through highlights is not helpful in alleviating
the issue of over-confidence stemming from availability of more information.
Our work aims to highlight the gap between how NLP developers perceive
informational need in human-AI interaction and the actual human interaction
with the information available to them.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Large Language Models are Frame-level Directors for Zero-shot  Text-to-Video Generation</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14330</p>
  <p><b>作者</b>：Susung Hong,  Junyoung Seo,  Sunghwan Hong,  Heeseong Shin,  Seungryong Kim</p>
  <p><b>备注</b>：The code and demo will be available at this https URL</p>
  <p><b>关键词</b>：extending pre-trained, paradigm of AI-generated, increasing attention, attention in extending, AIGC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the paradigm of AI-generated content (AIGC), there has been increasing
attention in extending pre-trained text-to-image (T2I) models to text-to-video
(T2V) generation. Despite their effectiveness, these frameworks face challenges
in maintaining consistent narratives and handling rapid shifts in scene
composition or object placement from a single user prompt. This paper
introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned
large language models (LLMs) to generate frame-by-frame descriptions from a
single abstract user prompt. DirecT2V utilizes LLM directors to divide user
inputs into separate prompts for each frame, enabling the inclusion of
time-varying content and facilitating consistent video generation. To maintain
temporal consistency and prevent object collapse, we propose a novel value
mapping method and dual-softmax filtering. Extensive experimental results
validate the effectiveness of the DirecT2V framework in producing visually
coherent and consistent videos from abstract user prompts, addressing the
challenges of zero-shot video generation.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Empowering LLM-based Machine Translation with Cultural Awareness</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14328</p>
  <p><b>作者</b>：Binwei Yao,  Ming Jiang,  Diyi Yang,  Junjie Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：culturally specific information, fail to translate, neural machine translation, machine translation, Traditional neural machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional neural machine translation (NMT) systems often fail to translate
sentences that contain culturally specific information. Most previous NMT
methods have incorporated external cultural knowledge during training, which
requires fine-tuning on low-frequency items specific to the culture. Recent
in-context learning utilizes lightweight prompts to guide large language models
(LLMs) to perform machine translation, however, whether such an approach works
in terms of injecting culture awareness into machine translation remains
unclear. To this end, we introduce a new data curation pipeline to construct a
culturally relevant parallel corpus, enriched with annotations of
cultural-specific entities. Additionally, we design simple but effective
prompting strategies to assist this LLM-based translation. Extensive
experiments show that our approaches can largely help incorporate cultural
knowledge into LLM-based machine translation, outperforming traditional NMT
systems in translating cultural-specific sentences.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14327</p>
  <p><b>作者</b>：Da Yin,  Xiao Liu,  Fan Yin,  Ming Zhong,  Hritik Bansal,  Jiawei Han,  Kai-Wei Chang</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：large language models, language models, emerged to enhance, enhance the capabilities, capabilities of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has emerged to enhance the capabilities of large language
models (LLMs) in providing appropriate outputs based on input instructions.
However, existing methods for collecting instruction-tuning data suffer from
limitations in scalability and affordability. In this paper, we propose
Dynosaur, a dynamic growth paradigm for instruction-tuning data curation. Built
upon the metadata of existing NLP datasets, we generate multiple task
instructions applicable to various NLP datasets and determine the relevant data
fields for constructing instruction-tuning data with LLMs. Dynosaur offers
several advantages: 1) lower generation costs (less than $12 for generating
800K instruction-tuning data), 2) good quality of instruction-tuning data
(better performance than Alpaca and Instruction GPT-4 on Super-NI with
comparable data sizes), and 3) the ability to grow dynamically by incorporating
new datasets from Huggingface Datasets Platform. We further investigate
continual learning as an approach to learning with the ever-growing
instruction-tuning dataset. We demonstrate that replay methods not only help
mitigate forgetting issues but help generalize to unseen tasks better. As a
novel continual learning scenario for instruction tuning, selecting tasks based
on instruction representations can be an effective replaying strategy. Code and
data are released at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：TalkUp: A Novel Dataset Paving the Way for Understanding Empowering  Language</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14326</p>
  <p><b>作者</b>：Lucille Njoo,  Chan Young Park,  Octavia Stappart,  Marvin Thielk,  Yi Chu,  Yulia Tsvetkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dynamics to healthcare, education to workplace, workplace dynamics, language, studied in NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Empowering language is important in many real-world contexts, from education
to workplace dynamics to healthcare. Though language technologies are growing
more prevalent in these contexts, empowerment has not been studied in NLP, and
moreover, it is inherently challenging to operationalize because of its subtle,
implicit nature. This work presents the first computational exploration of
empowering language. We first define empowerment detection as a new task,
grounding it in linguistic and social psychology literature. We then
crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons
why these posts are empowering to readers, and the social relationships between
posters and readers. Our preliminary analyses show that this dataset, which we
call TalkUp, can be used to train language models that capture empowering and
disempowering language. More broadly, as it is rich with the ambiguities and
diverse interpretations of real-world language, TalkUp provides an avenue to
explore implication, presuppositions, and how social context influences the
meaning of language.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Improving Factuality and Reasoning in Language Models through Multiagent  Debate</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14325</p>
  <p><b>作者</b>：Yilun Du,  Shuang Li,  Antonio Torralba,  Joshua B. Tenenbaum,  Igor Mordatch</p>
  <p><b>备注</b>：Project Webpage and Code: this https URL</p>
  <p><b>关键词</b>：demonstrated remarkable capabilities, recent years, Large language models, demonstrated remarkable, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
"society of minds" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Ties Matter: Modifying Kendall's Tau for Modern Metric Meta-Evaluation</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14324</p>
  <p><b>作者</b>：Daniel Deutsch,  George Foster,  Markus Freitag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：score individual translations, machine translation, individual translations, Kendall tau, tau is frequently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Kendall's tau is frequently used to meta-evaluate how well machine
translation (MT) evaluation metrics score individual translations. Its focus on
pairwise score comparisons is intuitive but raises the question of how ties
should be handled, a gray area that has motivated different variants in the
literature. We demonstrate that, in settings like modern MT meta-evaluation,
existing variants have weaknesses arising from their handling of ties, and in
some situations can even be gamed. We propose a novel variant that gives
metrics credit for correctly predicting ties, as well as an optimization
procedure that automatically introduces ties into metric scores, enabling fair
comparison between metrics that do and do not predict ties. We argue and
provide experimental evidence that these modifications lead to fairer
Kendall-based assessments of metric performance.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large  Language Models</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14323</p>
  <p><b>作者</b>：Zhipeng Chen,  Kun Zhou,  Beichen Zhang,  Zheng Gong,  Wayne Xin Zhao,  Ji-Rong Wen</p>
  <p><b>备注</b>：11 pages, working in progress</p>
  <p><b>关键词</b>：achieved excellent performance, require specific knowledge, large language models, reasoning, evaluation benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although large language models (LLMs) have achieved excellent performance in
a variety of evaluation benchmarks, they still struggle in complex reasoning
tasks which require specific knowledge and multi-hop reasoning. To improve the
reasoning abilities, we propose \textbf{ChatCoT}, a tool-augmented
chain-of-thought reasoning framework for chat-based LLMs. In ChatCoT, we model
the chain-of-thought~(CoT) reasoning as multi-turn conversations, to utilize
tools in a more natural way through chatting. At each turn, LLMs can either
interact with tools or perform the reasoning. Our approach can effectively
leverage the multi-turn conversation ability of chat-based LLMs, and integrate
the thought chain following and tools manipulation in a unified way. Specially,
we initialize the early turns of the conversation by the tools, tasks and
reasoning format, and propose an iterative \emph{tool-augmented reasoning} step
to perform step-by-step tool-augmented reasoning. The experiment results on two
complex reasoning datasets (MATH and HotpotQA) have shown the effectiveness of
ChatCoT on complex reasoning tasks, achieving a 6.8\% relative improvement over
the state-of-the-art baseline. Our code and data are available at:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：RET-LLM: Towards a General Read-Write Memory for Large Language Models</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14322</p>
  <p><b>作者</b>：Ali Modarressi,  Ayyoob Imani,  Mohsen Fayyaz,  Hinrich Schütze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, natural language processing, comprehensive data utilization, Large language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP) through their extensive parameters and comprehensive
data utilization. However, existing LLMs lack a dedicated memory unit, limiting
their ability to explicitly store and retrieve knowledge for various tasks. In
this paper, we propose RET-LLM a novel framework that equips LLMs with a
general write-read memory unit, allowing them to extract, store, and recall
knowledge from the text as needed for task performance. Inspired by Davidsonian
semantics theory, we extract and save knowledge in the form of triplets. The
memory unit is designed to be scalable, aggregatable, updatable, and
interpretable. Through qualitative evaluations, we demonstrate the superiority
of our proposed framework over baseline approaches in question answering tasks.
Moreover, our framework exhibits robust performance in handling temporal-based
question answering tasks, showcasing its ability to effectively manage
time-dependent information.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and  Text Embeddings</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14321</p>
  <p><b>作者</b>：William Brannon,  Suyash Fulay,  Hang Jiang,  Wonjune Kang,  Brandon Roy,  Jad Kabbara,  Deb Roy</p>
  <p><b>备注</b>：3 figures, 9 tables</p>
  <p><b>关键词</b>：Contrastive Graph-Text pretraining, jointly learning separate, Contrastive Graph-Text, supervening graph, Graph-Text pretraining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose ConGraT(Contrastive Graph-Text pretraining), a general,
self-supervised method for jointly learning separate representations of texts
and nodes in a parent (or ``supervening'') graph, where each text is associated
with one of the nodes. Datasets fitting this paradigm are common, from social
media (users and posts), to citation networks over articles, to link graphs
over web pages. We expand on prior work by providing a general,
self-supervised, joint pretraining method, one which does not depend on
particular dataset structure or a specific task. Our method uses two separate
encoders for graph nodes and texts, which are trained to align their
representations within a common latent space. Training uses a batch-wise
contrastive learning objective inspired by prior work on joint text and image
encoding. As graphs are more structured objects than images, we also extend the
training objective to incorporate information about node similarity and
plausible next guesses in matching nodes and texts. Experiments on various
datasets reveal that ConGraT outperforms strong baselines on various downstream
tasks, including node and text category classification and link prediction.
Code and certain datasets are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：CREATOR: Disentangling Abstract and Concrete Reasonings of Large  Language Models through Tool Creation</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14318</p>
  <p><b>作者</b>：Cheng Qian,  Chi Han,  Yi R. Fung,  Yujia Qin,  Zhiyuan Liu,  Heng Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, demonstrated significant progress, Large Language, utilizing external APIs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have demonstrated significant progress in
utilizing external APIs as tools for various tasks. However, their tool-using
ability is limited by the availability of suitable APIs and the instability of
implicit reasoning, particularly when simultaneously engaging in reasoning
about plans and actual calculations. To address these limitations, we propose
CREATOR, a novel framework that empowers LLMs to create their own tools through
documentation and code realization. CREATOR disentangles the LLM's ability into
two distinct phases: abstract tool creation and concrete decision execution,
which results in improved LLM performance. We evaluate CREATOR on two
established benchmarks: MATH, which consists of challenging math competition
problems, and TabMWP, which includes diverse tabular contents for
problem-solving. Remarkably, CREATOR significantly outperforms existing
chain-of-thought (CoT), program-of-thought (PoT), and tool-using baselines on
these two benchmarks. Additionally, we present a new dataset, Creation
Challenge, comprising 2K diverse questions, to highlight the necessity and
benefits of LLMs' tool creation ability in effectively addressing these
problems. Furthermore, our research reveals that leveraging LLMs as tool
creators facilitates knowledge transfer, and LLMs exhibit varying levels of
tool creation abilities, enabling them to flexibly tackle diverse situations.
Our study represents a promising avenue for maximizing the potential of LLMs
and advancing toward truly intelligent and adaptable AI systems.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Context-Aware Transformer Pre-Training for Answer Sentence Selection</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15358</p>
  <p><b>作者</b>：Luca Di Liello,  Siddhant Garg,  Alessandro Moschitti</p>
  <p><b>备注</b>：Accepted at ACL 2023</p>
  <p><b>关键词</b>：Answer Sentence Selection, Sentence Selection, building an accurate, core component, component for building</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Answer Sentence Selection (AS2) is a core component for building an accurate
Question Answering pipeline. AS2 models rank a set of candidate sentences based
on how likely they answer a given question. The state of the art in AS2
exploits pre-trained transformers by transferring them on large annotated
datasets, while using local contextual information around the candidate
sentence. In this paper, we propose three pre-training objectives designed to
mimic the downstream fine-tuning task of contextual AS2. This allows for
specializing LMs when fine-tuning for contextual AS2. Our experiments on three
public and two large-scale industrial datasets show that our pre-training
approaches (applied to RoBERTa and ELECTRA) can improve baseline contextual AS2
accuracy by up to 8% on some datasets.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Learning Answer Generation using Supervision from Automatic Question  Answering Evaluators</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15344</p>
  <p><b>作者</b>：Matteo Gabburo,  Siddhant Garg,  Rik Koncel-Kedziorski,  Alessandro Moschitti</p>
  <p><b>备注</b>：Accepted at ACL 2023</p>
  <p><b>关键词</b>：Recent studies show, Recent studies, studies show, show that sentence-level, sentence-level extractive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies show that sentence-level extractive QA, i.e., based on Answer
Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA)
models, which generate answers using the top-k answer sentences ranked by AS2
models (a la retrieval-augmented generation style). In this paper, we propose a
novel training paradigm for GenQA using supervision from automatic QA
evaluation models (GAVA). Specifically, we propose three strategies to transfer
knowledge from these QA evaluation models to a GenQA model: (i) augmenting
training data with answers generated by the GenQA model and labelled by GAVA
(either statically, before training, or (ii) dynamically, at every training
epoch); and (iii) using the GAVA score for weighting the generator loss during
the learning of the GenQA model. We evaluate our proposed methods on two
academic and one industrial dataset, obtaining a significant improvement in
answering accuracy over the previous state of the art.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Measuring and Mitigating Constraint Violations of In-Context Learning  for Utterance-to-API Semantic Parsing</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15338</p>
  <p><b>作者</b>：Shufan Wang,  Sebastien Jean,  Sailik Sengupta,  James Gung,  Nikolaos Pappas,  Yi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, pre-defined API specifications, task-oriented semantic parsing, translate users' utterances, executable task-oriented semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In executable task-oriented semantic parsing, the system aims to translate
users' utterances in natural language to machine-interpretable programs (API
calls) that can be executed according to pre-defined API specifications. With
the popularity of Large Language Models (LLMs), in-context learning offers a
strong baseline for such scenarios, especially in data-limited regimes.
However, LLMs are known to hallucinate and therefore pose a formidable
challenge in constraining generated content. Thus, it remains uncertain if LLMs
can effectively perform task-oriented utterance-to-API generation where
respecting API's structural and task-specific constraints is crucial.
In this work, we seek to measure, analyze and mitigate such constraints
violations. First, we identify the categories of various constraints in
obtaining API-semantics from task-oriented utterances, and define fine-grained
metrics that complement traditional ones. Second, we leverage these metrics to
conduct a detailed error analysis of constraints violations seen in
state-of-the-art LLMs, which motivates us to investigate two mitigation
strategies: Semantic-Retrieval of Demonstrations (SRD) and API-aware
Constrained Decoding (API-CD). Our experiments show that these strategies are
effective at reducing constraints violations and improving the quality of the
generated API calls, but require careful consideration given their
implementation complexity and latency.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Gorilla: Large Language Model Connected with Massive APIs</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15334</p>
  <p><b>作者</b>：Shishir G. Patil,  Tianjun Zhang,  Xin Wang,  Joseph E. Gonzalez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, advances recently, program synthesis, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have seen an impressive wave of advances
recently, with models now excelling in a variety of tasks, such as mathematical
reasoning and program synthesis. However, their potential to effectively use
tools via API calls remains unfulfilled. This is a challenging task even for
today's state-of-the-art LLMs such as GPT-4, largely due to their inability to
generate accurate input arguments and their tendency to hallucinate the wrong
usage of an API call. We release Gorilla, a finetuned LLaMA-based model that
surpasses the performance of GPT-4 on writing API calls. When combined with a
document retriever, Gorilla demonstrates a strong capability to adapt to
test-time document changes, enabling flexible user updates or version changes.
It also substantially mitigates the issue of hallucination, commonly
encountered when prompting LLMs directly. To evaluate the model's ability, we
introduce APIBench, a comprehensive dataset consisting of HuggingFace,
TorchHub, and TensorHub APIs. The successful integration of the retrieval
system with Gorilla demonstrates the potential for LLMs to use tools more
accurately, keep up with frequently updated documentation, and consequently
increase the reliability and applicability of their outputs. Gorilla's code,
model, data, and demo are available at this https URL</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Visual Programming for Text-to-Image Generation and Evaluation</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15328</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：18 pages; Project website: this https URL</p>
  <p><b>关键词</b>：demonstrated impressive performance, large language models, adopted language models, generation, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models have demonstrated impressive performance in many
domains, recent works have adopted language models (LMs) as controllers of
visual modules for vision-and-language tasks. While existing work focuses on
equipping LMs with visual understanding, we propose two novel
interpretable/explainable visual programming frameworks for text-to-image (T2I)
generation and evaluation. First, we introduce VPGen, an interpretable
step-by-step T2I generation framework that decomposes T2I generation into three
steps: object/count generation, layout generation, and image generation. We
employ an LM to handle the first two steps (object/count generation and layout
generation), by finetuning it on text-layout pairs. Our step-by-step T2I
generation framework provides stronger spatial control than end-to-end models,
the dominant approach for this task. Furthermore, we leverage the world
knowledge of pretrained LMs, overcoming the limitation of previous
layout-guided T2I works that can only handle predefined object classes. We
demonstrate that our VPGen has improved control in counts/spatial
relations/scales of objects than state-of-the-art T2I generation models.
Second, we introduce VPEval, an interpretable and explainable evaluation
framework for T2I generation based on visual programming. Unlike previous T2I
evaluations with a single scoring model that is accurate in some skills but
unreliable in others, VPEval produces evaluation programs that invoke a set of
visual modules that are experts in different skills, and also provides
visual+textual explanations of the evaluation results. Our analysis shows
VPEval provides a more human-correlated evaluation for skill-specific and
open-ended prompts than widely used single model-based evaluation. We hope our
work encourages future progress on interpretable/explainable generation and
evaluation for T2I models. Website: this https URL</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ChatGPT: Vision and Challenges</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15323</p>
  <p><b>作者</b>：Sukhpal Singh Gill,  Rupinder Kaur</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial intelligence, machine learning, learning have changed, changed the nature, nature of scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) and machine learning have changed the nature of
scientific inquiry in recent years. Of these, the development of virtual
assistants has accelerated greatly in the past few years, with ChatGPT becoming
a prominent AI language model. In this study, we examine the foundations,
vision, research challenges of ChatGPT. This article investigates into the
background and development of the technology behind it, as well as its popular
applications. Moreover, we discuss the advantages of bringing everything
together through ChatGPT and Internet of Things (IoT). Further, we speculate on
the future of ChatGPT by considering various possibilities for study and
development, such as energy-efficiency, cybersecurity, enhancing its
applicability to additional technologies (Robotics and Computer Vision),
strengthening human-AI communications, and bridging the technological gap.
Finally, we discuss the important ethics and current trends of ChatGPT.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Towards Foundation Models for Relational Databases [Vision Paper]</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15321</p>
  <p><b>作者</b>：Liane Vogel,  Benjamin Hilprecht,  Carsten Binnig</p>
  <p><b>备注</b>：Accepted at the Tabular Representation Learning Workshop at NeurIPS 2022 (TRL@NeurIPS2022)</p>
  <p><b>关键词</b>：Tabular representation learning, lot of attention, recently gained, gained a lot, Tabular representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tabular representation learning has recently gained a lot of attention.
However, existing approaches only learn a representation from a single table,
and thus ignore the potential to learn from the full structure of relational
databases, including neighboring tables that can contain important information
for a contextualized representation. Moreover, current models are significantly
limited in scale, which prevents that they learn from large databases. In this
paper, we thus introduce our vision of relational representation learning, that
can not only learn from the full relational structure, but also can scale to
larger database sizes that are commonly found in real-world. Moreover, we also
discuss opportunities and challenges we see along the way to enable this vision
and present initial very promising results. Overall, we argue that this
direction can lead to foundation models for relational databases that are today
only available for text and images.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Science in the Era of ChatGPT, Large Language Models and AI: Challenges  for Research Ethics Review and How to Respond</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15299</p>
  <p><b>作者</b>：Evangelos Pournaras</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ChatGPT find remarkable, artificial intelligence, ChatGPT find, find remarkable, remarkable but controversial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models of artificial intelligence (AI) such as ChatGPT find
remarkable but controversial applicability in science and research. This paper
reviews epistemological challenges, ethical and integrity risks in science
conduct. This is with the aim to lay new timely foundations for a high-quality
research ethics review in the era of AI. The role of AI language models as a
research instrument and subject is scrutinized along with ethical implications
for scientists, participants and reviewers. Ten recommendations shape a
response for a more responsible research conduct with AI language models.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Enhancing Retrieval-Augmented Large Language Models with Iterative  Retrieval-Generation Synergy</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15294</p>
  <p><b>作者</b>：Zhihong Shao,  Yeyun Gong,  Yelong Shen,  Minlie Huang,  Nan Duan,  Weizhu Chen</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：powerful text processors, limitations including outdated, Large language models, Large language, including outdated knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models are powerful text processors and reasoners, but are
still subject to limitations including outdated knowledge and hallucinations,
which necessitates connecting them to the world. Retrieval-augmented large
language models have raised extensive attention for grounding model generation
on external knowledge. However, retrievers struggle to capture relevance,
especially for queries with complex information needs. Recent work has proposed
to improve relevance modeling by having large language models actively involved
in retrieval, i.e., to improve retrieval with generation. In this paper, we
show that strong performance can be achieved by a method we call Iter-RetGen,
which synergizes retrieval and generation in an iterative manner. A model
output shows what might be needed to finish a task, and thus provides an
informative context for retrieving more relevant knowledge which in turn helps
generate a better output in the next iteration. Compared with recent work which
interleaves retrieval with generation when producing an output, Iter-RetGen
processes all retrieved knowledge as a whole and largely preserves the
flexibility in generation without structural constraints. We evaluate
Iter-RetGen on multi-hop question answering, fact verification, and commonsense
reasoning, and show that it can flexibly leverage parametric knowledge and
non-parametric knowledge, and is superior to or competitive with
state-of-the-art retrieval-augmented baselines while causing fewer overheads of
retrieval and generation. We can further improve performance via
generation-augmented retrieval adaptation.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：A Simple and Effective Framework for Strict Zero-Shot Hierarchical  Classification</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15282</p>
  <p><b>作者</b>：Rohan Bhambhoria,  Lei Chen,  Xiaodan Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, recent years, large language, language models, achieved strong performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, large language models (LLMs) have achieved strong
performance on benchmark tasks, especially in zero or few-shot settings.
However, these benchmarks often do not adequately address the challenges posed
in the real-world, such as that of hierarchical classification. In order to
address this challenge, we propose refactoring conventional tasks on
hierarchical datasets into a more indicative long-tail prediction task. We
observe LLMs are more prone to failure in these cases. To address these
limitations, we propose the use of entailment-contradiction prediction in
conjunction with LLMs, which allows for strong performance in a strict
zero-shot setting. Importantly, our method does not require any parameter
updates, a resource-intensive process and achieves strong performance across
multiple datasets.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Self-Evolution Learning for Discriminative Language Model Pretraining</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15275</p>
  <p><b>作者</b>：Qihuang Zhong,  Liang Ding,  Juhua Liu,  Bo Du,  Dacheng Tao</p>
  <p><b>备注</b>：Accepted to Findings of ACL2023</p>
  <p><b>关键词</b>：Masked language modeling, discriminative language model, Masked language, language modeling, discriminative language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Masked language modeling, widely used in discriminative language model (e.g.,
BERT) pretraining, commonly adopts a random masking strategy. However, random
masking does not consider the importance of the different words in the sentence
meaning, where some of them are more worthy to be predicted. Therefore, various
masking strategies (e.g., entity-level masking) are proposed, but most of them
require expensive prior knowledge and generally train from scratch without
reusing existing model weights. In this paper, we present Self-Evolution
learning (SE), a simple and effective token masking and learning method to
fully and wisely exploit the knowledge from data. SE focuses on learning the
informative yet under-explored tokens and adaptively regularizes the training
by introducing a novel Token-specific Label Smoothing approach. Experiments on
10 tasks show that our SE brings consistent and significant improvements
(+1.43~2.12 average scores) upon different PLMs. In-depth analyses demonstrate
that SE improves linguistic knowledge learning and generalization.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Revisiting Token Dropping Strategy in Efficient BERT Pretraining</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15273</p>
  <p><b>作者</b>：Qihuang Zhong,  Liang Ding,  Juhua Liu,  Xuebo Liu,  Min Zhang,  Bo Du,  Dacheng Tao</p>
  <p><b>备注</b>：Accepted to ACL2023 Main Conference</p>
  <p><b>关键词</b>：masked language models, Token dropping, middle layers, recently-proposed strategy, strategy to speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Token dropping is a recently-proposed strategy to speed up the pretraining of
masked language models, such as BERT, by skipping the computation of a subset
of the input tokens at several middle layers. It can effectively reduce the
training time without degrading much performance on downstream tasks. However,
we empirically find that token dropping is prone to a semantic loss problem and
falls short in handling semantic-intense tasks. Motivated by this, we propose a
simple yet effective semantic-consistent learning method (ScTD) to improve the
token dropping. ScTD aims to encourage the model to learn how to preserve the
semantic information in the representation space. Extensive experiments on 12
tasks show that, with the help of our ScTD, token dropping can achieve
consistent and significant performance gains across all task types and model
sizes. More encouragingly, ScTD saves up to 57% of pretraining time and brings
up to +1.56% average improvement over the vanilla token dropping.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Testing the General Deductive Reasoning Capacity of Large Language  Models Using OOD Examples</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15269</p>
  <p><b>作者</b>：Abulhair Saparov,  Richard Yuanzhe Pang,  Vishakh Padmakumar,  Nitish Joshi,  Seyed Mehran Kazemi,  Najoung Kim,  He He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general deductive reasoning, deductive reasoning ability, deductive reasoning, intractably large size, general deductive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the intractably large size of the space of proofs, any model that is
capable of general deductive reasoning must generalize to proofs of greater
complexity. Recent studies have shown that large language models (LLMs) possess
some abstract deductive reasoning ability given chain-of-thought prompts.
However, they have primarily been tested on proofs using modus ponens or of a
specific size, and from the same distribution as the in-context examples. To
measure the general deductive reasoning ability of LLMs, we test on a broad set
of deduction rules and measure their ability to generalize to more complex
proofs from simpler demonstrations from multiple angles: depth-, width-, and
compositional generalization. To facilitate systematic exploration, we
construct a new synthetic and programmable reasoning dataset that enables
control over deduction rules and proof complexity. Our experiments on four LLMs
of various sizes and training objectives show that they are able to generalize
to longer and compositional proofs. However, they require explicit
demonstrations to produce hypothetical subproofs, specifically in proof by
cases and proof by contradiction.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：EvEval: A Comprehensive Evaluation of Event Semantics for Large Language  Models</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15268</p>
  <p><b>作者</b>：Zhengwei Tao,  Zhi Jin,  Xiaoying Bai,  Haiyan Zhao,  Yanlin Feng,  Jia Li,  Wenpeng Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：event semantic processing, event semantic, semantic processing, serve as fundamental, fundamental units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Events serve as fundamental units of occurrence within various contexts. The
processing of event semantics in textual information forms the basis of
numerous natural language processing (NLP) applications. Recent studies have
begun leveraging large language models (LLMs) to address event semantic
processing. However, the extent that LLMs can effectively tackle these
challenges remains uncertain. Furthermore, the lack of a comprehensive
evaluation framework for event semantic processing poses a significant
challenge in evaluating these capabilities. In this paper, we propose an
overarching framework for event semantic processing, encompassing
understanding, reasoning, and prediction, along with their fine-grained
aspects. To comprehensively evaluate the event semantic processing abilities of
models, we introduce a novel benchmark called EVEVAL. We collect 8 datasets
that cover all aspects of event semantic processing. Extensive experiments are
conducted on EVEVAL, leading to several noteworthy findings based on the
obtained results.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of  Language Model</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15265</p>
  <p><b>作者</b>：Zirui Liu,  Guanchu Wang,  Shaochen Zhong,  Zhaozhuo Xu,  Daochen Zha,  Ruixiang Tang,  Zhimeng Jiang,  Kaixiong Zhou,  Vipin Chaudhary,  Shuai Xu,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pre-trained language, increasingly difficult due, pre-trained language model, extensive memory usage, fine-tuning the large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid growth in model size, fine-tuning the large pre-trained
language model has become increasingly difficult due to its extensive memory
usage. Previous works usually focus on reducing the number of trainable
parameters in the network. While the model parameters do contribute to memory
usage, the primary memory bottleneck during training arises from storing
feature maps, also known as activations, as they are crucial for gradient
calculation. Notably, neural networks are usually trained using stochastic
gradient descent. We argue that in stochastic optimization, models can handle
noisy gradients as long as the gradient estimator is unbiased with reasonable
variance. Following this motivation, we propose a new family of unbiased
estimators called WTA-CRS, for matrix production with reduced variance, which
only requires storing the sub-sampled activations for calculating the gradient.
Our work provides both theoretical and experimental evidence that, in the
context of tuning transformers, our proposed estimators exhibit lower variance
compared to existing ones. By replacing the linear operation with our
approximated one in transformers, we can achieve up to 2.7$\times$ peak memory
reduction with almost no accuracy drop and enables up to $6.4\times$ larger
batch size. Under the same hardware, WTA-CRS enables better down-streaming task
performance by applying larger models and/or faster training speed with larger
batch sizes.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Revisiting Parallel Context Windows: A Frustratingly Simple Alternative  and Chain-of-Thought Deterioration</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15262</p>
  <p><b>作者</b>：Kejuan Yang,  Xiao Liu,  Kaiwen Men,  Aohan Zeng,  Yuxiao Dong,  Jie Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Parallel Context Windows, parallel-integrated method Parallel, positional embedding techniques, recent parallel-integrated method, harnessing window-wise attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We identify two crucial limitations in the evaluation of recent
parallel-integrated method Parallel Context Windows (PCW), which extends the
maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing
window-wise attention and positional embedding techniques. We first show that a
simple yet strong baseline, weighted sum ensemble, is missing for the
in-context few-shot classification. Moreover, on more challenging
Chain-of-Thought (CoT) reasoning (e.g., HotpotQA), PCW would present unexpected
deterioration regarding question miscomprehension and false inference. Based on
our findings, we suggest that the existing PCW design may not guarantee
sufficient improvement and practicality in handling lengthy documents in
real-world applications. More community efforts on enabling language models'
long context understanding ability should be paid.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：LMs with a Voice: Spoken Language Modeling beyond Speech Tokens</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15255</p>
  <p><b>作者</b>：Eliya Nachmani,  Alon Levkovitch,  Julian Salazar,  Chulayutsh Asawaroengchai,  Soroosh Mariooryad,  RJ Skerry-Ryan,  Michelle Tadmor Ramanovich</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：present SPECTRON, adapting pre-trained language, approach to adapting, perform speech continuation, SPECTRON</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present SPECTRON, a novel approach to adapting pre-trained language models
(LMs) to perform speech continuation. By leveraging pre-trained speech
encoders, our model generates both text and speech outputs with the entire
system being trained end-to-end operating directly on spectrograms. Training
the entire model in the spectrogram domain simplifies our speech continuation
system versus existing cascade methods which use discrete speech
representations. We further show our method surpasses existing spoken language
models both in semantic content and speaker preservation while also benefiting
from the knowledge transferred from pre-existing models. Audio samples can be
found in our website this https URL</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Boosting Cross-lingual Transferability in Multilingual Models via  In-Context Learning</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15233</p>
  <p><b>作者</b>：Sunkyoung Kim,  Dayeon Ki,  Yireun Kim,  Jinsik Lee</p>
  <p><b>备注</b>：Work In Progress</p>
  <p><b>关键词</b>：concerned with monolingual, Existing cross-lingual transfer, CLT, cross-lingual transfer, transfer prompting method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing cross-lingual transfer (CLT) prompting methods are only concerned
with monolingual demonstration examples in the source language. In this paper,
we propose In-CLT, a novel cross-lingual transfer prompting method that
leverages both source and target languages to construct the demonstration
examples. We conduct comprehensive evaluations on multilingual benchmarks,
focusing on question answering tasks. Experiment results show that In-CLT
prompt not only improves multilingual models' cross-lingual transferability,
but also demonstrates remarkable unseen language generalization ability. In-CLT
prompting, in particular, improves model performance by 10 to 20\% points on
average when compared to prior cross-lingual transfer approaches. We also
observe the surprising performance gain on the other multilingual benchmarks,
especially in reasoning tasks. Furthermore, we investigate the relationship
between lexical similarity and pre-training corpora in terms of the
cross-lingual transfer gap.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：SAIL: Search-Augmented Instruction Learning</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15225</p>
  <p><b>作者</b>：Hongyin Luo,  Yung-Sung Chuang,  Yuan Gong,  Tianhua Zhang,  Yoon Kim,  Xixin Wu,  Danny Fox,  Helen Meng,  James Glass</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, lack transparency, Large language, search results, instruction fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have been significantly improved by instruction
fine-tuning, but still lack transparency and the ability to utilize up-to-date
knowledge and information. In this work, we propose search-augmented
instruction learning (SAIL), which grounds the language generation and
instruction following abilities on complex search results generated by in-house
and external search engines. With an instruction tuning corpus, we collect
search results for each training case from different search APIs and domains,
and construct a new search-grounded training set containing
\textit{(instruction, grounding information, response)} triplets. We then
fine-tune the LLaMA-7B model on the constructed training set. Since the
collected results contain unrelated and disputing languages, the model needs to
learn to ground on trustworthy search results, filter out distracting passages,
and generate the target response. The search result-denoising process entails
explicit trustworthy information selection and multi-hop reasoning, since the
retrieved passages might be informative but not contain the
instruction-following answer. Experiments show that the fine-tuned SAIL-7B
model has a strong instruction-following ability, and it performs significantly
better on transparency-sensitive tasks, including open-ended question answering
and fact checking.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Neural Summarization of Electronic Health Records</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15222</p>
  <p><b>作者</b>：Koyena Pal,  Seyed Ali Bahrainian,  Laura Mercurio,  Carsten Eickhoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming documents written, Hospital discharge documentation, discharge summaries, discharge summary, discharge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hospital discharge documentation is among the most essential, yet
time-consuming documents written by medical practitioners. The objective of
this study was to automatically generate hospital discharge summaries using
neural network summarization models. We studied various data preparation and
neural network training techniques that generate discharge summaries. Using
nursing notes and discharge summaries from the MIMIC-III dataset, we studied
the viability of the automatic generation of various sections of a discharge
summary using four state-of-the-art neural network summarization models (BART,
T5, Longformer and FLAN-T5). Our experiments indicated that training
environments including nursing notes as the source, and discrete sections of
the discharge summary as the target output (e.g. "History of Present Illness")
improve language model efficiency and text quality. According to our findings,
the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its
standard off-the-shelf version. We also found that fine-tuning the baseline
BART model with other setups caused different degrees of improvement (up to 80%
relative improvement). We also observed that a fine-tuned T5 generally achieves
higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5
achieves the highest ROUGE score overall, i.e., 45.6. For majority of the
fine-tuned language models, summarizing discharge summary report sections
separately outperformed the summarization the entire report quantitatively. On
the other hand, fine-tuning language models that were previously instruction
fine-tuned showed better performance in summarizing entire reports. This study
concludes that a focused dataset designed for the automatic generation of
discharge summaries by a language model can produce coherent Discharge Summary
sections.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model  Fine-tuning</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15212</p>
  <p><b>作者</b>：Zhen-Ru Zhang,  Chuanqi Tan,  Haiyang Xu,  Chengyu Wang,  Jun Huang,  Songfang Huang</p>
  <p><b>备注</b>：Accepted to ACL 2023 (Main conference)</p>
  <p><b>关键词</b>：large pre-trained language, pre-trained language models, Fine-tuning large pre-trained, prohibitively expensive, downstream tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large pre-trained language models on various downstream tasks
with whole parameters is prohibitively expensive. Hence, Parameter-efficient
fine-tuning has attracted attention that only optimizes a few task-specific
parameters with the frozen pre-trained model. In this work, we focus on prefix
tuning, which only optimizes continuous prefix vectors (i.e. pseudo tokens)
inserted into Transformer layers. Based on the observation that the learned
syntax and semantics representation varies a lot at different layers, we argue
that the adaptive prefix will be further tailored to each layer than the fixed
one, enabling the fine-tuning more effective and efficient. Thus, we propose
Adaptive Prefix Tuning (APT) to adjust the prefix in terms of both fine-grained
token level and coarse-grained layer level with a gate mechanism. Experiments
on the SuperGLUE and NER datasets show the effectiveness of APT. In addition,
taking the gate as a probing, we validate the efficiency and effectiveness of
the variable prefix.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：SciReviewGen: A Large-scale Dataset for Automatic Literature Review  Generation</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15186</p>
  <p><b>作者</b>：Tetsu Kasanishi,  Masaru Isonuma,  Junichiro Mori,  Ichiro Sakata</p>
  <p><b>备注</b>：ACL findings 2023 (to be appeared). arXiv admin note: text overlap with arXiv:1810.04020 by other authors</p>
  <p><b>关键词</b>：literature review generation, natural language processing, literature review, review generation, Automatic literature review</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic literature review generation is one of the most challenging tasks
in natural language processing. Although large language models have tackled
literature review generation, the absence of large-scale datasets has been a
stumbling block to the progress. We release SciReviewGen, consisting of over
10,000 literature reviews and 690,000 papers cited in the reviews. Based on the
dataset, we evaluate recent transformer-based summarization models on the
literature review generation task, including Fusion-in-Decoder extended for
literature review generation. Human evaluation results show that some
machine-generated summaries are comparable to human-written reviews, while
revealing the challenges of automatic literature review generation such as
hallucinations and a lack of detailed information. Our dataset and code are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Are Pre-trained Language Models Useful for Model Ensemble in Chinese  Grammatical Error Correction?</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15183</p>
  <p><b>作者</b>：Chenming Tang,  Xiuyu Wu,  Yunfang Wu</p>
  <p><b>备注</b>：7 pages, 1 figure. Accepted by ACL 2023 (main conference, short paper)</p>
  <p><b>关键词</b>：Grammatical Error Correction, Error Correction, Grammatical Error, boosting model performance, boosting model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model ensemble has been in widespread use for Grammatical Error Correction
(GEC), boosting model performance. We hypothesize that model ensemble based on
the perplexity (PPL) computed by pre-trained language models (PLMs) should
benefit the GEC system. To this end, we explore several ensemble strategies
based on strong PLMs with four sophisticated single models. However, the
performance does not improve but even gets worse after the PLM-based ensemble.
This surprising result sets us doing a detailed analysis on the data and coming
up with some insights on GEC. The human references of correct sentences is far
from sufficient in the test data, and the gap between a correct sentence and an
idiomatic one is worth our attention. Moreover, the PLM-based ensemble
strategies provide an effective way to extend and improve GEC benchmark data.
Our source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text  Classification</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15182</p>
  <p><b>作者</b>：He Zhu,  Chong Zhang,  Junjie Huang,  Junran Wu,  Ke Xu</p>
  <p><b>备注</b>：Accepted by ACL'23</p>
  <p><b>关键词</b>：Hierarchical text classification, complex hierarchical structure, multi-label classification, complex hierarchical, challenging subtask</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification as the labels form a complex hierarchical structure.
Existing dual-encoder methods in HTC achieve weak performance gains with huge
memory overheads and their structure encoders heavily rely on domain knowledge.
Under such observation, we tend to investigate the feasibility of a
memory-friendly model with strong generalization capability that could boost
the performance of HTC without prior statistics or label semantics. In this
paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance
the text representations with only syntactic information of the label
hierarchy. Specifically, we convert the label hierarchy into an unweighted tree
structure, termed coding tree, with the guidance of structural entropy. Then we
design a structure encoder to incorporate hierarchy-aware information in the
coding tree into text representations. Besides the text encoder, HiTIN only
contains a few multi-layer perceptions and linear transformations, which
greatly saves memory. We conduct experiments on three commonly used datasets
and the results demonstrate that HiTIN could achieve better test performance
and less memory consumption than state-of-the-art (SOTA) methods.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Pre-training Multi-party Dialogue Models with Latent Discourse Inference</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15175</p>
  <p><b>作者</b>：Yiyang Li,  Xinting Huang,  Wei Bi,  Hai Zhao</p>
  <p><b>备注</b>：Accepted by ACL 2023</p>
  <p><b>关键词</b>：interweaving reply-to relations, involve multiple interlocutors, resulting in interweaving, information flows, interweaving reply-to</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-party dialogues are more difficult for models to understand than
one-to-one two-party dialogues, since they involve multiple interlocutors,
resulting in interweaving reply-to relations and information flows. To step
over these obstacles, an effective way is to pre-train a model that understands
the discourse structure of multi-party dialogues, namely, to whom each
utterance is replying. However, due to the lack of explicitly annotated
discourse labels in multi-party dialogue corpora, previous works fail to scale
up the pre-training process by putting aside the unlabeled multi-party
conversational data for nothing. To fully utilize the unlabeled data, we
propose to treat the discourse structures as latent variables, then jointly
infer them and pre-train the discourse-aware model by unsupervised latent
variable inference methods. Experiments on multiple downstream tasks show that
our pre-trained model outperforms strong baselines by large margins and
achieves state-of-the-art (SOTA) results, justifying the effectiveness of our
method. The official implementation of this paper is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Topic-Guided Self-Introduction Generation for Social Media Users</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15138</p>
  <p><b>作者</b>：Chunpu Xu,  Jing Li,  Piji Li,  Min Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, social media self-introduction, personal interests, users, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Millions of users are active on social media. To allow users to better
showcase themselves and network with others, we explore the auto-generation of
social media self-introduction, a short sentence outlining a user's personal
interests. While most prior work profiles users with tags (e.g., ages), we
investigate sentence-level self-introductions to provide a more natural and
engaging way for users to know each other. Here we exploit a user's tweeting
history to generate their self-introduction. The task is non-trivial because
the history content may be lengthy, noisy, and exhibit various personal
interests. To address this challenge, we propose a novel unified topic-guided
encoder-decoder (UTGED) framework; it models latent topics to reflect salient
user interest, whose topic mixture then guides encoding a user's history and
topic words control decoding their self-introduction. For experiments, we
collect a large-scale Twitter dataset, and extensive results show the
superiority of our UTGED to the advanced encoder-decoder models without topic
modeling.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：On Degrees of Freedom in Defining and Testing Natural Language  Understanding</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15130</p>
  <p><b>作者</b>：Saku Sugawara,  Shun Tsugita</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：Natural language understanding, capabilities of systems, NLU, exaggerate or underestimate, underestimate the capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language understanding (NLU) studies often exaggerate or
underestimate the capabilities of systems, thereby limiting the reproducibility
of their findings. These erroneous evaluations can be attributed to the
difficulty of defining and testing NLU adequately. In this position paper, we
reconsider this challenge by identifying two types of researcher degrees of
freedom. We revisit Turing's original interpretation of the Turing test and
indicate that an NLU test does not provide an operational definition; it merely
provides inductive evidence that the test subject understands the language
sufficiently well to meet stakeholder objectives. In other words, stakeholders
are free to arbitrarily define NLU through their objectives. To use the test
results as inductive evidence, stakeholders must carefully assess if the
interpretation of test scores is valid or not. However, designing and using NLU
tests involve other degrees of freedom, such as specifying target skills and
defining evaluation metrics. As a result, achieving consensus among
stakeholders becomes difficult. To resolve this issue, we propose a validity
argument, which is a framework comprising a series of validation criteria
across test components. By demonstrating that current practices in NLU studies
can be associated with those criteria and organizing them into a comprehensive
checklist, we prove that the validity argument can serve as a coherent
guideline for designing credible test sets and facilitating scientific
communication.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Another Dead End for Morphological Tags? Perturbed Inputs and Parsing</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15119</p>
  <p><b>作者</b>：Alberto Muñoz-Ortiz,  David Vilares</p>
  <p><b>备注</b>：Accepted at Findings of ACL 2023</p>
  <p><b>关键词</b>：heavily questioned due, heavily questioned, questioned due, success of word-contextualized, word-contextualized parsers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The usefulness of part-of-speech tags for parsing has been heavily questioned
due to the success of word-contextualized parsers. Yet, most studies are
limited to coarse-grained tags and high quality written content; while we know
little about their influence when it comes to models in production that face
lexical errors. We expand these setups and design an adversarial attack to
verify if the use of morphological information by parsers: (i) contributes to
error propagation or (ii) if on the other hand it can play a role to correct
mistakes that word-only neural parsers make. The results on 14 diverse UD
treebanks show that under such attacks, for transition- and graph-based models
their use contributes to degrade the performance even faster, while for the
(lower-performing) sequence labeling parsers they are helpful. We also show
that if morphological tags were utopically robust against lexical
perturbations, they would be able to correct parsing mistakes.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15108</p>
  <p><b>作者</b>：Debayan Banerjee,  Pranav Ajit Nair,  Ricardo Usbeck,  Chris Biemann</p>
  <p><b>备注</b>：Accepted as a short paper to ACL 2023 findings</p>
  <p><b>关键词</b>：SPARQL semantic parsing, SPARQL query language, SPARQL semantic, semantic parsing, analyse the role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we analyse the role of output vocabulary for text-to-text (T2T)
models on the task of SPARQL semantic parsing. We perform experiments within
the the context of knowledge graph question answering (KGQA), where the task is
to convert questions in natural language to the SPARQL query language. We
observe that the query vocabulary is distinct from human vocabulary. Language
Models (LMs) are pre-dominantly trained for human language tasks, and hence, if
the query vocabulary is replaced with a vocabulary more attuned to the LM
tokenizer, the performance of models may improve. We carry out carefully
selected vocabulary substitutions on the queries and find absolute gains in the
range of 17% on the GrailQA dataset.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Fourier Transformer: Fast Long Range Modeling by Removing Sequence  Redundancy with FFT Operator</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15099</p>
  <p><b>作者</b>：Ziwei He,  Meng Yang,  Minwei Feng,  Jingcheng Yin,  Xinbing Wang,  Jingwen Leng,  Zhouhan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computationally demanding, prohibitively costly, costly for long, quadratic time, complexity with respect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The transformer model is known to be computationally demanding, and
prohibitively costly for long sequences, as the self-attention module uses a
quadratic time and space complexity with respect to sequence length. Many
researchers have focused on designing new forms of self-attention or
introducing new parameters to overcome this limitation, however a large portion
of them prohibits the model to inherit weights from large pretrained models. In
this work, the transformer's inefficiency has been taken care of from another
perspective. We propose Fourier Transformer, a simple yet effective approach by
progressively removing redundancies in hidden sequence using the ready-made
Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation
(DCT). Fourier Transformer is able to significantly reduce computational costs
while retain the ability to inherit from various large pretrained models.
Experiments show that our model achieves state-of-the-art performances among
all transformer-based models on the long-range modeling benchmark LRA with
significant improvement in both speed and space. For generative seq-to-seq
tasks including CNN/DailyMail and ELI5, by inheriting the BART weights our
model outperforms the standard BART and other efficient models. \footnote{Our
code is publicly available at
\url{this https URL}}</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Referral Augmentation for Zero-Shot Information Retrieval</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15098</p>
  <p><b>作者</b>：Michael Tang,  Shunyu Yao,  John Yang,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant performance gains, provide significant performance, concatenates document indices, propose Referral-Augmented Retrieval, propose Referral-Augmented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Referral-Augmented Retrieval (RAR), a simple technique that
concatenates document indices with referrals, i.e. text from other documents
that cite or link to the given document, to provide significant performance
gains for zero-shot information retrieval. The key insight behind our method is
that referrals provide a more complete, multi-view representation of a
document, much like incoming page links in algorithms like PageRank provide a
comprehensive idea of a webpage's importance. RAR works with both sparse and
dense retrievers, and outperforms generative text expansion techniques such as
DocT5Query and Query2Doc a 37% and 21% absolute improvement on ACL paper
retrieval Recall@10 -- while also eliminating expensive model training and
inference. We also analyze different methods for multi-referral aggregation and
show that RAR enables up-to-date information retrieval without re-training.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Dynamic Masking Rate Schedules for MLM Pretraining</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15096</p>
  <p><b>作者</b>：Zachary Ankner,  Naomi Saphra,  Davis Blalock,  Jonathan Frankle,  Matthew L. Leavitt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Masked Language Modeling, original BERT model, original BERT, BERT model fixed, Language Modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most works on transformers trained with the Masked Language Modeling (MLM)
objective use the original BERT model's fixed masking rate of 15%. Our work
instead dynamically schedules the masking ratio throughout training. We found
that linearly decreasing the masking rate from 30% to 15% over the course of
pretraining improves average GLUE accuracy by 0.46% in BERT-base, compared to a
standard 15% fixed rate. Further analyses demonstrate that the gains from
scheduling come from being exposed to both high and low masking rate regimes.
Our results demonstrate that masking rate scheduling is a simple way to improve
the quality of masked language models and achieve up to a 1.89x speedup in
pretraining.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：CSTS: Conditional Semantic Textual Similarity</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15093</p>
  <p><b>作者</b>：Ameet Deshpande,  Carlos E. Jimenez,  Howard Chen,  Vishvak Murahari,  Victoria Graf,  Tanmay Rajpurohit,  Ashwin Kalyan,  Danqi Chen,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：question answering, information retrieval, embedding methods, applications in information, Semantic textual similarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic textual similarity (STS) has been a cornerstone task in NLP that
measures the degree of similarity between a pair of sentences, with
applications in information retrieval, question answering, and embedding
methods. However, it is an inherently ambiguous task, with the sentence
similarity depending on the specific aspect of interest. We resolve this
ambiguity by proposing a novel task called conditional STS (C-STS) which
measures similarity conditioned on an aspect elucidated in natural language
(hereon, condition). As an example, the similarity between the sentences "The
NBA player shoots a three-pointer." and "A man throws a tennis ball into the
air to serve." is higher for the condition "The motion of the ball." (both
upward) and lower for "The size of the ball." (one large and one small).
C-STS's advantages are two-fold: (1) it reduces the subjectivity and ambiguity
of STS, and (2) enables fine-grained similarity evaluation using diverse
conditions. C-STS contains almost 20,000 instances from diverse domains and we
evaluate several state-of-the-art models to demonstrate that even the most
performant fine-tuning and in-context learning models (GPT-4, Flan, SimCSE)
find it challenging, with Spearman correlation scores of <50. we encourage the community to evaluate their models on c-sts provide a more holistic view of semantic similarity and natural language understanding.< p>
  </50.></p></details>
</details>
<details>
  <summary>51. <b>标题：STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data  Generation with Large Language Models</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15090</p>
  <p><b>作者</b>：Mingyu Derek Ma,  Xiaoxuan Wang,  Po-Nien Kung,  P. Jeffrey Brantingham,  Nanyun Peng,  Wei Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtain reasonable performance, low-resource event extraction, Structure prediction tasks, sub-task dependencies, event extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structure prediction tasks such as event extraction require an in-depth
understanding of the output structure and sub-task dependencies, thus they
still heavily rely on task-specific training data to obtain reasonable
performance. Due to the high cost of human annotation, low-resource event
extraction, which requires minimal human cost, is urgently needed in real-world
information extraction applications. We propose to synthesize data instances
given limited seed demonstrations to boost low-resource event extraction
performance. We propose STAR, a structure-to-text data generation method that
first generates complicated event structures (Y) and then generates input
passages (X), all with Large Language Models. We design fine-grained
step-by-step instructions and the error cases and quality issues identified
through self-reflection can be self-refined. Our experiments indicate that data
generated by STAR can significantly improve the low-resource event extraction
performance and they are even more effective than human-curated data points in
some cases.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Pento-DIARef: A Diagnostic Dataset for Learning the Incremental  Algorithm for Referring Expression Generation from Examples</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15087</p>
  <p><b>作者</b>：Philipp Sadler,  David Schlangen</p>
  <p><b>备注</b>：9 pages, Accepted to EACL 2023</p>
  <p><b>关键词</b>：typically defined extensionally, NLP tasks, pairs of image, recognised and understood, typically defined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>NLP tasks are typically defined extensionally through datasets containing
example instantiations (e.g., pairs of image i and text t), but motivated
intensionally through capabilities invoked in verbal descriptions of the task
(e.g., "t is a description of i, for which the content of i needs to be
recognised and understood"). We present Pento-DIARef, a diagnostic dataset in a
visual domain of puzzle pieces where referring expressions are generated by a
well-known symbolic algorithm (the "Incremental Algorithm"), which itself is
motivated by appeal to a hypothesised capability (eliminating distractors
through application of Gricean maxims). Our question then is whether the
extensional description (the dataset) is sufficient for a neural model to pick
up the underlying regularity and exhibit this capability given the simple task
definition of producing expressions from visual inputs. We find that a model
supported by a vision detection step and a targeted data generation scheme
achieves an almost perfect BLEU@1 score and sentence accuracy, whereas simpler
baselines do not.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Eliciting the Translation Ability of Large Language Models via  Multilingual Finetuning with Translation Instructions</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15083</p>
  <p><b>作者</b>：Jiahuan Li,  Hao Zhou,  Shujian Huang,  Shanbo Chen,  Jiajun Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large-scale Pretrained Language, Pretrained Language Models, shown strong abilities, parallel corpora, Pretrained Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale Pretrained Language Models~(LLMs), such as ChatGPT and GPT4, have
shown strong abilities in multilingual translations, without being explicitly
trained on parallel corpora. It is interesting how the LLMs obtain their
ability to carry out translation instructions for different languages. In this
paper, we present a detailed analysis by finetuning a multilingual pretrained
language model, XGLM-7B, to perform multilingual translation following given
instructions. Firstly, we show that the multilingual LLMs have stronger
translation abilities than previously demonstrated. For a certain language
pair, the performance depends on both the language families and the amount of
data used in the pretraining phase. Secondly, we find that LLMs' ability to
carry out translation instructions relies on the understanding of translation
instruction and the alignment among different languages. With proper
enhancement, LLMs could perform the translation task well even for those
language pairs unseen during the instruction tuning phase.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Cream: Visually-Situated Natural Language Understanding with Contrastive  Reading Model and Frozen Large Language Models</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15080</p>
  <p><b>作者</b>：Geewook Kim,  Hodong Lee,  Daehee Kim,  Haeji Jung,  Sanghee Park,  Yoonsik Kim,  Sangdoo Yun,  Taeho Kil,  Bado Lee,  Seunghyun Park</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Advances in Large, Large Language, inspired a surge, surge of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advances in Large Language Models (LLMs) have inspired a surge of research
exploring their expansion into the visual domain. While recent models exhibit
promise in generating abstract captions for images and conducting natural
conversations, their performance on text-rich images leaves room for
improvement. In this paper, we propose the Contrastive Reading Model (Cream), a
novel neural architecture designed to enhance the language-image understanding
capability of LLMs by capturing intricate details typically overlooked by
existing methods. Cream integrates vision and auxiliary encoders, complemented
by a contrastive feature alignment technique, resulting in a more effective
understanding of textual information within document images. Our approach,
thus, seeks to bridge the gap between vision and language understanding, paving
the way for more sophisticated Document Intelligence Assistants. Rigorous
evaluations across diverse tasks, such as visual question answering on document
images, demonstrate the efficacy of Cream as a state-of-the-art model in the
field of visual document understanding. We provide our codebase and
newly-generated datasets at this https URL</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Contrastive Learning of Sentence Embeddings from Scratch</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15077</p>
  <p><b>作者</b>：Junlei Zhang,  Zhenzhong Lan,  Junxian He</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：dominant approach, sentence embeddings, Contrastive learning, embeddings, sentence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning has been the dominant approach to train state-of-the-art
sentence embeddings. Previous studies have typically learned sentence
embeddings either through the use of human-annotated natural language inference
(NLI) data or via large-scale unlabeled sentences in an unsupervised manner.
However, even in the case of unlabeled data, their acquisition presents
challenges in certain domains due to various reasons. To address these issues,
we present SynCSE, a contrastive learning framework that trains sentence
embeddings with synthesized data. Specifically, we explore utilizing large
language models to synthesize the required data samples for contrastive
learning, including (1) producing positive and negative annotations given
unlabeled sentences (SynCSE-partial), and (2) generating sentences along with
their corresponding annotations from scratch (SynCSE-scratch). Experimental
results on sentence similarity and reranking tasks indicate that both
SynCSE-partial and SynCSE-scratch greatly outperform unsupervised baselines,
and SynCSE-partial even achieves comparable performance to the supervised
models in most settings.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Meta-Learning Online Adaptation of Language Models</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15076</p>
  <p><b>作者</b>：Nathan Hu,  Eric Mitchell,  Christopher D. Manning,  Chelsea Finn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：encode surprisingly broad, surprisingly broad knowledge, models encode surprisingly, Large language models, language models encode</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models encode surprisingly broad knowledge about the world
into their parameters. However, the knowledge in static language models can
fall out of date, limiting the model's effective "shelf life." While online
fine-tuning can reduce this degradation, we find that fine-tuning on a stream
of documents using standard optimizers such as Adam leads to a disappointingly
low level of information uptake. We hypothesize that online fine-tuning does
not sufficiently 'attend' to important information. That is, the gradient
signal from important tokens representing factual information is drowned out by
the gradient from inherently noisy tokens, suggesting a dynamic, context-aware
learning rate may be beneficial. To test this hypothesis, we meta-train a
small, autoregressive model to reweight the language modeling loss for each
token during online fine-tuning, with the objective of maximizing the
out-of-date base language model's ability to answer questions about a document
after a single weighted gradient step. We call this approach Context-aware
Meta-learned Loss Scaling (CaMeLS). Across three different distributions of
documents, our experiments find that fine-tuning on streams of thousands of
documents with CaMeLS substantially improves knowledge retention compared to
standard online fine-tuning. Finally, we find that the meta-learned weights are
general, and that a single reweighting model can be used to enhance the online
adaptation of many LMs.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：HuatuoGPT, towards Taming Language Model to Be a Doctor</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15075</p>
  <p><b>作者</b>：Hongbo Zhang,  Junying Chen,  Feng Jiang,  Fei Yu,  Zhihong Chen,  Jianquan Li,  Guiming Chen,  Xiangbo Wu,  Zhiyi Zhang,  Qingying Xiao,  Xiang Wan,  Benyou Wang,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data, language model, large language model, distilled language model, real-world data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present HuatuoGPT, a large language model (LLM) for medical
consultation. The core recipe of HuatuoGPT is to leverage both
\textit{distilled data from ChatGPT} and \textit{real-world data from doctors}
in the supervised fine-tuned stage. The responses of ChatGPT are usually
detailed, well-presented and informative while it cannot perform like a doctor
in many aspects, e.g. for integrative diagnosis. We argue that real-world data
from doctors would be complementary to distilled data in the sense the former
could tame a distilled language model to perform like doctors. To better
leverage the strengths of both data, we train a reward model to align the
language model with the merits that both data bring, following an RLAIF
(reinforced learning from AI feedback) fashion. To evaluate and benchmark the
models, we propose a comprehensive evaluation scheme (including automatic and
manual metrics). Experimental results demonstrate that HuatuoGPT achieves
state-of-the-art results in performing medical consultation among open-source
LLMs in GPT-4 evaluation, human evaluation, and medical benchmark datasets. It
is worth noting that by using additional real-world data and RLAIF, the
distilled language model (i.e., HuatuoGPT) outperforms its teacher model
ChatGPT in most cases. Our code, data, and models are publicly available at
\url{this https URL}. The online demo is
available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For  Large Language Models</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15074</p>
  <p><b>作者</b>：Daman Arora,  Himanshu Gaurav Singh,  Mausam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, past years, existing reasoning benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance on Large Language Models (LLMs) on existing reasoning
benchmarks has shot up considerably over the past years. In response, we
present JEEBench, a considerably more challenging benchmark dataset for
evaluating the problem solving abilities of LLMs. We curate 450 challenging
pre-engineering mathematics, physics and chemistry problems from the IIT
JEE-Advanced exam. Long-horizon reasoning on top of deep in-domain knowledge is
essential for solving problems in this benchmark. Our evaluation on the GPT
series of models reveals that although performance improves with newer models,
the best being GPT-4, the highest performance, even after using techniques like
Self-Consistency and Chain-of-Thought prompting is less than 40 percent. Our
analysis demonstrates that errors in algebraic manipulation and failure in
retrieving relevant domain specific concepts are primary contributors to GPT4's
low performance. Given the challenging nature of the benchmark, we hope that it
can guide future research in problem solving using LLMs. Our code and dataset
is available here.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Annotation Imputation to Individualize Predictions: Initial Studies on  Distribution Dynamics and Model Predictions</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15070</p>
  <p><b>作者</b>：London Lowmanstone,  Ruyuan Wan,  Risako Owan,  Jaehyung Kim,  Dongyeop Kang</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：time-consuming and expensive, crowdsourcing is time-consuming, data, dataset, Annotating data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotating data via crowdsourcing is time-consuming and expensive. Owing to
these costs, dataset creators often have each annotator label only a small
subset of the data. This leads to sparse datasets with examples that are marked
by few annotators; if an annotator is not selected to label an example, their
opinion regarding it is lost. This is especially concerning for subjective NLP
datasets where there is no correct label: people may have different valid
opinions. Thus, we propose using imputation methods to restore the opinions of
all annotators for all examples, creating a dataset that does not leave out any
annotator's view. We then train and prompt models with data from the imputed
dataset (rather than the original sparse dataset) to make predictions about
majority and individual annotations. Unfortunately, the imputed data provided
by our baseline methods does not improve predictions. However, through our
analysis of it, we develop a strong understanding of how different imputation
methods impact the original data in order to inform future imputation
techniques. We make all of our code and data publicly available.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks  for Exploring Theory of Mind</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15068</p>
  <p><b>作者</b>：Xiaomeng Ma,  Lingyu Gao,  Qihui Xu</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：numerous practical applications, Theory of Mind, distinct individuals, practical applications, capacity to comprehend</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Theory of Mind (ToM), the capacity to comprehend the mental states of
distinct individuals, is essential for numerous practical applications. With
the development of large language models, there is a heated debate about
whether they are able to perform ToM tasks. Previous studies have used
different tasks and prompts to test the ToM on large language models and the
results are inconsistent: some studies asserted these models are capable of
exhibiting ToM, while others suggest the opposite. In this study, We present
ToMChallenges, a dataset for comprehensively evaluating Theory of Mind based on
Sally-Anne and Smarties tests. We created 30 variations of each test (e.g.,
changing the person's name, location, and items). For each variation, we test
the model's understanding of different aspects: reality, belief, 1st order
belief, and 2nd order belief. We adapt our data for various tasks by creating
unique prompts tailored for each task category: Fill-in-the-Blank, Multiple
Choice, True/False, Chain-of-Thought True/False, Question Answering, and Text
Completion. If the model has a robust ToM, it should be able to achieve good
performance for different prompts across different tests. We evaluated two
GPT-3.5 models, text-davinci-003 and gpt-3.5-turbo-0301, with our datasets. Our
results indicate that consistent performance in ToM tasks remains a challenge.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Not All Metrics Are Guilty: Improving NLG Evaluation with LLM  Paraphrasing</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15067</p>
  <p><b>作者</b>：Tianyi Tang,  Hongyuan Lu,  Yuchen Eleanor Jiang,  Haoyang Huang,  Dongdong Zhang,  Wayne Xin Zhao,  Furu Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language generation, research about natural, human judgements, language generation, evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most research about natural language generation (NLG) relies on evaluation
benchmarks with limited references for a sample, which may result in poor
correlations with human judgements. The underlying reason is that one semantic
meaning can actually be expressed in different forms, and the evaluation with a
single or few references may not accurately reflect the quality of the model's
hypotheses. To address this issue, this paper presents a novel method, named
Para-Ref, to enhance existing evaluation benchmarks by enriching the number of
references. We leverage large language models (LLMs) to paraphrase a single
reference into multiple high-quality ones in diverse expressions. Experimental
results on representative NLG tasks of machine translation, text summarization,
and image caption demonstrate that our method can effectively improve the
correlation with human evaluation for sixteen automatic evaluation metrics by
+7.82% in ratio. We release the code and data at
this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：GPT4Graph: Can Large Language Models Understand Graph Structured Data ?  An Empirical Evaluation and Benchmarking</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15066</p>
  <p><b>作者</b>：Jiayan Guo,  Lun Du,  Hengyu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial general intelligence, demonstrating excellent performance, general intelligence, demonstrating excellent, indispensable to artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models~(LLM) like ChatGPT have become indispensable to
artificial general intelligence~(AGI), demonstrating excellent performance in
various natural language processing tasks. In the real world, graph data is
ubiquitous and an essential part of AGI and prevails in domains like social
network analysis, bioinformatics and recommender systems. The training corpus
of large language models often includes some algorithmic components, which
allows them to achieve certain effects on some graph data-related problems.
However, there is still little research on their performance on a broader range
of graph-structured data. In this study, we conduct an extensive investigation
to assess the proficiency of LLMs in comprehending graph data, employing a
diverse range of structural and semantic-related tasks. Our analysis
encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph
understanding. Through our study, we not only uncover the current limitations
of language models in comprehending graph structures and performing associated
reasoning tasks but also emphasize the necessity for further advancements and
novel approaches to enhance their graph processing capabilities. Our findings
contribute valuable insights towards bridging the gap between language models
and graph understanding, paving the way for more effective graph mining and
knowledge extraction.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs  without Fine-tuning</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15065</p>
  <p><b>作者</b>：Ximing Lu,  Faeze Brahman,  Peter West,  Jaehun Jang,  Khyathi Chandu,  Abhilasha Ravichander,  Lianhui Qin,  Prithviraj Ammanabrolu,  Liwei Jiang,  Sahana Ramnath,  Nouha Dziri,  Jillian Fisher,  Bill Yuchen Lin,  Skyler Hallinan,  Xiang Ren,  Sean Welleck,  Yejin Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：IPA, Inference-time Policy Adapters, language models, language, language models excel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models excel at a variety of language tasks when prompted with
examples or instructions. Yet controlling these models through prompting alone
is limited. Tailoring language models through fine-tuning (e.g., via
reinforcement learning) can be effective, but it is expensive and requires
model access.
We propose Inference-time Policy Adapters (IPA), which efficiently tailors a
language model such as GPT-3 without fine-tuning it. IPA guides a large base
model during decoding time through a lightweight policy adaptor trained to
optimize an arbitrary user objective with reinforcement learning.
On five challenging text generation tasks, such as toxicity reduction and
open-domain generation, IPA consistently brings significant improvements over
off-the-shelf language models. It outperforms competitive baseline methods,
sometimes even including expensive fine-tuning. In particular, tailoring GPT-2
with IPA can outperform GPT-3, while tailoring GPT- 3 with IPA brings a major
performance boost over GPT-3 (and sometimes even over GPT-4). Our promising
results highlight the potential of IPA as a lightweight alternative to
tailoring extreme-scale language models.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Prompt Optimization of Large Language Model for Interactive Tasks  without Gradient and Demonstrations</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15064</p>
  <p><b>作者</b>：Siqi Ouyang,  Lei Li</p>
  <p><b>备注</b>：Draft. Work in Progress</p>
  <p><b>关键词</b>：Large language models, remarkable language proficiency, demonstrated remarkable language, interactive tasks independently, solving interactive tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable language
proficiency, but they face challenges when solving interactive tasks
independently. Existing methods either rely on gradient access, which is often
inaccessible in state-of-the-art LLMs like GPT-4, or necessitate diverse and
high-quality in-context demonstrations. In this study, we propose LLM-PO, a
novel approach that enables LLMs to address these tasks without gradient access
or extensive demonstrations. The key idea is to maintain a text-based plan and
ask LLMs to reflect on pros and cons of the current plan based on experience
collected with it, to update the plan, and to collect more experiences with the
new plan. Experiments on HotpotQA demonstrate that LLM-PO achieves higher or on
par success rates compared to in-context learning (ICL) baselines while
requiring less inference cost.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Lawyer LLaMA Technical Report</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15062</p>
  <p><b>作者</b>：Quzhe Huang,  Mingxu Tao,  Zhenwei An,  Chen Zhang,  Cong Jiang,  Zhibin Chen,  Zirui Wu,  Yansong Feng</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：Large Language Models, exhibited remarkable performances, Large Language, Language Models, exhibited remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs), like LLaMA, have exhibited remarkable
performances across various tasks. Nevertheless, when deployed to specific
domains such as law or medicine, the models still confront the challenge of a
deficiency in domain-specific knowledge and an inadequate capability to
leverage that knowledge to resolve domain-related problems. In this paper, we
focus on the legal domain and explore how to inject domain knowledge during the
continual training stage and how to design proper supervised finetune tasks to
help the model tackle practical issues. Moreover, to alleviate the
hallucination problem during model's generation, we add a retrieval module and
extract relevant articles before the model answers any queries. Augmenting with
the extracted evidence, our model could generate more reliable responses. We
release our data and model at this https URL.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Who Wrote this Code? Watermarking for Code Generation</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15060</p>
  <p><b>作者</b>：Taehyun Lee,  Seokhee Hong,  Jaewoo Ahn,  Ilgee Hong,  Hwaran Lee,  Sangdoo Yun,  Jamin Shin,  Gunhee Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, recently shown remarkable, shown remarkable performance, generating executable code, code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models for code have recently shown remarkable performance in
generating executable code. However, this rapid advancement has been
accompanied by many legal and ethical concerns, such as code licensing issues,
code plagiarism, and malware generation, making watermarking machine-generated
code a very timely problem. Despite such imminent needs, we discover that
existing watermarking and machine-generated text detection methods for LLMs
fail to function with code generation tasks properly. Hence, in this work, we
propose a new watermarking method, SWEET, that significantly improves upon
previous approaches when watermarking machine-generated code. Our proposed
method selectively applies watermarking to the tokens with high enough entropy,
surpassing a defined threshold. The experiments on code generation benchmarks
show that our watermarked code has superior quality compared to code produced
by the previous state-of-the-art LLM watermarking method. Furthermore, our
watermark method also outperforms DetectGPT for the task of machine-generated
code detection.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Learning the String Partial Order</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15057</p>
  <p><b>作者</b>：Tianyu Liu,  Afra Amini,  Mrinmaya Sachan,  Ryan Cotterell</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：structured prediction problems, input string, structured prediction, prediction problems, solved in linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that most structured prediction problems can be solved in linear time
and space by considering them as partial orderings of the tokens in the input
string. Our method computes real numbers for each token in an input string and
sorts the tokens accordingly, resulting in as few as 2 total orders of the
tokens in the string. Each total order possesses a set of edges oriented from
smaller to greater tokens. The intersection of total orders results in a
partial order over the set of input tokens, which is then decoded into a
directed graph representing the desired structure. Experiments show that our
method achieves 95.4 LAS and 96.9 UAS by using an intersection of 2 total
orders, 95.7 LAS and 97.1 UAS with 4 on the English Penn Treebank dependency
parsing benchmark. Our method is also the first linear-complexity coreference
resolution model and achieves 79.2 F1 on the English OntoNotes benchmark, which
is comparable with state of the art.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Reasoning over Hierarchical Question Decomposition Tree for Explainable  Question Answering</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15056</p>
  <p><b>作者</b>：Jiajie Zhang,  Shulin Cao,  Tingjia Zhang,  Xin Lv,  Jiaxin Shi,  Qi Tian,  Juanzi Li,  Lei Hou</p>
  <p><b>备注</b>：has been accepted by ACL2023</p>
  <p><b>关键词</b>：Question Decomposition Tree, question, Hierarchical Question Decomposition, provide an explanation, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable question answering (XQA) aims to answer a given question and
provide an explanation why the answer is selected. Existing XQA methods focus
on reasoning on a single knowledge source, e.g., structured knowledge bases,
unstructured corpora, etc. However, integrating information from heterogeneous
knowledge sources is essential to answer complex questions. In this paper, we
propose to leverage question decomposing for heterogeneous knowledge
integration, by breaking down a complex question into simpler ones, and
selecting the appropriate knowledge source for each sub-question. To facilitate
reasoning, we propose a novel two-stage XQA framework, Reasoning over
Hierarchical Question Decomposition Tree (RoHT). First, we build the
Hierarchical Question Decomposition Tree (HQDT) to understand the semantics of
a complex question; then, we conduct probabilistic reasoning over HQDT from
root to leaves recursively, to aggregate heterogeneous knowledge at different
tree levels and search for a best solution considering the decomposing and
answering probabilities. The experiments on complex QA datasets KQA Pro and
Musique show that our framework outperforms SOTA methods significantly,
demonstrating the effectiveness of leveraging question decomposing for
knowledge integration and our RoHT framework.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Understanding Arithmetic Reasoning in Language Models using Causal  Mediation Analysis</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15054</p>
  <p><b>作者</b>：Alessandro Stolfo,  Yonatan Belinkov,  Mrinmaya Sachan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：store information related, recent research, limited understanding, process and store, store information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical reasoning in large language models (LLMs) has garnered attention
in recent research, but there is limited understanding of how these models
process and store information related to arithmetic tasks. In this paper, we
present a mechanistic interpretation of LLMs for arithmetic-based questions
using a causal mediation analysis framework. By intervening on the activations
of specific model components and measuring the resulting changes in predicted
probabilities, we identify the subset of parameters responsible for specific
predictions. We analyze two pre-trained language models with different sizes
(2.8B and 6B parameters). Experimental results reveal that a small set of
mid-late layers significantly affect predictions for arithmetic-based
questions, with distinct activation patterns for correct and wrong predictions.
We also investigate the role of the attention mechanism and compare the model's
activation patterns for arithmetic queries with the prediction of factual
knowledge. Our findings provide insights into the mechanistic interpretation of
LLMs for arithmetic tasks and highlight the specific components involved in
arithmetic reasoning.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Decomposing Complex Queries for Tip-of-the-tongue Retrieval</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15053</p>
  <p><b>作者</b>：Kevin Lin,  Kyle Lo,  Joseph E. Gonzalez,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：describe content elements, document text, re-finding items, users who forget, content elements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When re-finding items, users who forget or are uncertain about identifying
details often rely on creative strategies for expressing their information
needs -- complex queries that describe content elements (e.g., book characters
or events), information beyond the document text (e.g., descriptions of book
covers), or personal context (e.g., when they read a book). This retrieval
setting, called tip of the tongue (TOT), is especially challenging for models
heavily reliant on lexical and semantic overlap between query and document
text. In this work, we introduce a simple yet effective framework for handling
such complex queries by decomposing the query into individual clues, routing
those as sub-queries to specialized retrievers, and ensembling the results.
This approach allows us to take advantage of off-the-shelf retrievers (e.g.,
CLIP for retrieving images of book covers) or incorporate retriever-specific
logic (e.g., date constraints). We show that our framework incorportating query
decompositions into retrievers can improve gold book recall up to 7% relative
again for Recall@5 on a new collection of 14,441 real-world query-book pairs
from an online community for resolving TOT inquiries.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：A Monte Carlo Language Model Pipeline for Zero-Shot Sociopolitical Event  Extraction</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15051</p>
  <p><b>作者</b>：Erica Cai,  Brendan O'Connor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify actions, actions between pairs, emph, dyadic zero-shot event, zero-shot event extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider dyadic zero-shot event extraction (EE) to identify actions
between pairs of actors. The \emph{zero-shot} setting allows social scientists
or other non-computational researchers to extract any customized,
user-specified set of events without training, resulting in a \emph{dyadic}
event database, allowing insight into sociopolitical relational dynamics among
actors and the higher level organizations or countries they represent.
Unfortunately, we find that current zero-shot EE methods perform poorly for the
task, with issues including word sense ambiguity, modality mismatch, and
efficiency. Straightforward application of large language model prompting
typically performs even worse. We address these challenges with a new
fine-grained, multi-stage generative question-answer method, using a Monte
Carlo approach to exploit and overcome the randomness of generative outputs. It
performs 90\% fewer queries than a previous approach, with strong performance
on the widely-used Automatic Content Extraction dataset. Finally, we extend our
method to extract affiliations of actor arguments and demonstrate our method
and findings on a dyadic international relations case study.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15048</p>
  <p><b>作者</b>：Mete Sertkan,  Sophia Althammer,  Sebastian Hofstätter</p>
  <p><b>备注</b>：Accepted at ACL 2023 (System Demonstrations)</p>
  <p><b>关键词</b>：meta-analysis for multi-task, facilitate the easy, introduce Ranger, Ranger, evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce Ranger - a toolkit to facilitate the easy use of
effect-size-based meta-analysis for multi-task evaluation in NLP and IR. We
observed that our communities often face the challenge of aggregating results
over incomparable metrics and scenarios, which makes conclusions and take-away
messages less reliable. With Ranger, we aim to address this issue by providing
a task-agnostic toolkit that combines the effect of a treatment on multiple
tasks into one statistical evaluation, allowing for comparison of metrics and
computation of an overall summary effect. Our toolkit produces
publication-ready forest plots that enable clear communication of evaluation
results over multiple tasks. Our goal with the ready-to-use Ranger toolkit is
to promote robust, effect-size-based evaluation and improve evaluation
standards in the community. We provide two case studies for common IR and NLP
settings to highlight Ranger's benefits.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Ghostbuster: Detecting Text Ghostwritten by Large Language Models</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15047</p>
  <p><b>作者</b>：Vivek Verma,  Eve Fleisig,  Nicholas Tomlin,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：system for detecting, introduce Ghostbuster, AI-generated, detection, Ghostbuster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Ghostbuster, a state-of-the-art system for detecting
AI-generated text. Our method works by passing documents through a series of
weaker language models and running a structured search over possible
combinations of their features, then training a classifier on the selected
features to determine if the target document was AI-generated. Crucially,
Ghostbuster does not require access to token probabilities from the target
model, making it useful for detecting text generated by black-box models or
unknown model versions. In conjunction with our model, we release three new
datasets of human and AI-generated text as detection benchmarks that cover
multiple domains (student essays, creative fiction, and news) and task setups:
document-level detection, author identification, and a challenge task of
paragraph-level detection. Ghostbuster averages 99.1 F1 across all three
datasets on document-level detection, outperforming previous approaches such as
GPTZero and DetectGPT by up to 32.7 F1.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：SETI: Systematicity Evaluation of Textual Inference</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15045</p>
  <p><b>作者</b>：Xiyan Fu,  Anette Frank</p>
  <p><b>备注</b>：Accepted to Findings of ACL2023</p>
  <p><b>关键词</b>：evaluating pre-trained language, Systematicity Evaluation, pre-trained language models, comprehensive benchmark designed, Evaluation of Textual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose SETI (Systematicity Evaluation of Textual Inference), a novel and
comprehensive benchmark designed for evaluating pre-trained language models
(PLMs) for their systematicity capabilities in the domain of textual inference.
Specifically, SETI offers three different NLI tasks and corresponding datasets
to evaluate various types of systematicity in reasoning processes. In order to
solve these tasks, models are required to perform compositional inference based
on known primitive constituents. We conduct experiments of SETI on six widely
used PLMs. Results show that various PLMs are able to solve unseen
compositional inferences when having encountered the knowledge of how to
combine primitives, with good performance. However, they are considerably
limited when this knowledge is unknown to the model (40-100% points decrease).
Furthermore, we find that PLMs can improve drastically once exposed to crucial
compositional knowledge in minimalistic shots. These findings position SETI as
the first benchmark for measuring the future progress of PLMs in achieving
systematicity generalization in the textual inference.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Is Summary Useful or Not? An Extrinsic Human Evaluation of Text  Summaries on Downstream Tasks</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15044</p>
  <p><b>作者</b>：Xiao Pu,  Mingqi Gao,  Xiaojun Wan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：summarization relies heavily, text, Research on automated, automated text summarization, text summarization relies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research on automated text summarization relies heavily on human and
automatic evaluation. While recent work on human evaluation mainly adopted
intrinsic evaluation methods, judging the generic quality of text summaries,
e.g. informativeness and coherence, our work focuses on evaluating the
usefulness of text summaries with extrinsic methods. We carefully design three
different downstream tasks for extrinsic human evaluation of summaries, i.e.,
question answering, text classification and text similarity assessment. We
carry out experiments using system rankings and user behavior data to evaluate
the performance of different summarization models. We find summaries are
particularly useful in tasks that rely on an overall judgment of the text,
while being less effective for question answering tasks. The results show that
summaries generated by fine-tuned models lead to higher consistency in
usefulness across all three tasks, as rankings of fine-tuned summarization
systems are close across downstream tasks according to the proposed extrinsic
metrics. Summaries generated by models in the zero-shot setting, however, are
found to be biased towards the text classification and similarity assessment
tasks, due to its general and less detailed summary style. We further evaluate
the correlation of 14 intrinsic automatic metrics with human criteria and show
that intrinsic automatic metrics perform well in evaluating the usefulness of
summaries in the question-answering task, but are less effective in the other
two tasks. This highlights the limitations of relying solely on intrinsic
automatic metrics in evaluating the performance and usefulness of summaries.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Generating Faithful Synthetic Data with Large Language Models: A Case  Study in Computational Social Science</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15041</p>
  <p><b>作者</b>：Veniamin Veselovsky,  Manoel Horta Ribeiro,  Akhil Arora,  Martin Josifoski,  Ashton Anderson,  Robert West</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, synthetic data generation, synthetic data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have democratized synthetic data generation,
which in turn has the potential to simplify and broaden a wide gamut of NLP
tasks. Here, we tackle a pervasive problem in synthetic data generation: its
generative distribution often differs from the distribution of real-world data
researchers care about (in other words, it is unfaithful). In a case study on
sarcasm detection, we study three strategies to increase the faithfulness of
synthetic data: grounding, filtering, and taxonomy-based generation. We
evaluate these strategies using the performance of classifiers trained with
generated synthetic data on real-world data. While all three strategies improve
the performance of classifiers, we find that grounding works best for the task
at hand. As synthetic data generation plays an ever-increasing role in NLP
research, we expect this work to be a stepping stone in improving its utility.
We conclude this paper with some recommendations on how to generate
high(er)-fidelity synthetic data for specific tasks.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Active Learning for Natural Language Generation</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15040</p>
  <p><b>作者</b>：Yotam Perlitz,  Ariel Gera,  Michal Shmueli-Scheuer,  Dafna Sheinwald,  Noam Slonim,  Liat Ein-Dor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：labeled data due, time consuming process, consuming process involved, text generation suffers, text generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of text generation suffers from a severe shortage of labeled data
due to the extremely expensive and time consuming process involved in manual
annotation. A natural approach for coping with this problem is active learning
(AL), a well-known machine learning technique for improving annotation
efficiency by selectively choosing the most informative examples to label.
However, while AL has been well-researched in the context of text
classification, its application to text generation remained largely unexplored.
In this paper, we present a first systematic study of active learning for text
generation, considering a diverse set of tasks and multiple leading AL
strategies. Our results indicate that existing AL strategies, despite their
success in classification, are largely ineffective for the text generation
scenario, and fail to consistently surpass the baseline of random example
selection. We highlight some notable differences between the classification and
generation scenarios, and analyze the selection behaviors of existing AL
strategies. Our findings motivate exploring novel approaches for applying AL to
NLG tasks.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Is GPT-4 a Good Data Analyst?</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15038</p>
  <p><b>作者</b>：Liying Cheng,  Xingxuan Li,  Lidong Bing</p>
  <p><b>备注</b>：11 pages, 2 figures</p>
  <p><b>关键词</b>：including context understanding, large language models, code generation, language generation, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models (LLMs) have demonstrated their powerful capabilities
in plenty of domains and tasks, including context understanding, code
generation, language generation, data storytelling, etc., many data analysts
may raise concerns if their jobs will be replaced by AI. This controversial
topic has drawn a lot of attention in public. However, we are still at a stage
of divergent opinions without any definitive conclusion. Motivated by this, we
raise the research question of "is GPT-4 a good data analyst?" in this work and
aim to answer it by conducting head-to-head comparative studies. In detail, we
regard GPT-4 as a data analyst to perform end-to-end data analysis with
databases from a wide range of domains. We propose a framework to tackle the
problems by carefully designing the prompts for GPT-4 to conduct experiments.
We also design several task-specific evaluation metrics to systematically
compare the performance between several professional human data analysts and
GPT-4. Experimental results show that GPT-4 can achieve comparable performance
to humans. We also provide in-depth discussions about our results to shed light
on further studies before we reach the conclusion that GPT-4 can replace data
analysts.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Self-ICL: Zero-Shot In-Context Learning with Self-Generated  Demonstrations</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15035</p>
  <p><b>作者</b>：Wei-Lin Chen,  Cheng-Kuang Wu,  Hsin-Hsi Chen</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：superior in-context learning, exhibited superior in-context, Large language models, Large language, in-context learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LMs) have exhibited superior in-context learning (ICL)
ability to adopt to target tasks by prompting with a few input-output
demonstrations. Towards better ICL, different methods are proposed to select
representative demonstrations from existing training corpora. However, such a
setting is not aligned with real-world practices, as end-users usually query
LMs without accesses to demonstration pools. Inspired by evidence suggesting
LMs' zero-shot capabilities are underrated, and the role of demonstrations are
primarily for exposing models' intrinsic functionalities, we introduce
Self-ICL, a simple framework for zero-shot ICL. Given a test input, Self-ICL
first prompts the model to generate pseudo-inputs. Next, the model predicts
pseudo-labels for the pseudo-inputs via zero-shot prompting. Finally, we
construct pseudo-demonstrations from pseudo-input-label pairs, and perform ICL
for the test input. Evaluation on BIG-Bench Hard shows Self-ICL steadily
surpasses zero-shot and zero-shot chain-of-thought baselines on head-to-head
and all-task average performance. Our findings suggest the possibility to
bootstrap LMs' intrinsic capabilities towards better zero-shot performance.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient  Vision-Language Models</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15033</p>
  <p><b>作者</b>：Zekun Wang,  Jingchang Chen,  Wangchunshu Zhou,  Ming Liu,  Bing Qin</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：achieving remarkable performance, achieving remarkable, vision-language tasks, Transformer-based pretrained vision-language, pretrained vision-language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite achieving remarkable performance on various vision-language tasks,
Transformer-based pretrained vision-language models (VLMs) still suffer from
efficiency issues arising from long inputs and numerous parameters, limiting
their real-world applications. However, the huge computation is redundant for
most samples and the degree of redundancy and the respective components vary
significantly depending on tasks and input instances. In this work, we propose
an adaptive acceleration method SmartTrim for VLMs, which adjusts the inference
overhead based on the complexity of instances. Specifically, SmartTrim
incorporates lightweight trimming modules into the backbone to perform
task-specific pruning on redundant inputs and parameters, without the need for
additional pre-training or data augmentation. Since visual and textual
representations complement each other in VLMs, we propose to leverage
cross-modal interaction information to provide more critical semantic guidance
for identifying redundant parts. Meanwhile, we introduce a self-distillation
strategy that encourages the trimmed model to be consistent with the
full-capacity model, which yields further performance gains. Experimental
results demonstrate that SmartTrim significantly reduces the computation
overhead (2-3 times) of various VLMs with comparable performance (only a 1-2%
degradation) on various vision-language tasks. Compared to previous
acceleration methods, SmartTrim attains a better efficiency-performance
trade-off, demonstrating great potential for application in
resource-constrained scenarios.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：How to Distill your BERT: An Empirical Study on the Impact of Weight  Initialisation and Distillation Objectives</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15032</p>
  <p><b>作者</b>：Xinpeng Wang,  Leonie Weissweiler,  Hinrich Schütze,  Barbara Plank</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：compression of BERT, BERT models, shown to improve, improve compression, intermediate layer distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, various intermediate layer distillation (ILD) objectives have been
shown to improve compression of BERT models via Knowledge Distillation (KD).
However, a comprehensive evaluation of the objectives in both task-specific and
task-agnostic settings is lacking. To the best of our knowledge, this is the
first work comprehensively evaluating distillation objectives in both settings.
We show that attention transfer gives the best performance overall. We also
study the impact of layer choice when initializing the student from the teacher
layers, finding a significant impact on the performance in task-specific
distillation. For vanilla KD and hidden states transfer, initialisation with
lower layers of the teacher gives a considerable improvement over higher
layers, especially on the task of QNLI (up to an absolute percentage change of
17.8 in accuracy). Attention transfer behaves consistently under different
initialisation settings. We release our code as an efficient transformer-based
model distillation framework for further studies.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet  Categories</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15028</p>
  <p><b>作者</b>：Heming Xia,  Qingxiu Dong,  Lei Li,  Jingjing Xu,  Ziwei Qin,  Zhifang Sui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual commonsense knowledge, Pretrained Language Models, Pretrained Language, commonsense knowledge, visual commonsense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Pretrained Language Models (PLMs) have been serving as
general-purpose interfaces, posing a significant demand for comprehensive
visual knowledge. However, it remains unclear how well current PLMs and their
visually augmented counterparts (VaLMs) can master visual commonsense
knowledge. To investigate this, we propose ImageNetVC, a fine-grained,
human-annotated dataset specifically designed for zero-shot visual commonsense
evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we delve
into the fundamental visual commonsense knowledge of both unimodal PLMs and
VaLMs, uncovering the scaling law and the influence of the backbone model on
VaLMs. Furthermore, we investigate the factors affecting the visual commonsense
knowledge of large-scale models, providing insights into the development of
language models enriched with visual commonsense knowledge. Our code and
dataset are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Dior-CVAE: Diffusion Priors in Variational Dialog Generation</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15025</p>
  <p><b>作者</b>：Tianyu Yang,  Thy Thy Tran,  Iryna Gurevych</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Conditional variational autoencoders, diverse response generation, recently for diverse, represent the relationship, CVAE model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional variational autoencoders (CVAEs) have been used recently for
diverse response generation, by introducing latent variables to represent the
relationship between a dialog context and its potential responses. However, the
diversity of the generated responses brought by a CVAE model is limited due to
the oversimplified assumption of the isotropic Gaussian prior. We propose,
Dior-CVAE, a hierarchical CVAE model with an informative prior produced by a
diffusion model. Dior-CVAE derives a series of layer-wise latent variables
using attention mechanism and infusing them into decoder layers accordingly. We
propose memory dropout in the latent infusion to alleviate posterior collapse.
The prior distribution of the latent variables is parameterized by a diffusion
model to introduce a multimodal distribution. Overall, experiments on two
popular open-domain dialog datasets indicate the advantages of our approach
over previous Transformer-based variational dialog models in dialog response
generation. We publicly release the code for reproducing Dior-CVAE and all
baselines at
this https URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic  Agricultural Text Classification</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15024</p>
  <p><b>作者</b>：Biao Zhao,  Weiqiang Jin,  Javier Del Ser,  Guang Yang</p>
  <p><b>备注</b>：24 pages,10+figures,46references.Both the first two authors, Biao Zhao and Weiqiang Jin, made equal contributions to this work. Corresponding author: Guang Yang</p>
  <p><b>关键词</b>：sustainable smart agriculture, massive agricultural knowledge, massive amount, smart agriculture, era of sustainable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of sustainable smart agriculture, a massive amount of agricultural
news text is being posted on the Internet, in which massive agricultural
knowledge has been accumulated. In this context, it is urgent to explore
effective text classification techniques for users to access the required
agricultural knowledge with high efficiency. Mainstream deep learning
approaches employing fine-tuning strategies on pre-trained language models
(PLMs), have demonstrated remarkable performance gains over the past few years.
Nonetheless, these methods still face many drawbacks that are complex to solve,
including: 1. Limited agricultural training data due to the expensive-cost and
labour-intensive annotation; 2. Poor domain transferability, especially of
cross-linguistic ability; 3. Complex and expensive large models
deployment.Inspired by the extraordinary success brought by the recent ChatGPT
(e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore
the capability and utilization of ChatGPT applying to the agricultural
informatization field. ....(shown in article).... Code has been released on
Github
this https URL.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：An Efficient Multilingual Language Model Compression through Vocabulary  Trimming</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15020</p>
  <p><b>作者</b>：Asahi Ushio,  Yi Zhou,  Jose Camacho-Collados</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multilingual, powerful tool, vocabulary, LMs, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilingual language model (LM) have become a powerful tool in NLP
especially for non-English languages. Nevertheless, model parameters of
multilingual LMs remain large due to the larger embedding matrix of the
vocabulary covering tokens in different languages. On the contrary, monolingual
LMs can be trained in a target language with the language-specific vocabulary
only, but this requires a large budget and availability of reliable corpora to
achieve a high-quality LM from scratch. In this paper, we propose
vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a
target language by deleting irrelevant tokens from its vocabulary. In theory,
VT can compress any existing multilingual LM to build monolingual LMs in any
language covered by the multilingual LM. In our experiments, we show that VT
can retain the original performance of the multilingual LM, while being smaller
in size (in general around 50% of the original vocabulary size is enough) than
the original multilingual LM. The evaluation is performed over four NLP tasks
(two generative and two classification tasks) among four widely used
multilingual LMs in seven languages. Finally, we show that this methodology can
keep the best of both monolingual and multilingual worlds by keeping a small
size as monolingual models without the need for specifically retraining them,
and even limiting potentially harmful social biases.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Calc-X: Enriching Arithmetical Chain-of-Thoughts Datasets by Interaction  with Symbolic Systems</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15017</p>
  <p><b>作者</b>：Marek Kadlčík,  Michal Štefánik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work in enriching, non-parametric components, requiring arithmetical reasoning, report overviews, overviews our ongoing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report overviews our ongoing work in enriching chain-of-thoughts
datasets requiring arithmetical reasoning with the integration of
non-parametric components, such as a calculator. We conduct an analysis of
prominent relevant datasets such as GSM8K, Ape210K, AQuA-RAT, and MathQA and
propose a machine-processable HTML-like format specifically tailored for
working with semi-structured chains. By converting the datasets into this
unified format, we enable the effective integration of large language models
and symbolic systems, empowering them to tackle arithmetical reasoning tasks
more efficiently.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Unlocking Temporal Question Answering for Large Language Models Using  Code Execution</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15014</p>
  <p><b>作者</b>：Xingxuan Li,  Liying Cheng,  Qingyu Tan,  Hwee Tou Ng,  Shafiq Joty,  Lidong Bing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, natural language processing, made significant progress, Large language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have made significant progress in natural
language processing (NLP), and are utilized extensively in various
applications. Recent works, such as chain-of-thought (CoT), have shown that
intermediate reasoning steps can improve the performance of LLMs for complex
reasoning tasks, such as math problems and symbolic question-answering tasks.
However, we notice the challenge that LLMs face when it comes to temporal
reasoning. Our preliminary experiments show that generating intermediate
reasoning steps does not always boost the performance of complex temporal
question-answering tasks. Therefore, we propose a novel framework that combines
the extraction capability of LLMs and the logical reasoning capability of a
Python solver to tackle this issue. Extensive experiments and analysis
demonstrate the effectiveness of our framework in handling intricate time-bound
reasoning tasks.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Bactrian-X : A Multilingual Replicable Instruction-Following Model with  Low-Rank Adaptation</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15011</p>
  <p><b>作者</b>：Haonan Li,  Fajri Koto,  Minghao Wu,  Alham Fikri Aji,  Timothy Baldwin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great promise, natural language processing, Instruction tuning, multilingual instruction tuning, shown great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has shown great promise in the field of natural language
processing. However, the research on multilingual instruction tuning has been
limited due to the scarcity of high-quality instruction-response datasets. To
address this gap, we present Bactrian-X, a comprehensive multilingual parallel
dataset of 3.4 million instruction-response pairs across 52 languages.
Leveraging this dataset, we train a set of adapters using low-rank adaptation
(LoRA), which are lightweight components seamlessly integrated with
foundational models. These adapters have a significantly smaller parameter
count than the base model, making them easily replaceable and usable as
plug-ins for different languages or language groups. Through extensive
experiments on 52 languages, we demonstrate the superior performance of our
models in various multilingual evaluation settings. Our proposed models
outperform both the vanilla models and the existing instruction-tuned models.
The code and models are publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism  and Synonymous Substitution</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15010</p>
  <p><b>作者</b>：Hongbo Zhang,  Xiang Wan,  Benyou Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：relational knowledge, store relational knowledge, relational knowledge present, Pre-trained language models, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models (PLMs) were considered to be able to store
relational knowledge present in the training data. However, some relational
knowledge seems to be discarded unsafely in PLMs due to \textbf{report bias}:
low-frequency relational knowledge might be underexpressed compared to
high-frequency one in PLMs. This gives us a hint that relational knowledge
might not be redundant to the stored knowledge of PLMs, but rather be
complementary. To additionally inject relational knowledge into PLMs, we
propose a simple-yet-effective approach to inject relational knowledge into
PLMs, which is inspired by three observations (namely, polymorphism, synonymous
substitution, and association). In particular, we switch entities in the
training corpus to related entities (either hypernyms/hyponyms/synonyms, or
arbitrarily-related concepts). Experimental results show that the proposed
approach could not only better capture relational knowledge, but also improve
the performance in various biomedical downstream tasks. Our model is available
in \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation  into Input Regurgitation and Prompt-Induced Sanitization</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15008</p>
  <p><b>作者</b>：Aman Priyanshu,  Supriti Vijay,  Ayush Kumar,  Rakshit Naidu,  Fatemehsadat Mireshghallah</p>
  <p><b>备注</b>：12 pages, 9 figures, and 4 tables</p>
  <p><b>关键词</b>：industry hiring decisions, industry hiring, hiring decisions, personal assistants, widely adopted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LLM-powered chatbots are becoming widely adopted in applications such as
healthcare, personal assistants, industry hiring decisions, etc. In many of
these cases, chatbots are fed sensitive, personal information in their prompts,
as samples for in-context learning, retrieved records from a database, or as
part of the conversation. The information provided in the prompt could directly
appear in the output, which might have privacy ramifications if there is
sensitive information there. As such, in this paper, we aim to understand the
input copying and regurgitation capabilities of these models during inference
and how they can be directly instructed to limit this copying by complying with
regulations such as HIPAA and GDPR, based on their internal knowledge of them.
More specifically, we find that when ChatGPT is prompted to summarize cover
letters of a 100 candidates, it would retain personally identifiable
information (PII) verbatim in 57.4% of cases, and we find this retention to be
non-uniform between different subgroups of people, based on attributes such as
gender identity. We then probe ChatGPT's perception of privacy-related policies
and privatization mechanisms by directly instructing it to provide compliant
outputs and observe a significant omission of PII from output.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Sentiment Analysis in the Era of Large Language Models: A Reality Check</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15005</p>
  <p><b>作者</b>：Wenxuan Zhang,  Yue Deng,  Bing Liu,  Sinno Jialin Pan,  Lidong Bing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long-standing research area, natural language processing, long-standing research, research area, area in natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentiment analysis (SA) has been a long-standing research area in natural
language processing. It can offer rich insights into human sentiments and
opinions and has thus seen considerable interest from both academia and
industry. With the advent of large language models (LLMs) such as ChatGPT,
there is a great potential for their employment on SA problems. However, the
extent to which existing LLMs can be leveraged for different sentiment analysis
tasks remains unclear. This paper aims to provide a comprehensive investigation
into the capabilities of LLMs in performing various sentiment analysis tasks,
from conventional sentiment classification to aspect-based sentiment analysis
and multifaceted analysis of subjective texts. We evaluate performance across
13 tasks on 26 datasets and compare the results against small language models
(SLMs) trained on domain-specific datasets. Our study reveals that while LLMs
demonstrate satisfactory performance in simpler tasks, they lag behind in more
complex tasks requiring deeper understanding or structured sentiment
information. However, LLMs significantly outperform SLMs in few-shot learning
settings, suggesting their potential when annotation resources are limited. We
also highlight the limitations of current evaluation practices in assessing
LLMs' SA abilities and propose a novel benchmark, \textsc{SentiEval}, for a
more comprehensive and realistic evaluation. Data and code during our
investigations are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：LLMDet: A Large Language Models Detection Tool</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15004</p>
  <p><b>作者</b>：Kangxi Wu,  Liang Pang,  Huawei Shen,  Xueqi Cheng,  Tat-Seng Chua</p>
  <p><b>备注</b>：7 pages, 1 figure</p>
  <p><b>关键词</b>：generative language models, high-quality human-authored text, fluency and diversity, text, advancement of generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the advancement of generative language models, the generated text has
come remarkably close to high-quality human-authored text in terms of fluency
and diversity. This calls for a highly practical detection tool that can
identify the source of text, preferably pinpointing the language model it
originates from. However, existing detection tools typically require access to
language models and can only differentiate between machine-generated and
human-authored text, failing to meet the requirements of rapid detection and
text tracing. Therefore, in this paper, we propose an efficient, secure, and
scalable detection tool called LLMDet, which calculates the proxy perplexity of
text by utilizing the prior information of the model's next-token
probabilities, obtained through pre-training. Subsequently, we use the
self-watermarking information of the model, as measured by proxy perplexity, to
detect the source of the text. We found that our method demonstrates impressive
detection performance while ensuring speed and security, particularly achieving
a recognition accuracy of 97.97\% for human-authored text. Furthermore, our
detection tool also shows promising results in identifying the large language
model (e.g., GPT-2, OPT, LLaMA, Vicuna...) responsible for the text. We release
the code and processed data at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A RelEntLess Benchmark for Modelling Graded Relations between Named  Entities</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15002</p>
  <p><b>作者</b>：Asahi Ushio,  Jose Camacho Collados,  Steven Schockaert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing Knowledge Graphs, rank entity pairs, entity pairs based, hard to draw, draw a line</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relations such as "is influenced by", "is known for" or "is a competitor of"
are inherently graded: we can rank entity pairs based on how well they satisfy
these relations, but it is hard to draw a line between those pairs that satisfy
them and those that do not. Such graded relations play a central role in many
applications, yet they are typically not covered by existing Knowledge Graphs.
In this paper, we consider the possibility of using Large Language Models
(LLMs) to fill this gap. To this end, we introduce a new benchmark, in which
entity pairs have to be ranked according to how much they satisfy a given
graded relation. The task is formulated as a few-shot ranking problem, where
models only have access to a description of the relation and five prototypical
instances. We use the proposed benchmark to evaluate state-of-the-art relation
embedding strategies as well as several recent LLMs, covering both publicly
available LLMs and closed models such as GPT-4. Overall, we find a strong
correlation between model size and performance, with smaller Language Models
struggling to outperform a naive baseline. The results of the largest Flan-T5
and OPT models are remarkably strong, although a clear gap with human
performance remains.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with  Recursive Thinking and Self-Questioning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14999</p>
  <p><b>作者</b>：Jingyuan Qi,  Zhiyang Xu,  Ying Shen,  Minqian Liu,  Di Jin,  Qifan Wang,  Lifu Huang</p>
  <p><b>备注</b>：15 pages, 12 figure, 2 algorithms</p>
  <p><b>关键词</b>：Socratic Questioning, enables large-scale language, language model, large-scale language models, thinking process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chain-of-Thought prompting (CoT) enables large-scale language models to solve
complex reasoning problems by decomposing the problem and tackling it
step-by-step. However, Chain-of-Thought is a greedy thinking process that
requires the language model to come up with a starting point and generate the
next step solely based on previous steps. This thinking process is different
from how humans approach a complex problem e.g., we proactively raise
sub-problems related to the original problem and recursively answer them. In
this work, we propose Socratic Questioning, a divide-and-conquer fashion
algorithm that simulates the self-questioning and recursive thinking process.
Socratic Questioning is driven by a Self-Questioning module that employs a
large-scale language model to propose sub-problems related to the original
problem as intermediate steps and Socratic Questioning recursively backtracks
and answers the sub-problems until reaches the original problem. We apply our
proposed algorithm to the visual question-answering task as a case study and by
evaluating it on three public benchmark datasets, we observe a significant
performance improvement over all baselines on (almost) all datasets. In
addition, the qualitative analysis clearly demonstrates the intermediate
thinking steps elicited by Socratic Questioning are similar to the human's
recursively thinking process of a complex reasoning problem.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14998</p>
  <p><b>作者</b>：Saba Ahmadi,  Aishwarya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：UMIC, Hessel, CLIPScore, human judgment, correlation with human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and
UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image
captions, demonstrating a high correlation with human judgment. In this work,
our focus lies in evaluating the robustness of these metrics in scenarios that
require distinguishing between two captions with high lexical overlap but very
different meanings. Our findings reveal that despite their high correlation
with human judgment, both CLIPScore and UMIC struggle to identify fine-grained
errors in captions. However, when comparing different types of fine-grained
errors, both metrics exhibit limited sensitivity to implausibility of captions
and strong sensitivity to lack of sufficient visual grounding. Probing further
into the visual grounding aspect, we found that both CLIPScore and UMIC are
impacted by the size of image-relevant objects mentioned in the caption, and
that CLIPScore is also sensitive to the number of mentions of image-relevant
objects in the caption. In terms of linguistic aspects of a caption, we found
that both metrics lack the ability to comprehend negation, UMIC is sensitive to
caption lengths, and CLIPScore is insensitive to the structure of the sentence.
We hope our findings will serve as a valuable guide towards improving
reference-free evaluation in image captioning.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：The ACL OCL Corpus: advancing Open science in Computational Linguistics</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14996</p>
  <p><b>作者</b>：Shaurya Rohatgi,  Yanxia Qin,  Benjamin Aw,  Niranjana Unnithan,  Min-Yen Kan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Computational Linguistics domain, ACL OCL, ACL Anthology, Anthology to assist, ACL OCL includes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a scholarly corpus from the ACL Anthology to assist Open
scientific research in the Computational Linguistics domain, named as ACL OCL.
Compared with previous ARC and AAN versions, ACL OCL includes structured
full-texts with logical sections, references to figures, and links to a large
knowledge resource (semantic scholar). ACL OCL contains 74k scientific papers,
together with 210k figures extracted up to September 2022. To observe the
development in the computational linguistics domain, we detect the topics of
all OCL papers with a supervised neural model. We observe ''Syntax: Tagging,
Chunking and Parsing'' topic is significantly shrinking and ''Natural Language
Generation'' is resurging. Our dataset is open and available to download from
HuggingFace in this https URL.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs  and for GPTs</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14994</p>
  <p><b>作者</b>：Dongjie Yang,  Ruifeng Yuan,  YuanTao Fan,  YiFei Yang,  Zili Wang,  Shushen Wang,  Hai Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tuning Large Language, Large Language Models, Large Language, NLP tasks, tuning Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>General chat models, like ChatGPT, have attained impressive capability to
resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with
high-quality instruction data. However, collecting human-written high-quality
data, especially multi-turn dialogues, is expensive and unattainable for most
people. Though previous studies have used powerful LLMs to generate the
dialogues automatically, but they all suffer from generating untruthful
dialogues because of the LLMs hallucination. Therefore, we propose a method
called RefGPT to generate enormous truthful and customized dialogues without
worrying about factual errors caused by the model hallucination. RefGPT solves
the model hallucination in dialogue generation by restricting the LLMs to
leverage the given reference instead of reciting their own knowledge to
generate dialogues. Additionally, RefGPT adds detailed controls on every
utterances to enable highly customization capability, which previous studies
have ignored. On the basis of RefGPT, we also propose two high-quality dialogue
datasets generated by GPT-4, namely RefGPT-Fact and RefGPT-Code. RefGPT-Fact is
100k multi-turn dialogue datasets based on factual knowledge and RefGPT-Code is
76k multi-turn dialogue dataset covering a wide range of coding scenarios. Our
code and datasets are released in this https URL</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：How To Control Text Simplification? An Empirical Study of Control Tokens  for Meaning Preserving Controlled Simplification</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14993</p>
  <p><b>作者</b>：Sweta Agrawal,  Marine Carpuat</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：specific audience, preserving its meaning, Text simplification rewrites, simplification rewrites text, control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text simplification rewrites text to be more readable for a specific
audience, while preserving its meaning. However, determining what makes a text
easy to read depends on who are the intended readers. Recent work has
introduced a wealth of techniques to control output simplicity, ranging from
specifying the desired reading grade level to providing control tokens that
directly encode low-level simplification edit operations. However, it remains
unclear how to set the input parameters that control simplification in
practice. Existing approaches set them at the corpus level, disregarding the
complexity of individual source text, and do not directly evaluate them at the
instance level. In this work, we conduct an empirical study to understand how
different control mechanisms impact the adequacy and simplicity of model
outputs. Based on these insights, we introduce a simple method for predicting
control tokens at the sentence level to enhance the quality of the simplified
text. Predicting control token values using features extracted from the
original complex text and a user-specified degree of complexity improves the
quality of the simplified outputs over corpus-level search-based heuristics.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Reasoning with Language Model is Planning with World Model</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14992</p>
  <p><b>作者</b>：Shibo Hao,  Yi Gu,  Haodi Ma,  Joshua Jiahua Hong,  Zhen Wang,  Daisy Zhe Wang,  Zhiting Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, remarkable reasoning capabilities, shown remarkable reasoning, reasoning, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable reasoning capabilities,
especially when prompted to generate intermediate reasoning steps (e.g.,
Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are
easy for humans, such as generating action plans for executing tasks in a given
environment, or performing complex math, logical, and commonsense reasoning.
The deficiency stems from the key fact that LLMs lack an internal
$\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment
status, intermediate variable values) and simulate long-term outcomes of
actions. This prevents LLMs from performing deliberate planning akin to human
brains, which involves exploring alternative reasoning paths, anticipating
future states and rewards, and iteratively refining existing reasoning steps.
To overcome the limitations, we propose a new LLM reasoning framework,
$\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$
$\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning
agent, and incorporates a principled planning algorithm (based on Monto Carlo
Tree Search) for strategic exploration in the vast reasoning space. During
reasoning, the LLM (as agent) incrementally builds a reasoning tree under the
guidance of the LLM (as world model) and task-specific rewards, and obtains a
high-reward reasoning path efficiently with a proper balance between
exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of
challenging reasoning problems including plan generation, math reasoning, and
logical inference. Empirical results on these tasks demonstrate the superiority
of RAP over various strong baselines, including CoT and least-to-most prompting
with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%
relative improvement in a plan generation setting.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：MuLER: Detailed and Scalable Reference-based Evaluation</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14991</p>
  <p><b>作者</b>：Taelin Karidi,  Leshem Choshen,  Gal Patel,  Omri Abend</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fine-grained analysis tool, text generation, machine translation, transforms any reference-based, reference-based evaluation metric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel methodology (namely, MuLER) that transforms any
reference-based evaluation metric for text generation, such as machine
translation (MT) into a fine-grained analysis tool.
Given a system and a metric, MuLER quantifies how much the chosen metric
penalizes specific error types (e.g., errors in translating names of
locations). MuLER thus enables a detailed error analysis which can lead to
targeted improvement efforts for specific phenomena.
We perform experiments in both synthetic and naturalistic settings to support
MuLER's validity and showcase its usability in MT evaluation, and other tasks,
such as summarization. Analyzing all submissions to WMT in 2014-2020, we find
consistent trends. For example, nouns and verbs are among the most frequent POS
tags. However, they are among the hardest to translate. Performance on most POS
tags improves with overall system performance, but a few are not thus
correlated (their identity changes from language to language). Preliminary
experiments with summarization reveal similar trends.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Dolphin: A Challenging and Diverse Benchmark for Arabic NLG</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14989</p>
  <p><b>作者</b>：El Moatez Billah Nagoudi,  Ahmed El-Shangiti,  AbdelRahim Elmadany,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：languages and varieties, evaluation framework, wide collection, Arabic languages, Arabic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Dolphin, a novel benchmark that addresses the need for an
evaluation framework for the wide collection of Arabic languages and varieties.
The proposed benchmark encompasses a broad range of 13 different NLG tasks,
including text summarization, machine translation, question answering, and
dialogue generation, among others. Dolphin comprises a substantial corpus of 40
diverse and representative public datasets across 50 test splits, carefully
curated to reflect real-world scenarios and the linguistic richness of Arabic.
It sets a new standard for evaluating the performance and generalization
capabilities of Arabic and multilingual models, promising to enable researchers
to push the boundaries of current methodologies. We provide an extensive
analysis of Dolphin, highlighting its diversity and identifying gaps in current
Arabic NLG research. We also evaluate several Arabic and multilingual models on
our benchmark, allowing us to set strong baselines against which researchers
can compare.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Large Language Models are Effective Table-to-Text Generators,  Evaluators, and Feedback Providers</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14987</p>
  <p><b>作者</b>：Yilun Zhao,  Haowei Zhang,  Shengyun Si,  Linyong Nan,  Xiangru Tang,  Arman Cohan</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：shown remarkable ability, Large language models, controllable text generation, shown remarkable, remarkable ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable ability on controllable
text generation. However, the potential of LLMs in generating text from
structured tables remains largely under-explored. In this paper, we study the
capabilities of LLMs for table-to-text generation tasks, particularly aiming to
investigate their performance in generating natural language statements that
can be logically entailed by a provided table. First, we investigate how LLMs
compare to state-of-the-art table-to-text fine-tuned models, and demonstrate
that LLMs can generate statements with higher faithfulness compared with
previous state-of-the-art fine-tuned models. Given this finding, we next
explore whether LLMs can serve as faithfulness-level automated evaluation
metrics. Through human evaluation, we show that evaluation metrics adopted from
LLMs correlates better with human judgments compared with existing
faithfulness-level metrics. Finally, we demonstrate that LLMs using
chain-of-thought prompting can generate high-fidelity natural language feedback
for other table-to-text models' generations, provide insights for future work
regarding the distillation of text generation capabilities from LLMs to smaller
models.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：IdealGPT: Iteratively Decomposing Vision and Language Reasoning via  Large Language Models</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14985</p>
  <p><b>作者</b>：Haoxuan You,  Rui Sun,  Zhecan Wang,  Long Chen,  Gengyu Wang,  Hammad A. Ayyubi,  Kai-Wei Chang,  Shih-Fu Chang</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：made unprecedented progress, understanding has made, made unprecedented, unprecedented progress, final answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of vision-and-language (VL) understanding has made unprecedented
progress with end-to-end large pre-trained VL models (VLMs). However, they
still fall short in zero-shot reasoning tasks that require multi-step
inferencing. To achieve this goal, previous works resort to a
divide-and-conquer pipeline. In this paper, we argue that previous efforts have
several inherent shortcomings: 1) They rely on domain-specific sub-question
decomposing models. 2) They force models to predict the final answer even if
the sub-questions or sub-answers provide insufficient information. We address
these limitations via IdealGPT, a framework that iteratively decomposes VL
reasoning using large language models (LLMs). Specifically, IdealGPT utilizes
an LLM to generate sub-questions, a VLM to provide corresponding sub-answers,
and another LLM to reason to achieve the final answer. These three modules
perform the divide-and-conquer procedure iteratively until the model is
confident about the final answer to the main question. We evaluate IdealGPT on
multiple challenging VL reasoning tasks under a zero-shot setting. In
particular, our IdealGPT outperforms the best existing GPT-4-like models by an
absolute 10% on VCR and 15% on SNLI-VE. Code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Benchmarking Arabic AI with Large Language Models</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14982</p>
  <p><b>作者</b>：Ahmed Abdelali,  Hamdy Mubarak,  Shammur Absar Chowdhury,  Maram Hasanain,  Basel Mousi,  Sabri Boughorbel,  Yassine El Kheir,  Daniel Izham,  Fahim Dalvi,  Majd Hawasly,  Nizi Nazar,  Yousseif Elshahawy,  Ahmed Ali,  Nadir Durrani,  Natasa Milic-Frayling,  Firoj Alam</p>
  <p><b>备注</b>：Foundation Models, Large Language Models, Arabic NLP, Arabic Speech, Arabic AI, , CHatGPT Evaluation, USM Evaluation, Whisper Evaluation</p>
  <p><b>关键词</b>：large Foundation Models, developing large-scale task-specific, large Foundation, Foundation Models, large-scale task-specific datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With large Foundation Models (FMs), language technologies (AI in general) are
entering a new paradigm: eliminating the need for developing large-scale
task-specific datasets and supporting a variety of tasks through set-ups
ranging from zero-shot to few-shot learning. However, understanding FMs
capabilities requires a systematic benchmarking effort by comparing FMs
performance with the state-of-the-art (SOTA) task-specific models. With that
goal, past work focused on the English language and included a few efforts with
multiple languages. Our study contributes to ongoing research by evaluating FMs
performance for standard Arabic NLP and Speech processing, including a range of
tasks from sequence tagging to content classification across diverse domains.
We start with zero-shot learning using GPT-3.5-turbo, Whisper, and USM,
addressing 33 unique tasks using 59 publicly available datasets resulting in 96
test setups. For a few tasks, FMs performs on par or exceeds the performance of
the SOTA models but for the majority it under-performs. Given the importance of
prompt for the FMs performance, we discuss our prompt strategies in detail and
elaborate on our findings. Our future work on Arabic AI will explore few-shot
prompting, expand the range of tasks, and investigate additional open-source
models.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Improving Factuality of Abstractive Summarization without Sacrificing  Summary Quality</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14981</p>
  <p><b>作者</b>：Tanay Dixit,  Fei Wang,  Muhao Chen</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：widely studied topic, Improving factual consistency, studied topic, consistency of abstractive, widely studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving factual consistency of abstractive summarization has been a widely
studied topic. However, most of the prior works on training factuality-aware
models have ignored the negative effect it has on summary quality. We propose
EFACTSUM (i.e., Effective Factual Summarization), a candidate summary
generation and ranking technique to improve summary factuality without
sacrificing summary quality. We show that using a contrastive learning
framework with our refined candidate summaries leads to significant gains on
both factuality and similarity-based metrics. Specifically, we propose a
ranking strategy in which we effectively combine two metrics, thereby
preventing any conflict during training. Models trained using our approach show
up to 6 points of absolute improvement over the base model with respect to
FactCC on XSUM and 11 points on CNN/DM, without negatively affecting either
similarity-based metrics or absractiveness.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14976</p>
  <p><b>作者</b>：Md Tawkat Islam Khondaker,  Abdul Waheed,  El Moatez Billah Nagoudi,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：recent emergence, brought a revolutionary, revolutionary change, Arabic NLP, Arabic NLP tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent emergence of ChatGPT has brought a revolutionary change in the
landscape of NLP. Although ChatGPT has consistently shown impressive
performance on English benchmarks, its exact capabilities on most other
languages remain largely unknown. To better understand ChatGPT's capabilities
on Arabic, we present a large-scale evaluation of the model on a broad range of
Arabic NLP tasks. Namely, we evaluate ChatGPT on 32 diverse natural language
understanding and generation tasks on over 60 different datasets. To the best
of our knowledge, our work offers the first performance analysis of ChatGPT on
Arabic NLP at such a massive scale. Our results show that, despite its success
on English benchmarks, ChatGPT trained in-context (few-shot) is consistently
outperformed by much smaller dedicated models finetuned on Arabic. These
results suggest that there is significant place for improvement for
instruction-tuned LLMs such as ChatGPT.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence  Scores from Language Models Fine-Tuned with Human Feedback</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14975</p>
  <p><b>作者</b>：Katherine Tian,  Eric Mitchell,  Allan Zhou,  Archit Sharma,  Rafael Rafailov,  Huaxiu Yao,  Chelsea Finn,  Christopher D. Manning</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trustworthy real-world prediction, real-world prediction system, answer is correct, answer is indicative, trustworthy real-world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A trustworthy real-world prediction system should be well-calibrated; that
is, its confidence in an answer is indicative of the likelihood that the answer
is correct, enabling deferral to a more expensive expert in cases of
low-confidence predictions. While recent studies have shown that unsupervised
pre-training produces large language models (LMs) that are remarkably
well-calibrated, the most widely-used LMs in practice are fine-tuned with
reinforcement learning with human feedback (RLHF-LMs) after the initial
unsupervised pre-training stage, and results are mixed as to whether these
models preserve the well-calibratedness of their ancestors. In this paper, we
conduct a broad evaluation of computationally feasible methods for extracting
confidence scores from LLMs fine-tuned with RLHF. We find that with the right
prompting strategy, RLHF-LMs verbalize probabilities that are much better
calibrated than the model's conditional probabilities, enabling fairly
well-calibrated predictions. Through a combination of prompting strategy and
temperature scaling, we find that we can reduce the expected calibration error
of RLHF-LMs by over 50%.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：OverPrompt: Enhancing ChatGPT Capabilities through an Efficient  In-Context Learning Approach</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14973</p>
  <p><b>作者</b>：Jiazheng Li,  Runcong Zhao,  Yulan He,  Lin Gui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：utilising long prompts, pre-trained large language, large language models, revolutionised various applications, costs and inefficiencies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The exceptional performance of pre-trained large language models has
revolutionised various applications, but their adoption in production
environments is hindered by prohibitive costs and inefficiencies, particularly
when utilising long prompts. This paper proposes OverPrompt, an in-context
learning method aimed at improving LLM efficiency and performance by processing
multiple inputs in parallel. Evaluated across diverse datasets, OverPrompt
enhances task efficiency and integrates a diverse range of examples for
improved performance. Particularly, it amplifies fact-checking and sentiment
analysis tasks when supplemented with contextual information. Synthetic data
grouping further enhances performance, suggesting a viable approach for data
augmentation.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge  Conflicts in Event Temporal Reasoning</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14970</p>
  <p><b>作者</b>：Tianqing Fang,  Zhaowei Wang,  Wenxuan Zhou,  Hongming Zhang,  Yangqiu Song,  Muhao Chen</p>
  <p><b>备注</b>：13 pages, 1 figure</p>
  <p><b>关键词</b>：Event temporal reasoning, temporal reasoning aims, Event temporal, temporal reasoning, aims at identifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event temporal reasoning aims at identifying the temporal relations between
two or more events. However, knowledge conflicts arise when there is a mismatch
between the actual temporal relations of events in the context and the prior
knowledge or biases learned by the model. We first systematically define
distinct kinds of bias in event temporal reasoning, which include event
relation prior bias, tense bias, narrative bias, and dependency bias, as
indicators to study knowledge conflicts. To mitigate such event-related
knowledge conflict, we introduce a Counterfactual Data Augmentation based
method that can be applied to both Pre-trained Language Models (PLMs) and Large
Language Models (LLMs) either as additional training data or demonstrations for
In-Context Learning. Experiments suggest the importance of mitigating knowledge
conflicts in event temporal reasoning tasks for reducing hallucination and
highlight the potential of counterfactual data augmentation for improving model
performance.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Tricking LLMs into Disobedience: Understanding, Analyzing, and  Preventing Jailbreaks</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14965</p>
  <p><b>作者</b>：Abhinav Rao,  Sachin Vashistha,  Atharva Naik,  Somak Aditya,  Monojit Choudhury</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, commercial Large Language, degenerate output behavior, content regulator policies, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent explorations with commercial Large Language Models (LLMs) have shown
that non-expert users can jailbreak LLMs by simply manipulating the prompts;
resulting in degenerate output behavior, privacy and security breaches,
offensive outputs, and violations of content regulator policies. Limited formal
studies have been carried out to formalize and analyze these attacks and their
mitigations. We bridge this gap by proposing a formalism and a taxonomy of
known (and possible) jailbreaks. We perform a survey of existing jailbreak
methods and their effectiveness on open-source and commercial LLMs (such as GPT
3.5, OPT, BLOOM, and FLAN-T5-xxl). We further propose a limited set of prompt
guards and discuss their effectiveness against known attack types.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Detecting and Characterizing Political Incivility on Social Media</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14964</p>
  <p><b>作者</b>：Sagi Penzel,  Nir Lotan,  Alon Zoizner,  Einat Minkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：political incivility, political communication study, political incivility detection, impact and perceptions, political</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Researchers of political communication study the impact and perceptions of
political incivility on social media. Yet, so far, relatively few works
attempted to automatically detect and characterize political incivility. In our
work, we study political incivility in Twitter, presenting several research
contributions. First, we present state-of-the-art incivility detection results
using a large dataset, which we collected and labeled via crowd sourcing.
Importantly, we distinguish between uncivil political speech that is impolite
and intolerant anti-democratic discourse. Applying political incivility
detection at large-scale, we derive insights regarding the prevalence of this
phenomenon across users, and explore the network characteristics of users who
are susceptible to disseminating uncivil political content online. Finally, we
propose an approach for modeling social context information about the tweet
author alongside the tweet content, showing that this leads to significantly
improved performance on the task of political incivility detection. This result
holds promise for related tasks, such as hate speech and stance detection.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text  Classification</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14963</p>
  <p><b>作者</b>：Yau-Shian Wang,  Ta-Chung Chi,  Ruohong Zhang,  Yiming Yang</p>
  <p><b>备注</b>：accepted by ACL 2023</p>
  <p><b>关键词</b>：contrastive learning framework, zero-shot text classification, text classification, contrastive learning, framework that substantially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present PESCO, a novel contrastive learning framework that substantially
improves the performance of zero-shot text classification. We formulate text
classification as a neural text matching problem where each document is treated
as a query, and the system learns the mapping from each query to the relevant
class labels by (1) adding prompts to enhance label matching, and (2) using
retrieved labels to enrich the training set in a self-training loop of
contrastive learning. PESCO achieves state-of-the-art performance on four
benchmark text classification datasets. On DBpedia, we achieve 98.5\% accuracy
without any labeled data, which is close to the fully-supervised result.
Extensive experiments and analyses show all the components of PESCO are
necessary for improving the performance of zero-shot text classification.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Editing Commonsense Knowledge in GPT</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14956</p>
  <p><b>作者</b>：Anshita Gupta,  Debanjan Mondal,  Akshay Krishna Sheshadri,  Wenlong Zhao,  Xiang Lorraine Li,  Sarah Wiegreffe,  Niket Tandon</p>
  <p><b>备注</b>：Code and data is available at this https URL</p>
  <p><b>关键词</b>：received increasing attention, updating encyclopedic knowledge, Memory editing methods, updating encyclopedic, transformers have received</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Memory editing methods for updating encyclopedic knowledge in transformers
have received increasing attention for their efficacy, specificity, and
generalization advantages. However, it remains unclear if such methods can be
adapted for the more nuanced domain of commonsense knowledge. We propose
$MEMIT_{CSK}$, an adaptation of MEMIT to edit commonsense mistakes in GPT-2
Large and XL. We extend editing to various token locations and employ a robust
layer selection strategy. Models edited by $MEMIT_{CSK}$ outperforms the
fine-tuning baselines by 10.97% and 10.73% F1 scores on subsets of PEP3k and
20Q. We further propose a novel evaluation dataset, MEMIT-CSK-PROBE, that
contains unaffected neighborhood, affected neighborhood, affected paraphrase,
and affected reasoning challenges. $MEMIT_{CSK}$ demonstrates favorable
semantic generalization, outperforming fine-tuning baselines by 13.72% and
5.57% overall scores on MEMIT-CSK-PROBE. These results suggest a compelling
future direction of incorporating context-specific user feedback concerning
commonsense in GPT by direct model editing, rectifying and customizing model
behaviors via human-in-the-loop systems.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Adversarial Demonstration Attacks on Large Language Models</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14950</p>
  <p><b>作者</b>：Jiongxiao Wang,  Zichen Liu,  Keun Hee Park,  Muhao Chen,  Chaowei Xiao</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：powerful large language, large language models, powerful large, large language, ICL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the emergence of more powerful large language models (LLMs), such as
ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence
in leveraging these models for specific tasks by utilizing data-label pairs as
precondition prompts. While incorporating demonstrations can greatly enhance
the performance of LLMs across various tasks, it may introduce a new security
concern: attackers can manipulate only the demonstrations without changing the
input to perform an attack. In this paper, we investigate the security concern
of ICL from an adversarial perspective, focusing on the impact of
demonstrations. We propose an ICL attack based on TextAttack, which aims to
only manipulate the demonstration without changing the input to mislead the
models. Our results demonstrate that as the number of demonstrations increases,
the robustness of in-context learning would decreases. Furthermore, we also
observe that adversarially attacked demonstrations exhibit transferability to
diverse input examples. These findings emphasize the critical security risks
associated with ICL and underscore the necessity for extensive research on the
robustness of ICL, particularly given its increasing significance in the
advancement of LLMs.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Cross-lingual Data Augmentation for Document-grounded Dialog Systems in  Low Resource Languages</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14949</p>
  <p><b>作者</b>：Qi Gou,  Zehua Xia,  Wenzhe Du</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Document-Grounded Dialogue Systems, framework to address, address the issue, issue of data, Dialogue Systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a framework to address the issue of data scarcity in
Document-Grounded Dialogue Systems(DGDS). Our model leverages high-resource
languages to enhance the capability of dialogue generation in low-resource
languages. Specifically, We present a novel pipeline CLEM (Cross-Lingual
Enhanced Model) including adversarial training retrieval (Retriever and
Re-ranker), and Fid (fusion-in-decoder) generator. To further leverage
high-resource language, we also propose an innovative architecture to conduct
alignment across different languages with translated training. Extensive
experiment results demonstrate the effectiveness of our model and we achieved
4th place in the DialDoc 2023 Competition. Therefore, CLEM can serve as a
solution to resource scarcity in DGDS and provide useful guidance for
multi-lingual alignment tasks.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：How Predictable Are Large Language Model Capabilities? A Case Study on  BIG-bench</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14947</p>
  <p><b>作者</b>：Qinyuan Ye,  Harvey Yiyun Fu,  Xiang Ren,  Robin Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurately predict LLM, predict LLM performance, large language model, numbers of parameters, numbers of in-context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the predictability of large language model (LLM) capabilities:
given records of past experiments using different model families, numbers of
parameters, tasks, and numbers of in-context examples, can we accurately
predict LLM performance on new experiment configurations? Answering this
question has practical implications for LLM users (e.g., deciding which models
to try), developers (e.g., prioritizing evaluation on representative tasks),
and the research community (e.g., identifying hard-to-predict capabilities that
warrant further investigation).
We study the performance prediction problem on experiment records from
BIG-bench. On a random train-test split, an MLP-based predictor achieves RMSE
below 5%, demonstrating the presence of learnable patterns within the
experiment records. Further, we formulate the problem of searching for
"small-bench," an informative subset of BIG-bench tasks from which the
performance of the full set can be maximally recovered, and find a subset as
informative for evaluating new model families as BIG-bench Hard, while being 3x
smaller.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large  Language Models with SocKET Benchmark</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14938</p>
  <p><b>作者</b>：Minje Choi,  Jiaxin Pei,  Sagar Kumar,  Chang Shu,  David Jurgens</p>
  <p><b>备注</b>：24 pages, 7 tables, 5 figures</p>
  <p><b>关键词</b>：variety of syntactic, shown to perform, Large language, LLMs, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have been shown to perform well at a variety of
syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed
in many forms including conversational agents that interact with humans, we
lack a grounded benchmark to measure how well LLMs understand \textit{social}
language. Here, we introduce a new theory-driven benchmark, SocKET, that
contains 58 NLP tasks testing social knowledge which we group into five
categories: humor & sarcasm, offensiveness, sentiment & emotion, and
trustworthiness. In tests on the benchmark, we demonstrate that current models
attain only moderate performance but reveal significant potential for task
transfer among different types and categories of tasks, which were predicted
from theory. Through zero-shot evaluations, we show that pretrained models
already possess some innate but limited capabilities of social language
understanding and training on one category of tasks can improve zero-shot
testing on others. Our benchmark provides a systematic way to analyze model
performance on an important dimension of language and points to clear room for
improvement to build more socially-aware LLMs. The associated resources are
released at this https URL.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking  Systems</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14937</p>
  <p><b>作者</b>：Hannah Bast,  Matthias Hertel,  Natalie Prange</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：entity linking systems, linking systems, entity linking, entity, benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing evaluations of entity linking systems often say little about how the
system is going to perform for a particular application. There are four
fundamental reasons for this: many benchmarks focus on named entities; it is
hard to define which other entities to include; there are ambiguities in entity
recognition and entity linking; many benchmarks have errors or artifacts that
invite overfitting or lead to evaluation results of limited meaningfulness.
We provide a more meaningful and fair in-depth evaluation of a variety of
existing end-to-end entity linkers. We characterize the strengths and
weaknesses of these linkers and how well the results from the respective
publications can be reproduced. Our evaluation is based on several widely used
benchmarks, which exhibit the problems mentioned above to various degrees, as
well as on two new benchmarks, which address these problems.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Trade-Offs Between Fairness and Privacy in Language Modeling</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14936</p>
  <p><b>作者</b>：Cleo Matzken,  Steffen Eger,  Ivan Habernal</p>
  <p><b>备注</b>：Findings of ACL 2023</p>
  <p><b>关键词</b>：contemporary NLP models, contemporary NLP, gaining in importance, NLP models, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Protecting privacy in contemporary NLP models is gaining in importance. So
does the need to mitigate social biases of such models. But can we have both at
the same time? Existing research suggests that privacy preservation comes at
the price of worsening biases in classification tasks. In this paper, we
explore the extent to which this tradeoff really holds when we incorporate both
privacy preservation and de-biasing techniques into training text generation
models. How does improving the model along one dimension affect the other
dimension as well as the utility of the model? We conduct an extensive set of
experiments that include bias detection, privacy attacks, language modeling,
and performance on downstream tasks.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Modeling Appropriate Language in Argumentation</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14935</p>
  <p><b>作者</b>：Timon Ziegenbein,  Shahbaz Syed,  Felix Lange,  Martin Potthast,  Henning Wachsmuth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make ad-hoc decisions, maintain civility, moderators must make, make ad-hoc, removed to maintain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online discussion moderators must make ad-hoc decisions about whether the
contributions of discussion participants are appropriate or should be removed
to maintain civility. Existing research on offensive language and the resulting
tools cover only one aspect among many involved in such decisions. The question
of what is considered appropriate in a controversial discussion has not yet
been systematically addressed. In this paper, we operationalize appropriate
language in argumentation for the first time. In particular, we model
appropriateness through the absence of flaws, grounded in research on argument
quality assessment, especially in aspects from rhetoric. From these, we derive
a new taxonomy of 14 dimensions that determine inappropriate language in online
discussions. Building on three argument quality corpora, we then create a
corpus of 2191 arguments annotated for the 14 dimensions. Empirical analyses
support that the taxonomy covers the concept of appropriateness
comprehensively, showing several plausible correlations with argument quality
dimensions. Moreover, results of baseline approaches to assessing
appropriateness suggest that all dimensions can be modeled computationally on
the corpus.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Discriminator-Guided Multi-step Reasoning with Language Models</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14934</p>
  <p><b>作者</b>：Muhammad Khalifa,  Lajanugen Logeswaran,  Moontae Lee,  Honglak Lee,  Lu Wang</p>
  <p><b>备注</b>：19 pages, 7 figures, and 8 tables</p>
  <p><b>关键词</b>：high probabilities, GRACE, probabilities, reasoning, decoding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of multi-step reasoning, language models (LMs) probabilities
are often miscalibrated -- solutions with high probabilities are not always
correct. Therefore, greedy decoding, which is the standard decoding method for
reasoning tasks, often yields incorrect solutions. In addition, methods such as
self-consistency and verifiers rely on sampling from the LM distribution and do
not tackle the underlying issue. To address this, we introduce Guiding
Multi-step ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise
decoding approach that nudges the model towards producing correct reasoning
steps. GRACE employs a discriminator model, which is trained to differentiate
correct steps from invalid ones, to adjust decoding preferences based on the
correctness of each reasoning step. Importantly, GRACE does not require
fine-tuning or re-training the LMs. When compared with conventional decoding
strategies over four popular math reasoning benchmarks, GRACE exhibits
significant improvements in both final answer accuracy and step correctness,
outperforming both greedy decoding and self-consistency.\footnote{Our code can
be found at \url{this https URL.}}</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：In-Context Impersonation Reveals Large Language Models' Strengths and  Biases</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14930</p>
  <p><b>作者</b>：Leonard Salewski,  Stephan Alaniz,  Isabel Rio-Torto,  Eric Schulz,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：everyday conversations, adapt their vocabulary, LLMs, chosen roles, roles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Aligning Language Models to User Opinions</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14929</p>
  <p><b>作者</b>：EunJeong Hwang,  Bodhisattwa Prasad Majumder,  Niket Tandon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：align models' behavior, important aspect, aspect of developing, interact with humans, models' behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An important aspect of developing LLMs that interact with humans is to align
models' behavior to their users. It is possible to prompt an LLM into behaving
as a certain persona, especially a user group or ideological persona the model
captured during its pertaining stage. But, how to best align an LLM with a
specific user and not a demographic or ideological group remains an open
question. Mining public opinion surveys (by Pew Research), we find that the
opinions of a user and their demographics and ideologies are not mutual
predictors. We use this insight to align LLMs by modeling both user opinions as
well as user demographics and ideology, achieving up to 7 points accuracy gains
in predicting public opinions from survey questions across a broad set of
topics. In addition to the typical approach of prompting LLMs with demographics
and ideology, we discover that utilizing the most relevant past opinions from
individual users enables the model to predict user opinions more accurately.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Towards Reliable Misinformation Mitigation: Generalization, Uncertainty,  and GPT-4</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14928</p>
  <p><b>作者</b>：Kellin Pelrine,  Meilina Reksoprodjo,  Caleb Gupta,  Joel Christoph,  Reihaneh Rabbany</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical societal challenge, societal challenge, effective solution, current approaches, produce an effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Misinformation poses a critical societal challenge, and current approaches
have yet to produce an effective solution. We propose focusing on
generalization, soft classification, and leveraging recent large language
models to create more practical tools in contexts where perfect predictions
remain unattainable. We begin by demonstrating that GPT-4 and other language
models can outperform existing methods in the literature. Next, we explore
their generalization, revealing that GPT-4 and RoBERTa-large exhibit critical
differences in failure modes, which offer potential for significant performance
improvements. Finally, we show that these models can be employed in soft
classification frameworks to better quantify uncertainty. We find that models
with inferior hard classification results can achieve superior soft
classification performance. Overall, this research lays groundwork for future
tools that can drive real-world progress on misinformation.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Universal Self-adaptive Prompting</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14926</p>
  <p><b>作者</b>：Xingchen Wan,  Ruoxi Sun,  Hootan Nakhost,  Hanjun Dai,  Julian Martin Eisenschlos,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：10 pages, 3 figures, 4 tables (19 pages, 5 figures and 9 tables including references and appendices)</p>
  <p><b>关键词</b>：modern large language, impressive general zero-shot, automatic prompt design, hallmark of modern, modern large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A hallmark of modern large language models (LLMs) is their impressive general
zero-shot and few-shot abilities, often elicited through prompt-based and/or
in-context learning. However, while highly coveted and being the most general,
zero-shot performances in LLMs are still typically weaker due to the lack of
guidance and the difficulty of applying existing automatic prompt design
methods in general tasks when ground-truth labels are unavailable. In this
study, we address this by presenting Universal Self-adaptive Prompting (USP),
an automatic prompt design approach specifically tailored for zero-shot
learning (while compatible with few-shot). Requiring only a small amount of
unlabeled data & an inference-only LLM, USP is highly versatile: to achieve
universal prompting, USP categorizes a possible NLP task into one of the three
possible task types, and then uses a corresponding selector to select the most
suitable queries & zero-shot model-generated responses as
pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a
fully automated way. We evaluate zero-shot USP with two PaLM models, and
demonstrate performances that are considerably stronger than standard zero-shot
baselines and are comparable to or even superior than few-shot baselines across
more than 20 natural language understanding (NLU) and natural language
generation (NLG) tasks.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Frugal Prompting for Dialog Models</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14919</p>
  <p><b>作者</b>：Bishal Santra,  Sakya Basak,  Abhinandan De,  Manish Gupta,  Pawan Goyal</p>
  <p><b>备注</b>：First two authors have equal contribution</p>
  <p><b>关键词</b>：natural language processing, researchers approach problems, large language models, language processing, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of large language models (LLMs) in natural language processing (NLP)
tasks is rapidly increasing, leading to changes in how researchers approach
problems in the field. To fully utilize these models' abilities, a better
understanding of their behavior for different input protocols is required. With
LLMs, users can directly interact with the models through a text-based
interface to define and solve various tasks. Hence, understanding the
conversational abilities of these LLMs, which may not have been specifically
trained for dialog modeling, is also important. This study examines different
approaches for building dialog systems using LLMs by considering various
aspects of the prompt. As part of prompt tuning, we experiment with various
ways of providing instructions, exemplars, current query and additional
context. The research also analyzes the representations of dialog history that
have the optimal usable-information density. Based on the findings, the paper
suggests more compact ways of providing dialog history information while
ensuring good performance and reducing model's inference-API costs. The
research contributes to a better understanding of how LLMs can be effectively
used for building interactive systems.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Structural Ambiguity and its Disambiguation in Language Model Based  Parsers: the Case of Dutch Clause Relativization</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14917</p>
  <p><b>作者</b>：Gijs Wijnholds,  Michael Moortgat</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dutch relative clauses, paper addresses structural, addresses structural ambiguity, ambiguity in Dutch, Dutch relative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses structural ambiguity in Dutch relative clauses. By
investigating the task of disambiguation by grounding, we study how the
presence of a prior sentence can resolve relative clause ambiguities. We apply
this method to two parsing architectures in an attempt to demystify the parsing
and language model components of two present-day neural parsers. Results show
that a neurosymbolic parser, based on proof nets, is more open to data bias
correction than an approach based on universal dependencies, although both
setups suffer from a comparable initial data bias.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual  Named Entity Recognition</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14913</p>
  <p><b>作者</b>：Tingting Ma,  Qianhui Wu,  Huiqiang Jiang,  Börje F. Karlsson,  Tiejun Zhao,  Chin-Yew Lin</p>
  <p><b>备注</b>：ACL 2023. Our code is available at this https URL</p>
  <p><b>关键词</b>：Cross-lingual named entity, named entity recognition, NER system, leveraging labeled data, Cross-lingual named</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-lingual named entity recognition (NER) aims to train an NER system that
generalizes well to a target language by leveraging labeled data in a given
source language. Previous work alleviates the data scarcity problem by
translating source-language labeled data or performing knowledge distillation
on target-language unlabeled data. However, these methods may suffer from label
noise due to the automatic labeling process. In this paper, we propose CoLaDa,
a Collaborative Label Denoising Framework, to address this problem.
Specifically, we first explore a model-collaboration-based denoising scheme
that enables models trained on different data sources to collaboratively
denoise pseudo labels used by each other. We then present an
instance-collaboration-based strategy that considers the label consistency of
each token's neighborhood in the representation space for denoising.
Experiments on different benchmark datasets show that the proposed CoLaDa
achieves superior results compared to previous methods, especially when
generalizing to distant languages.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：From Shortcuts to Triggers: Backdoor Defense with Denoised PoE</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14910</p>
  <p><b>作者</b>：Qin Liu,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：backdoor attacks, backdoor, data poisoning, attacks, diverse backdoor attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models are often at risk of diverse backdoor attacks, especially
data poisoning. Thus, it is important to investigate defense solutions for
addressing them. Existing backdoor defense methods mainly focus on backdoor
attacks with explicit triggers, leaving a universal defense against various
backdoor attacks with diverse triggers largely unexplored. In this paper, we
propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised
Product-of-Experts), which is inspired by the shortcut nature of backdoor
attacks, to defend various backdoor attacks. DPoE consists of two models: a
shallow model that captures the backdoor shortcuts and a main model that is
prevented from learning the backdoor shortcuts. To address the label flip
caused by backdoor attackers, DPoE incorporates a denoising design. Experiments
on SST-2 dataset show that DPoE significantly improves the defense performance
against various types of backdoor triggers including word-level,
sentence-level, and syntactic triggers. Furthermore, DPoE is also effective
under a more challenging but practical setting that mixes multiple types of
trigger.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：PURR: Efficiently Editing Language Model Hallucinations by Denoising  Language Model Corruptions</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14908</p>
  <p><b>作者</b>：Anthony Chen,  Panupong Pasupat,  Sameer Singh,  Hongrae Lee,  Kelvin Guu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsubstantiated claims commonly, large language models, language models, large language, persistent drawback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The remarkable capabilities of large language models have been accompanied by
a persistent drawback: the generation of false and unsubstantiated claims
commonly known as "hallucinations". To combat this issue, recent research has
introduced approaches that involve editing and attributing the outputs of
language models, particularly through prompt-based editing. However, the
inference cost and speed of using large language models for editing currently
bottleneck prompt-based methods. These bottlenecks motivate the training of
compact editors, which is challenging due to the scarcity of training data for
this purpose. To overcome these challenges, we exploit the power of large
language models to introduce corruptions (i.e., noise) into text and
subsequently fine-tune compact editors to denoise the corruptions by
incorporating relevant evidence. Our methodology is entirely unsupervised and
provides us with faux hallucinations for training in any domain. Our Petite
Unsupervised Research and Revision model, PURR, not only improves attribution
over existing editing methods based on fine-tuning and prompting, but also
achieves faster execution times by orders of magnitude.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Coverage-based Example Selection for In-Context Learning</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14907</p>
  <p><b>作者</b>：Shivanshu Gupta,  Sameer Singh,  Matt Gardner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, In-context learning, ability of large, large language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In-context learning (ICL), the ability of large language models to perform
novel tasks by conditioning on a prompt with a few task examples, requires
demonstrations that are informative about the test instance. The standard
approach of independently selecting the most similar examples selects redundant
demonstrations while overlooking important information. This work proposes a
framework for assessing the informativeness of demonstrations based on their
coverage of salient aspects (e.g., reasoning patterns) of the test input. Using
this framework, we show that contextual token embeddings effectively capture
these salient aspects, and their recall measured using BERTScore-Recall (BSR)
yields a reliable measure of informativeness. Further, we extend recall metrics
like BSR to propose their set versions to find maximally informative sets of
demonstrations. On 6 complex compositional generation tasks and 7 diverse LLMs,
we show that Set-BSR outperforms the standard similarity-based approach by up
to 16% on average and, despite being learning-free, often surpasses methods
that leverage task or LLM-specific training.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Identifying Informational Sources in News Articles</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14904</p>
  <p><b>作者</b>：Alexander Spangher,  Nanyun Peng,  Jonathan May,  Emilio Ferrara</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：informational sources, sources, informational sources journalists, journalists, articles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>News articles are driven by the informational sources journalists use in
reporting. Modeling when, how and why sources get used together in stories can
help us better understand the information we consume and even help journalists
with the task of producing it. In this work, we take steps toward this goal by
constructing the largest and widest-ranging annotated dataset, to date, of
informational sources used in news writing. We show that our dataset can be
used to train high-performing models for information detection and source
attribution. We further introduce a novel task, source prediction, to study the
compositionality of sources in news articles. We show good performance on this
task, which we argue is an important proof for narrative science exploring the
internal structure of news articles and aiding in planning-based language
generation, and an important step towards a source-recommendation system to aid
journalists.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box  Machine-Generated Text Detection</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14902</p>
  <p><b>作者</b>：Yuxia Wang,  Jonibek Mansurov,  Petar Ivanov,  Jinyan Su,  Artem Shelmanov,  Akim Tsvigun,  Chenxi Whitehouse,  Osama Mohammed Afzal,  Tarek Mahmoud,  Alham Fikri Aji,  Preslav Nakov</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：demonstrated remarkable capability, generate fluent responses, user queries, academic context, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable capability to
generate fluent responses to a wide variety of user queries, but this has also
resulted in concerns regarding the potential misuse of such texts in
journalism, educational, and academic context. In this work, we aim to develop
automatic systems to identify machine-generated text and to detect potential
misuse. We first introduce a large-scale benchmark M4, which is
multi-generator, multi-domain, and multi-lingual corpus for machine-generated
text detection. Using the dataset, we experiment with a number of methods and
we show that it is challenging for detectors to generalize well on unseen
examples if they are either from different domains or are generated by
different large language models. In such cases, detectors tend to misclassify
machine-generated text as human-written. These results show that the problem is
far from solved and there is a lot of room for improvement. We believe that our
dataset M4, which covers different generators, domains and languages, will
enable future research towards more robust approaches for this pressing
societal problem. The M4 dataset is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Chain-of-Questions Training with Latent Answers for Robust Multistep  Question Answering</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14901</p>
  <p><b>作者</b>：Wang Zhu,  Jesse Thomason,  Robin Jia</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：robustly answer multistep, answer multistep questions, generating and answering, train a language, language model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We train a language model (LM) to robustly answer multistep questions by
generating and answering sub-questions. We propose Chain-of-Questions, a
framework that trains a model to generate sub-questions and sub-answers one at
a time by leveraging human annotated question decomposition meaning
representation (QDMR). The key technical challenge is that QDMR only contains
sub-questions but not answers to those sub-questions, so we treat sub-answers
as latent variables and optimize them using a novel dynamic mixture of Hard-EM
and MAPO. Chain-of-Questions greatly outperforms strong neuro-symbolic methods
by 9.0 F1 on DROP contrast set, and outperforms GPT-3.5 by 24.3 F1 on HOTPOTQA
adversarial set, thus demonstrating the effectiveness and robustness of our
framework.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：PIVOINE: Instruction Tuning for Open-world Information Extraction</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14898</p>
  <p><b>作者</b>：Keming Lu,  Xiaoman Pan,  Kaiqiang Song,  Hongming Zhang,  Dong Yu,  Jianshu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Open-world Information Extraction, Information Extraction, Open-world, unstructured texts, Open-world Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of Open-world Information Extraction (Open-world IE),
which extracts comprehensive entity profiles from unstructured texts. Different
from the conventional closed-world setting of Information Extraction (IE),
Open-world IE considers a more general situation where entities and relations
could be beyond a predefined ontology. More importantly, we seek to develop a
large language model (LLM) that is able to perform Open-world IE to extract
desirable entity profiles characterized by (possibly fine-grained) natural
language instructions. We achieve this by finetuning LLMs using instruction
tuning. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction
tuning dataset for Open-world IE enriched with a comprehensive corpus,
extensive annotations, and diverse instructions. We finetune the pretrained
BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world IE
with strong instruction-following capabilities. Our experiments demonstrate
that PIVOINE significantly outperforms traditional closed-world methods and
other LLM baselines, displaying impressive generalization capabilities on both
unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as
a promising solution to tackle the open-world challenge in IE effectively.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Text encoders are performance bottlenecks in contrastive vision-language  models</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14897</p>
  <p><b>作者</b>：Amita Kamath,  Jack Hessel,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Performant vision-language, CLIP represent captions, CLIP represent, single vector, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Performant vision-language (VL) models like CLIP represent captions using a
single vector. How much information about language is lost in this bottleneck?
We first curate CompPrompts, a set of increasingly compositional image captions
that VL models should be able to capture (e.g., single object, to
object+property, to multiple interacting objects). Then, we train text-only
recovery probes that aim to reconstruct captions from single-vector text
representations produced by several VL models. This approach doesn't require
images, allowing us to test on a broader range of scenes compared to prior
work. We find that: 1) CLIP's text encoder falls short on object relationships,
attribute-object association, counting, and negations; 2) some text encoders
work significantly better than others; and 3) text-only recovery performance
predicts multi-modal matching performance on ControlledImCaps: a new evaluation
benchmark we collect+release consisting of fine-grained compositional
images+captions. Specifically -- our results suggest text-only recoverability
is a necessary (but not sufficient) condition for modeling compositional
factors in contrastive vision+language models. We release data+code.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Extracting Psychological Indicators Using Question Answering</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14891</p>
  <p><b>作者</b>：Luka Pavlović</p>
  <p><b>备注</b>：4 pages, 0 figures</p>
  <p><b>关键词</b>：extracting text spans, psychological traits, asked question, propose a method, method for extracting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a method for extracting text spans that may indicate
one of the BIG5 psychological traits using a question-answering task with
examples that have no answer for the asked question. We utilized the RoBERTa
model fine-tuned on SQuAD 2.0 dataset. The model was further fine-tuned
utilizing comments from Reddit. We examined the effect of the percentage of
examples with no answer in the training dataset on the overall performance. The
results obtained in this study are in line with the SQuAD 2.0 benchmark and
present a good baseline for further research.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Evaluating NLG Evaluation Metrics: A Measurement Theory Perspective</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14889</p>
  <p><b>作者</b>：Ziang Xiao,  Susu Zhang,  Vivian Lai,  Q. Vera Liao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Generation, Language Generation, Natural Language, challenge in Natural, NLG evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the fundamental challenge in Natural Language Generation (NLG)
model evaluation, the design and validation of evaluation metrics. Recognizing
the limitations of existing metrics and issues with human judgment, we propose
using measurement theory, the foundation of test design, as a framework for
conceptualizing and evaluating the validity and reliability of NLG evaluation
metrics. This approach offers a systematic method for defining "good" metrics,
developing robust metrics, and assessing metric performance. In this paper, we
introduce core concepts in measurement theory in the context of NLG evaluation
and key methods to evaluate the performance of NLG metrics. Through this
framework, we aim to promote the design, evaluation, and interpretation of
valid and reliable metrics, ultimately contributing to the advancement of
robust and effective NLG models in real-world settings.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Privacy Implications of Retrieval-Based Language Models</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14888</p>
  <p><b>作者</b>：Yangsibo Huang,  Samyak Gupta,  Zexuan Zhong,  Kai Li,  Danqi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated improved interpretability, incorporating retrieved text, Retrieval-based language models, improved interpretability, demonstrated improved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval-based language models (LMs) have demonstrated improved
interpretability, factuality, and adaptability compared to their parametric
counterparts, by incorporating retrieved text from external datastores. While
it is well known that parametric models are prone to leaking private data, it
remains unclear how the addition of a retrieval datastore impacts model
privacy. In this work, we present the first study of privacy risks in
retrieval-based LMs, particularly $k$NN-LMs. Our goal is to explore the optimal
design and training procedure in domains where privacy is of concern, aiming to
strike a balance between utility and privacy. Crucially, we find that $k$NN-LMs
are more susceptible to leaking private information from their private
datastore than parametric models. We further explore mitigations of privacy
risks. When privacy information is targeted and readily detected in the text,
we find that a simple sanitization step would completely eliminate the risks,
while decoupling query and key encoders achieves an even better utility-privacy
trade-off. Otherwise, we consider strategies of mixing public and private data
in both datastore and encoder training. While these methods offer modest
improvements, they leave considerable room for future work. Together, our
findings provide insights for practitioners to better understand and mitigate
privacy risks in retrieval-based LMs. Our code is available at:
this https URL .</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Interpretable by Design Visual Question Answering</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14882</p>
  <p><b>作者</b>：Xingyu Fu,  Ben Zhou,  Sihao Chen,  Mark Yatskar,  Dan Roth</p>
  <p><b>备注</b>：Multimodal, Vision and Language</p>
  <p><b>关键词</b>：Visual Question Answering, vision and language, aligned and reasoned, multimodal setting, Question Answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model interpretability has long been a hard problem for the AI community
especially in the multimodal setting, where vision and language need to be
aligned and reasoned at the same time. In this paper, we specifically focus on
the problem of Visual Question Answering (VQA). While previous researches try
to probe into the network structures of black-box multimodal models, we propose
to tackle the problem from a different angle -- to treat interpretability as an
explicit additional goal.
Given an image and question, we argue that an interpretable VQA model should
be able to tell what conclusions it can get from which part of the image, and
show how each statement help to arrive at an answer. We introduce InterVQA:
Interpretable-by-design VQA, where we design an explicit intermediate dynamic
reasoning structure for VQA problems and enforce symbolic reasoning that only
use the structure for final answer prediction to take place. InterVQA produces
high-quality explicit intermediate reasoning steps, while maintaining similar
to the state-of-the-art (sota) end-task performance.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：ByteSized32: A Corpus and Challenge Task for Generating Task-Specific  World Models Expressed as Text Games</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14879</p>
  <p><b>作者</b>：Ruoyao Wang,  Graham Todd,  Eric Yuan,  Ziang Xiao,  Marc-Alexandre Côté,  Peter Jansen</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：explicit world models, generating text-based games, generate explicit world, common-sense reasoning tasks, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we examine the ability of language models to generate explicit
world models of scientific and common-sense reasoning tasks by framing this as
a problem of generating text-based games. To support this, we introduce
ByteSized32, a corpus of 32 highly-templated text games written in Python
totaling 24k lines of code, each centered around a particular task, and paired
with a set of 16 unseen text game specifications for evaluation. We propose a
suite of automatic and manual metrics for assessing simulation validity,
compliance with task specifications, playability, winnability, and alignment
with the physical world. In a single-shot evaluation of GPT-4 on this
simulation-as-code-generation task, we find it capable of producing runnable
games in 27% of cases, highlighting the difficulty of this challenge task. We
discuss areas of future improvement, including GPT-4's apparent capacity to
perform well at simulating near canonical task solutions, with performance
dropping off as simulations include distractors or deviate from canonical
solutions in the action space.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Leveraging GPT-4 for Automatic Translation Post-Editing</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14878</p>
  <p><b>作者</b>：Vikas Raunak,  Amr Sharaf,  Hany Hassan Awadallah,  Arul Menezes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Machine Translation, Neural Machine, Machine Translation, represents the leading, Translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Neural Machine Translation (NMT) represents the leading approach to
Machine Translation (MT), the outputs of NMT models still require translation
post-editing to rectify errors and enhance quality, particularly under critical
settings. In this work, we formalize the task of translation post-editing with
Large Language Models (LLMs) and explore the use of GPT-4 to automatically
post-edit NMT outputs across several language pairs. Our results demonstrate
that GPT-4 is adept at translation post-editing and produces meaningful edits
even when the target language is not English. Notably, we achieve
state-of-the-art performance on WMT-22 English-Chinese, English-German,
Chinese-English and German-English language pairs using GPT-4 based
post-editing, as evaluated by state-of-the-art MT quality metrics.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Improving Probability-based Prompt Selection Through Unified Evaluation  and Analysis</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14877</p>
  <p><b>作者</b>：Sohee Yang,  Jonghyeon Kim,  Joel Jang,  Seonghyeon Ye,  Hyunji Lee,  Minjoon Seo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, require task-specific training, demonstrated great capabilities, Large Language, prompt selection methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have demonstrated great capabilities in solving
a wide range of tasks in a resource-efficient manner through prompting, which
does not require task-specific training, but suffers from performance
fluctuation when there are multiple prompt candidates. Previous works have
introduced gradient-free probability-based prompt selection methods that aim to
choose the optimal prompt among the candidates for a given task but fail to
provide a comprehensive and fair comparison between each other. In this paper,
we propose a unified framework to interpret and evaluate the existing
probability-based prompt selection methods by performing extensive experiments
on 13 common NLP tasks. We find that all existing methods can be unified into
some variant of the method that maximizes the mutual information between the
input and the corresponding model output (denoted as MI). Using the finding, we
develop several variants of MI and increases the effectiveness of the best
prompt selection method from 87.79% to 94.98%, measured as the ratio of the
performance of the selected prompt to that of the optimal oracle prompt.
Furthermore, we propose a novel calibration method called Calibration by
Marginalization (CBM) that is orthogonal to existing methods and helps increase
the prompt selection effectiveness of the best method by 99.44%. The code and
datasets used in our work will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：From Words to Wires: Generating Functioning Electronic Devices from  Natural Language Descriptions</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14874</p>
  <p><b>作者</b>：Peter Jansen</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：previously unknown skill, high-level textual descriptions, unknown skill, textual descriptions, show that contemporary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we show that contemporary language models have a previously
unknown skill -- the capacity for electronic circuit design from high-level
textual descriptions, akin to code generation. We introduce two benchmarks:
Pins100, assessing model knowledge of electrical components, and Micro25,
evaluating a model's capability to design common microcontroller circuits and
code in the Arduino ecosystem that involve input, output, sensors, motors,
protocols, and logic -- with models such as GPT-4 and Claude-V1 achieving
between 60% to 96% Pass@1 on generating full devices. We include six case
studies of using language models as a design assistant for moderately complex
devices, such as a radiation-powered random number generator, an emoji
keyboard, a visible spectrometer, and several assistive devices, while offering
a qualitative analysis performance, outlining evaluation challenges, and
suggesting areas of development to improve complex circuit design and practical
utility. With this work, we aim to spur research at the juncture of natural
language processing and electronic design.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：ClusterLLM: Large Language Models as a Guide for Text Clustering</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14871</p>
  <p><b>作者</b>：Yuwei Zhang,  Zihan Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language model, instruction-tuned large language, text clustering framework, language model, framework that leverages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce ClusterLLM, a novel text clustering framework that leverages
feedback from an instruction-tuned large language model, such as ChatGPT.
Compared with traditional unsupervised methods that builds upon "small"
embedders, ClusterLLM exhibits two intriguing advantages: (1) it enjoys the
emergent capability of LLM even if its embeddings are inaccessible; and (2) it
understands the user's preference on clustering through textual instruction
and/or a few annotated data. First, we prompt ChatGPT for insights on
clustering perspective by constructing hard triplet questions <does a better correspond to b than c>, where A, B and C are similar data points that belong
to different clusters according to small embedder. We empirically show that
this strategy is both effective for fine-tuning small embedder and
cost-efficient to query ChatGPT. Second, we prompt ChatGPT for helps on
clustering granularity by carefully designed pairwise questions <do a and b belong to the same category>, and tune the granularity from cluster hierarchies
that is the most consistent with the ChatGPT answers. Extensive experiments on
14 datasets show that ClusterLLM consistently improves clustering quality, at
an average cost of ~$0.6 per dataset.</do></does></p>
  </details>
</details>
<details>
  <summary>146. <b>标题：CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense  Question Answering</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14869</p>
  <p><b>作者</b>：Weiqi Wang,  Tianqing Fang,  Wenxuan Ding,  Baixuan Xu,  Xin Liu,  Yangqiu Song,  Antoine Bosselut</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specific datasets, CommonSense Knowledge Bases, capacity to reason, reason about general, presented in specific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of zero-shot commonsense question answering evaluates models on
their capacity to reason about general scenarios beyond those presented in
specific datasets. Existing approaches for tackling this task leverage external
knowledge from CommonSense Knowledge Bases (CSKBs) by pretraining the model on
synthetic QA pairs constructed from CSKBs. In these approaches, negative
examples (distractors) are formulated by randomly sampling from CSKBs using
fairly primitive keyword constraints. However, two bottlenecks limit these
approaches: the inherent incompleteness of CSKBs limits the semantic coverage
of synthetic QA pairs, and the lack of human annotations makes the sampled
negative examples potentially uninformative and contradictory. To tackle these
limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a
zero-shot commonsense question-answering framework that fully leverages the
power of conceptualization. Specifically, CAR abstracts a commonsense knowledge
triple to many higher-level instances, which increases the coverage of CSKB and
expands the ground-truth answer space, reducing the likelihood of selecting
false-negative distractors. Extensive experiments demonstrate that CAR more
robustly generalizes to answering questions about zero-shot commonsense
scenarios than existing methods, including large language models, such as
GPT3.5 and ChatGPT. Our codes, data, and model checkpoints are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Large Language Model Distillation Doesn't Need a Teacher</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14864</p>
  <p><b>作者</b>：Ananya Harsh Jha,  Dirk Groeneveld,  Emma Strubell,  Iz Beltagy</p>
  <p><b>备注</b>：10 pages, 3 figures, 5 tables</p>
  <p><b>关键词</b>：Knowledge distillation trains, computational constraints, trains a smaller, match the output, output distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation trains a smaller student model to match the output
distribution of a larger teacher to maximize the end-task performance under
computational constraints. However, existing literature on language model
distillation primarily focuses on compressing encoder-only models that are then
specialized by task-specific supervised finetuning. We need to rethink this
setup for more recent large language models with tens to hundreds of billions
of parameters. Task-specific finetuning is impractical at this scale, and model
performance is often measured using zero/few-shot prompting. Thus, in this
work, we advocate for task-agnostic zero-shot evaluated distillation for large
language models without access to end-task finetuning data. We propose a
teacher-free task-agnostic distillation method, which uses a truncated version
of the larger model for initialization, and continues pretraining this model
using a language modeling objective. Our teacher-free method shines in a
distillation regime where it is infeasible to fit both the student and teacher
into the GPU memory. Despite its simplicity, our method can effectively reduce
the model size by 50\%, matching or outperforming the vanilla distillation
method on perplexity and accuracy on 13 zero-shot end-tasks while being 1.5x
computationally efficient.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Utility-Probability Duality of Neural Networks</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14859</p>
  <p><b>作者</b>：Huang Bojun,  Fei Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural networks, modern neural networks, typically understood, distribution of desired, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is typically understood that the training of modern neural networks is a
process of fitting the probability distribution of desired output. However,
recent paradoxical observations in a number of language generation tasks let
one wonder if this canonical probability-based explanation can really account
for the empirical success of deep learning.
To resolve this issue, we propose an alternative utility-based explanation to
the standard supervised learning procedure in deep learning. The basic idea is
to interpret the learned neural network not as a probability model but as an
ordinal utility function that encodes the preference revealed in training data.
In this perspective, training of the neural network corresponds to a utility
learning process. Specifically, we show that for all neural networks with
softmax outputs, the SGD learning dynamic of maximum likelihood estimation
(MLE) can be seen as an iteration process that optimizes the neural network
toward an optimal utility function. This utility-based interpretation can
explain several otherwise-paradoxical observations about the neural networks
thus trained. Moreover, our utility-based theory also entails an equation that
can transform the learned utility values back to a new kind of probability
estimation with which probability-compatible decision rules enjoy dramatic
(double-digits) performance improvements.
These evidences collectively reveal a phenomenon of utility-probability
duality in terms of what modern neural networks are (truly) modeling: We
thought they are one thing (probabilities), until the unexplainable showed up;
changing mindset and treating them as another thing (utility values) largely
reconcile the theory, despite remaining subtleties regarding its original
(probabilistic) identity.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual  Transfer</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14857</p>
  <p><b>作者</b>：Akari Asai,  Sneha Kudugunta,  Xinyan Velocity Yu,  Terra Blevins,  Hila Gonen,  Machel Reid,  Yulia Tsvetkov,  Sebastian Ruder,  Hannaneh Hajishirzi</p>
  <p><b>备注</b>：The data and code is available at this https URL</p>
  <p><b>关键词</b>：natural language processing, remarkable advancements, generalization in natural, developed and evaluated, evaluated primarily</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite remarkable advancements in few-shot generalization in natural
language processing, most models are developed and evaluated primarily in
English. To facilitate research on few-shot cross-lingual transfer, we
introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across
54 languages in a sequence-to-sequence format and provides a fixed set of
few-shot examples and instructions. BUFFET is designed to establish a rigorous
and equitable evaluation framework for few-shot cross-lingual transfer across a
broad range of tasks and languages. Using BUFFET, we perform thorough
evaluations of state-of-the-art multilingual large language models with
different transfer methods, namely in-context learning and fine-tuning. Our
findings reveal significant room for improvement in few-shot in-context
cross-lingual transfer. In particular, ChatGPT with in-context learning often
performs worse than much smaller mT5-base models fine-tuned on English task
data and few-shot in-language examples. Our analysis suggests various avenues
for future research in few-shot cross-lingual transfer, such as improved
pretraining, understanding, and future evaluations.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Drafting Event Schemas using Language Models</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14847</p>
  <p><b>作者</b>：Anisha Gunjal,  Greg Durrett</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：studied event prediction, mediated through structured, structured representations, schemas, event language modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Past work has studied event prediction and event language modeling, sometimes
mediated through structured representations of knowledge in the form of event
schemas. Such schemas can lead to explainable predictions and forecasting of
unseen events given incomplete information. In this work, we look at the
process of creating such schemas to describe complex events. We use large
language models (LLMs) to draft schemas directly in natural language, which can
be further refined by human curators as necessary. Our focus is on whether we
can achieve sufficient diversity and recall of key events and whether we can
produce the schemas in a sufficiently descriptive style. We show that large
language models are able to achieve moderate recall against schemas taken from
two different datasets, with even better results when multiple prompts and
multiple samples are combined. Moreover, we show that textual entailment
methods can be used for both matching schemas to instances of events as well as
evaluating overlap between gold and predicted schemas. Our method paves the way
for easier distillation of event knowledge from large language model into
schemas.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：Meta-Learning For Vision-and-Language Cross-lingual Transfer</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14843</p>
  <p><b>作者</b>：Hanxu Hu,  Frank Keller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pre-trained vison-language models, achieve excellent performance, Current pre-trained vison-language, achieve excellent, pre-trained vison-language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current pre-trained vison-language models (PVLMs) achieve excellent
performance on a range of multi-modal datasets. Recent work has aimed at
building multilingual models, and a range of novel multilingual multi-modal
datasets have been proposed. Current PVLMs typically perform poorly on these
datasets when used for multi-modal zero-shot or few-shot cross-lingual
transfer, especially for low-resource languages. To alleviate this problem, we
propose a novel meta-learning fine-tuning framework. Our framework makes
current PVLMs rapidly adaptive to new languages in vision-language scenarios by
designing MAML in a cross-lingual multi-modal manner. Experiments show that our
method boosts the performance of current state-of-the-art PVLMs in both
zero-shot and few-shot cross-lingual transfer on a range of vision-language
understanding tasks and datasets (XVNLI, xGQA, MaRVL, xFlicker&Co</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Exploring Sentiment Analysis Techniques in Natural Language Processing:  A Comprehensive Review</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14842</p>
  <p><b>作者</b>：Karthick Prasad Gunasekaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：written text, automated process, process of detecting, detecting and understanding, understanding the emotions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentiment analysis (SA) is the automated process of detecting and
understanding the emotions conveyed through written text. Over the past decade,
SA has gained significant popularity in the field of Natural Language
Processing (NLP). With the widespread use of social media and online platforms,
SA has become crucial for companies to gather customer feedback and shape their
marketing strategies. Additionally, researchers rely on SA to analyze public
sentiment on various topics. In this particular research study, a comprehensive
survey was conducted to explore the latest trends and techniques in SA. The
survey encompassed a wide range of methods, including lexicon-based,
graph-based, network-based, machine learning, deep learning, ensemble-based,
rule-based, and hybrid techniques. The paper also addresses the challenges and
opportunities in SA, such as dealing with sarcasm and irony, analyzing
multi-lingual data, and addressing ethical concerns. To provide a practical
case study, Twitter was chosen as one of the largest online social media
platforms. Furthermore, the researchers shed light on the diverse application
areas of SA, including social media, healthcare, marketing, finance, and
politics. The paper also presents a comparative and comprehensive analysis of
existing trends and techniques, datasets, and evaluation metrics. The ultimate
goal is to offer researchers and practitioners a systematic review of SA
techniques, identify existing gaps, and suggest possible improvements. This
study aims to enhance the efficiency and accuracy of SA processes, leading to
smoother and error-free outcomes.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and  Compositional Experts</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14839</p>
  <p><b>作者</b>：Yunshui Li,  Binyuan Hui,  ZhiChao Yin,  Min Yang,  Fei Huang,  Yongbin Li</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：Perceiving multi-modal information, multi-modal dialogue, artificial intelligence, multi-modal, information and fulfilling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perceiving multi-modal information and fulfilling dialogues with humans is a
long-term goal of artificial intelligence. Pre-training is commonly regarded as
an effective approach for multi-modal dialogue. However, due to the limited
availability of multi-modal dialogue data, there is still scarce research on
multi-modal dialogue pre-training. Yet another intriguing challenge emerges
from the encompassing nature of multi-modal dialogue, which involves various
modalities and tasks. Moreover, new forms of tasks may arise at unpredictable
points in the future. Hence, it is essential for designed multi-modal dialogue
models to possess sufficient flexibility to adapt to such scenarios. This paper
proposes \textbf{PaCE}, a unified, structured, compositional multi-modal
dialogue pre-training framework. It utilizes a combination of several
fundamental experts to accommodate multiple dialogue-related tasks and can be
pre-trained using limited dialogue and extensive non-dialogue multi-modal data.
Furthermore, we propose a progressive training method where old experts from
the past can assist new experts, facilitating the expansion of their
capabilities. Experimental results demonstrate that PaCE achieves
state-of-the-art results on eight multi-modal dialog benchmarks.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text  Translation</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14838</p>
  <p><b>作者</b>：Chenyang Le,  Yao Qian,  Long Zhou,  Shujie Liu,  Michael Zeng,  Xuedong Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joint speech-language training, GPU consumption, data and GPU, training data, challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Joint speech-language training is challenging due to the large demand for
training data and GPU consumption, as well as the modality gap between speech
and language. We present ComSL, a speech-language model built atop a composite
architecture of public pretrained speech-only and language-only models and
optimized data-efficiently for spoken language tasks. Particularly, we propose
to incorporate cross-modality learning into transfer learning and conduct them
simultaneously for downstream tasks in a multi-task learning manner. Our
approach has demonstrated effectiveness in end-to-end speech-to-text
translation tasks, achieving a new state-of-the-art average BLEU score of 31.5
on the multilingual speech to English text translation task for 21 languages,
as measured on the public CoVoST2 evaluation set.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：SummIt: Iterative Text Summarization via ChatGPT</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14835</p>
  <p><b>作者</b>：Haopeng Zhang,  Xiao Liu,  Jiawei Zhang</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：made significant progress, typically generates summaries, Existing text summarization, text summarization systems, single step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing text summarization systems have made significant progress in recent
years but typically generates summaries in a single step. The one-shot
summarization setting is sometimes inadequate, however, as the generated
summary may contain hallucinations or overlook important details related to the
reader's interests. In this paper, we address this limitation by proposing
SummIt, an iterative text summarization framework based on large language
models like ChatGPT. Our framework enables the model to refine the generated
summary iteratively through self-evaluation and feedback, closely resembling
the iterative process humans undertake when drafting and revising summaries. We
also explore using in-context learning to guide the rationale generation and
summary refinement. Furthermore, we explore the potential benefits of
integrating knowledge and topic extractors into the framework to enhance
summary faithfulness and controllability. We evaluate the performance of our
framework on three benchmark summarization datasets through empirical and
qualitative analyses. We also conduct a human evaluation to validate the
effectiveness of the model's refinements and find a potential issue of
over-correction. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Towards Few-shot Entity Recognition in Document Images: A Graph Neural  Network Approach Robust to Image Manipulation</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14828</p>
  <p><b>作者</b>：Prashant Krishnan,  Zilong Wang,  Yangkun Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved significant performance, incorporating layout information, typically bounding box, bounding box coordinates, document images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances of incorporating layout information, typically bounding box
coordinates, into pre-trained language models have achieved significant
performance in entity recognition from document images. Using coordinates can
easily model the absolute position of each token, but they might be sensitive
to manipulations in document images (e.g., shifting, rotation or scaling),
especially when the training data is limited in few-shot settings. In this
paper, we propose to further introduce the topological adjacency relationship
among the tokens, emphasizing their relative position information.
Specifically, we consider the tokens in the documents as nodes and formulate
the edges based on the topological heuristics from the k-nearest bounding
boxes. Such adjacency graphs are invariant to affine transformations including
shifting, rotations and scaling. We incorporate these graphs into the
pre-trained language model by adding graph neural network layers on top of the
language model embeddings, leading to a novel model LAGER. Extensive
experiments on two benchmark datasets show that LAGER significantly outperforms
strong baselines under different few-shot settings and also demonstrate better
robustness to manipulations.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent  Classification</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14827</p>
  <p><b>作者</b>：Mujeen Sung,  James Gung,  Elman Mansimov,  Nikolaos Pappas,  Raphael Shu,  Salvatore Romeo,  Yi Zhang,  Vittorio Castelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task-oriented dialogue systems, identifies user intents, plays an important, important role, role in task-oriented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intent classification (IC) plays an important role in task-oriented dialogue
systems as it identifies user intents from given utterances. However, models
trained on limited annotations for IC often suffer from a lack of
generalization to unseen intent classes. We propose a novel pre-training method
for text encoders that uses contrastive learning with intent psuedo-labels to
produce embeddings that are well-suited for IC tasks. By applying this
pre-training strategy, we also introduce the pre-trained intent-aware encoder
(PIE). Specifically, we first train a tagger to identify key phrases within
utterances that are crucial for interpreting intents. We then use these
extracted phrases to create examples for pre-training a text encoder in a
contrastive manner. As a result, our PIE model achieves up to 5.4% and 4.0%
higher accuracy than the previous state-of-the-art pre-trained sentence encoder
for the N-way zero- and one-shot settings on four IC datasets.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Large Language Models are In-Context Semantic Reasoners rather than  Symbolic Reasoners</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14825</p>
  <p><b>作者</b>：Xiaojuan Tang,  Zilong Zheng,  Jiaqi Li,  Fanxu Meng,  Song-Chun Zhu,  Yitao Liang,  Muhan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, machine learning community, emergent few-shot reasoning, Language Models, few-shot reasoning capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emergent few-shot reasoning capabilities of Large Language Models (LLMs)
have excited the natural language and machine learning community over recent
years. Despite of numerous successful applications, the underlying mechanism of
such in-context capabilities still remains unclear. In this work, we
hypothesize that the learned \textit{semantics} of language tokens do the most
heavy lifting during the reasoning process. Different from human's symbolic
reasoning process, the semantic representations of LLMs could create strong
connections among tokens, thus composing a superficial logical chain. To test
our hypothesis, we decouple semantics from the language reasoning process and
evaluate three kinds of reasoning abilities, i.e., deduction, induction and
abduction. Our findings reveal that semantics play a vital role in LLMs'
in-context reasoning -- LLMs perform significantly better when semantics are
consistent with commonsense but struggle to solve symbolic or
counter-commonsense reasoning tasks by leveraging in-context new knowledge. The
surprising observations question whether modern LLMs have mastered the
inductive, deductive and abductive reasoning abilities as in human
intelligence, and motivate research on unveiling the magic existing within the
black-box LLMs. On the whole, our analysis provides a novel perspective on the
role of semantics in developing and evaluating language models' reasoning
abilities. Code is available at {\url{this https URL}}.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Mitigating Temporal Misalignment by Discarding Outdated Facts</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14824</p>
  <p><b>作者</b>：Michael J.Q. Zhang,  Eunsol Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retain vast amounts, large language models, nontrivial to update, large language, retain vast</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While large language models are able to retain vast amounts of world
knowledge seen during pretraining, such knowledge is prone to going out of date
and is nontrivial to update. Furthermore, these models are often used under
temporal misalignment, tasked with answering questions about the present,
despite having only been trained on data collected in the past. To mitigate the
effects of temporal misalignment, we propose fact duration prediction: the task
of predicting how long a given fact will remain true. In our experiments, we
demonstrate how identifying facts that are prone to rapid change can help
models avoid from reciting outdated information and identify which predictions
require seeking out up-to-date knowledge sources. We also show how modeling
fact duration improves calibration for knowledge-intensive tasks, such as
open-retrieval question answering, under temporal misalignment by discarding
volatile facts. Our data and code will be released publicly at
this https URL.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Machine Reading Comprehension using Case-based Reasoning</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14815</p>
  <p><b>作者</b>：Dung Thai,  Dhruv Agarwal,  Mudit Chaudhary,  Rajarshi Das,  Manzil Zaheer,  Jay-Yoon Lee,  Hannaneh Hajishirzi,  Andrew McCallum</p>
  <p><b>备注</b>：9 pages, 2 figures</p>
  <p><b>关键词</b>：machine reading comprehension, case-based reasoning, present an accurate, accurate and interpretable, extraction in machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an accurate and interpretable method for answer extraction in
machine reading comprehension that is reminiscent of case-based reasoning (CBR)
from classical AI. Our method (CBR-MRC) builds on the hypothesis that
contextualized answers to similar questions share semantic similarities with
each other. Given a target question, CBR-MRC retrieves a set of similar
questions from a memory of observed cases and predicts an answer by selecting
the span in the target context that is most similar to the contextualized
representations of answers in the retrieved cases. The semi-parametric nature
of our approach allows CBR-MRC to attribute a prediction to the specific set of
cases used during inference, making it a desirable choice for building reliable
and debuggable QA systems. We show that CBR-MRC achieves high test accuracy
comparable with large reader models, outperforming baselines by 11.5 and 8.4 EM
on NaturalQuestions and NewsQA, respectively. Further, we also demonstrate the
ability of CBR-MRC in identifying not just the correct answer tokens but also
the span with the most relevant supporting evidence. Lastly, we observe that
contexts for certain question types show higher lexical diversity than others
and find CBR-MRC to be robust to these variations while performance using
fully-parametric methods drops.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：AWESOME: GPU Memory-constrained Long Document Summarization using Memory  Mechanism and Global Salient Content</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14806</p>
  <p><b>作者</b>：Shuyang Cao,  Lu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：limited computing resources, present significant challenges, computing resources, systems are critical, critical for domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Long document summarization systems are critical for domains with lengthy and
jargonladen text, yet they present significant challenges to researchers and
developers with limited computing resources. Existing solutions mainly focus on
efficient attentions or divide-and-conquer strategies. The former reduces
theoretical time complexity, but is still memory-heavy. The latter methods
sacrifice global context, leading to uninformative and incoherent summaries.
This work aims to leverage the memory-efficient nature of divide-and-conquer
methods while preserving global context. Concretely, our framework AWESOME uses
two novel mechanisms: (1) External memory mechanisms track previously encoded
document segments and their corresponding summaries, to enhance global document
understanding and summary coherence. (2) Global salient content is further
identified beforehand to augment each document segment to support its
summarization. Extensive experiments on diverse genres of text, including
government reports, transcripts, scientific papers, and novels, show that
AWESOME produces summaries with improved informativeness, faithfulness, and
coherence than competitive baselines on longer documents, while having a
similar or smaller GPU memory footprint.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Estimating Large Language Model Capabilities without Labeled Test Data</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14802</p>
  <p><b>作者</b>：Harvey Yiyun Fu,  Qinyuan Ye,  Albert Xu,  Xiang Ren,  Robin Jia</p>
  <p><b>备注</b>：14 pages, 4 figures</p>
  <p><b>关键词</b>：Large Language Models, Language Models, ICL varies widely, Large Language, ICL accuracy estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have exhibited an impressive ability to perform
in-context learning (ICL) from only a few examples, but the success of ICL
varies widely from task to task. Thus, it is important to quickly determine
whether ICL is applicable to a new task, but directly evaluating ICL accuracy
can be expensive in situations where test data is expensive to annotate -- the
exact situations where ICL is most appealing. In this paper, we propose the
task of ICL accuracy estimation, in which we predict the accuracy of an LLM
when doing in-context learning on a new task given only unlabeled data for that
task. To perform ICL accuracy estimation, we propose a method that trains a
meta-model using LLM confidence scores as features. We compare our method to
several strong accuracy estimation baselines on a new benchmark that covers 4
LLMs and 3 task collections. On average, the meta-model improves over all
baselines and achieves the same estimation performance as directly evaluating
on 40 labeled test examples per task, across the total 12 settings. We
encourage future work to improve on our methods and evaluate on our ICL
accuracy estimation benchmark to deepen our understanding of when ICL works.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop  Questions</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14795</p>
  <p><b>作者</b>：Zexuan Zhong,  Zhengxuan Wu,  Christopher D. Manning,  Christopher Potts,  Danqi Chen</p>
  <p><b>备注</b>：Our code and datasets are available at this https URL</p>
  <p><b>关键词</b>：date quickly, information stored, retraining from scratch, edited facts, British Prime Minister</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The information stored in large language models (LLMs) falls out of date
quickly, and retraining from scratch is often not an option. This has recently
given rise to a range of techniques for injecting new facts through updating
model weights. Current evaluation paradigms are extremely limited, mainly
validating the recall of edited facts, but changing one fact should cause
rippling changes to the model's related beliefs. If we edit the UK Prime
Minister to now be Rishi Sunak, then we should get a different answer to Who is
married to the British Prime Minister? In this work, we present a benchmark
MQuAKE (Multi-hop Question Answering for Knowledge Editing) comprising
multi-hop questions that assess whether edited models correctly answer
questions where the answer should change as an entailed consequence of edited
facts. While we find that current knowledge-editing approaches can recall
edited facts accurately, they fail catastrophically on the constructed
multi-hop questions. We thus propose a simple memory-based approach, MeLLo,
which stores all edited facts externally while prompting the language model
iteratively to generate answers that are consistent with the edited facts.
While MQuAKE remains challenging, we show that MeLLo scales well with LLMs (up
to 175B) and outperforms previous model editors by a large margin.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak  Supervision for Text Classification</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14794</p>
  <p><b>作者</b>：Chengyu Dong,  Zihan Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：turn high-level human, high-level human heuristics, designing sophisticated methods, weakly supervised text, supervised text classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in weakly supervised text classification mostly focus on
designing sophisticated methods to turn high-level human heuristics into
quality pseudo-labels. In this paper, we revisit the seed matching-based
method, which is arguably the simplest way to generate pseudo-labels, and show
that its power was greatly underestimated. We show that the limited performance
of seed matching is largely due to the label bias injected by the simple
seed-match rule, which prevents the classifier from learning reliable
confidence for selecting high-quality pseudo-labels. Interestingly, simply
deleting the seed words present in the matched input texts can mitigate the
label bias and help learn better confidence. Subsequently, the performance
achieved by seed matching can be improved significantly, making it on par with
or even better than the state-of-the-art. Furthermore, to handle the case when
the seed words are not made known, we propose to simply delete the word tokens
in the input text randomly with a high deletion ratio. Remarkably, seed
matching equipped with this random deletion method can often achieve even
better performance than that with seed deletion.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：Faithful Low-Resource Data-to-Text Generation through Cycle Training</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14793</p>
  <p><b>作者</b>：Zhuoer Wang,  Marcus Collins,  Nikhita Vedula,  Simone Filice,  Shervin Malmasi,  Oleg Rokhlenko</p>
  <p><b>备注</b>：19 pages, 4 figures, ACL 2023</p>
  <p><b>关键词</b>：recent years, primarily due, structured data, advanced significantly, significantly in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Methods to generate text from structured data have advanced significantly in
recent years, primarily due to fine-tuning of pre-trained language models on
large datasets. However, such models can fail to produce output faithful to the
input data, particularly on out-of-domain data. Sufficient annotated data is
often not available for specific domains, leading us to seek an unsupervised
approach to improve the faithfulness of output text. Since the problem is
fundamentally one of consistency between the representations of the structured
data and text, we evaluate the effectiveness of cycle training in this work.
Cycle training uses two models which are inverses of each other: one that
generates text from structured data, and one which generates the structured
data from natural language text. We show that cycle training, when initialized
with a small amount of supervised data (100 samples in our case), achieves
nearly the same performance as fully supervised approaches for the data-to-text
generation task on the WebNLG, E2E, WTQ, and WSQL datasets. We perform
extensive empirical analysis with automated evaluation metrics and a newly
designed human evaluation schema to reveal different cycle training strategies'
effectiveness of reducing various types of generation errors. Our code is
publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：Large Language Models as Counterfactual Generator: Strengths and  Weaknesses</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14791</p>
  <p><b>作者</b>：Yongqi Li,  Mayi Xu,  Xin Miao,  Shen Zhou,  Tieyun Qian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated remarkable performance, Large language models, demonstrated remarkable, remarkable performance, natural language understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable performance in a
range of natural language understanding and generation tasks. Yet, their
ability to generate counterfactuals, which can be used for areas like data
augmentation, remains under-explored. This study aims to investigate the
counterfactual generation capabilities of LLMs and analysis factors that
influence this ability. First, we evaluate how effective are LLMs in
counterfactual generation through data augmentation experiments for small
language models (SLMs) across four tasks: sentiment analysis, natural language
inference, named entity recognition, and relation extraction. While LLMs show
promising enhancements in various settings, they struggle in complex tasks due
to their self-limitations and the lack of logical guidance to produce
counterfactuals that align with commonsense. Second, our analysis reveals the
pivotal role of providing accurate task definitions and detailed step-by-step
instructions to LLMs in generating counterfactuals. Interestingly, we also find
that LLMs can generate reasonable counterfactuals even with unreasonable
demonstrations, which illustrates that demonstrations are primarily to regulate
the output format.This study provides the first comprehensive insight into
counterfactual generation abilities of LLMs, and offers a novel perspective on
utilizing LLMs for data augmentation to enhance SLMs.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Advancing Topic Segmentation and Outline Generation in Chinese Texts:  The Paragraph-level Topic Representation, Corpus, and Benchmark</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14790</p>
  <p><b>作者</b>：Feng Jiang,  Weihao Liu,  Xiaomin Chu,  Peifeng Li,  Qiaoming Zhu,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：coherent topic sections, paragraph-level topic structure, topic structure, discourse topic structure, Topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Topic segmentation and outline generation strive to divide a document into
coherent topic sections and generate corresponding subheadings. Such a process
unveils the discourse topic structure of a document that benefits quickly
grasping and understanding the overall context of the document from a higher
level. However, research and applications in this field have been restrained
due to the lack of proper paragraph-level topic representations and
large-scale, high-quality corpora in Chinese compared to the success achieved
in English. Addressing these issues, we introduce a hierarchical
paragraph-level topic structure representation with title, subheading, and
paragraph that comprehensively models the document discourse topic structure.
In addition, we ensure a more holistic representation of topic distribution
within the document by using sentences instead of keywords to represent
sub-topics. Following this representation, we construct the largest Chinese
Paragraph-level Topic Structure corpus (CPTS), four times larger than the
previously largest one. We also employ a two-stage man-machine collaborative
annotation method to ensure the high quality of the corpus both in form and
semantics. Finally, we validate the computability of CPTS on two fundamental
tasks (topic segmentation and outline generation) by several strong baselines,
and its efficacy has been preliminarily confirmed on the downstream task:
discourse parsing. The representation, corpus, and benchmark we established
will provide a solid foundation for future studies.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Adapting Language Models to Compress Contexts</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14788</p>
  <p><b>作者</b>：Alexis Chevalier,  Alexander Wettig,  Anirudh Ajith,  Danqi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：processing long text, widely-applicable tools, expensive computational cost, summary vectors, powerful and widely-applicable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer-based language models (LMs) are powerful and widely-applicable
tools, but their usefulness is constrained by a finite context window and the
expensive computational cost of processing long text documents. We propose to
adapt pre-trained LMs into AutoCompressors. These models are capable of
compressing long contexts into compact summary vectors, which are then
accessible to the model as soft prompts. Summary vectors are trained with an
unsupervised objective, whereby long documents are processed in segments and
summary vectors from all previous segments are used in language modeling. We
fine-tune OPT models on sequences of up to 30,720 tokens and show that
AutoCompressors can utilize long contexts to improve perplexity. We evaluate
AutoCompressors on in-context learning by compressing task demonstrations. We
find that summary vectors are good substitutes for plain-text demonstrations,
increasing accuracy while reducing inference cost. Finally, we explore the
benefits of pre-computing summary vectors for large corpora by applying summary
vectors to retrieval-augmented language modeling. Overall, AutoCompressors
emerge as a simple and inexpensive solution for extending the context window of
LMs while speeding up inference over long contexts.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14785</p>
  <p><b>作者</b>：Victoria Basmov,  Yoav Goldberg,  Reut Tsarfaty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper sheds light, simple inference tasks, focusing on simple, paper sheds, sheds light</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper sheds light on the limitations of ChatGPT's understanding
capabilities, focusing on simple inference tasks that are typically easy for
humans but appear to be challenging for the model. Specifically, we target (i)
grammatically-specified entailments, (ii) premises with evidential adverbs of
uncertainty, and (iii) monotonicity entailments. We present expert-designed
evaluation sets for these inference types and conduct experiments in a
zero-shot setup. Our results show that the model struggles with these types of
inferences, exhibiting moderate to low accuracy. Moreover, while ChatGPT
demonstrates knowledge of the underlying linguistic concepts when prompted
directly, it often fails to incorporate this knowledge to make correct
inferences. Even more strikingly, further experiments show that embedding the
premise under presupposition triggers or non-factive verbs causes the model to
predict entailment more frequently {regardless} of the correct semantic label.
Overall these results suggest that, despite GPT's celebrated language
understanding capacity, ChatGPT has blindspots with respect to certain types of
entailment, and that certain entailment-cancelling features act as ``blinds''
overshadowing the semantics of the embedded premise. Our analyses emphasize the
need for further research into the linguistic comprehension and reasoning
capabilities of LLMs, in order to improve their reliability, and establish
their trustworthiness for real-world applications.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：Anthropomorphization of AI: Opportunities and Risks</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14784</p>
  <p><b>作者</b>：Ameet Deshpande,  Tanmay Rajpurohit,  Karthik Narasimhan,  Ashwin Kalyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attribute human-like traits, non-human entities, traits to non-human, attribute human-like, human-like traits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anthropomorphization is the tendency to attribute human-like traits to
non-human entities. It is prevalent in many social contexts -- children
anthropomorphize toys, adults do so with brands, and it is a literary device.
It is also a versatile tool in science, with behavioral psychology and
evolutionary biology meticulously documenting its consequences. With widespread
adoption of AI systems, and the push from stakeholders to make it human-like
through alignment techniques, human voice, and pictorial avatars, the tendency
for users to anthropomorphize it increases significantly. We take a dyadic
approach to understanding this phenomenon with large language models (LLMs) by
studying (1) the objective legal implications, as analyzed through the lens of
the recent blueprint of AI bill of rights and the (2) subtle psychological
aspects customization and anthropomorphization. We find that anthropomorphized
LLMs customized for different user bases violate multiple provisions in the
legislative blueprint. In addition, we point out that anthropomorphization of
LLMs affects the influence they can have on their users, thus having the
potential to fundamentally change the nature of human-AI interaction, with
potential for manipulation and negative influence. With LLMs being
hyper-personalized for vulnerable groups like children and patients among
others, our work is a timely and important contribution. We propose a
conservative strategy for the cautious use of anthropomorphization to improve
trustworthiness of AI systems.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Disentangled Phonetic Representation for Chinese Spelling Correction</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14783</p>
  <p><b>作者</b>：Zihong Liang,  Xiaojun Quan,  Qifan Wang</p>
  <p><b>备注</b>：Accepted to ACL 2023 Main Conference</p>
  <p><b>关键词</b>：Chinese Spelling Correction, Spelling Correction, Chinese Spelling, Chinese texts, correct erroneous characters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chinese Spelling Correction (CSC) aims to detect and correct erroneous
characters in Chinese texts. Although efforts have been made to introduce
phonetic information (Hanyu Pinyin) in this task, they typically merge phonetic
representations with character representations, which tends to weaken the
representation effect of normal texts. In this work, we propose to disentangle
the two types of features to allow for direct interaction between textual and
phonetic information. To learn useful phonetic representations, we introduce a
pinyin-to-character objective to ask the model to predict the correct
characters based solely on phonetic information, where a separation mask is
imposed to disable attention from phonetic input to text. To avoid overfitting
the phonetics, we further design a self-distillation module to ensure that
semantic information plays a major role in the prediction. Extensive
experiments on three CSC benchmarks demonstrate the superiority of our method
in using phonetic information.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：Text Conditional Alt-Text Generation for Twitter Images</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14779</p>
  <p><b>作者</b>：Nikita Srivatsan,  Sofia Samaniego,  Omar Florez,  Taylor Berg-Kirkpatrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating alternative text, generating alternative, specifically Twitter, images shared, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we present an approach for generating alternative text (or
alt-text) descriptions for images shared on social media, specifically Twitter.
This task is more than just a special case of image captioning, as alt-text is
both more literally descriptive and context-specific. Also critically, images
posted to Twitter are often accompanied by user-written text that despite not
necessarily describing the image may provide useful context that if properly
leveraged can be informative -- e.g. the tweet may name an uncommon object in
the image that the model has not previously seen. We address this with a CLIP
prefix model that extracts an embedding of the image and passes it to a mapping
network that outputs a short sequence in word embedding space, or a ``prefix'',
to which we also concatenate the text from the tweet itself. This lets the
model condition on both visual and textual information from the post. The
combined multimodal prefix is then fed as a prompt to a pretrained language
model which autoregressively completes the sequence to generate the alt-text.
While prior work has used similar methods for captioning, ours is the first to
our knowledge that incorporates textual information from the associated social
media post into the prefix as well, and we further demonstrate through
ablations that utility of these two information sources stacks. We put forward
a new dataset scraped from Twitter and evaluate on it across a variety of
automated metrics as well as human evaluation, and show that our approach of
conditioning on both tweet text and visual information significantly
outperforms prior work.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：Measuring the Knowledge Acquisition-Utilization Gap in Pretrained  Language Models</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14775</p>
  <p><b>作者</b>：Amirhossein Kazemnejad,  Mehdi Rezagholizadeh,  Prasanna Parthasarathi,  Sarath Chandar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：acquiring vast amounts, pre-trained language models, knowledge, performing downstream tasks, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While pre-trained language models (PLMs) have shown evidence of acquiring
vast amounts of knowledge, it remains unclear how much of this parametric
knowledge is actually usable in performing downstream tasks. We propose a
systematic framework to measure parametric knowledge utilization in PLMs. Our
framework first extracts knowledge from a PLM's parameters and subsequently
constructs a downstream task around this extracted knowledge. Performance on
this task thus depends exclusively on utilizing the model's possessed
knowledge, avoiding confounding factors like insufficient signal. As an
instantiation, we study factual knowledge of PLMs and measure utilization
across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps -
in acquired vs. utilized knowledge, (2) they show limited robustness in
utilizing knowledge under distribution shifts, and (3) larger models close the
acquired knowledge gap but the utilized knowledge gap remains. Overall, our
study provides insights into PLMs' capabilities beyond their acquired
knowledge.</p>
  </details>
</details>
<details>
  <summary>174. <b>标题：A Controllable QA-based Framework for Decontextualization</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14772</p>
  <p><b>作者</b>：Benjamin Newman,  Luca Soldaini,  Raymond Fok,  Arman Cohan,  Kyle Lo</p>
  <p><b>备注</b>：11 pages, 3 figures, 6 tables</p>
  <p><b>关键词</b>：model generated inaccuracies., applications require surfacing, require surfacing extracted, surfacing extracted snippets, real-world applications require</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many real-world applications require surfacing extracted snippets to users,
whether motivated by assistive tools for literature surveys or document
cross-referencing, or needs to mitigate and recover from model generated
inaccuracies., Yet, these passages can be difficult to consume when divorced
from their original document context. In this work, we explore the limits of
LLMs to perform decontextualization of document snippets in user-facing
scenarios, focusing on two real-world settings - question answering and
citation context previews for scientific documents. We propose a
question-answering framework for decontextualization that allows for better
handling of user information needs and preferences when determining the scope
of rewriting. We present results showing state-of-the-art LLMs under our
framework remain competitive with end-to-end approaches. We also explore
incorporating user preferences into the system, finding our framework allows
for controllability.</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14771</p>
  <p><b>作者</b>：Xiaochuang Han,  Sachin Kumar,  Yulia Tsvetkov,  Marjan Ghazvininejad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Diffusion-based language models, competent generative models, autoregressive LMs, Diffusion-based language, competent generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion-based language models (LMs) have been shown to be competent
generative models that are easy to control at inference and are a promising
alternative to autoregressive LMs. While autoregressive LMs have benefited
immensely from scaling and instruction-based learning, existing studies on
diffusion LMs have been conducted on a relatively smaller scale. Starting with
a recently proposed diffusion model SSD-LM, in this work we explore methods to
scale it from 0.4B to 13B parameters, proposing several techniques to improve
its training and inference efficiency. We call the new model SSD-2. We further
show that this model can be easily finetuned to follow instructions. Finally,
leveraging diffusion models' capability at inference-time control, we show that
SSD-2 facilitates novel ensembles with 100x smaller models that can be
customized and deployed by individual users. We find that compared to
autoregressive models, the collaboration between diffusion models is more
effective, leading to higher-quality and more relevant model responses due to
their ability to incorporate bi-directional contexts.</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Using Natural Language Explanations to Rescale Human Judgments</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14770</p>
  <p><b>作者</b>：Manya Wadhwa,  Jifan Chen,  Junyi Jessy Li,  Greg Durrett</p>
  <p><b>备注</b>：Data available at this https URL</p>
  <p><b>关键词</b>：high-quality human-labeled data, feedback and evaluation, brought a critical, high-quality human-labeled, processes like human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of large language models (LLMs) has brought a critical need for
high-quality human-labeled data, particularly for processes like human feedback
and evaluation. A common practice is to label data via consensus annotation
over the judgments of multiple crowdworkers. However, different annotators may
have different interpretations of labeling schemes unless given extensive
training, and for subjective NLP tasks, even trained expert annotators can
diverge heavily. We show that these nuances can be captured by high quality
natural language explanations, and propose a method to rescale ordinal
annotation in the presence of disagreement using LLMs. Specifically, we feed
Likert ratings and corresponding natural language explanations into an LLM and
prompt it to produce a numeric score. This score should reflect the underlying
assessment of the example by the annotator. The presence of explanations allows
the LLM to homogenize ratings across annotators in spite of scale usage
differences. We explore our technique in the context of a document-grounded
question answering task on which large language models achieve near-human
performance. Among questions where annotators identify incompleteness in the
answers, our rescaling improves correlation between nearly all annotator pairs,
improving pairwise correlation on these examples by an average of 0.2 Kendall's
tau.</p>
  </details>
</details>
<details>
  <summary>177. <b>标题：BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14766</p>
  <p><b>作者</b>：Hao Sun,  Xiao Liu,  Yeyun Gong,  Yan Zhang,  Nan Duan</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：accessing external information, requires accessing external, crucial task, accessing external, external information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-domain question answering is a crucial task that often requires
accessing external information. Existing methods typically adopt a single-turn
retrieve-then-read approach, where relevant documents are first retrieved, and
questions are then answered based on the retrieved information. However, there
are cases where answering a question requires implicit knowledge that is not
directly retrievable from the question itself. In this work, we propose a novel
question-answering pipeline called eamSearchQA. Our approach leverages large
language models(LLMs) to iteratively generate new questions about the original
question, enabling an iterative reasoning process. By iteratively refining and
expanding the scope of the question, our method aims to capture and utilize
hidden knowledge that may not be directly obtainable through retrieval. We
evaluate our approach on the widely-used open-domain NQ and WebQ datasets. The
experimental results demonstrate that BeamSearchQA significantly outperforms
other zero-shot baselines, indicating its effectiveness in tackling the
challenges of open-domain question answering.</p>
  </details>
</details>
<details>
  <summary>178. <b>标题：Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in  Large Language Models</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14763</p>
  <p><b>作者</b>：Natalie Shapira,  Mosh Levy,  Seyed Hossein Alavi,  Xuhui Zhou,  Yejin Choi,  Yoav Goldberg,  Maarten Sap,  Vered Shwartz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：capabilities warrants developing, warrants developing reliable, developing reliable metrics, assess machine, escalating debate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The escalating debate on AI's capabilities warrants developing reliable
metrics to assess machine "intelligence". Recently, many anecdotal examples
were used to suggest that newer large language models (LLMs) like ChatGPT and
GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached
conflicting conclusions regarding those abilities. We investigate the extent of
LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs
exhibit certain N-ToM abilities, this behavior is far from being robust. We
further examine the factors impacting performance on N-ToM tasks and discover
that LLMs struggle with adversarial examples, indicating reliance on shallow
heuristics rather than robust ToM abilities. We caution against drawing
conclusions from anecdotal examples, limited benchmark testing, and using
human-designed psychological tests to evaluate models.</p>
  </details>
</details>
<details>
  <summary>179. <b>标题：UniChart: A Universal Vision-language Pretrained Model for Chart  Comprehension and Reasoning</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14761</p>
  <p><b>作者</b>：Ahmed Masry,  Parsa Kavehzadeh,  Xuan Long Do,  Enamul Hoque,  Shafiq Joty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visualizing key insights, visualizing key, tasks, popular for analyzing, key insights</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Charts are very popular for analyzing data, visualizing key insights and
answering complex reasoning questions about data. To facilitate chart-based
data analysis using natural language, several downstream tasks have been
introduced recently such as chart question answering and chart summarization.
However, most of the methods that solve these tasks use pretraining on language
or vision-language tasks that do not attempt to explicitly model the structure
of the charts (e.g., how data is visually encoded and how chart elements are
related to each other). To address this, we first build a large corpus of
charts covering a wide variety of topics and visual styles. We then present
UniChart, a pretrained model for chart comprehension and reasoning. UniChart
encodes the relevant text, data, and visual elements of charts and then uses a
chart-grounded text decoder to generate the expected output in natural
language. We propose several chart-specific pretraining tasks that include: (i)
low-level tasks to extract the visual elements (e.g., bars, lines) and data
from charts, and (ii) high-level tasks to acquire chart understanding and
reasoning skills. We find that pretraining the model on a large corpus with
chart-specific low- and high-level tasks followed by finetuning on three
down-streaming tasks results in state-of-the-art performance on three
downstream tasks.</p>
  </details>
</details>
<details>
  <summary>180. <b>标题：Bi-Drop: Generalizable Fine-tuning for Pre-trained Language Models via  Adaptive Subnetwork Optimization</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14760</p>
  <p><b>作者</b>：Shoujie Tong,  Heming Xia,  Damai Dai,  Tianyu Liu,  Binghuai Lin,  Yunbo Cao,  Zhifang Sui</p>
  <p><b>备注</b>：Work in progress. Co-first authors with equal contributions</p>
  <p><b>关键词</b>：achieved remarkable success, natural language understanding, language understanding tasks, achieved remarkable, remarkable success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models have achieved remarkable success in a variety of
natural language understanding tasks. Nevertheless, finetuning large pretrained
models on downstream tasks is susceptible to overfitting if the training set is
limited, which will lead to diminished performance. In this work, we propose a
dynamic fine-tuning strategy for pretrained language models called Bi-Drop. It
utilizes the gradient information of various sub-models generated by dropout to
update the model parameters selectively. Experiments on the GLUE benchmark show
that Bi-Drop outperforms previous fine-tuning methods by a considerable margin,
and exhibits consistent superiority over vanilla fine-tuning across various
pretrained models. Furthermore, empirical results indicate that Bi-Drop yields
substantial improvements in the multiple task or domain transfer, data
imbalance, and low-resource scenarios, demonstrating superb generalization
ability and robustness.</p>
  </details>
</details>
<details>
  <summary>181. <b>标题：Human-Centered Metrics for Dialog System Evaluation</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14757</p>
  <p><b>作者</b>：Salvatore Giorgi,  Shreya Havaldar,  Farhan Ahmed,  Zuhaib Akhtar,  Shalaka Vaidya,  Gary Pan,  Lyle H. Ungar,  H. Andrew Schwartz,  Joao Sedoc</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conversational agents express, short-term factors, longer-term factors, factors like personality, conversational agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present metrics for evaluating dialog systems through a
psychologically-grounded "human" lens: conversational agents express a
diversity of both states (short-term factors like emotions) and traits
(longer-term factors like personality) just as people do. These interpretable
metrics consist of five measures from established psychology constructs that
can be applied both across dialogs and on turns within dialogs: emotional
entropy, linguistic style and emotion matching, as well as agreeableness and
empathy. We compare these human metrics against 6 state-of-the-art automatic
metrics (e.g. BARTScore and BLEURT) on 7 standard dialog system data sets. We
also introduce a novel data set, the Three Bot Dialog Evaluation Corpus, which
consists of annotated conversations from ChatGPT, GPT-3, and BlenderBot. We
demonstrate the proposed human metrics offer novel information, are
uncorrelated with automatic metrics, and lead to increased accuracy beyond
existing automatic metrics for predicting crowd-sourced dialog judgements. The
interpretability and unique signal of our proposed human-centered framework
make it a valuable tool for evaluating and improving dialog systems.</p>
  </details>
</details>
<details>
  <summary>182. <b>标题：Don't Take This Out of Context! On the Need for Contextual Models and  Evaluations for Stylistic Rewriting</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14755</p>
  <p><b>作者</b>：Akhila Yerukola,  Xuhui Zhou,  Maarten Sap</p>
  <p><b>备注</b>：may 24 submission</p>
  <p><b>关键词</b>：stylistic text rewriting, rewriting methods operate, existing stylistic text, text rewriting methods, stylistic text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing stylistic text rewriting methods operate on a sentence level,
but ignoring the broader context of the text can lead to generic, ambiguous,
and incoherent rewrites. In this paper, we propose the integration of preceding
textual context into both the rewriting and evaluation stages of stylistic text
rewriting, focusing on formality, toxicity, and sentiment transfer tasks. We
conduct a comparative evaluation of rewriting through few-shot prompting of
GPT-3.5 and GPT NeoX, comparing non-contextual rewrites to contextual rewrites.
Our experiments show that humans often prefer contextual rewrites over
non-contextual ones, but automatic metrics (e.g., BLEU, sBERT) do not. To
bridge this gap, we propose context-infused versions of common automatic
metrics, and show that these better reflect human preferences. Overall, our
paper highlights the importance of integrating preceding textual context into
both the rewriting and evaluation stages of stylistic text rewriting.</p>
  </details>
</details>
<details>
  <summary>183. <b>标题：DialogVCS: Robust Natural Language Understanding in Dialogue System  Upgrade</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14751</p>
  <p><b>作者</b>：Zefan Cai,  Xin Zheng,  Tianyu Liu,  Xu Wang,  Haoran Meng,  Jiaqi Han,  Gang Yuan,  Binghuai Lin,  Baobao Chang,  Yunbo Cao</p>
  <p><b>备注</b>：work in progress. The first three authors contribute equally</p>
  <p><b>关键词</b>：natural language understanding, existent data accumulated, product dialogue systems, Dialogue Version Control, language understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the constant updates of the product dialogue systems, we need to retrain
the natural language understanding (NLU) model as new data from the real users
would be merged into the existent data accumulated in the last updates. Within
the newly added data, new intents would emerge and might have semantic
entanglement with the existing intents, e.g. new intents that are semantically
too specific or generic are actually subset or superset of some existing
intents in the semantic space, thus impairing the robustness of the NLU model.
As the first attempt to solve this problem, we setup a new benchmark consisting
of 4 Dialogue Version Control dataSets (DialogVCS). We formulate the intent
detection with imperfect data in the system update as a multi-label
classification task with positive but unlabeled intents, which asks the models
to recognize all the proper intents, including the ones with semantic
entanglement, in the inference. We also propose comprehensive baseline models
and conduct in-depth analyses for the benchmark, showing that the semantically
entangled intents can be effectively recognized with an automatic workflow.</p>
  </details>
</details>
<details>
  <summary>184. <b>标题：Mastering the ABCDs of Complex Questions: Answer-Based Claim  Decomposition for Fine-grained Self-Evaluation</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14750</p>
  <p><b>作者</b>：Nishant Balepur,  Jie Huang,  Samraj Moorjani,  Hari Sundaram,  Kevin Chen-Chuan Chang</p>
  <p><b>备注</b>：In progress preprint</p>
  <p><b>关键词</b>：large language models, answering complex questions, large language, answering complex, criteria</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When answering complex questions, large language models (LLMs) may produce
answers that do not satisfy all criteria of the question. While existing
self-evaluation techniques aim to detect if such answers are correct, these
techniques are unable to determine which criteria of the question are satisfied
by the generated answers. To address this issue, we propose answer-based claim
decomposition (ABCD), a prompting strategy that decomposes questions into a
series of true/false claims that can be used to verify which criteria of the
input question an answer satisfies. Using the decomposed ABCD claims, we
perform fine-grained self-evaluation. Through preliminary experiments on three
datasets, including a newly-collected challenge dataset ObscureQA, we find that
GPT-3.5 has some ability to determine to what extent its answer satisfies the
criteria of the input question, and can give insights into the errors and
knowledge gaps of the model.</p>
  </details>
</details>
<details>
  <summary>185. <b>标题：ECHo: Event Causality Inference via Human-centric Reasoning</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14740</p>
  <p><b>作者</b>：Yuxi Xie,  Guanzhen Li,  Min-Yen Kan</p>
  <p><b>备注</b>：Please find data and code at this https URL</p>
  <p><b>关键词</b>：event causality inference, causality inference grounded, event causality, causality inference, inference grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce ECHo, a diagnostic dataset of event causality inference grounded
in visual-and-linguistic social scenarios. ECHo employs real-world
human-centric deductive information collected from crime drama, bridging the
gap in multimodal reasoning towards higher social intelligence through the
elicitation of intermediate Theory-of-Mind (ToM). We propose a unified
framework aligned with the Chain-of-Thought (CoT) paradigm to assess the
reasoning capability of current AI systems. This ToM-enhanced CoT pipeline can
accommodate and integrate various large foundation models in zero-shot
visual-and-linguistic understanding. With this framework, we scrutinize the
advanced large language and multimodal models via three complementary
human-centric ECHo tasks. Further analysis demonstrates ECHo as a challenging
dataset to expose imperfections and inconsistencies in reasoning.</p>
  </details>
</details>
<details>
  <summary>186. <b>标题：Trusting Your Evidence: Hallucinate Less with Context-aware Decoding</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14739</p>
  <p><b>作者</b>：Weijia Shi,  Xiaochuang Han,  Mike Lewis,  Yulia Tsvetkov,  Luke Zettlemoyer,  Scott Wen-tau Yih</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：struggle to pay, pay enough attention, generate texts, input context, Language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models (LMs) often struggle to pay enough attention to the input
context, and generate texts that are unfaithful or contain hallucinations. To
mitigate this issue, we present context-aware decoding (CAD), which follows a
contrastive output distribution that amplifies the difference between the
output probabilities when a model is used with and without context. Our
experiments show that CAD, without additional training, significantly improves
the faithfulness of different LM families, including OPT, GPT, LLaMA and
FLAN-T5 for summarization tasks (e.g., 14.3% gain for LLaMA in factuality
metrics). Furthermore, CAD is particularly effective in overriding a model's
prior knowledge when it contradicts the provided context, leading to
substantial improvements in tasks where resolving the knowledge conflict is
essential.</p>
  </details>
</details>
<details>
  <summary>187. <b>标题：Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14735</p>
  <p><b>作者</b>：Vyoma Raman,  Eve Fleisig,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determine performance discrepancies, standard method, method for measuring, measuring the impacts, marginalized communities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A standard method for measuring the impacts of AI on marginalized communities
is to determine performance discrepancies between specified demographic groups.
These approaches aim to address harms toward vulnerable groups, but they
obscure harm patterns faced by intersectional subgroups or shared across
demographic groups. We instead operationalize "the margins" as data points that
are statistical outliers due to having demographic attributes distant from the
"norm" and measure harms toward these outliers. We propose a Group-Based
Performance Disparity Index (GPDI) that measures the extent to which a
subdivision of a dataset into subgroups identifies those facing increased
harms. We apply our approach to detecting disparities in toxicity detection and
find that text targeting outliers is 28% to 86% more toxic for all types of
toxicity examined. We also discover that model performance is consistently
worse for demographic outliers, with disparities in error between outliers and
non-outliers ranging from 28% to 71% across toxicity types. Our outlier-based
analysis has comparable or higher GPDI than traditional subgroup-based
analyses, suggesting that outlier analysis enhances identification of subgroups
facing greater harms. Finally, we find that minoritized racial and religious
groups are most associated with outliers, which suggests that outlier analysis
is particularly beneficial for identifying harms against those groups.</p>
  </details>
</details>
<details>
  <summary>188. <b>标题：Advancements in Arabic Grammatical Error Detection and Correction: An  Empirical Investigation</b></summary>
  <p><b>编号</b>：[399]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14734</p>
  <p><b>作者</b>：Bashar Alhafni,  Go Inoue,  Christian Khairallah,  Nizar Habash</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem in English, GEC, Arabic GEC, Grammatical error correction, well-explored problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Grammatical error correction (GEC) is a well-explored problem in English with
many existing models and datasets. However, research on GEC in morphologically
rich languages has been limited due to challenges such as data scarcity and
language complexity. In this paper, we present the first results on Arabic GEC
by using two newly developed Transformer-based pretrained sequence-to-sequence
models. We address the task of multi-class Arabic grammatical error detection
(GED) and present the first results on multi-class Arabic GED. We show that
using GED information as auxiliary input in GEC models improves GEC performance
across three datasets spanning different genres. Moreover, we also investigate
the use of contextual morphological preprocessing in aiding GEC systems. Our
models achieve state-of-the-art results on two Arabic GEC shared tasks datasets
and establish a strong benchmark on a newly created dataset.</p>
  </details>
</details>
<details>
  <summary>189. <b>标题：SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language  Representations</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14728</p>
  <p><b>作者</b>：Victoria Lin,  Louis-Philippe Morency</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：model decision-making process, recent years, decision-making process, dominant form, featurization in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although deep language representations have become the dominant form of
language featurization in recent years, in many settings it is important to
understand a model's decision-making process. This necessitates not only an
interpretable model but also interpretable features. In particular, language
must be featurized in a way that is interpretable while still characterizing
the original text well. We present SenteCon, a method for introducing human
interpretability in deep language representations. Given a passage of text,
SenteCon encodes the text as a layer of interpretable categories in which each
dimension corresponds to the relevance of a specific category. Our empirical
evaluations indicate that encoding language with SenteCon provides high-level
interpretability at little to no cost to predictive performance on downstream
tasks. Moreover, we find that SenteCon outperforms existing interpretable
language representations with respect to both its downstream performance and
its agreement with human characterizations of the text.</p>
  </details>
</details>
<details>
  <summary>190. <b>标题：In-Context Demonstration Selection with Cross Entropy Difference</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14726</p>
  <p><b>作者</b>：Dan Iter,  Reid Pryzant,  Ruochen Xu,  Shuohang Wang,  Yang Liu,  Yichong Xu,  Chenguang Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：in-context, Large language models, in-context demonstrations, Large language, demonstrations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) can use in-context demonstrations to improve
performance on zero-shot tasks. However, selecting the best in-context examples
is challenging because model performance can vary widely depending on the
selected examples. We present a cross-entropy difference (CED) method for
selecting in-context demonstrations. Our method is based on the observation
that the effectiveness of in-context demonstrations negatively correlates with
the perplexity of the test example by a language model that was finetuned on
that demonstration. We utilize parameter efficient finetuning to train small
models on training data that are used for computing the cross-entropy
difference between a test example and every candidate in-context demonstration.
This metric is used to rank and select in-context demonstrations independently
for each test input. We evaluate our method on a mix-domain dataset that
combines 8 benchmarks, representing 4 text generation tasks, showing that CED
for in-context demonstration selection can improve performance for a variety of
LLMs.</p>
  </details>
</details>
<details>
  <summary>191. <b>标题：AMELI: Enhancing Multimodal Entity Linking with Fine-Grained Attributes</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14725</p>
  <p><b>作者</b>：Barry Menglong Yao,  Yu Chen,  Qifan Wang,  Sijia Wang,  Minqian Liu,  Zhiyang Xu,  Licheng Yu,  Lifu Huang</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：multimodal entity linking, text description, multimodal knowledge base, attribute-aware multimodal entity, propose attribute-aware multimodal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose attribute-aware multimodal entity linking, where the input is a
mention described with a text and image, and the goal is to predict the
corresponding target entity from a multimodal knowledge base (KB) where each
entity is also described with a text description, a visual image and a set of
attributes and values. To support this research, we construct AMELI, a
large-scale dataset consisting of 18,472 reviews and 35,598 products. To
establish baseline performance on AMELI, we experiment with the current
state-of-the-art multimodal entity linking approaches and our enhanced
attribute-aware model and demonstrate the importance of incorporating the
attribute information into the entity linking process. To be best of our
knowledge, we are the first to build benchmark dataset and solutions for the
attribute-aware multimodal entity linking task. Datasets and codes will be made
publicly available.</p>
  </details>
</details>
<details>
  <summary>192. <b>标题：I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create  Visual Metaphors</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14724</p>
  <p><b>作者</b>：Tuhin Chakrabarty,  Arkadiy Saakyan,  Olivia Winn,  Artemis Panagopoulou,  Yue Yang,  Marianna Apidianaki,  Smaranda Muresan</p>
  <p><b>备注</b>：ACL 2023 (Findings)</p>
  <p><b>关键词</b>：powerful rhetorical devices, communicate creative ideas, linguistic metaphors, ideas through images, powerful rhetorical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual metaphors are powerful rhetorical devices used to persuade or
communicate creative ideas through images. Similar to linguistic metaphors,
they convey meaning implicitly through symbolism and juxtaposition of the
symbols. We propose a new task of generating visual metaphors from linguistic
metaphors. This is a challenging task for diffusion-based text-to-image models,
such as DALL$\cdot$E 2, since it requires the ability to model implicit meaning
and compositionality. We propose to solve the task through the collaboration
between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3
(davinci-002) with Chain-of-Thought prompting generates text that represents a
visual elaboration of the linguistic metaphor containing the implicit meaning
and relevant objects, which is then used as input to the diffusion-based
text-to-image models.Using a human-AI collaboration framework, where humans
interact both with the LLM and the top-performing diffusion model, we create a
high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic
metaphors and their associated visual elaborations. Evaluation by professional
illustrators shows the promise of LLM-Diffusion Model collaboration for this
this http URL evaluate the utility of our Human-AI collaboration framework and the
quality of our dataset, we perform both an intrinsic human-based evaluation and
an extrinsic evaluation using visual entailment as a downstream task.</p>
  </details>
</details>
<details>
  <summary>193. <b>标题：CuRIAM: Corpus re Interpretation and Metalanguage in U.S. Supreme Court  Opinions</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14719</p>
  <p><b>作者</b>：Michael Kranzlein,  Nathan Schneider,  Kevin Tobia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：judicial decisions involve, judicial opinion requires, judicial decisions, decisions involve, involve the interpretation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most judicial decisions involve the interpretation of legal texts; as such,
judicial opinion requires the use of language as a medium to comment on or draw
attention to other language. Language used this way is called metalanguage. We
develop an annotation schema for categorizing types of legal metalanguage and
apply our schema to a set of U.S. Supreme Court opinions, yielding a corpus
totaling 59k tokens. We remark on several patterns observed in the kinds of
metalanguage used by the justices.</p>
  </details>
</details>
<details>
  <summary>194. <b>标题：Improving Language Models with Advantage-based Offline Policy Gradients</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14718</p>
  <p><b>作者</b>：Ashutosh Baheti,  Ximing Lu,  Faeze Brahman,  Ronan Le Bras,  Maarten Sap,  Mark Riedl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constraints is challenging, user-defined quality, quality or style, style constraints, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving language model generations according to some user-defined quality
or style constraints is challenging. Typical approaches include learning on
additional human-written data, filtering ``low-quality'' data using heuristics
and/or using reinforcement learning with human feedback (RLHF). However,
filtering can remove valuable training signals, whereas data collection and
RLHF constantly require additional human-written or LM exploration data which
can be costly to obtain. A natural question to ask is ``Can we leverage RL to
optimize LM utility on existing crowd-sourced and internet data?''
To this end, we present Left-over Lunch RL (LoL-RL), a simple training
algorithm that uses offline policy gradients for learning language generation
tasks as a 1-step RL game. LoL-RL can finetune LMs to optimize arbitrary
classifier-based or human-defined utility functions on any sequence-to-sequence
data. Experiments with five different language generation tasks using models of
varying sizes and multiple rewards show that models trained with LoL-RL can
consistently outperform the best supervised learning models. We also release
our experimental code. this https URL</p>
  </details>
</details>
<details>
  <summary>195. <b>标题：Exploiting Correlations Between Contexts and Definitions with Multiple  Definition Modeling</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14717</p>
  <p><b>作者</b>：Linhan Zhang,  Qian Chen,  Wen Wang,  Yuxin Jiang,  Bing Li,  Wei Wang,  Xin Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced natural language, natural language applications, Single Definition Modeling, Definition modeling, Multiple Definition Modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Definition modeling is an important task in advanced natural language
applications such as understanding and conversation. Since its introduction, it
focus on generating one definition for a target word or phrase in a given
context, which we refer to as Single Definition Modeling (SDM). However, this
approach does not adequately model the correlations and patterns among
different contexts and definitions of words. In addition, the creation of a
training dataset for SDM requires significant human expertise and effort. In
this paper, we carefully design a new task called Multiple Definition Modeling
(MDM) that pool together all contexts and definition of target words. We
demonstrate the ease of creating a model as well as multiple training sets
automatically. % In the experiments, we demonstrate and analyze the benefits of
MDM, including improving SDM's performance by using MDM as the pretraining task
and its comparable performance in the zero-shot setting.</p>
  </details>
</details>
<details>
  <summary>196. <b>标题：GlobalBench: A Benchmark for Global Progress in Natural Language  Processing</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14716</p>
  <p><b>作者</b>：Yueqi Song,  Catherine Cui,  Simran Khanuja,  Pengfei Liu,  Fahim Faisal,  Alissa Ostapenko,  Genta Indra Winata,  Alham Fikri Aji,  Samuel Cahyawijaya,  Yulia Tsvetkov,  Antonios Anastasopoulos,  Graham Neubig</p>
  <p><b>备注</b>：Preprint, 9 pages</p>
  <p><b>关键词</b>：NLP system performance, significant disparities, languages, major advances, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the major advances in NLP, significant disparities in NLP system
performance across languages still exist. Arguably, these are due to uneven
resource allocation and sub-optimal incentives to work on less resourced
languages. To track and further incentivize the global development of equitable
language technology, we introduce GlobalBench. Prior multilingual benchmarks
are static and have focused on a limited number of tasks and languages. In
contrast, GlobalBench is an ever-expanding collection that aims to dynamically
track progress on all NLP datasets in all languages. Rather than solely
measuring accuracy, GlobalBench also tracks the estimated per-speaker utility
and equity of technology across all languages, providing a multi-faceted view
of how language technology is serving people of the world. Furthermore,
GlobalBench is designed to identify the most under-served languages, and
rewards research efforts directed towards those languages. At present, the most
under-served languages are the ones with a relatively high population, but
nonetheless overlooked by composite multilingual benchmarks (like Punjabi,
Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190
languages, and has 1,128 system submissions spanning 62 languages.</p>
  </details>
</details>
<details>
  <summary>197. <b>标题：Gender Biases in Automatic Evaluation Metrics: A Case Study on Image  Captioning</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14711</p>
  <p><b>作者</b>：Haoyi Qiu,  Zi-Yi Dou,  Tianlu Wang,  Asli Celikyilmaz,  Nanyun Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong performance, natural language generation, model-based evaluation metrics, Pretrained model-based evaluation, evaluation metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained model-based evaluation metrics have demonstrated strong
performance with high correlations with human judgments in various natural
language generation tasks such as image captioning. Despite the impressive
results, their impact on fairness is under-explored -- it is widely
acknowledged that pretrained models can encode societal biases, and utilizing
them for evaluation purposes may inadvertently manifest and potentially amplify
biases. In this paper, we conduct a systematic study in gender biases of
model-based evaluation metrics with a focus on image captioning tasks.
Specifically, we first identify and quantify gender biases in different
evaluation metrics regarding profession, activity, and object concepts. Then,
we demonstrate the negative consequences of using these biased metrics, such as
favoring biased generation models in deployment and propagating the biases to
generation models through reinforcement learning. We also present a simple but
effective alternative to reduce gender biases by combining n-gram
matching-based and pretrained model-based evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>198. <b>标题：Instructions as Backdoors: Backdoor Vulnerabilities of Instruction  Tuning for Large Language Models</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14710</p>
  <p><b>作者</b>：Jiashu Xu,  Mingyu Derek Ma,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve superior performance, superior performance, data, Instruction-tuned models, achieve superior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction-tuned models are trained on crowdsourcing datasets with task
instructions to achieve superior performance. However, in this work we raise
security concerns about this training paradigm. Our studies demonstrate that an
attacker can inject backdoors by issuing very few malicious instructions among
thousands of gathered data and control model behavior through data poisoning,
without even the need of modifying data instances or labels themselves. Through
such instruction attacks, the attacker can achieve over 90% attack success rate
across four commonly used NLP datasets, and cause persistent backdoors that are
easily transferred to 15 diverse datasets zero-shot. In this way, the attacker
can directly apply poisoned instructions designed for one dataset on many other
datasets. Moreover, the poisoned model cannot be cured by continual learning.
Lastly, instruction attacks show resistance to existing inference-time defense.
These findings highlight the need for more robust defenses against data
poisoning attacks in instructiontuning models and underscore the importance of
ensuring data quality in instruction crowdsourcing.</p>
  </details>
</details>
<details>
  <summary>199. <b>标题：The student becomes the master: Matching GPT3 on Scientific Factual  Error Correction</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14707</p>
  <p><b>作者</b>：Dhananjay Ashok,  Atharva Kulkarni,  Hai Pham,  Barnabás Póczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Factual Claim Correction, prohibitively high cost, creating error correction, Scientific Claim Correction, Factual Claim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the prohibitively high cost of creating error correction datasets,
most Factual Claim Correction methods rely on a powerful verification model to
guide the correction process. This leads to a significant drop in performance
in domains like Scientific Claim Correction, where good verification models do
not always exist. In this work, we introduce a claim correction system that
makes no domain assumptions and does not require a verifier but is able to
outperform existing methods by an order of magnitude -- achieving 94%
correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open
dataset, compared to the next best methods 0.5% and 1.50% respectively. Our
method leverages the power of prompting with LLMs during training to create a
richly annotated dataset that can be used for fully supervised training and
regularization. We additionally use a claim-aware decoding procedure to improve
the quality of corrected claims. Our method is competitive with the very LLM
that was used to generate the annotated dataset -- with GPT3.5 achieving 89.5%
and 60% correction accuracy on SciFact and SciFact-Open, despite using 1250
times as many parameters as our model.</p>
  </details>
</details>
<details>
  <summary>200. <b>标题：Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse  Mixture of Experts</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14705</p>
  <p><b>作者</b>：Sheng Shen,  Le Hou,  Yanqi Zhou,  Nan Du,  Shayne Longpre,  Jason Wei,  Hyung Won Chung,  Barret Zoph,  William Fedus,  Xinyun Chen,  Tu Vu,  Yuexin Wu,  Wuyang Chen,  Albert Webson,  Yunxuan Li,  Vincent Zhao,  Hongkun Yu,  Kurt Keutzer,  Trevor Darrell,  Denny Zhou</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：scalable methods, explosive growth, applications have led, increased demand, demand for efficient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The explosive growth of language models and their applications have led to an
increased demand for efficient and scalable methods. In this paper, we
introduce Flan-MoE, a set of Instruction-Finetuned Sparse Mixture-of-Expert
(MoE) models. We show that naively finetuning MoE models on a task-specific
dataset (in other words, no instruction-finetuning) often yield worse
performance compared to dense models of the same computational complexity.
However, our Flan-MoE outperforms dense models under multiple experiment
settings: instruction-finetuning only and instruction-finetuning followed by
task-specific finetuning. This shows that instruction-finetuning is an
essential stage for MoE models. Specifically, our largest model, Flan-MoE-32B,
surpasses the performance of Flan-PaLM-62B on four benchmarks, while utilizing
only one-third of the FLOPs. The success of Flan-MoE encourages rethinking the
design of large-scale, high-performance language models, under the setting of
task-agnostic learning.</p>
  </details>
</details>
<details>
  <summary>201. <b>标题：Analyzing Influential Factors in Human Preference Judgments via GPT-4</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14702</p>
  <p><b>作者</b>：Yebowen Hu,  Kaiqiang Song,  Sangwoo Cho,  Xiaoyang Wang,  Hassan Foroosh,  Fei Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：guiding large language, large language models, pivotal in guiding, guiding large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pairwise human judgments are pivotal in guiding large language models (LLMs)
to generate outputs that align with human preferences. They are also often used
in summarization evaluation, complementing existing automatic metrics. Despite
their significance, however, there has been limited research probing these
pairwise human judgments. The collective impact and respective weights of
factors such as informativeness, coherence, fluency, and factual consistency
remain elusive. The impact of hidden factors on the final judgment is also
unclear. In this paper, we conduct an in-depth examination of a dataset of
pairwise human judgments released by OpenAI. Utilizing the Bradley-Terry-Luce
model, we identify key factors that could potentially influence human
judgments. Our research uncovers the inherent preferences embedded in human
judgments and suggests strategies to boost sample efficiency. Finally, we
provide insights on the construction of balanced datasets for human judgment
evaluations, a crucial step in shaping the behaviors of future LLMs.</p>
  </details>
</details>
<details>
  <summary>202. <b>标题：Modeling rapid language learning by distilling Bayesian priors into  artificial neural networks</b></summary>
  <p><b>编号</b>：[427]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14701</p>
  <p><b>作者</b>：R. Thomas McCoy,  Thomas L. Griffiths</p>
  <p><b>备注</b>：21 pages plus references; 4 figures</p>
  <p><b>关键词</b>：Bayesian model, neural network, remarkably little experience, Bayesian, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans can learn languages from remarkably little experience. Developing
computational models that explain this ability has been a major challenge in
cognitive science. Bayesian models that build in strong inductive biases -
factors that guide generalization - have been successful at explaining how
humans might generalize from few examples in controlled settings but are
usually too restrictive to be tractably applied to more naturalistic data. By
contrast, neural networks have flexible representations that allow them to
learn well from naturalistic data but require many more examples than humans
receive. We show that learning from limited naturalistic data is possible with
an approach that combines the strong inductive biases of a Bayesian model with
the flexible representations of a neural network. This approach works by
distilling a Bayesian model's biases into a neural network. Like a Bayesian
model, the resulting system can learn formal linguistic patterns from a small
number of examples. Like a neural network, it can also learn aspects of English
syntax from a corpus of natural language - and it outperforms a standard neural
network at acquiring the linguistic phenomena of recursion and priming.
Bridging the divide between Bayesian models and neural networks makes it
possible to handle a broader range of learning scenarios than either approach
can handle on its own.</p>
  </details>
</details>
<details>
  <summary>203. <b>标题：SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to  Rank</b></summary>
  <p><b>编号</b>：[430]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14696</p>
  <p><b>作者</b>：Dheeraj Mekala,  Adithya Samavedhi,  Chengyu Dong,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：OOD detection, Deep neural classifiers, neural classifiers trained, OOD detection methods, supervised OOD detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural classifiers trained with cross-entropy loss (CE loss) often
suffer from poor calibration, necessitating the task of out-of-distribution
(OOD) detection. Traditional supervised OOD detection methods require expensive
manual annotation of in-distribution and OOD samples. To address the annotation
bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that
requires only in-distribution samples as supervision. We cast OOD detection as
an inter-document intra-label (IDIL) ranking problem and train the classifier
with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a
set of in-distribution documents and their labels, for each label, we train the
classifier to rank the softmax scores of documents belonging to that label to
be higher than the scores of documents that belong to other labels. Unlike CE
loss, our IDIL loss function reaches zero when the desired confidence ranking
is achieved and gradients are backpropagated to decrease probabilities
associated with incorrect labels rather than continuously increasing the
probability of the correct label. Extensive experiments with several
classifiers on multiple classification datasets demonstrate the effectiveness
of our method in both coarse- and fine-grained settings.</p>
  </details>
</details>
<details>
  <summary>204. <b>标题：A Causal View of Entity Bias in (Large) Language Models</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14695</p>
  <p><b>作者</b>：Fei Wang,  Wenjie Mo,  Yiwei Wang,  Wenxuan Zhou,  Muhao Chen</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：widely affects pretrained, bias widely affects, make unfaithful predictions, Entity bias widely, mitigate entity bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity bias widely affects pretrained (large) language models, causing them
to excessively rely on (biased) parametric knowledge to make unfaithful
predictions. Although causality-inspired methods have shown great potential to
mitigate entity bias, it is hard to precisely estimate the parameters of
underlying causal models in practice. The rise of black-box LLMs also makes the
situation even worse, because of their inaccessible parameters and uncalibrated
logits. To address these problems, we propose a specific structured causal
model (SCM) whose parameters are comparatively easier to estimate. Building
upon this SCM, we propose causal intervention techniques to mitigate entity
bias for both white-box and black-box settings. The proposed causal
intervention perturbs the original entity with neighboring entities. This
intervention reduces specific biasing information pertaining to the original
entity while still preserving sufficient common predictive information from
similar entities. When evaluated on the relation extraction task, our
training-time intervention significantly improves the F1 score of RoBERTa by
5.7 points on EntRED, in which spurious shortcuts between entities and labels
are removed. Meanwhile, our in-context intervention effectively reduces the
knowledge conflicts between parametric knowledge and contextual knowledge in
GPT-3.5 and improves the F1 score by 9.14 points on a challenging test set
derived from Re-TACRED.</p>
  </details>
</details>
<details>
  <summary>205. <b>标题：Have Large Language Models Developed a Personality?: Applicability of  Self-Assessment Tests in Measuring Personality in LLMs</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14693</p>
  <p><b>作者</b>：Xiaoyang Song,  Akshat Gupta,  Kiyan Mohebbizadeh,  Shujie Hu,  Anant Singh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, personality, Language Models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Have Large Language Models (LLMs) developed a personality? The short answer
is a resounding "We Don't Know!". In this paper, we show that we do not yet
have the right tools to measure personality in language models. Personality is
an important characteristic that influences behavior. As LLMs emulate
human-like intelligence and performance in various tasks, a natural question to
ask is whether these models have developed a personality. Previous works have
evaluated machine personality through self-assessment personality tests, which
are a set of multiple-choice questions created to evaluate personality in
humans. A fundamental assumption here is that human personality tests can
accurately measure personality in machines. In this paper, we investigate the
emergence of personality in five LLMs of different sizes ranging from 1.5B to
30B. We propose the Option-Order Symmetry property as a necessary condition for
the reliability of these self-assessment tests. Under this condition, the
answer to self-assessment questions is invariant to the order in which the
options are presented. We find that many LLMs personality test responses do not
preserve option-order symmetry. We take a deeper look at LLMs test responses
where option-order symmetry is preserved to find that in these cases, LLMs do
not take into account the situational statement being tested and produce the
exact same answer irrespective of the situation being tested. We also identify
the existence of inherent biases in these LLMs which is the root cause of the
aforementioned phenomenon and makes self-assessment tests unreliable. These
observations indicate that self-assessment tests are not the correct tools to
measure personality in LLMs. Through this paper, we hope to draw attention to
the shortcomings of current literature in measuring personality in LLMs and
call for developing tools for machine personality measurement.</p>
  </details>
</details>
<details>
  <summary>206. <b>标题：ExpertPrompting: Instructing Large Language Models to be Distinguished  Experts</b></summary>
  <p><b>编号</b>：[437]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14688</p>
  <p><b>作者</b>：Benfeng Xu,  An Yang,  Junyang Lin,  Quan Wang,  Chang Zhou,  Yongdong Zhang,  Zhendong Mao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligned large language, large language model, crafting of prompts, aligned large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The answering quality of an aligned large language model (LLM) can be
drastically improved if treated with proper crafting of prompts. In this paper,
we propose ExpertPrompting to elicit the potential of LLMs to answer as
distinguished experts. We first utilize In-Context Learning to automatically
synthesize detailed and customized descriptions of the expert identity for each
specific instruction, and then ask LLMs to provide answer conditioned on such
agent background. Based on this augmented prompting strategy, we produce a new
set of instruction-following data using GPT-3.5, and train a competitive
open-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation
to show that 1) the expert data is of significantly higher quality than vanilla
answers, and 2) ExpertLLaMA outperforms existing open-source opponents and
achieves 96\% of the original ChatGPT's capability. All data and the
ExpertLLaMA model will be made publicly available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>207. <b>标题：TACR: A Table-alignment-based Cell-selection and Reasoning Model for  Hybrid Question-Answering</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14682</p>
  <p><b>作者</b>：Jian Wu,  Yicheng Xu,  Yan Gao,  Jian-Guang Lou,  Börje F. Karlsson,  Manabu Okumura</p>
  <p><b>备注</b>：Accepted at Findings of ACL 2023</p>
  <p><b>关键词</b>：witnessed significant research, recent years, witnessed significant, significant research, research in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hybrid Question-Answering (HQA), which targets reasoning over tables and
passages linked from table cells, has witnessed significant research in recent
years. A common challenge in HQA and other passage-table QA datasets is that it
is generally unrealistic to iterate over all table rows, columns, and linked
passages to retrieve evidence. Such a challenge made it difficult for previous
studies to show their reasoning ability in retrieving answers. To bridge this
gap, we propose a novel Table-alignment-based Cell-selection and Reasoning
model (TACR) for hybrid text and table QA, evaluated on the HybridQA and
WikiTableQuestions datasets. In evidence retrieval, we design a
table-question-alignment enhanced cell-selection method to retrieve
fine-grained evidence. In answer reasoning, we incorporate a QA module that
treats the row containing selected cells as context. Experimental results over
the HybridQA and WikiTableQuestions (WTQ) datasets show that TACR achieves
state-of-the-art results on cell selection and outperforms fine-grained
evidence retrieval baselines on HybridQA, while achieving competitive
performance on WTQ. We also conducted a detailed analysis to demonstrate that
being able to align questions to tables in the cell-selection stage can result
in important gains from experiments of over 90\% table row and column selection
accuracy, meanwhile also improving output explainability.</p>
  </details>
</details>
<details>
  <summary>208. <b>标题：Emergent inabilities? Inverse scaling over the course of pretraining</b></summary>
  <p><b>编号</b>：[444]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14681</p>
  <p><b>作者</b>：James A. Michaelov,  Benjamin K. Bergen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model parameter size, occur, parameter size, training, performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Does inverse scaling only occur as a function of model parameter size, or can
it also occur over the course of training? We carry out an exploratory study
investigating whether, over the course of training on the language modeling
task, the performance of language models at specific tasks can decrease while
general performance remains high. We find that for two tasks from the Inverse
Scaling Challenge - quote-repetition and redefine-math - this is indeed the
case. Specifically, we find that for Pythia (Biderman et al., 2023) models with
a higher number of parameters, performance decreases over the course of
training at these two tasks, despite these models showing standard (positive)
scaling overall. This highlights the importance of testing model performance at
all relevant benchmarks any time they are trained on additional data, even if
their overall performance improves.</p>
  </details>
</details>
<details>
  <summary>209. <b>标题：GRILL: Grounded Vision-language Pre-training via Aligning Text and Image  Regions</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14676</p>
  <p><b>作者</b>：Woojeong Jin,  Subhabrata Mukherjee,  Yu Cheng,  Yelong Shen,  Weizhu Chen,  Ahmed Hassan Awadallah,  Damien Jose,  Xiang Ren</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：important ability, learners to achieve, tasks, Generalization to unseen, grounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization to unseen tasks is an important ability for few-shot learners
to achieve better zero-/few-shot performance on diverse tasks. However, such
generalization to vision-language tasks including grounding and generation
tasks has been under-explored; existing few-shot VL models struggle to handle
tasks that involve object grounding and multiple images such as visual
commonsense reasoning or NLVR2. In this paper, we introduce GRILL, GRounded
vIsion Language aLigning, a novel VL model that can be generalized to diverse
tasks including visual question answering, captioning, and grounding tasks with
no or very few training instances. Specifically, GRILL learns object grounding
and localization by exploiting object-text alignments, which enables it to
transfer to grounding tasks in a zero-/few-shot fashion. We evaluate our model
on various zero-/few-shot VL tasks and show that it consistently surpasses the
state-of-the-art few-shot methods.</p>
  </details>
</details>
<details>
  <summary>210. <b>标题：Quantifying Character Similarity with Vision Transformers</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14672</p>
  <p><b>作者</b>：Xinmei Yang,  Abhishek Arora,  Shao-Yu Jheng,  Melissa Dell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantitative social science, require linking data, noisy sources, social science, data from multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Record linkage is a bedrock of quantitative social science, as analyses often
require linking data from multiple, noisy sources. Off-the-shelf string
matching methods are widely used, as they are straightforward and cheap to
implement and scale. Not all character substitutions are equally probable, and
for some settings there are widely used handcrafted lists denoting which string
substitutions are more likely, that improve the accuracy of string matching.
However, such lists do not exist for many settings, skewing research with
linked datasets towards a few high-resource contexts that are not
representative of the diversity of human societies. This study develops an
extensible way to measure character substitution costs for OCR'ed documents, by
employing large-scale self-supervised training of vision transformers (ViT)
with augmented digital fonts. For each language written with the CJK script, we
contrastively learn a metric space where different augmentations of the same
character are represented nearby. In this space, homoglyphic characters - those
with similar appearance such as ``O'' and ``0'' - have similar vector
representations. Using the cosine distance between characters' representations
as the substitution cost in an edit distance matching algorithm significantly
improves record linkage compared to other widely used string matching methods,
as OCR errors tend to be homoglyphic in nature. Homoglyphs can plausibly
capture character visual similarity across any script, including low-resource
settings. We illustrate this by creating homoglyph sets for 3,000 year old
ancient Chinese characters, which are highly pictorial. Fascinatingly, a ViT is
able to capture relationships in how different abstract concepts were
conceptualized by ancient societies, that have been noted in the archaeological
literature.</p>
  </details>
</details>
<details>
  <summary>211. <b>标题：Diffusion Models in NLP: A Survey</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14671</p>
  <p><b>作者</b>：Hao Zou,  Zae Myung Kim,  Dongyeop Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diffusion models, models, diffusion, NLP, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP.</p>
  </details>
</details>
<details>
  <summary>212. <b>标题：You Are What You Annotate: Towards Better Models through Annotator  Representations</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14663</p>
  <p><b>作者</b>：Naihao Deng,  Siyang Liu,  Xinliang Frederick Zhang,  Winston Wu,  Lu Wang,  Rada Mihalcea</p>
  <p><b>备注</b>：19 pages</p>
  <p><b>关键词</b>：natural language processing, language processing, ubiquitous in natural, natural language, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotator disagreement is ubiquitous in natural language processing (NLP)
tasks. There are multiple reasons for such disagreements, including the
subjectivity of the task, difficult cases, unclear guidelines, and so on.
Rather than simply aggregating labels to obtain data annotations, we instead
propose to explicitly account for the annotator idiosyncrasies and leverage
them in the modeling process. We create representations for the annotators
(annotator embeddings) and their annotations (annotation embeddings) with
learnable matrices associated with each. Our approach significantly improves
model performance on various NLP benchmarks by adding fewer than 1% model
parameters. By capturing the unique tendencies and subjectivity of individual
annotators, our embeddings help democratize AI and ensure that AI models are
inclusive of diverse viewpoints.</p>
  </details>
</details>
<details>
  <summary>213. <b>标题：Complex Mathematical Symbol Definition Structures: A Dataset and Model  for Coordination Resolution in Definition Extraction</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14660</p>
  <p><b>作者</b>：Anna Martin-Boyle,  Andrew Head,  Kyle Lo,  Risham Sidhu,  Marti A. Hearst,  Dongyeop Kang</p>
  <p><b>备注</b>：9 pages, 4 figures</p>
  <p><b>关键词</b>：improving scholarly reading, scholarly reading interfaces, important for improving, reading interfaces, scholarly information extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical symbol definition extraction is important for improving
scholarly reading interfaces and scholarly information extraction (IE).
However, the task poses several challenges: math symbols are difficult to
process as they are not composed of natural language morphemes; and scholarly
papers often contain sentences that require resolving complex coordinate
structures. We present SymDef, an English language dataset of 5,927 sentences
from full-text scientific papers where each sentence is annotated with all
mathematical symbols linked with their corresponding definitions. This dataset
focuses specifically on complex coordination structures such as "respectively"
constructions, which often contain overlapping definition spans. We also
introduce a new definition extraction method that masks mathematical symbols,
creates a copy of each sentence for each symbol, specifies a target symbol, and
predicts its corresponding definition spans using slot filling. Our experiments
show that our definition extraction model significantly outperforms RoBERTa and
other strong IE baseline systems by 10.9 points with a macro F1 score of 84.82.
With our dataset and model, we can detect complex definitions in scholarly
documents to make scientific writing more readable.</p>
  </details>
</details>
<details>
  <summary>214. <b>标题：InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration  in Improving the Performance of Information Extraction</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14659</p>
  <p><b>作者</b>：Ishani Mondal,  Michelle Yuan,  Anandhavelu N,  Aparna Garimella,  Francis Ferraro,  Andrew Blair-Stanek,  Benjamin Van Durme,  Jordan Boyd-Graber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Learning template based, difficult task, crucial yet difficult, based information extraction, template based information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning template based information extraction from documents is a crucial
yet difficult task. Prior template-based IE approaches assume foreknowledge of
the domain templates; however, real-world IE do not have pre-defined schemas
and it is a figure-out-as you go phenomena. To quickly bootstrap templates in a
real-world setting, we need to induce template slots from documents with zero
or minimal supervision. Since the purpose of question answering intersect with
the goal of information extraction, we use automatic question generation to
induce template slots from the documents and investigate how a tiny amount of a
proxy human-supervision on-the-fly (termed as InteractiveIE) can further boost
the performance. Extensive experiments on biomedical and legal documents, where
obtaining training data is expensive, reveal encouraging trends of performance
improvement using InteractiveIE over AI-only baseline.</p>
  </details>
</details>
<details>
  <summary>215. <b>标题：Evaluate What You Can't Evaluate: Unassessable Generated Responses  Quality</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14658</p>
  <p><b>作者</b>：Yongkang Liu,  Shi Feng,  Daling Wang,  Yifei Zhang,  Hinrich Schütze</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：large language models, remarkable language understanding, shown remarkable language, large language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LLMs (large language models) such as ChatGPT have shown remarkable language
understanding and generation capabilities. Although reference-free evaluators
based on LLMs show better human alignment than traditional reference-based
evaluators, there are many challenges in using reference-free evaluators based
on LLMs. Reference-free evaluators are more suitable for open-ended examples
with different semantics responses. But not all examples are open-ended. For
closed-ended examples with unique correct semantic response, reference-free
evaluators will still consider it high quality when giving a response that is
inconsistent with the facts and the semantic of reference. In order to
comprehensively evaluate the reliability of evaluators based on LLMs, we
construct two adversarial meta-evaluation dialogue generation datasets
KdConv-ADV and DSTC7-ADV based on KdConv and DSTC7-AVSD, respectively. Compared
to previous meta-evaluation benchmarks, KdConv-ADV and DSTC7-ADV are much more
challenging since they requires evaluators to be able to reasonably evaluate
closed-ended examples with the help of external knowledge or even its own
knowledge. Empirical results show that the ability of LLMs to identify
unreasonable responses is insufficient. There are risks in using eference-free
evaluators based on LLMs to evaluate the quality of dialogue responses.</p>
  </details>
</details>
<details>
  <summary>216. <b>标题：Denoising Bottleneck with Mutual Information Maximization for Video  Multimodal Fusion</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14652</p>
  <p><b>作者</b>：Shaoxaing Wu,  Damai Dai,  Ziwei Qin,  Tianyu Liu,  Binghuai Lin,  Yunbo Cao,  Zhifang Sui</p>
  <p><b>备注</b>：Accept at ACL2023</p>
  <p><b>关键词</b>：integrate multimodal signals, aims to integrate, make a complementary, complementary prediction, multiple modalities contents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video multimodal fusion aims to integrate multimodal signals in videos, such
as visual, audio and text, to make a complementary prediction with multiple
modalities contents. However, unlike other image-text multimodal tasks, video
has longer multimodal sequences with more redundancy and noise in both visual
and audio modalities. Prior denoising methods like forget gate are coarse in
the granularity of noise filtering. They often suppress the redundant and noisy
information at the risk of losing critical information. Therefore, we propose a
denoising bottleneck fusion (DBF) model for fine-grained video multimodal
fusion. On the one hand, we employ a bottleneck mechanism to filter out noise
and redundancy with a restrained receptive field. On the other hand, we use a
mutual information maximization module to regulate the filter-out module to
preserve key information within different modalities. Our DBF model achieves
significant improvement over current state-of-the-art baselines on multiple
benchmarks covering multimodal sentiment analysis and multimodal summarization
tasks. It proves that our model can effectively capture salient features from
noisy and redundant video, audio, and text inputs. The code for this paper is
publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>217. <b>标题：Revisit and Outstrip Entity Alignment: A Perspective of Generative  Models</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14651</p>
  <p><b>作者</b>：Lingbing Guo,  Zhuo Chen,  Jiaoyan Chen,  Huajun Chen</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：achieved great successes, Recent embedding-based methods, entity alignment, knowledge graph, embeddings of multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent embedding-based methods have achieved great successes on exploiting
entity alignment from knowledge graph (KG) embeddings of multiple modals. In
this paper, we study embedding-based entity alignment (EEA) from a perspective
of generative models. We show that EEA is a special problem where the main
objective is analogous to that in a typical generative model, based on which we
theoretically prove the effectiveness of the recently developed generative
adversarial network (GAN)-based EEA methods. We then reveal that their
incomplete objective limits the capacity on both entity alignment and entity
synthesis (i.e., generating new entities). We mitigate this problem by
introducing a generative EEA (abbr., GEEA) framework with the proposed mutual
variational autoencoder (M-VAE) as the generative model. M-VAE can convert an
entity from one KG to another and generate new entities from random noise
vectors. We demonstrate the power of GEEA with theoretical analysis and
empirical experiments on both entity alignment and entity synthesis tasks.</p>
  </details>
</details>
<details>
  <summary>218. <b>标题：Meta-review Generation with Checklist-guided Iterative Introspection</b></summary>
  <p><b>编号</b>：[466]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14647</p>
  <p><b>作者</b>：Qi Zeng,  Mankeerat Sidhu,  Hou Pong Chan,  Lu Wang,  Heng Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leading to controversy, consensus among reviewers, controversy or consensus, scientific opinion summarization, current opinion summarization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Opinions in the scientific domain can be divergent, leading to controversy or
consensus among reviewers. However, current opinion summarization datasets
mostly focus on product review domains, which do not account for this
variability under the assumption that the input opinions are non-controversial.
To address this gap, we propose the task of scientific opinion summarization,
where research paper reviews are synthesized into meta-reviews. To facilitate
this task, we introduce a new ORSUM dataset covering 10,989 paper meta-reviews
and 40,903 paper reviews from 39 conferences. Furthermore, we propose the
Checklist-guided Iterative Introspection (CGI$^2$) approach, which breaks down
the task into several stages and iteratively refines the summary under the
guidance of questions from a checklist. We conclude that (1) human-written
summaries are not always reliable since many do not follow the guideline, and
(2) the combination of task decomposition and iterative self-refinement shows
promising discussion involvement ability and can be applied to other complex
text generation using black-box LLM.</p>
  </details>
</details>
<details>
  <summary>219. <b>标题：Iteratively Improving Biomedical Entity Linking and Event Extraction via  Hard Expectation-Maximization</b></summary>
  <p><b>编号</b>：[467]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14645</p>
  <p><b>作者</b>：Xiaochu Li,  Minqian Liu,  Zhiyang Xu,  Lifu Huang</p>
  <p><b>备注</b>：15 pages, 3 figures, 10 tables</p>
  <p><b>关键词</b>：support text understanding, Biomedical entity linking, entity linking, event extraction, Biomedical entity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biomedical entity linking and event extraction are two crucial tasks to
support text understanding and retrieval in the biomedical domain. These two
tasks intrinsically benefit each other: entity linking disambiguates the
biomedical concepts by referring to external knowledge bases and the domain
knowledge further provides additional clues to understand and extract the
biological processes, while event extraction identifies a key trigger and
entities involved to describe each biological process which also captures the
structural context to better disambiguate the biomedical entities. However,
previous research typically solves these two tasks separately or in a pipeline,
leading to error propagation. What's more, it's even more challenging to solve
these two tasks together as there is no existing dataset that contains
annotations for both tasks. To solve these challenges, we propose joint
biomedical entity linking and event extraction by regarding the event
structures and entity references in knowledge bases as latent variables and
updating the two task-specific models in a hard Expectation-Maximization (EM)
fashion: (1) predicting the missing variables for each partially annotated
dataset based on the current two task-specific models, and (2) updating the
parameters of each model on the corresponding pseudo completed dataset.
Experimental results on two benchmark datasets: Genia 2011 for event extraction
and BC4GO for entity linking, show that our joint framework significantly
improves the model for each individual task and outperforms the strong
baselines for both tasks. We will make the code and model checkpoints publicly
available once the paper is accepted.</p>
  </details>
</details>
<details>
  <summary>220. <b>标题：CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14635</p>
  <p><b>作者</b>：Yan Zhou,  Qingkai Fang,  Yang Feng</p>
  <p><b>备注</b>：ACL 2023 main conference</p>
  <p><b>关键词</b>：translating speech signals, source language, target language, modality gap, Optimal Transport CMOT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end speech translation (ST) is the task of translating speech signals
in the source language into text in the target language. As a cross-modal task,
end-to-end ST is difficult to train with limited data. Existing methods often
try to transfer knowledge from machine translation (MT), but their performances
are restricted by the modality gap between speech and text. In this paper, we
propose Cross-modal Mixup via Optimal Transport CMOT to overcome the modality
gap. We find the alignment between speech and text sequences via optimal
transport and then mix up the sequences from different modalities at a token
level using the alignment. Experiments on the MuST-C ST benchmark demonstrate
that CMOT achieves an average BLEU of 30.0 in 8 translation directions,
outperforming previous methods. Further analysis shows CMOT can adaptively find
the alignment between modalities, which helps alleviate the modality gap
between speech and text. Code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>221. <b>标题：Testing Causal Models of Word Meaning in GPT-3 and -4</b></summary>
  <p><b>编号</b>：[474]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14630</p>
  <p><b>作者</b>：Sam Musker,  Ellie Pavlick</p>
  <p><b>备注</b>：Unabridged version. Code available at this https URL</p>
  <p><b>关键词</b>：driven extraordinary improvements, improvements in NLP, Large Language Models, driven extraordinary, extraordinary improvements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have driven extraordinary improvements in NLP.
However, it is unclear how such models represent lexical concepts-i.e., the
meanings of the words they use. This paper evaluates the lexical
representations of GPT-3 and GPT-4 through the lens of HIPE theory, a theory of
concept representations which focuses on representations of words describing
artifacts (such as "mop", "pencil", and "whistle"). The theory posits a causal
graph that relates the meanings of such words to the form, use, and history of
the objects to which they refer. We test LLMs using the same stimuli originally
used by Chaigneau et al. (2004) to evaluate the theory in humans, and consider
a variety of prompt designs. Our experiments concern judgements about causal
outcomes, object function, and object naming. We find no evidence that GPT-3
encodes the causal structure hypothesized by HIPE, but do find evidence that
GPT-4 encodes such structure. The results contribute to a growing body of
research characterizing the representational capacity of large language models.</p>
  </details>
</details>
<details>
  <summary>222. <b>标题：Mixture of Prompt Experts for Generalizable and Interpretable Question  Answering</b></summary>
  <p><b>编号</b>：[476]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14628</p>
  <p><b>作者</b>：Chenglei Si,  Weijia Shi,  Chen Zhao,  Luke Zettlemoyer,  Jordan Boyd-Graber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ultimate quests, question, question types, specialized, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the ultimate quests of question answering (QA) is to deploy a system
that can answer any type of question from the users, and refrain from answering
when it does not know the answer. While recent advancements in scaling large
language models (LLMs) brought significant improvements on various QA datasets,
it remains difficult for a single model to generalize across question types
that require distinct reasoning abilities. In this paper, we first provide
empirical evidence that state-of-the-art LLMs such as Codex suffer from poor
generalizability on question types beyond those seen in the prompt. To address
this, we propose a Mixture-of-Prompt-Experts (MOPE) system that ensembles
multiple specialized LLMs. We first implement each specialized model based on
the same backbone model (Codex) but with prompts optimized for different
reasoning categories including factual, multihop, mathematical, and commonsense
reasoning. By strategically selecting the best specialized model for each given
question, our MOPE system significantly outperforms any single specialized
model on a collection of 12 QA datasets from four reasoning types. Moreover,
the attribution and agreement among specialized expert models offer greater
interpretability, allowing for better selective question answering. Our human
study further confirms that presenting the expert predictions and answer
selection process helps annotators more accurately decide when to trust the
system's output. We release all code and data to facilitate future work.</p>
  </details>
</details>
<details>
  <summary>223. <b>标题：Enabling Large Language Models to Generate Text with Citations</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14627</p>
  <p><b>作者</b>：Tianyu Gao,  Howard Yen,  Jiatong Yu,  Danqi Chen</p>
  <p><b>备注</b>：Code and data are available at this https URL</p>
  <p><b>关键词</b>：Large language models, Large language, prone to hallucination, widely-used tool, generated outputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have emerged as a widely-used tool for
information seeking, but their generated outputs are prone to hallucination. In
this work, we aim to enable LLMs to generate text with citations, improving
their factual correctness and verifiability. Existing work mainly relies on
commercial search engines and human evaluation, making it challenging to
reproduce and compare with different modeling approaches. We propose ALCE, the
first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a
diverse set of questions and retrieval corpora and requires building end-to-end
systems to retrieve supporting evidence and generate answers with citations. We
build automatic metrics along three dimensions -- fluency, correctness, and
citation quality -- and demonstrate their strong correlation with human
judgements. Our experiments with state-of-the-art LLMs and novel prompting
strategies show that current systems have considerable room for improvements --
for example, on the ELI5 dataset, even the best model has 49% of its
generations lacking complete citation support. Our extensive analyses further
highlight promising future directions, including developing better retrievers,
advancing long-context LLMs, and improving the ability to synthesize
information from multiple sources.</p>
  </details>
</details>
<details>
  <summary>224. <b>标题：KNN-LM Does Not Improve Open-ended Text Generation</b></summary>
  <p><b>编号</b>：[478]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14625</p>
  <p><b>作者</b>：Shufan Wang,  Yixiao Song,  Andrew Drozdov,  Aparna Garimella,  Varun Manjunatha,  Mohit Iyyer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interpolation-based retrieval-augmented language, generation quality, retrieval-augmented language models, open-ended generation quality, interpolation-based retrieval-augmented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the generation quality of interpolation-based
retrieval-augmented language models (LMs). These methods, best exemplified by
the KNN-LM, interpolate the LM's predicted distribution of the next word with a
distribution formed from the most relevant retrievals for a given prefix. While
the KNN-LM and related methods yield impressive decreases in perplexity, we
discover that they do not exhibit corresponding improvements in open-ended
generation quality, as measured by both automatic evaluation metrics (e.g.,
MAUVE) and human evaluations. Digging deeper, we find that interpolating with a
retrieval distribution actually increases perplexity compared to a baseline
Transformer LM for the majority of tokens in the WikiText-103 test set, even
though the overall perplexity is lower due to a smaller number of tokens for
which perplexity dramatically decreases after interpolation. However, when
decoding a long sequence at inference time, significant improvements on this
smaller subset of tokens are washed out by slightly worse predictions on most
tokens. Furthermore, we discover that the entropy of the retrieval distribution
increases faster than that of the base LM as the generated sequence becomes
longer, which indicates that retrieval is less reliable when using
model-generated text as queries (i.e., is subject to exposure bias). We hope
that our analysis spurs future work on improved decoding algorithms and
interpolation strategies for retrieval-augmented language models.</p>
  </details>
</details>
<details>
  <summary>225. <b>标题：Self-Checker: Plug-and-Play Modules for Fact-Checking with Large  Language Models</b></summary>
  <p><b>编号</b>：[479]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14623</p>
  <p><b>作者</b>：Miaoran Li,  Baolin Peng,  Zhu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accuracy of claims, commonly utilized, utilized for validating, validating the factual, factual accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fact-checking is an essential task in NLP that is commonly utilized for
validating the factual accuracy of claims. Prior work has mainly focused on
fine-tuning pre-trained languages models on specific datasets, which can be
computationally intensive and time-consuming. With the rapid development of
large language models (LLMs), such as ChatGPT and GPT-3, researchers are now
exploring their in-context learning capabilities for a wide range of tasks. In
this paper, we aim to assess the capacity of LLMs for fact-checking by
introducing Self-Checker, a framework comprising a set of plug-and-play modules
that facilitate fact-checking by purely prompting LLMs in an almost zero-shot
setting. This framework provides a fast and efficient way to construct
fact-checking systems in low-resource environments. Empirical results
demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking.
However, there is still significant room for improvement compared to SOTA
fine-tuned models, which suggests that LLM adoption could be a promising
approach for future fact-checking research.</p>
  </details>
</details>
<details>
  <summary>226. <b>标题：EXnet: Efficient In-context Learning for Data-less Text classification</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14622</p>
  <p><b>作者</b>：Debaditya Shome,  Kuldeep Yadav</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made significant progress, encoding world knowledge, Large pre-trained language, Large pre-trained, paradigms including zero-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models (PLMs) have made significant progress in
encoding world knowledge and spawned a new set of learning paradigms including
zero-shot, few-shot, and in-context learning. Many language tasks can be
modeled as a set of prompts (for example, is this text about geography?) and
language models can provide binary answers, i.e., Yes or No. There is evidence
to suggest that the next-word prediction used by many PLMs does not align well
with zero-shot paradigms. Therefore, PLMs are fine-tuned as a
question-answering system. In-context learning extends zero-shot learning by
incorporating prompts and examples, resulting in increased task accuracy. Our
paper presents EXnet, a model specifically designed to perform in-context
learning without any limitations on the number of examples. We argue that
in-context learning is an effective method to increase task accuracy, and
providing examples facilitates cross-task generalization, especially when it
comes to text classification tasks. With extensive experiments, we show that
even our smallest model (15M parameters) generalizes to several unseen
classification tasks and domains.</p>
  </details>
</details>
<details>
  <summary>227. <b>标题：Abductive Commonsense Reasoning Exploiting Mutually Exclusive  Explanations</b></summary>
  <p><b>编号</b>：[482]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14618</p>
  <p><b>作者</b>：Wenting Zhao,  Justin T. Chiu,  Claire Cardie,  Alexander M. Rush</p>
  <p><b>备注</b>：accepted at ACL'23</p>
  <p><b>关键词</b>：aims to find, find plausible explanations, Abductive reasoning aims, Abductive reasoning, find plausible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Abductive reasoning aims to find plausible explanations for an event. This
style of reasoning is critical for commonsense tasks where there are often
multiple plausible explanations. Existing approaches for abductive reasoning in
natural language processing (NLP) often rely on manually generated annotations
for supervision; however, such annotations can be subjective and biased.
Instead of using direct supervision, this work proposes an approach for
abductive commonsense reasoning that exploits the fact that only a subset of
explanations is correct for a given context. The method uses posterior
regularization to enforce a mutual exclusion constraint, encouraging the model
to learn the distinction between fluent explanations and plausible ones. We
evaluate our approach on a diverse set of abductive reasoning datasets;
experimental results show that our approach outperforms or is comparable to
directly applying pretrained language models in a zero-shot manner and other
knowledge-augmented zero-shot methods.</p>
  </details>
</details>
<details>
  <summary>228. <b>标题：COMET-M: Reasoning about Multiple Events in Complex Sentences</b></summary>
  <p><b>编号</b>：[483]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14617</p>
  <p><b>作者</b>：Sahithya Ravi,  Raymond Ng,  Vered Shwartz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：speaker intended meaning, involves drawing commonsense, stated explicitly, speaker intended, intended meaning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the speaker's intended meaning often involves drawing
commonsense inferences to reason about what is not stated explicitly. In
multi-event sentences, it requires understanding the relationships between
events based on contextual knowledge. We propose COMET-M (Multi-Event), an
event-centric commonsense model capable of generating commonsense inferences
for a target event within a complex sentence. COMET-M builds upon COMET
(Bosselut et al., 2019), which excels at generating event-centric inferences
for simple sentences, but struggles with the complexity of multi-event
sentences prevalent in natural text. To overcome this limitation, we curate a
multi-event inference dataset of 35K human-written inferences. We trained
COMET-M on the human-written inferences and also created baselines using
automatically labeled examples. Experimental results demonstrate the
significant performance improvement of COMET-M over COMET in generating
multi-event inferences. Moreover, COMET-M successfully produces distinct
inferences for each target event, taking the complete context into
consideration. COMET-M holds promise for downstream tasks involving natural
text such as coreference resolution, dialogue, and story understanding.</p>
  </details>
</details>
<details>
  <summary>229. <b>标题：Exploring the Grounding Issues in Image Caption</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14616</p>
  <p><b>作者</b>：Pin-Er Chen,  Hsin-Yu Chou,  Po-Ya Angela Wang,  Yu-Hsiang Tseng,  Shu-Kai Hsieh</p>
  <p><b>备注</b>：10 pages, 10 figures</p>
  <p><b>关键词</b>：computational cognitive-linguistic view, Ecological Niche Association, cognitive-linguistic view, paper explores, computational cognitive-linguistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the grounding issue concerning multimodal semantic
representation from a computational cognitive-linguistic view. Five perceptual
properties of groundedness are annotated and analyzed: Affordance, Perceptual
salience, Object number, Gaze cueing, and Ecological Niche Association (ENA).
We annotated selected images from the Flickr30k dataset with exploratory
analyses and statistical modeling of their captions. Our findings suggest that
a comprehensive understanding of an object or event requires cognitive
attention, semantic distinctions in linguistic expression, and multimodal
construction. During this construction process, viewers integrate situated
meaning and affordance into multimodal semantics, which is consolidated into
image captions used in the image-text dataset incorporating visual and textual
elements. Our findings suggest that situated meaning and affordance grounding
are critical for grounded natural language understanding systems to generate
appropriate responses and show the potential to advance the understanding of
human construal in diverse situations.</p>
  </details>
</details>
<details>
  <summary>230. <b>标题：Selectively Answering Ambiguous Questions</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14613</p>
  <p><b>作者</b>：Jeremy R. Cole,  Michael J.Q. Zhang,  Daniel Gillick,  Julian Martin Eisenschlos,  Bhuwan Dhingra,  Jacob Eisenstein</p>
  <p><b>备注</b>：10 pages, 5 figures, 2 pages of appendix</p>
  <p><b>关键词</b>：Trustworthy language models, Trustworthy language, answer, questions, question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trustworthy language models should abstain from answering questions when they
do not know the answer. However, the answer to a question can be unknown for a
variety of reasons. Prior research has focused on the case in which the
question is clear and the answer is unambiguous but possibly unknown. However,
the answer to a question can also be unclear due to uncertainty of the
questioner's intent or context. We investigate question answering from this
perspective, focusing on answering a subset of questions with a high degree of
accuracy, from a set of questions in which many are inherently ambiguous. In
this setting, we find that the most reliable approach to calibration involves
quantifying repetition within a set of sampled model outputs, rather than the
model's likelihood or self-verification as used in prior work. % We find this
to be the case across different types of uncertainty, varying model scales and
both with or without instruction tuning. Our results suggest that
sampling-based confidence scores help calibrate answers to relatively
unambiguous questions, with more dramatic improvements on ambiguous questions.</p>
  </details>
</details>
<details>
  <summary>231. <b>标题：This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language  Models</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14610</p>
  <p><b>作者</b>：Bryan Li,  Chris Callison-Burch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linguistic context, introduce the notion, tendency to report, contested Spratly Islands, Spratly Islands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the notion of geopolitical bias -- a tendency to report
different geopolitical knowledge depending on the linguistic context. As a case
study, we consider territorial disputes between countries. For example, for the
widely contested Spratly Islands, would an LM be more likely to say they belong
to China if asked in Chinese, vs. to the Philippines if asked in Tagalog? To
evaluate if such biases exist, we first collect a dataset of territorial
disputes from Wikipedia, then associate each territory with a set of
multilingual, multiple-choice questions. This dataset, termed BorderLines,
consists of 250 territories with questions in 45 languages. We pose these
question sets to language models, and analyze geopolitical bias in their
responses through several proposed quantitative metrics. The metrics compare
between responses in different question languages as well as to the actual
geopolitical situation. The phenomenon of geopolitical bias is a uniquely
cross-lingual evaluation, contrasting with prior work's monolingual (mostly
English) focus on bias evaluation. Its existence shows that the knowledge of
LMs, unlike multilingual humans, is inconsistent across languages.</p>
  </details>
</details>
<details>
  <summary>232. <b>标题：OpenPI2.0: An Improved Dataset for Entity Tracking in Texts</b></summary>
  <p><b>编号</b>：[492]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14603</p>
  <p><b>作者</b>：Li Zhang,  Hainiu Xu,  Abhinav Kommula,  Niket Tandon,  Chris Callison-Burch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：event reasoning, long been deemed, deemed effective, effective in event, Representing texts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representing texts as information about entities has long been deemed
effective in event reasoning. We propose OpenPI2.0, an improved dataset for
tracking entity states in procedural texts. OpenPI2.0 features not only
canonicalized entities that facilitate evaluation, but also salience
annotations including both manual labels and automatic predictions. Regarding
entity salience, we provide a survey on annotation subjectivity, modeling
feasibility, and downstream applications in tasks such as question answering
and classical planning.</p>
  </details>
</details>
<details>
  <summary>233. <b>标题：Learning Semantic Role Labeling from Compatible Label Sequences</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14600</p>
  <p><b>作者</b>：Tao Li,  Ghazaleh Kazeminejad,  Susan W. Brown,  Martha Palmer,  Vivek Srikumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper addresses, addresses the question, efficiently learn, compatible label sequences, label sequences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the question of how to efficiently learn from disjoint,
compatible label sequences. We argue that the compatible structures between
disjoint label sets help model learning and inference. We verify this
hypothesis on the task of semantic role labeling (SRL), specifically, tagging a
sentence with two role sequences: VerbNet arguments and PropBank arguments.
Prior work has shown that cross-task interaction improves performance. However,
the two tasks are still separately decoded, running the risk of generating
structurally inconsistent label sequences (as per lexicons like SEMLINK). To
eliminate this issue, we first propose a simple and effective setup that
jointly handles VerbNet and PropBank labels as one sequence. With this setup,
we show that enforcing SEMLINK constraints during decoding constantly improves
the overall F1. With special input constructions, our joint model infers
VerbNet arguments from PropBank arguments with over 99% accuracy. We also
propose a constrained marginal model that uses SEMLINK information during
training to further benefit from the large amounts of PropBank-only data. Our
models achieve state-of-the-art F1's on VerbNet and PropBank argument labeling
on the CoNLL05 dataset with strong out-of-domain generalization.</p>
  </details>
</details>
<details>
  <summary>234. <b>标题：Bridging Continuous and Discrete Spaces: Interpretable Sentence  Representation Learning via Compositional Operations</b></summary>
  <p><b>编号</b>：[495]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14599</p>
  <p><b>作者</b>：James Y. Huang,  Wenlin Yao,  Kaiqiang Song,  Hongming Zhang,  Muhao Chen,  Dong Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sentence, compositional sentence operations, vector representations, representations to capture, sentence embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional sentence embedding models encode sentences into vector
representations to capture useful properties such as the semantic similarity
between sentences. However, in addition to similarity, sentence semantics can
also be interpreted via compositional operations such as sentence fusion or
difference. It is unclear whether the compositional semantics of sentences can
be directly reflected as compositional operations in the embedding space. To
more effectively bridge the continuous embedding and discrete text spaces, we
explore the plausibility of incorporating various compositional properties into
the sentence embedding space that allows us to interpret embedding
transformations as compositional sentence operations. We propose InterSent, an
end-to-end framework for learning interpretable sentence embeddings that
supports compositional sentence operations in the embedding space. Our method
optimizes operator networks and a bottleneck encoder-decoder model to produce
meaningful and interpretable sentence embeddings. Experimental results
demonstrate that our method significantly improves the interpretability of
sentence embeddings on four textual generation tasks over existing approaches
while maintaining strong performance on traditional semantic similarity tasks.</p>
  </details>
</details>
<details>
  <summary>235. <b>标题：Voices of Her: Analyzing Gender Differences in the AI Publication World</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14597</p>
  <p><b>作者</b>：Yiwen Ding,  Jiarui Liu,  Zhiheng Lyu,  Kun Zhang,  Bernhard Schoelkopf,  Zhijing Jin,  Rada Mihalcea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：covering diverse topics, analyzed gender bias, bias in research, covering diverse, previous studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While several previous studies have analyzed gender bias in research, we are
still missing a comprehensive analysis of gender differences in the AI
community, covering diverse topics and different development trends. Using the
AI Scholar dataset of 78K researchers in the field of AI, we identify several
gender differences: (1) Although female researchers tend to have fewer overall
citations than males, this citation difference does not hold for all
academic-age groups; (2) There exist large gender homophily in co-authorship on
AI papers; (3) Female first-authored papers show distinct linguistic styles,
such as longer text, more positive emotion words, and more catchy titles than
male first-authored papers. Our analysis provides a window into the current
demographic trends in our AI community, and encourages more gender equality and
diversity in the future. Our code and data are at
this https URL.</p>
  </details>
</details>
<details>
  <summary>236. <b>标题：Attentiveness to Answer Choices Doesn't Always Entail High QA Accuracy</b></summary>
  <p><b>编号</b>：[498]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14596</p>
  <p><b>作者</b>：Sarah Wiegreffe,  Matthew Finlayson,  Oyvind Tafjord,  Peter Clark,  Ashish Sabharwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, large language, few-shot settings, settings to discriminative, vocabulary tokens</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When large language models (LMs) are applied in zero- or few-shot settings to
discriminative tasks such as multiple-choice questions, their attentiveness
(i.e., probability mass) is spread across many vocabulary tokens that are not
valid choices. Such a spread across multiple surface forms with identical
meaning is thought to cause an underestimation of a model's true performance,
referred to as the "surface form competition" (SFC) hypothesis. This has
motivated the introduction of various probability normalization methods.
However, many core questions remain unanswered. How do we measure SFC or
attentiveness? Are there direct ways of increasing attentiveness on valid
choices? Does increasing attentiveness always improve task accuracy? We propose
a mathematical formalism for studying this phenomenon, provide a metric for
quantifying attentiveness, and identify a simple method for increasing it --
namely, in-context learning with even just one example containing answer
choices. The formalism allows us to quantify SFC and bound its impact. Our
experiments on three diverse datasets and six LMs reveal several surprising
findings. For example, encouraging models to generate a valid answer choice
can, in fact, be detrimental to task performance for some LMs, and prior
probability normalization methods are less effective (sometimes even
detrimental) to instruction-tuned LMs. We conclude with practical insights for
effectively using prompted LMs for multiple-choice tasks.</p>
  </details>
</details>
<details>
  <summary>237. <b>标题：Instruction Tuning with Lexicons for Zero-Shot Style Classification</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14592</p>
  <p><b>作者</b>：Ruohao Guo,  Wei Xu,  Alan Ritter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convey authors' intentions, intentions and attitudes, convey authors', authors' intentions, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Style is used to convey authors' intentions and attitudes. Despite the
success of large pre-trained language models on style classification, prior
work relies on fine-tuning with labeled examples. Prompting large language
models to classify style without fine-tuning is challenging because language
styles can be difficult to define. In this study, we investigate the
effectiveness of style lexicons as a means for instructing language models how
to identify new styles that are unseen during training. Our experiments show
that lexicon-based instructions improve transfer zero-shot performance
significantly. We will release our code and data.</p>
  </details>
</details>
<details>
  <summary>238. <b>标题：ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers</b></summary>
  <p><b>编号</b>：[502]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14591</p>
  <p><b>作者</b>：Kexun Zhang,  Danqing Wang,  Jingtao Xia,  William Yang Wang,  Lei Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, Large language, excel at implementing, functionality descriptions, ALGO</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) excel at implementing code from functionality
descriptions, but struggle with algorithmic problems that require not only
implementation but also identification of the suitable algorithm. Moreover,
LLM-generated programs lack guaranteed correctness and require human
verification. To address these challenges, we propose ALGO, a framework that
synthesizes Algorithmic programs with LLM-Generated Oracles to guide the
creation and verify their correctness. ALGO first generates a probably correct
but possibly slow reference oracle by prompting an LLM to exhaustively
enumerate all the combinations of relevant variables. This oracle is then
utilized to guide an arbitrary search strategy in exploring the algorithm space
and to verify the algorithms synthesized. Our study shows that the
LLM-generated oracles are correct for 88% of the cases. With the oracles as
verifiers, ALGO can be integrated with any existing code generation model in a
model-agnostic manner to enhance its performance. Experiments show that when
equipped with ALGO, we achieve an 8x better one-submission pass rate over the
Codex model and a 2.6x better one-submission pass rate over CodeT, the current
state-of-the-art model on CodeContests. We can also get 1.3x better pass rate
over the ChatGPT Code Interpreter on unseen problems.</p>
  </details>
</details>
<details>
  <summary>239. <b>标题：RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents</b></summary>
  <p><b>编号</b>：[503]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14590</p>
  <p><b>作者</b>：Pritika Ramu,  Sijia Wang,  Lalla Mouatadid,  Joy Rimchala,  Lifu Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：form understanding predominantly, understanding predominantly relies, necessitating extensive data, large pre-trained language, Current research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current research in form understanding predominantly relies on large
pre-trained language models, necessitating extensive data for pre-training.
However, the importance of layout structure (i.e., the spatial relationship
between the entity blocks in the visually rich document) to relation extraction
has been overlooked. In this paper, we propose REgion-Aware Relation Extraction
(RE$^2$) that leverages region-level spatial structure among the entity blocks
to improve their relation prediction. We design an edge-aware graph attention
network to learn the interaction between entities while considering their
spatial relationship defined by their region-level representations. We also
introduce a constraint objective to regularize the model towards consistency
with the inherent constraints of the relation extraction task. Extensive
experiments across various datasets, languages and domains demonstrate the
superiority of our proposed approach.</p>
  </details>
</details>
<details>
  <summary>240. <b>标题：Evaluating end-to-end entity linking on domain-specific knowledge bases:  Learning about ancient technologies from museum collections</b></summary>
  <p><b>编号</b>：[504]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14588</p>
  <p><b>作者</b>：Sebastian Cadavid-Sanchez,  Khalil Kacem,  Rafael Aparecido Martins Frade,  Johannes Boehm,  Thomas Chaney,  Danial Lashkari,  Daniel Simig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly large unstructured, large unstructured textual, unstructured textual datasets, historical questions, study social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To study social, economic, and historical questions, researchers in the
social sciences and humanities have started to use increasingly large
unstructured textual datasets. While recent advances in NLP provide many tools
to efficiently process such data, most existing approaches rely on generic
solutions whose performance and suitability for domain-specific tasks is not
well understood. This work presents an attempt to bridge this domain gap by
exploring the use of modern Entity Linking approaches for the enrichment of
museum collection data. We collect a dataset comprising of more than 1700 texts
annotated with 7,510 mention-entity pairs, evaluate some off-the-shelf
solutions in detail using this dataset and finally fine-tune a recent
end-to-end EL model on this data. We show that our fine-tuned model
significantly outperforms other approaches currently available in this domain
and present a proof-of-concept use case of this model. We release our dataset
and our best model.</p>
  </details>
</details>
<details>
  <summary>241. <b>标题：Contextualized Topic Coherence Metrics</b></summary>
  <p><b>编号</b>：[505]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14587</p>
  <p><b>作者</b>：Hamed Rahimi,  Jacob Louis Hoover,  David Mimno,  Hubert Naacke,  Camelia Constantin,  Bernd Amann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meaningful topic identification, neural topic modeling, actual meaningful topic, recent explosion, criticized for optimizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent explosion in work on neural topic modeling has been criticized for
optimizing automated topic evaluation metrics at the expense of actual
meaningful topic identification. But human annotation remains expensive and
time-consuming. We propose LLM-based methods inspired by standard human topic
evaluations, in a family of metrics called Contextualized Topic Coherence
(CTC). We evaluate both a fully automated version as well as a semi-automated
CTC that allows human-centered evaluation of coherence while maintaining the
efficiency of automated methods. We evaluate CTC relative to five other metrics
on six topic models and find that it outperforms automated topic coherence
methods, works well on short documents, and is not susceptible to meaningless
but high-scoring topics.</p>
  </details>
</details>
<details>
  <summary>242. <b>标题：Making the Implicit Explicit: Implicit Content as a First Class Citizen  in NLP</b></summary>
  <p><b>编号</b>：[509]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14583</p>
  <p><b>作者</b>：Alexander Hoyle,  Rupak Sarkar,  Pranav Goel,  Philip Resnik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explicit content support, multifaceted, Language, Language is multifaceted, NLP methods typically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language is multifaceted. A given utterance can be re-expressed in equivalent
forms, and its implicit and explicit content support various logical and
pragmatic inferences. When processing an utterance, we consider these different
aspects, as mediated by our interpretive goals -- understanding that "it's dark
in here" may be a veiled direction to turn on a light. Nonetheless, NLP methods
typically operate over the surface form alone, eliding this nuance.
In this work, we represent language with language, and direct an LLM to
decompose utterances into logical and plausible inferences. The reduced
complexity of the decompositions makes them easier to embed, opening up novel
applications. Variations on our technique lead to state-of-the-art improvements
on sentence embedding benchmarks, a substantive application in computational
political science, and to a novel construct-discovery process, which we
validate with human annotations.</p>
  </details>
</details>
<details>
  <summary>243. <b>标题：Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person</b></summary>
  <p><b>编号</b>：[511]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14580</p>
  <p><b>作者</b>：Lucas Rafael Stefanel Gris,  Ricardo Marcacini,  Arnaldo Candido Junior,  Edresson Casanova,  Anderson Soares,  Sandra Maria Aluísio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：involving human-machine interactions, human-machine interactions, recently Whisper ASR, play a key, key role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic speech recognition (ASR) systems play a key role in applications
involving human-machine interactions. Despite their importance, ASR models for
the Portuguese language proposed in the last decade have limitations in
relation to the correct identification of punctuation marks in automatic
transcriptions, which hinder the use of transcriptions by other systems,
models, and even by humans. However, recently Whisper ASR was proposed by
OpenAI, a general-purpose speech recognition model that has generated great
expectations in dealing with such limitations. This chapter presents the first
study on the performance of Whisper for punctuation prediction in the
Portuguese language. We present an experimental evaluation considering both
theoretical aspects involving pausing points (comma) and complete ideas
(exclamation, question, and fullstop), as well as practical aspects involving
transcript-based topic modeling - an application dependent on punctuation marks
for promising performance. We analyzed experimental results from videos of
Museum of the Person, a virtual museum that aims to tell and preserve people's
life histories, thus discussing the pros and cons of Whisper in a real-world
scenario. Although our experiments indicate that Whisper achieves
state-of-the-art results, we conclude that some punctuation marks require
improvements, such as exclamation, semicolon and colon.</p>
  </details>
</details>
<details>
  <summary>244. <b>标题：Connecting the Dots: What Graph-Based Text Representations Work Best for  Text Classification using Graph Neural Networks?</b></summary>
  <p><b>编号</b>：[513]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14578</p>
  <p><b>作者</b>：Margarita Bugueño,  Gerard de Melo</p>
  <p><b>备注</b>：17 pages, 2 figures, 15 tables. The Appendix starts on page 12</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, structure-aware machine learning, machine learning, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the success of Graph Neural Networks (GNNs) for structure-aware machine
learning, numerous studies have explored their application to text
classification, as an alternative to traditional feature representation models.
However, most studies considered just a specific domain and validated on data
with particular characteristics. This work presents an extensive empirical
investigation of graph-based text representation methods proposed for text
classification, identifying practical implications and open challenges in the
field. We compare several GNN architectures as well as BERT across five
datasets, encompassing short and also long documents. The results show that: i)
graph performance is highly related to the textual input features and domain,
ii) despite its outstanding performance, BERT has difficulties converging when
dealing with short texts, iii) graph methods are particularly beneficial for
longer documents.</p>
  </details>
</details>
<details>
  <summary>245. <b>标题：Difference-Masking: Choosing What to Mask in Continued Pretraining</b></summary>
  <p><b>编号</b>：[514]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14577</p>
  <p><b>作者</b>：Alex Wilf,  Syeda Nahida Akter,  Leena Mathur,  Paul Pu Liang,  Sheryl Mathew,  Mengrou Shou,  Eric Nyberg,  Louis-Philippe Morency</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promising SSL performance, led to promising, variety of downstream, Self-supervised learning, promising SSL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) and the objective of masking-and-predicting in
particular have led to promising SSL performance on a variety of downstream
tasks. However, while most approaches randomly mask tokens, there is strong
intuition from the field of education that deciding what to mask can
substantially improve learning outcomes. We introduce Difference-Masking, an
approach that automatically chooses what to mask during continued pretraining
by considering what makes an unlabelled target domain different from the
pretraining domain. Empirically, we find that Difference-Masking outperforms
baselines on continued pretraining settings across four diverse language and
multimodal video tasks. The cross-task applicability of Difference-Masking
supports the effectiveness of our framework for SSL pretraining in language,
vision, and other domains.</p>
  </details>
</details>
<details>
  <summary>246. <b>标题：Parameter-Efficient Language Model Tuning with Active Learning in  Low-Resource Settings</b></summary>
  <p><b>编号</b>：[515]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14576</p>
  <p><b>作者</b>：Josip Jukić,  Jan Šnajder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Pre-trained language models, Pre-trained language, language models, low-resource settings, PEFT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models (PLMs) have ignited a surge in demand for
effective fine-tuning techniques, particularly in low-resource domains and
languages. Active learning (AL), a set of algorithms designed to decrease
labeling costs by minimizing label complexity, has shown promise in confronting
the labeling bottleneck. Concurrently, adapter modules, designed for
parameter-efficient fine-tuning (PEFT), have showcased notable potential in
low-resource settings. However, the interplay between AL and adapter-based PEFT
remains unexplored. In our study, we empirically investigate PEFT behavior with
AL in low-resource settings for text classification tasks. Our findings affirm
the superiority of PEFT over full-fine tuning (FFT) in low-resource settings
and demonstrate that this advantage persists in AL setups. Finally, we delve
into the properties of PEFT and FFT through the lens of forgetting dynamics and
instance-level representations, linking them to AL instance selection behavior
and the stability of PEFT. Our research underscores the synergistic potential
of AL, PEFT, and TAPT in low-resource settings, paving the way for advancements
in efficient and effective fine-tuning.</p>
  </details>
</details>
<details>
  <summary>247. <b>标题：Detecting and Mitigating Indirect Stereotypes in Word Embeddings</b></summary>
  <p><b>编号</b>：[517]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14574</p>
  <p><b>作者</b>：Erin George,  Joyce Chew,  Deanna Needell</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：including harmful stereotypes, including harmful, word embeddings, word, Societal biases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Societal biases in the usage of words, including harmful stereotypes, are
frequently learned by common word embedding methods. These biases manifest not
only between a word and an explicit marker of its stereotype, but also between
words that share related stereotypes. This latter phenomenon, sometimes called
"indirect bias,'' has resisted prior attempts at debiasing. In this paper, we
propose a novel method called Biased Indirect Relationship Modification (BIRM)
to mitigate indirect bias in distributional word embeddings by modifying biased
relationships between words before embeddings are learned. This is done by
considering how the co-occurrence probability of a given pair of words changes
in the presence of words marking an attribute of bias, and using this to
average out the effect of a bias attribute. To evaluate this method, we perform
a series of common tests and demonstrate that measures of bias in the word
embeddings are reduced in exchange for minor reduction in the semantic quality
of the embeddings. In addition, we conduct novel tests for measuring indirect
stereotypes by extending the Word Embedding Association Test (WEAT) with new
test sets for indirect binary gender stereotypes. With these tests, we
demonstrate the presence of more subtle stereotypes not addressed by previous
work. The proposed method is able to reduce the presence of some of these new
stereotypes, serving as a crucial next step towards non-stereotyped word
embeddings.</p>
  </details>
</details>
<details>
  <summary>248. <b>标题：From Characters to Words: Hierarchical Pre-trained Language Model for  Open-vocabulary Language Understanding</b></summary>
  <p><b>编号</b>：[518]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14571</p>
  <p><b>作者</b>：Li Sun,  Florian Luisier,  Kayhan Batmanghelich,  Dinei Florencio,  Cha Zhang</p>
  <p><b>备注</b>：Accepted to ACL 2023 Main Conference</p>
  <p><b>关键词</b>：convert raw text, natural language understanding, language understanding require, discrete tokens, understanding require</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current state-of-the-art models for natural language understanding require a
preprocessing step to convert raw text into discrete tokens. This process known
as tokenization relies on a pre-built vocabulary of words or sub-word
morphemes. This fixed vocabulary limits the model's robustness to spelling
errors and its capacity to adapt to new domains. In this work, we introduce a
novel open-vocabulary language model that adopts a hierarchical two-level
approach: one at the word level and another at the sequence level. Concretely,
we design an intra-word module that uses a shallow Transformer architecture to
learn word representations from their characters, and a deep inter-word
Transformer module that contextualizes each word representation by attending to
the entire word sequence. Our model thus directly operates on character
sequences with explicit awareness of word boundaries, but without biased
sub-word or word-level vocabulary. Experiments on various downstream tasks show
that our method outperforms strong baselines. We also demonstrate that our
hierarchical model is robust to textual corruption and domain shift.</p>
  </details>
</details>
<details>
  <summary>249. <b>标题：Few-shot Unified Question Answering: Tuning Models or Prompts?</b></summary>
  <p><b>编号</b>：[520]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14569</p>
  <p><b>作者</b>：Srijan Bansal,  Semih Yavuz,  Bo Pang,  Meghana Bhat,  Yingbo Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specific question types, investigate specific question, specialized models catering, question types, reasoning skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question-answering (QA) tasks often investigate specific question types,
knowledge domains, or reasoning skills, leading to specialized models catering
to specific categories of QA tasks. While recent research has explored the idea
of unified QA models, such models are usually explored for high-resource
scenarios and require re-training to extend their capabilities. To overcome
these drawbacks, the paper explores the potential of two paradigms of tuning,
model, and prompts, for unified QA under a low-resource setting. The paper
provides an exhaustive analysis of their applicability using 16 QA datasets,
revealing that prompt tuning can perform as well as model tuning in a few-shot
setting with a good initialization. The study also shows that parameter-sharing
results in superior few-shot performance, simple knowledge transfer techniques
for prompt initialization can be effective, and prompt tuning achieves a
significant performance boost from pre-training in a low-resource regime. The
research offers insights into the advantages and limitations of prompt tuning
for unified QA in a few-shot setting, contributing to the development of
effective and efficient systems in low-resource scenarios.</p>
  </details>
</details>
<details>
  <summary>250. <b>标题：PEARL: Prompting Large Language Models to Plan and Execute Actions Over  Long Documents</b></summary>
  <p><b>编号</b>：[523]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14564</p>
  <p><b>作者</b>：Simeng Sun,  Yang Liu,  Shuohang Wang,  Chenguang Zhu,  Mohit Iyyer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, PEARL, language models, large language, tasks by decomposing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Strategies such as chain-of-thought prompting improve the performance of
large language models (LLMs) on complex reasoning tasks by decomposing input
examples into intermediate steps. However, it remains unclear how to apply such
methods to reason over long input documents, in which both the decomposition
and the output of each intermediate step are non-trivial to obtain. In this
work, we propose PEARL, a prompting framework to improve reasoning over long
documents, which consists of three stages: action mining, plan formulation, and
plan execution. More specifically, given a question about a long document,
PEARL decomposes the question into a sequence of actions (e.g., SUMMARIZE,
FIND_EVENT, FIND_RELATION) and then executes them over the document to obtain
the answer. Each stage of PEARL is implemented via zero-shot or few-shot
prompting of LLMs (in our work, GPT-4) with minimal human input. We evaluate
PEARL on a challenging subset of the QuALITY dataset, which contains questions
that require complex reasoning over long narrative texts. PEARL outperforms
zero-shot and chain-of-thought prompting on this dataset, and ablation
experiments show that each stage of PEARL is critical to its performance.
Overall, PEARL is a first step towards leveraging LLMs to reason over long
documents.</p>
  </details>
</details>
<details>
  <summary>251. <b>标题：Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented  Dialogues and Annotations</b></summary>
  <p><b>编号</b>：[526]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14556</p>
  <p><b>作者</b>：Tiziano Labruna,  Sofia Brenna,  Andrea Zaninello,  Bernardo Magnini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exhibited unprecedented capabilities, producing high-quality text, Large pre-trained language, pre-trained language models, Large pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models have exhibited unprecedented capabilities
in producing high-quality text via prompting techniques. This fact introduces
new possibilities for data collection and annotation, particularly in
situations where such data is scarce, complex to gather, expensive, or even
sensitive. In this paper, we explore the potential of these models to generate
and annotate goal-oriented dialogues, and conduct an in-depth analysis to
evaluate their quality. Our experiments employ ChatGPT, and encompass three
categories of goal-oriented dialogues (task-oriented, collaborative, and
explanatory), two generation modes (interactive and one-shot), and two
languages (English and Italian). Based on extensive human-based evaluations, we
demonstrate that the quality of generated dialogues and annotations is on par
with those generated by humans.</p>
  </details>
</details>
<details>
  <summary>252. <b>标题：All Roads Lead to Rome? Exploring the Invariance of Transformers'  Representations</b></summary>
  <p><b>编号</b>：[527]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14555</p>
  <p><b>作者</b>：Yuxin Ren,  Qipeng Guo,  Zhijing Jin,  Shauli Ravfogel,  Mrinmaya Sachan,  Bernhard Schölkopf,  Ryan Cotterell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bring propelling advances, NLP tasks, models bring propelling, Transformer models bring, bring propelling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer models bring propelling advances in various NLP tasks, thus
inducing lots of interpretability research on the learned representations of
the models. However, we raise a fundamental question regarding the reliability
of the representations. Specifically, we investigate whether transformers learn
essentially isomorphic representation spaces, or those that are sensitive to
the random seeds in their pretraining process. In this work, we formulate the
Bijection Hypothesis, which suggests the use of bijective methods to align
different models' representation spaces. We propose a model based on invertible
neural networks, BERT-INN, to learn the bijection more effectively than other
existing bijective methods such as the canonical correlation analysis (CCA). We
show the advantage of BERT-INN both theoretically and through extensive
experiments, and apply it to align the reproduced BERT embeddings to draw
insights that are meaningful to the interpretability research. Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>253. <b>标题：Sources of Hallucination by Large Language Models on Inference Tasks</b></summary>
  <p><b>编号</b>：[529]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14552</p>
  <p><b>作者</b>：Nick McKenna,  Tianyi Li,  Liang Cheng,  Mohammad Javad Hosseini,  Mark Johnson,  Mark Steedman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Natural Language, Large Language, capable of Natural, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are claimed to be capable of Natural Language
Inference (NLI), necessary for applied tasks like question answering and
summarization, yet this capability is under-explored. We present a series of
behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which
probe their behavior using controlled experiments. We establish two factors
which predict much of their performance, and propose that these are major
sources of hallucination in generative LLM. First, the most influential factor
is memorization of the training data. We show that models falsely label NLI
test samples as entailing when the hypothesis is attested in the training text,
regardless of the premise. We further show that named entity IDs are used as
"indices" to access the memorized data. Second, we show that LLMs exploit a
further corpus-based heuristic using the relative frequencies of words. We show
that LLMs score significantly worse on NLI test samples which do not conform to
these factors than those which do; we also discuss a tension between the two
factors, and a performance trade-off.</p>
  </details>
</details>
<details>
  <summary>254. <b>标题：Interpretable Automatic Fine-grained Inconsistency Detection in Text  Summarization</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14548</p>
  <p><b>作者</b>：Hou Pong Chan,  Qi Zeng,  Heng Ji</p>
  <p><b>备注</b>：Accepted by ACL Findings 2023. Code and data are available at this https URL</p>
  <p><b>关键词</b>：consistency evaluation approaches, Existing factual consistency, factual consistency evaluation, text summarization provide, summarization provide binary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing factual consistency evaluation approaches for text summarization
provide binary predictions and limited insights into the weakness of
summarization systems. Therefore, we propose the task of fine-grained
inconsistency detection, the goal of which is to predict the fine-grained types
of factual errors in a summary. Motivated by how humans inspect factual
inconsistency in summaries, we propose an interpretable fine-grained
inconsistency detection model, FineGrainFact, which explicitly represents the
facts in the documents and summaries with semantic frames extracted by semantic
role labeling, and highlights the related semantic frames to predict
inconsistency. The highlighted semantic frames help verify predicted error
types and correct inconsistent summaries. Experiment results demonstrate that
our model outperforms strong baselines and provides evidence to support or
refute the summary.</p>
  </details>
</details>
<details>
  <summary>255. <b>标题：LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond</b></summary>
  <p><b>编号</b>：[536]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14540</p>
  <p><b>作者</b>：Philippe Laban,  Wojciech Kryściński,  Divyansh Agarwal,  Alexander R. Fabbri,  Caiming Xiong,  Shafiq Joty,  Chien-Sheng Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：practical settings, recent appearance, crucial to reduce, reduce the propagation, propagation of misinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent appearance of LLMs in practical settings, having methods that
can effectively detect factual inconsistencies is crucial to reduce the
propagation of misinformation and improve trust in model outputs. When testing
on existing factual consistency benchmarks, we find that a few large language
models (LLMs) perform competitively on classification benchmarks for factual
inconsistency detection compared to traditional non-LLM methods. However, a
closer analysis reveals that most LLMs fail on more complex formulations of the
task and exposes issues with existing evaluation benchmarks, affecting
evaluation precision. To address this, we propose a new protocol for
inconsistency detection benchmark creation and implement it in a 10-domain
benchmark called SummEdits. This new benchmark is 20 times more cost-effective
per sample than previous benchmarks and highly reproducible, as we estimate
inter-annotator agreement at about 0.9. Most LLMs struggle on SummEdits, with
performance close to random chance. The best-performing model, GPT-4, is still
8\% below estimated human performance, highlighting the gaps in LLMs' ability
to reason about facts and detect inconsistencies when they occur.</p>
  </details>
</details>
<details>
  <summary>256. <b>标题：Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural  Machine Translation</b></summary>
  <p><b>编号</b>：[537]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14538</p>
  <p><b>作者</b>：Frédéric Odermatt,  Béni Egressy,  Roger Wattenhofer</p>
  <p><b>备注</b>：14 pages, 7 figures</p>
  <p><b>关键词</b>：paper presents, Cascade Beam Search, Beam Search, terminology constraints, translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a plug-and-play approach for translation with terminology
constraints. Terminology constraints are an important aspect of many modern
translation pipelines. In both specialized domains and newly emerging domains
(such as the COVID-19 pandemic), accurate translation of technical terms is
crucial. Recent approaches often train models to copy terminologies from the
input into the output sentence by feeding the target terminology along with the
input. But this requires expensive training whenever the underlying language
model is changed or the system should specialize to a new domain. We propose
Cascade Beam Search, a plug-and-play terminology-forcing approach that requires
no training. Cascade Beam Search has two parts: 1) logit manipulation to
increase the probability of target terminologies and 2) a cascading beam setup
based on grid beam search, where beams are grouped by the number of
terminologies they contain. We evaluate the performance of our approach by
competing against the top submissions of the WMT21 terminology translation
task. Our plug-and-play approach performs on par with the winning submissions
without using a domain-specific language model and with no additional training.</p>
  </details>
</details>
<details>
  <summary>257. <b>标题：MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties  Grounded in Math Reasoning Problems</b></summary>
  <p><b>编号</b>：[539]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14536</p>
  <p><b>作者</b>：Jakub Macina,  Nico Daheim,  Sankalan Pal Chowdhury,  Tanmay Sinha,  Manu Kapur,  Iryna Gurevych,  Mrinmaya Sachan</p>
  <p><b>备注</b>：Jakub Macina, Nico Daheim, and Sankalan Pal Chowdhury contributed equally to this work. Code and dataset available: this https URL</p>
  <p><b>关键词</b>：hold great potential, making education personalized, tutors hold great, hold great, great potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although automatic dialogue tutors hold great potential in making education
personalized and more accessible, research on such systems has been hampered by
a lack of sufficiently large and high-quality datasets. However, collecting
such datasets remains challenging, as recording tutoring sessions raises
privacy concerns and crowdsourcing leads to insufficient data quality. To
address this problem, we propose a framework to semi-synthetically generate
such dialogues by pairing real teachers with a large language model (LLM)
scaffolded to represent common student errors. In this paper, we describe our
ongoing efforts to use this framework to collect MathDial, a dataset of
currently ca. 1.5k tutoring dialogues grounded in multi-step math word
problems. We show that our dataset exhibits rich pedagogical properties,
focusing on guiding students using sense-making questions to let them explore
problems. Moreover, we outline that MathDial and its grounding annotations can
be used to finetune language models to be more effective tutors (and not just
solvers) and highlight remaining challenges that need to be addressed by the
research community. We will release our dataset publicly to foster research in
this socially important area of NLP.</p>
  </details>
</details>
<details>
  <summary>258. <b>标题：Detecting Propaganda Techniques in Code-Switched Social Media Text</b></summary>
  <p><b>编号</b>：[541]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14534</p>
  <p><b>作者</b>：Muhammad Umar Salman,  Asif Hanif,  Shady Shehata,  Preslav Nakov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intended to influence, influence the opinions, public to promote, Propaganda, propaganda detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Propaganda is a form of communication intended to influence the opinions and
the mindset of the public to promote a particular agenda. With the rise of
social media, propaganda has spread rapidly, leading to the need for automatic
propaganda detection systems. Most work on propaganda detection has focused on
high-resource languages, such as English, and little effort has been made to
detect propaganda for low-resource languages. Yet, it is common to find a mix
of multiple languages in social media communication, a phenomenon known as
code-switching. Code-switching combines different languages within the same
text, which poses a challenge for automatic systems. With this in mind, here we
propose the novel task of detecting propaganda techniques in code-switched
text. To support this task, we create a corpus of 1,030 texts code-switching
between English and Roman Urdu, annotated with 20 propaganda techniques, which
we make publicly available. We perform a number of experiments contrasting
different experimental setups, and we find that it is important to model the
multilinguality directly (rather than using translation) as well as to use the
right fine-tuning strategy. The code and the dataset are publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>259. <b>标题：How to Choose How to Choose Your Chatbot: A Massively Multi-System  MultiReference Data Set for Dialog Metric Evaluation</b></summary>
  <p><b>编号</b>：[542]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14533</p>
  <p><b>作者</b>：Huda Khayrallah,  Zuhaib Akhtar,  Edward Cohen,  João Sedoc</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Massively Multi-System MultiReference, enable future work, Massively Multi-System, Multi-System MultiReference dataset, release MMSMR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We release MMSMR, a Massively Multi-System MultiReference dataset to enable
future work on metrics and evaluation for dialog. Automatic metrics for
dialogue evaluation should be robust proxies for human judgments; however, the
verification of robustness is currently far from satisfactory. To quantify the
robustness correlation and understand what is necessary in a test set, we
create and release an 8-reference dialog dataset by extending single-reference
evaluation sets and introduce this new language learning conversation dataset.
We then train 1750 systems and evaluate them on our novel test set and the
DailyDialog dataset. We release the novel test set, and model hyper parameters,
inference outputs, and metric scores for each system on a variety of datasets.</p>
  </details>
</details>
<details>
  <summary>260. <b>标题：Eliminating Spurious Correlations from Pre-trained Models via Data  Mixing</b></summary>
  <p><b>编号</b>：[548]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14521</p>
  <p><b>作者</b>：Yihao Xue,  Ali Payani,  Yu Yang,  Baharan Mirzasoleiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable convergence, Machine learning models, Machine learning, robustness properties, spurious correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models pre-trained on large datasets have achieved
remarkable convergence and robustness properties. However, these models often
exploit spurious correlations between certain attributes and labels, which are
prevalent in the majority of examples within specific categories but are not
predictive of these categories in general. The learned spurious correlations
may persist even after fine-tuning on new data, which degrades models'
performance on examples that do not exhibit the spurious correlation. In this
work, we propose a simple and highly effective method to eliminate spurious
correlations from pre-trained models. The key idea of our method is to leverage
a small set of examples with spurious attributes, and balance the spurious
attributes across all classes via data mixing. We theoretically confirm the
effectiveness of our method, and empirically demonstrate its state-of-the-art
performance on various vision and NLP tasks, including eliminating spurious
correlations from pre-trained ResNet50 on Waterbirds and CelebA, adversarially
pre-trained ResNet50 on ImageNet, and BERT pre-trained on CivilComments.</p>
  </details>
</details>
<details>
  <summary>261. <b>标题：Deduction under Perturbed Evidence: Probing Student Simulation  Capabilities of Large Language Models</b></summary>
  <p><b>编号</b>：[552]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14507</p>
  <p><b>作者</b>：Shashank Sonkar,  Richard G. Baraniuk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, explore whether Large, Language Models, DUPE</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We explore whether Large Language Models (LLMs) are capable of logical
reasoning with distorted facts, which we call Deduction under Perturbed
Evidence (DUPE). DUPE presents a unique challenge to LLMs since they typically
rely on their parameters, which encode mostly accurate information, to reason
and make inferences. However, in DUPE, LLMs must reason over manipulated or
falsified evidence present in their prompts, which can result in false
conclusions that are valid only under the manipulated evidence. Our goal with
DUPE is to determine whether LLMs can arrive at these false conclusions and
identify whether the dominant factor influencing the deduction process is the
encoded data in the parameters or the manipulated evidence in the prompts. To
evaluate the DUPE capabilities of LLMs, we create a DUPEd version of the
StrategyQA dataset, where facts are manipulated to reverse the answer to the
question. Our findings show that even the most advanced GPT models struggle to
reason on manipulated facts - showcasing poor DUPE skills - with accuracy
dropping by 45% compared to the original dataset. We also investigate prompt
settings inspired from student simulation models, which mitigate the accuracy
drop to some extent. Our findings have practical implications for understanding
the performance of LLMs in real-world applications such as student simulation
models that involve reasoning over inaccurate information.</p>
  </details>
</details>
<details>
  <summary>262. <b>标题：RetICL: Sequential Retrieval of In-Context Examples with Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[553]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14502</p>
  <p><b>作者</b>：Alexander Scarlatos,  Andrew Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perform specific tasks, recent developments, language models focus, perform specific, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many recent developments in large language models focus on prompting them to
perform specific tasks. One effective prompting method is in-context learning,
where the model performs a (possibly new) generation/prediction task given one
(or more) examples. Past work has shown that the choice of examples can make a
large impact on task performance. However, finding good examples is not
straightforward since the definition of a representative group of examples can
vary greatly depending on the task. While there are many existing methods for
selecting in-context examples, they generally score examples independently,
ignoring the dependency between them and the order in which they are provided
to the large language model. In this work, we propose Retrieval for In-Context
Learning (RetICL), a learnable method for modeling and optimally selecting
examples sequentially for in-context learning. We frame the problem of
sequential example selection as a Markov decision process, design an example
retriever model using an LSTM, and train it using proximal policy optimization
(PPO). We validate RetICL on math problem solving datasets and show that it
outperforms both heuristic and learnable baselines, and achieves
state-of-the-art accuracy on the TabMWP dataset. We also use case studies to
show that RetICL implicitly learns representations of math problem solving
strategies.</p>
  </details>
</details>
<details>
  <summary>263. <b>标题：NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive  Decoders</b></summary>
  <p><b>编号</b>：[555]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14499</p>
  <p><b>作者</b>：Livio Baldini Soares,  Daniel Gillick,  Jeremy R. Cole,  Tom Kwiatkowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：terms of accuracy, rerankers are extremely, extremely effective, effective in terms, Neural document rerankers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural document rerankers are extremely effective in terms of accuracy.
However, the best models require dedicated hardware for serving, which is
costly and often not feasible. To avoid this serving-time requirement, we
present a method of capturing up to 86% of the gains of a Transformer
cross-attention model with a lexicalized scoring function that only requires
10-6% of the Transformer's FLOPs per document and can be served using commodity
CPUs. When combined with a BM25 retriever, this approach matches the quality of
a state-of-the art dual encoder retriever, that still requires an accelerator
for query encoding. We introduce NAIL (Non-Autoregressive Indexing with
Language models) as a model architecture that is compatible with recent
encoder-decoder and decoder-only large language models, such as T5, GPT-3 and
PaLM. This model architecture can leverage existing pre-trained checkpoints and
can be fine-tuned for efficiently constructing document representations that do
not require neural processing of queries.</p>
  </details>
</details>
<details>
  <summary>264. <b>标题：Self-Polish: Enhance Reasoning in Large Language Models via Problem  Refinement</b></summary>
  <p><b>编号</b>：[556]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14497</p>
  <p><b>作者</b>：Zhiheng Xi,  Senjie Jin,  Yuhao Zhou,  Rui Zheng,  Songyang Gao,  Tao Gui,  Qi Zhang,  Xuanjing Huang</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：large language models, rationales and answers, shed new light, light on enhancing, capabilities of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting methods such as Chain-of-Thought (CoT) have shed new light on
enhancing the reasoning capabilities of large language models, and researchers
have extensively explored the generation process of rationales and answers.
However, they have overlooked the potential challenges posed by the poor
quality of reasoning problems, which may influence the reasoning performance
significantly. In this work, we propose Self-Polish (SP), a novel method that
facilitates the model's problem-solving process by prompting them to
progressively refine the given problems to be more comprehensible and solvable.
Specifically, the method teaches models to eliminate irrelevant information,
rearrange the logic structure and organize local conditions into new ones
parallelly. SP is orthogonal to all other prompting methods, making it
convenient to integrate with state-of-the-art techniques for further
improvement. We conduct thorough experiments on five benchmarks to illustrate
the effectiveness of the proposed method. For example, with Text-davinci-003,
our method boosts the performance of standard few-shot prompting by $8.0\%$ on
GSM8K and $17.8\%$ on MultiArith; it also improves the performance of CoT by
$6.0\%$ on GSM8K and $6.0\%$ on MathQA, respectively. Furthermore, our method
also showcases impressive performance on robustness evaluation.</p>
  </details>
</details>
<details>
  <summary>265. <b>标题：Prompt position really matters in few-shot and zero-shot NLU tasks</b></summary>
  <p><b>编号</b>：[558]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14493</p>
  <p><b>作者</b>：Junyu Mao,  Stuart E. Middleton,  Mahesan Niranjan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made remarkable advancements, attracting a lot, attention from researchers, made remarkable, remarkable advancements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt-based models have made remarkable advancements in the fields of
zero-shot and few-shot learning, attracting a lot of attention from
researchers. Developing an effective prompt template plays a critical role.
However, prior studies have mainly focused on prompt vocabulary selection or
embedding initialization with the reserved prompt position fixed. In this
empirical study, we conduct the most comprehensive analysis to date of prompt
position option for natural language understanding tasks. Our findings quantify
the substantial impact prompt position has on model performance. We observe
that the prompt position used in prior studies is often sub-optimal for both
zero-shot and few-shot settings. These findings suggest prompt position
optimisation as an interesting research direction alongside the existing focus
on prompt engineering.</p>
  </details>
</details>
<details>
  <summary>266. <b>标题：Sociocultural Norm Similarities and Differences via Situational  Alignment and Explainable Textual Entailment</b></summary>
  <p><b>编号</b>：[559]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14492</p>
  <p><b>作者</b>：Sky CH-Wang,  Arkadiy Saakyan,  Oliver Li,  Zhou Yu,  Smaranda Muresan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Designing systems, social norms, social, norms, American cultures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing systems that can reason across cultures requires that they are
grounded in the norms of the contexts in which they operate. However, current
research on developing computational models of social norms has primarily
focused on American society. Here, we propose a novel approach to discover and
compare descriptive social norms across Chinese and American cultures. We
demonstrate our approach by leveraging discussions on a Chinese Q&A
platform-Zhihu-and the existing SocialChemistry dataset as proxies for
contrasting cultural axes, align social situations cross-culturally, and
extract social norms from texts using in-context learning. Embedding
Chain-of-Thought prompting in a human-AI collaborative framework, we build a
high-quality dataset of 3,069 social norms aligned with social situations
across Chinese and American cultures alongside corresponding free-text
explanations. To test the ability of models to reason about social norms across
cultures, we introduce the task of explainable social norm entailment, showing
that existing models under 3B parameters have significant room for improvement
in both automatic and human evaluation. Further analysis of cross-cultural norm
differences based on our dataset shows empirical alignment with the social
orientations framework, revealing several situational and descriptive nuances
in norms across these cultures.</p>
  </details>
</details>
<details>
  <summary>267. <b>标题：Are Large Language Models Robust Zero-shot Coreference Resolvers?</b></summary>
  <p><b>编号</b>：[561]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14489</p>
  <p><b>作者</b>：Nghia T. Le,  Alan Ritter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Winograd Schema Challenge, Recent progress, relies on continued, continued training, training using annotated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent progress in domain adaptation for coreference resolution relies on
continued training using annotated data from target domains. At the same time,
pre-trained large language models (LMs) have exhibited strong zero- and
few-shot learning abilities across a wide range of NLP tasks including pronoun
resolution. While this demonstrates evidence of coreference ability, previous
work has mostly studied this ability using simple sentence-level datasets such
as the Winograd Schema Challenge. In this work, we assess the feasibility of
zero-shot learning for coreference resolution by evaluating instruction-tuned
language models on more difficult, linguistically-complex coreference
benchmarks (e.g., CoNLL-2012). We demonstrate that zero-shot prompting
outperforms current unsupervised coreference systems. Further investigations
reveal the robust zero-shot generalization ability of instruction-tuned LMs
across a wide range of domains, languages, and time periods, as well as a
strong reliance on high-quality mention detection systems.</p>
  </details>
</details>
<details>
  <summary>268. <b>标题：Language Model Self-improvement by Reinforcement Learning Contemplation</b></summary>
  <p><b>编号</b>：[564]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14483</p>
  <p><b>作者</b>：Jing-Cheng Pang,  Pengyuan Wang,  Kaiyuan Li,  Xiong-Hui Chen,  Jiacheng Xu,  Zongzhang Zhang,  Yang Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Large Language Models, exhibited remarkable performance, exhibited remarkable, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have exhibited remarkable performance across
various natural language processing (NLP) tasks. However, fine-tuning these
models often necessitates substantial supervision, which can be expensive and
time-consuming to obtain. This paper introduces a novel unsupervised method
called LanguageModel Self-Improvement by Reinforcement Learning Contemplation
(SIRLC) that improves LLMs without reliance on external labels. Our approach is
grounded in the observation that it is simpler for language models to assess
text quality than to generate text. Building on this insight, SIRLC assigns
LLMs dual roles as both student and teacher. As a student, the LLM generates
answers to unlabeled questions, while as a teacher, it evaluates the generated
text and assigns scores accordingly. The model parameters are updated using
reinforcement learning to maximize the evaluation score. We demonstrate that
SIRLC can be applied to various NLP tasks, such as reasoning problems, text
generation, and machine translation. Our experiments show that SIRLC
effectively improves LLM performance without external supervision, resulting in
a 5.6% increase in answering accuracy for reasoning tasks and a rise in
BERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be
applied to models of different sizes, showcasing its broad applicability.</p>
  </details>
</details>
<details>
  <summary>269. <b>标题：Is a Prestigious Job the same as a Prestigious Country? A Case Study on  Multilingual Sentence Embeddings and European Countries</b></summary>
  <p><b>编号</b>：[565]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14482</p>
  <p><b>作者</b>：Jindřich Libovický</p>
  <p><b>备注</b>：10 pages, 1 figure</p>
  <p><b>关键词</b>：capture European countries, representations capture European, European languages, capture European, European countries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study how multilingual sentence representations capture European countries
and how this differs across European languages. We prompt the models with
templated sentences that we machine-translate into 12 European languages and
analyze the most prominent dimensions in the embeddings. Our analysis reveals
that the most prominent country feature in the embedding is its economic
strength in terms of GPD. When prompted specifically for job prestige, the
embedding space clearly distinguishes high and low-prestige jobs. The
occupational dimension is uncorrelated with the most dominant country
dimensions for three out of four studied models. One model: Distilled
Multilingual Universal Sentence Encoder, however, exhibited a connection
between occupational prestige and country of origin, which is a potential
source of nationality-based discrimination. Our findings are consistent across
languages and, to some extent, with the exception mentioned above, across
studied representation models.</p>
  </details>
</details>
<details>
  <summary>270. <b>标题：FOCUS: Effective Embedding Initialization for Specializing Pretrained  Multilingual Models on a Single Language</b></summary>
  <p><b>编号</b>：[566]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14481</p>
  <p><b>作者</b>：Konstantin Dobler,  Gerard de Melo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtain high-quality language, warm start, start can reduce, data and compute, compute to obtain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using model weights pretrained on a high-resource language as a warm start
can reduce the need for data and compute to obtain high-quality language models
in low-resource languages. To accommodate the new language, the pretrained
vocabulary and embeddings need to be adapted. Previous work on embedding
initialization for such adapted vocabularies has mostly focused on monolingual
source models. In this paper, we investigate the multilingual source model
setting and propose FOCUS - Fast Overlapping Token Combinations Using
Sparsemax, a novel embedding initialization method that outperforms previous
work when adapting XLM-R. FOCUS represents newly added tokens as combinations
of tokens in the overlap of the pretrained and new vocabularies. The
overlapping tokens are selected based on semantic similarity in an auxiliary
token embedding space. Our implementation of FOCUS is publicly available on
GitHub.</p>
  </details>
</details>
<details>
  <summary>271. <b>标题：BAND: Biomedical Alert News Dataset</b></summary>
  <p><b>编号</b>：[567]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14480</p>
  <p><b>作者</b>：Zihao Fu,  Meiru Zhang,  Zaiqiao Meng,  Yannan Shen,  Anya Okhmatovskaia,  David Buckeridge,  Nigel Collier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Infectious disease outbreaks, disease outbreaks continue, health and well-being, continue to pose, pose a significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Infectious disease outbreaks continue to pose a significant threat to human
health and well-being. To improve disease surveillance and understanding of
disease spread, several surveillance systems have been developed to monitor
daily news alerts and social media. However, existing systems lack thorough
epidemiological analysis in relation to corresponding alerts or news, largely
due to the scarcity of well-annotated reports data. To address this gap, we
introduce the Biomedical Alert News Dataset (BAND), which includes 1,508
samples from existing reported news articles, open emails, and alerts, as well
as 30 epidemiology-related questions. These questions necessitate the model's
expert reasoning abilities, thereby offering valuable insights into the
outbreak of the disease. The BAND dataset brings new challenges to the NLP
world, requiring better disguise capability of the content and the ability to
infer important information. We provide several benchmark tasks, including
Named Entity Recognition (NER), Question Answering (QA), and Event Extraction
(EE), to show how existing models are capable of handling these tasks in the
epidemiology domain. To the best of our knowledge, the BAND corpus is the
largest corpus of well-annotated biomedical outbreak alert news with
elaborately designed questions, making it a valuable resource for
epidemiologists and NLP researchers alike.</p>
  </details>
</details>
<details>
  <summary>272. <b>标题：CGCE: A Chinese Generative Chat Evaluation Benchmark for General and  Financial Domains</b></summary>
  <p><b>编号</b>：[569]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14471</p>
  <p><b>作者</b>：Xuanyu Zhang,  Bingbing Li,  Qing Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative chat models, natural language generation, significant performance improvements, Chinese Generative Chat, revolutionized natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative chat models, such as ChatGPT and GPT-4, have revolutionized
natural language generation (NLG) by incorporating instructions and human
feedback to achieve significant performance improvements. However, the lack of
standardized evaluation benchmarks for chat models, particularly for Chinese
and domain-specific models, hinders their assessment and progress. To address
this gap, we introduce the Chinese Generative Chat Evaluation (CGCE) benchmark,
focusing on general and financial domains. The CGCE benchmark encompasses
diverse tasks, including 200 questions in the general domain and 150 specific
professional questions in the financial domain. Manual scoring evaluates
factors such as accuracy, coherence, expression clarity, and completeness. The
CGCE benchmark provides researchers with a standardized framework to assess and
compare Chinese generative chat models, fostering advancements in NLG research.</p>
  </details>
</details>
<details>
  <summary>273. <b>标题：Run Like a Girl! Sports-Related Gender Bias in Language and Vision</b></summary>
  <p><b>编号</b>：[571]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14468</p>
  <p><b>作者</b>：Sophia Harrison,  Eleonora Gualdoni,  Gemma Boleda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Language and Vision, perpetuate harmful stereotypes, Vision datasets, stereotypes and discrimination, potential to perpetuate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gender bias in Language and Vision datasets and models has the potential to
perpetuate harmful stereotypes and discrimination. We analyze gender bias in
two Language and Vision datasets. Consistent with prior work, we find that both
datasets underrepresent women, which promotes their invisibilization. Moreover,
we hypothesize and find that a bias affects human naming choices for people
playing sports: speakers produce names indicating the sport (e.g. 'tennis
player' or 'surfer') more often when it is a man or a boy participating in the
sport than when it is a woman or a girl, with an average of 46% vs. 35% of
sports-related names for each gender. A computational model trained on these
naming data reproduces the bias. We argue that both the data and the model
result in representational harm against women.</p>
  </details>
</details>
<details>
  <summary>274. <b>标题：Towards Massively Multi-domain Multilingual Readability Assessment</b></summary>
  <p><b>编号</b>：[573]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14463</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Mohit Chandra,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massively multi-domain multilingual, automatic readability assessment, multi-domain multilingual dataset, massively multi-domain, multi-domain multilingual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ReadMe++, a massively multi-domain multilingual dataset for
automatic readability assessment. Prior work on readability assessment has been
mostly restricted to the English language and one or two text domains.
Additionally, the readability levels of sentences used in many previous
datasets are assumed on the document-level other than sentence-level, which
raises doubt about the quality of previous evaluations. We address those gaps
in the literature by providing an annotated dataset of 6,330 sentences in
Arabic, English, and Hindi collected from 64 different domains of text. Unlike
previous datasets, ReadMe++ offers more domain and language diversity and is
manually annotated at a sentence level using the Common European Framework of
Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework
that reduces subjectivity in annotation. Our experiments demonstrate that
models fine-tuned using ReadMe++ achieve strong cross-lingual transfer
capabilities and generalization to unseen domains. ReadMe++ will be made
publicly available to the research community.</p>
  </details>
</details>
<details>
  <summary>275. <b>标题：Enhancing Generation through Summarization Duality and Explicit Outline  Control</b></summary>
  <p><b>编号</b>：[576]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14459</p>
  <p><b>作者</b>：Yunzhe Li,  Qian Chen,  Weixiang Yan,  Wen Wang,  Qinglin Zhang,  Hari Sundaram</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：Automatically open-ended long, open-ended long text, poses significant challenges, significant challenges due, long text generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically open-ended long text generation poses significant challenges
due to semantic incoherence and plot implausibility. Previous works usually
alleviate this problem through outlines in the form of short phrases or
abstractive signals by designing unsupervised tasks, which tend to be unstable
and weakly interpretable.
Assuming that a summary serves as a mature outline, we introduce a two-stage,
summary-enhanced outline supervised generation framework. This framework
leverages the dual characteristics of the summarization task to improve outline
prediction, resulting in more explicit and plausible outlines. Furthermore, we
identify an underutilization issue in outline-based generation with both
standard pretrained language models (e.g., GPT-2, BART) and large language
models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit
outline control method for more effective utilization of generated outlines.</p>
  </details>
</details>
<details>
  <summary>276. <b>标题：Dancing Between Success and Failure: Edit-level Simplification  Evaluation using SALSA</b></summary>
  <p><b>编号</b>：[577]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14458</p>
  <p><b>作者</b>：David Heineman,  Yao Dou,  Mounica Maddela,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：producing highly rated, systems' specific strengths, highly rated text, evaluation methods fail, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (e.g., GPT-3.5) are uniquely capable of producing
highly rated text simplification, yet current human evaluation methods fail to
provide a clear understanding of systems' specific strengths and weaknesses. To
address this limitation, we introduce SALSA, an edit-based human annotation
framework that enables holistic and fine-grained text simplification
evaluation. We develop twenty one linguistically grounded edit types, covering
the full spectrum of success and failure across dimensions of conceptual,
syntactic and lexical simplicity. Using SALSA, we collect 12K edit annotations
on 700 simplifications, revealing discrepancies in the distribution of
transformation approaches performed by fine-tuned models, few-shot LLMs and
humans, and finding GPT-3.5 performs more quality edits than humans, but still
exhibits frequent errors. Using our fine-grained annotations, we develop
LENS-SALSA, a reference-free automatic simplification metric, trained to
predict sentence- and word-level quality simultaneously. Additionally, we
introduce word-level quality estimation for simplification and report promising
baseline results. Our training material, annotation toolkit, and data are
released at this http URL.</p>
  </details>
</details>
<details>
  <summary>277. <b>标题：Pre-training Language Models for Comparative Reasoning</b></summary>
  <p><b>编号</b>：[578]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14457</p>
  <p><b>作者</b>：Mengxia Yu,  Zhihan Zhang,  Wenhao Yu,  Meng Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pre-train language models, comparative reasoning, language models, reasoning, comparative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel framework to pre-train language models for
enhancing their abilities of comparative reasoning over texts. While recent
research has developed models for NLP tasks that require comparative reasoning,
they suffer from costly manual data labeling and limited generalizability to
different tasks. Our approach involves a scalable method for collecting data
for text-based entity comparison, which leverages both structured and
unstructured data, and the design of three novel pre-training tasks. Evaluation
on a range of downstream tasks including comparative question answering,
question generation, and summarization shows that our pre-training framework
significantly improves the comparative reasoning abilities of language models,
especially under low-resource conditions. This work also releases the first
integrated benchmark for comparative reasoning over texts.</p>
  </details>
</details>
<details>
  <summary>278. <b>标题：Having Beer after Prayer? Measuring Cultural Bias in Large Language  Models</b></summary>
  <p><b>编号</b>：[579]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14456</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models culturally biased, culturally biased, language models, language models culturally, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Are language models culturally biased? It is important that language models
conform to the cultural aspects of the communities they serve. However, we show
in this paper that language models suffer from a significant bias towards
Western culture when handling and generating text in Arabic, often preferring,
and producing Western-fitting content as opposed to the relevant Arab content.
We quantify this bias through a likelihood scoring-based metric using naturally
occurring contexts that we collect from online social media. Our experiments
reveal that both Arabic monolingual and multilingual models exhibit bias
towards Western culture in eight different cultural aspects: person names,
food, clothing, location, literature, beverage, religion, and sports. Models
also tend to exhibit more bias when prompted with Arabic sentences that are
more linguistically aligned with English. These findings raise concerns about
the cultural relevance of current language models. Our analyses show that
providing culture-indicating tokens or culturally-relevant demonstrations to
the model can help in debiasing.</p>
  </details>
</details>
<details>
  <summary>279. <b>标题：On Robustness of Finetuned Transformer-based NLP Models</b></summary>
  <p><b>编号</b>：[580]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14453</p>
  <p><b>作者</b>：Pavan Kalyan Reddy Neerudu,  Subba Reddy Oota,  Mounika Marreddy,  Venkateswara Rao Kagita,  Manish Gupta</p>
  <p><b>备注</b>：16 pages, 8 figures</p>
  <p><b>关键词</b>：natural language processing, large number, number of natural, models, BERT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer-based pretrained models like BERT, GPT-2 and T5 have been
finetuned for a large number of natural language processing (NLP) tasks, and
have been shown to be very effective. However, while finetuning, what changes
across layers in these models with respect to pretrained checkpoints is
under-studied. Further, how robust are these models to perturbations in input
text? Does the robustness vary depending on the NLP task for which the models
have been finetuned? While there exists some work on studying robustness of
BERT finetuned for a few NLP tasks, there is no rigorous study which compares
this robustness across encoder only, decoder only and encoder-decoder models.
In this paper, we study the robustness of three language models (BERT, GPT-2
and T5) with eight different text perturbations on the General Language
Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and
STIR) to quantify changes between pretrained and finetuned language model
representations across layers. GPT-2 representations are more robust than BERT
and T5 across multiple types of input perturbation. Although models exhibit
good robustness broadly, dropping nouns, verbs or changing characters are the
most impactful. Overall, this study provides valuable insights into
perturbation-specific weaknesses of popular Transformer-based models which
should be kept in mind when passing inputs.</p>
  </details>
</details>
<details>
  <summary>280. <b>标题：Is Information Extraction Solved by ChatGPT? An Analysis of Performance,  Evaluation Criteria, Robustness and Errors</b></summary>
  <p><b>编号</b>：[583]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14450</p>
  <p><b>作者</b>：Ridong Han,  Tao Peng,  Chaohao Yang,  Benyou Wang,  Lu Liu,  Xiang Wan</p>
  <p><b>备注</b>：23 pages, version 1.0</p>
  <p><b>关键词</b>：large language models, ChatGPT, language models, stimulated the research, research boom</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>ChatGPT has stimulated the research boom in the field of large language
models. In this paper, we assess the capabilities of ChatGPT from four
perspectives including Performance, Evaluation Criteria, Robustness and Error
Types. Specifically, we first evaluate ChatGPT's performance on 17 datasets
with 14 IE sub-tasks under the zero-shot, few-shot and chain-of-thought
scenarios, and find a huge performance gap between ChatGPT and SOTA results.
Next, we rethink this gap and propose a soft-matching strategy for evaluation
to more accurately reflect ChatGPT's performance. Then, we analyze the
robustness of ChatGPT on 14 IE sub-tasks, and find that: 1) ChatGPT rarely
outputs invalid responses; 2) Irrelevant context and long-tail target types
greatly affect ChatGPT's performance; 3) ChatGPT cannot understand well the
subject-object relationships in RE task. Finally, we analyze the errors of
ChatGPT, and find that "unannotated spans" is the most dominant error type.
This raises concerns about the quality of annotated data, and indicates the
possibility of annotating data with ChatGPT. The data and code are released at
Github site.</p>
  </details>
</details>
<details>
  <summary>281. <b>标题：Exploring Contrast Consistency of Open-Domain Question Answering Systems  on Minimally Edited Questions</b></summary>
  <p><b>编号</b>：[585]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14441</p>
  <p><b>作者</b>：Zhihan Zhang,  Wenhao Yu,  Zheng Ning,  Mingxuan Ju,  Meng Jiang</p>
  <p><b>备注</b>：Accepted at TACL. This is a pre-MIT Press publication version</p>
  <p><b>关键词</b>：make consistently correct, consistently correct predictions, aspect in NLP, presence of perturbations, make consistently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrast consistency, the ability of a model to make consistently correct
predictions in the presence of perturbations, is an essential aspect in NLP.
While studied in tasks such as sentiment analysis and reading comprehension, it
remains unexplored in open-domain question answering (OpenQA) due to the
difficulty of collecting perturbed questions that satisfy factuality
requirements. In this work, we collect minimally edited questions as
challenging contrast sets to evaluate OpenQA models. Our collection approach
combines both human annotation and large language model generation. We find
that the widely used dense passage retriever (DPR) performs poorly on our
contrast sets, despite fitting the training set well and performing
competitively on standard test sets. To address this issue, we introduce a
simple and effective query-side contrastive loss with the aid of data
augmentation to improve DPR training. Our experiments on the contrast sets
demonstrate that DPR's contrast consistency is improved without sacrificing its
accuracy on the standard test sets.</p>
  </details>
</details>
<details>
  <summary>282. <b>标题：Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment  Triplet Extraction</b></summary>
  <p><b>编号</b>：[586]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14434</p>
  <p><b>作者</b>：Yew Ken Chia,  Hui Chen,  Wei Han,  Guizhen Chen,  Sharifah Mahani Aljunied,  Soujanya Poria,  Lidong Bing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sentiment Triplet Extraction, Triplet Extraction, Aspect Sentiment Triplet, Sentiment Triplet, subtask of Aspect-Based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aspect Sentiment Triplet Extraction (ASTE) is a subtask of Aspect-Based
Sentiment Analysis (ABSA) that considers each opinion term, their expressed
sentiment, and the corresponding aspect targets. However, existing methods are
limited to the in-domain setting with two domains. Hence, we propose a
domain-expanded benchmark to address the in-domain, out-of-domain and
cross-domain settings. We support the new benchmark by annotating more than
4000 data samples for two new domains based on hotel and cosmetics reviews. Our
analysis of five existing methods shows that while there is a significant gap
between in-domain and out-of-domain performance, generative methods have a
strong potential for domain generalization. Our datasets, code implementation
and models are available at this https URL .</p>
  </details>
</details>
<details>
  <summary>283. <b>标题：Image Manipulation via Multi-Hop Instructions -- A New Dataset and  Weakly-Supervised Neuro-Symbolic Approach</b></summary>
  <p><b>编号</b>：[588]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14410</p>
  <p><b>作者</b>：Harman Singh,  Poorva Garg,  Mohit Gupta,  Kevin Shah,  Arnab Kumar Mondal,  Dinesh Khandelwal,  Parag Singla,  Dinesh Garg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Symbolic Concept Learning, natural language text, Neuro Symbolic Concept, multi-modal spaces, multiple AI applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are interested in image manipulation via natural language text -- a task
that is useful for multiple AI applications but requires complex reasoning over
multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning
(NSCL), which has been quite effective for the task of Visual Question
Answering (VQA), for the task of image manipulation. Our system referred to as
NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and
only requires weak supervision in the form of annotated data for VQA. NeuroSIM
parses an instruction into a symbolic program, based on a Domain Specific
Language (DSL) comprising of object attributes and manipulation operations,
that guides its execution. We create a new dataset for the task, and extensive
experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA
baselines that make use of supervised data for manipulation.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Siamese Masked Autoencoders</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14344</p>
  <p><b>作者</b>：Agrim Gupta,  Jiajun Wu,  Jia Deng,  Li Fei-Fei</p>
  <p><b>备注</b>：Project page this https URL</p>
  <p><b>关键词</b>：varying object appearances, computer vision, present Siamese Masked, images or scenes, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Establishing correspondence between images or scenes is a significant
challenge in computer vision, especially given occlusions, viewpoint changes,
and varying object appearances. In this paper, we present Siamese Masked
Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for
learning visual correspondence from videos. SiamMAE operates on pairs of
randomly sampled video frames and asymmetrically masks them. These frames are
processed independently by an encoder network, and a decoder composed of a
sequence of cross-attention layers is tasked with predicting the missing
patches in the future frame. By masking a large fraction ($95\%$) of patches in
the future frame while leaving the past frame unchanged, SiamMAE encourages the
network to focus on object motion and learn object-centric representations.
Despite its conceptual simplicity, features learned via SiamMAE outperform
state-of-the-art self-supervised methods on video object segmentation, pose
keypoint propagation, and semantic part propagation tasks. SiamMAE achieves
competitive results without relying on data augmentation, handcrafted
tracking-based pretext tasks, or other techniques to prevent representational
collapse.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Video Prediction Models as Rewards for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14343</p>
  <p><b>作者</b>：Alejandro Escontrela,  Ademi Adeniji,  Wilson Yan,  Ajay Jain,  Xue Bin Peng,  Ken Goldberg,  Youngwoon Lee,  Danijar Hafner,  Pieter Abbeel</p>
  <p><b>备注</b>：20 pages, 15 figures, 4 tables. under review</p>
  <p><b>关键词</b>：learn complex behaviors, Video Prediction, learn complex, long-standing challenge, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Specifying reward signals that allow agents to learn complex behaviors is a
long-standing challenge in reinforcement learning. A promising approach is to
extract preferences for behaviors from unlabeled videos, which are widely
available on the internet. We present Video Prediction Rewards (VIPER), an
algorithm that leverages pretrained video prediction models as action-free
reward signals for reinforcement learning. Specifically, we first train an
autoregressive transformer on expert videos and then use the video prediction
likelihoods as reward signals for a reinforcement learning agent. VIPER enables
expert-level control without programmatic task rewards across a wide range of
DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction
model allows us to derive rewards for an out-of-distribution environment where
no expert data is available, enabling cross-embodiment generalization for
tabletop manipulation. We see our work as starting point for scalable reward
specification from unlabeled videos that will benefit from the rapid advances
in generative modeling. Source code and datasets are available on the project
website: this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Sophia: A Scalable Stochastic Second-order Optimizer for Language Model  Pre-training</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14342</p>
  <p><b>作者</b>：Hong Liu,  Zhiyuan Li,  David Hall,  Percy Liang,  Tengyu Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cost of training, massive cost, Clipped Stochastic Optimization, non-trivial improvement, algorithm would lead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the massive cost of language model pre-training, a non-trivial
improvement of the optimization algorithm would lead to a material reduction on
the time and cost of training. Adam and its variants have been state-of-the-art
for years, and more sophisticated second-order (Hessian-based) optimizers often
incur too much per-step overhead. In this paper, we propose Sophia,
Second-order Clipped Stochastic Optimization, a simple scalable second-order
optimizer that uses a light-weight estimate of the diagonal Hessian as the
pre-conditioner. The update is the moving average of the gradients divided by
the moving average of the estimated Hessian, followed by element-wise clipping.
The clipping controls the worst-case update size and tames the negative impact
of non-convexity and rapid change of Hessian along the trajectory. Sophia only
estimates the diagonal Hessian every handful of iterations, which has
negligible average per-step time and memory overhead. On language modeling with
GPT-2 models of sizes ranging from 125M to 770M, Sophia achieves a 2x speed-up
compared with Adam in the number of steps, total compute, and wall-clock time.
Theoretically, we show that Sophia adapts to the curvature in different
components of the parameters, which can be highly heterogeneous for language
modeling tasks. Our run-time bound does not depend on the condition number of
the loss.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Improving Factuality and Reasoning in Language Models through Multiagent  Debate</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14325</p>
  <p><b>作者</b>：Yilun Du,  Shuang Li,  Antonio Torralba,  Joshua B. Tenenbaum,  Igor Mordatch</p>
  <p><b>备注</b>：Project Webpage and Code: this https URL</p>
  <p><b>关键词</b>：demonstrated remarkable capabilities, recent years, Large language models, demonstrated remarkable, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
"society of minds" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Inverse Preference Learning: Preference-based RL without a Reward  Function</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15363</p>
  <p><b>作者</b>：Joey Hejna,  Dorsa Sadigh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：difficult to design, hard to align, Preference-based Reinforcement Learning, Reward, human intent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reward functions are difficult to design and often hard to align with human
intent. Preference-based Reinforcement Learning (RL) algorithms address these
problems by learning reward functions from human feedback. However, the
majority of preference-based RL methods naïvely combine supervised reward
models with off-the-shelf RL algorithms. Contemporary approaches have sought to
improve performance and query complexity by using larger and more complex
reward architectures such as transformers. Instead of using highly complex
architectures, we develop a new and parameter-efficient algorithm, Inverse
Preference Learning (IPL), specifically designed for learning from offline
preference data. Our key insight is that for a fixed policy, the $Q$-function
encodes all information about the reward function, effectively making them
interchangeable. Using this insight, we completely eliminate the need for a
learned reward function. Our resulting algorithm is simpler and more
parameter-efficient. Across a suite of continuous control and robotics
benchmarks, IPL attains competitive performance compared to more complex
approaches that leverage transformer-based and non-Markovian reward functions
while having fewer algorithmic hyperparameters and learned network parameters.
Our code is publicly released.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Context-Aware Transformer Pre-Training for Answer Sentence Selection</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15358</p>
  <p><b>作者</b>：Luca Di Liello,  Siddhant Garg,  Alessandro Moschitti</p>
  <p><b>备注</b>：Accepted at ACL 2023</p>
  <p><b>关键词</b>：Answer Sentence Selection, Sentence Selection, building an accurate, core component, component for building</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Answer Sentence Selection (AS2) is a core component for building an accurate
Question Answering pipeline. AS2 models rank a set of candidate sentences based
on how likely they answer a given question. The state of the art in AS2
exploits pre-trained transformers by transferring them on large annotated
datasets, while using local contextual information around the candidate
sentence. In this paper, we propose three pre-training objectives designed to
mimic the downstream fine-tuning task of contextual AS2. This allows for
specializing LMs when fine-tuning for contextual AS2. Our experiments on three
public and two large-scale industrial datasets show that our pre-training
approaches (applied to RoBERTa and ELECTRA) can improve baseline contextual AS2
accuracy by up to 8% on some datasets.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A Virtual Reality Tool for Representing, Visualizing and Updating Deep  Learning Models</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15353</p>
  <p><b>作者</b>：Hannes Kath,  Bengt Lüers,  Thiago S. Gouvêa,  Daniel Sonntag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：lack of transparency, transparency limits, limits its impact, potential application areas, virtual reality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is ubiquitous, but its lack of transparency limits its impact
on several potential application areas. We demonstrate a virtual reality tool
for automating the process of assigning data inputs to different categories. A
dataset is represented as a cloud of points in virtual space. The user explores
the cloud through movement and uses hand gestures to categorise portions of the
cloud. This triggers gradual movements in the cloud: points of the same
category are attracted to each other, different groups are pushed apart, while
points are globally distributed in a way that utilises the entire space. The
space, time, and forces observed in virtual reality can be mapped to
well-defined machine learning concepts, namely the latent space, the training
epochs and the backpropagation. Our tool illustrates how the inner workings of
deep neural networks can be made tangible and transparent. We expect this
approach to accelerate the autonomous development of deep learning applications
by end users in novel areas.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Optimal Rates for Bandit Nonstochastic Control</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15352</p>
  <p><b>作者</b>：Y. Jennifer Sun,  Stephen Newman,  Elad Hazan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Linear Quadratic Regulator, Linear Quadratic Gaussian, Linear Quadratic, Quadratic Regulator, Quadratic Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear Quadratic Regulator (LQR) and Linear Quadratic Gaussian (LQG) control
are foundational and extensively researched problems in optimal control. We
investigate LQR and LQG problems with semi-adversarial perturbations and
time-varying adversarial bandit loss functions. The best-known sublinear regret
algorithm of~\cite{gradu2020non} has a $T^{\frac{3}{4}}$ time horizon
dependence, and its authors posed an open question about whether a tight rate
of $\sqrt{T}$ could be achieved. We answer in the affirmative, giving an
algorithm for bandit LQR and LQG which attains optimal regret (up to
logarithmic factors) for both known and unknown systems. A central component of
our method is a new scheme for bandit convex optimization with memory, which is
of independent interest.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Black-Box Variational Inference Converges</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15349</p>
  <p><b>作者</b>：Kyurae Kim,  Kaiwen Wu,  Jisu Oh,  Yian Ma,  Jacob R. Gardner</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：Monte Carlo variational, Monte Carlo, full black-box variational, Carlo variational inference, Carlo variational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide the first convergence guarantee for full black-box variational
inference (BBVI), also known as Monte Carlo variational inference. While
preliminary investigations worked on simplified versions of BBVI (e.g., bounded
domain, bounded support, only optimizing for the scale, and such), our setup
does not need any such algorithmic modifications. Our results hold for
log-smooth posterior densities with and without strong log-concavity and the
location-scale variational family. Also, our analysis reveals that certain
algorithm design choices commonly employed in practice, particularly, nonlinear
parameterizations of the scale of the variational approximation, can result in
suboptimal convergence rates. Fortunately, running BBVI with proximal
stochastic gradient descent fixes these limitations, and thus achieves the
strongest known convergence rate guarantees. We evaluate this theoretical
insight by comparing proximal SGD against other standard implementations of
BBVI on large-scale Bayesian inference problems.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：READ: Recurrent Adaptation of Large Transformers</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15348</p>
  <p><b>作者</b>：Sid Wang,  John Nguyen,  Ke Li,  Carole-Jean Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Computer Vision tasks, Natural Language, Language Processing, Processing and Computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale Transformers has led to the explosion of many AI
applications across Natural Language Processing and Computer Vision tasks.
However, fine-tuning all pre-trained model parameters becomes impractical as
the model size and number of tasks increase. Parameter-efficient transfer
learning (PETL) methods aim to address these challenges. While effective in
reducing the number of trainable parameters, PETL methods still require
significant energy and computational resources to fine-tune. In this paper, we
introduce \textbf{RE}current \textbf{AD}aption (READ) -- a lightweight and
memory-efficient fine-tuning method -- to overcome the limitations of the
current PETL approaches. Specifically, READ inserts a small RNN network
alongside the backbone model so that the model does not have to back-propagate
through the large backbone network. Through comprehensive empirical evaluation
of the GLUE benchmark, we demonstrate READ can achieve a $56\%$ reduction in
the training memory consumption and an $84\%$ reduction in the GPU energy usage
while retraining high model quality compared to full-tuning. Additionally, the
model size of READ does not grow with the backbone model size, making it a
highly scalable solution for fine-tuning large Transformers.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Learning Answer Generation using Supervision from Automatic Question  Answering Evaluators</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15344</p>
  <p><b>作者</b>：Matteo Gabburo,  Siddhant Garg,  Rik Koncel-Kedziorski,  Alessandro Moschitti</p>
  <p><b>备注</b>：Accepted at ACL 2023</p>
  <p><b>关键词</b>：Recent studies show, Recent studies, studies show, show that sentence-level, sentence-level extractive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies show that sentence-level extractive QA, i.e., based on Answer
Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA)
models, which generate answers using the top-k answer sentences ranked by AS2
models (a la retrieval-augmented generation style). In this paper, we propose a
novel training paradigm for GenQA using supervision from automatic QA
evaluation models (GAVA). Specifically, we propose three strategies to transfer
knowledge from these QA evaluation models to a GenQA model: (i) augmenting
training data with answers generated by the GenQA model and labelled by GAVA
(either statically, before training, or (ii) dynamically, at every training
epoch); and (iii) using the GAVA score for weighting the generator loss during
the learning of the GenQA model. We evaluate our proposed methods on two
academic and one industrial dataset, obtaining a significant improvement in
answering accuracy over the previous state of the art.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Is Your Model "MADD"? A Novel Metric to Evaluate Algorithmic Fairness  for Predictive Student Models</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15342</p>
  <p><b>作者</b>：Mélina Verger,  Sébastien Lallé,  François Bouchet,  Vanda Luengo</p>
  <p><b>备注</b>：12 pages, conference</p>
  <p><b>关键词</b>：making informed decisions, learning environments due, informed decisions, Predictive, learning environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predictive student models are increasingly used in learning environments due
to their ability to enhance educational outcomes and support stakeholders in
making informed decisions. However, predictive models can be biased and produce
unfair outcomes, leading to potential discrimination against some students and
possible harmful long-term implications. This has prompted research on fairness
metrics meant to capture and quantify such biases. Nonetheless, so far,
existing fairness metrics used in education are predictive
performance-oriented, focusing on assessing biased outcomes across groups of
students, without considering the behaviors of the models nor the severity of
the biases in the outcomes. Therefore, we propose a novel metric, the Model
Absolute Density Distance (MADD), to analyze models' discriminatory behaviors
independently from their predictive performance. We also provide a
complementary visualization-based analysis to enable fine-grained human
assessment of how the models discriminate between groups of students. We
evaluate our approach on the common task of predicting student success in
online courses, using several common predictive classification models on an
open educational dataset. We also compare our metric to the only predictive
performance-oriented fairness metric developed in education, ABROCA. Results on
this dataset show that: (1) fair predictive performance does not guarantee fair
models' behaviors and thus fair outcomes, (2) there is no direct relationship
between data bias and predictive performance bias nor discriminatory behaviors
bias, and (3) trained on the same data, models exhibit different discriminatory
behaviors, according to different sensitive features too. We thus recommend
using the MADD on models that show satisfying predictive performance, to gain a
finer-grained understanding on how they behave and to refine models selection
and their usage.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Deep Generative Model for Interactive Data Annotation through Direct  Manipulation in Latent Space</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15337</p>
  <p><b>作者</b>：Hannes Kath,  Thiago S. Gouvêa,  Daniel Sonntag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fields of application, application is constrained, constrained by lack, lack of annotated, ML-assisted data annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The impact of machine learning (ML) in many fields of application is
constrained by lack of annotated data. Among existing tools for ML-assisted
data annotation, one little explored tool type relies on an analogy between the
coordinates of a graphical user interface and the latent space of a neural
network for interaction through direct manipulation. In the present work, we 1)
expand the paradigm by proposing two new analogies: time and force as
reflecting iterations and gradients of network training; 2) propose a network
model for learning a compact graphical representation of the data that takes
into account both its internal structure and user provided annotations; and 3)
investigate the impact of model hyperparameters on the learned graphical
representations of the data, identifying candidate model variants for a future
user study.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Breaking the Curse of Quality Saturation with User-Centric Ranking</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15333</p>
  <p><b>作者</b>：Zhuokai Zhao,  Yang Yang,  Wenyu Wang,  Chihuang Liu,  Yu Shi,  Wenjie Hu,  Haotian Zhang,  Shuang Yang</p>
  <p><b>备注</b>：accepted to publish at KDD 2023</p>
  <p><b>关键词</b>：puzzle in search, key puzzle, utilize a small, small portion, vastly available user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key puzzle in search, ads, and recommendation is that the ranking model can
only utilize a small portion of the vastly available user interaction data. As
a result, increasing data volume, model size, or computation FLOPs will quickly
suffer from diminishing returns. We examined this problem and found that one of
the root causes may lie in the so-called ``item-centric'' formulation, which
has an unbounded vocabulary and thus uncontrolled model complexity. To mitigate
quality saturation, we introduce an alternative formulation named
``user-centric ranking'', which is based on a transposed view of the dyadic
user-item interaction data. We show that this formulation has a promising
scaling property, enabling us to train better-converged models on substantially
larger data sets.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：No-Regret Online Prediction with Strategic Experts</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15331</p>
  <p><b>作者</b>：Omid Sadeghi,  Maryam Fazel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：online binary prediction, expert advice framework, allowed to pick, study a generalization, online binary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a generalization of the online binary prediction with expert advice
framework where at each round, the learner is allowed to pick $m\geq 1$ experts
from a pool of $K$ experts and the overall utility is a modular or submodular
function of the chosen experts. We focus on the setting in which experts act
strategically and aim to maximize their influence on the algorithm's
predictions by potentially misreporting their beliefs about the events. Among
others, this setting finds applications in forecasting competitions where the
learner seeks not only to make predictions by aggregating different forecasters
but also to rank them according to their relative performance. Our goal is to
design algorithms that satisfy the following two requirements: 1)
$\textit{Incentive-compatible}$: Incentivize the experts to report their
beliefs truthfully, and 2) $\textit{No-regret}$: Achieve sublinear regret with
respect to the true beliefs of the best fixed set of $m$ experts in hindsight.
Prior works have studied this framework when $m=1$ and provided
incentive-compatible no-regret algorithms for the problem. We first show that a
simple reduction of our problem to the $m=1$ setting is neither efficient nor
effective. Then, we provide algorithms that utilize the specific structure of
the utility functions to achieve the two desired goals.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Visual Programming for Text-to-Image Generation and Evaluation</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15328</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：18 pages; Project website: this https URL</p>
  <p><b>关键词</b>：demonstrated impressive performance, large language models, adopted language models, generation, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models have demonstrated impressive performance in many
domains, recent works have adopted language models (LMs) as controllers of
visual modules for vision-and-language tasks. While existing work focuses on
equipping LMs with visual understanding, we propose two novel
interpretable/explainable visual programming frameworks for text-to-image (T2I)
generation and evaluation. First, we introduce VPGen, an interpretable
step-by-step T2I generation framework that decomposes T2I generation into three
steps: object/count generation, layout generation, and image generation. We
employ an LM to handle the first two steps (object/count generation and layout
generation), by finetuning it on text-layout pairs. Our step-by-step T2I
generation framework provides stronger spatial control than end-to-end models,
the dominant approach for this task. Furthermore, we leverage the world
knowledge of pretrained LMs, overcoming the limitation of previous
layout-guided T2I works that can only handle predefined object classes. We
demonstrate that our VPGen has improved control in counts/spatial
relations/scales of objects than state-of-the-art T2I generation models.
Second, we introduce VPEval, an interpretable and explainable evaluation
framework for T2I generation based on visual programming. Unlike previous T2I
evaluations with a single scoring model that is accurate in some skills but
unreliable in others, VPEval produces evaluation programs that invoke a set of
visual modules that are experts in different skills, and also provides
visual+textual explanations of the evaluation results. Our analysis shows
VPEval provides a more human-correlated evaluation for skill-specific and
open-ended prompts than widely used single model-based evaluation. We hope our
work encourages future progress on interpretable/explainable generation and
evaluation for T2I models. Website: this https URL</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Training on Thin Air: Improve Image Classification with Generated Data</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15316</p>
  <p><b>作者</b>：Yongchao Zhou,  Hshmat Sahak,  Jimmy Ba</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective predictive systems, building effective predictive, present Diffusion Inversion, Acquiring high-quality data, Stable Diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Acquiring high-quality data for training discriminative models is a crucial
yet challenging aspect of building effective predictive systems. In this paper,
we present Diffusion Inversion, a simple yet effective method that leverages
the pre-trained generative model, Stable Diffusion, to generate diverse,
high-quality training data for image classification. Our approach captures the
original data distribution and ensures data coverage by inverting images to the
latent space of Stable Diffusion, and generates diverse novel training images
by conditioning the generative model on noisy versions of these vectors. We
identify three key components that allow our generated images to successfully
supplant the original dataset, leading to a 2-3x enhancement in sample
complexity and a 6.5x decrease in sampling time. Moreover, our approach
consistently outperforms generic prompt-based steering methods and KNN
retrieval baseline across a wide range of datasets. Additionally, we
demonstrate the compatibility of our approach with widely-used data
augmentation techniques, as well as the reliability of the generated data in
supporting various neural architectures and enhancing few-shot learning.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Personalized Dictionary Learning for Heterogeneous Datasets</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15311</p>
  <p><b>作者</b>：Geyu Liang,  Naichen Shi,  Raed Al Kontar,  Salar Fattahi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging problem named, named Personalized Dictionary, introduce a relevant, relevant yet challenging, global and local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a relevant yet challenging problem named Personalized Dictionary
Learning (PerDL), where the goal is to learn sparse linear representations from
heterogeneous datasets that share some commonality. In PerDL, we model each
dataset's shared and unique features as global and local dictionaries.
Challenges for PerDL not only are inherited from classical dictionary learning
(DL), but also arise due to the unknown nature of the shared and unique
features. In this paper, we rigorously formulate this problem and provide
conditions under which the global and local dictionaries can be provably
disentangled. Under these conditions, we provide a meta-algorithm called
Personalized Matching and Averaging (PerMA) that can recover both global and
local dictionaries from heterogeneous datasets. PerMA is highly efficient; it
converges to the ground truth at a linear rate under suitable conditions.
Moreover, it automatically borrows strength from strong learners to improve the
prediction of weak learners. As a general framework for extracting global and
local dictionaries, we show the application of PerDL in different learning
tasks, such as training with imbalanced datasets and video surveillance.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal  Image Generation</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15296</p>
  <p><b>作者</b>：Marco Bellagente,  Manuel Brack,  Hannah Teufel,  Felix Friedrich,  Björn Deiseroth,  Constantin Eichenberg,  Andrew Dai,  Robert Baldock,  Souradeep Nanda,  Koen Oostermeijer,  Andres Felipe Cruz-Salinas,  Patrick Schramowski,  Kristian Kersting,  Samuel Weinbach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide to users, recent popularity, largely be attributed, intuitive interface, interface they provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent popularity of text-to-image diffusion models (DM) can largely be
attributed to the intuitive interface they provide to users. The intended
generation can be expressed in natural language, with the model producing
faithful interpretations of text prompts. However, expressing complex or
nuanced ideas in text alone can be difficult. To ease image generation, we
propose MultiFusion that allows one to express complex and nuanced concepts
with arbitrarily interleaved inputs of multiple modalities and languages.
MutliFusion leverages pre-trained models and aligns them for integration into a
cohesive system, thereby avoiding the need for extensive training from scratch.
Our experimental results demonstrate the efficient transfer of capabilities
from individual modules to the downstream model. Specifically, the fusion of
all independent components allows the image generation module to utilize
multilingual, interleaved multimodal inputs despite being trained solely on
monomodal data in a single language.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：The Crucial Role of Normalization in Sharpness-Aware Minimization</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15287</p>
  <p><b>作者</b>：Yan Dai,  Kwangjun Ahn,  Suvrit Sra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed gradient-based optimizer, deep neural networks, recently proposed gradient-based, Sharpness-Aware Minimization, gradient-based optimizer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based
optimizer (Foret et al., ICLR 2021) that greatly improves the prediction
performance of deep neural networks. Consequently, there has been a surge of
interest in explaining its empirical success. We focus, in particular, on
understanding the role played by normalization, a key component of the SAM
updates. We theoretically and empirically study the effect of normalization in
SAM for both convex and non-convex functions, revealing two key roles played by
normalization: i) it helps in stabilizing the algorithm; and ii) it enables the
algorithm to drift along a continuum (manifold) of minima -- a property
identified by recent theoretical works that is the key to better performance.
We further argue that these two properties of normalization make SAM robust
against the choice of hyper-parameters, supporting the practicality of SAM. Our
conclusions are backed by various experiments.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Replicable Reinforcement Learning</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15284</p>
  <p><b>作者</b>：Eric Eaton,  Marcel Hussing,  Michael Kearns,  Jessica Sorrell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce identical outputs, algorithm produce identical, identical outputs, high probability, data sciences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The replicability crisis in the social, behavioral, and data sciences has led
to the formulation of algorithm frameworks for replicability -- i.e., a
requirement that an algorithm produce identical outputs (with high probability)
when run on two different samples from the same underlying distribution. While
still in its infancy, provably replicable algorithms have been developed for
many fundamental tasks in machine learning and statistics, including
statistical query learning, the heavy hitters problem, and distribution
testing. In this work we initiate the study of replicable reinforcement
learning, providing a provably replicable algorithm for parallel value
iteration, and a provably replicable version of R-max in the episodic setting.
These are the first formal replicability results for control problems, which
present different challenges for replication than batch learning settings.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Successor-Predecessor Intrinsic Exploration</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15277</p>
  <p><b>作者</b>：Changmin Yu,  Neil Burgess,  Maneesh Sahani,  Sam Gershman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intrinsic, intrinsic rewards, rewards, external rewards, Exploration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exploration is essential in reinforcement learning, particularly in
environments where external rewards are sparse. Here we focus on exploration
with intrinsic rewards, where the agent transiently augments the external
rewards with self-generated intrinsic rewards. Although the study of intrinsic
rewards has a long history, existing methods focus on composing the intrinsic
reward based on measures of future prospects of states, ignoring the
information contained in the retrospective structure of transition sequences.
Here we argue that the agent can utilise retrospective information to generate
explorative behaviour with structure-awareness, facilitating efficient
exploration based on global instead of local information. We propose
Successor-Predecessor Intrinsic Exploration (SPIE), an exploration algorithm
based on a novel intrinsic reward combining prospective and retrospective
information. We show that SPIE yields more efficient and ethologically
plausible exploratory behaviour in environments with sparse rewards and
bottleneck states than competing methods. We also implement SPIE in deep
reinforcement learning agents, and show that the resulting agent achieves
stronger empirical performance than existing methods on sparse-reward Atari
games.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Robust Sparse Mean Estimation via Incremental Learning</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15276</p>
  <p><b>作者</b>：Jianhao Ma,  Rui Ray Chen,  Yinghui He,  Salar Fattahi,  Wei Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：partially corrupted samples, corrupted samples drawn, sparse mean estimation, robust sparse, heavy-tailed distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the problem of robust sparse mean estimation, where
the goal is to estimate a $k$-sparse mean from a collection of partially
corrupted samples drawn from a heavy-tailed distribution. Existing estimators
face two critical challenges in this setting. First, they are limited by a
conjectured computational-statistical tradeoff, implying that any
computationally efficient algorithm needs $\tilde\Omega(k^2)$ samples, while
its statistically-optimal counterpart only requires $\tilde O(k)$ samples.
Second, the existing estimators fall short of practical use as they scale
poorly with the ambient dimension. This paper presents a simple mean estimator
that overcomes both challenges under moderate conditions: it runs in
near-linear time and memory (both with respect to the ambient dimension) while
requiring only $\tilde O(k)$ samples to recover the true mean. At the core of
our method lies an incremental learning phenomenon: we introduce a simple
nonconvex framework that can incrementally learn the top-$k$ nonzero elements
of the mean while keeping the zero elements arbitrarily small. Unlike existing
estimators, our method does not need any prior knowledge of the sparsity level
$k$. We prove the optimality of our estimator by providing a matching
information-theoretic lower bound. Finally, we conduct a series of simulations
to corroborate our theoretical findings. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Training Energy-Based Normalizing Flow with Score-Matching Objectives</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15267</p>
  <p><b>作者</b>：Chen-Hao Chao,  Wei-Fang Sun,  Yen-Chang Hsu,  Zsolt Kira,  Chun-Yi Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：energy-based normalizing flow, called energy-based normalizing, energy-based generative models, approach called energy-based, modeling approach called</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we establish a connection between the parameterization of
flow-based and energy-based generative models, and present a new flow-based
modeling approach called energy-based normalizing flow (EBFlow). We demonstrate
that by optimizing EBFlow with score-matching objectives, the computation of
Jacobian determinants for linear transformations can be entirely bypassed. This
feature enables the use of arbitrary linear layers in the construction of
flow-based models without increasing the computational time complexity of each
training iteration from $\mathcal{O}(D^2L)$ to $\mathcal{O}(D^3L)$ for an
$L$-layered model that accepts $D$-dimensional inputs. This makes the training
of EBFlow more efficient than the commonly-adopted maximum likelihood training
method. In addition to the reduction in runtime, we enhance the training
stability and empirical performance of EBFlow through a number of techniques
developed based on our analysis on the score-matching methods. The experimental
results demonstrate that our approach achieves a significant speedup compared
to maximum likelihood estimation, while outperforming prior efficient training
techniques with a noticeable margin in terms of negative log-likelihood (NLL).</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of  Language Model</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15265</p>
  <p><b>作者</b>：Zirui Liu,  Guanchu Wang,  Shaochen Zhong,  Zhaozhuo Xu,  Daochen Zha,  Ruixiang Tang,  Zhimeng Jiang,  Kaixiong Zhou,  Vipin Chaudhary,  Shuai Xu,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pre-trained language, increasingly difficult due, pre-trained language model, extensive memory usage, fine-tuning the large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid growth in model size, fine-tuning the large pre-trained
language model has become increasingly difficult due to its extensive memory
usage. Previous works usually focus on reducing the number of trainable
parameters in the network. While the model parameters do contribute to memory
usage, the primary memory bottleneck during training arises from storing
feature maps, also known as activations, as they are crucial for gradient
calculation. Notably, neural networks are usually trained using stochastic
gradient descent. We argue that in stochastic optimization, models can handle
noisy gradients as long as the gradient estimator is unbiased with reasonable
variance. Following this motivation, we propose a new family of unbiased
estimators called WTA-CRS, for matrix production with reduced variance, which
only requires storing the sub-sampled activations for calculating the gradient.
Our work provides both theoretical and experimental evidence that, in the
context of tuning transformers, our proposed estimators exhibit lower variance
compared to existing ones. By replacing the linear operation with our
approximated one in transformers, we can achieve up to 2.7$\times$ peak memory
reduction with almost no accuracy drop and enables up to $6.4\times$ larger
batch size. Under the same hardware, WTA-CRS enables better down-streaming task
performance by applying larger models and/or faster training speed with larger
batch sizes.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Collaborative World Models: An Online-Offline Transfer RL Approach</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15260</p>
  <p><b>作者</b>：Qi Wang,  Junming Yang,  Yunbo Wang,  Xin Jin,  Wenjun Zeng,  Xiaokang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Training visual reinforcement, Collaborative World Models, called Collaborative World, visual reinforcement learning, datasets is challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training visual reinforcement learning (RL) models in offline datasets is
challenging due to overfitting issues in representation learning and
overestimation problems in value function. In this paper, we propose a transfer
learning method called Collaborative World Models (CoWorld) to improve the
performance of visual RL under offline conditions. The core idea is to use an
easy-to-interact, off-the-shelf simulator to train an auxiliary RL model as the
online ``test bed'' for the offline policy learned in the target domain, which
provides a flexible constraint for the value function -- Intuitively, we want
to mitigate the overestimation problem of value functions outside the offline
data distribution without impeding the exploration of actions with potential
advantages. Specifically, CoWorld performs domain-collaborative representation
learning to bridge the gap between online and offline hidden state
distributions. Furthermore, it performs domain-collaborative behavior learning
that enables the source RL agent to provide target-aware value estimation,
allowing for effective offline policy regularization. Experiments show that
CoWorld significantly outperforms existing methods in offline visual control
tasks in DeepMind Control and Meta-World.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：LMs with a Voice: Spoken Language Modeling beyond Speech Tokens</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15255</p>
  <p><b>作者</b>：Eliya Nachmani,  Alon Levkovitch,  Julian Salazar,  Chulayutsh Asawaroengchai,  Soroosh Mariooryad,  RJ Skerry-Ryan,  Michelle Tadmor Ramanovich</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：present SPECTRON, adapting pre-trained language, approach to adapting, perform speech continuation, SPECTRON</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present SPECTRON, a novel approach to adapting pre-trained language models
(LMs) to perform speech continuation. By leveraging pre-trained speech
encoders, our model generates both text and speech outputs with the entire
system being trained end-to-end operating directly on spectrograms. Training
the entire model in the spectrogram domain simplifies our speech continuation
system versus existing cascade methods which use discrete speech
representations. We further show our method surpasses existing spoken language
models both in semantic content and speaker preservation while also benefiting
from the knowledge transferred from pre-existing models. Audio samples can be
found in our website this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Rethinking the Evaluation Protocol of Domain Generalization</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15253</p>
  <p><b>作者</b>：Han Yu,  Xingxuan Zhang,  Renzhe Xu,  Jiashuo Liu,  Yue He,  Peng Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging common knowledge, common knowledge learned, OOD generalization ability, test data information, OOD generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain generalization aims to solve the challenge of Out-of-Distribution
(OOD) generalization by leveraging common knowledge learned from multiple
training domains to generalize to unseen test domains. To accurately evaluate
the OOD generalization ability, it is necessary to ensure that test data
information is unavailable. However, the current domain generalization protocol
may still have potential test data information leakage. This paper examines the
potential risks of test data information leakage in two aspects of the current
protocol: pretraining on ImageNet and oracle model selection. We propose that
training from scratch and using multiple test domains would result in a more
precise evaluation of OOD generalization ability. We also rerun the algorithms
with the modified protocol and introduce a new leaderboard to encourage future
research in domain generalization with a fairer comparison.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Decision-Aware Actor-Critic with Function Approximation and Theoretical  Guarantees</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15249</p>
  <p><b>作者</b>：Sharan Vaswani,  Amirreza Kazemi,  Reza Babanezhad,  Nicolas Le Roux</p>
  <p><b>备注</b>：44 pages</p>
  <p><b>关键词</b>：policy gradient method, gradient method, value-based method, reinforcement learning, method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Actor-critic (AC) methods are widely used in reinforcement learning (RL) and
benefit from the flexibility of using any policy gradient method as the actor
and value-based method as the critic. The critic is usually trained by
minimizing the TD error, an objective that is potentially decorrelated with the
true goal of achieving a high reward with the actor. We address this mismatch
by designing a joint objective for training the actor and critic in a
decision-aware fashion. We use the proposed objective to design a generic, AC
algorithm that can easily handle any function approximation. We explicitly
characterize the conditions under which the resulting algorithm guarantees
monotonic policy improvement, regardless of the choice of the policy and critic
parameterization. Instantiating the generic algorithm results in an actor that
involves maximizing a sequence of surrogate functions (similar to TRPO, PPO)
and a critic that involves minimizing a closely connected objective. Using
simple bandit examples, we provably establish the benefit of the proposed
critic objective over the standard squared error. Finally, we empirically
demonstrate the benefit of our decision-aware actor-critic framework on simple
RL problems.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Machine Unlearning: its nature, scope, and importance for a "delete  culture"</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15242</p>
  <p><b>作者</b>：Luciano Floridi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, intellectual property, Language Models, explores the cultural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The article explores the cultural shift from recording to deleting
information in the digital age and its implications on privacy, intellectual
property (IP), and Large Language Models like ChatGPT. It begins by defining a
delete culture where information, in principle legal, is made unavailable or
inaccessible because unacceptable or undesirable, especially but not only due
to its potential to infringe on privacy or IP. Then it focuses on two
strategies in this context: deleting, to make information unavailable; and
blocking, to make it inaccessible. The article argues that both strategies have
significant implications, particularly for machine learning (ML) models where
information is not easily made unavailable. However, the emerging research area
of Machine Unlearning (MU) is highlighted as a potential solution. MU, still in
its infancy, seeks to remove specific data points from ML models, effectively
making them 'forget' completely specific information. If successful, MU could
provide a feasible means to manage the overabundance of information and ensure
a better protection of privacy and IP. However, potential ethical risks, such
as misuse, overuse, and underuse of MU, should be systematically studied to
devise appropriate policies.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Robust Classification via a Single Diffusion Model</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15241</p>
  <p><b>作者</b>：Huanran Chen,  Yinpeng Dong,  Zhengyi Wang,  Xiao Yang,  Chengqi Duan,  Hang Su,  Jun Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating realistic data, diffusion models, successfully applied, applied to improving, noises or generating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, diffusion models have been successfully applied to improving
adversarial robustness of image classifiers by purifying the adversarial noises
or generating realistic data for adversarial training. However, the
diffusion-based purification can be evaded by stronger adaptive attacks while
adversarial training does not perform well under unseen threats, exhibiting
inevitable limitations of these methods. To better harness the expressive power
of diffusion models, in this paper we propose Robust Diffusion Classifier
(RDC), a generative classifier that is constructed from a pre-trained diffusion
model to be adversarially robust. Our method first maximizes the data
likelihood of a given input and then predicts the class probabilities of the
optimized input using the conditional likelihood of the diffusion model through
Bayes' theorem. Since our method does not require training on particular
adversarial attacks, we demonstrate that it is more generalizable to defend
against multiple unseen threats. In particular, RDC achieves $73.24\%$ robust
accuracy against $\ell_\infty$ norm-bounded perturbations with
$\epsilon_\infty=8/255$ on CIFAR-10, surpassing the previous state-of-the-art
adversarial training models by $+2.34\%$. The findings highlight the potential
of generative classifiers by employing diffusion models for adversarial
robustness compared with the commonly studied discriminative classifiers.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Ethics and Deep Learning</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15239</p>
  <p><b>作者</b>：Travis LaCroix,  Simon J. D. Prince</p>
  <p><b>备注</b>：Copyright in this Work has been licensed exclusively to The MIT Press, this https URL, which will be releasing the final version to the public in 2023. All inquiries regarding rights should be addressed to The MIT Press, Rights and Permissions Department</p>
  <p><b>关键词</b>：Understanding Deep, Prince, Understanding, Deep, http URL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article appears as chapter 21 of Prince (2023, Understanding Deep
Learning); a complete draft of the textbook is available here:
this http URL. This chapter considers potential harms arising from the
design and use of AI systems. These include algorithmic bias, lack of
explainability, data privacy violations, militarization, fraud, and
environmental concerns. The aim is not to provide advice on being more ethical.
Instead, the goal is to express ideas and start conversations in key areas that
have received attention in philosophy, political science, and the broader
social sciences.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：On the road to more accurate mobile cellular traffic predictions</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15234</p>
  <p><b>作者</b>：Natalia Vassileva Vesselinova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：main contribution reported, substantially more accurate, main contribution, contribution reported, made substantially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The main contribution reported in the paper is a novel paradigm through which
mobile cellular traffic forecasting is made substantially more accurate.
Specifically, by incorporating freely available road metrics we characterise
the data generation process and spatial dependencies. Therefore, this provides
a means for improving the forecasting estimates. We employ highway flow and
average speed variables together with a cellular network traffic metric in a
light learning structure to predict the short-term future load on a cell
covering a segment of a highway. This is in sharp contrast to prior art that
mainly studies urban scenarios (with pedestrian and limited vehicular speeds)
and develops machine learning approaches that use exclusively network metrics
and meta information to make mid-term and long-term predictions. The learning
structure can be used at a cell or edge level, and can find application in both
federated and centralised learning.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Short and Straight: Geodesics on Differentiable Manifolds</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15228</p>
  <p><b>作者</b>：Daniel Kelshaw,  Luca Magri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, learning models provide, underlying data, discovered by machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manifolds discovered by machine learning models provide a compact
representation of the underlying data. Geodesics on these manifolds define
locally length-minimising curves and provide a notion of distance, which are
key for reduced-order modelling, statistical inference, and interpolation. In
this work, we first analyse existing methods for computing length-minimising
geodesics. We find that these are not suitable for obtaining valid paths, and
thus, geodesic distances. We remedy these shortcomings by leveraging numerical
tools from differential geometry, which provide the means to obtain
Hamiltonian-conserving geodesics. Second, we propose a model-based
parameterisation for distance fields and geodesic flows on continuous
manifolds. Our approach exploits a manifold-aware extension to the Eikonal
equation, eliminating the need for approximations or discretisation. Finally,
we develop a curvature-based training mechanism, sampling and scaling points in
regions of the manifold exhibiting larger values of the Ricci scalar. This
sampling and scaling approach ensures that we capture regions of the manifold
subject to higher degrees of geodesic deviation. Our proposed methods provide
principled means to compute valid geodesics and geodesic distances on
manifolds. This work opens opportunities for latent-space interpolation,
optimal control, and distance computation on differentiable manifolds.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Real time dense anomaly detection by learning on synthetic negative data</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15227</p>
  <p><b>作者</b>：Anja Delić,  Matej Grcić,  Siniša Šegvić</p>
  <p><b>备注</b>：3 pages</p>
  <p><b>关键词</b>：dense anomaly detection, anomaly detection rely, approaches to dense, dense anomaly, anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most approaches to dense anomaly detection rely on generative modeling or on
discriminative methods that train with negative data. We consider a recent
hybrid method that optimizes the same shared representation according to
cross-entropy of the discriminative predictions, and negative log likelihood of
the predicted energy-based density. We extend that work with a jointly trained
generative flow that samples synthetic negatives at the border of the inlier
distribution. The proposed extension provides potential to learn the hybrid
method without real negative data. Our experiments analyze the impact of
training with synthetic negative data and validate contribution of the
energy-based density during training and evaluation.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Multi-modal Machine Learning for Vehicle Rating Predictions Using Image,  Text, and Parametric Data</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15218</p>
  <p><b>作者</b>：Hanqi Su,  Binyang Song,  Faez Ahmed</p>
  <p><b>备注</b>：The paper submitted to IDETC/CIE2023, the International Design Engineering Technical Conferences & Computers and Information in Engineering Conference, has been accepted</p>
  <p><b>关键词</b>：configuring good vehicles, facilitate designing, designing and configuring, configuring good, Accurate vehicle rating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate vehicle rating prediction can facilitate designing and configuring
good vehicles. This prediction allows vehicle designers and manufacturers to
optimize and improve their designs in a timely manner, enhance their product
performance, and effectively attract consumers. However, most of the existing
data-driven methods rely on data from a single mode, e.g., text, image, or
parametric data, which results in a limited and incomplete exploration of the
available information. These methods lack comprehensive analyses and
exploration of data from multiple modes, which probably leads to inaccurate
conclusions and hinders progress in this field. To overcome this limitation, we
propose a multi-modal learning model for more comprehensive and accurate
vehicle rating predictions. Specifically, the model simultaneously learns
features from the parametric specifications, text descriptions, and images of
vehicles to predict five vehicle rating scores, including the total score,
critics score, performance score, safety score, and interior score. We compare
the multi-modal learning model to the corresponding unimodal models and find
that the multi-modal model's explanatory power is 4% - 12% higher than that of
the unimodal models. On this basis, we conduct sensitivity analyses using SHAP
to interpret our model and provide design and optimization directions to
designers and manufacturers. Our study underscores the importance of the
data-driven multi-modal learning approach for vehicle design, evaluation, and
optimization. We have made the code publicly available at
this http URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Shadow Cones: Unveiling Partial Orders in Hyperbolic Space</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15215</p>
  <p><b>作者</b>：Tao Yu,  Toni J.B. Liu,  Albert Tseng,  Christopher De Sa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce superior low-dimensional, superior low-dimensional embeddings, unattainable in Euclidean, Euclidean space, shown to produce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperbolic space has been shown to produce superior low-dimensional
embeddings of hierarchical structures that are unattainable in Euclidean space.
Building upon this, the entailment cone formulation of Ganea et al. uses
geodesically convex cones to embed partial orderings in hyperbolic space.
However, these entailment cones lack intuitive interpretations due to their
definitions via complex concepts such as tangent vectors and the exponential
map in Riemannian space. In this paper, we present shadow cones, an innovative
framework that provides a physically intuitive interpretation for defining
partial orders on general manifolds. This is achieved through the use of
metaphoric light sources and object shadows, inspired by the sun-earth-moon
relationship. Shadow cones consist of two primary classes: umbral and penumbral
cones. Our results indicate that shadow cones offer robust representation and
generalization capabilities across a variety of datasets, such as WordNet and
ConceptNet, thereby outperforming the top-performing entailment cones. Our
findings indicate that shadow cones offer an innovative, general approach to
geometrically encode partial orders, enabling better representation and
analysis of datasets with hierarchical structures.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Relating Implicit Bias and Adversarial Attacks through Intrinsic  Dimension</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15203</p>
  <p><b>作者</b>：Lorenzo Basile,  Nikos Karantzas,  Alberto D'Onofrio,  Luca Bortolussi,  Alex Rodriguez,  Fabio Anselmi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impressive performance, adversarial attacks, attacks, implicit bias, input data designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite their impressive performance in classification, neural networks are
known to be vulnerable to adversarial attacks. These attacks are small
perturbations of the input data designed to fool the model. Naturally, a
question arises regarding the potential connection between the architecture,
settings, or properties of the model and the nature of the attack. In this
work, we aim to shed light on this problem by focusing on the implicit bias of
the neural network, which refers to its inherent inclination to favor specific
patterns or outcomes. Specifically, we investigate one aspect of the implicit
bias, which involves the essential Fourier frequencies required for accurate
image classification. We conduct tests to assess the statistical relationship
between these frequencies and those necessary for a successful attack. To delve
into this relationship, we propose a new method that can uncover non-linear
correlations between sets of coordinates, which, in our case, are the
aforementioned frequencies. By exploiting the entanglement between intrinsic
dimension and correlation, we provide empirical evidence that the network bias
in Fourier space and the target frequencies of adversarial attacks are closely
tied.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Feature-aligned N-BEATS with Sinkhorn divergence</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15196</p>
  <p><b>作者</b>：Myeongho Jeon,  Myungjoo Kang,  Joonhun Lee,  Kyunghyun Park</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose Feature-aligned N-BEATS, univariate time series, propose Feature-aligned, series forecasting problems, time series forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we propose Feature-aligned N-BEATS as a domain generalization
model for univariate time series forecasting problems. The proposed model is an
extension of the doubly residual stacking architecture of N-BEATS (Oreshkin et
al. [34]) into a representation learning framework. The model is a new
structure that involves marginal feature probability measures (i.e.,
pushforward measures of multiple source domains) induced by the intricate
composition of residual operators of N-BEATS in each stack and aligns them
stack-wise via an entropic regularized Wasserstein distance referred to as the
Sinkhorn divergence (Genevay et al. [14]). The loss function consists of a
typical forecasting loss for multiple source domains and an alignment loss
calculated with the Sinkhorn divergence, which allows the model to learn
invariant features stack-wise across multiple source data sequences while
retaining N-BEATS's interpretable design. We conduct a comprehensive
experimental evaluation of the proposed approach and the results demonstrate
the model's forecasting and generalization capabilities in comparison with
methods based on the original N-BEATS.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion  Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15194</p>
  <p><b>作者</b>：Sungnyun Kim,  Junsoo Lee,  Kibeom Hong,  Daesik Kim,  Namhyuk Ahn</p>
  <p><b>备注</b>：18 pages, 16 figures, and 3 tables</p>
  <p><b>关键词</b>：significantly expanded generative, expanded generative capabilities, progress in diffusion-based, recent progress, significantly expanded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent progress in diffusion-based text-to-image generation models has
significantly expanded generative capabilities via conditioning the text
descriptions. However, since relying solely on text prompts is still
restrictive for fine-grained customization, we aim to extend the boundaries of
conditional generation to incorporate diverse types of modalities, e.g.,
sketch, box, and style embedding, simultaneously. We thus design a multimodal
text-to-image diffusion model, coined as DiffBlender, that achieves the
aforementioned goal in a single model by training only a few small
hypernetworks. DiffBlender facilitates a convenient scaling of input
modalities, without altering the parameters of an existing large-scale
generative model to retain its well-established knowledge. Furthermore, our
study sets new standards for multimodal generation by conducting quantitative
and qualitative comparisons with existing approaches. By diversifying the
channels of conditioning modalities, DiffBlender faithfully reflects the
provided information or, in its absence, creates imaginative generation.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Adaptive Policy Learning to Additional Tasks</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15193</p>
  <p><b>作者</b>：Wenjian Hao,  Zehui Lu,  Zihao Liang,  Tianyu Zhou,  Shaoshuai Mou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：additional tasks, original task, tuning a pre-trained, adapt to additional, altering the original</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper develops a policy learning method for tuning a pre-trained policy
to adapt to additional tasks without altering the original task. A method named
Adaptive Policy Gradient (APG) is proposed in this paper, which combines
Bellman's principle of optimality with the policy gradient approach to improve
the convergence rate. This paper provides theoretical analysis which guarantees
the convergence rate and sample complexity of $\mathcal{O}(1/T)$ and
$\mathcal{O}(1/\epsilon)$, respectively, where $T$ denotes the number of
iterations and $\epsilon$ denotes the accuracy of the resulting stationary
policy. Furthermore, several challenging numerical simulations, including
cartpole, lunar lander, and robot arm, are provided to show that APG obtains
similar performance compared to existing deterministic policy gradient methods
while utilizing much less data and converging at a faster rate.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball  Trajectory Prediction with Spin and Impacts</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15189</p>
  <p><b>作者</b>：Jan Achterhold,  Philip Tobuschat,  Hao Ma,  Dieter Buechler,  Michael Muehlebach,  Joerg Stueckler</p>
  <p><b>备注</b>：Accepted for publication at the 5th Annual Conference on Learning for Dynamics and Control (L4DC) 2023. With supplementary material</p>
  <p><b>关键词</b>：table tennis ball, present a method, method for table, table tennis, tennis ball trajectory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a method for table tennis ball trajectory filtering
and prediction. Our gray-box approach builds on a physical model. At the same
time, we use data to learn parameters of the dynamics model, of an extended
Kalman filter, and of a neural model that infers the ball's initial condition.
We demonstrate superior prediction performance of our approach over two
black-box approaches, which are not supplied with physical prior knowledge. We
demonstrate that initializing the spin from parameters of the ball launcher
using a neural network drastically improves long-time prediction performance
over estimating the spin purely from measured ball positions. An accurate
prediction of the ball trajectory is crucial for successful returns. We
therefore evaluate the return performance with a pneumatic artificial muscular
robot and achieve a return rate of 29/30 (97.7%).</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Policy Learning based on Deep Koopman Representation</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15188</p>
  <p><b>作者</b>：Wenjian Hao,  Paulo C. Heredia,  Bowen Huang,  Zehui Lu,  Zihao Liang,  Shaoshuai Mou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Koopman operator theory, unknown dynamical system, optimal policy simultaneously, policy gradient approach, learning algorithm based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a policy learning algorithm based on the Koopman operator
theory and policy gradient approach, which seeks to approximate an unknown
dynamical system and search for optimal policy simultaneously, using the
observations gathered through interaction with the environment. The proposed
algorithm has two innovations: first, it introduces the so-called deep Koopman
representation into the policy gradient to achieve a linear approximation of
the unknown dynamical system, all with the purpose of improving data
efficiency; second, the accumulated errors for long-term tasks induced by
approximating system dynamics are avoided by applying Bellman's principle of
optimality. Furthermore, a theoretical analysis is provided to prove the
asymptotic convergence of the proposed algorithm and characterize the
corresponding sampling complexity. These conclusions are also supported by
simulations on several challenging benchmark environments.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Using Models Based on Cognitive Theory to Predict Human Behavior in  Traffic: A Case Study</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15187</p>
  <p><b>作者</b>：Julian F. Schumann,  Aravinda Ramakrishnan Srinivasan,  Jens Kober,  Gustav Markkula,  Arkady Zgonnikov</p>
  <p><b>备注</b>：6 pages, 2 figures</p>
  <p><b>关键词</b>：time-efficient driving style, revolutionize transportation, driving style, potential to revolutionize, unable to ensure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of automated vehicles has the potential to revolutionize
transportation, but they are currently unable to ensure a safe and
time-efficient driving style. Reliable models predicting human behavior are
essential for overcoming this issue. While data-driven models are commonly used
to this end, they can be vulnerable in safety-critical edge cases. This has led
to an interest in models incorporating cognitive theory, but as such models are
commonly developed for explanatory purposes, this approach's effectiveness in
behavior prediction has remained largely untested so far. In this article, we
investigate the usefulness of the \emph{Commotions} model -- a novel
cognitively plausible model incorporating the latest theories of human
perception, decision-making, and motor control -- for predicting human behavior
in gap acceptance scenarios, which entail many important traffic interactions
such as lane changes and intersections. We show that this model can compete
with or even outperform well-established data-driven prediction models across
several naturalistic datasets. These results demonstrate the promise of
incorporating cognitive theory in behavior prediction models for automated
vehicles.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Mixture of Experts with Uncertainty Voting for Imbalanced Deep  Regression Problems</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15178</p>
  <p><b>作者</b>：Yuchang Jiang,  Vivien Sainte Fare Garnot,  Konrad Schindler,  Jan Dirk Wegner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying machine learning, real-world problems, imbalance is ubiquitous, ubiquitous when applying, applying machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data imbalance is ubiquitous when applying machine learning to real-world
problems, particularly regression problems. If training data are imbalanced,
the learning is dominated by the densely covered regions of the target
distribution, consequently, the learned regressor tends to exhibit poor
performance in sparsely covered regions. Beyond standard measures like
over-sampling or re-weighting, there are two main directions to handle learning
from imbalanced data. For regression, recent work relies on the continuity of
the distribution; whereas for classification there has been a trend to employ
mixture-of-expert models and let some ensemble members specialize in
predictions for the sparser regions. Here, we adapt the mixture-of-experts
approach to the regression setting. A main question when using this approach is
how to fuse the predictions from multiple experts into one output. Drawing
inspiration from recent work on probabilistic deep learning, we propose to base
the fusion on the aleatoric uncertainties of individual experts, thus obviating
the need for a separate aggregation module. In our method, dubbed MOUV, each
expert predicts not only an output value but also its uncertainty, which in
turn serves as a statistically motivated criterion to rely on the right
experts. We compare our method with existing alternatives on multiple public
benchmarks and show that MOUV consistently outperforms the prior art, while at
the same time producing better calibrated uncertainty estimates. Our code is
available at link-upon-publication.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Simultaneous identification of models and parameters of scientific  simulators</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15174</p>
  <p><b>作者</b>：Cornelius Schröder,  Jakob H. Macke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model components, components, model, multiple discrete components, scien tists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many scientific models are composed of multiple discrete components, and
scien tists often make heuristic decisions about which components to include.
Bayesian inference provides a mathematical framework for systematically
selecting model components, but defining prior distributions over model
components and developing associated inference schemes has been challenging. We
approach this problem in an amortized simulation-based inference framework: We
define implicit model priors over a fixed set of candidate components and train
neural networks to infer joint probability distributions over both, model
components and associated parameters from simulations. To represent
distributions over model components, we introduce a conditional mixture of
multivariate binary distributions in the Grassmann formalism. Our approach can
be applied to any compositional stochastic simulator without requiring access
to likelihood evaluations. We first illustrate our method on a simple time
series model with redundant components and show that it can retrieve joint
posterior distribution over a set of symbolic expressions and their parameters
while accurately capturing redundancy with strongly correlated posteriors. We
then apply our approach to drift-diffusion models, a commonly used model class
in cognitive neuroscience. After validating the method on synthetic data, we
show that our approach explains experimental data as well as previous methods,
but that our fully probabilistic approach can help to discover multiple
data-consistent model configurations, as well as reveal non-identifiable model
components and parameters. Our method provides a powerful tool for data-driven
scientific inquiry which will allow scientists to systematically identify
essential model components and make uncertainty-informed modelling decisions.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Personalized DP-SGD using Sampling Mechanisms</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15165</p>
  <p><b>作者</b>：Geon Heo,  Junseok Seo,  Steven Euijong Whang</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：Stochastic Gradient Descent, Differentially Private Stochastic, Private Stochastic Gradient, privacy, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized privacy becomes critical in deep learning for Trustworthy AI.
While Differentially Private Stochastic Gradient Descent (DP-SGD) is widely
used in deep learning methods supporting privacy, it provides the same level of
privacy to all individuals, which may lead to overprotection and low utility.
In practice, different users may require different privacy levels, and the
model can be improved by using more information about the users with lower
privacy requirements. There are also recent works on differential privacy of
individuals when using DP-SGD, but they are mostly about individual privacy
accounting and do not focus on satisfying different privacy levels. We thus
extend DP-SGD to support a recent privacy notion called
($\Phi$,$\Delta$)-Personalized Differential Privacy (($\Phi$,$\Delta$)-PDP),
which extends an existing PDP concept called $\Phi$-PDP. Our algorithm uses a
multi-round personalized sampling mechanism and embeds it within the DP-SGD
iterations. Experiments on real datasets show that our algorithm outperforms
DP-SGD and simple combinations of DP-SGD with existing PDP mechanisms in terms
of model performance and efficiency due to its embedded sampling mechanism.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Towards More Suitable Personalization in Federated Learning via  Decentralized Partial Model Training</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15157</p>
  <p><b>作者</b>：Yifan Shi,  Yingqi Liu,  Yan Sun,  Zihao Lin,  Li Shen,  Xueqian Wang,  Dacheng Tao</p>
  <p><b>备注</b>：26 pages</p>
  <p><b>关键词</b>：Personalized federated learning, federated learning, aims to produce, insurmountable problem, real FL systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized federated learning (PFL) aims to produce the greatest
personalized model for each client to face an insurmountable problem--data
heterogeneity in real FL systems. However, almost all existing works have to
face large communication burdens and the risk of disruption if the central
server fails. Only limited efforts have been used in a decentralized way but
still suffers from inferior representation ability due to sharing the full
model with its neighbors. Therefore, in this paper, we propose a personalized
FL framework with a decentralized partial model training called DFedAlt. It
personalizes the "right" components in the modern deep models by alternately
updating the shared and personal parameters to train partially personalized
models in a peer-to-peer manner. To further promote the shared parameters
aggregation process, we propose DFedSalt integrating the local Sharpness Aware
Minimization (SAM) optimizer to update the shared parameters. It adds proper
perturbation in the direction of the gradient to overcome the shared model
inconsistency across clients. Theoretically, we provide convergence analysis of
both algorithms in the general non-convex setting for decentralized partial
model training in PFL. Our experiments on several real-world data with various
data partition settings demonstrate that (i) decentralized training is more
suitable for partial personalization, which results in state-of-the-art (SOTA)
accuracy compared with the SOTA PFL baselines; (ii) the shared parameters with
proper perturbation make partial personalized FL more suitable for
decentralized training, where DFedSalt achieves most competitive performance.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Momentum Provably Improves Error Feedback!</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15155</p>
  <p><b>作者</b>：Ilyas Fatkhullin,  Alexander Tyurin,  Peter Richtárik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training machine learning, machine learning models, modern algorithms invariably, high communication overhead, lossy communication compression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the high communication overhead when training machine learning models
in a distributed environment, modern algorithms invariably rely on lossy
communication compression. However, when untreated, the errors caused by
compression propagate, and can lead to severely unstable behavior, including
exponential divergence. Almost a decade ago, Seide et al [2014] proposed an
error feedback (EF) mechanism, which we refer to as EF14, as an immensely
effective heuristic for mitigating this issue. However, despite steady
algorithmic and theoretical advances in the EF field in the last decade, our
understanding is far from complete. In this work we address one of the most
pressing issues. In particular, in the canonical nonconvex setting, all known
variants of EF rely on very large batch sizes to converge, which can be
prohibitive in practice. We propose a surprisingly simple fix which removes
this issue both theoretically, and in practice: the application of Polyak's
momentum to the latest incarnation of EF due to Richtárik et al. [2021]
known as EF21. Our algorithm, for which we coin the name EF21-SGDM, improves
the communication and sample complexities of previous error feedback algorithms
under standard smoothness and bounded variance assumptions, and does not
require any further strong assumptions such as bounded gradient dissimilarity.
Moreover, we propose a double momentum version of our method that improves the
complexities even further. Our proof seems to be novel even when compression is
removed from the method, and as such, our proof technique is of independent
interest in the study of nonconvex stochastic optimization enriched with
Polyak's momentum.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Reliability Scores from Saliency Map Clusters for Improved Image-based  Harvest-Readiness Prediction in Cauliflower</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15149</p>
  <p><b>作者</b>：Jana Kierdorf,  Ribana Roscher</p>
  <p><b>备注</b>：Preprint, 8 pages, 6 figures</p>
  <p><b>关键词</b>：fulfill high-quality standards, harvest important, hand-harvested crop, fulfill high-quality, high-quality standards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cauliflower is a hand-harvested crop that must fulfill high-quality standards
in sales making the timing of harvest important. However, accurately
determining harvest-readiness can be challenging due to the cauliflower head
being covered by its canopy. While deep learning enables automated
harvest-readiness estimation, errors can occur due to field-variability and
limited training data. In this paper, we analyze the reliability of a
harvest-readiness classifier with interpretable machine learning. By
identifying clusters of saliency maps, we derive reliability scores for each
classification result using knowledge about the domain and the image
properties. For unseen data, the reliability can be used to (i) inform farmers
to improve their decision-making and (ii) increase the model prediction
accuracy. Using RGB images of single cauliflower plants at different
developmental stages from the GrowliFlower dataset, we investigate various
saliency mapping approaches and find that they result in different quality of
reliability scores. With the most suitable interpretation tool, we adjust the
classification result and achieve a 15.72% improvement of the overall accuracy
to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for
the GrowliFlower dataset.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Theoretically Principled Federated Learning for Balancing Privacy and  Utility</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15148</p>
  <p><b>作者</b>：Xiaojin Zhang,  Wenjie Li,  Kai Chen,  Shutao Xia,  Qiang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general learning framework, distorting model parameters, propose a general, mechanisms that protects, protects privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a general learning framework for the protection mechanisms that
protects privacy via distorting model parameters, which facilitates the
trade-off between privacy and utility. The algorithm is applicable to arbitrary
privacy measurements that maps from the distortion to a real value. It can
achieve personalized utility-privacy trade-off for each model parameter, on
each client, at each communication round in federated learning. Such adaptive
and fine-grained protection can improve the effectiveness of privacy-preserved
federated learning.
Theoretically, we show that gap between the utility loss of the protection
hyperparameter output by our algorithm and that of the optimal protection
hyperparameter is sub-linear in the total number of iterations. The
sublinearity of our algorithm indicates that the average gap between the
performance of our algorithm and that of the optimal performance goes to zero
when the number of iterations goes to infinity. Further, we provide the
convergence rate of our proposed algorithm. We conduct empirical results on
benchmark datasets to verify that our method achieves better utility than the
baseline methods under the same privacy budget.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：From Tempered to Benign Overfitting in ReLU Neural Networks</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15141</p>
  <p><b>作者</b>：Guy Kornowski,  Gilad Yehudai,  Ohad Shamir</p>
  <p><b>备注</b>：43 pages</p>
  <p><b>关键词</b>：Overparameterized neural networks, perfectly fit noisy, fit noisy data, Overparameterized neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Overparameterized neural networks (NNs) are observed to generalize well even
when trained to perfectly fit noisy data. This phenomenon motivated a large
body of work on "benign overfitting", where interpolating predictors achieve
near-optimal performance. Recently, it was conjectured and empirically observed
that the behavior of NNs is often better described as "tempered overfitting",
where the performance is non-optimal yet also non-trivial, and degrades as a
function of the noise level. However, a theoretical justification of this claim
for non-linear NNs has been lacking so far. In this work, we provide several
results that aim at bridging these complementing views. We study a simple
classification setting with 2-layer ReLU NNs, and prove that under various
assumptions, the type of overfitting transitions from tempered in the extreme
case of one-dimensional data, to benign in high dimensions. Thus, we show that
the input dimension has a crucial role on the type of overfitting in this
setting, which we also validate empirically for intermediate dimensions.
Overall, our results shed light on the intricate connections between the
dimension, sample size, architecture and training algorithm on the one hand,
and the type of resulting overfitting on the other hand.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Topic-Guided Self-Introduction Generation for Social Media Users</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15138</p>
  <p><b>作者</b>：Chunpu Xu,  Jing Li,  Piji Li,  Min Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, social media self-introduction, personal interests, users, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Millions of users are active on social media. To allow users to better
showcase themselves and network with others, we explore the auto-generation of
social media self-introduction, a short sentence outlining a user's personal
interests. While most prior work profiles users with tags (e.g., ages), we
investigate sentence-level self-introductions to provide a more natural and
engaging way for users to know each other. Here we exploit a user's tweeting
history to generate their self-introduction. The task is non-trivial because
the history content may be lengthy, noisy, and exhibit various personal
interests. To address this challenge, we propose a novel unified topic-guided
encoder-decoder (UTGED) framework; it models latent topics to reflect salient
user interest, whose topic mixture then guides encoding a user's history and
topic words control decoding their self-introduction. For experiments, we
collect a large-scale Twitter dataset, and extensive results show the
superiority of our UTGED to the advanced encoder-decoder models without topic
modeling.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Beyond Individual Input for Deep Anomaly Detection on Tabular Data</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15121</p>
  <p><b>作者</b>：Hugo Thimonier,  Fabrice Popineau,  Arpad Rimmel,  Bich-Liên Doan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Anomaly detection, leverages Non-Parametric Transformers, deep anomaly detection, Anomaly, Non-Parametric Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection is crucial in various domains, such as finance, healthcare,
and cybersecurity. In this paper, we propose a novel deep anomaly detection
method for tabular data that leverages Non-Parametric Transformers (NPTs), a
model initially proposed for supervised tasks, to capture both feature-feature
and sample-sample dependencies. In a reconstruction-based framework, we train
the NPT model to reconstruct masked features of normal samples. We use the
model's ability to reconstruct the masked features during inference to generate
an anomaly score. To the best of our knowledge, our proposed method is the
first to combine both feature-feature and sample-sample dependencies for
anomaly detection on tabular datasets. We evaluate our method on an extensive
benchmark of tabular datasets and demonstrate that our approach outperforms
existing state-of-the-art methods based on both the F1-Score and AUROC.
Moreover, our work opens up new research directions for exploring the potential
of NPTs for other tasks on tabular data.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Fairness in Streaming Submodular Maximization over a Matroid Constraint</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15118</p>
  <p><b>作者</b>：Marwa El Halabi,  Federico Fusco,  Ashkan Norouzi-Fard,  Jakab Tardos,  Jakub Tarnawski</p>
  <p><b>备注</b>：Accepted to ICML 23</p>
  <p><b>关键词</b>：large-scale dataset, task of selecting, selecting a representative, representative subset, submodular maximization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Streaming submodular maximization is a natural model for the task of
selecting a representative subset from a large-scale dataset. If datapoints
have sensitive attributes such as gender or race, it becomes important to
enforce fairness to avoid bias and discrimination. This has spurred significant
interest in developing fair machine learning algorithms. Recently, such
algorithms have been developed for monotone submodular maximization under a
cardinality constraint.
In this paper, we study the natural generalization of this problem to a
matroid constraint. We give streaming algorithms as well as impossibility
results that provide trade-offs between efficiency, quality and fairness. We
validate our findings empirically on a range of well-known real-world
applications: exemplar-based clustering, movie recommendation, and maximum
coverage in social networks.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：CSTS: Conditional Semantic Textual Similarity</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15093</p>
  <p><b>作者</b>：Ameet Deshpande,  Carlos E. Jimenez,  Howard Chen,  Vishvak Murahari,  Victoria Graf,  Tanmay Rajpurohit,  Ashwin Kalyan,  Danqi Chen,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：question answering, information retrieval, embedding methods, applications in information, Semantic textual similarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic textual similarity (STS) has been a cornerstone task in NLP that
measures the degree of similarity between a pair of sentences, with
applications in information retrieval, question answering, and embedding
methods. However, it is an inherently ambiguous task, with the sentence
similarity depending on the specific aspect of interest. We resolve this
ambiguity by proposing a novel task called conditional STS (C-STS) which
measures similarity conditioned on an aspect elucidated in natural language
(hereon, condition). As an example, the similarity between the sentences "The
NBA player shoots a three-pointer." and "A man throws a tennis ball into the
air to serve." is higher for the condition "The motion of the ball." (both
upward) and lower for "The size of the ball." (one large and one small).
C-STS's advantages are two-fold: (1) it reduces the subjectivity and ambiguity
of STS, and (2) enables fine-grained similarity evaluation using diverse
conditions. C-STS contains almost 20,000 instances from diverse domains and we
evaluate several state-of-the-art models to demonstrate that even the most
performant fine-tuning and in-context learning models (GPT-4, Flan, SimCSE)
find it challenging, with Spearman correlation scores of <50. we encourage the community to evaluate their models on c-sts provide a more holistic view of semantic similarity and natural language understanding.< p>
  </50.></p></details>
</details>
<details>
  <summary>57. <b>标题：FedZero: Leveraging Renewable Excess Energy in Federated Learning</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15092</p>
  <p><b>作者</b>：Philipp Wiesner,  Ramin Khalili,  Dennis Grinwald,  Pratik Agrawal,  Lauritz Thamsen,  Odej Kao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enables distributed model, emerging machine learning, machine learning technique, distributed model training, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is an emerging machine learning technique that
enables distributed model training across data silos or edge devices without
data sharing. Yet, FL inevitably introduces inefficiencies compared to
centralized model training, which will further increase the already high energy
usage and associated carbon emissions of machine learning in the future.
Although the scheduling of workloads based on the availability of low-carbon
energy has received considerable attention in recent years, it has not yet been
investigated in the context of FL. However, FL is a highly promising use case
for carbon-aware computing, as training jobs constitute of energy-intensive
batch processes scheduled in geo-distributed environments.
We propose FedZero, a FL system that operates exclusively on renewable excess
energy and spare capacity of compute infrastructure to effectively reduce the
training's operational carbon emissions to zero. Based on energy and load
forecasts, FedZero leverages the spatio-temporal availability of excess energy
by cherry-picking clients for fast convergence and fair participation. Our
evaluation, based on real solar and load traces, shows that FedZero converges
considerably faster under the mentioned constraints than state-of-the-art
approaches, is highly scalable, and is robust against forecasting errors.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Unpaired Image-to-Image Translation via Neural Schrödinger Bridge</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15086</p>
  <p><b>作者</b>：Beomsu Kim,  Gihyun Kwon,  Kwanyoung Kim,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic differential equations, simulate stochastic differential, differential equations, powerful class, class of generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models are a powerful class of generative models which simulate
stochastic differential equations (SDEs) to generate data from noise. Although
diffusion models have achieved remarkable progress in recent years, they have
limitations in the unpaired image-to-image translation tasks due to the
Gaussian prior assumption. Schrödinger Bridge (SB), which learns an SDE to
translate between two arbitrary distributions, have risen as an attractive
solution to this problem. However, none of SB models so far have been
successful at unpaired translation between high-resolution images. In this
work, we propose the Unpaired Neural Schrödinger Bridge (UNSB), which
combines SB with adversarial training and regularization to learn a SB between
unpaired data. We demonstrate that UNSB is scalable, and that it successfully
solves various unpaired image-to-image translation tasks. Code:
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Understanding Arithmetic Reasoning in Language Models using Causal  Mediation Analysis</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15054</p>
  <p><b>作者</b>：Alessandro Stolfo,  Yonatan Belinkov,  Mrinmaya Sachan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：store information related, recent research, limited understanding, process and store, store information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical reasoning in large language models (LLMs) has garnered attention
in recent research, but there is limited understanding of how these models
process and store information related to arithmetic tasks. In this paper, we
present a mechanistic interpretation of LLMs for arithmetic-based questions
using a causal mediation analysis framework. By intervening on the activations
of specific model components and measuring the resulting changes in predicted
probabilities, we identify the subset of parameters responsible for specific
predictions. We analyze two pre-trained language models with different sizes
(2.8B and 6B parameters). Experimental results reveal that a small set of
mid-late layers significantly affect predictions for arithmetic-based
questions, with distinct activation patterns for correct and wrong predictions.
We also investigate the role of the attention mechanism and compare the model's
activation patterns for arithmetic queries with the prediction of factual
knowledge. Our findings provide insights into the mechanistic interpretation of
LLMs for arithmetic tasks and highlight the specific components involved in
arithmetic reasoning.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Test like you Train in Implicit Deep Learning</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15042</p>
  <p><b>作者</b>：Zaccharie Ramzi,  Pierre Ablin,  Gabriel Peyré,  Thomas Moreau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Equilibrium Networks, recently gained popularity, Deep Equilibrium, Equilibrium Networks, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Implicit deep learning has recently gained popularity with applications
ranging from meta-learning to Deep Equilibrium Networks (DEQs). In its general
formulation, it relies on expressing some components of deep learning pipelines
implicitly, typically via a root equation called the inner problem. In
practice, the solution of the inner problem is approximated during training
with an iterative procedure, usually with a fixed number of inner iterations.
During inference, the inner problem needs to be solved with new data. A popular
belief is that increasing the number of inner iterations compared to the one
used during training yields better performance. In this paper, we question such
an assumption and provide a detailed theoretical analysis in a simple setting.
We demonstrate that overparametrization plays a key role: increasing the number
of iterations at test time cannot improve performance for overparametrized
networks. We validate our theory on an array of implicit deep-learning
problems. DEQs, which are typically overparametrized, do not benefit from
increasing the number of iterations at inference while meta-learning, which is
typically not overparametrized, benefits from it.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：How to Distill your BERT: An Empirical Study on the Impact of Weight  Initialisation and Distillation Objectives</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15032</p>
  <p><b>作者</b>：Xinpeng Wang,  Leonie Weissweiler,  Hinrich Schütze,  Barbara Plank</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：compression of BERT, BERT models, shown to improve, improve compression, intermediate layer distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, various intermediate layer distillation (ILD) objectives have been
shown to improve compression of BERT models via Knowledge Distillation (KD).
However, a comprehensive evaluation of the objectives in both task-specific and
task-agnostic settings is lacking. To the best of our knowledge, this is the
first work comprehensively evaluating distillation objectives in both settings.
We show that attention transfer gives the best performance overall. We also
study the impact of layer choice when initializing the student from the teacher
layers, finding a significant impact on the performance in task-specific
distillation. For vanilla KD and hidden states transfer, initialisation with
lower layers of the teacher gives a considerable improvement over higher
layers, especially on the task of QNLI (up to an absolute percentage change of
17.8 in accuracy). Attention transfer behaves consistently under different
initialisation settings. We release our code as an efficient transformer-based
model distillation framework for further studies.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15021</p>
  <p><b>作者</b>：Yao Mu,  Qinglong Zhang,  Mengkang Hu,  Wenhai Wang,  Mingyu Ding,  Jun Jin,  Bin Wang,  Jifeng Dai,  Yu Qiao,  Ping Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：executing action sequences, accomplish long-horizon tasks, frontier in robotics, physical environments, Embodied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied AI is a crucial frontier in robotics, capable of planning and
executing action sequences for robots to accomplish long-horizon tasks in
physical environments. In this work, we introduce EmbodiedGPT, an end-to-end
multi-modal foundation model for embodied AI, empowering embodied agents with
multi-modal understanding and execution capabilities. To achieve this, we have
made the following efforts: (i) We craft a large-scale embodied planning
dataset, termed EgoCOT. The dataset consists of carefully selected videos from
the Ego4D dataset, along with corresponding high-quality language instructions.
Specifically, we generate a sequence of sub-goals with the "Chain of Thoughts"
mode for effective embodied planning. (ii) We introduce an efficient training
approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B
large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We
introduce a paradigm for extracting task-related features from LLM-generated
planning queries to form a closed loop between high-level planning and
low-level control. Extensive experiments show the effectiveness of EmbodiedGPT
on embodied tasks, including embodied planning, embodied control, visual
captioning, and visual question answering. Notably, EmbodiedGPT significantly
enhances the success rate of the embodied control task by extracting more
effective features. It has achieved a remarkable 1.6 times increase in success
rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World
benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Calc-X: Enriching Arithmetical Chain-of-Thoughts Datasets by Interaction  with Symbolic Systems</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15017</p>
  <p><b>作者</b>：Marek Kadlčík,  Michal Štefánik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work in enriching, non-parametric components, requiring arithmetical reasoning, report overviews, overviews our ongoing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report overviews our ongoing work in enriching chain-of-thoughts
datasets requiring arithmetical reasoning with the integration of
non-parametric components, such as a calculator. We conduct an analysis of
prominent relevant datasets such as GSM8K, Ape210K, AQuA-RAT, and MathQA and
propose a machine-processable HTML-like format specifically tailored for
working with semi-structured chains. By converting the datasets into this
unified format, we enable the effective integration of large language models
and symbolic systems, empowering them to tackle arithmetical reasoning tasks
more efficiently.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：An Unsupervised Method for Estimating Class Separability of Datasets  with Application to LLMs Fine-Tuning</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15016</p>
  <p><b>作者</b>：Najah Ghalyan,  Kostis Gourgoulias,  Yash Satsangi,  Sean Moran,  Maxime Labonne,  Joseph Sabelja</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leverages topological characteristics, class separability, estimate class separability, class separability estimated, proposed method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes an unsupervised method that leverages topological
characteristics of data manifolds to estimate class separability of the data
without requiring labels. Experiments conducted in this paper on several
datasets demonstrate a clear correlation and consistency between the class
separability estimated by the proposed method with supervised metrics like
Fisher Discriminant Ratio~(FDR) and cross-validation of a classifier, which
both require labels. This can enable implementing learning paradigms aimed at
learning from both labeled and unlabeled data, like semi-supervised and
transductive learning. This would be particularly useful when we have limited
labeled data and a relatively large unlabeled dataset that can be used to
enhance the learning process. The proposed method is implemented for language
model fine-tuning with automated stopping criterion by monitoring class
separability of the embedding-space manifold in an unsupervised setting. The
proposed methodology has been first validated on synthetic data, where the
results show a clear consistency between class separability estimated by the
proposed method and class separability computed by FDR. The method has been
also implemented on both public and internal data. The results show that the
proposed method can effectively aid -- without the need for labels -- a
decision on when to stop or continue the fine-tuning of a language model and
which fine-tuning iteration is expected to achieve a maximum classification
performance through quantification of the class separability of the embedding
manifold.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Local SGD Accelerates Convergence by Exploiting Second Order Information  of the Loss Function</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15013</p>
  <p><b>作者</b>：Linxuan Pan,  Shenghui Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical gradient descent, machine learning schemes, local statistical gradient, distributed machine learning, gradient descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With multiple iterations of updates, local statistical gradient descent
(L-SGD) has been proven to be very effective in distributed machine learning
schemes such as federated learning. In fact, many innovative works have shown
that L-SGD with independent and identically distributed (IID) data can even
outperform SGD. As a result, extensive efforts have been made to unveil the
power of L-SGD. However, existing analysis failed to explain why the multiple
local updates with small mini-batches of data (L-SGD) can not be replaced by
the update with one big batch of data and a larger learning rate (SGD). In this
paper, we offer a new perspective to understand the strength of L-SGD. We
theoretically prove that, with IID data, L-SGD can effectively explore the
second order information of the loss function. In particular, compared with
SGD, the updates of L-SGD have much larger projection on the eigenvectors of
the Hessian matrix with small eigenvalues, which leads to faster convergence.
Under certain conditions, L-SGD can even approach the Newton method. Experiment
results over two popular datasets validate the theoretical results.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：A RelEntLess Benchmark for Modelling Graded Relations between Named  Entities</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15002</p>
  <p><b>作者</b>：Asahi Ushio,  Jose Camacho Collados,  Steven Schockaert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing Knowledge Graphs, rank entity pairs, entity pairs based, hard to draw, draw a line</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relations such as "is influenced by", "is known for" or "is a competitor of"
are inherently graded: we can rank entity pairs based on how well they satisfy
these relations, but it is hard to draw a line between those pairs that satisfy
them and those that do not. Such graded relations play a central role in many
applications, yet they are typically not covered by existing Knowledge Graphs.
In this paper, we consider the possibility of using Large Language Models
(LLMs) to fill this gap. To this end, we introduce a new benchmark, in which
entity pairs have to be ranked according to how much they satisfy a given
graded relation. The task is formulated as a few-shot ranking problem, where
models only have access to a description of the relation and five prototypical
instances. We use the proposed benchmark to evaluate state-of-the-art relation
embedding strategies as well as several recent LLMs, covering both publicly
available LLMs and closed models such as GPT-4. Overall, we find a strong
correlation between model size and performance, with smaller Language Models
struggling to outperform a naive baseline. The results of the largest Flan-T5
and OPT models are remarkably strong, although a clear gap with human
performance remains.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Contrastive Training of Complex-Valued Autoencoders for Object Discovery</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15001</p>
  <p><b>作者</b>：Aleksandar Stanić,  Anand Gopalakrishnan,  Kazuki Irie,  Jürgen Schmidhuber</p>
  <p><b>备注</b>：26 pages, 14 figures</p>
  <p><b>关键词</b>：attention-based routing, object-centric models, slots, Synchrony-based models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current state-of-the-art object-centric models use slots and attention-based
routing for binding. However, this class of models has several conceptual
limitations: the number of slots is hardwired; all slots have equal capacity;
training has high computational cost; there are no object-level relational
factors within slots. Synchrony-based models in principle can address these
limitations by using complex-valued activations which store binding information
in their phase components. However, working examples of such synchrony-based
models have been developed only very recently, and are still limited to toy
grayscale datasets and simultaneous storage of less than three objects in
practice. Here we introduce architectural modifications and a novel contrastive
learning method that greatly improve the state-of-the-art synchrony-based
model. For the first time, we obtain a class of synchrony-based models capable
of discovering objects in an unsupervised manner in multi-object color datasets
and simultaneously representing more than three objects</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14998</p>
  <p><b>作者</b>：Saba Ahmadi,  Aishwarya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：UMIC, Hessel, CLIPScore, human judgment, correlation with human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and
UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image
captions, demonstrating a high correlation with human judgment. In this work,
our focus lies in evaluating the robustness of these metrics in scenarios that
require distinguishing between two captions with high lexical overlap but very
different meanings. Our findings reveal that despite their high correlation
with human judgment, both CLIPScore and UMIC struggle to identify fine-grained
errors in captions. However, when comparing different types of fine-grained
errors, both metrics exhibit limited sensitivity to implausibility of captions
and strong sensitivity to lack of sufficient visual grounding. Probing further
into the visual grounding aspect, we found that both CLIPScore and UMIC are
impacted by the size of image-relevant objects mentioned in the caption, and
that CLIPScore is also sensitive to the number of mentions of image-relevant
objects in the caption. In terms of linguistic aspects of a caption, we found
that both metrics lack the ability to comprehend negation, UMIC is sensitive to
caption lengths, and CLIPScore is insensitive to the structure of the sentence.
We hope our findings will serve as a valuable guide towards improving
reference-free evaluation in image captioning.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Reasoning with Language Model is Planning with World Model</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14992</p>
  <p><b>作者</b>：Shibo Hao,  Yi Gu,  Haodi Ma,  Joshua Jiahua Hong,  Zhen Wang,  Daisy Zhe Wang,  Zhiting Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, remarkable reasoning capabilities, shown remarkable reasoning, reasoning, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable reasoning capabilities,
especially when prompted to generate intermediate reasoning steps (e.g.,
Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are
easy for humans, such as generating action plans for executing tasks in a given
environment, or performing complex math, logical, and commonsense reasoning.
The deficiency stems from the key fact that LLMs lack an internal
$\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment
status, intermediate variable values) and simulate long-term outcomes of
actions. This prevents LLMs from performing deliberate planning akin to human
brains, which involves exploring alternative reasoning paths, anticipating
future states and rewards, and iteratively refining existing reasoning steps.
To overcome the limitations, we propose a new LLM reasoning framework,
$\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$
$\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning
agent, and incorporates a principled planning algorithm (based on Monto Carlo
Tree Search) for strategic exploration in the vast reasoning space. During
reasoning, the LLM (as agent) incrementally builds a reasoning tree under the
guidance of the LLM (as world model) and task-specific rewards, and obtains a
high-reward reasoning path efficiently with a proper balance between
exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of
challenging reasoning problems including plan generation, math reasoning, and
logical inference. Empirical results on these tasks demonstrate the superiority
of RAP over various strong baselines, including CoT and least-to-most prompting
with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%
relative improvement in a plan generation setting.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Non-adversarial Robustness of Deep Learning Methods for Computer Vision</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14986</p>
  <p><b>作者</b>：Gorana Gojić,  Vladimir Vincan,  Ognjen Kundačina,  Dragiša Mišković,  Dinu Dragan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distribution shifts caused, distribution shifts, natural variations, data distribution shifts, shifts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-adversarial robustness, also known as natural robustness, is a property
of deep learning models that enables them to maintain performance even when
faced with distribution shifts caused by natural variations in data. However,
achieving this property is challenging because it is difficult to predict in
advance the types of distribution shifts that may occur. To address this
challenge, researchers have proposed various approaches, some of which
anticipate potential distribution shifts, while others utilize knowledge about
the shifts that have already occurred to enhance model generalizability. In
this paper, we present a brief overview of the most recent techniques for
improving the robustness of computer vision methods, as well as a summary of
commonly used robustness benchmark datasets for evaluating the model's
performance under data distribution shifts. Finally, we examine the strengths
and limitations of the approaches reviewed and identify general trends in deep
learning robustness improvement for computer vision.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Adversarial robustness of amortized Bayesian inference</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14984</p>
  <p><b>作者</b>：Manuel Glöckler,  Michael Deistler,  Jakob H. Macke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：requires running potentially, running potentially costly, amortized Bayesian inference, costly inference procedures, inference procedures separately</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian inference usually requires running potentially costly inference
procedures separately for every new observation. In contrast, the idea of
amortized Bayesian inference is to initially invest computational cost in
training an inference network on simulated data, which can subsequently be used
to rapidly perform inference (i.e., to return estimates of posterior
distributions) for new observations. This approach has been applied to many
real-world models in the sciences and engineering, but it is unclear how robust
the approach is to adversarial perturbations in the observed data. Here, we
study the adversarial robustness of amortized Bayesian inference, focusing on
simulation-based estimation of multi-dimensional posterior distributions. We
show that almost unrecognizable, targeted perturbations of the observations can
lead to drastic changes in the predicted posterior and highly unrealistic
posterior predictive samples, across several benchmark tasks and a real-world
example from neuroscience. We propose a computationally efficient
regularization scheme based on penalizing the Fisher information of the
conditional density estimator, and show how it improves the adversarial
robustness of amortized Bayesian inference.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Improving Factuality of Abstractive Summarization without Sacrificing  Summary Quality</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14981</p>
  <p><b>作者</b>：Tanay Dixit,  Fei Wang,  Muhao Chen</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：widely studied topic, Improving factual consistency, studied topic, consistency of abstractive, widely studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving factual consistency of abstractive summarization has been a widely
studied topic. However, most of the prior works on training factuality-aware
models have ignored the negative effect it has on summary quality. We propose
EFACTSUM (i.e., Effective Factual Summarization), a candidate summary
generation and ranking technique to improve summary factuality without
sacrificing summary quality. We show that using a contrastive learning
framework with our refined candidate summaries leads to significant gains on
both factuality and similarity-based metrics. Specifically, we propose a
ranking strategy in which we effectively combine two metrics, thereby
preventing any conflict during training. Models trained using our approach show
up to 6 points of absolute improvement over the base model with respect to
FactCC on XSUM and 11 points on CNN/DM, without negatively affecting either
similarity-based metrics or absractiveness.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Probabilistic Exponential Integrators</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14978</p>
  <p><b>作者</b>：Nathanael Bosch,  Philipp Hennig,  Filip Tronarp</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Probabilistic solvers provide, uncertainty quantification, framework for simulation, provide a flexible, flexible and efficient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic solvers provide a flexible and efficient framework for
simulation, uncertainty quantification, and inference in dynamical systems.
However, like standard solvers, they suffer performance penalties for certain
stiff systems, where small steps are required not for reasons of numerical
accuracy but for the sake of stability. This issue is greatly alleviated in
semi-linear problems by the probabilistic exponential integrators developed in
this paper. By including the fast, linear dynamics in the prior, we arrive at a
class of probabilistic integrators with favorable properties. Namely, they are
proven to be L-stable, and in a certain case reduce to a classic exponential
integrator -- with the added benefit of providing a probabilistic account of
the numerical error. The method is also generalized to arbitrary non-linear
systems by imposing piece-wise semi-linearity on the prior via Jacobians of the
vector field at the previous estimates, resulting in probabilistic exponential
Rosenbrock methods. We evaluate the proposed methods on multiple stiff
differential equations and demonstrate their improved stability and efficiency
over established probabilistic solvers. The present contribution thus expands
the range of problems that can be effectively tackled within probabilistic
numerics.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14976</p>
  <p><b>作者</b>：Md Tawkat Islam Khondaker,  Abdul Waheed,  El Moatez Billah Nagoudi,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：recent emergence, brought a revolutionary, revolutionary change, Arabic NLP, Arabic NLP tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent emergence of ChatGPT has brought a revolutionary change in the
landscape of NLP. Although ChatGPT has consistently shown impressive
performance on English benchmarks, its exact capabilities on most other
languages remain largely unknown. To better understand ChatGPT's capabilities
on Arabic, we present a large-scale evaluation of the model on a broad range of
Arabic NLP tasks. Namely, we evaluate ChatGPT on 32 diverse natural language
understanding and generation tasks on over 60 different datasets. To the best
of our knowledge, our work offers the first performance analysis of ChatGPT on
Arabic NLP at such a massive scale. Our results show that, despite its success
on English benchmarks, ChatGPT trained in-context (few-shot) is consistently
outperformed by much smaller dedicated models finetuned on Arabic. These
results suggest that there is significant place for improvement for
instruction-tuned LLMs such as ChatGPT.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Block-local learning with probabilistic latent representations</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14974</p>
  <p><b>作者</b>：David Kappel,  Khaleelulla Khan Nazeer,  Cabrel Teguemne Fokam,  Christian Mayr,  Anand Subramoney</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm requires sequential, requires sequential updates, ubiquitous backpropagation algorithm, backpropagation algorithm requires, algorithm requires</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ubiquitous backpropagation algorithm requires sequential updates across
blocks of a network, introducing a locking problem. Moreover, backpropagation
relies on the transpose of weight matrices to calculate updates, introducing a
weight transport problem across blocks. Both these issues prevent efficient
parallelisation and horizontal scaling of models across devices. We propose a
new method that introduces a twin network that propagates information backwards
from the targets to the input to provide auxiliary local losses. Forward and
backward propagation can work in parallel and with different sets of weights,
addressing the problems of weight transport and locking. Our approach derives
from a statistical interpretation of end-to-end training which treats
activations of network layers as parameters of probability distributions. The
resulting learning framework uses these parameters locally to assess the
matching between forward and backward information. Error backpropagation is
then performed locally within each block, leading to `block-local' learning.
Several previously proposed alternatives to error backpropagation emerge as
special cases of our model. We present results on various tasks and
architectures, including transformers, demonstrating state-of-the-art
performance using block-local learning. These results provide a new principled
framework to train very large networks in a distributed setting and can also be
applied in neuromorphic systems.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Focus Your Attention (with Adaptive IIR Filters)</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14952</p>
  <p><b>作者</b>：Shahar Lutati,  Itamar Zimerman,  Lior Wolf</p>
  <p><b>备注</b>：11 pages, 4 figures</p>
  <p><b>关键词</b>：Infinite, Impulse Response, input sequence prior, applying conventional attention, filters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a new layer in which dynamic (i.e.,input-dependent) Infinite
Impulse Response (IIR) filters of order two are used to process the input
sequence prior to applying conventional attention. The input is split into
chunks, and the coefficients of these filters are determined based on previous
chunks to maintain causality. Despite their relatively low order, the causal
adaptive filters are shown to focus attention on the relevant sequence
elements. The layer performs on-par with state of the art networks, with a
fraction of the parameters and with time complexity that is sub-quadratic with
input size. The obtained layer is favorable to layers such as Heyna, GPT2, and
Mega, both with respect to the number of parameters and the obtained level of
performance on multiple long-range sequence problems.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Adversarial Demonstration Attacks on Large Language Models</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14950</p>
  <p><b>作者</b>：Jiongxiao Wang,  Zichen Liu,  Keun Hee Park,  Muhao Chen,  Chaowei Xiao</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：powerful large language, large language models, powerful large, large language, ICL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the emergence of more powerful large language models (LLMs), such as
ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence
in leveraging these models for specific tasks by utilizing data-label pairs as
precondition prompts. While incorporating demonstrations can greatly enhance
the performance of LLMs across various tasks, it may introduce a new security
concern: attackers can manipulate only the demonstrations without changing the
input to perform an attack. In this paper, we investigate the security concern
of ICL from an adversarial perspective, focusing on the impact of
demonstrations. We propose an ICL attack based on TextAttack, which aims to
only manipulate the demonstration without changing the input to mislead the
models. Our results demonstrate that as the number of demonstrations increases,
the robustness of in-context learning would decreases. Furthermore, we also
observe that adversarially attacked demonstrations exhibit transferability to
diverse input examples. These findings emphasize the critical security risks
associated with ICL and underscore the necessity for extensive research on the
robustness of ICL, particularly given its increasing significance in the
advancement of LLMs.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：How Predictable Are Large Language Model Capabilities? A Case Study on  BIG-bench</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14947</p>
  <p><b>作者</b>：Qinyuan Ye,  Harvey Yiyun Fu,  Xiang Ren,  Robin Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurately predict LLM, predict LLM performance, large language model, numbers of parameters, numbers of in-context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the predictability of large language model (LLM) capabilities:
given records of past experiments using different model families, numbers of
parameters, tasks, and numbers of in-context examples, can we accurately
predict LLM performance on new experiment configurations? Answering this
question has practical implications for LLM users (e.g., deciding which models
to try), developers (e.g., prioritizing evaluation on representative tasks),
and the research community (e.g., identifying hard-to-predict capabilities that
warrant further investigation).
We study the performance prediction problem on experiment records from
BIG-bench. On a random train-test split, an MLP-based predictor achieves RMSE
below 5%, demonstrating the presence of learnable patterns within the
experiment records. Further, we formulate the problem of searching for
"small-bench," an informative subset of BIG-bench tasks from which the
performance of the full set can be maximally recovered, and find a subset as
informative for evaluating new model families as BIG-bench Hard, while being 3x
smaller.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：In-Context Impersonation Reveals Large Language Models' Strengths and  Biases</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14930</p>
  <p><b>作者</b>：Leonard Salewski,  Stephan Alaniz,  Isabel Rio-Torto,  Eric Schulz,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：everyday conversations, adapt their vocabulary, LLMs, chosen roles, roles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Towards Reliable Misinformation Mitigation: Generalization, Uncertainty,  and GPT-4</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14928</p>
  <p><b>作者</b>：Kellin Pelrine,  Meilina Reksoprodjo,  Caleb Gupta,  Joel Christoph,  Reihaneh Rabbany</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical societal challenge, societal challenge, effective solution, current approaches, produce an effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Misinformation poses a critical societal challenge, and current approaches
have yet to produce an effective solution. We propose focusing on
generalization, soft classification, and leveraging recent large language
models to create more practical tools in contexts where perfect predictions
remain unattainable. We begin by demonstrating that GPT-4 and other language
models can outperform existing methods in the literature. Next, we explore
their generalization, revealing that GPT-4 and RoBERTa-large exhibit critical
differences in failure modes, which offer potential for significant performance
improvements. Finally, we show that these models can be employed in soft
classification frameworks to better quantify uncertainty. We find that models
with inferior hard classification results can achieve superior soft
classification performance. Overall, this research lays groundwork for future
tools that can drive real-world progress on misinformation.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Universal Self-adaptive Prompting</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14926</p>
  <p><b>作者</b>：Xingchen Wan,  Ruoxi Sun,  Hootan Nakhost,  Hanjun Dai,  Julian Martin Eisenschlos,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：10 pages, 3 figures, 4 tables (19 pages, 5 figures and 9 tables including references and appendices)</p>
  <p><b>关键词</b>：modern large language, impressive general zero-shot, automatic prompt design, hallmark of modern, modern large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A hallmark of modern large language models (LLMs) is their impressive general
zero-shot and few-shot abilities, often elicited through prompt-based and/or
in-context learning. However, while highly coveted and being the most general,
zero-shot performances in LLMs are still typically weaker due to the lack of
guidance and the difficulty of applying existing automatic prompt design
methods in general tasks when ground-truth labels are unavailable. In this
study, we address this by presenting Universal Self-adaptive Prompting (USP),
an automatic prompt design approach specifically tailored for zero-shot
learning (while compatible with few-shot). Requiring only a small amount of
unlabeled data & an inference-only LLM, USP is highly versatile: to achieve
universal prompting, USP categorizes a possible NLP task into one of the three
possible task types, and then uses a corresponding selector to select the most
suitable queries & zero-shot model-generated responses as
pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a
fully automated way. We evaluate zero-shot USP with two PaLM models, and
demonstrate performances that are considerably stronger than standard zero-shot
baselines and are comparable to or even superior than few-shot baselines across
more than 20 natural language understanding (NLU) and natural language
generation (NLG) tasks.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：SVDinsTN: An Integrated Method for Tensor Network Representation with  Efficient Structure Search</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14912</p>
  <p><b>作者</b>：Yu-Bang Zheng,  Xi-Le Zhao,  Junhua Zeng,  Chao Li,  Qibin Zhao,  Heng-Chao Li,  Ting-Zhu Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Tensor network, machine learning, powerful technique, analysis and machine, Existing TN-SS methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tensor network (TN) representation is a powerful technique for data analysis
and machine learning. It practically involves a challenging TN structure search
(TN-SS) problem, which aims to search for the optimal structure to achieve a
compact representation. Existing TN-SS methods mainly adopt a bi-level
optimization method that leads to excessive computational costs due to repeated
structure evaluations. To address this issue, we propose an efficient
integrated (single-level) method named SVD-inspired TN decomposition
(SVDinsTN), eliminating the need for repeated tedious structure evaluation. By
inserting a diagonal factor for each edge of the fully-connected TN, we
calculate TN cores and diagonal factors simultaneously, with factor sparsity
revealing the most compact TN structure. Experimental results on real-world
data demonstrate that SVDinsTN achieves approximately $10^2\sim{}10^3$ times
acceleration in runtime compared to the existing TN-SS methods while
maintaining a comparable level of representation ability.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：From Shortcuts to Triggers: Backdoor Defense with Denoised PoE</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14910</p>
  <p><b>作者</b>：Qin Liu,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：backdoor attacks, backdoor, data poisoning, attacks, diverse backdoor attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models are often at risk of diverse backdoor attacks, especially
data poisoning. Thus, it is important to investigate defense solutions for
addressing them. Existing backdoor defense methods mainly focus on backdoor
attacks with explicit triggers, leaving a universal defense against various
backdoor attacks with diverse triggers largely unexplored. In this paper, we
propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised
Product-of-Experts), which is inspired by the shortcut nature of backdoor
attacks, to defend various backdoor attacks. DPoE consists of two models: a
shallow model that captures the backdoor shortcuts and a main model that is
prevented from learning the backdoor shortcuts. To address the label flip
caused by backdoor attackers, DPoE incorporates a denoising design. Experiments
on SST-2 dataset show that DPoE significantly improves the defense performance
against various types of backdoor triggers including word-level,
sentence-level, and syntactic triggers. Furthermore, DPoE is also effective
under a more challenging but practical setting that mixes multiple types of
trigger.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Chain-of-Questions Training with Latent Answers for Robust Multistep  Question Answering</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14901</p>
  <p><b>作者</b>：Wang Zhu,  Jesse Thomason,  Robin Jia</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：robustly answer multistep, answer multistep questions, generating and answering, train a language, language model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We train a language model (LM) to robustly answer multistep questions by
generating and answering sub-questions. We propose Chain-of-Questions, a
framework that trains a model to generate sub-questions and sub-answers one at
a time by leveraging human annotated question decomposition meaning
representation (QDMR). The key technical challenge is that QDMR only contains
sub-questions but not answers to those sub-questions, so we treat sub-answers
as latent variables and optimize them using a novel dynamic mixture of Hard-EM
and MAPO. Chain-of-Questions greatly outperforms strong neuro-symbolic methods
by 9.0 F1 on DROP contrast set, and outperforms GPT-3.5 by 24.3 F1 on HOTPOTQA
adversarial set, thus demonstrating the effectiveness and robustness of our
framework.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Text encoders are performance bottlenecks in contrastive vision-language  models</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14897</p>
  <p><b>作者</b>：Amita Kamath,  Jack Hessel,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Performant vision-language, CLIP represent captions, CLIP represent, single vector, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Performant vision-language (VL) models like CLIP represent captions using a
single vector. How much information about language is lost in this bottleneck?
We first curate CompPrompts, a set of increasingly compositional image captions
that VL models should be able to capture (e.g., single object, to
object+property, to multiple interacting objects). Then, we train text-only
recovery probes that aim to reconstruct captions from single-vector text
representations produced by several VL models. This approach doesn't require
images, allowing us to test on a broader range of scenes compared to prior
work. We find that: 1) CLIP's text encoder falls short on object relationships,
attribute-object association, counting, and negations; 2) some text encoders
work significantly better than others; and 3) text-only recovery performance
predicts multi-modal matching performance on ControlledImCaps: a new evaluation
benchmark we collect+release consisting of fine-grained compositional
images+captions. Specifically -- our results suggest text-only recoverability
is a necessary (but not sufficient) condition for modeling compositional
factors in contrastive vision+language models. We release data+code.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Privacy Implications of Retrieval-Based Language Models</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14888</p>
  <p><b>作者</b>：Yangsibo Huang,  Samyak Gupta,  Zexuan Zhong,  Kai Li,  Danqi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated improved interpretability, incorporating retrieved text, Retrieval-based language models, improved interpretability, demonstrated improved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval-based language models (LMs) have demonstrated improved
interpretability, factuality, and adaptability compared to their parametric
counterparts, by incorporating retrieved text from external datastores. While
it is well known that parametric models are prone to leaking private data, it
remains unclear how the addition of a retrieval datastore impacts model
privacy. In this work, we present the first study of privacy risks in
retrieval-based LMs, particularly $k$NN-LMs. Our goal is to explore the optimal
design and training procedure in domains where privacy is of concern, aiming to
strike a balance between utility and privacy. Crucially, we find that $k$NN-LMs
are more susceptible to leaking private information from their private
datastore than parametric models. We further explore mitigations of privacy
risks. When privacy information is targeted and readily detected in the text,
we find that a simple sanitization step would completely eliminate the risks,
while decoupling query and key encoders achieves an even better utility-privacy
trade-off. Otherwise, we consider strategies of mixing public and private data
in both datastore and encoder training. While these methods offer modest
improvements, they leave considerable room for future work. Together, our
findings provide insights for practitioners to better understand and mitigate
privacy risks in retrieval-based LMs. Our code is available at:
this https URL .</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Reconstructive Neuron Pruning for Backdoor Defense</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14876</p>
  <p><b>作者</b>：Yige Li,  Xixiang Lyu,  Xingjun Ma,  Nodens Koren,  Lingjuan Lyu,  Bo Li,  Yu-Gang Jiang</p>
  <p><b>备注</b>：Accepted by ICML23</p>
  <p><b>关键词</b>：Deep neural networks, raising security concerns, Deep neural, neural networks, raising security</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have been found to be vulnerable to backdoor
attacks, raising security concerns about their deployment in mission-critical
applications. While existing defense methods have demonstrated promising
results, it is still not clear how to effectively remove backdoor-associated
neurons in backdoored DNNs. In this paper, we propose a novel defense called
\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons
via an unlearning and then recovering process. Specifically, RNP first unlearns
the neurons by maximizing the model's error on a small subset of clean samples
and then recovers the neurons by minimizing the model's error on the same data.
In RNP, unlearning is operated at the neuron level while recovering is operated
at the filter level, forming an asymmetric reconstructive learning procedure.
We show that such an asymmetric process on only a few clean samples can
effectively expose and prune the backdoor neurons implanted by a wide range of
attacks, achieving a new state-of-the-art defense performance. Moreover, the
unlearned model at the intermediate step of our RNP can be directly used to
improve other backdoor defense tasks including backdoor removal, trigger
recovery, backdoor label detection, and backdoor sample detection. Code is
available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Timeseries-aware Uncertainty Wrappers for Uncertainty Quantification of  Information-Fusion-Enhanced AI Models based on Machine Learning</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14872</p>
  <p><b>作者</b>：Janek Groß,  Michael Kläs,  Lisa Jöckel,  Pascal Gerber</p>
  <p><b>备注</b>：8 pages, 7 figures, VERDI workshop collocated with the DSN conference 2023</p>
  <p><b>关键词</b>：Artificial Intelligence, system architectures arises, reliable system architectures, components in cyber-physical, architectures arises</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of Artificial Intelligence (AI) components in cyber-physical
systems is becoming more common, the need for reliable system architectures
arises. While data-driven models excel at perception tasks, model outcomes are
usually not dependable enough for safety-critical applications. In this work,we
present a timeseries-aware uncertainty wrapper for dependable uncertainty
estimates on timeseries data. The uncertainty wrapper is applied in combination
with information fusion over successive model predictions in time. The
application of the uncertainty wrapper is demonstrated with a traffic sign
recognition use case. We show that it is possible to increase model accuracy
through information fusion and additionally increase the quality of uncertainty
estimates through timeseries-aware input quality features.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Utility-Probability Duality of Neural Networks</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14859</p>
  <p><b>作者</b>：Huang Bojun,  Fei Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural networks, modern neural networks, typically understood, distribution of desired, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is typically understood that the training of modern neural networks is a
process of fitting the probability distribution of desired output. However,
recent paradoxical observations in a number of language generation tasks let
one wonder if this canonical probability-based explanation can really account
for the empirical success of deep learning.
To resolve this issue, we propose an alternative utility-based explanation to
the standard supervised learning procedure in deep learning. The basic idea is
to interpret the learned neural network not as a probability model but as an
ordinal utility function that encodes the preference revealed in training data.
In this perspective, training of the neural network corresponds to a utility
learning process. Specifically, we show that for all neural networks with
softmax outputs, the SGD learning dynamic of maximum likelihood estimation
(MLE) can be seen as an iteration process that optimizes the neural network
toward an optimal utility function. This utility-based interpretation can
explain several otherwise-paradoxical observations about the neural networks
thus trained. Moreover, our utility-based theory also entails an equation that
can transform the learned utility values back to a new kind of probability
estimation with which probability-compatible decision rules enjoy dramatic
(double-digits) performance improvements.
These evidences collectively reveal a phenomenon of utility-probability
duality in terms of what modern neural networks are (truly) modeling: We
thought they are one thing (probabilities), until the unexplainable showed up;
changing mindset and treating them as another thing (utility values) largely
reconcile the theory, despite remaining subtleties regarding its original
(probabilistic) identity.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient  Pre-LN Transformers</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14858</p>
  <p><b>作者</b>：Zixuan Jiang,  Jiaqi Gu,  Hanqing Zhu,  David Z. Pan</p>
  <p><b>备注</b>：15 pages, 5 tables, code available at this https URL</p>
  <p><b>关键词</b>：machine learning applications, achieved great success, Transformers, learning applications, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have achieved great success in machine learning applications.
Normalization techniques, such as Layer Normalization (LayerNorm, LN) and Root
Mean Square Normalization (RMSNorm), play a critical role in accelerating and
stabilizing the training of Transformers. While LayerNorm recenters and
rescales input vectors, RMSNorm only rescales the vectors by their RMS value.
Despite being more computationally efficient, RMSNorm may compromise the
representation ability of Transformers. There is currently no consensus
regarding the preferred normalization technique, as some models employ
LayerNorm while others utilize RMSNorm, especially in recent large language
models. It is challenging to convert Transformers with one normalization to the
other type. While there is an ongoing disagreement between the two
normalization types, we propose a solution to unify two mainstream Transformer
architectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent
redundant mean information in the main branch of Pre-LN Transformers, we can
reduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose
the Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a
lossless compression of the zero-mean vectors. We formally establish the
equivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in
both training and inference. It implies that Pre-LN Transformers can be
substituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the
same arithmetic functionality along with free efficiency improvement.
Experiments demonstrate that we can reduce the training and inference time of
Pre-LN Transformers by up to 10%.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：SWAMP: Sparse Weight Averaging with Multiple Particles for Iterative  Magnitude Pruning</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14852</p>
  <p><b>作者</b>：Moonseok Choi,  Hyungi Lee,  Giung Nam,  Juho Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimal memory demands, accelerated inference speeds, memory demands, ever-increasing size, size of modern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the ever-increasing size of modern neural networks, the significance of
sparse architectures has surged due to their accelerated inference speeds and
minimal memory demands. When it comes to global pruning techniques, Iterative
Magnitude Pruning (IMP) still stands as a state-of-the-art algorithm despite
its simple nature, particularly in extremely sparse regimes. In light of the
recent finding that the two successive matching IMP solutions are linearly
connected without a loss barrier, we propose Sparse Weight Averaging with
Multiple Particles (SWAMP), a straightforward modification of IMP that achieves
performance comparable to an ensemble of two IMP solutions. For every
iteration, we concurrently train multiple sparse models, referred to as
particles, using different batch orders yet the same matching ticket, and then
weight average such models to produce a single mask. We demonstrate that our
method consistently outperforms existing baselines across different sparsities
through extensive experiments on various data and neural network structures.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Introducing Competition to Boost the Transferability of Targeted  Adversarial Examples through Clean Feature Mixup</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14846</p>
  <p><b>作者</b>：Junyoung Byun,  Myung-Joon Kwon,  Seungju Cho,  Yoonji Kim,  Changick Kim</p>
  <p><b>备注</b>：CVPR 2023 camera-ready</p>
  <p><b>关键词</b>：subtle input modifications, Deep neural networks, Deep neural, input modifications, incorrect predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks are widely known to be susceptible to adversarial
examples, which can cause incorrect predictions through subtle input
modifications. These adversarial examples tend to be transferable between
models, but targeted attacks still have lower attack success rates due to
significant variations in decision boundaries. To enhance the transferability
of targeted adversarial examples, we propose introducing competition into the
optimization process. Our idea is to craft adversarial perturbations in the
presence of two new types of competitor noises: adversarial perturbations
towards different target classes and friendly perturbations towards the correct
class. With these competitors, even if an adversarial example deceives a
network to extract specific features leading to the target class, this
disturbance can be suppressed by other competitors. Therefore, within this
competition, adversarial examples should take different attack strategies by
leveraging more diverse features to overwhelm their interference, leading to
improving their transferability to different models. Considering the
computational complexity, we efficiently simulate various interference from
these two types of competitors in feature space by randomly mixing up stored
clean features in the model inference and named this method Clean Feature Mixup
(CFM). Our extensive experimental results on the ImageNet-Compatible and
CIFAR-10 datasets show that the proposed method outperforms the existing
baselines with a clear margin. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Building Transportation Foundation Model via Generative Graph  Transformer</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14826</p>
  <p><b>作者</b>：Xuhong Wang,  Ding Wang,  Liang Chen,  Yilun Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：densely populated areas, Efficient traffic management, maintaining urban mobility, areas where congestion, expensive commutes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient traffic management is crucial for maintaining urban mobility,
especially in densely populated areas where congestion, accidents, and delays
can lead to frustrating and expensive commutes. However, existing prediction
methods face challenges in terms of optimizing a single objective and
understanding the complex composition of the transportation system. Moreover,
they lack the ability to understand the macroscopic system and cannot
efficiently utilize big data. In this paper, we propose a novel approach,
Transportation Foundation Model (TFM), which integrates the principles of
traffic simulation into traffic prediction. TFM uses graph structures and
dynamic graph generation algorithms to capture the participatory behavior and
interaction of transportation system actors. This data-driven and model-free
simulation method addresses the challenges faced by traditional systems in
terms of structural complexity and model accuracy and provides a foundation for
solving complex transportation problems with real data. The proposed approach
shows promising results in accurately predicting traffic outcomes in an urban
transportation setting.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Can Copyright be Reduced to Privacy?</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14822</p>
  <p><b>作者</b>：Niva Elkin-Koren,  Uri Hacohen,  Roi Livni,  Shay Moran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：copyrighted input content, increasing concern, produce outputs, remarkably similar, generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is an increasing concern that generative AI models may produce outputs
that are remarkably similar to the copyrighted input content on which they are
trained. This worry has escalated as the quality and complexity of generative
models have immensely improved, and the availability of large datasets
containing copyrighted material has increased. Researchers are actively
exploring strategies to mitigate the risk of producing infringing samples, and
a recent line of work suggests to employ techniques such as differential
privacy and other forms of algorithmic stability to safeguard copyrighted
content.
In this work, we examine the question whether algorithmic stability
techniques such as differential privacy are suitable to ensure the responsible
use of generative models without inadvertently violating copyright laws. We
argue that there are fundamental differences between privacy and copyright that
should not be overlooked. In particular we highlight that although algorithmic
stability may be perceived as a practical tool to detect copying, it does not
necessarily equate to copyright protection. Therefore, if it is adopted as
standard for copyright infringement, it may undermine copyright law intended
purposes.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Provable Offline Reinforcement Learning with Human Feedback</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14816</p>
  <p><b>作者</b>：Wenhao Zhan,  Masatoshi Uehara,  Nathan Kallus,  Jason D. Lee,  Wen Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offline reinforcement learning, reinforcement learning, learning with human, form of preference, general function approximation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the problem of offline reinforcement learning
with human feedback where feedback is available in the form of preference
between trajectory pairs rather than explicit rewards. Our proposed algorithm
consists of two main steps: (1) estimate the implicit reward using Maximum
Likelihood Estimation (MLE) with general function approximation from offline
data and (2) solve a distributionally robust planning problem over a confidence
set around the MLE. We consider the general reward setting where the reward can
be defined over the whole trajectory and provide a novel guarantee that allows
us to learn any target policy with a polynomial number of samples, as long as
the target policy is covered by the offline data. This guarantee is the first
of its kind with general function approximation. To measure the coverage of the
target policy, we introduce a new single-policy concentrability coefficient,
which can be upper bounded by the per-trajectory concentrability coefficient.
We also establish lower bounds that highlight the necessity of such
concentrability and the difference from standard RL, where state-action-wise
rewards are directly observed. We further extend and analyze our algorithm when
the feedback is given over action pairs.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：What functions can Graph Neural Networks compute on random graphs? The  role of Positional Encoding</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14814</p>
  <p><b>作者</b>：Nicolas Keriven (CNRS, IRISA),  Samuel Vaiter (CNRS, LJAD)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, Graph Neural, expressive power, aim to deepen</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We aim to deepen the theoretical understanding of Graph Neural Networks
(GNNs) on large graphs, with a focus on their expressive power. Existing
analyses relate this notion to the graph isomorphism problem, which is mostly
relevant for graphs of small sizes, or studied graph classification or
regression tasks, while prediction tasks on nodes are far more relevant on
large graphs. Recently, several works showed that, on very general random
graphs models, GNNs converge to certains functions as the number of nodes
grows. In this paper, we provide a more complete and intuitive description of
the function space generated by equivariant GNNs for node-tasks, through
general notions of convergence that encompass several previous examples. We
emphasize the role of input node features, and study the impact of node
Positional Encodings (PEs), a recent line of work that has been shown to yield
state-of-the-art results in practice. Through the study of several examples of
PEs on large random graphs, we extend previously known universality results to
significantly more general models. Our theoretical results hint at some
normalization tricks, which is shown numerically to have a positive impact on
GNN generalization on synthetic and real data. Our proofs contain new
concentration inequalities of independent interest.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak  Supervision for Text Classification</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14794</p>
  <p><b>作者</b>：Chengyu Dong,  Zihan Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：turn high-level human, high-level human heuristics, designing sophisticated methods, weakly supervised text, supervised text classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in weakly supervised text classification mostly focus on
designing sophisticated methods to turn high-level human heuristics into
quality pseudo-labels. In this paper, we revisit the seed matching-based
method, which is arguably the simplest way to generate pseudo-labels, and show
that its power was greatly underestimated. We show that the limited performance
of seed matching is largely due to the label bias injected by the simple
seed-match rule, which prevents the classifier from learning reliable
confidence for selecting high-quality pseudo-labels. Interestingly, simply
deleting the seed words present in the matched input texts can mitigate the
label bias and help learn better confidence. Subsequently, the performance
achieved by seed matching can be improved significantly, making it on par with
or even better than the state-of-the-art. Furthermore, to handle the case when
the seed words are not made known, we propose to simply delete the word tokens
in the input text randomly with a high deletion ratio. Remarkably, seed
matching equipped with this random deletion method can often achieve even
better performance than that with seed deletion.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Anthropomorphization of AI: Opportunities and Risks</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14784</p>
  <p><b>作者</b>：Ameet Deshpande,  Tanmay Rajpurohit,  Karthik Narasimhan,  Ashwin Kalyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attribute human-like traits, non-human entities, traits to non-human, attribute human-like, human-like traits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anthropomorphization is the tendency to attribute human-like traits to
non-human entities. It is prevalent in many social contexts -- children
anthropomorphize toys, adults do so with brands, and it is a literary device.
It is also a versatile tool in science, with behavioral psychology and
evolutionary biology meticulously documenting its consequences. With widespread
adoption of AI systems, and the push from stakeholders to make it human-like
through alignment techniques, human voice, and pictorial avatars, the tendency
for users to anthropomorphize it increases significantly. We take a dyadic
approach to understanding this phenomenon with large language models (LLMs) by
studying (1) the objective legal implications, as analyzed through the lens of
the recent blueprint of AI bill of rights and the (2) subtle psychological
aspects customization and anthropomorphization. We find that anthropomorphized
LLMs customized for different user bases violate multiple provisions in the
legislative blueprint. In addition, we point out that anthropomorphization of
LLMs affects the influence they can have on their users, thus having the
potential to fundamentally change the nature of human-AI interaction, with
potential for manipulation and negative influence. With LLMs being
hyper-personalized for vulnerable groups like children and patients among
others, our work is a timely and important contribution. We propose a
conservative strategy for the cautious use of anthropomorphization to improve
trustworthiness of AI systems.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Zero-shot Task Preference Addressing Enabled by Imprecise Bayesian  Continual Learning</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14782</p>
  <p><b>作者</b>：Pengyuan Lu,  Michele Caprio,  Eric Eaton,  Insup Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generic multi-task learning, multi-objective optimization, generic multi-task, nature of multi-objective, IBCL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Like generic multi-task learning, continual learning has the nature of
multi-objective optimization, and therefore faces a trade-off between the
performance of different tasks. That is, to optimize for the current task
distribution, it may need to compromise performance on some tasks to improve on
others. This means there exist multiple models that are each optimal at
different times, each addressing a distinct task-performance trade-off.
Researchers have discussed how to train particular models to address specific
preferences on these trade-offs. However, existing algorithms require
additional sample overheads -- a large burden when there are multiple, possibly
infinitely many, preferences. As a response, we propose Imprecise Bayesian
Continual Learning (IBCL). Upon a new task, IBCL (1) updates a knowledge base
in the form of a convex hull of model parameter distributions and (2) obtains
particular models to address preferences with zero-shot. That is, IBCL does not
require any additional training overhead to construct preference-addressing
models from its knowledge base. We show that models obtained by IBCL have
guarantees in identifying the preferred parameters. Moreover, experiments show
that IBCL is able to locate the Pareto set of parameters given a preference,
maintain similar to better performance than baseline methods, and significantly
reduce training overhead via zero-shot preference addressing.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Text Conditional Alt-Text Generation for Twitter Images</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14779</p>
  <p><b>作者</b>：Nikita Srivatsan,  Sofia Samaniego,  Omar Florez,  Taylor Berg-Kirkpatrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating alternative text, generating alternative, specifically Twitter, images shared, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we present an approach for generating alternative text (or
alt-text) descriptions for images shared on social media, specifically Twitter.
This task is more than just a special case of image captioning, as alt-text is
both more literally descriptive and context-specific. Also critically, images
posted to Twitter are often accompanied by user-written text that despite not
necessarily describing the image may provide useful context that if properly
leveraged can be informative -- e.g. the tweet may name an uncommon object in
the image that the model has not previously seen. We address this with a CLIP
prefix model that extracts an embedding of the image and passes it to a mapping
network that outputs a short sequence in word embedding space, or a ``prefix'',
to which we also concatenate the text from the tweet itself. This lets the
model condition on both visual and textual information from the post. The
combined multimodal prefix is then fed as a prompt to a pretrained language
model which autoregressively completes the sequence to generate the alt-text.
While prior work has used similar methods for captioning, ours is the first to
our knowledge that incorporates textual information from the associated social
media post into the prefix as well, and we further demonstrate through
ablations that utility of these two information sources stacks. We put forward
a new dataset scraped from Twitter and evaluate on it across a variety of
automated metrics as well as human evaluation, and show that our approach of
conditioning on both tweet text and visual information significantly
outperforms prior work.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Generative Modeling through the Semi-dual Formulation of Unbalanced  Optimal Transport</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14777</p>
  <p><b>作者</b>：Jaemoo Choi,  Jaewoong Choi,  Myungjoo Kang</p>
  <p><b>备注</b>：23 pages, 15 figures</p>
  <p><b>关键词</b>：problem investigates, cost function, map that bridges, transport map, UOT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimal Transport (OT) problem investigates a transport map that bridges two
distributions while minimizing a given cost function. In this regard, OT
between tractable prior distribution and data has been utilized for generative
modeling tasks. However, OT-based methods are susceptible to outliers and face
optimization challenges during training. In this paper, we propose a novel
generative model based on the semi-dual formulation of Unbalanced Optimal
Transport (UOT). Unlike OT, UOT relaxes the hard constraint on distribution
matching. This approach provides better robustness against outliers, stability
during training, and faster convergence. We validate these properties
empirically through experiments. Moreover, we study the theoretical upper-bound
of divergence between distributions in UOT. Our model outperforms existing
OT-based generative models, achieving FID scores of 2.97 on CIFAR-10 and 5.80
on CelebA-HQ-256.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Measuring the Knowledge Acquisition-Utilization Gap in Pretrained  Language Models</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14775</p>
  <p><b>作者</b>：Amirhossein Kazemnejad,  Mehdi Rezagholizadeh,  Prasanna Parthasarathi,  Sarath Chandar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：acquiring vast amounts, pre-trained language models, knowledge, performing downstream tasks, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While pre-trained language models (PLMs) have shown evidence of acquiring
vast amounts of knowledge, it remains unclear how much of this parametric
knowledge is actually usable in performing downstream tasks. We propose a
systematic framework to measure parametric knowledge utilization in PLMs. Our
framework first extracts knowledge from a PLM's parameters and subsequently
constructs a downstream task around this extracted knowledge. Performance on
this task thus depends exclusively on utilizing the model's possessed
knowledge, avoiding confounding factors like insufficient signal. As an
instantiation, we study factual knowledge of PLMs and measure utilization
across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps -
in acquired vs. utilized knowledge, (2) they show limited robustness in
utilizing knowledge under distribution shifts, and (3) larger models close the
acquired knowledge gap but the utilized knowledge gap remains. Overall, our
study provides insights into PLMs' capabilities beyond their acquired
knowledge.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：SUVR: A Search-based Approach to Unsupervised Visual Representation  Learning</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14754</p>
  <p><b>作者</b>：Yi-Zhan Xu,  Chih-Yao Chen,  Cheng-Te Li</p>
  <p><b>备注</b>：ICASSP 2023</p>
  <p><b>关键词</b>：collecting annotated data, annotated data, unlabeled data, grown in popularity, difficulty of collecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised learning has grown in popularity because of the difficulty of
collecting annotated data and the development of modern frameworks that allow
us to learn from unlabeled data. Existing studies, however, either disregard
variations at different levels of similarity or only consider negative samples
from one batch. We argue that image pairs should have varying degrees of
similarity, and the negative samples should be allowed to be drawn from the
entire dataset. In this work, we propose Search-based Unsupervised Visual
Representation Learning (SUVR) to learn better image representations in an
unsupervised manner. We first construct a graph from the image dataset by the
similarity between images, and adopt the concept of graph traversal to explore
positive samples. In the meantime, we make sure that negative samples can be
drawn from the full dataset. Quantitative experiments on five benchmark image
classification datasets demonstrate that SUVR can significantly outperform
strong competing methods on unsupervised embedding learning. Qualitative
experiments also show that SUVR can produce better representations in which
similar images are clustered closer together than unrelated images in the
latent space.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：A New Era in Software Security: Towards Self-Healing Software via Large  Language Models and Formal Verification</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14752</p>
  <p><b>作者</b>：Yiannis Charalambous,  Norbert Tihanyi,  Ridhi Jain,  Youcheng Sun,  Mohamed Amine Ferrag,  Lucas C. Cordeiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Formal Verification strategies, paper we present, solution that combines, combines the capabilities, Formal Verification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present a novel solution that combines the capabilities of
Large Language Models (LLMs) with Formal Verification strategies to verify and
automatically repair software vulnerabilities. Initially, we employ Bounded
Model Checking (BMC) to locate the software vulnerability and derive a
counterexample. The counterexample provides evidence that the system behaves
incorrectly or contains a vulnerability. The counterexample that has been
detected, along with the source code, are provided to the LLM engine. Our
approach involves establishing a specialized prompt language for conducting
code debugging and generation to understand the vulnerability's root cause and
repair the code. Finally, we use BMC to verify the corrected version of the
code generated by the LLM. As a proof of concept, we create ESBMC-AI based on
the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained
Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C
programs. Our experimentation involved generating a dataset comprising 1000 C
code samples, each consisting of 20 to 50 lines of code. Notably, our proposed
method achieved an impressive success rate of up to 80% in repairing vulnerable
code encompassing buffer overflow and pointer dereference failures. We assert
that this automated approach can effectively incorporate into the software
development lifecycle's continuous integration and deployment (CI/CD) process.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Multi-State RNA Design with Geometric Multi-Graph Neural Networks</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14749</p>
  <p><b>作者</b>：Chaitanya K. Joshi,  Arian R. Jamasb,  Ramon Viñas,  Charles Harris,  Simon Mathis,  Pietro Liò</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：therapeutic development, broad applications, applications across synthetic, synthetic biology, biology and therapeutic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computational RNA design has broad applications across synthetic biology and
therapeutic development. Fundamental to the diverse biological functions of RNA
is its conformational flexibility, enabling single sequences to adopt a variety
of distinct 3D states. Currently, computational biomolecule design tasks are
often posed as inverse problems, where sequences are designed based on adopting
a single desired structural conformation. In this work, we propose gRNAde, a
geometric RNA design pipeline that operates on sets of 3D RNA backbone
structures to explicitly account for and reflect RNA conformational diversity
in its designs. We demonstrate the utility of gRNAde for improving native
sequence recovery over single-state approaches on a new large-scale 3D RNA
design dataset, especially for multi-state and structurally diverse RNAs. Our
code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Applications of Machine Learning in Detecting Afghan Fake Banknotes</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14745</p>
  <p><b>作者</b>：Hamida Ashna,  Ziaullah Momand</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unauthorized imitation money, lacking government approval, imitation money lacking, money lacking government, unauthorized imitation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fake currency, unauthorized imitation money lacking government approval,
constitutes a form of fraud. Particularly in Afghanistan, the prevalence of
fake currency poses significant challenges and detrimentally impacts the
economy. While banks and commercial establishments employ authentication
machines, the public lacks access to such systems, necessitating a program that
can detect counterfeit banknotes accessible to all. This paper introduces a
method using image processing to identify counterfeit Afghan banknotes by
analyzing specific security features. Extracting first and second order
statistical features from input images, the WEKA machine learning tool was
employed to construct models and perform classification with Random Forest,
PART, and Naïve Bayes algorithms. The Random Forest algorithm achieved
exceptional accuracy of 99% in detecting fake Afghan banknotes, indicating the
efficacy of the proposed method as a solution for identifying counterfeit
currency.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14735</p>
  <p><b>作者</b>：Vyoma Raman,  Eve Fleisig,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determine performance discrepancies, standard method, method for measuring, measuring the impacts, marginalized communities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A standard method for measuring the impacts of AI on marginalized communities
is to determine performance discrepancies between specified demographic groups.
These approaches aim to address harms toward vulnerable groups, but they
obscure harm patterns faced by intersectional subgroups or shared across
demographic groups. We instead operationalize "the margins" as data points that
are statistical outliers due to having demographic attributes distant from the
"norm" and measure harms toward these outliers. We propose a Group-Based
Performance Disparity Index (GPDI) that measures the extent to which a
subdivision of a dataset into subgroups identifies those facing increased
harms. We apply our approach to detecting disparities in toxicity detection and
find that text targeting outliers is 28% to 86% more toxic for all types of
toxicity examined. We also discover that model performance is consistently
worse for demographic outliers, with disparities in error between outliers and
non-outliers ranging from 28% to 71% across toxicity types. Our outlier-based
analysis has comparable or higher GPDI than traditional subgroup-based
analyses, suggesting that outlier analysis enhances identification of subgroups
facing greater harms. Finally, we find that minoritized racial and religious
groups are most associated with outliers, which suggests that outlier analysis
is particularly beneficial for identifying harms against those groups.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：On the Generalization of Diffusion Model</b></summary>
  <p><b>编号</b>：[416]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14712</p>
  <p><b>作者</b>：Mingyang Yi,  Jiacheng Sun,  Zhenguo Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained diffusion model, diffusion model, training set, diffusion probabilistic generative, probabilistic generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The diffusion probabilistic generative models are widely used to generate
high-quality data. Though they can synthetic data that does not exist in the
training set, the rationale behind such generalization is still unexplored. In
this paper, we formally define the generalization of the generative model,
which is measured by the mutual information between the generated data and the
training set. The definition originates from the intuition that the model which
generates data with less correlation to the training set exhibits better
generalization ability. Meanwhile, we show that for the empirical optimal
diffusion model, the data generated by a deterministic sampler are all highly
related to the training set, thus poor generalization. This result contradicts
the observation of the trained diffusion model's (approximating empirical
optima) extrapolation ability (generating unseen data). To understand this
contradiction, we empirically verify the difference between the sufficiently
trained diffusion model and the empirical optima. We found, though obtained
through sufficient training, there still exists a slight difference between
them, which is critical to making the diffusion model generalizable. Moreover,
we propose another training objective whose empirical optimal solution has no
potential generalization problem. We empirically show that the proposed
training objective returns a similar model to the original one, which further
verifies the generalization ability of the trained diffusion model.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Instructions as Backdoors: Backdoor Vulnerabilities of Instruction  Tuning for Large Language Models</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14710</p>
  <p><b>作者</b>：Jiashu Xu,  Mingyu Derek Ma,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve superior performance, superior performance, data, Instruction-tuned models, achieve superior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction-tuned models are trained on crowdsourcing datasets with task
instructions to achieve superior performance. However, in this work we raise
security concerns about this training paradigm. Our studies demonstrate that an
attacker can inject backdoors by issuing very few malicious instructions among
thousands of gathered data and control model behavior through data poisoning,
without even the need of modifying data instances or labels themselves. Through
such instruction attacks, the attacker can achieve over 90% attack success rate
across four commonly used NLP datasets, and cause persistent backdoors that are
easily transferred to 15 diverse datasets zero-shot. In this way, the attacker
can directly apply poisoned instructions designed for one dataset on many other
datasets. Moreover, the poisoned model cannot be cured by continual learning.
Lastly, instruction attacks show resistance to existing inference-time defense.
These findings highlight the need for more robust defenses against data
poisoning attacks in instructiontuning models and underscore the importance of
ensuring data quality in instruction crowdsourcing.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Regret Matching+: (In)Stability and Fast Convergence in Games</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14709</p>
  <p><b>作者</b>：Gabriele Farina,  Julien Grand-Clément,  Christian Kroer,  Chung-Wei Lee,  Haipeng Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solving large-scale games, Regret Matching, variants are important, solving large-scale, Matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regret Matching+ (RM+) and its variants are important algorithms for solving
large-scale games. However, a theoretical understanding of their success in
practice is still a mystery. Moreover, recent advances on fast convergence in
games are limited to no-regret algorithms such as online mirror descent, which
satisfy stability. In this paper, we first give counterexamples showing that
RM+ and its predictive version can be unstable, which might cause other players
to suffer large regret. We then provide two fixes: restarting and chopping off
the positive orthant that RM+ works in. We show that these fixes are sufficient
to get $O(T^{1/4})$ individual regret and $O(1)$ social regret in normal-form
games via RM+ with predictions. We also apply our stabilizing techniques to
clairvoyant updates in the uncoupled learning setting for RM+ and prove
desirable results akin to recent works for Clairvoyant online mirror descent.
Our experiments show the advantages of our algorithms over vanilla RM+-based
algorithms in matrix and extensive-form games.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：The student becomes the master: Matching GPT3 on Scientific Factual  Error Correction</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14707</p>
  <p><b>作者</b>：Dhananjay Ashok,  Atharva Kulkarni,  Hai Pham,  Barnabás Póczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Factual Claim Correction, prohibitively high cost, creating error correction, Scientific Claim Correction, Factual Claim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the prohibitively high cost of creating error correction datasets,
most Factual Claim Correction methods rely on a powerful verification model to
guide the correction process. This leads to a significant drop in performance
in domains like Scientific Claim Correction, where good verification models do
not always exist. In this work, we introduce a claim correction system that
makes no domain assumptions and does not require a verifier but is able to
outperform existing methods by an order of magnitude -- achieving 94%
correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open
dataset, compared to the next best methods 0.5% and 1.50% respectively. Our
method leverages the power of prompting with LLMs during training to create a
richly annotated dataset that can be used for fully supervised training and
regularization. We additionally use a claim-aware decoding procedure to improve
the quality of corrected claims. Our method is competitive with the very LLM
that was used to generate the annotated dataset -- with GPT3.5 achieving 89.5%
and 60% correction accuracy on SciFact and SciFact-Open, despite using 1250
times as many parameters as our model.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：PruMUX: Augmenting Data Multiplexing with Model Compression</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14706</p>
  <p><b>作者</b>：Yushan Su,  Vishvak Murahari,  Karthik Narasimhan,  Kai Li</p>
  <p><b>备注</b>：Findings of the Association for Computational Linguistics (ACL 2023)</p>
  <p><b>关键词</b>：efficient inference, inference are critical, critical to leveraging, leveraging their capabilities, language models increase</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As language models increase in size by the day, methods for efficient
inference are critical to leveraging their capabilities for various
applications. Prior work has investigated techniques like model pruning,
knowledge distillation, and data multiplexing to increase model throughput
without sacrificing accuracy. In this paper, we combine two such methods --
structured pruning and data multiplexing -- to compound the speedup gains
obtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X
throughput improvement over BERT-base model with accuracy threshold from 80% to
74%. We further study various combinations of parameters (such as sparsity and
multiplexing factor) in the two techniques to provide a comprehensive analysis
of the tradeoff between accuracy and throughput in the resulting models. We
then propose Auto-PruMUX, a meta-level model that can predict the
high-performance parameters for pruning and multiplexing given a desired
accuracy loss budget, providing a practical method to leverage the combination
effectively.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：An Evaluation on Practical Batch Bayesian Sampling Algorithms for Online  Adaptive Traffic Experimentation</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14704</p>
  <p><b>作者</b>：Zezhong Zhang,  Ted Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian sampling algorithms, adaptive traffic experimentation, Bayesian batch bandit, Bayesian sampling, multi-armed bandit algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To speed up online testing, adaptive traffic experimentation through
multi-armed bandit algorithms is rising as an essential complementary
alternative to the fixed horizon A/B testing. Based on recent research on best
arm identification and statistical inference with adaptively collected data,
this paper derives and evaluates four Bayesian batch bandit algorithms (NB-TS,
WB-TS, NB-TTTS, WB-TTTS), which are combinations of two ways of weighting
batches (Naive Batch and Weighted Batch) and two Bayesian sampling strategies
(Thompson Sampling and Top-Two Thompson Sampling) to adaptively determine
traffic allocation. These derived Bayesian sampling algorithms are practically
based on summary batch statistics of a reward metric for pilot experiments,
where one of the combination WB-TTTS in this paper seems to be newly discussed.
The comprehensive evaluation on the four Bayesian sampling algorithms covers
trustworthiness, sensitivity and regret of a testing methodology. Moreover, the
evaluation includes 4 real-world eBay experiments and 40 reproducible synthetic
experiments to reveal the learnings, which covers both stationary and
non-stationary situations. Our evaluation reveals that, (a) There exist false
positives inflation with equivalent best arms, while seldom discussed in
literatures; (b) To control false positives, connections between convergence of
posterior optimal probabilities and neutral posterior reshaping are discovered;
(c) WB-TTTS shows competitive recall, higher precision, and robustness against
non-stationary trend; (d) NB-TS outperforms on minimizing regret trials except
on precision and robustness; (e) WB-TTTS is a promising alternative if regret
of A/B Testing is affordable, otherwise NB-TS is still a powerful choice with
regret consideration for pilot experiments.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14700</p>
  <p><b>作者</b>：Ziuhi Wu,  Haichang Gao,  Bingqian Zhou,  Ping Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：implementing knowledge distillation, receive identical inputs, function matching task, models receive identical, function matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>\emph{Consistent teaching} is an effective paradigm for implementing
knowledge distillation (KD), where both student and teacher models receive
identical inputs, and KD is treated as a function matching task (FunMatch).
However, one limitation of FunMatch is that it does not account for the
transfer of adversarial robustness, a model's resistance to adversarial
attacks. To tackle this problem, we propose a simple but effective strategy
called Adversarial Function Matching (AdvFunMatch), which aims to match
distributions for all data points within the $\ell_p$-norm ball of the training
data, in accordance with consistent teaching. Formulated as a min-max
optimization problem, AdvFunMatch identifies the worst-case instances that
maximizes the KL-divergence between teacher and student model outputs, which we
refer to as "mismatched examples," and then matches the outputs on these
mismatched examples. Our experimental results show that AdvFunMatch effectively
produces student models with both high clean accuracy and robustness.
Furthermore, we reveal that strong data augmentations (\emph{e.g.},
AutoAugment) are beneficial in AdvFunMatch, whereas prior works have found them
less effective in adversarial training. Code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Can Transformers Learn to Solve Problems Recursively?</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14699</p>
  <p><b>作者</b>：Shizhuo Dylan Zhang,  Curt Tigges,  Stella Biderman,  Maxim Raginsky,  Talia Ringer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years shown, years shown promise, helping software engineers, software engineers write, engineers write programs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have in recent years shown promise for helping software
engineers write programs and even formally verify them. While semantic
information plays a crucial part in these processes, it remains unclear to what
degree popular neural architectures like transformers are capable of modeling
that information. This paper examines the behavior of neural networks learning
algorithms relevant to programs and formal verification proofs through the lens
of mechanistic interpretability, focusing in particular on structural
recursion. Structural recursion is at the heart of tasks on which symbolic
tools currently outperform neural models, like inferring semantic relations
between datatypes and emulating program behavior. We evaluate the ability of
transformer models to learn to emulate the behavior of structurally recursive
functions from input-output examples. Our evaluation includes empirical and
conceptual analyses of the limitations and capabilities of transformer models
in approximating these functions, as well as reconstructions of the ``shortcut"
algorithms the model learns. By reconstructing these algorithms, we are able to
correctly predict 91 percent of failure cases for one of the approximated
functions. Our work provides a new foundation for understanding the behavior of
neural networks that fail to solve the very tasks they are trained for.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：A Causal View of Entity Bias in (Large) Language Models</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14695</p>
  <p><b>作者</b>：Fei Wang,  Wenjie Mo,  Yiwei Wang,  Wenxuan Zhou,  Muhao Chen</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：widely affects pretrained, bias widely affects, make unfaithful predictions, Entity bias widely, mitigate entity bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity bias widely affects pretrained (large) language models, causing them
to excessively rely on (biased) parametric knowledge to make unfaithful
predictions. Although causality-inspired methods have shown great potential to
mitigate entity bias, it is hard to precisely estimate the parameters of
underlying causal models in practice. The rise of black-box LLMs also makes the
situation even worse, because of their inaccessible parameters and uncalibrated
logits. To address these problems, we propose a specific structured causal
model (SCM) whose parameters are comparatively easier to estimate. Building
upon this SCM, we propose causal intervention techniques to mitigate entity
bias for both white-box and black-box settings. The proposed causal
intervention perturbs the original entity with neighboring entities. This
intervention reduces specific biasing information pertaining to the original
entity while still preserving sufficient common predictive information from
similar entities. When evaluated on the relation extraction task, our
training-time intervention significantly improves the F1 score of RoBERTa by
5.7 points on EntRED, in which spurious shortcuts between entities and labels
are removed. Meanwhile, our in-context intervention effectively reduces the
knowledge conflicts between parametric knowledge and contextual knowledge in
GPT-3.5 and improves the F1 score by 9.14 points on a challenging test set
derived from Re-TACRED.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Have Large Language Models Developed a Personality?: Applicability of  Self-Assessment Tests in Measuring Personality in LLMs</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14693</p>
  <p><b>作者</b>：Xiaoyang Song,  Akshat Gupta,  Kiyan Mohebbizadeh,  Shujie Hu,  Anant Singh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, personality, Language Models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Have Large Language Models (LLMs) developed a personality? The short answer
is a resounding "We Don't Know!". In this paper, we show that we do not yet
have the right tools to measure personality in language models. Personality is
an important characteristic that influences behavior. As LLMs emulate
human-like intelligence and performance in various tasks, a natural question to
ask is whether these models have developed a personality. Previous works have
evaluated machine personality through self-assessment personality tests, which
are a set of multiple-choice questions created to evaluate personality in
humans. A fundamental assumption here is that human personality tests can
accurately measure personality in machines. In this paper, we investigate the
emergence of personality in five LLMs of different sizes ranging from 1.5B to
30B. We propose the Option-Order Symmetry property as a necessary condition for
the reliability of these self-assessment tests. Under this condition, the
answer to self-assessment questions is invariant to the order in which the
options are presented. We find that many LLMs personality test responses do not
preserve option-order symmetry. We take a deeper look at LLMs test responses
where option-order symmetry is preserved to find that in these cases, LLMs do
not take into account the situational statement being tested and produce the
exact same answer irrespective of the situation being tested. We also identify
the existence of inherent biases in these LLMs which is the root cause of the
aforementioned phenomenon and makes self-assessment tests unreliable. These
observations indicate that self-assessment tests are not the correct tools to
measure personality in LLMs. Through this paper, we hope to draw attention to
the shortcomings of current literature in measuring personality in LLMs and
call for developing tools for machine personality measurement.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Generalizing Importance Weighting to A Universal Solver for Distribution  Shift Problems</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14690</p>
  <p><b>作者</b>：Tongtong Fang,  Nan Lu,  Gang Niu,  Masashi Sugiyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cases, test support, density is non-zero, support, probability density</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distribution shift (DS) may have two levels: the distribution itself changes,
and the support (i.e., the set where the probability density is non-zero) also
changes. When considering the support change between the training and test
distributions, there can be four cases: (i) they exactly match; (ii) the
training support is wider (and thus covers the test support); (iii) the test
support is wider; (iv) they partially overlap. Existing methods are good at
cases (i) and (ii), while cases (iii) and (iv) are more common nowadays but
still under-explored. In this paper, we generalize importance weighting (IW), a
golden solver for cases (i) and (ii), to a universal solver for all cases.
Specifically, we first investigate why IW may fail in cases (iii) and (iv);
based on the findings, we propose generalized IW (GIW) that could handle cases
(iii) and (iv) and would reduce to IW in cases (i) and (ii). In GIW, the test
support is split into an in-training (IT) part and an out-of-training (OOT)
part, and the expected risk is decomposed into a weighted classification term
over the IT part and a standard classification term over the OOT part, which
guarantees the risk consistency of GIW. Then, the implementation of GIW
consists of three components: (a) the split of validation data is carried out
by the one-class support vector machine, (b) the first term of the empirical
risk can be handled by any IW algorithm given training data and IT validation
data, and (c) the second term just involves OOT validation data. Experiments
demonstrate that GIW is a universal solver for DS problems, outperforming IW
methods in cases (iii) and (iv).</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：On progressive sharpening, flat minima and generalisation</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14683</p>
  <p><b>作者</b>：Lachlan Ewen MacDonald,  Jack Valmadre,  Simon Lucey</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：network loss Hessians, deep network loss, approach to understanding, understanding the relationship, input-output Jacobian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a new approach to understanding the relationship between loss
curvature and generalisation in deep learning. Specifically, we use existing
empirical analyses of the spectrum of deep network loss Hessians to ground an
ansatz tying together the loss Hessian and the input-output Jacobian of a deep
neural network. We then prove a series of theoretical results which quantify
the degree to which the input-output Jacobian of a model approximates its
Lipschitz norm over a data distribution, and deduce a novel generalisation
bound in terms of the empirical Jacobian. We use our ansatz, together with our
theoretical results, to give a new account of the recently observed progressive
sharpening phenomenon, as well as the generalisation properties of flat minima.
Experimental evidence is provided to validate our claims.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Revenge of MLP in Sequential Recommendation</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14675</p>
  <p><b>作者</b>：Yiheng Jiang,  Yuanbo Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：user-item interactive behaviors, historical user-item interactive, infer dynamic preferences, user-item interactive, infer dynamic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sequential recommendation models sequences of historical user-item
interactive behaviors (or referred as token) to better infer dynamic
preferences. Fueled by the improved neural network architectures such as RNN,
CNN and Transformer, this field has enjoyed rapid performance boost in the past
years. Recent progress on all-MLP models lights on an efficient method with
less intensive computation, token-mixing MLP, to learn the transformation
patterns among historical behaviors. However, due to the inherent
fully-connection design that allows the unrestricted cross-token communication
and ignores the chronological order, we find that directly applying
token-mixing MLP into sequential recommendation leads to subpar performance. In
this paper, we present a purely MLP-based sequential recommendation
architecture TriMLP with a novel \underline{Tri}angular Mixer where the
modified \underline{MLP} endows tokens with ordered interactions. As the
cross-token interaction in MLP is actually matrix multiplication, Triangular
Mixer drops the lower-triangle neurons in the weight matrix and thus blocks the
connections from future tokens, which prevents information leakage and improves
prediction capability under the standard auto-regressive training fashion. To
further model long and short-term preferences on fine-grained level, the mixer
adopts a dual-branch structure based on the delicate MLP described above,
namely global and local mixing, to separately capture the sequential long-range
dependencies and local patterns. Empirical study on 9 different scale datasets
(contain 50K\textasciitilde20M behaviors) of various benchmarks, including
MovieLens, Amazon and Tenrec, demonstrates that TriMLP attains promising and
stable accuracy/efficiency trade-off, i.e., averagely surpasses several
state-of-the-art baselines by 5.32\% and saves 8.44\% inference time cost.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Dealing with Cross-Task Class Discrimination in Online Continual  Learning</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14657</p>
  <p><b>作者</b>：Yiduo Guo,  Bing Liu,  Dongyan Zhao</p>
  <p><b>备注</b>：Accepted by CVPR2023</p>
  <p><b>关键词</b>：Existing continual learning, replay data, Existing continual, research regards catastrophic, catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing continual learning (CL) research regards catastrophic forgetting
(CF) as almost the only challenge. This paper argues for another challenge in
class-incremental learning (CIL), which we call cross-task class discrimination
(CTCD),~i.e., how to establish decision boundaries between the classes of the
new task and old tasks with no (or limited) access to the old task data. CTCD
is implicitly and partially dealt with by replay-based methods. A replay method
saves a small amount of data (replay data) from previous tasks. When a batch of
current task data arrives, the system jointly trains the new data and some
sampled replay data. The replay data enables the system to partially learn the
decision boundaries between the new classes and the old classes as the amount
of the saved data is small. However, this paper argues that the replay approach
also has a dynamic training bias issue which reduces the effectiveness of the
replay data in solving the CTCD problem. A novel optimization objective with a
gradient-based adaptive method is proposed to dynamically deal with the problem
in the online CL process. Experimental results show that the new method
achieves much better results in online CL.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：RSRM: Reinforcement Symbolic Regression Machine</b></summary>
  <p><b>编号</b>：[460]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14656</p>
  <p><b>作者</b>：Yilong Xu,  Yang Liu,  Hao Sun</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：parsimonious math equations, symbolic regression, math, math equations, RSRM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In nature, the behaviors of many complex systems can be described by
parsimonious math equations. Automatically distilling these equations from
limited data is cast as a symbolic regression process which hitherto remains a
grand challenge. Keen efforts in recent years have been placed on tackling this
issue and demonstrated success in symbolic regression. However, there still
exist bottlenecks that current methods struggle to break when the discrete
search space tends toward infinity and especially when the underlying math
formula is intricate. To this end, we propose a novel Reinforcement Symbolic
Regression Machine (RSRM) that masters the capability of uncovering complex
math equations from only scarce data. The RSRM model is composed of three key
modules: (1) a Monte Carlo tree search (MCTS) agent that explores optimal math
expression trees consisting of pre-defined math operators and variables, (2) a
Double Q-learning block that helps reduce the feasible search space of MCTS via
properly understanding the distribution of reward, and (3) a modulated sub-tree
discovery block that heuristically learns and defines new math operators to
improve representation ability of math expression trees. Biding of these
modules yields the state-of-the-art performance of RSRM in symbolic regression
as demonstrated by multiple sets of benchmark examples. The RSRM model shows
clear superiority over several representative baseline models.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Learning Survival Distribution with Implicit Survival Function</b></summary>
  <p><b>编号</b>：[461]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14655</p>
  <p><b>作者</b>：Yu Ling,  Weimin Tan,  Bo Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Survival analysis aims, Implicit Neural Representation, analysis aims, aims at modeling, modeling the relationship</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Survival analysis aims at modeling the relationship between covariates and
event occurrence with some untracked (censored) samples. In implementation,
existing methods model the survival distribution with strong assumptions or in
a discrete time space for likelihood estimation with censorship, which leads to
weak generalization. In this paper, we propose Implicit Survival Function (ISF)
based on Implicit Neural Representation for survival distribution estimation
without strong assumptions,and employ numerical integration to approximate the
cumulative distribution function for prediction and optimization. Experimental
results show that ISF outperforms the state-of-the-art methods in three public
datasets and has robustness to the hyperparameter controlling estimation
precision.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Revisit and Outstrip Entity Alignment: A Perspective of Generative  Models</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14651</p>
  <p><b>作者</b>：Lingbing Guo,  Zhuo Chen,  Jiaoyan Chen,  Huajun Chen</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：achieved great successes, Recent embedding-based methods, entity alignment, knowledge graph, embeddings of multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent embedding-based methods have achieved great successes on exploiting
entity alignment from knowledge graph (KG) embeddings of multiple modals. In
this paper, we study embedding-based entity alignment (EEA) from a perspective
of generative models. We show that EEA is a special problem where the main
objective is analogous to that in a typical generative model, based on which we
theoretically prove the effectiveness of the recently developed generative
adversarial network (GAN)-based EEA methods. We then reveal that their
incomplete objective limits the capacity on both entity alignment and entity
synthesis (i.e., generating new entities). We mitigate this problem by
introducing a generative EEA (abbr., GEEA) framework with the proposed mutual
variational autoencoder (M-VAE) as the generative model. M-VAE can convert an
entity from one KG to another and generate new entities from random noise
vectors. We demonstrate the power of GEEA with theoretical analysis and
empirical experiments on both entity alignment and entity synthesis tasks.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：A Joint Time-frequency Domain Transformer for Multivariate Time Series  Forecasting</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14649</p>
  <p><b>作者</b>：Yushu Chen,  Shengzhuo Liu,  Jinzhe Yang,  Hao Jing,  Wenlai Zhao,  Guangwen Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-frequency domain Transformer, minimizing computational demands, joint time-frequency domain, enhance predicting performance, domain Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To enhance predicting performance while minimizing computational demands,
this paper introduces a joint time-frequency domain Transformer (JTFT) for
multivariate forecasting. The method exploits the sparsity of time series in
the frequency domain using a small number of learnable frequencies to extract
temporal dependencies effectively. Alongside the frequency domain
representation, a fixed number of the most recent data points are directly
encoded in the time domain, bolstering the learning of local relationships and
mitigating the adverse effects of non-stationarity. JTFT achieves linear
complexity since the length of the internal representation remains independent
of the input sequence length. Additionally, a low-rank attention layer is
proposed to efficiently capture cross-dimensional dependencies and prevent
performance degradation due to the entanglement of temporal and channel-wise
modeling. Experiments conducted on six real-world datasets demonstrate that
JTFT outperforms state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：KARNet: Kalman Filter Augmented Recurrent Neural Network for Learning  World Models in Autonomous Driving Tasks</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14644</p>
  <p><b>作者</b>：Hemanth Manjunatha,  Andrey Pak,  Dimitar Filev,  Panagiotis Tsiotras</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2205.08712</p>
  <p><b>关键词</b>：Autonomous driving, autonomous driving planning, autonomous driving technology, received a great, great deal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous driving has received a great deal of attention in the automotive
industry and is often seen as the future of transportation. The development of
autonomous driving technology has been greatly accelerated by the growth of
end-to-end machine learning techniques that have been successfully used for
perception, planning, and control tasks. An important aspect of autonomous
driving planning is knowing how the environment evolves in the immediate future
and taking appropriate actions. An autonomous driving system should effectively
use the information collected from the various sensors to form an abstract
representation of the world to maintain situational awareness. For this
purpose, deep learning models can be used to learn compact latent
representations from a stream of incoming data. However, most deep learning
models are trained end-to-end and do not incorporate any prior knowledge (e.g.,
from physics) of the vehicle in the architecture. In this direction, many works
have explored physics-infused neural network (PINN) architectures to infuse
physics models during training. Inspired by this observation, we present a
Kalman filter augmented recurrent neural network architecture to learn the
latent representation of the traffic flow using front camera images only. We
demonstrate the efficacy of the proposed model in both imitation and
reinforcement learning settings using both simulated and real-world datasets.
The results show that incorporating an explicit model of the vehicle (states
estimated using Kalman filtering) in the end-to-end learning significantly
increases performance.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Newton-Cotes Graph Neural Networks: On the Time Evolution of Dynamic  Systems</b></summary>
  <p><b>编号</b>：[469]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14642</p>
  <p><b>作者</b>：Lingbing Guo,  Weiqing Wang,  Zhuo Chen,  Ningyu Zhang,  Zequn Sun,  Yixuan Lai,  Qiang Zhang,  Huajun Chen</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：important analytical approaches, Reasoning system dynamics, scientific studies, important analytical, analytical approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reasoning system dynamics is one of the most important analytical approaches
for many scientific studies. With the initial state of a system as input, the
recent graph neural networks (GNNs)-based methods are capable of predicting the
future state distant in time with high accuracy. Although these methods have
diverse designs in modeling the coordinates and interacting forces of the
system, we show that they actually share a common paradigm that learns the
integration of the velocity over the interval between the initial and terminal
coordinates. However, their integrand is constant w.r.t. time. Inspired by this
observation, we propose a new approach to predict the integration based on
several velocity estimations with Newton-Cotes formulas and prove its
effectiveness theoretically. Extensive experiments on several benchmarks
empirically demonstrate consistent and significant improvement compared with
the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Graphy Analysis Using a GPU-based Parallel Algorithm: Quantum Clustering</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14641</p>
  <p><b>作者</b>：Zhe Wang,  ZhiJie He,  Ding Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying Quantum Clustering, Quantum Clustering, Graph Gradient Descent, applying Quantum, article introduces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The article introduces a new method for applying Quantum Clustering to graph
structures. Quantum Clustering (QC) is a novel density-based unsupervised
learning method that determines cluster centers by constructing a potential
function. In this method, we use the Graph Gradient Descent algorithm to find
the centers of clusters. GPU parallelization is utilized for computing
potential values. We also conducted experiments on five widely used datasets
and evaluated using four indicators. The results show superior performance of
the method. Finally, we discuss the influence of $\sigma$ on the experimental
results.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code  Generation</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14637</p>
  <p><b>作者</b>：Davit Soselia,  Khalid Saifullah,  Tianyi Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CSS code generation, development and design, Automated HTML, CSS code, important yet challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated HTML/CSS code generation from screenshots is an important yet
challenging problem with broad applications in website development and design.
In this paper, we present a novel vision-code transformer approach that
leverages an Encoder-Decoder architecture as well as explore actor-critic
fine-tuning as a method for improving upon the baseline. For this purpose, two
image encoders are compared: Vision Transformer (ViT) and Document Image
Transformer (DiT).
We propose an end-to-end pipeline that can generate high-quality code
snippets directly from screenshots, streamlining the website creation process
for developers. To train and evaluate our models, we created a synthetic
dataset of 30,000 unique pairs of code and corresponding screenshots.
We evaluate the performance of our approach using a combination of automated
metrics such as MSE, BLEU, IoU, and a novel htmlBLEU score, where our models
demonstrated strong performance. We establish a strong baseline with the
DiT-GPT2 model and show that actor-critic can be used to improve IoU score from
the baseline of 0.64 to 0.79 and lower MSE from 12.25 to 9.02. We achieved
similar performance as when using larger models, with much lower computational
cost.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Enabling Large Language Models to Generate Text with Citations</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14627</p>
  <p><b>作者</b>：Tianyu Gao,  Howard Yen,  Jiatong Yu,  Danqi Chen</p>
  <p><b>备注</b>：Code and data are available at this https URL</p>
  <p><b>关键词</b>：Large language models, Large language, prone to hallucination, widely-used tool, generated outputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have emerged as a widely-used tool for
information seeking, but their generated outputs are prone to hallucination. In
this work, we aim to enable LLMs to generate text with citations, improving
their factual correctness and verifiability. Existing work mainly relies on
commercial search engines and human evaluation, making it challenging to
reproduce and compare with different modeling approaches. We propose ALCE, the
first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a
diverse set of questions and retrieval corpora and requires building end-to-end
systems to retrieve supporting evidence and generate answers with citations. We
build automatic metrics along three dimensions -- fluency, correctness, and
citation quality -- and demonstrate their strong correlation with human
judgements. Our experiments with state-of-the-art LLMs and novel prompting
strategies show that current systems have considerable room for improvements --
for example, on the ELI5 dataset, even the best model has 49% of its
generations lacking complete citation support. Our extensive analyses further
highlight promising future directions, including developing better retrievers,
advancing long-context LLMs, and improving the ability to synthesize
information from multiple sources.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：EXnet: Efficient In-context Learning for Data-less Text classification</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14622</p>
  <p><b>作者</b>：Debaditya Shome,  Kuldeep Yadav</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made significant progress, encoding world knowledge, Large pre-trained language, Large pre-trained, paradigms including zero-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models (PLMs) have made significant progress in
encoding world knowledge and spawned a new set of learning paradigms including
zero-shot, few-shot, and in-context learning. Many language tasks can be
modeled as a set of prompts (for example, is this text about geography?) and
language models can provide binary answers, i.e., Yes or No. There is evidence
to suggest that the next-word prediction used by many PLMs does not align well
with zero-shot paradigms. Therefore, PLMs are fine-tuned as a
question-answering system. In-context learning extends zero-shot learning by
incorporating prompts and examples, resulting in increased task accuracy. Our
paper presents EXnet, a model specifically designed to perform in-context
learning without any limitations on the number of examples. We argue that
in-context learning is an effective method to increase task accuracy, and
providing examples facilitates cross-task generalization, especially when it
comes to text classification tasks. With extensive experiments, we show that
even our smallest model (15M parameters) generalizes to several unseen
classification tasks and domains.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Inverse Reinforcement Learning with the Average Reward Criterion</b></summary>
  <p><b>编号</b>：[490]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14608</p>
  <p><b>作者</b>：Feiyang Wu,  Jingyang Ke,  Anqi Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, Reinforcement Learning, Inverse Reinforcement, IRL, IRL problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of Inverse Reinforcement Learning (IRL) with an
average-reward criterion. The goal is to recover an unknown policy and a reward
function when the agent only has samples of states and actions from an
experienced agent. Previous IRL methods assume that the expert is trained in a
discounted environment, and the discount factor is known. This work alleviates
this assumption by proposing an average-reward framework with efficient
learning algorithms. We develop novel stochastic first-order methods to solve
the IRL problem under the average-reward setting, which requires solving an
Average-reward Markov Decision Process (AMDP) as a subproblem. To solve the
subproblem, we develop a Stochastic Policy Mirror Descent (SPMD) method under
general state and action spaces that needs $\mathcal{O}(1/\varepsilon)$ steps
of gradient computation. Equipped with SPMD, we propose the Inverse Policy
Mirror Descent (IPMD) method for solving the IRL problem with a
$\mathcal{O}(1/\varepsilon^2)$ complexity. To the best of our knowledge, the
aforementioned complexity results are new in IRL. Finally, we corroborate our
analysis with numerical experiments using the MuJoCo benchmark and additional
control tasks.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Learning Semantic Role Labeling from Compatible Label Sequences</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14600</p>
  <p><b>作者</b>：Tao Li,  Ghazaleh Kazeminejad,  Susan W. Brown,  Martha Palmer,  Vivek Srikumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper addresses, addresses the question, efficiently learn, compatible label sequences, label sequences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the question of how to efficiently learn from disjoint,
compatible label sequences. We argue that the compatible structures between
disjoint label sets help model learning and inference. We verify this
hypothesis on the task of semantic role labeling (SRL), specifically, tagging a
sentence with two role sequences: VerbNet arguments and PropBank arguments.
Prior work has shown that cross-task interaction improves performance. However,
the two tasks are still separately decoded, running the risk of generating
structurally inconsistent label sequences (as per lexicons like SEMLINK). To
eliminate this issue, we first propose a simple and effective setup that
jointly handles VerbNet and PropBank labels as one sequence. With this setup,
we show that enforcing SEMLINK constraints during decoding constantly improves
the overall F1. With special input constructions, our joint model infers
VerbNet arguments from PropBank arguments with over 99% accuracy. We also
propose a constrained marginal model that uses SEMLINK information during
training to further benefit from the large amounts of PropBank-only data. Our
models achieve state-of-the-art F1's on VerbNet and PropBank argument labeling
on the CoNLL05 dataset with strong out-of-domain generalization.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Voices of Her: Analyzing Gender Differences in the AI Publication World</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14597</p>
  <p><b>作者</b>：Yiwen Ding,  Jiarui Liu,  Zhiheng Lyu,  Kun Zhang,  Bernhard Schoelkopf,  Zhijing Jin,  Rada Mihalcea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：covering diverse topics, analyzed gender bias, bias in research, covering diverse, previous studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While several previous studies have analyzed gender bias in research, we are
still missing a comprehensive analysis of gender differences in the AI
community, covering diverse topics and different development trends. Using the
AI Scholar dataset of 78K researchers in the field of AI, we identify several
gender differences: (1) Although female researchers tend to have fewer overall
citations than males, this citation difference does not hold for all
academic-age groups; (2) There exist large gender homophily in co-authorship on
AI papers; (3) Female first-authored papers show distinct linguistic styles,
such as longer text, more positive emotion words, and more catchy titles than
male first-authored papers. Our analysis provides a window into the current
demographic trends in our AI community, and encourages more gender equality and
diversity in the future. Our code and data are at
this https URL.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Attentiveness to Answer Choices Doesn't Always Entail High QA Accuracy</b></summary>
  <p><b>编号</b>：[498]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14596</p>
  <p><b>作者</b>：Sarah Wiegreffe,  Matthew Finlayson,  Oyvind Tafjord,  Peter Clark,  Ashish Sabharwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, large language, few-shot settings, settings to discriminative, vocabulary tokens</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When large language models (LMs) are applied in zero- or few-shot settings to
discriminative tasks such as multiple-choice questions, their attentiveness
(i.e., probability mass) is spread across many vocabulary tokens that are not
valid choices. Such a spread across multiple surface forms with identical
meaning is thought to cause an underestimation of a model's true performance,
referred to as the "surface form competition" (SFC) hypothesis. This has
motivated the introduction of various probability normalization methods.
However, many core questions remain unanswered. How do we measure SFC or
attentiveness? Are there direct ways of increasing attentiveness on valid
choices? Does increasing attentiveness always improve task accuracy? We propose
a mathematical formalism for studying this phenomenon, provide a metric for
quantifying attentiveness, and identify a simple method for increasing it --
namely, in-context learning with even just one example containing answer
choices. The formalism allows us to quantify SFC and bound its impact. Our
experiments on three diverse datasets and six LMs reveal several surprising
findings. For example, encouraging models to generate a valid answer choice
can, in fact, be detrimental to task performance for some LMs, and prior
probability normalization methods are less effective (sometimes even
detrimental) to instruction-tuned LMs. We conclude with practical insights for
effectively using prompted LMs for multiple-choice tasks.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Operationalizing Counterfactual Metrics: Incentives, Ranking, and  Information Asymmetry</b></summary>
  <p><b>编号</b>：[499]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14595</p>
  <p><b>作者</b>：Serena Wang,  Stephen Bates,  P. M. Aronow,  Michael I. Jordan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social sciences, machine learning, sciences to machine, social welfare, aligned with social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>From the social sciences to machine learning, it has been well documented
that metrics to be optimized are not always aligned with social welfare. In
healthcare, Dranove et al. [12] showed that publishing surgery mortality
metrics actually harmed the welfare of sicker patients by increasing provider
selection behavior. Using a principal-agent model, we directly study the
incentive misalignments that arise from such average treated outcome metrics,
and show that the incentives driving treatment decisions would align with
maximizing total patient welfare if the metrics (i) accounted for
counterfactual untreated outcomes and (ii) considered total welfare instead of
average welfare among treated patients. Operationalizing this, we show how
counterfactual metrics can be modified to satisfy desirable properties when
used for ranking. Extending to realistic settings when the providers observe
more about patients than the regulatory agencies do, we bound the decay in
performance by the degree of information asymmetry between the principal and
the agent. In doing so, our model connects principal-agent information
asymmetry with unobserved heterogeneity in causal inference.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：torchgfn: A PyTorch GFlowNet library</b></summary>
  <p><b>编号</b>：[500]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14594</p>
  <p><b>作者</b>：Salem Lahlou,  Joseph D. Viviano,  Victor Schmidt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generative flow networks, flow networks, increasing popularity, popularity of generative, generative flow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing popularity of generative flow networks (GFlowNets or GFNs) is
accompanied with a proliferation of code sources. This hinders the
implementation of new features, such as training losses, that can readily be
compared to existing ones, on a set of common environments. In addition to
slowing down research in the field of GFlowNets, different code bases use
different conventions, that might be confusing for newcomers. `torchgfn` is a
library built on top of PyTorch, that aims at addressing both problems. It
provides user with a simple API for environments, and useful abstractions for
samplers and losses. Multiple examples are provided, replicating published
results. The code is available in this https URL.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Instruction Tuning with Lexicons for Zero-Shot Style Classification</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14592</p>
  <p><b>作者</b>：Ruohao Guo,  Wei Xu,  Alan Ritter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convey authors' intentions, intentions and attitudes, convey authors', authors' intentions, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Style is used to convey authors' intentions and attitudes. Despite the
success of large pre-trained language models on style classification, prior
work relies on fine-tuning with labeled examples. Prompting large language
models to classify style without fine-tuning is challenging because language
styles can be difficult to define. In this study, we investigate the
effectiveness of style lexicons as a means for instructing language models how
to identify new styles that are unseen during training. Our experiments show
that lexicon-based instructions improve transfer zero-shot performance
significantly. We will release our code and data.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Evaluating end-to-end entity linking on domain-specific knowledge bases:  Learning about ancient technologies from museum collections</b></summary>
  <p><b>编号</b>：[504]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14588</p>
  <p><b>作者</b>：Sebastian Cadavid-Sanchez,  Khalil Kacem,  Rafael Aparecido Martins Frade,  Johannes Boehm,  Thomas Chaney,  Danial Lashkari,  Daniel Simig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly large unstructured, large unstructured textual, unstructured textual datasets, historical questions, study social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To study social, economic, and historical questions, researchers in the
social sciences and humanities have started to use increasingly large
unstructured textual datasets. While recent advances in NLP provide many tools
to efficiently process such data, most existing approaches rely on generic
solutions whose performance and suitability for domain-specific tasks is not
well understood. This work presents an attempt to bridge this domain gap by
exploring the use of modern Entity Linking approaches for the enrichment of
museum collection data. We collect a dataset comprising of more than 1700 texts
annotated with 7,510 mention-entity pairs, evaluate some off-the-shelf
solutions in detail using this dataset and finally fine-tune a recent
end-to-end EL model on this data. We show that our fine-tuned model
significantly outperforms other approaches currently available in this domain
and present a proof-of-concept use case of this model. We release our dataset
and our best model.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Robust Explanations for Deep Neural Networks via Pseudo Neural Tangent  Kernel Surrogate Models</b></summary>
  <p><b>编号</b>：[507]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14585</p>
  <p><b>作者</b>：Andrew Engel,  Zhichao Wang,  Natalie S. Frank,  Ioana Dumitriu,  Sutanay Choudhury,  Anand Sarwate,  Tony Chiang</p>
  <p><b>备注</b>：9 pages, 4 figures, 3 tables</p>
  <p><b>关键词</b>：recent progress, made on explainable, data attribution tasks, neural network, training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the ways recent progress has been made on explainable AI has been via
explain-by-example strategies, specifically, through data attribution tasks.
The feature spaces used to attribute decisions to training data, however, have
not been compared against one another as to whether they form a truly
representative surrogate model of the neural network (NN). Here, we demonstrate
the efficacy of surrogate linear feature spaces to neural networks through two
means: (1) we establish that a normalized psuedo neural tangent kernel (pNTK)
is more correlated to the neural network decision functions than embedding
based and influence based alternatives in both computer vision and large
language model architectures; (2) we show that the attributions created from
the normalized pNTK more accurately select perturbed training data in a data
poisoning attribution task than these alternatives. Based on these
observations, we conclude that kernel linear models are effective surrogate
models across multiple classification architectures and that pNTK-based kernels
are the most appropriate surrogate feature space of all kernels studied.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Interpretation of Time-Series Deep Models: A Survey</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14582</p>
  <p><b>作者</b>：Ziqi Zhao,  Yucheng Shi,  Shushan Wu,  Fan Yang,  Wenzhan Song,  Ninghao Liu</p>
  <p><b>备注</b>：18 pages, 3 figures, 1 table</p>
  <p><b>关键词</b>：widely researched nowadays, Deep learning models, learning models developed, Deep learning, researched nowadays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models developed for time-series associated tasks have become
more widely researched nowadays. However, due to the unintuitive nature of
time-series data, the interpretability problem -- where we understand what is
under the hood of these models -- becomes crucial. The advancement of similar
studies in computer vision has given rise to many post-hoc methods, which can
also shed light on how to explain time-series models. In this paper, we present
a wide range of post-hoc interpretation methods for time-series models based on
backpropagation, perturbation, and approximation. We also want to bring focus
onto inherently interpretable models, a novel category of interpretation where
human-understandable information is designed within the models. Furthermore, we
introduce some common evaluation metrics used for the explanations, and propose
several directions of future researches on the time-series interpretability
problem. As a highlight, our work summarizes not only the well-established
interpretation methods, but also a handful of fairly recent and under-developed
techniques, which we hope to capture their essence and spark future endeavours
to innovate and improvise.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Difference-Masking: Choosing What to Mask in Continued Pretraining</b></summary>
  <p><b>编号</b>：[514]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14577</p>
  <p><b>作者</b>：Alex Wilf,  Syeda Nahida Akter,  Leena Mathur,  Paul Pu Liang,  Sheryl Mathew,  Mengrou Shou,  Eric Nyberg,  Louis-Philippe Morency</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promising SSL performance, led to promising, variety of downstream, Self-supervised learning, promising SSL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) and the objective of masking-and-predicting in
particular have led to promising SSL performance on a variety of downstream
tasks. However, while most approaches randomly mask tokens, there is strong
intuition from the field of education that deciding what to mask can
substantially improve learning outcomes. We introduce Difference-Masking, an
approach that automatically chooses what to mask during continued pretraining
by considering what makes an unlabelled target domain different from the
pretraining domain. Empirically, we find that Difference-Masking outperforms
baselines on continued pretraining settings across four diverse language and
multimodal video tasks. The cross-task applicability of Difference-Masking
supports the effectiveness of our framework for SSL pretraining in language,
vision, and other domains.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Detecting and Mitigating Indirect Stereotypes in Word Embeddings</b></summary>
  <p><b>编号</b>：[517]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14574</p>
  <p><b>作者</b>：Erin George,  Joyce Chew,  Deanna Needell</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：including harmful stereotypes, including harmful, word embeddings, word, Societal biases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Societal biases in the usage of words, including harmful stereotypes, are
frequently learned by common word embedding methods. These biases manifest not
only between a word and an explicit marker of its stereotype, but also between
words that share related stereotypes. This latter phenomenon, sometimes called
"indirect bias,'' has resisted prior attempts at debiasing. In this paper, we
propose a novel method called Biased Indirect Relationship Modification (BIRM)
to mitigate indirect bias in distributional word embeddings by modifying biased
relationships between words before embeddings are learned. This is done by
considering how the co-occurrence probability of a given pair of words changes
in the presence of words marking an attribute of bias, and using this to
average out the effect of a bias attribute. To evaluate this method, we perform
a series of common tests and demonstrate that measures of bias in the word
embeddings are reduced in exchange for minor reduction in the semantic quality
of the embeddings. In addition, we conduct novel tests for measuring indirect
stereotypes by extending the Word Embedding Association Test (WEAT) with new
test sets for indirect binary gender stereotypes. With these tests, we
demonstrate the presence of more subtle stereotypes not addressed by previous
work. The proposed method is able to reduce the presence of some of these new
stereotypes, serving as a crucial next step towards non-stereotyped word
embeddings.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Constant Memory Attentive Neural Processes</b></summary>
  <p><b>编号</b>：[522]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14567</p>
  <p><b>作者</b>：Leo Feng,  Frederick Tung,  Hossein Hajimirsadeghi,  Yoshua Bengio,  Mohamed Osama Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：estimating predictive uncertainties, Attentive Neural Processes, Neural Processes, predictive uncertainties, Constant Memory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Processes (NPs) are efficient methods for estimating predictive
uncertainties. NPs comprise of a conditioning phase where a context dataset is
encoded, a querying phase where the model makes predictions using the context
dataset encoding, and an updating phase where the model updates its encoding
with newly received datapoints. However, state-of-the-art methods require
additional memory which scales linearly or quadratically with the size of the
dataset, limiting their applications, particularly in low-resource settings. In
this work, we propose Constant Memory Attentive Neural Processes (CMANPs), an
NP variant which only requires constant memory for the conditioning, querying,
and updating phases. In building CMANPs, we propose Constant Memory Attention
Block (CMAB), a novel general-purpose attention block that can compute its
output in constant memory and perform updates in constant computation.
Empirically, we show CMANPs achieve state-of-the-art results on meta-regression
and image completion tasks while being (1) significantly more memory efficient
than prior methods and (2) more scalable to harder settings.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：GiPH: Generalizable Placement Learning for Adaptive Heterogeneous  Computing</b></summary>
  <p><b>编号</b>：[524]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14562</p>
  <p><b>作者</b>：Yi Hu,  Chaoran Zhang,  Edward Andert,  Harshul Singh,  Aviral Shrivastava,  James Laudon,  Yanqi Zhou,  Bob Iannucci,  Carlee Joe-Wong</p>
  <p><b>备注</b>：to be published in Proceedings of Machine Learning and Systems 5 (MLSys 2023)</p>
  <p><b>关键词</b>：achieving low application, target device cluster, critical for achieving, achieving low, low application completion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Careful placement of a computational application within a target device
cluster is critical for achieving low application completion time. The problem
is challenging due to its NP-hardness and combinatorial nature. In recent
years, learning-based approaches have been proposed to learn a placement policy
that can be applied to unseen applications, motivated by the problem of placing
a neural network across cloud servers. These approaches, however, generally
assume the device cluster is fixed, which is not the case in mobile or edge
computing settings, where heterogeneous devices move in and out of range for a
particular application. We propose a new learning approach called GiPH, which
learns policies that generalize to dynamic device clusters via 1) a novel graph
representation gpNet that efficiently encodes the information needed for
choosing a good placement, and 2) a scalable graph neural network (GNN) that
learns a summary of the gpNet information. GiPH turns the placement problem
into that of finding a sequence of placement improvements, learning a policy
for selecting this sequence that scales to problems of arbitrary size. We
evaluate GiPH with a wide range of task graphs and device clusters and show
that our learned policy rapidly find good placements for new problem instances.
GiPH finds placements with up to 30.5% lower completion times, searching up to
3X faster than other search-based placement policies.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCiM DNN Accelerators</b></summary>
  <p><b>编号</b>：[525]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14561</p>
  <p><b>作者</b>：Yifan Qin,  Zheyu Yan,  Wujie Wen,  Xiaobo Sharon Hu,  Yiyu Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：utilizing non-volatile memory, accelerating deep neural, deep neural networks, utilizing non-volatile, non-volatile memory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compute-in-Memory (CiM) utilizing non-volatile memory (NVM) devices presents
a highly promising and efficient approach for accelerating deep neural networks
(DNNs). By concurrently storing network weights and performing matrix
operations within the same crossbar structure, CiM accelerators offer DNN
inference acceleration with minimal area requirements and exceptional energy
efficiency. However, the stochasticity and intrinsic variations of NVM devices
often lead to performance degradation, such as reduced classification accuracy,
compared to expected outcomes. Although several methods have been proposed to
mitigate device variation and enhance robustness, most of them rely on overall
modulation and lack constraints on the training process. Drawing inspiration
from the negative feedback mechanism, we introduce a novel training approach
that uses a multi-exit mechanism as negative feedback to enhance the
performance of DNN models in the presence of device variation. Our negative
feedback training method surpasses state-of-the-art techniques by achieving an
impressive improvement of up to 12.49% in addressing DNN robustness against
device variation.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：All Roads Lead to Rome? Exploring the Invariance of Transformers'  Representations</b></summary>
  <p><b>编号</b>：[527]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14555</p>
  <p><b>作者</b>：Yuxin Ren,  Qipeng Guo,  Zhijing Jin,  Shauli Ravfogel,  Mrinmaya Sachan,  Bernhard Schölkopf,  Ryan Cotterell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bring propelling advances, NLP tasks, models bring propelling, Transformer models bring, bring propelling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer models bring propelling advances in various NLP tasks, thus
inducing lots of interpretability research on the learned representations of
the models. However, we raise a fundamental question regarding the reliability
of the representations. Specifically, we investigate whether transformers learn
essentially isomorphic representation spaces, or those that are sensitive to
the random seeds in their pretraining process. In this work, we formulate the
Bijection Hypothesis, which suggests the use of bijective methods to align
different models' representation spaces. We propose a model based on invertible
neural networks, BERT-INN, to learn the bijection more effectively than other
existing bijective methods such as the canonical correlation analysis (CCA). We
show the advantage of BERT-INN both theoretically and through extensive
experiments, and apply it to align the reproduced BERT embeddings to draw
insights that are meaningful to the interpretability research. Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Exploring Semantic Variations in GAN Latent Spaces via Matrix  Factorization</b></summary>
  <p><b>编号</b>：[530]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14551</p>
  <p><b>作者</b>：Andrey Palaev,  Rustam A. Lukmanov,  Adil Khan</p>
  <p><b>备注</b>：Accepted at ICLR 2023 Tiny Papers</p>
  <p><b>关键词</b>：Controlled data generation, Controlled data, data generation, desirable but challenging, challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlled data generation with GANs is desirable but challenging due to the
nonlinearity and high dimensionality of their latent spaces. In this work, we
explore image manipulations learned by GANSpace, a state-of-the-art method
based on PCA. Through quantitative and qualitative assessments we show: (a)
GANSpace produces a wide range of high-quality image manipulations, but they
can be highly entangled, limiting potential use cases; (b) Replacing PCA with
ICA improves the quality and disentanglement of manipulations; (c) The quality
of the generated images can be sensitive to the size of GANs, but regardless of
their complexity, fundamental controlling directions can be observed in their
latent spaces.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Sequence Modeling is a Robust Contender for Offline Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[531]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14550</p>
  <p><b>作者</b>：Prajjwal Bhargava,  Rohan Chitnis,  Alborz Geramifard,  Shagun Sodhani,  Amy Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Offline reinforcement learning, Imitation Learning, Sequence Modeling, reinforcement learning, static dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline reinforcement learning (RL) allows agents to learn effective,
return-maximizing policies from a static dataset. Three major paradigms for
offline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A key
open question is: which paradigm is preferred under what conditions? We study
this question empirically by exploring the performance of representative
algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and
Decision Transformer (DT) -- across the commonly used D4RL and Robomimic
benchmarks. We design targeted experiments to understand their behavior
concerning data suboptimality and task complexity. Our key findings are: (1)
Sequence Modeling requires more data than Q-Learning to learn competitive
policies but is more robust; (2) Sequence Modeling is a substantially better
choice than both Q-Learning and Imitation Learning in sparse-reward and
low-quality data settings; and (3) Sequence Modeling and Imitation Learning are
preferable as task horizon increases, or when data is obtained from suboptimal
human demonstrators. Based on the overall strength of Sequence Modeling, we
also investigate architectural choices and scaling trends for DT on Atari and
D4RL and make design recommendations. We find that scaling the amount of data
for DT by 5x gives a 2.5x average score improvement on Atari.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Bulk-Switching Memristor-based Compute-In-Memory Module for Deep Neural  Network Training</b></summary>
  <p><b>编号</b>：[534]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14547</p>
  <p><b>作者</b>：Yuting Wu,  Qiwen Wang,  Ziyu Wang,  Xinxin Wang,  Buvna Ayyagari,  Siddarth Krishnan,  Michael Chudzik,  Wei D. Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural network, neural network, CIM, deep neural, higher performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The need for deep neural network (DNN) models with higher performance and
better functionality leads to the proliferation of very large models. Model
training, however, requires intensive computation time and energy.
Memristor-based compute-in-memory (CIM) modules can perform vector-matrix
multiplication (VMM) in situ and in parallel, and have shown great promises in
DNN inference applications. However, CIM-based model training faces challenges
due to non-linear weight updates, device variations, and low-precision in
analog computing circuits. In this work, we experimentally implement a
mixed-precision training scheme to mitigate these effects using a
bulk-switching memristor CIM module. Lowprecision CIM modules are used to
accelerate the expensive VMM operations, with high precision weight updates
accumulated in digital units. Memristor devices are only changed when the
accumulated weight update value exceeds a pre-defined threshold. The proposed
scheme is implemented with a system-on-chip (SoC) of fully integrated analog
CIM modules and digital sub-systems, showing fast convergence of LeNet training
to 97.73%. The efficacy of training larger models is evaluated using realistic
hardware parameters and shows that that analog CIM modules can enable efficient
mix-precision DNN training with accuracy comparable to full-precision software
trained models. Additionally, models trained on chip are inherently robust to
hardware variations, allowing direct mapping to CIM inference chips without
additional re-training.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：Disincentivizing Polarization in Social Networks</b></summary>
  <p><b>编号</b>：[538]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14537</p>
  <p><b>作者</b>：Christian Borgs,  Jennifer Chayes,  Christian Ikeokwu,  Ellen Vitercik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：filter bubbles, algorithmic personalization drives, social networks, personalization drives users, content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>On social networks, algorithmic personalization drives users into filter
bubbles where they rarely see content that deviates from their interests. We
present a model for content curation and personalization that avoids filter
bubbles, along with algorithmic guarantees and nearly matching lower bounds. In
our model, the platform interacts with $n$ users over $T$ timesteps, choosing
content for each user from $k$ categories. The platform receives stochastic
rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the
intuition that if some users are shown some category of content, then all users
should see at least a small amount of that content. We first analyze a naive
formalization of this intuition and show it has unintended consequences: it
leads to ``tyranny of the majority'' with the burden of diversification borne
disproportionately by those with minority interests. This leads us to our model
which distributes this burden more equitably. We require that the probability
any user is shown a particular type of content is at least $\gamma$ times the
average probability all users are shown that type of content. Full
personalization corresponds to $\gamma = 0$ and complete homogenization
corresponds to $\gamma = 1$; hence, $\gamma$ encodes a hard cap on the level of
personalization. We also analyze additional formulations where the platform can
exceed its cap but pays a penalty proportional to its constraint violation. We
provide algorithmic guarantees for optimizing recommendations subject to these
constraints. These include nearly matching upper and lower bounds for the
entire range of $\gamma \in [0,1]$ showing that the reward of a multi-agent
variant of UCB is nearly optimal. Using real-world preference data, we
empirically verify that under our model, users share the burden of
diversification with only minor utility loss under our constraints.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Uncertainty Quantification over Graph with Conformalized Graph Neural  Networks</b></summary>
  <p><b>编号</b>：[540]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14535</p>
  <p><b>作者</b>：Kexin Huang,  Ying Jin,  Emmanuel Candes,  Jure Leskovec</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful machine learning, machine learning prediction, Graph Neural Networks, Neural Networks, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are powerful machine learning prediction models
on graph-structured data. However, GNNs lack rigorous uncertainty estimates,
limiting their reliable deployment in settings where the cost of errors is
significant. We propose conformalized GNN (CF-GNN), extending conformal
prediction (CP) to graph-based models for guaranteed uncertainty estimates.
Given an entity in the graph, CF-GNN produces a prediction set/interval that
provably contains the true label with pre-defined coverage probability (e.g.
90%). We establish a permutation invariance condition that enables the validity
of CP on graph data and provide an exact characterization of the test-time
coverage. Moreover, besides valid coverage, it is crucial to reduce the
prediction set size/interval length for practical use. We observe a key
connection between non-conformity scores and network structures, which
motivates us to develop a topology-aware output correction model that learns to
update the prediction and produces more efficient prediction sets/intervals.
Extensive experiments show that CF-GNN achieves any pre-defined target marginal
coverage while significantly reducing the prediction set/interval size by up to
74% over the baselines. It also empirically achieves satisfactory conditional
coverage over various raw and network features.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：Basis Function Encoding of Numerical Features in Factorization Machines  for Improved Accuracy</b></summary>
  <p><b>编号</b>：[544]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14528</p>
  <p><b>作者</b>：Alex Shtoff,  Elie Abboud,  Rotem Stram,  Oren Somekh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large scale real-time, scale real-time content, real-time content recommendation, content recommendation systems, low computational costs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Factorization machine (FM) variants are widely used for large scale real-time
content recommendation systems, since they offer an excellent balance between
model accuracy and low computational costs for training and inference. These
systems are trained on tabular data with both numerical and categorical
columns. Incorporating numerical columns poses a challenge, and they are
typically incorporated using a scalar transformation or binning, which can be
either learned or chosen a-priori. In this work, we provide a systematic and
theoretically-justified way to incorporate numerical features into FM variants
by encoding them into a vector of function values for a set of functions of
one's choice.
We view factorization machines as approximators of segmentized functions,
namely, functions from a field's value to the real numbers, assuming the
remaining fields are assigned some given constants, which we refer to as the
segment. From this perspective, we show that our technique yields a model that
learns segmentized functions of the numerical feature spanned by the set of
functions of one's choice, namely, the spanning coefficients vary between
segments. Hence, to improve model accuracy we advocate the use of functions
known to have strong approximation power, and offer the B-Spline basis due to
its well-known approximation power, availability in software libraries, and
efficiency. Our technique preserves fast training and inference, and requires
only a small modification of the computational graph of an FM model. Therefore,
it is easy to incorporate into an existing system to improve its performance.
Finally, we back our claims with a set of experiments, including synthetic,
performance evaluation on several data-sets, and an A/B test on a real online
advertising system which shows improved performance.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Eliminating Spurious Correlations from Pre-trained Models via Data  Mixing</b></summary>
  <p><b>编号</b>：[548]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14521</p>
  <p><b>作者</b>：Yihao Xue,  Ali Payani,  Yu Yang,  Baharan Mirzasoleiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable convergence, Machine learning models, Machine learning, robustness properties, spurious correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models pre-trained on large datasets have achieved
remarkable convergence and robustness properties. However, these models often
exploit spurious correlations between certain attributes and labels, which are
prevalent in the majority of examples within specific categories but are not
predictive of these categories in general. The learned spurious correlations
may persist even after fine-tuning on new data, which degrades models'
performance on examples that do not exhibit the spurious correlation. In this
work, we propose a simple and highly effective method to eliminate spurious
correlations from pre-trained models. The key idea of our method is to leverage
a small set of examples with spurious attributes, and balance the spurious
attributes across all classes via data mixing. We theoretically confirm the
effectiveness of our method, and empirically demonstrate its state-of-the-art
performance on various vision and NLP tasks, including eliminating spurious
correlations from pre-trained ResNet50 on Waterbirds and CelebA, adversarially
pre-trained ResNet50 on ImageNet, and BERT pre-trained on CivilComments.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：CongFu: Conditional Graph Fusion for Drug Synergy Prediction</b></summary>
  <p><b>编号</b>：[549]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14517</p>
  <p><b>作者</b>：Oleksii Tsepa,  Bohdan Naida,  Bo Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：amplified combined effect, optimizing therapeutic outcomes, Drug synergy, presents a critical, therapeutic outcomes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Drug synergy, characterized by the amplified combined effect of multiple
drugs, presents a critical phenomenon for optimizing therapeutic outcomes.
However, limited data on drug synergy, arising from the vast number of possible
drug combinations and computational costs, motivate the need for predictive
methods. In this work, we introduce CongFu, a novel Conditional Graph Fusion
Layer, designed to predict drug synergy. CongFu employs an attention mechanism
and a bottleneck to extract local graph contexts and conditionally fuse graph
data within a global context. Its modular architecture enables flexible
replacement of layer modules, including readouts and graph encoders,
facilitating customization for diverse applications. To evaluate the
performance of CongFu, we conduct comprehensive experiments on four datasets,
encompassing three distinct setups for drug synergy prediction. Remarkably,
CongFu achieves state-of-the-art results on 11 out of 12 benchmark datasets,
demonstrating its ability to capture intricate patterns of drug synergy.
Through extensive ablation studies, we validate the significance of individual
layer components, affirming their contributions to overall predictive
performance. By addressing the challenge of predicting drug synergy in untested
drug pairs, CongFu opens new avenues for optimizing drug combinations and
advancing personalized medicine.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Chakra: Advancing Performance Benchmarking and Co-design using  Standardized Execution Traces</b></summary>
  <p><b>编号</b>：[550]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14516</p>
  <p><b>作者</b>：Srinivas Sridharan,  Taekyung Heo,  Louis Feng,  Zhaodong Wang,  Matt Bergeron,  Wenyin Fu,  Shengbao Zheng,  Brian Coutinho,  Saeed Rashidi,  Changhai Man,  Tushar Krishna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Chakra ETs, driving optimizations, Chakra, next-generation hardware, ETs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benchmarking and co-design are essential for driving optimizations and
innovation around ML models, ML software, and next-generation hardware. Full
workload benchmarks, e.g. MLPerf, play an essential role in enabling fair
comparison across different software and hardware stacks especially once
systems are fully designed and deployed. However, the pace of AI innovation
demands a more agile methodology to benchmark creation and usage by simulators
and emulators for future system co-design. We propose Chakra, an open graph
schema for standardizing workload specification capturing key operations and
dependencies, also known as Execution Trace (ET). In addition, we propose a
complementary set of tools/capabilities to enable collection, generation, and
adoption of Chakra ETs by a wide range of simulators, emulators, and
benchmarks. For instance, we use generative AI models to learn latent
statistical properties across thousands of Chakra ETs and use these models to
synthesize Chakra ETs. These synthetic ETs can obfuscate key proprietary
information and also target future what-if scenarios. As an example, we
demonstrate an end-to-end proof-of-concept that converts PyTorch ETs to Chakra
ETs and uses this to drive an open-source training system simulator
(ASTRA-sim). Our end-goal is to build a vibrant industry-wide ecosystem of
agile benchmarks and tools to drive future AI system co-design.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：RetICL: Sequential Retrieval of In-Context Examples with Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[553]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14502</p>
  <p><b>作者</b>：Alexander Scarlatos,  Andrew Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perform specific tasks, recent developments, language models focus, perform specific, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many recent developments in large language models focus on prompting them to
perform specific tasks. One effective prompting method is in-context learning,
where the model performs a (possibly new) generation/prediction task given one
(or more) examples. Past work has shown that the choice of examples can make a
large impact on task performance. However, finding good examples is not
straightforward since the definition of a representative group of examples can
vary greatly depending on the task. While there are many existing methods for
selecting in-context examples, they generally score examples independently,
ignoring the dependency between them and the order in which they are provided
to the large language model. In this work, we propose Retrieval for In-Context
Learning (RetICL), a learnable method for modeling and optimally selecting
examples sequentially for in-context learning. We frame the problem of
sequential example selection as a Markov decision process, design an example
retriever model using an LSTM, and train it using proximal policy optimization
(PPO). We validate RetICL on math problem solving datasets and show that it
outperforms both heuristic and learnable baselines, and achieves
state-of-the-art accuracy on the TabMWP dataset. We also use case studies to
show that RetICL implicitly learns representations of math problem solving
strategies.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Point2SSM: Learning Morphological Variations of Anatomies from Point  Cloud</b></summary>
  <p><b>编号</b>：[562]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14486</p>
  <p><b>作者</b>：Jadie Adams,  Shireen Elhabian</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：accurately construct correspondence-based, construct correspondence-based statistical, statistical shape models, correspondence-based statistical shape, accurately construct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Point2SSM, a novel unsupervised learning approach that can
accurately construct correspondence-based statistical shape models (SSMs) of
anatomy directly from point clouds. SSMs are crucial in clinical research for
analyzing the population-level morphological variation in bones and organs.
However, traditional methods for creating SSMs have limitations that hinder
their widespread adoption, such as the need for noise-free surface meshes or
binary volumes, reliance on assumptions or predefined templates, and
simultaneous optimization of the entire cohort leading to lengthy inference
times given new data. Point2SSM overcomes these barriers by providing a
data-driven solution that infers SSMs directly from raw point clouds, reducing
inference burdens and increasing applicability as point clouds are more easily
acquired. Deep learning on 3D point clouds has seen recent success in
unsupervised representation learning, point-to-point matching, and shape
correspondence; however, their application to constructing SSMs of anatomies is
largely unexplored. In this work, we benchmark state-of-the-art point cloud
deep networks on the task of SSM and demonstrate that they are not robust to
the challenges of anatomical SSM, such as noisy, sparse, or incomplete input
and significantly limited training data. Point2SSM addresses these challenges
via an attention-based module that provides correspondence mappings from
learned point features. We demonstrate that the proposed method significantly
outperforms existing networks in terms of both accurate surface sampling and
correspondence, better capturing population-level statistics.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Knowledge Graphs Querying</b></summary>
  <p><b>编号</b>：[563]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14485</p>
  <p><b>作者</b>：Arijit Khan</p>
  <p><b>备注</b>：accepted at ACM SIGMOD Record 2023</p>
  <p><b>关键词</b>：NELL were constructed, store large-scale, represents an entity, entity with attributes, directed edge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL
were constructed to store large-scale, real-world facts as (subject, predicate,
object) triples -- that can also be modeled as a graph, where a node (a subject
or an object) represents an entity with attributes, and a directed edge (a
predicate) is a relationship between two entities. Querying KGs is critical in
web search, question answering (QA), semantic search, personal assistants, fact
checking, and recommendation. While significant progress has been made on KG
construction and curation, thanks to deep learning recently we have seen a
surge of research on KG querying and QA. The objectives of our survey are
two-fold. First, research on KG querying has been conducted by several
communities, such as databases, data mining, semantic web, machine learning,
information retrieval, and natural language processing (NLP), with different
focus and terminologies; and also in diverse topics ranging from graph
databases, query languages, join algorithms, graph patterns matching, to more
sophisticated KG embedding and natural language questions (NLQs). We aim at
uniting different interdisciplinary topics and concepts that have been
developed for KG querying. Second, many recent advances on KG and query
embedding, multimodal KG, and KG-QA come from deep learning, IR, NLP, and
computer vision domains. We identify important challenges of KG querying that
received less attention by graph databases, and by the DB community in general,
e.g., incomplete KG, semantic matching, multimodal data, and NLQs. We conclude
by discussing interesting opportunities for the data management community, for
instance, KG as a unified data model and vector-based query processing.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Language Model Self-improvement by Reinforcement Learning Contemplation</b></summary>
  <p><b>编号</b>：[564]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14483</p>
  <p><b>作者</b>：Jing-Cheng Pang,  Pengyuan Wang,  Kaiyuan Li,  Xiong-Hui Chen,  Jiacheng Xu,  Zongzhang Zhang,  Yang Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Large Language Models, exhibited remarkable performance, exhibited remarkable, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have exhibited remarkable performance across
various natural language processing (NLP) tasks. However, fine-tuning these
models often necessitates substantial supervision, which can be expensive and
time-consuming to obtain. This paper introduces a novel unsupervised method
called LanguageModel Self-Improvement by Reinforcement Learning Contemplation
(SIRLC) that improves LLMs without reliance on external labels. Our approach is
grounded in the observation that it is simpler for language models to assess
text quality than to generate text. Building on this insight, SIRLC assigns
LLMs dual roles as both student and teacher. As a student, the LLM generates
answers to unlabeled questions, while as a teacher, it evaluates the generated
text and assigns scores accordingly. The model parameters are updated using
reinforcement learning to maximize the evaluation score. We demonstrate that
SIRLC can be applied to various NLP tasks, such as reasoning problems, text
generation, and machine translation. Our experiments show that SIRLC
effectively improves LLM performance without external supervision, resulting in
a 5.6% increase in answering accuracy for reasoning tasks and a rise in
BERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be
applied to models of different sizes, showcasing its broad applicability.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：A Block-Coordinate Approach of Multi-level Optimization with an  Application to Physics-Informed Neural Networks</b></summary>
  <p><b>编号</b>：[568]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14477</p>
  <p><b>作者</b>：Serge Gratton,  Valentin Mercier,  Elisa Riccietti,  Philippe L. Toint</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：involved sub-problems, advantages and exploitation, Multi-level methods, large-scale problems, solution of large-scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-level methods are widely used for the solution of large-scale problems,
because of their computational advantages and exploitation of the
complementarity between the involved sub-problems. After a re-interpretation of
multi-level methods from a block-coordinate point of view, we propose a
multi-level algorithm for the solution of nonlinear optimization problems and
analyze its evaluation complexity. We apply it to the solution of partial
differential equations using physics-informed neural networks (PINNs) and show
on a few test problems that the approach results in better solutions and
significant computational savings</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：FLAIR #2: textural and temporal information for semantic segmentation  from multi-source optical imagery</b></summary>
  <p><b>编号</b>：[572]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14467</p>
  <p><b>作者</b>：Anatol Garioud,  Apolline De Wit,  Marc Poupée,  Marion Valette,  Sébastien Giordano,  Boris Wattrelos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mapping land cover, semantic segmentation task, segmentation task aimed, high spatial resolution, land cover</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The FLAIR #2 dataset hereby presented includes two very distinct types of
data, which are exploited for a semantic segmentation task aimed at mapping
land cover. The data fusion workflow proposes the exploitation of the fine
spatial and textural information of very high spatial resolution (VHR)
mono-temporal aerial imagery and the temporal and spectral richness of high
spatial resolution (HR) time series of Copernicus Sentinel-2 satellite images.
The French National Institute of Geographical and Forest Information (IGN), in
response to the growing availability of high-quality Earth Observation (EO)
data, is actively exploring innovative strategies to integrate these data with
heterogeneous characteristics. IGN is therefore offering this dataset to
promote innovation and improve our knowledge of our territories.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：Towards Massively Multi-domain Multilingual Readability Assessment</b></summary>
  <p><b>编号</b>：[573]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14463</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Mohit Chandra,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massively multi-domain multilingual, automatic readability assessment, multi-domain multilingual dataset, massively multi-domain, multi-domain multilingual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ReadMe++, a massively multi-domain multilingual dataset for
automatic readability assessment. Prior work on readability assessment has been
mostly restricted to the English language and one or two text domains.
Additionally, the readability levels of sentences used in many previous
datasets are assumed on the document-level other than sentence-level, which
raises doubt about the quality of previous evaluations. We address those gaps
in the literature by providing an annotated dataset of 6,330 sentences in
Arabic, English, and Hindi collected from 64 different domains of text. Unlike
previous datasets, ReadMe++ offers more domain and language diversity and is
manually annotated at a sentence level using the Common European Framework of
Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework
that reduces subjectivity in annotation. Our experiments demonstrate that
models fine-tuned using ReadMe++ achieve strong cross-lingual transfer
capabilities and generalization to unseen domains. ReadMe++ will be made
publicly available to the research community.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：Having Beer after Prayer? Measuring Cultural Bias in Large Language  Models</b></summary>
  <p><b>编号</b>：[579]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14456</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models culturally biased, culturally biased, language models, language models culturally, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Are language models culturally biased? It is important that language models
conform to the cultural aspects of the communities they serve. However, we show
in this paper that language models suffer from a significant bias towards
Western culture when handling and generating text in Arabic, often preferring,
and producing Western-fitting content as opposed to the relevant Arab content.
We quantify this bias through a likelihood scoring-based metric using naturally
occurring contexts that we collect from online social media. Our experiments
reveal that both Arabic monolingual and multilingual models exhibit bias
towards Western culture in eight different cultural aspects: person names,
food, clothing, location, literature, beverage, religion, and sports. Models
also tend to exhibit more bias when prompted with Arabic sentences that are
more linguistically aligned with English. These findings raise concerns about
the cultural relevance of current language models. Our analyses show that
providing culture-indicating tokens or culturally-relevant demonstrations to
the model can help in debiasing.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：Fourier Neural Operators for Arbitrary Resolution Climate Data  Downscaling</b></summary>
  <p><b>编号</b>：[581]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14452</p>
  <p><b>作者</b>：Qidong Yang,  Alex Hernandez-Garcia,  Paula Harder,  Venkatesh Ramesh,  Prasanna Sattegeri,  Daniela Szwarcman,  Campbell D. Watson,  David Rolnick</p>
  <p><b>备注</b>：Presented at the ICLR 2023 workshop on "Tackling Climate Change with Machine Learning"</p>
  <p><b>关键词</b>：essential in guiding, guiding our understanding, change and responding, Climate, climate change</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Climate simulations are essential in guiding our understanding of climate
change and responding to its effects. However, it is computationally expensive
to resolve complex climate processes at high spatial resolution. As one way to
speed up climate simulations, neural networks have been used to downscale
climate variables from fast-running low-resolution simulations, but
high-resolution training data are often unobtainable or scarce, greatly
limiting accuracy. In this work, we propose a downscaling method based on the
Fourier neural operator. It trains with data of a small upsampling factor and
then can zero-shot downscale its input to arbitrary unseen high resolution.
Evaluated both on ERA5 climate model data and on the Navier-Stokes equation
solution data, our downscaling model significantly outperforms state-of-the-art
convolutional and generative adversarial downscaling models, both in standard
single-resolution downscaling and in zero-shot generalization to higher
upsampling factors. Furthermore, we show that our method also outperforms
state-of-the-art data-driven partial differential equation solvers on
Navier-Stokes equations. Overall, our work bridges the gap between simulation
of a physical process and interpolation of low-resolution output, showing that
it is possible to combine both approaches and significantly improve upon each
other.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：Kernel Interpolation with Sparse Grids</b></summary>
  <p><b>编号</b>：[582]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14451</p>
  <p><b>作者</b>：Mohit Yadav,  Daniel Sheldon,  Cameron Musco</p>
  <p><b>备注</b>：Accepted at Neural Information Processing Systems (NeurIPS) 2022</p>
  <p><b>关键词</b>：accelerates Gaussian process, accelerates Gaussian, Gaussian process, fast linear algebra, kernel covariance function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured kernel interpolation (SKI) accelerates Gaussian process (GP)
inference by interpolating the kernel covariance function using a dense grid of
inducing points, whose corresponding kernel matrix is highly structured and
thus amenable to fast linear algebra. Unfortunately, SKI scales poorly in the
dimension of the input points, since the dense grid size grows exponentially
with the dimension. To mitigate this issue, we propose the use of sparse grids
within the SKI framework. These grids enable accurate interpolation, but with a
number of points growing more slowly with dimension. We contribute a novel
nearly linear time matrix-vector multiplication algorithm for the sparse grid
kernel matrix. Next, we describe how sparse grids can be combined with an
efficient interpolation scheme based on simplices. With these changes, we
demonstrate that SKI can be scaled to higher dimensions while maintaining
accuracy.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust  Conversational Understanding</b></summary>
  <p><b>编号</b>：[584]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14449</p>
  <p><b>作者</b>：Zheng Chen,  Ziyan Jiang,  Fan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Google Assistant, Collaborative User Index, user index, reduce user frictions, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to
understand queries with defects to ensure robust conversational understanding
and reduce user frictions. The defective queries are often induced by user
ambiguities and mistakes, or errors in the automatic speech recognition (ASR)
and natural language understanding (NLU).
Personalized query rewriting (personalized QR) targets reducing defects in
the torso and tail user query traffic, and it typically relies on an index of
past successful user interactions with the conversational AI. This paper
presents our "Collaborative Query Rewriting" approach that focuses on rewriting
novel user interactions unseen in the user history. This approach builds a
"user Feedback Interaction Graph" (FIG) consisting of historical user-entity
interactions, and leverages multi-hop customer affinity to enrich each user's
index (i.e. the Collaborative User Index) that would help cover future unseen
defective queries. To counteract the precision degradation from the enlarged
index, we introduced additional transformer layers to the L1 retrieval model
and added multi-hop affinity and guardrail features to the L2 re-ranking model.
Given the production constraints of storage cost and runtime retrieval
latency, managing the size of the Collaborative User Index is important. As the
user index can be pre-computed, we explored using a Large Language Model (LLM)
for multi-hop customer affinity retrieval on the Video/Music domains. In
particular, this paper looked into the Dolly-V2 7B model. Given limited user
index size, We found the user index derived from fine-tuned Dolly-V2 generation
significantly enhanced coverage of unseen user interactions. Consequently, this
boosted QR performance on unseen user interactions compared to the graph
traversal based user index.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Evolution: A Unified Formula for Feature Operators from a High-level  Perspective</b></summary>
  <p><b>编号</b>：[589]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14409</p>
  <p><b>作者</b>：Zhicheng Cai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feature operators, self-attention and involution, Evolution, operators, feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, different types of feature operators (e.g., convolution,
self-attention and involution) utilize different approaches to extract and
aggregate the features. Resemblance can be hardly discovered from their
mathematical formulas. However, these three operators all serve the same
paramount purpose and bear no difference in essence. Hence we probe into the
essence of various feature operators from a high-level perspective, transformed
their components equivalently, and explored their mathematical expressions
within higher dimensions. We raise one clear and concrete unified formula for
different feature operators termed as Evolution. Evolution utilizes the
Evolution Function to generate the Evolution Kernel, which extracts and
aggregates the features in certain positions of the input feature map. We
mathematically deduce the equivalent transformation from the traditional
formulas of these feature operators to Evolution and prove the unification. In
addition, we discuss the forms of Evolution Functions and the properties of
generated Evolution Kernels, intending to give inspirations to the further
research and innovations of powerful feature operators.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：Deep Learning based Forecasting: a case study from the online fashion  industry</b></summary>
  <p><b>编号</b>：[590]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14406</p>
  <p><b>作者</b>：Manuel Kunz,  Stefan Birr,  Mones Raslan,  Lei Ma,  Zhen Li,  Adele Gouttes,  Mateusz Koren,  Tofigh Naghibi,  Johannes Stephan,  Mariia Bulycheva,  Matthias Grzeschik,  Armin Kekić,  Michael Narodovitch,  Kashif Rasul,  Julian Sieber,  Tim Januschowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：online fashion industry, data-driven forecasting models, fixed inventory assumption, fashion industry, industry set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Demand forecasting in the online fashion industry is particularly amendable
to global, data-driven forecasting models because of the industry's set of
particular challenges. These include the volume of data, the irregularity, the
high amount of turn-over in the catalog and the fixed inventory assumption.
While standard deep learning forecasting approaches cater for many of these,
the fixed inventory assumption requires a special treatment via controlling the
relationship between price and demand closely. In this case study, we describe
the data and our modelling approach for this forecasting problem in detail and
present empirical results that highlight the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：NeuralMatrix: Moving Entire Neural Networks to General Matrix  Multiplication for Efficient Inference</b></summary>
  <p><b>编号</b>：[591]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14405</p>
  <p><b>作者</b>：Ruiqi Sun,  Jie Zhao,  Xin He,  Yiran Li,  An Zou</p>
  <p><b>备注</b>：12 pages, 4 figures, Submitted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023)</p>
  <p><b>关键词</b>：deep neural networks, versatile deep neural, single general matrix, general matrix multiplication, introduce NeuralMatrix</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we introduce NeuralMatrix, a novel framework that enables the
computation of versatile deep neural networks (DNNs) on a single general matrix
multiplication (GEMM) accelerator. The proposed approach overcomes the
specificity limitations of ASIC-based accelerators while achieving
application-specific acceleration levels compared to general-purpose processors
such as CPUs and GPUs. We address the challenges of mapping both linear and
nonlinear operations in DNN computation to general matrix multiplications and
the impact of using a GEMM accelerator on DNN inference accuracy. Extensive
experiments are conducted on various DNN models from three popular categories
(i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results
demonstrate that DNNs suffer only up to a 2.02% accuracy loss after being
converted to general matrix multiplication, while achieving 113x to 19.44x
improvements in throughput per power compared to CPUs and GPUs.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Layer-adaptive Structured Pruning Guided by Latency</b></summary>
  <p><b>编号</b>：[592]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14403</p>
  <p><b>作者</b>：Siyuan Pan,  Linna Zhang,  Jie Zhang,  Xiaoshuang Li,  Liang Hou,  Xiaobing Tu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2010.07611, arXiv:2110.10811 by other authors</p>
  <p><b>关键词</b>：simplify network architecture, improve inference speed, pruning, inference speed, Structured pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured pruning can simplify network architecture and improve inference
speed. Combined with the underlying hardware and inference engine in which the
final model is deployed, better results can be obtained by using latency
collaborative loss function to guide network pruning together. Existing pruning
methods that optimize latency have demonstrated leading performance, however,
they often overlook the hardware features and connection in the network. To
address this problem, we propose a global importance score SP-LAMP(Structured
Pruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance
score LAMP from unstructured pruning to structured pruning. In SP-LAMP, each
layer includes a filter with an SP-LAMP score of 1, and the remaining filters
are grouped. We utilize a group knapsack solver to maximize the SP-LAMP score
under latency constraints. In addition, we improve the strategy of collect the
latency to make it more accurate. In particular, for ResNet50/ResNet18 on
ImageNet and CIFAR10, SP-LAMP is 1.28x/8.45x faster with +1.7%/-1.57% top-1
accuracy changed, respectively. Experimental results in ResNet56 on CIFAR10
demonstrate that our algorithm achieves lower latency compared to alternative
approaches while ensuring accuracy and FLOPs.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：Improving Speech Emotion Recognition Performance using Differentiable  Architecture Search</b></summary>
  <p><b>编号</b>：[593]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14402</p>
  <p><b>作者</b>：Thejan Rajapakshe,  Rajib Rana,  Sara Khalifa,  Berrak Sisman,  Björn Schuller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Speech Emotion Recognition, Emotion Recognition, Speech Emotion, human-computer interactions, critical enabler</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) is a critical enabler of emotion-aware
communication in human-computer interactions. Deep Learning (DL) has improved
the performance of SER models by improving model complexity. However, designing
DL architectures requires prior experience and experimental evaluations.
Encouragingly, Neural Architecture Search (NAS) allows automatic search for an
optimum DL model. In particular, Differentiable Architecture Search (DARTS) is
an efficient method of using NAS to search for optimised models. In this paper,
we propose DARTS for a joint CNN and LSTM architecture for improving SER
performance. Our choice of the CNN LSTM coupling is inspired by results showing
that similar models offer improved performance. While SER researchers have
considered CNNs and RNNs separately, the viability of using DARTs jointly for
CNN and LSTM still needs exploration. Experimenting with the IEMOCAP dataset,
we demonstrate that our approach outperforms best-reported results using DARTS
for SER.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：Reviewing Evolution of Learning Functions and Semantic Information  Measures for Understanding Deep Learning</b></summary>
  <p><b>编号</b>：[594]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14397</p>
  <p><b>作者</b>：Chenguang Lu</p>
  <p><b>备注</b>：34 pages, 9 figures. published in Entropy, 2023</p>
  <p><b>关键词</b>：Noise Contrast Estimation, Mutual Information, Information Noise Contrast, Estimated Mutual Information, Semantic Mutual Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A new trend in deep learning, represented by Mutual Information Neural
Estimation (MINE) and Information Noise Contrast Estimation (InfoNCE), is
emerging. In this trend, similarity functions and Estimated Mutual Information
(EMI) are used as learning and objective functions. Coincidentally, EMI is
essentially the same as Semantic Mutual Information (SeMI) proposed by the
author 30 years ago. This paper first reviews the evolutionary histories of
semantic information measures and learning functions. Then, it briefly
introduces the author's semantic information G theory with the rate-fidelity
function R(G) (G denotes SeMI, and R(G) extends R(D)) and its applications to
multi-label learning, the maximum Mutual Information (MI) classification, and
mixture models. Then it discusses how we should understand the relationship
between SeMI and Shan-non's MI, two generalized entropies (fuzzy entropy and
coverage entropy), Autoencoders, Gibbs distributions, and partition functions
from the perspective of the R(G) function or the G theory. An important
conclusion is that mixture models and Restricted Boltzmann Machines converge
because SeMI is maximized, and Shannon's MI is minimized, making information
efficiency G/R close to 1. A potential opportunity is to simplify deep learning
by using Gaussian channel mixture models for pre-training deep neural networks'
latent layers without considering gradients. It also discusses how the SeMI
measure is used as the reward function (reflecting purposiveness) for
reinforcement learning. The G theory helps interpret deep learning but is far
from enough. Combining semantic information theory and deep learning will
accelerate their development.</p>
  </details>
</details>
<details>
  <summary>174. <b>标题：FITNESS: A Causal De-correlation Approach for Mitigating Bias in Machine  Learning Software</b></summary>
  <p><b>编号</b>：[595]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14396</p>
  <p><b>作者</b>：Ying Xiao,  Shangwen Wang,  Sicen Liu,  Dingyuan Xue,  Xian Zhan,  Yepang Liu</p>
  <p><b>备注</b>：12 pages, 7 figures and 6 tables</p>
  <p><b>关键词</b>：including college admissions, machine learning algorithms, Software built, variety of fields, including college</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software built on top of machine learning algorithms is becoming increasingly
prevalent in a variety of fields, including college admissions, healthcare,
insurance, and justice. The effectiveness and efficiency of these systems
heavily depend on the quality of the training datasets. Biased datasets can
lead to unfair and potentially harmful outcomes, particularly in such critical
decision-making systems where the allocation of resources may be affected. This
can exacerbate discrimination against certain groups and cause significant
social disruption. To mitigate such unfairness, a series of bias-mitigating
methods are proposed. Generally, these studies improve the fairness of the
trained models to a certain degree but with the expense of sacrificing the
model performance. In this paper, we propose FITNESS, a bias mitigation
approach via de-correlating the causal effects between sensitive features
(e.g., the sex) and the label. Our key idea is that by de-correlating such
effects from a causality perspective, the model would avoid making predictions
based on sensitive features and thus fairness could be improved. Furthermore,
FITNESS leverages multi-objective optimization to achieve a better
performance-fairness trade-off. To evaluate the effectiveness, we compare
FITNESS with 7 state-of-the-art methods in 8 benchmark tasks by multiple
metrics. Results show that FITNESS can outperform the state-of-the-art methods
on bias mitigation while preserve the model's performance: it improved the
model's fairness under all the scenarios while decreased the model's
performance under only 26.67% of the scenarios. Additionally, FITNESS surpasses
the Fairea Baseline in 96.72% cases, outperforming all methods we compared.</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：Towards credible visual model interpretation with path attribution</b></summary>
  <p><b>编号</b>：[596]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14395</p>
  <p><b>作者</b>：Naveed Akhtar,  Muhammad A. A. K. Jalwana</p>
  <p><b>备注</b>：ICML'23 paper (text improved for CV community)</p>
  <p><b>关键词</b>：visual model interpretation, interpretation tools due, post-hoc model interpretation, model interpretation tools, attribution framework stands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originally inspired by game-theory, path attribution framework stands out
among the post-hoc model interpretation tools due to its axiomatic nature.
However, recent developments show that this framework can still suffer from
counter-intuitive results. Moreover, specifically for deep visual models, the
existing path-based methods also fall short on conforming to the original
intuitions that are the basis of the claimed axiomatic properties of this
framework. We address these problems with a systematic investigation, and
pinpoint the conditions in which the counter-intuitive results can be avoided
for deep visual model interpretation with the path attribution strategy. We
also devise a scheme to preclude the conditions in which visual model
interpretation can invalidate the axiomatic properties of path attribution.
These insights are combined into a method that enables reliable visual model
interpretation. Our findings are establish empirically with multiple datasets,
models and evaluation metrics. Extensive experiments show a consistent
performance gain of our method over the baselines.</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Unsupervised Spiking Neural Network Model of Prefrontal Cortex to study  Task Switching with Synaptic deficiency</b></summary>
  <p><b>编号</b>：[597]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14394</p>
  <p><b>作者</b>：Ashwin Viswanathan Kannan,  Goutam Mylavarapu,  Johnson P Thomas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Spiking Neural Networks, Prefrontal Cortex, Neural Networks, understand how neurons, neurons adapt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we build a computational model of Prefrontal Cortex (PFC)
using Spiking Neural Networks (SNN) to understand how neurons adapt and respond
to tasks switched under short and longer duration of stimulus changes. We also
explore behavioral deficits arising out of the PFC lesions by simulating
lesioned states in our Spiking architecture model. Although there are some
computational models of the PFC, SNN's have not been used to model them. In
this study, we use SNN's having parameters close to biologically plausible
values and train the model using unsupervised Spike Timing Dependent Plasticity
(STDP) learning rule. Our model is based on connectionist architectures and
exhibits neural phenomena like sustained activity which helps in generating
short-term or working memory. We use these features to simulate lesions by
deactivating synaptic pathways and record the weight adjustments of learned
patterns and capture the accuracy of learning tasks in such conditions. All our
experiments are trained and recorded using a real-world Fashion MNIST (FMNIST)
dataset and through this work, we bridge the gap between bio-realistic models
and those that perform well in pattern recognition tasks</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Video Prediction Models as Rewards for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14343</p>
  <p><b>作者</b>：Alejandro Escontrela,  Ademi Adeniji,  Wilson Yan,  Ajay Jain,  Xue Bin Peng,  Ken Goldberg,  Youngwoon Lee,  Danijar Hafner,  Pieter Abbeel</p>
  <p><b>备注</b>：20 pages, 15 figures, 4 tables. under review</p>
  <p><b>关键词</b>：learn complex behaviors, Video Prediction, learn complex, long-standing challenge, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Specifying reward signals that allow agents to learn complex behaviors is a
long-standing challenge in reinforcement learning. A promising approach is to
extract preferences for behaviors from unlabeled videos, which are widely
available on the internet. We present Video Prediction Rewards (VIPER), an
algorithm that leverages pretrained video prediction models as action-free
reward signals for reinforcement learning. Specifically, we first train an
autoregressive transformer on expert videos and then use the video prediction
likelihoods as reward signals for a reinforcement learning agent. VIPER enables
expert-level control without programmatic task rewards across a wide range of
DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction
model allows us to derive rewards for an out-of-distribution environment where
no expert data is available, enabling cross-embodiment generalization for
tabletop manipulation. We see our work as starting point for scalable reward
specification from unlabeled videos that will benefit from the rapid advances
in generative modeling. Source code and datasets are available on the project
website: this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Automatic Model Selection with Large Language Models for Reasoning</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14333</p>
  <p><b>作者</b>：Xu Zhao,  Yuxi Xie,  Kenji Kawaguchi,  Junxian He,  Qizhe Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Program-Aided Language Models, Language Models represent, strengths and weaknesses, large language model, Program-Aided Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chain-of-Thought and Program-Aided Language Models represent two distinct
reasoning methods, each with its own strengths and weaknesses. We demonstrate
that it is possible to combine the best of both worlds by using different
models for different problems, employing a large language model (LLM) to
perform model selection. Through a theoretical analysis, we discover that the
performance improvement is determined by the differences between the combined
methods and the success rate of choosing the correct model. On eight reasoning
datasets, our proposed approach shows significant improvements. Furthermore, we
achieve new state-of-the-art results on GSM8K and SVAMP with accuracies of
96.5% and 93.7%, respectively. Our code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：What Else Do I Need to Know? The Effect of Background Information on  Users' Reliance on AI Systems</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14331</p>
  <p><b>作者</b>：Navita Goyal,  Eleftheria Briakou,  Amanda Liu,  Connor Baumler,  Claire Bonial,  Jeffrey Micher,  Clare R. Voss,  Marine Carpuat,  Hal Daumé III</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：shown impressive performance, retrieving relevant context, shown impressive, impressive performance, performance at answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI systems have shown impressive performance at answering questions by
retrieving relevant context. However, with the increasingly large models, it is
impossible and often undesirable to constrain models' knowledge or reasoning to
only the retrieved context. This leads to a mismatch between the information
that these models access to derive the answer and the information available to
the user consuming the AI predictions to assess the AI predicted answer. In
this work, we study how users interact with AI systems in absence of sufficient
information to assess AI predictions. Further, we ask the question of whether
adding the requisite background alleviates the concerns around over-reliance in
AI predictions. Our study reveals that users rely on AI predictions even in the
absence of sufficient information needed to assess its correctness. Providing
the relevant background, however, helps users catch AI errors better, reducing
over-reliance on incorrect AI predictions. On the flip side, background
information also increases users' confidence in their correct as well as
incorrect judgments. Contrary to common expectation, aiding a user's perusal of
the context and the background through highlights is not helpful in alleviating
the issue of over-confidence stemming from availability of more information.
Our work aims to highlight the gap between how NLP developers perceive
informational need in human-AI interaction and the actual human interaction
with the information available to them.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Large Language Models are Frame-level Directors for Zero-shot  Text-to-Video Generation</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14330</p>
  <p><b>作者</b>：Susung Hong,  Junyoung Seo,  Sunghwan Hong,  Heeseong Shin,  Seungryong Kim</p>
  <p><b>备注</b>：The code and demo will be available at this https URL</p>
  <p><b>关键词</b>：extending pre-trained, paradigm of AI-generated, increasing attention, attention in extending, AIGC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the paradigm of AI-generated content (AIGC), there has been increasing
attention in extending pre-trained text-to-image (T2I) models to text-to-video
(T2V) generation. Despite their effectiveness, these frameworks face challenges
in maintaining consistent narratives and handling rapid shifts in scene
composition or object placement from a single user prompt. This paper
introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned
large language models (LLMs) to generate frame-by-frame descriptions from a
single abstract user prompt. DirecT2V utilizes LLM directors to divide user
inputs into separate prompts for each frame, enabling the inclusion of
time-varying content and facilitating consistent video generation. To maintain
temporal consistency and prevent object collapse, we propose a novel value
mapping method and dual-softmax filtering. Extensive experimental results
validate the effectiveness of the DirecT2V framework in producing visually
coherent and consistent videos from abstract user prompts, addressing the
challenges of zero-shot video generation.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14327</p>
  <p><b>作者</b>：Da Yin,  Xiao Liu,  Fan Yin,  Ming Zhong,  Hritik Bansal,  Jiawei Han,  Kai-Wei Chang</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：large language models, language models, emerged to enhance, enhance the capabilities, capabilities of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has emerged to enhance the capabilities of large language
models (LLMs) in providing appropriate outputs based on input instructions.
However, existing methods for collecting instruction-tuning data suffer from
limitations in scalability and affordability. In this paper, we propose
Dynosaur, a dynamic growth paradigm for instruction-tuning data curation. Built
upon the metadata of existing NLP datasets, we generate multiple task
instructions applicable to various NLP datasets and determine the relevant data
fields for constructing instruction-tuning data with LLMs. Dynosaur offers
several advantages: 1) lower generation costs (less than $12 for generating
800K instruction-tuning data), 2) good quality of instruction-tuning data
(better performance than Alpaca and Instruction GPT-4 on Super-NI with
comparable data sizes), and 3) the ability to grow dynamically by incorporating
new datasets from Huggingface Datasets Platform. We further investigate
continual learning as an approach to learning with the ever-growing
instruction-tuning dataset. We demonstrate that replay methods not only help
mitigate forgetting issues but help generalize to unseen tasks better. As a
novel continual learning scenario for instruction tuning, selecting tasks based
on instruction representations can be an effective replaying strategy. Code and
data are released at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Improving Factuality and Reasoning in Language Models through Multiagent  Debate</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14325</p>
  <p><b>作者</b>：Yilun Du,  Shuang Li,  Antonio Torralba,  Joshua B. Tenenbaum,  Igor Mordatch</p>
  <p><b>备注</b>：Project Webpage and Code: this https URL</p>
  <p><b>关键词</b>：demonstrated remarkable capabilities, recent years, Large language models, demonstrated remarkable, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
"society of minds" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：READ: Recurrent Adaptation of Large Transformers</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15348</p>
  <p><b>作者</b>：Sid Wang,  John Nguyen,  Ke Li,  Carole-Jean Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Computer Vision tasks, Natural Language, Language Processing, Processing and Computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale Transformers has led to the explosion of many AI
applications across Natural Language Processing and Computer Vision tasks.
However, fine-tuning all pre-trained model parameters becomes impractical as
the model size and number of tasks increase. Parameter-efficient transfer
learning (PETL) methods aim to address these challenges. While effective in
reducing the number of trainable parameters, PETL methods still require
significant energy and computational resources to fine-tune. In this paper, we
introduce \textbf{RE}current \textbf{AD}aption (READ) -- a lightweight and
memory-efficient fine-tuning method -- to overcome the limitations of the
current PETL approaches. Specifically, READ inserts a small RNN network
alongside the backbone model so that the model does not have to back-propagate
through the large backbone network. Through comprehensive empirical evaluation
of the GLUE benchmark, we demonstrate READ can achieve a $56\%$ reduction in
the training memory consumption and an $84\%$ reduction in the GPU energy usage
while retraining high model quality compared to full-tuning. Additionally, the
model size of READ does not grow with the backbone model size, making it a
highly scalable solution for fine-tuning large Transformers.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Bayesian calibration of differentiable agent-based models</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15340</p>
  <p><b>作者</b>：Arnau Quera-Bofarull,  Ayush Chopra,  Anisoara Calinescu,  Michael Wooldridge,  Joel Dyer</p>
  <p><b>备注</b>：Accepted for Oral Presentation at the AI4ABM Workshop at ICLR 2023</p>
  <p><b>关键词</b>：modelling complex systems, ABMs' likelihood functions, mathematical operations comprising, Agent-based modelling, complex systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Agent-based modelling (ABMing) is a powerful and intuitive approach to
modelling complex systems; however, the intractability of ABMs' likelihood
functions and the non-differentiability of the mathematical operations
comprising these models present a challenge to their use in the real world.
These difficulties have in turn generated research on approximate Bayesian
inference methods for ABMs and on constructing differentiable approximations to
arbitrary ABMs, but little work has been directed towards designing approximate
Bayesian inference techniques for the specific case of differentiable ABMs. In
this work, we aim to address this gap and discuss how generalised variational
inference procedures may be employed to provide misspecification-robust
Bayesian parameter inferences for differentiable ABMs. We demonstrate with
experiments on a differentiable ABM of the COVID-19 pandemic that our approach
can result in accurate inferences, and discuss avenues for future work.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Measuring and Mitigating Constraint Violations of In-Context Learning  for Utterance-to-API Semantic Parsing</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15338</p>
  <p><b>作者</b>：Shufan Wang,  Sebastien Jean,  Sailik Sengupta,  James Gung,  Nikolaos Pappas,  Yi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, pre-defined API specifications, task-oriented semantic parsing, translate users' utterances, executable task-oriented semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In executable task-oriented semantic parsing, the system aims to translate
users' utterances in natural language to machine-interpretable programs (API
calls) that can be executed according to pre-defined API specifications. With
the popularity of Large Language Models (LLMs), in-context learning offers a
strong baseline for such scenarios, especially in data-limited regimes.
However, LLMs are known to hallucinate and therefore pose a formidable
challenge in constraining generated content. Thus, it remains uncertain if LLMs
can effectively perform task-oriented utterance-to-API generation where
respecting API's structural and task-specific constraints is crucial.
In this work, we seek to measure, analyze and mitigate such constraints
violations. First, we identify the categories of various constraints in
obtaining API-semantics from task-oriented utterances, and define fine-grained
metrics that complement traditional ones. Second, we leverage these metrics to
conduct a detailed error analysis of constraints violations seen in
state-of-the-art LLMs, which motivates us to investigate two mitigation
strategies: Semantic-Retrieval of Demonstrations (SRD) and API-aware
Constrained Decoding (API-CD). Our experiments show that these strategies are
effective at reducing constraints violations and improving the quality of the
generated API calls, but require careful consideration given their
implementation complexity and latency.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Gorilla: Large Language Model Connected with Massive APIs</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15334</p>
  <p><b>作者</b>：Shishir G. Patil,  Tianjun Zhang,  Xin Wang,  Joseph E. Gonzalez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, advances recently, program synthesis, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have seen an impressive wave of advances
recently, with models now excelling in a variety of tasks, such as mathematical
reasoning and program synthesis. However, their potential to effectively use
tools via API calls remains unfulfilled. This is a challenging task even for
today's state-of-the-art LLMs such as GPT-4, largely due to their inability to
generate accurate input arguments and their tendency to hallucinate the wrong
usage of an API call. We release Gorilla, a finetuned LLaMA-based model that
surpasses the performance of GPT-4 on writing API calls. When combined with a
document retriever, Gorilla demonstrates a strong capability to adapt to
test-time document changes, enabling flexible user updates or version changes.
It also substantially mitigates the issue of hallucination, commonly
encountered when prompting LLMs directly. To evaluate the model's ability, we
introduce APIBench, a comprehensive dataset consisting of HuggingFace,
TorchHub, and TensorHub APIs. The successful integration of the retrieval
system with Gorilla demonstrates the potential for LLMs to use tools more
accurately, keep up with frequently updated documentation, and consequently
increase the reliability and applicability of their outputs. Gorilla's code,
model, data, and demo are available at this https URL</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Visual Programming for Text-to-Image Generation and Evaluation</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15328</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：18 pages; Project website: this https URL</p>
  <p><b>关键词</b>：demonstrated impressive performance, large language models, adopted language models, generation, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models have demonstrated impressive performance in many
domains, recent works have adopted language models (LMs) as controllers of
visual modules for vision-and-language tasks. While existing work focuses on
equipping LMs with visual understanding, we propose two novel
interpretable/explainable visual programming frameworks for text-to-image (T2I)
generation and evaluation. First, we introduce VPGen, an interpretable
step-by-step T2I generation framework that decomposes T2I generation into three
steps: object/count generation, layout generation, and image generation. We
employ an LM to handle the first two steps (object/count generation and layout
generation), by finetuning it on text-layout pairs. Our step-by-step T2I
generation framework provides stronger spatial control than end-to-end models,
the dominant approach for this task. Furthermore, we leverage the world
knowledge of pretrained LMs, overcoming the limitation of previous
layout-guided T2I works that can only handle predefined object classes. We
demonstrate that our VPGen has improved control in counts/spatial
relations/scales of objects than state-of-the-art T2I generation models.
Second, we introduce VPEval, an interpretable and explainable evaluation
framework for T2I generation based on visual programming. Unlike previous T2I
evaluations with a single scoring model that is accurate in some skills but
unreliable in others, VPEval produces evaluation programs that invoke a set of
visual modules that are experts in different skills, and also provides
visual+textual explanations of the evaluation results. Our analysis shows
VPEval provides a more human-correlated evaluation for skill-specific and
open-ended prompts than widely used single model-based evaluation. We hope our
work encourages future progress on interpretable/explainable generation and
evaluation for T2I models. Website: this https URL</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Model evaluation for extreme risks</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15324</p>
  <p><b>作者</b>：Toby Shevlane,  Sebastian Farquhar,  Ben Garfinkel,  Mary Phuong,  Jess Whittlestone,  Jade Leung,  Daniel Kokotajlo,  Nahema Marchal,  Markus Anderljung,  Noam Kolt,  Lewis Ho,  Divya Siddarth,  Shahar Avin,  Will Hawkins,  Been Kim,  Iason Gabriel,  Vijay Bolina,  Jack Clark,  Yoshua Bengio,  Paul Christiano,  Allan Dafoe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Current approaches, systems tend, produce systems, approaches to building, building general-purpose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current approaches to building general-purpose AI systems tend to produce
systems with both beneficial and harmful capabilities. Further progress in AI
development could lead to capabilities that pose extreme risks, such as
offensive cyber capabilities or strong manipulation skills. We explain why
model evaluation is critical for addressing extreme risks. Developers must be
able to identify dangerous capabilities (through "dangerous capability
evaluations") and the propensity of models to apply their capabilities for harm
(through "alignment evaluations"). These evaluations will become critical for
keeping policymakers and other stakeholders informed, and for making
responsible decisions about model training, deployment, and security.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题："What if?" in Probabilistic Logic Programming</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15318</p>
  <p><b>作者</b>：Rafael Kiesel,  Kilian Rückschloß,  Felix Weitkämper</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ProbLog program, ProbLog, ProbLog program defines, Boolean random variables, program</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A ProbLog program is a logic program with facts that only hold with a
specified probability. In this contribution we extend this ProbLog language by
the ability to answer "What if" queries. Intuitively, a ProbLog program defines
a distribution by solving a system of equations in terms of mutually
independent predefined Boolean random variables. In the theory of causality,
Judea Pearl proposes a counterfactual reasoning for such systems of equations.
Based on Pearl's calculus, we provide a procedure for processing these
counterfactual queries on ProbLog programs, together with a proof of
correctness and a full implementation. Using the latter, we provide insights
into the influence of different parameters on the scalability of inference.
Finally, we also show that our approach is consistent with CP-logic, i.e. with
the causal semantics for logic programs with annotated with disjunctions.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Science in the Era of ChatGPT, Large Language Models and AI: Challenges  for Research Ethics Review and How to Respond</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15299</p>
  <p><b>作者</b>：Evangelos Pournaras</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ChatGPT find remarkable, artificial intelligence, ChatGPT find, find remarkable, remarkable but controversial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models of artificial intelligence (AI) such as ChatGPT find
remarkable but controversial applicability in science and research. This paper
reviews epistemological challenges, ethical and integrity risks in science
conduct. This is with the aim to lay new timely foundations for a high-quality
research ethics review in the era of AI. The role of AI language models as a
research instrument and subject is scrutinized along with ethical implications
for scientists, participants and reviewers. Ten recommendations shape a
response for a more responsible research conduct with AI language models.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal  Image Generation</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15296</p>
  <p><b>作者</b>：Marco Bellagente,  Manuel Brack,  Hannah Teufel,  Felix Friedrich,  Björn Deiseroth,  Constantin Eichenberg,  Andrew Dai,  Robert Baldock,  Souradeep Nanda,  Koen Oostermeijer,  Andres Felipe Cruz-Salinas,  Patrick Schramowski,  Kristian Kersting,  Samuel Weinbach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide to users, recent popularity, largely be attributed, intuitive interface, interface they provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent popularity of text-to-image diffusion models (DM) can largely be
attributed to the intuitive interface they provide to users. The intended
generation can be expressed in natural language, with the model producing
faithful interpretations of text prompts. However, expressing complex or
nuanced ideas in text alone can be difficult. To ease image generation, we
propose MultiFusion that allows one to express complex and nuanced concepts
with arbitrarily interleaved inputs of multiple modalities and languages.
MutliFusion leverages pre-trained models and aligns them for integration into a
cohesive system, thereby avoiding the need for extensive training from scratch.
Our experimental results demonstrate the efficient transfer of capabilities
from individual modules to the downstream model. Specifically, the fusion of
all independent components allows the image generation module to utilize
multilingual, interleaved multimodal inputs despite being trained solely on
monomodal data in a single language.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：The Crucial Role of Normalization in Sharpness-Aware Minimization</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15287</p>
  <p><b>作者</b>：Yan Dai,  Kwangjun Ahn,  Suvrit Sra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed gradient-based optimizer, deep neural networks, recently proposed gradient-based, Sharpness-Aware Minimization, gradient-based optimizer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based
optimizer (Foret et al., ICLR 2021) that greatly improves the prediction
performance of deep neural networks. Consequently, there has been a surge of
interest in explaining its empirical success. We focus, in particular, on
understanding the role played by normalization, a key component of the SAM
updates. We theoretically and empirically study the effect of normalization in
SAM for both convex and non-convex functions, revealing two key roles played by
normalization: i) it helps in stabilizing the algorithm; and ii) it enables the
algorithm to drift along a continuum (manifold) of minima -- a property
identified by recent theoretical works that is the key to better performance.
We further argue that these two properties of normalization make SAM robust
against the choice of hyper-parameters, supporting the practicality of SAM. Our
conclusions are backed by various experiments.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Simple and Effective Framework for Strict Zero-Shot Hierarchical  Classification</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15282</p>
  <p><b>作者</b>：Rohan Bhambhoria,  Lei Chen,  Xiaodan Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, recent years, large language, language models, achieved strong performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, large language models (LLMs) have achieved strong
performance on benchmark tasks, especially in zero or few-shot settings.
However, these benchmarks often do not adequately address the challenges posed
in the real-world, such as that of hierarchical classification. In order to
address this challenge, we propose refactoring conventional tasks on
hierarchical datasets into a more indicative long-tail prediction task. We
observe LLMs are more prone to failure in these cases. To address these
limitations, we propose the use of entailment-contradiction prediction in
conjunction with LLMs, which allows for strong performance in a strict
zero-shot setting. Importantly, our method does not require any parameter
updates, a resource-intensive process and achieves strong performance across
multiple datasets.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Testing the General Deductive Reasoning Capacity of Large Language  Models Using OOD Examples</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15269</p>
  <p><b>作者</b>：Abulhair Saparov,  Richard Yuanzhe Pang,  Vishakh Padmakumar,  Nitish Joshi,  Seyed Mehran Kazemi,  Najoung Kim,  He He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general deductive reasoning, deductive reasoning ability, deductive reasoning, intractably large size, general deductive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the intractably large size of the space of proofs, any model that is
capable of general deductive reasoning must generalize to proofs of greater
complexity. Recent studies have shown that large language models (LLMs) possess
some abstract deductive reasoning ability given chain-of-thought prompts.
However, they have primarily been tested on proofs using modus ponens or of a
specific size, and from the same distribution as the in-context examples. To
measure the general deductive reasoning ability of LLMs, we test on a broad set
of deduction rules and measure their ability to generalize to more complex
proofs from simpler demonstrations from multiple angles: depth-, width-, and
compositional generalization. To facilitate systematic exploration, we
construct a new synthetic and programmable reasoning dataset that enables
control over deduction rules and proof complexity. Our experiments on four LLMs
of various sizes and training objectives show that they are able to generalize
to longer and compositional proofs. However, they require explicit
demonstrations to produce hypothetical subproofs, specifically in proof by
cases and proof by contradiction.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：EvEval: A Comprehensive Evaluation of Event Semantics for Large Language  Models</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15268</p>
  <p><b>作者</b>：Zhengwei Tao,  Zhi Jin,  Xiaoying Bai,  Haiyan Zhao,  Yanlin Feng,  Jia Li,  Wenpeng Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：event semantic processing, event semantic, semantic processing, serve as fundamental, fundamental units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Events serve as fundamental units of occurrence within various contexts. The
processing of event semantics in textual information forms the basis of
numerous natural language processing (NLP) applications. Recent studies have
begun leveraging large language models (LLMs) to address event semantic
processing. However, the extent that LLMs can effectively tackle these
challenges remains uncertain. Furthermore, the lack of a comprehensive
evaluation framework for event semantic processing poses a significant
challenge in evaluating these capabilities. In this paper, we propose an
overarching framework for event semantic processing, encompassing
understanding, reasoning, and prediction, along with their fine-grained
aspects. To comprehensively evaluate the event semantic processing abilities of
models, we introduce a novel benchmark called EVEVAL. We collect 8 datasets
that cover all aspects of event semantic processing. Extensive experiments are
conducted on EVEVAL, leading to several noteworthy findings based on the
obtained results.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Discounting in Strategy Logic</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15256</p>
  <p><b>作者</b>：Munyque Mittelmann,  Aniello Murano,  Laurent Perrussel</p>
  <p><b>备注</b>：Extended version of the paper accepted at IJCAI 2023</p>
  <p><b>关键词</b>：strategies and time, dimension in multi-agent, multi-agent systems, reason about strategies, important dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discounting is an important dimension in multi-agent systems as long as we
want to reason about strategies and time. It is a key aspect in economics as it
captures the intuition that the far-away future is not as important as the near
future. Traditional verification techniques allow to check whether there is a
winning strategy for a group of agents but they do not take into account the
fact that satisfying a goal sooner is different from satisfying it after a long
wait. In this paper, we augment Strategy Logic with future discounting over a
set of discounted functions D, denoted SLdisc[D]. We consider "until" operators
with discounting functions: the satisfaction value of a specification in
SLdisc[D] is a value in [0, 1], where the longer it takes to fulfill
requirements, the smaller the satisfaction value is. We motivate our approach
with classical examples from Game Theory and study the complexity of
model-checking SLdisc[D]-formulas.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Rethinking the Evaluation Protocol of Domain Generalization</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15253</p>
  <p><b>作者</b>：Han Yu,  Xingxuan Zhang,  Renzhe Xu,  Jiashuo Liu,  Yue He,  Peng Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging common knowledge, common knowledge learned, OOD generalization ability, test data information, OOD generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain generalization aims to solve the challenge of Out-of-Distribution
(OOD) generalization by leveraging common knowledge learned from multiple
training domains to generalize to unseen test domains. To accurately evaluate
the OOD generalization ability, it is necessary to ensure that test data
information is unavailable. However, the current domain generalization protocol
may still have potential test data information leakage. This paper examines the
potential risks of test data information leakage in two aspects of the current
protocol: pretraining on ImageNet and oracle model selection. We propose that
training from scratch and using multiple test domains would result in a more
precise evaluation of OOD generalization ability. We also rerun the algorithms
with the modified protocol and introduce a new leaderboard to encourage future
research in domain generalization with a fairer comparison.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Decision-Aware Actor-Critic with Function Approximation and Theoretical  Guarantees</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15249</p>
  <p><b>作者</b>：Sharan Vaswani,  Amirreza Kazemi,  Reza Babanezhad,  Nicolas Le Roux</p>
  <p><b>备注</b>：44 pages</p>
  <p><b>关键词</b>：policy gradient method, gradient method, value-based method, reinforcement learning, method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Actor-critic (AC) methods are widely used in reinforcement learning (RL) and
benefit from the flexibility of using any policy gradient method as the actor
and value-based method as the critic. The critic is usually trained by
minimizing the TD error, an objective that is potentially decorrelated with the
true goal of achieving a high reward with the actor. We address this mismatch
by designing a joint objective for training the actor and critic in a
decision-aware fashion. We use the proposed objective to design a generic, AC
algorithm that can easily handle any function approximation. We explicitly
characterize the conditions under which the resulting algorithm guarantees
monotonic policy improvement, regardless of the choice of the policy and critic
parameterization. Instantiating the generic algorithm results in an actor that
involves maximizing a sequence of surrogate functions (similar to TRPO, PPO)
and a critic that involves minimizing a closely connected objective. Using
simple bandit examples, we provably establish the benefit of the proposed
critic objective over the standard squared error. Finally, we empirically
demonstrate the benefit of our decision-aware actor-critic framework on simple
RL problems.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Ethics and Deep Learning</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15239</p>
  <p><b>作者</b>：Travis LaCroix,  Simon J. D. Prince</p>
  <p><b>备注</b>：Copyright in this Work has been licensed exclusively to The MIT Press, this https URL, which will be releasing the final version to the public in 2023. All inquiries regarding rights should be addressed to The MIT Press, Rights and Permissions Department</p>
  <p><b>关键词</b>：Understanding Deep, Prince, Understanding, Deep, http URL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article appears as chapter 21 of Prince (2023, Understanding Deep
Learning); a complete draft of the textbook is available here:
this http URL. This chapter considers potential harms arising from the
design and use of AI systems. These include algorithmic bias, lack of
explainability, data privacy violations, militarization, fraud, and
environmental concerns. The aim is not to provide advice on being more ethical.
Instead, the goal is to express ideas and start conversations in key areas that
have received attention in philosophy, political science, and the broader
social sciences.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Boosting Cross-lingual Transferability in Multilingual Models via  In-Context Learning</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15233</p>
  <p><b>作者</b>：Sunkyoung Kim,  Dayeon Ki,  Yireun Kim,  Jinsik Lee</p>
  <p><b>备注</b>：Work In Progress</p>
  <p><b>关键词</b>：concerned with monolingual, Existing cross-lingual transfer, CLT, cross-lingual transfer, transfer prompting method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing cross-lingual transfer (CLT) prompting methods are only concerned
with monolingual demonstration examples in the source language. In this paper,
we propose In-CLT, a novel cross-lingual transfer prompting method that
leverages both source and target languages to construct the demonstration
examples. We conduct comprehensive evaluations on multilingual benchmarks,
focusing on question answering tasks. Experiment results show that In-CLT
prompt not only improves multilingual models' cross-lingual transferability,
but also demonstrates remarkable unseen language generalization ability. In-CLT
prompting, in particular, improves model performance by 10 to 20\% points on
average when compared to prior cross-lingual transfer approaches. We also
observe the surprising performance gain on the other multilingual benchmarks,
especially in reasoning tasks. Furthermore, we investigate the relationship
between lexical similarity and pre-training corpora in terms of the
cross-lingual transfer gap.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Neural Summarization of Electronic Health Records</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15222</p>
  <p><b>作者</b>：Koyena Pal,  Seyed Ali Bahrainian,  Laura Mercurio,  Carsten Eickhoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming documents written, Hospital discharge documentation, discharge summaries, discharge summary, discharge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hospital discharge documentation is among the most essential, yet
time-consuming documents written by medical practitioners. The objective of
this study was to automatically generate hospital discharge summaries using
neural network summarization models. We studied various data preparation and
neural network training techniques that generate discharge summaries. Using
nursing notes and discharge summaries from the MIMIC-III dataset, we studied
the viability of the automatic generation of various sections of a discharge
summary using four state-of-the-art neural network summarization models (BART,
T5, Longformer and FLAN-T5). Our experiments indicated that training
environments including nursing notes as the source, and discrete sections of
the discharge summary as the target output (e.g. "History of Present Illness")
improve language model efficiency and text quality. According to our findings,
the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its
standard off-the-shelf version. We also found that fine-tuning the baseline
BART model with other setups caused different degrees of improvement (up to 80%
relative improvement). We also observed that a fine-tuned T5 generally achieves
higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5
achieves the highest ROUGE score overall, i.e., 45.6. For majority of the
fine-tuned language models, summarizing discharge summary report sections
separately outperformed the summarization the entire report quantitatively. On
the other hand, fine-tuning language models that were previously instruction
fine-tuned showed better performance in summarizing entire reports. This study
concludes that a focused dataset designed for the automatic generation of
discharge summaries by a language model can produce coherent Discharge Summary
sections.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Selection for short-term empowerment accelerates the evolution of  homeostatic neural cellular automata</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15220</p>
  <p><b>作者</b>：Caitlin Grasso,  Josh Bongard</p>
  <p><b>备注</b>：To be published in the Proceedings of the Genetic and Evolutionary Computation Conference 2023 (GECCO'23), 8 pages, 9 figures</p>
  <p><b>关键词</b>：neural cellular automata, information-theoretic metric, domain independent, cellular automata, fitness function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Empowerment -- a domain independent, information-theoretic metric -- has
previously been shown to assist in the evolutionary search for neural cellular
automata (NCA) capable of homeostasis when employed as a fitness function. In
our previous study, we successfully extended empowerment, defined as maximum
time-lagged mutual information between agents' actions and future sensations,
to a distributed sensorimotor system embodied as an NCA. However, the
time-delay between actions and their corresponding sensations was arbitrarily
chosen. Here, we expand upon previous work by exploring how the time scale at
which empowerment operates impacts its efficacy as an auxiliary objective to
accelerate the discovery of homeostatic NCAs. We show that shorter time delays
result in marked improvements over empowerment with longer delays, when
compared to evolutionary selection only for homeostasis. Moreover, we evaluate
stability and adaptability of evolved NCAs, both hallmarks of living systems
that are of interest to replicate in artificial ones. We find that short-term
empowered NCA are more stable and are capable of generalizing better to unseen
homeostatic challenges. Taken together, these findings motivate the use of
empowerment during the evolution of other artifacts, and suggest how it should
be incorporated to accelerate evolution of desired behaviors for them. Source
code for the experiments in this paper can be found at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Multi-modal Machine Learning for Vehicle Rating Predictions Using Image,  Text, and Parametric Data</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15218</p>
  <p><b>作者</b>：Hanqi Su,  Binyang Song,  Faez Ahmed</p>
  <p><b>备注</b>：The paper submitted to IDETC/CIE2023, the International Design Engineering Technical Conferences & Computers and Information in Engineering Conference, has been accepted</p>
  <p><b>关键词</b>：configuring good vehicles, facilitate designing, designing and configuring, configuring good, Accurate vehicle rating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate vehicle rating prediction can facilitate designing and configuring
good vehicles. This prediction allows vehicle designers and manufacturers to
optimize and improve their designs in a timely manner, enhance their product
performance, and effectively attract consumers. However, most of the existing
data-driven methods rely on data from a single mode, e.g., text, image, or
parametric data, which results in a limited and incomplete exploration of the
available information. These methods lack comprehensive analyses and
exploration of data from multiple modes, which probably leads to inaccurate
conclusions and hinders progress in this field. To overcome this limitation, we
propose a multi-modal learning model for more comprehensive and accurate
vehicle rating predictions. Specifically, the model simultaneously learns
features from the parametric specifications, text descriptions, and images of
vehicles to predict five vehicle rating scores, including the total score,
critics score, performance score, safety score, and interior score. We compare
the multi-modal learning model to the corresponding unimodal models and find
that the multi-modal model's explanatory power is 4% - 12% higher than that of
the unimodal models. On this basis, we conduct sensitivity analyses using SHAP
to interpret our model and provide design and optimization directions to
designers and manufacturers. Our study underscores the importance of the
data-driven multi-modal learning approach for vehicle design, evaluation, and
optimization. We have made the code publicly available at
this http URL.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：L-CAD: Language-based Colorization with Any-level Descriptions</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15217</p>
  <p><b>作者</b>：Zheng Chang,  Shuchen Weng,  Peixuan Zhang,  Yu Li,  Si Li,  Boxin Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visually pleasing colors, user-friendly natural language, colorization produces plausible, produces plausible, plausible and visually</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language-based colorization produces plausible and visually pleasing colors
under the guidance of user-friendly natural language descriptions. Previous
methods implicitly assume that users provide comprehensive color descriptions
for most of the objects in the image, which leads to suboptimal performance. In
this paper, we propose a unified model to perform language-based colorization
with any-level descriptions. We leverage the pretrained cross-modality
generative model for its robust language understanding and rich color priors to
handle the inherent ambiguity of any-level descriptions. We further design
modules to align with input conditions to preserve local spatial structures and
prevent the ghosting effect. With the proposed novel sampling strategy, our
model achieves instance-aware colorization in diverse and complex scenarios.
Extensive experimental results demonstrate our advantages of effectively
handling any-level descriptions and outperforming both language-based and
automatic colorization methods. The code and pretrained models are available
at: this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Relating Implicit Bias and Adversarial Attacks through Intrinsic  Dimension</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15203</p>
  <p><b>作者</b>：Lorenzo Basile,  Nikos Karantzas,  Alberto D'Onofrio,  Luca Bortolussi,  Alex Rodriguez,  Fabio Anselmi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impressive performance, adversarial attacks, attacks, implicit bias, input data designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite their impressive performance in classification, neural networks are
known to be vulnerable to adversarial attacks. These attacks are small
perturbations of the input data designed to fool the model. Naturally, a
question arises regarding the potential connection between the architecture,
settings, or properties of the model and the nature of the attack. In this
work, we aim to shed light on this problem by focusing on the implicit bias of
the neural network, which refers to its inherent inclination to favor specific
patterns or outcomes. Specifically, we investigate one aspect of the implicit
bias, which involves the essential Fourier frequencies required for accurate
image classification. We conduct tests to assess the statistical relationship
between these frequencies and those necessary for a successful attack. To delve
into this relationship, we propose a new method that can uncover non-linear
correlations between sets of coordinates, which, in our case, are the
aforementioned frequencies. By exploiting the entanglement between intrinsic
dimension and correlation, we provide empirical evidence that the network bias
in Fourier space and the target frequencies of adversarial attacks are closely
tied.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Feature-aligned N-BEATS with Sinkhorn divergence</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15196</p>
  <p><b>作者</b>：Myeongho Jeon,  Myungjoo Kang,  Joonhun Lee,  Kyunghyun Park</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose Feature-aligned N-BEATS, univariate time series, propose Feature-aligned, series forecasting problems, time series forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we propose Feature-aligned N-BEATS as a domain generalization
model for univariate time series forecasting problems. The proposed model is an
extension of the doubly residual stacking architecture of N-BEATS (Oreshkin et
al. [34]) into a representation learning framework. The model is a new
structure that involves marginal feature probability measures (i.e.,
pushforward measures of multiple source domains) induced by the intricate
composition of residual operators of N-BEATS in each stack and aligns them
stack-wise via an entropic regularized Wasserstein distance referred to as the
Sinkhorn divergence (Genevay et al. [14]). The loss function consists of a
typical forecasting loss for multiple source domains and an alignment loss
calculated with the Sinkhorn divergence, which allows the model to learn
invariant features stack-wise across multiple source data sequences while
retaining N-BEATS's interpretable design. We conduct a comprehensive
experimental evaluation of the proposed approach and the results demonstrate
the model's forecasting and generalization capabilities in comparison with
methods based on the original N-BEATS.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion  Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15194</p>
  <p><b>作者</b>：Sungnyun Kim,  Junsoo Lee,  Kibeom Hong,  Daesik Kim,  Namhyuk Ahn</p>
  <p><b>备注</b>：18 pages, 16 figures, and 3 tables</p>
  <p><b>关键词</b>：significantly expanded generative, expanded generative capabilities, progress in diffusion-based, recent progress, significantly expanded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent progress in diffusion-based text-to-image generation models has
significantly expanded generative capabilities via conditioning the text
descriptions. However, since relying solely on text prompts is still
restrictive for fine-grained customization, we aim to extend the boundaries of
conditional generation to incorporate diverse types of modalities, e.g.,
sketch, box, and style embedding, simultaneously. We thus design a multimodal
text-to-image diffusion model, coined as DiffBlender, that achieves the
aforementioned goal in a single model by training only a few small
hypernetworks. DiffBlender facilitates a convenient scaling of input
modalities, without altering the parameters of an existing large-scale
generative model to retain its well-established knowledge. Furthermore, our
study sets new standards for multimodal generation by conducting quantitative
and qualitative comparisons with existing approaches. By diversifying the
channels of conditioning modalities, DiffBlender faithfully reflects the
provided information or, in its absence, creates imaginative generation.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Using Models Based on Cognitive Theory to Predict Human Behavior in  Traffic: A Case Study</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15187</p>
  <p><b>作者</b>：Julian F. Schumann,  Aravinda Ramakrishnan Srinivasan,  Jens Kober,  Gustav Markkula,  Arkady Zgonnikov</p>
  <p><b>备注</b>：6 pages, 2 figures</p>
  <p><b>关键词</b>：time-efficient driving style, revolutionize transportation, driving style, potential to revolutionize, unable to ensure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of automated vehicles has the potential to revolutionize
transportation, but they are currently unable to ensure a safe and
time-efficient driving style. Reliable models predicting human behavior are
essential for overcoming this issue. While data-driven models are commonly used
to this end, they can be vulnerable in safety-critical edge cases. This has led
to an interest in models incorporating cognitive theory, but as such models are
commonly developed for explanatory purposes, this approach's effectiveness in
behavior prediction has remained largely untested so far. In this article, we
investigate the usefulness of the \emph{Commotions} model -- a novel
cognitively plausible model incorporating the latest theories of human
perception, decision-making, and motor control -- for predicting human behavior
in gap acceptance scenarios, which entail many important traffic interactions
such as lane changes and intersections. We show that this model can compete
with or even outperform well-established data-driven prediction models across
several naturalistic datasets. These results demonstrate the promise of
incorporating cognitive theory in behavior prediction models for automated
vehicles.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：SciReviewGen: A Large-scale Dataset for Automatic Literature Review  Generation</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15186</p>
  <p><b>作者</b>：Tetsu Kasanishi,  Masaru Isonuma,  Junichiro Mori,  Ichiro Sakata</p>
  <p><b>备注</b>：ACL findings 2023 (to be appeared). arXiv admin note: text overlap with arXiv:1810.04020 by other authors</p>
  <p><b>关键词</b>：literature review generation, natural language processing, literature review, review generation, Automatic literature review</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic literature review generation is one of the most challenging tasks
in natural language processing. Although large language models have tackled
literature review generation, the absence of large-scale datasets has been a
stumbling block to the progress. We release SciReviewGen, consisting of over
10,000 literature reviews and 690,000 papers cited in the reviews. Based on the
dataset, we evaluate recent transformer-based summarization models on the
literature review generation task, including Fusion-in-Decoder extended for
literature review generation. Human evaluation results show that some
machine-generated summaries are comparable to human-written reviews, while
revealing the challenges of automatic literature review generation such as
hallucinations and a lack of detailed information. Our dataset and code are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Personalized DP-SGD using Sampling Mechanisms</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15165</p>
  <p><b>作者</b>：Geon Heo,  Junseok Seo,  Steven Euijong Whang</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：Stochastic Gradient Descent, Differentially Private Stochastic, Private Stochastic Gradient, privacy, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized privacy becomes critical in deep learning for Trustworthy AI.
While Differentially Private Stochastic Gradient Descent (DP-SGD) is widely
used in deep learning methods supporting privacy, it provides the same level of
privacy to all individuals, which may lead to overprotection and low utility.
In practice, different users may require different privacy levels, and the
model can be improved by using more information about the users with lower
privacy requirements. There are also recent works on differential privacy of
individuals when using DP-SGD, but they are mostly about individual privacy
accounting and do not focus on satisfying different privacy levels. We thus
extend DP-SGD to support a recent privacy notion called
($\Phi$,$\Delta$)-Personalized Differential Privacy (($\Phi$,$\Delta$)-PDP),
which extends an existing PDP concept called $\Phi$-PDP. Our algorithm uses a
multi-round personalized sampling mechanism and embeds it within the DP-SGD
iterations. Experiments on real datasets show that our algorithm outperforms
DP-SGD and simple combinations of DP-SGD with existing PDP mechanisms in terms
of model performance and efficiency due to its embedded sampling mechanism.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Reliability Scores from Saliency Map Clusters for Improved Image-based  Harvest-Readiness Prediction in Cauliflower</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15149</p>
  <p><b>作者</b>：Jana Kierdorf,  Ribana Roscher</p>
  <p><b>备注</b>：Preprint, 8 pages, 6 figures</p>
  <p><b>关键词</b>：fulfill high-quality standards, harvest important, hand-harvested crop, fulfill high-quality, high-quality standards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cauliflower is a hand-harvested crop that must fulfill high-quality standards
in sales making the timing of harvest important. However, accurately
determining harvest-readiness can be challenging due to the cauliflower head
being covered by its canopy. While deep learning enables automated
harvest-readiness estimation, errors can occur due to field-variability and
limited training data. In this paper, we analyze the reliability of a
harvest-readiness classifier with interpretable machine learning. By
identifying clusters of saliency maps, we derive reliability scores for each
classification result using knowledge about the domain and the image
properties. For unseen data, the reliability can be used to (i) inform farmers
to improve their decision-making and (ii) increase the model prediction
accuracy. Using RGB images of single cauliflower plants at different
developmental stages from the GrowliFlower dataset, we investigate various
saliency mapping approaches and find that they result in different quality of
reliability scores. With the most suitable interpretation tool, we adjust the
classification result and achieve a 15.72% improvement of the overall accuracy
to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for
the GrowliFlower dataset.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Theoretically Principled Federated Learning for Balancing Privacy and  Utility</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15148</p>
  <p><b>作者</b>：Xiaojin Zhang,  Wenjie Li,  Kai Chen,  Shutao Xia,  Qiang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general learning framework, distorting model parameters, propose a general, mechanisms that protects, protects privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a general learning framework for the protection mechanisms that
protects privacy via distorting model parameters, which facilitates the
trade-off between privacy and utility. The algorithm is applicable to arbitrary
privacy measurements that maps from the distortion to a real value. It can
achieve personalized utility-privacy trade-off for each model parameter, on
each client, at each communication round in federated learning. Such adaptive
and fine-grained protection can improve the effectiveness of privacy-preserved
federated learning.
Theoretically, we show that gap between the utility loss of the protection
hyperparameter output by our algorithm and that of the optimal protection
hyperparameter is sub-linear in the total number of iterations. The
sublinearity of our algorithm indicates that the average gap between the
performance of our algorithm and that of the optimal performance goes to zero
when the number of iterations goes to infinity. Further, we provide the
convergence rate of our proposed algorithm. We conduct empirical results on
benchmark datasets to verify that our method achieves better utility than the
baseline methods under the same privacy budget.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Topic-Guided Self-Introduction Generation for Social Media Users</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15138</p>
  <p><b>作者</b>：Chunpu Xu,  Jing Li,  Piji Li,  Min Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, social media self-introduction, personal interests, users, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Millions of users are active on social media. To allow users to better
showcase themselves and network with others, we explore the auto-generation of
social media self-introduction, a short sentence outlining a user's personal
interests. While most prior work profiles users with tags (e.g., ages), we
investigate sentence-level self-introductions to provide a more natural and
engaging way for users to know each other. Here we exploit a user's tweeting
history to generate their self-introduction. The task is non-trivial because
the history content may be lengthy, noisy, and exhibit various personal
interests. To address this challenge, we propose a novel unified topic-guided
encoder-decoder (UTGED) framework; it models latent topics to reflect salient
user interest, whose topic mixture then guides encoding a user's history and
topic words control decoding their self-introduction. For experiments, we
collect a large-scale Twitter dataset, and extensive results show the
superiority of our UTGED to the advanced encoder-decoder models without topic
modeling.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：On Degrees of Freedom in Defining and Testing Natural Language  Understanding</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15130</p>
  <p><b>作者</b>：Saku Sugawara,  Shun Tsugita</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：Natural language understanding, capabilities of systems, NLU, exaggerate or underestimate, underestimate the capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language understanding (NLU) studies often exaggerate or
underestimate the capabilities of systems, thereby limiting the reproducibility
of their findings. These erroneous evaluations can be attributed to the
difficulty of defining and testing NLU adequately. In this position paper, we
reconsider this challenge by identifying two types of researcher degrees of
freedom. We revisit Turing's original interpretation of the Turing test and
indicate that an NLU test does not provide an operational definition; it merely
provides inductive evidence that the test subject understands the language
sufficiently well to meet stakeholder objectives. In other words, stakeholders
are free to arbitrarily define NLU through their objectives. To use the test
results as inductive evidence, stakeholders must carefully assess if the
interpretation of test scores is valid or not. However, designing and using NLU
tests involve other degrees of freedom, such as specifying target skills and
defining evaluation metrics. As a result, achieving consensus among
stakeholders becomes difficult. To resolve this issue, we propose a validity
argument, which is a framework comprising a series of validation criteria
across test components. By demonstrating that current practices in NLU studies
can be associated with those criteria and organizing them into a comprehensive
checklist, we prove that the validity argument can serve as a coherent
guideline for designing credible test sets and facilitating scientific
communication.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：A Mini Review on the utilization of Reinforcement Learning with OPC UA</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15113</p>
  <p><b>作者</b>：Simon Schindler,  Martin Uray,  Stefan Huber</p>
  <p><b>备注</b>：submitted to INDIN'23</p>
  <p><b>关键词</b>：powerful machine learning, machine learning paradigm, game playing achieving, natural language processing, Reinforcement Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning (RL) is a powerful machine learning paradigm that has
been applied in various fields such as robotics, natural language processing
and game playing achieving state-of-the-art results. Targeted to solve
sequential decision making problems, it is by design able to learn from
experience and therefore adapt to changing dynamic environments. These
capabilities make it a prime candidate for controlling and optimizing complex
processes in industry. The key to fully exploiting this potential is the
seamless integration of RL into existing industrial systems. The industrial
communication standard Open Platform Communications UnifiedArchitecture (OPC
UA) could bridge this gap. However, since RL and OPC UA are from different
fields,there is a need for researchers to bridge the gap between the two
technologies. This work serves to bridge this gap by providing a brief
technical overview of both technologies and carrying out a semi-exhaustive
literature review to gain insights on how RL and OPC UA are applied in
combination. With this survey, three main research topics have been identified,
following the intersection of RL with OPC UA. The results of the literature
review show that RL is a promising technology for the control and optimization
of industrial processes, but does not yet have the necessary standardized
interfaces to be deployed in real-world scenarios with reasonably low effort.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Guessing Winning Policies in LTL Synthesis by Semantic Learning</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15109</p>
  <p><b>作者</b>：Jan Kretinsky,  Tobias Meggendorfer,  Maximilian Prokop,  Sabine Rieder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：LTL synthesis problem, parity game originating, LTL synthesis, rigorous LTL synthesis, provide a learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide a learning-based technique for guessing a winning strategy in a
parity game originating from an LTL synthesis problem. A cheaply obtained guess
can be useful in several applications. Not only can the guessed strategy be
applied as best-effort in cases where the game's huge size prohibits rigorous
approaches, but it can also increase the scalability of rigorous LTL synthesis
in several ways. Firstly, checking whether a guessed strategy is winning is
easier than constructing one. Secondly, even if the guess is wrong in some
places, it can be fixed by strategy iteration faster than constructing one from
scratch. Thirdly, the guess can be used in on-the-fly approaches to prioritize
exploration in the most fruitful directions.
In contrast to previous works, we (i)~reflect the highly structured logical
information in game's states, the so-called semantic labelling, coming from the
recent LTL-to-automata translations, and (ii)~learn to reflect it properly by
learning from previously solved games, bringing the solving process closer to
human-like reasoning.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Computer Vision for Construction Progress Monitoring: A Real-Time Object  Detection Approach</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15097</p>
  <p><b>作者</b>：Jiesheng Yang,  Andreas Wilde,  Karsten Menzel,  Md Zubair Sheikh,  Boris Kuznetsov</p>
  <p><b>备注</b>：15 Pages</p>
  <p><b>关键词</b>：effective project management, ensuring on-time, on-budget delivery, essential for effective, on-time and on-budget</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Construction progress monitoring (CPM) is essential for effective project
management, ensuring on-time and on-budget delivery. Traditional CPM methods
often rely on manual inspection and reporting, which are time-consuming and
prone to errors. This paper proposes a novel approach for automated CPM using
state-of-the-art object detection algorithms. The proposed method leverages
e.g. YOLOv8's real-time capabilities and high accuracy to identify and track
construction elements within site images and videos. A dataset was created,
consisting of various building elements and annotated with relevant objects for
training and validation. The performance of the proposed approach was evaluated
using standard metrics, such as precision, recall, and F1-score, demonstrating
significant improvement over existing methods. The integration of Computer
Vision into CPM provides stakeholders with reliable, efficient, and
cost-effective means to monitor project progress, facilitating timely
decision-making and ultimately contributing to the successful completion of
construction projects.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Dynamic Masking Rate Schedules for MLM Pretraining</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15096</p>
  <p><b>作者</b>：Zachary Ankner,  Naomi Saphra,  Davis Blalock,  Jonathan Frankle,  Matthew L. Leavitt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Masked Language Modeling, original BERT model, original BERT, BERT model fixed, Language Modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most works on transformers trained with the Masked Language Modeling (MLM)
objective use the original BERT model's fixed masking rate of 15%. Our work
instead dynamically schedules the masking ratio throughout training. We found
that linearly decreasing the masking rate from 30% to 15% over the course of
pretraining improves average GLUE accuracy by 0.46% in BERT-base, compared to a
standard 15% fixed rate. Further analyses demonstrate that the gains from
scheduling come from being exposed to both high and low masking rate regimes.
Our results demonstrate that masking rate scheduling is a simple way to improve
the quality of masked language models and achieve up to a 1.89x speedup in
pretraining.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：CSTS: Conditional Semantic Textual Similarity</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15093</p>
  <p><b>作者</b>：Ameet Deshpande,  Carlos E. Jimenez,  Howard Chen,  Vishvak Murahari,  Victoria Graf,  Tanmay Rajpurohit,  Ashwin Kalyan,  Danqi Chen,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：question answering, information retrieval, embedding methods, applications in information, Semantic textual similarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic textual similarity (STS) has been a cornerstone task in NLP that
measures the degree of similarity between a pair of sentences, with
applications in information retrieval, question answering, and embedding
methods. However, it is an inherently ambiguous task, with the sentence
similarity depending on the specific aspect of interest. We resolve this
ambiguity by proposing a novel task called conditional STS (C-STS) which
measures similarity conditioned on an aspect elucidated in natural language
(hereon, condition). As an example, the similarity between the sentences "The
NBA player shoots a three-pointer." and "A man throws a tennis ball into the
air to serve." is higher for the condition "The motion of the ball." (both
upward) and lower for "The size of the ball." (one large and one small).
C-STS's advantages are two-fold: (1) it reduces the subjectivity and ambiguity
of STS, and (2) enables fine-grained similarity evaluation using diverse
conditions. C-STS contains almost 20,000 instances from diverse domains and we
evaluate several state-of-the-art models to demonstrate that even the most
performant fine-tuning and in-context learning models (GPT-4, Flan, SimCSE)
find it challenging, with Spearman correlation scores of <50. we encourage the community to evaluate their models on c-sts provide a more holistic view of semantic similarity and natural language understanding.< p>
  </50.></p></details>
</details>
<details>
  <summary>44. <b>标题：STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data  Generation with Large Language Models</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15090</p>
  <p><b>作者</b>：Mingyu Derek Ma,  Xiaoxuan Wang,  Po-Nien Kung,  P. Jeffrey Brantingham,  Nanyun Peng,  Wei Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtain reasonable performance, low-resource event extraction, Structure prediction tasks, sub-task dependencies, event extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structure prediction tasks such as event extraction require an in-depth
understanding of the output structure and sub-task dependencies, thus they
still heavily rely on task-specific training data to obtain reasonable
performance. Due to the high cost of human annotation, low-resource event
extraction, which requires minimal human cost, is urgently needed in real-world
information extraction applications. We propose to synthesize data instances
given limited seed demonstrations to boost low-resource event extraction
performance. We propose STAR, a structure-to-text data generation method that
first generates complicated event structures (Y) and then generates input
passages (X), all with Large Language Models. We design fine-grained
step-by-step instructions and the error cases and quality issues identified
through self-reflection can be self-refined. Our experiments indicate that data
generated by STAR can significantly improve the low-resource event extraction
performance and they are even more effective than human-curated data points in
some cases.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Unpaired Image-to-Image Translation via Neural Schrödinger Bridge</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15086</p>
  <p><b>作者</b>：Beomsu Kim,  Gihyun Kwon,  Kwanyoung Kim,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic differential equations, simulate stochastic differential, differential equations, powerful class, class of generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models are a powerful class of generative models which simulate
stochastic differential equations (SDEs) to generate data from noise. Although
diffusion models have achieved remarkable progress in recent years, they have
limitations in the unpaired image-to-image translation tasks due to the
Gaussian prior assumption. Schrödinger Bridge (SB), which learns an SDE to
translate between two arbitrary distributions, have risen as an attractive
solution to this problem. However, none of SB models so far have been
successful at unpaired translation between high-resolution images. In this
work, we propose the Unpaired Neural Schrödinger Bridge (UNSB), which
combines SB with adversarial training and regularization to learn a SB between
unpaired data. We demonstrate that UNSB is scalable, and that it successfully
solves various unpaired image-to-image translation tasks. Code:
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Cream: Visually-Situated Natural Language Understanding with Contrastive  Reading Model and Frozen Large Language Models</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15080</p>
  <p><b>作者</b>：Geewook Kim,  Hodong Lee,  Daehee Kim,  Haeji Jung,  Sanghee Park,  Yoonsik Kim,  Sangdoo Yun,  Taeho Kil,  Bado Lee,  Seunghyun Park</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Advances in Large, Large Language, inspired a surge, surge of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advances in Large Language Models (LLMs) have inspired a surge of research
exploring their expansion into the visual domain. While recent models exhibit
promise in generating abstract captions for images and conducting natural
conversations, their performance on text-rich images leaves room for
improvement. In this paper, we propose the Contrastive Reading Model (Cream), a
novel neural architecture designed to enhance the language-image understanding
capability of LLMs by capturing intricate details typically overlooked by
existing methods. Cream integrates vision and auxiliary encoders, complemented
by a contrastive feature alignment technique, resulting in a more effective
understanding of textual information within document images. Our approach,
thus, seeks to bridge the gap between vision and language understanding, paving
the way for more sophisticated Document Intelligence Assistants. Rigorous
evaluations across diverse tasks, such as visual question answering on document
images, demonstrate the efficacy of Cream as a state-of-the-art model in the
field of visual document understanding. We provide our codebase and
newly-generated datasets at this https URL</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：HuatuoGPT, towards Taming Language Model to Be a Doctor</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15075</p>
  <p><b>作者</b>：Hongbo Zhang,  Junying Chen,  Feng Jiang,  Fei Yu,  Zhihong Chen,  Jianquan Li,  Guiming Chen,  Xiangbo Wu,  Zhiyi Zhang,  Qingying Xiao,  Xiang Wan,  Benyou Wang,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data, language model, large language model, distilled language model, real-world data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present HuatuoGPT, a large language model (LLM) for medical
consultation. The core recipe of HuatuoGPT is to leverage both
\textit{distilled data from ChatGPT} and \textit{real-world data from doctors}
in the supervised fine-tuned stage. The responses of ChatGPT are usually
detailed, well-presented and informative while it cannot perform like a doctor
in many aspects, e.g. for integrative diagnosis. We argue that real-world data
from doctors would be complementary to distilled data in the sense the former
could tame a distilled language model to perform like doctors. To better
leverage the strengths of both data, we train a reward model to align the
language model with the merits that both data bring, following an RLAIF
(reinforced learning from AI feedback) fashion. To evaluate and benchmark the
models, we propose a comprehensive evaluation scheme (including automatic and
manual metrics). Experimental results demonstrate that HuatuoGPT achieves
state-of-the-art results in performing medical consultation among open-source
LLMs in GPT-4 evaluation, human evaluation, and medical benchmark datasets. It
is worth noting that by using additional real-world data and RLAIF, the
distilled language model (i.e., HuatuoGPT) outperforms its teacher model
ChatGPT in most cases. Our code, data, and models are publicly available at
\url{this https URL}. The online demo is
available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For  Large Language Models</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15074</p>
  <p><b>作者</b>：Daman Arora,  Himanshu Gaurav Singh,  Mausam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, past years, existing reasoning benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance on Large Language Models (LLMs) on existing reasoning
benchmarks has shot up considerably over the past years. In response, we
present JEEBench, a considerably more challenging benchmark dataset for
evaluating the problem solving abilities of LLMs. We curate 450 challenging
pre-engineering mathematics, physics and chemistry problems from the IIT
JEE-Advanced exam. Long-horizon reasoning on top of deep in-domain knowledge is
essential for solving problems in this benchmark. Our evaluation on the GPT
series of models reveals that although performance improves with newer models,
the best being GPT-4, the highest performance, even after using techniques like
Self-Consistency and Chain-of-Thought prompting is less than 40 percent. Our
analysis demonstrates that errors in algebraic manipulation and failure in
retrieving relevant domain specific concepts are primary contributors to GPT4's
low performance. Given the challenging nature of the benchmark, we hope that it
can guide future research in problem solving using LLMs. Our code and dataset
is available here.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks  for Exploring Theory of Mind</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15068</p>
  <p><b>作者</b>：Xiaomeng Ma,  Lingyu Gao,  Qihui Xu</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：numerous practical applications, Theory of Mind, distinct individuals, practical applications, capacity to comprehend</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Theory of Mind (ToM), the capacity to comprehend the mental states of
distinct individuals, is essential for numerous practical applications. With
the development of large language models, there is a heated debate about
whether they are able to perform ToM tasks. Previous studies have used
different tasks and prompts to test the ToM on large language models and the
results are inconsistent: some studies asserted these models are capable of
exhibiting ToM, while others suggest the opposite. In this study, We present
ToMChallenges, a dataset for comprehensively evaluating Theory of Mind based on
Sally-Anne and Smarties tests. We created 30 variations of each test (e.g.,
changing the person's name, location, and items). For each variation, we test
the model's understanding of different aspects: reality, belief, 1st order
belief, and 2nd order belief. We adapt our data for various tasks by creating
unique prompts tailored for each task category: Fill-in-the-Blank, Multiple
Choice, True/False, Chain-of-Thought True/False, Question Answering, and Text
Completion. If the model has a robust ToM, it should be able to achieve good
performance for different prompts across different tests. We evaluated two
GPT-3.5 models, text-davinci-003 and gpt-3.5-turbo-0301, with our datasets. Our
results indicate that consistent performance in ToM tasks remains a challenge.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：GPT4Graph: Can Large Language Models Understand Graph Structured Data ?  An Empirical Evaluation and Benchmarking</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15066</p>
  <p><b>作者</b>：Jiayan Guo,  Lun Du,  Hengyu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial general intelligence, demonstrating excellent performance, general intelligence, demonstrating excellent, indispensable to artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models~(LLM) like ChatGPT have become indispensable to
artificial general intelligence~(AGI), demonstrating excellent performance in
various natural language processing tasks. In the real world, graph data is
ubiquitous and an essential part of AGI and prevails in domains like social
network analysis, bioinformatics and recommender systems. The training corpus
of large language models often includes some algorithmic components, which
allows them to achieve certain effects on some graph data-related problems.
However, there is still little research on their performance on a broader range
of graph-structured data. In this study, we conduct an extensive investigation
to assess the proficiency of LLMs in comprehending graph data, employing a
diverse range of structural and semantic-related tasks. Our analysis
encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph
understanding. Through our study, we not only uncover the current limitations
of language models in comprehending graph structures and performing associated
reasoning tasks but also emphasize the necessity for further advancements and
novel approaches to enhance their graph processing capabilities. Our findings
contribute valuable insights towards bridging the gap between language models
and graph understanding, paving the way for more effective graph mining and
knowledge extraction.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Lawyer LLaMA Technical Report</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15062</p>
  <p><b>作者</b>：Quzhe Huang,  Mingxu Tao,  Zhenwei An,  Chen Zhang,  Cong Jiang,  Zhibin Chen,  Zirui Wu,  Yansong Feng</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：Large Language Models, exhibited remarkable performances, Large Language, Language Models, exhibited remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs), like LLaMA, have exhibited remarkable
performances across various tasks. Nevertheless, when deployed to specific
domains such as law or medicine, the models still confront the challenge of a
deficiency in domain-specific knowledge and an inadequate capability to
leverage that knowledge to resolve domain-related problems. In this paper, we
focus on the legal domain and explore how to inject domain knowledge during the
continual training stage and how to design proper supervised finetune tasks to
help the model tackle practical issues. Moreover, to alleviate the
hallucination problem during model's generation, we add a retrieval module and
extract relevant articles before the model answers any queries. Augmenting with
the extracted evidence, our model could generate more reliable responses. We
release our data and model at this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Iteratively Improving Speech Recognition and Voice Conversion</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15055</p>
  <p><b>作者</b>：Mayank Kumar Singh,  Naoya Takahashi,  Onoe Naoyuki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ensuring linguistic consistency, ASR, automatic speech recognition, ASR model, voice conversion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many existing works on voice conversion (VC) tasks use automatic speech
recognition (ASR) models for ensuring linguistic consistency between source and
converted samples. However, for the low-data resource domains, training a
high-quality ASR remains to be a challenging task. In this work, we propose a
novel iterative way of improving both the ASR and VC models. We first train an
ASR model which is used to ensure content preservation while training a VC
model. In the next iteration, the VC model is used as a data augmentation
method to further fine-tune the ASR model and generalize it to diverse
speakers. By iteratively leveraging the improved ASR model to train VC model
and vice-versa, we experimentally show improvement in both the models. Our
proposed framework outperforms the ASR and one-shot VC baseline models on
English singing and Hindi speech domains in subjective and objective
evaluations in low-data resource settings.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Ghostbuster: Detecting Text Ghostwritten by Large Language Models</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15047</p>
  <p><b>作者</b>：Vivek Verma,  Eve Fleisig,  Nicholas Tomlin,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：system for detecting, introduce Ghostbuster, AI-generated, detection, Ghostbuster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Ghostbuster, a state-of-the-art system for detecting
AI-generated text. Our method works by passing documents through a series of
weaker language models and running a structured search over possible
combinations of their features, then training a classifier on the selected
features to determine if the target document was AI-generated. Crucially,
Ghostbuster does not require access to token probabilities from the target
model, making it useful for detecting text generated by black-box models or
unknown model versions. In conjunction with our model, we release three new
datasets of human and AI-generated text as detection benchmarks that cover
multiple domains (student essays, creative fiction, and news) and task setups:
document-level detection, author identification, and a challenge task of
paragraph-level detection. Ghostbuster averages 99.1 F1 across all three
datasets on document-level detection, outperforming previous approaches such as
GPTZero and DetectGPT by up to 32.7 F1.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：How to Distill your BERT: An Empirical Study on the Impact of Weight  Initialisation and Distillation Objectives</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15032</p>
  <p><b>作者</b>：Xinpeng Wang,  Leonie Weissweiler,  Hinrich Schütze,  Barbara Plank</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：compression of BERT, BERT models, shown to improve, improve compression, intermediate layer distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, various intermediate layer distillation (ILD) objectives have been
shown to improve compression of BERT models via Knowledge Distillation (KD).
However, a comprehensive evaluation of the objectives in both task-specific and
task-agnostic settings is lacking. To the best of our knowledge, this is the
first work comprehensively evaluating distillation objectives in both settings.
We show that attention transfer gives the best performance overall. We also
study the impact of layer choice when initializing the student from the teacher
layers, finding a significant impact on the performance in task-specific
distillation. For vanilla KD and hidden states transfer, initialisation with
lower layers of the teacher gives a considerable improvement over higher
layers, especially on the task of QNLI (up to an absolute percentage change of
17.8 in accuracy). Attention transfer behaves consistently under different
initialisation settings. We release our code as an efficient transformer-based
model distillation framework for further studies.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet  Categories</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15028</p>
  <p><b>作者</b>：Heming Xia,  Qingxiu Dong,  Lei Li,  Jingjing Xu,  Ziwei Qin,  Zhifang Sui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual commonsense knowledge, Pretrained Language Models, Pretrained Language, commonsense knowledge, visual commonsense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Pretrained Language Models (PLMs) have been serving as
general-purpose interfaces, posing a significant demand for comprehensive
visual knowledge. However, it remains unclear how well current PLMs and their
visually augmented counterparts (VaLMs) can master visual commonsense
knowledge. To investigate this, we propose ImageNetVC, a fine-grained,
human-annotated dataset specifically designed for zero-shot visual commonsense
evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we delve
into the fundamental visual commonsense knowledge of both unimodal PLMs and
VaLMs, uncovering the scaling law and the influence of the backbone model on
VaLMs. Furthermore, we investigate the factors affecting the visual commonsense
knowledge of large-scale models, providing insights into the development of
language models enriched with visual commonsense knowledge. Our code and
dataset are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Transferring Visual Attributes from Natural Language to Verified Image  Generation</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15026</p>
  <p><b>作者</b>：Rodrigo Valerio,  Joao Bordalo,  Michal Yarom,  Yonattan Bitton,  Idan Szpektor,  Joao Magalhaes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image generation, widely popular, popular in generating, image, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text to image generation methods (T2I) are widely popular in generating art
and other creative artifacts. While visual hallucinations can be a positive
factor in scenarios where creativity is appreciated, such artifacts are poorly
suited for cases where the generated image needs to be grounded in complex
natural language without explicit visual elements. In this paper, we propose to
strengthen the consistency property of T2I methods in the presence of natural
complex language, which often breaks the limits of T2I methods by including
non-visual information, and textual elements that require knowledge for
accurate generation. To address these phenomena, we propose a Natural Language
to Verified Image generation approach (NL2VI) that converts a natural prompt
into a visual prompt, which is more suitable for image generation. A T2I model
then generates an image for the visual prompt, which is then verified with VQA
algorithms. Experimentally, aligning natural prompts with image generation can
improve the consistency of the generated images by up to 11% over the state of
the art. Moreover, improvements can generalize to challenging domains like
cooking and DIY tasks, where the correctness of the generated image is crucial
to illustrate actions.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic  Agricultural Text Classification</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15024</p>
  <p><b>作者</b>：Biao Zhao,  Weiqiang Jin,  Javier Del Ser,  Guang Yang</p>
  <p><b>备注</b>：24 pages,10+figures,46references.Both the first two authors, Biao Zhao and Weiqiang Jin, made equal contributions to this work. Corresponding author: Guang Yang</p>
  <p><b>关键词</b>：sustainable smart agriculture, massive agricultural knowledge, massive amount, smart agriculture, era of sustainable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of sustainable smart agriculture, a massive amount of agricultural
news text is being posted on the Internet, in which massive agricultural
knowledge has been accumulated. In this context, it is urgent to explore
effective text classification techniques for users to access the required
agricultural knowledge with high efficiency. Mainstream deep learning
approaches employing fine-tuning strategies on pre-trained language models
(PLMs), have demonstrated remarkable performance gains over the past few years.
Nonetheless, these methods still face many drawbacks that are complex to solve,
including: 1. Limited agricultural training data due to the expensive-cost and
labour-intensive annotation; 2. Poor domain transferability, especially of
cross-linguistic ability; 3. Complex and expensive large models
deployment.Inspired by the extraordinary success brought by the recent ChatGPT
(e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore
the capability and utilization of ChatGPT applying to the agricultural
informatization field. ....(shown in article).... Code has been released on
Github
this https URL.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15021</p>
  <p><b>作者</b>：Yao Mu,  Qinglong Zhang,  Mengkang Hu,  Wenhai Wang,  Mingyu Ding,  Jun Jin,  Bin Wang,  Jifeng Dai,  Yu Qiao,  Ping Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：executing action sequences, accomplish long-horizon tasks, frontier in robotics, physical environments, Embodied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied AI is a crucial frontier in robotics, capable of planning and
executing action sequences for robots to accomplish long-horizon tasks in
physical environments. In this work, we introduce EmbodiedGPT, an end-to-end
multi-modal foundation model for embodied AI, empowering embodied agents with
multi-modal understanding and execution capabilities. To achieve this, we have
made the following efforts: (i) We craft a large-scale embodied planning
dataset, termed EgoCOT. The dataset consists of carefully selected videos from
the Ego4D dataset, along with corresponding high-quality language instructions.
Specifically, we generate a sequence of sub-goals with the "Chain of Thoughts"
mode for effective embodied planning. (ii) We introduce an efficient training
approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B
large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We
introduce a paradigm for extracting task-related features from LLM-generated
planning queries to form a closed loop between high-level planning and
low-level control. Extensive experiments show the effectiveness of EmbodiedGPT
on embodied tasks, including embodied planning, embodied control, visual
captioning, and visual question answering. Notably, EmbodiedGPT significantly
enhances the success rate of the embodied control task by extracting more
effective features. It has achieved a remarkable 1.6 times increase in success
rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World
benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Calc-X: Enriching Arithmetical Chain-of-Thoughts Datasets by Interaction  with Symbolic Systems</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15017</p>
  <p><b>作者</b>：Marek Kadlčík,  Michal Štefánik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work in enriching, non-parametric components, requiring arithmetical reasoning, report overviews, overviews our ongoing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report overviews our ongoing work in enriching chain-of-thoughts
datasets requiring arithmetical reasoning with the integration of
non-parametric components, such as a calculator. We conduct an analysis of
prominent relevant datasets such as GSM8K, Ape210K, AQuA-RAT, and MathQA and
propose a machine-processable HTML-like format specifically tailored for
working with semi-structured chains. By converting the datasets into this
unified format, we enable the effective integration of large language models
and symbolic systems, empowering them to tackle arithmetical reasoning tasks
more efficiently.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation  into Input Regurgitation and Prompt-Induced Sanitization</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15008</p>
  <p><b>作者</b>：Aman Priyanshu,  Supriti Vijay,  Ayush Kumar,  Rakshit Naidu,  Fatemehsadat Mireshghallah</p>
  <p><b>备注</b>：12 pages, 9 figures, and 4 tables</p>
  <p><b>关键词</b>：industry hiring decisions, industry hiring, hiring decisions, personal assistants, widely adopted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LLM-powered chatbots are becoming widely adopted in applications such as
healthcare, personal assistants, industry hiring decisions, etc. In many of
these cases, chatbots are fed sensitive, personal information in their prompts,
as samples for in-context learning, retrieved records from a database, or as
part of the conversation. The information provided in the prompt could directly
appear in the output, which might have privacy ramifications if there is
sensitive information there. As such, in this paper, we aim to understand the
input copying and regurgitation capabilities of these models during inference
and how they can be directly instructed to limit this copying by complying with
regulations such as HIPAA and GDPR, based on their internal knowledge of them.
More specifically, we find that when ChatGPT is prompted to summarize cover
letters of a 100 candidates, it would retain personally identifiable
information (PII) verbatim in 57.4% of cases, and we find this retention to be
non-uniform between different subgroups of people, based on attributes such as
gender identity. We then probe ChatGPT's perception of privacy-related policies
and privatization mechanisms by directly instructing it to provide compliant
outputs and observe a significant omission of PII from output.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：A Human-in-the-Loop Approach for Information Extraction from Privacy  Policies under Data Scarcity</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15006</p>
  <p><b>作者</b>：Michael Gebauer,  Faraz Mashhur,  Nicola Leschke,  Elias Grünewald,  Frank Pallas</p>
  <p><b>备注</b>：Accepted for 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&P)</p>
  <p><b>关键词</b>：transparency-enhancing technologies, privacy policies, door openers, broad variety, privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine-readable representations of privacy policies are door openers for a
broad variety of novel privacy-enhancing and, in particular,
transparency-enhancing technologies (TETs). In order to generate such
representations, transparency information needs to be extracted from written
privacy policies. However, respective manual annotation and extraction
processes are laborious and require expert knowledge. Approaches for fully
automated annotation, in turn, have so far not succeeded due to overly high
error rates in the specific domain of privacy policies. In the end, a lack of
properly annotated privacy policies and respective machine-readable
representations persists and enduringly hinders the development and
establishment of novel technical approaches fostering policy perception and
data subject informedness.
In this work, we present a prototype system for a `Human-in-the-Loop'
approach to privacy policy annotation that integrates ML-generated suggestions
and ultimately human annotation decisions. We propose an ML-based suggestion
system specifically tailored to the constraint of data scarcity prevalent in
the domain of privacy policy annotation. On this basis, we provide meaningful
predictions to users thereby streamlining the annotation process. Additionally,
we also evaluate our approach through a prototypical implementation to show
that our ML-based extraction approach provides superior performance over other
recently used extraction models for legal documents.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Contrastive Training of Complex-Valued Autoencoders for Object Discovery</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.15001</p>
  <p><b>作者</b>：Aleksandar Stanić,  Anand Gopalakrishnan,  Kazuki Irie,  Jürgen Schmidhuber</p>
  <p><b>备注</b>：26 pages, 14 figures</p>
  <p><b>关键词</b>：attention-based routing, object-centric models, slots, Synchrony-based models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current state-of-the-art object-centric models use slots and attention-based
routing for binding. However, this class of models has several conceptual
limitations: the number of slots is hardwired; all slots have equal capacity;
training has high computational cost; there are no object-level relational
factors within slots. Synchrony-based models in principle can address these
limitations by using complex-valued activations which store binding information
in their phase components. However, working examples of such synchrony-based
models have been developed only very recently, and are still limited to toy
grayscale datasets and simultaneous storage of less than three objects in
practice. Here we introduce architectural modifications and a novel contrastive
learning method that greatly improve the state-of-the-art synchrony-based
model. For the first time, we obtain a class of synchrony-based models capable
of discovering objects in an unsupervised manner in multi-object color datasets
and simultaneously representing more than three objects</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14998</p>
  <p><b>作者</b>：Saba Ahmadi,  Aishwarya Agrawal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：UMIC, Hessel, CLIPScore, human judgment, correlation with human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and
UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image
captions, demonstrating a high correlation with human judgment. In this work,
our focus lies in evaluating the robustness of these metrics in scenarios that
require distinguishing between two captions with high lexical overlap but very
different meanings. Our findings reveal that despite their high correlation
with human judgment, both CLIPScore and UMIC struggle to identify fine-grained
errors in captions. However, when comparing different types of fine-grained
errors, both metrics exhibit limited sensitivity to implausibility of captions
and strong sensitivity to lack of sufficient visual grounding. Probing further
into the visual grounding aspect, we found that both CLIPScore and UMIC are
impacted by the size of image-relevant objects mentioned in the caption, and
that CLIPScore is also sensitive to the number of mentions of image-relevant
objects in the caption. In terms of linguistic aspects of a caption, we found
that both metrics lack the ability to comprehend negation, UMIC is sensitive to
caption lengths, and CLIPScore is insensitive to the structure of the sentence.
We hope our findings will serve as a valuable guide towards improving
reference-free evaluation in image captioning.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Reasoning with Language Model is Planning with World Model</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14992</p>
  <p><b>作者</b>：Shibo Hao,  Yi Gu,  Haodi Ma,  Joshua Jiahua Hong,  Zhen Wang,  Daisy Zhe Wang,  Zhiting Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, remarkable reasoning capabilities, shown remarkable reasoning, reasoning, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable reasoning capabilities,
especially when prompted to generate intermediate reasoning steps (e.g.,
Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are
easy for humans, such as generating action plans for executing tasks in a given
environment, or performing complex math, logical, and commonsense reasoning.
The deficiency stems from the key fact that LLMs lack an internal
$\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment
status, intermediate variable values) and simulate long-term outcomes of
actions. This prevents LLMs from performing deliberate planning akin to human
brains, which involves exploring alternative reasoning paths, anticipating
future states and rewards, and iteratively refining existing reasoning steps.
To overcome the limitations, we propose a new LLM reasoning framework,
$\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$
$\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning
agent, and incorporates a principled planning algorithm (based on Monto Carlo
Tree Search) for strategic exploration in the vast reasoning space. During
reasoning, the LLM (as agent) incrementally builds a reasoning tree under the
guidance of the LLM (as world model) and task-specific rewards, and obtains a
high-reward reasoning path efficiently with a proper balance between
exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of
challenging reasoning problems including plan generation, math reasoning, and
logical inference. Empirical results on these tasks demonstrate the superiority
of RAP over various strong baselines, including CoT and least-to-most prompting
with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%
relative improvement in a plan generation setting.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：MuLER: Detailed and Scalable Reference-based Evaluation</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14991</p>
  <p><b>作者</b>：Taelin Karidi,  Leshem Choshen,  Gal Patel,  Omri Abend</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fine-grained analysis tool, text generation, machine translation, transforms any reference-based, reference-based evaluation metric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel methodology (namely, MuLER) that transforms any
reference-based evaluation metric for text generation, such as machine
translation (MT) into a fine-grained analysis tool.
Given a system and a metric, MuLER quantifies how much the chosen metric
penalizes specific error types (e.g., errors in translating names of
locations). MuLER thus enables a detailed error analysis which can lead to
targeted improvement efforts for specific phenomena.
We perform experiments in both synthetic and naturalistic settings to support
MuLER's validity and showcase its usability in MT evaluation, and other tasks,
such as summarization. Analyzing all submissions to WMT in 2014-2020, we find
consistent trends. For example, nouns and verbs are among the most frequent POS
tags. However, they are among the hardest to translate. Performance on most POS
tags improves with overall system performance, but a few are not thus
correlated (their identity changes from language to language). Preliminary
experiments with summarization reveal similar trends.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Benchmarking Arabic AI with Large Language Models</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14982</p>
  <p><b>作者</b>：Ahmed Abdelali,  Hamdy Mubarak,  Shammur Absar Chowdhury,  Maram Hasanain,  Basel Mousi,  Sabri Boughorbel,  Yassine El Kheir,  Daniel Izham,  Fahim Dalvi,  Majd Hawasly,  Nizi Nazar,  Yousseif Elshahawy,  Ahmed Ali,  Nadir Durrani,  Natasa Milic-Frayling,  Firoj Alam</p>
  <p><b>备注</b>：Foundation Models, Large Language Models, Arabic NLP, Arabic Speech, Arabic AI, , CHatGPT Evaluation, USM Evaluation, Whisper Evaluation</p>
  <p><b>关键词</b>：large Foundation Models, developing large-scale task-specific, large Foundation, Foundation Models, large-scale task-specific datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With large Foundation Models (FMs), language technologies (AI in general) are
entering a new paradigm: eliminating the need for developing large-scale
task-specific datasets and supporting a variety of tasks through set-ups
ranging from zero-shot to few-shot learning. However, understanding FMs
capabilities requires a systematic benchmarking effort by comparing FMs
performance with the state-of-the-art (SOTA) task-specific models. With that
goal, past work focused on the English language and included a few efforts with
multiple languages. Our study contributes to ongoing research by evaluating FMs
performance for standard Arabic NLP and Speech processing, including a range of
tasks from sequence tagging to content classification across diverse domains.
We start with zero-shot learning using GPT-3.5-turbo, Whisper, and USM,
addressing 33 unique tasks using 59 publicly available datasets resulting in 96
test setups. For a few tasks, FMs performs on par or exceeds the performance of
the SOTA models but for the majority it under-performs. Given the importance of
prompt for the FMs performance, we discuss our prompt strategies in detail and
elaborate on our findings. Our future work on Arabic AI will explore few-shot
prompting, expand the range of tasks, and investigate additional open-source
models.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Improving Factuality of Abstractive Summarization without Sacrificing  Summary Quality</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14981</p>
  <p><b>作者</b>：Tanay Dixit,  Fei Wang,  Muhao Chen</p>
  <p><b>备注</b>：ACL 2023</p>
  <p><b>关键词</b>：widely studied topic, Improving factual consistency, studied topic, consistency of abstractive, widely studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving factual consistency of abstractive summarization has been a widely
studied topic. However, most of the prior works on training factuality-aware
models have ignored the negative effect it has on summary quality. We propose
EFACTSUM (i.e., Effective Factual Summarization), a candidate summary
generation and ranking technique to improve summary factuality without
sacrificing summary quality. We show that using a contrastive learning
framework with our refined candidate summaries leads to significant gains on
both factuality and similarity-based metrics. Specifically, we propose a
ranking strategy in which we effectively combine two metrics, thereby
preventing any conflict during training. Models trained using our approach show
up to 6 points of absolute improvement over the base model with respect to
FactCC on XSUM and 11 points on CNN/DM, without negatively affecting either
similarity-based metrics or absractiveness.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Scale Matters: Attribution Meets the Wavelet Domain to Explain Model  Sensitivity to Image Corruptions</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14979</p>
  <p><b>作者</b>：Gabriel Kasmi,  Laurent Dubus,  Yves-Marie Saint Drenan,  Philippe Blanc</p>
  <p><b>备注</b>：main: 9 pages, appendix 19 pages, 32 figures, 5 tables</p>
  <p><b>关键词</b>：shown remarkable performance, image corruptions, Neural networks, computer vision, networks have shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have shown remarkable performance in computer vision, but
their deployment in real-world scenarios is challenging due to their
sensitivity to image corruptions. Existing attribution methods are
uninformative for explaining the sensitivity to image corruptions, while the
literature on robustness only provides model-based explanations. However, the
ability to scrutinize models' behavior under image corruptions is crucial to
increase the user's trust. Towards this end, we introduce the Wavelet sCale
Attribution Method (WCAM), a generalization of attribution from the pixel
domain to the space-scale domain. Attribution in the space-scale domain reveals
where and on what scales the model focuses. We show that the WCAM explains
models' failures under image corruptions, identifies sufficient information for
prediction, and explains how zoom-in increases accuracy.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge  Conflicts in Event Temporal Reasoning</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14970</p>
  <p><b>作者</b>：Tianqing Fang,  Zhaowei Wang,  Wenxuan Zhou,  Hongming Zhang,  Yangqiu Song,  Muhao Chen</p>
  <p><b>备注</b>：13 pages, 1 figure</p>
  <p><b>关键词</b>：Event temporal reasoning, temporal reasoning aims, Event temporal, temporal reasoning, aims at identifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event temporal reasoning aims at identifying the temporal relations between
two or more events. However, knowledge conflicts arise when there is a mismatch
between the actual temporal relations of events in the context and the prior
knowledge or biases learned by the model. We first systematically define
distinct kinds of bias in event temporal reasoning, which include event
relation prior bias, tense bias, narrative bias, and dependency bias, as
indicators to study knowledge conflicts. To mitigate such event-related
knowledge conflict, we introduce a Counterfactual Data Augmentation based
method that can be applied to both Pre-trained Language Models (PLMs) and Large
Language Models (LLMs) either as additional training data or demonstrations for
In-Context Learning. Experiments suggest the importance of mitigating knowledge
conflicts in event temporal reasoning tasks for reducing hallucination and
highlight the potential of counterfactual data augmentation for improving model
performance.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Adversarial Demonstration Attacks on Large Language Models</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14950</p>
  <p><b>作者</b>：Jiongxiao Wang,  Zichen Liu,  Keun Hee Park,  Muhao Chen,  Chaowei Xiao</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：powerful large language, large language models, powerful large, large language, ICL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the emergence of more powerful large language models (LLMs), such as
ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence
in leveraging these models for specific tasks by utilizing data-label pairs as
precondition prompts. While incorporating demonstrations can greatly enhance
the performance of LLMs across various tasks, it may introduce a new security
concern: attackers can manipulate only the demonstrations without changing the
input to perform an attack. In this paper, we investigate the security concern
of ICL from an adversarial perspective, focusing on the impact of
demonstrations. We propose an ICL attack based on TextAttack, which aims to
only manipulate the demonstration without changing the input to mislead the
models. Our results demonstrate that as the number of demonstrations increases,
the robustness of in-context learning would decreases. Furthermore, we also
observe that adversarially attacked demonstrations exhibit transferability to
diverse input examples. These findings emphasize the critical security risks
associated with ICL and underscore the necessity for extensive research on the
robustness of ICL, particularly given its increasing significance in the
advancement of LLMs.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large  Language Models with SocKET Benchmark</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14938</p>
  <p><b>作者</b>：Minje Choi,  Jiaxin Pei,  Sagar Kumar,  Chang Shu,  David Jurgens</p>
  <p><b>备注</b>：24 pages, 7 tables, 5 figures</p>
  <p><b>关键词</b>：variety of syntactic, shown to perform, Large language, LLMs, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have been shown to perform well at a variety of
syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed
in many forms including conversational agents that interact with humans, we
lack a grounded benchmark to measure how well LLMs understand \textit{social}
language. Here, we introduce a new theory-driven benchmark, SocKET, that
contains 58 NLP tasks testing social knowledge which we group into five
categories: humor & sarcasm, offensiveness, sentiment & emotion, and
trustworthiness. In tests on the benchmark, we demonstrate that current models
attain only moderate performance but reveal significant potential for task
transfer among different types and categories of tasks, which were predicted
from theory. Through zero-shot evaluations, we show that pretrained models
already possess some innate but limited capabilities of social language
understanding and training on one category of tasks can improve zero-shot
testing on others. Our benchmark provides a systematic way to analyze model
performance on an important dimension of language and points to clear room for
improvement to build more socially-aware LLMs. The associated resources are
released at this https URL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Discriminator-Guided Multi-step Reasoning with Language Models</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14934</p>
  <p><b>作者</b>：Muhammad Khalifa,  Lajanugen Logeswaran,  Moontae Lee,  Honglak Lee,  Lu Wang</p>
  <p><b>备注</b>：19 pages, 7 figures, and 8 tables</p>
  <p><b>关键词</b>：high probabilities, GRACE, probabilities, reasoning, decoding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of multi-step reasoning, language models (LMs) probabilities
are often miscalibrated -- solutions with high probabilities are not always
correct. Therefore, greedy decoding, which is the standard decoding method for
reasoning tasks, often yields incorrect solutions. In addition, methods such as
self-consistency and verifiers rely on sampling from the LM distribution and do
not tackle the underlying issue. To address this, we introduce Guiding
Multi-step ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise
decoding approach that nudges the model towards producing correct reasoning
steps. GRACE employs a discriminator model, which is trained to differentiate
correct steps from invalid ones, to adjust decoding preferences based on the
correctness of each reasoning step. Importantly, GRACE does not require
fine-tuning or re-training the LMs. When compared with conventional decoding
strategies over four popular math reasoning benchmarks, GRACE exhibits
significant improvements in both final answer accuracy and step correctness,
outperforming both greedy decoding and self-consistency.\footnote{Our code can
be found at \url{this https URL.}}</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：In-Context Impersonation Reveals Large Language Models' Strengths and  Biases</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14930</p>
  <p><b>作者</b>：Leonard Salewski,  Stephan Alaniz,  Isabel Rio-Torto,  Eric Schulz,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：everyday conversations, adapt their vocabulary, LLMs, chosen roles, roles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Universal Self-adaptive Prompting</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14926</p>
  <p><b>作者</b>：Xingchen Wan,  Ruoxi Sun,  Hootan Nakhost,  Hanjun Dai,  Julian Martin Eisenschlos,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：10 pages, 3 figures, 4 tables (19 pages, 5 figures and 9 tables including references and appendices)</p>
  <p><b>关键词</b>：modern large language, impressive general zero-shot, automatic prompt design, hallmark of modern, modern large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A hallmark of modern large language models (LLMs) is their impressive general
zero-shot and few-shot abilities, often elicited through prompt-based and/or
in-context learning. However, while highly coveted and being the most general,
zero-shot performances in LLMs are still typically weaker due to the lack of
guidance and the difficulty of applying existing automatic prompt design
methods in general tasks when ground-truth labels are unavailable. In this
study, we address this by presenting Universal Self-adaptive Prompting (USP),
an automatic prompt design approach specifically tailored for zero-shot
learning (while compatible with few-shot). Requiring only a small amount of
unlabeled data & an inference-only LLM, USP is highly versatile: to achieve
universal prompting, USP categorizes a possible NLP task into one of the three
possible task types, and then uses a corresponding selector to select the most
suitable queries & zero-shot model-generated responses as
pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a
fully automated way. We evaluate zero-shot USP with two PaLM models, and
demonstrate performances that are considerably stronger than standard zero-shot
baselines and are comparable to or even superior than few-shot baselines across
more than 20 natural language understanding (NLU) and natural language
generation (NLG) tasks.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Structural Ambiguity and its Disambiguation in Language Model Based  Parsers: the Case of Dutch Clause Relativization</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14917</p>
  <p><b>作者</b>：Gijs Wijnholds,  Michael Moortgat</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dutch relative clauses, paper addresses structural, addresses structural ambiguity, ambiguity in Dutch, Dutch relative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses structural ambiguity in Dutch relative clauses. By
investigating the task of disambiguation by grounding, we study how the
presence of a prior sentence can resolve relative clause ambiguities. We apply
this method to two parsing architectures in an attempt to demystify the parsing
and language model components of two present-day neural parsers. Results show
that a neurosymbolic parser, based on proof nets, is more open to data bias
correction than an approach based on universal dependencies, although both
setups suffer from a comparable initial data bias.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：From Shortcuts to Triggers: Backdoor Defense with Denoised PoE</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14910</p>
  <p><b>作者</b>：Qin Liu,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：backdoor attacks, backdoor, data poisoning, attacks, diverse backdoor attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models are often at risk of diverse backdoor attacks, especially
data poisoning. Thus, it is important to investigate defense solutions for
addressing them. Existing backdoor defense methods mainly focus on backdoor
attacks with explicit triggers, leaving a universal defense against various
backdoor attacks with diverse triggers largely unexplored. In this paper, we
propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised
Product-of-Experts), which is inspired by the shortcut nature of backdoor
attacks, to defend various backdoor attacks. DPoE consists of two models: a
shallow model that captures the backdoor shortcuts and a main model that is
prevented from learning the backdoor shortcuts. To address the label flip
caused by backdoor attackers, DPoE incorporates a denoising design. Experiments
on SST-2 dataset show that DPoE significantly improves the defense performance
against various types of backdoor triggers including word-level,
sentence-level, and syntactic triggers. Furthermore, DPoE is also effective
under a more challenging but practical setting that mixes multiple types of
trigger.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Leveraging Pre-trained Large Language Models to Construct and Utilize  World Models for Model-based Task Planning</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14909</p>
  <p><b>作者</b>：Lin Guan,  Karthik Valmeekam,  Sarath Sreedharan,  Subbarao Kambhampati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying pre-trained large, pre-trained large language, PDDL, growing interest, interest in applying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a growing interest in applying pre-trained large language models
(LLMs) to planning problems. However, methods that use LLMs directly as
planners are currently impractical due to several factors, including limited
correctness of plans, strong reliance on feedback from interactions with
simulators or even the actual environment, and the inefficiency in utilizing
human feedback. In this work, we introduce a novel alternative paradigm that
constructs an explicit world (domain) model in planning domain definition
language (PDDL) and then uses it to plan with sound domain-independent
planners. To address the fact that LLMs may not generate a fully functional
PDDL model initially, we employ LLMs as an interface between PDDL and sources
of corrective feedback, such as PDDL validators and humans. For users who lack
a background in PDDL, we show that LLMs can translate PDDL into natural
language and effectively encode corrective feedback back to the underlying
domain model. Our framework not only enjoys the correctness guarantee offered
by the external planners but also reduces human involvement by allowing users
to correct domain models at the beginning, rather than inspecting and
correcting (through interactive prompting) every generated plan as in previous
work. On two IPC domains and a Household domain that is more complicated than
commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be
leveraged to produce high-quality PDDL models for over 40 actions, and the
corrected PDDL models are then used to successfully solve 48 challenging
planning tasks. Resources including the source code will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Identifying Informational Sources in News Articles</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14904</p>
  <p><b>作者</b>：Alexander Spangher,  Nanyun Peng,  Jonathan May,  Emilio Ferrara</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：informational sources, sources, informational sources journalists, journalists, articles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>News articles are driven by the informational sources journalists use in
reporting. Modeling when, how and why sources get used together in stories can
help us better understand the information we consume and even help journalists
with the task of producing it. In this work, we take steps toward this goal by
constructing the largest and widest-ranging annotated dataset, to date, of
informational sources used in news writing. We show that our dataset can be
used to train high-performing models for information detection and source
attribution. We further introduce a novel task, source prediction, to study the
compositionality of sources in news articles. We show good performance on this
task, which we argue is an important proof for narrative science exploring the
internal structure of news articles and aiding in planning-based language
generation, and an important step towards a source-recommendation system to aid
journalists.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Evaluating NLG Evaluation Metrics: A Measurement Theory Perspective</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14889</p>
  <p><b>作者</b>：Ziang Xiao,  Susu Zhang,  Vivian Lai,  Q. Vera Liao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Generation, Language Generation, Natural Language, challenge in Natural, NLG evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the fundamental challenge in Natural Language Generation (NLG)
model evaluation, the design and validation of evaluation metrics. Recognizing
the limitations of existing metrics and issues with human judgment, we propose
using measurement theory, the foundation of test design, as a framework for
conceptualizing and evaluating the validity and reliability of NLG evaluation
metrics. This approach offers a systematic method for defining "good" metrics,
developing robust metrics, and assessing metric performance. In this paper, we
introduce core concepts in measurement theory in the context of NLG evaluation
and key methods to evaluate the performance of NLG metrics. Through this
framework, we aim to promote the design, evaluation, and interpretation of
valid and reliable metrics, ultimately contributing to the advancement of
robust and effective NLG models in real-world settings.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Interpretable by Design Visual Question Answering</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14882</p>
  <p><b>作者</b>：Xingyu Fu,  Ben Zhou,  Sihao Chen,  Mark Yatskar,  Dan Roth</p>
  <p><b>备注</b>：Multimodal, Vision and Language</p>
  <p><b>关键词</b>：Visual Question Answering, vision and language, aligned and reasoned, multimodal setting, Question Answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model interpretability has long been a hard problem for the AI community
especially in the multimodal setting, where vision and language need to be
aligned and reasoned at the same time. In this paper, we specifically focus on
the problem of Visual Question Answering (VQA). While previous researches try
to probe into the network structures of black-box multimodal models, we propose
to tackle the problem from a different angle -- to treat interpretability as an
explicit additional goal.
Given an image and question, we argue that an interpretable VQA model should
be able to tell what conclusions it can get from which part of the image, and
show how each statement help to arrive at an answer. We introduce InterVQA:
Interpretable-by-design VQA, where we design an explicit intermediate dynamic
reasoning structure for VQA problems and enforce symbolic reasoning that only
use the structure for final answer prediction to take place. InterVQA produces
high-quality explicit intermediate reasoning steps, while maintaining similar
to the state-of-the-art (sota) end-task performance.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：ByteSized32: A Corpus and Challenge Task for Generating Task-Specific  World Models Expressed as Text Games</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14879</p>
  <p><b>作者</b>：Ruoyao Wang,  Graham Todd,  Eric Yuan,  Ziang Xiao,  Marc-Alexandre Côté,  Peter Jansen</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：explicit world models, generating text-based games, generate explicit world, common-sense reasoning tasks, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we examine the ability of language models to generate explicit
world models of scientific and common-sense reasoning tasks by framing this as
a problem of generating text-based games. To support this, we introduce
ByteSized32, a corpus of 32 highly-templated text games written in Python
totaling 24k lines of code, each centered around a particular task, and paired
with a set of 16 unseen text game specifications for evaluation. We propose a
suite of automatic and manual metrics for assessing simulation validity,
compliance with task specifications, playability, winnability, and alignment
with the physical world. In a single-shot evaluation of GPT-4 on this
simulation-as-code-generation task, we find it capable of producing runnable
games in 27% of cases, highlighting the difficulty of this challenge task. We
discuss areas of future improvement, including GPT-4's apparent capacity to
perform well at simulating near canonical task solutions, with performance
dropping off as simulations include distractors or deviate from canonical
solutions in the action space.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Leveraging GPT-4 for Automatic Translation Post-Editing</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14878</p>
  <p><b>作者</b>：Vikas Raunak,  Amr Sharaf,  Hany Hassan Awadallah,  Arul Menezes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Machine Translation, Neural Machine, Machine Translation, represents the leading, Translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Neural Machine Translation (NMT) represents the leading approach to
Machine Translation (MT), the outputs of NMT models still require translation
post-editing to rectify errors and enhance quality, particularly under critical
settings. In this work, we formalize the task of translation post-editing with
Large Language Models (LLMs) and explore the use of GPT-4 to automatically
post-edit NMT outputs across several language pairs. Our results demonstrate
that GPT-4 is adept at translation post-editing and produces meaningful edits
even when the target language is not English. Notably, we achieve
state-of-the-art performance on WMT-22 English-Chinese, English-German,
Chinese-English and German-English language pairs using GPT-4 based
post-editing, as evaluated by state-of-the-art MT quality metrics.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：From Words to Wires: Generating Functioning Electronic Devices from  Natural Language Descriptions</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14874</p>
  <p><b>作者</b>：Peter Jansen</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：previously unknown skill, high-level textual descriptions, unknown skill, textual descriptions, show that contemporary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we show that contemporary language models have a previously
unknown skill -- the capacity for electronic circuit design from high-level
textual descriptions, akin to code generation. We introduce two benchmarks:
Pins100, assessing model knowledge of electrical components, and Micro25,
evaluating a model's capability to design common microcontroller circuits and
code in the Arduino ecosystem that involve input, output, sensors, motors,
protocols, and logic -- with models such as GPT-4 and Claude-V1 achieving
between 60% to 96% Pass@1 on generating full devices. We include six case
studies of using language models as a design assistant for moderately complex
devices, such as a radiation-powered random number generator, an emoji
keyboard, a visible spectrometer, and several assistive devices, while offering
a qualitative analysis performance, outlining evaluation challenges, and
suggesting areas of development to improve complex circuit design and practical
utility. With this work, we aim to spur research at the juncture of natural
language processing and electronic design.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient  Pre-LN Transformers</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14858</p>
  <p><b>作者</b>：Zixuan Jiang,  Jiaqi Gu,  Hanqing Zhu,  David Z. Pan</p>
  <p><b>备注</b>：15 pages, 5 tables, code available at this https URL</p>
  <p><b>关键词</b>：machine learning applications, achieved great success, Transformers, learning applications, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have achieved great success in machine learning applications.
Normalization techniques, such as Layer Normalization (LayerNorm, LN) and Root
Mean Square Normalization (RMSNorm), play a critical role in accelerating and
stabilizing the training of Transformers. While LayerNorm recenters and
rescales input vectors, RMSNorm only rescales the vectors by their RMS value.
Despite being more computationally efficient, RMSNorm may compromise the
representation ability of Transformers. There is currently no consensus
regarding the preferred normalization technique, as some models employ
LayerNorm while others utilize RMSNorm, especially in recent large language
models. It is challenging to convert Transformers with one normalization to the
other type. While there is an ongoing disagreement between the two
normalization types, we propose a solution to unify two mainstream Transformer
architectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent
redundant mean information in the main branch of Pre-LN Transformers, we can
reduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose
the Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a
lossless compression of the zero-mean vectors. We formally establish the
equivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in
both training and inference. It implies that Pre-LN Transformers can be
substituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the
same arithmetic functionality along with free efficiency improvement.
Experiments demonstrate that we can reduce the training and inference time of
Pre-LN Transformers by up to 10%.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：SWAMP: Sparse Weight Averaging with Multiple Particles for Iterative  Magnitude Pruning</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14852</p>
  <p><b>作者</b>：Moonseok Choi,  Hyungi Lee,  Giung Nam,  Juho Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimal memory demands, accelerated inference speeds, memory demands, ever-increasing size, size of modern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given the ever-increasing size of modern neural networks, the significance of
sparse architectures has surged due to their accelerated inference speeds and
minimal memory demands. When it comes to global pruning techniques, Iterative
Magnitude Pruning (IMP) still stands as a state-of-the-art algorithm despite
its simple nature, particularly in extremely sparse regimes. In light of the
recent finding that the two successive matching IMP solutions are linearly
connected without a loss barrier, we propose Sparse Weight Averaging with
Multiple Particles (SWAMP), a straightforward modification of IMP that achieves
performance comparable to an ensemble of two IMP solutions. For every
iteration, we concurrently train multiple sparse models, referred to as
particles, using different batch orders yet the same matching ticket, and then
weight average such models to produce a single mask. We demonstrate that our
method consistently outperforms existing baselines across different sparsities
through extensive experiments on various data and neural network structures.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Exploring Sentiment Analysis Techniques in Natural Language Processing:  A Comprehensive Review</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14842</p>
  <p><b>作者</b>：Karthick Prasad Gunasekaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：written text, automated process, process of detecting, detecting and understanding, understanding the emotions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentiment analysis (SA) is the automated process of detecting and
understanding the emotions conveyed through written text. Over the past decade,
SA has gained significant popularity in the field of Natural Language
Processing (NLP). With the widespread use of social media and online platforms,
SA has become crucial for companies to gather customer feedback and shape their
marketing strategies. Additionally, researchers rely on SA to analyze public
sentiment on various topics. In this particular research study, a comprehensive
survey was conducted to explore the latest trends and techniques in SA. The
survey encompassed a wide range of methods, including lexicon-based,
graph-based, network-based, machine learning, deep learning, ensemble-based,
rule-based, and hybrid techniques. The paper also addresses the challenges and
opportunities in SA, such as dealing with sarcasm and irony, analyzing
multi-lingual data, and addressing ethical concerns. To provide a practical
case study, Twitter was chosen as one of the largest online social media
platforms. Furthermore, the researchers shed light on the diverse application
areas of SA, including social media, healthcare, marketing, finance, and
politics. The paper also presents a comparative and comprehensive analysis of
existing trends and techniques, datasets, and evaluation metrics. The ultimate
goal is to offer researchers and practitioners a systematic review of SA
techniques, identify existing gaps, and suggest possible improvements. This
study aims to enhance the efficiency and accuracy of SA processes, leading to
smoother and error-free outcomes.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Building Transportation Foundation Model via Generative Graph  Transformer</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14826</p>
  <p><b>作者</b>：Xuhong Wang,  Ding Wang,  Liang Chen,  Yilun Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：densely populated areas, Efficient traffic management, maintaining urban mobility, areas where congestion, expensive commutes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient traffic management is crucial for maintaining urban mobility,
especially in densely populated areas where congestion, accidents, and delays
can lead to frustrating and expensive commutes. However, existing prediction
methods face challenges in terms of optimizing a single objective and
understanding the complex composition of the transportation system. Moreover,
they lack the ability to understand the macroscopic system and cannot
efficiently utilize big data. In this paper, we propose a novel approach,
Transportation Foundation Model (TFM), which integrates the principles of
traffic simulation into traffic prediction. TFM uses graph structures and
dynamic graph generation algorithms to capture the participatory behavior and
interaction of transportation system actors. This data-driven and model-free
simulation method addresses the challenges faced by traditional systems in
terms of structural complexity and model accuracy and provides a foundation for
solving complex transportation problems with real data. The proposed approach
shows promising results in accurately predicting traffic outcomes in an urban
transportation setting.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Large Language Models are In-Context Semantic Reasoners rather than  Symbolic Reasoners</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14825</p>
  <p><b>作者</b>：Xiaojuan Tang,  Zilong Zheng,  Jiaqi Li,  Fanxu Meng,  Song-Chun Zhu,  Yitao Liang,  Muhan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, machine learning community, emergent few-shot reasoning, Language Models, few-shot reasoning capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emergent few-shot reasoning capabilities of Large Language Models (LLMs)
have excited the natural language and machine learning community over recent
years. Despite of numerous successful applications, the underlying mechanism of
such in-context capabilities still remains unclear. In this work, we
hypothesize that the learned \textit{semantics} of language tokens do the most
heavy lifting during the reasoning process. Different from human's symbolic
reasoning process, the semantic representations of LLMs could create strong
connections among tokens, thus composing a superficial logical chain. To test
our hypothesis, we decouple semantics from the language reasoning process and
evaluate three kinds of reasoning abilities, i.e., deduction, induction and
abduction. Our findings reveal that semantics play a vital role in LLMs'
in-context reasoning -- LLMs perform significantly better when semantics are
consistent with commonsense but struggle to solve symbolic or
counter-commonsense reasoning tasks by leveraging in-context new knowledge. The
surprising observations question whether modern LLMs have mastered the
inductive, deductive and abductive reasoning abilities as in human
intelligence, and motivate research on unveiling the magic existing within the
black-box LLMs. On the whole, our analysis provides a novel perspective on the
role of semantics in developing and evaluating language models' reasoning
abilities. Code is available at {\url{this https URL}}.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak  Supervision for Text Classification</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14794</p>
  <p><b>作者</b>：Chengyu Dong,  Zihan Wang,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：turn high-level human, high-level human heuristics, designing sophisticated methods, weakly supervised text, supervised text classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in weakly supervised text classification mostly focus on
designing sophisticated methods to turn high-level human heuristics into
quality pseudo-labels. In this paper, we revisit the seed matching-based
method, which is arguably the simplest way to generate pseudo-labels, and show
that its power was greatly underestimated. We show that the limited performance
of seed matching is largely due to the label bias injected by the simple
seed-match rule, which prevents the classifier from learning reliable
confidence for selecting high-quality pseudo-labels. Interestingly, simply
deleting the seed words present in the matched input texts can mitigate the
label bias and help learn better confidence. Subsequently, the performance
achieved by seed matching can be improved significantly, making it on par with
or even better than the state-of-the-art. Furthermore, to handle the case when
the seed words are not made known, we propose to simply delete the word tokens
in the input text randomly with a high deletion ratio. Remarkably, seed
matching equipped with this random deletion method can often achieve even
better performance than that with seed deletion.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Advancing Topic Segmentation and Outline Generation in Chinese Texts:  The Paragraph-level Topic Representation, Corpus, and Benchmark</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14790</p>
  <p><b>作者</b>：Feng Jiang,  Weihao Liu,  Xiaomin Chu,  Peifeng Li,  Qiaoming Zhu,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：coherent topic sections, paragraph-level topic structure, topic structure, discourse topic structure, Topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Topic segmentation and outline generation strive to divide a document into
coherent topic sections and generate corresponding subheadings. Such a process
unveils the discourse topic structure of a document that benefits quickly
grasping and understanding the overall context of the document from a higher
level. However, research and applications in this field have been restrained
due to the lack of proper paragraph-level topic representations and
large-scale, high-quality corpora in Chinese compared to the success achieved
in English. Addressing these issues, we introduce a hierarchical
paragraph-level topic structure representation with title, subheading, and
paragraph that comprehensively models the document discourse topic structure.
In addition, we ensure a more holistic representation of topic distribution
within the document by using sentences instead of keywords to represent
sub-topics. Following this representation, we construct the largest Chinese
Paragraph-level Topic Structure corpus (CPTS), four times larger than the
previously largest one. We also employ a two-stage man-machine collaborative
annotation method to ensure the high quality of the corpus both in form and
semantics. Finally, we validate the computability of CPTS on two fundamental
tasks (topic segmentation and outline generation) by several strong baselines,
and its efficacy has been preliminarily confirmed on the downstream task:
discourse parsing. The representation, corpus, and benchmark we established
will provide a solid foundation for future studies.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14785</p>
  <p><b>作者</b>：Victoria Basmov,  Yoav Goldberg,  Reut Tsarfaty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper sheds light, simple inference tasks, focusing on simple, paper sheds, sheds light</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper sheds light on the limitations of ChatGPT's understanding
capabilities, focusing on simple inference tasks that are typically easy for
humans but appear to be challenging for the model. Specifically, we target (i)
grammatically-specified entailments, (ii) premises with evidential adverbs of
uncertainty, and (iii) monotonicity entailments. We present expert-designed
evaluation sets for these inference types and conduct experiments in a
zero-shot setup. Our results show that the model struggles with these types of
inferences, exhibiting moderate to low accuracy. Moreover, while ChatGPT
demonstrates knowledge of the underlying linguistic concepts when prompted
directly, it often fails to incorporate this knowledge to make correct
inferences. Even more strikingly, further experiments show that embedding the
premise under presupposition triggers or non-factive verbs causes the model to
predict entailment more frequently {regardless} of the correct semantic label.
Overall these results suggest that, despite GPT's celebrated language
understanding capacity, ChatGPT has blindspots with respect to certain types of
entailment, and that certain entailment-cancelling features act as ``blinds''
overshadowing the semantics of the embedded premise. Our analyses emphasize the
need for further research into the linguistic comprehension and reasoning
capabilities of LLMs, in order to improve their reliability, and establish
their trustworthiness for real-world applications.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Anthropomorphization of AI: Opportunities and Risks</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14784</p>
  <p><b>作者</b>：Ameet Deshpande,  Tanmay Rajpurohit,  Karthik Narasimhan,  Ashwin Kalyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attribute human-like traits, non-human entities, traits to non-human, attribute human-like, human-like traits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anthropomorphization is the tendency to attribute human-like traits to
non-human entities. It is prevalent in many social contexts -- children
anthropomorphize toys, adults do so with brands, and it is a literary device.
It is also a versatile tool in science, with behavioral psychology and
evolutionary biology meticulously documenting its consequences. With widespread
adoption of AI systems, and the push from stakeholders to make it human-like
through alignment techniques, human voice, and pictorial avatars, the tendency
for users to anthropomorphize it increases significantly. We take a dyadic
approach to understanding this phenomenon with large language models (LLMs) by
studying (1) the objective legal implications, as analyzed through the lens of
the recent blueprint of AI bill of rights and the (2) subtle psychological
aspects customization and anthropomorphization. We find that anthropomorphized
LLMs customized for different user bases violate multiple provisions in the
legislative blueprint. In addition, we point out that anthropomorphization of
LLMs affects the influence they can have on their users, thus having the
potential to fundamentally change the nature of human-AI interaction, with
potential for manipulation and negative influence. With LLMs being
hyper-personalized for vulnerable groups like children and patients among
others, our work is a timely and important contribution. We propose a
conservative strategy for the cautious use of anthropomorphization to improve
trustworthiness of AI systems.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Measuring the Knowledge Acquisition-Utilization Gap in Pretrained  Language Models</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14775</p>
  <p><b>作者</b>：Amirhossein Kazemnejad,  Mehdi Rezagholizadeh,  Prasanna Parthasarathi,  Sarath Chandar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：acquiring vast amounts, pre-trained language models, knowledge, performing downstream tasks, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While pre-trained language models (PLMs) have shown evidence of acquiring
vast amounts of knowledge, it remains unclear how much of this parametric
knowledge is actually usable in performing downstream tasks. We propose a
systematic framework to measure parametric knowledge utilization in PLMs. Our
framework first extracts knowledge from a PLM's parameters and subsequently
constructs a downstream task around this extracted knowledge. Performance on
this task thus depends exclusively on utilizing the model's possessed
knowledge, avoiding confounding factors like insufficient signal. As an
instantiation, we study factual knowledge of PLMs and measure utilization
across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps -
in acquired vs. utilized knowledge, (2) they show limited robustness in
utilizing knowledge under distribution shifts, and (3) larger models close the
acquired knowledge gap but the utilized knowledge gap remains. Overall, our
study provides insights into PLMs' capabilities beyond their acquired
knowledge.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Don't Take This Out of Context! On the Need for Contextual Models and  Evaluations for Stylistic Rewriting</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14755</p>
  <p><b>作者</b>：Akhila Yerukola,  Xuhui Zhou,  Maarten Sap</p>
  <p><b>备注</b>：may 24 submission</p>
  <p><b>关键词</b>：stylistic text rewriting, rewriting methods operate, existing stylistic text, text rewriting methods, stylistic text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing stylistic text rewriting methods operate on a sentence level,
but ignoring the broader context of the text can lead to generic, ambiguous,
and incoherent rewrites. In this paper, we propose the integration of preceding
textual context into both the rewriting and evaluation stages of stylistic text
rewriting, focusing on formality, toxicity, and sentiment transfer tasks. We
conduct a comparative evaluation of rewriting through few-shot prompting of
GPT-3.5 and GPT NeoX, comparing non-contextual rewrites to contextual rewrites.
Our experiments show that humans often prefer contextual rewrites over
non-contextual ones, but automatic metrics (e.g., BLEU, sBERT) do not. To
bridge this gap, we propose context-infused versions of common automatic
metrics, and show that these better reflect human preferences. Overall, our
paper highlights the importance of integrating preceding textual context into
both the rewriting and evaluation stages of stylistic text rewriting.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：A New Era in Software Security: Towards Self-Healing Software via Large  Language Models and Formal Verification</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14752</p>
  <p><b>作者</b>：Yiannis Charalambous,  Norbert Tihanyi,  Ridhi Jain,  Youcheng Sun,  Mohamed Amine Ferrag,  Lucas C. Cordeiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Formal Verification strategies, paper we present, solution that combines, combines the capabilities, Formal Verification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present a novel solution that combines the capabilities of
Large Language Models (LLMs) with Formal Verification strategies to verify and
automatically repair software vulnerabilities. Initially, we employ Bounded
Model Checking (BMC) to locate the software vulnerability and derive a
counterexample. The counterexample provides evidence that the system behaves
incorrectly or contains a vulnerability. The counterexample that has been
detected, along with the source code, are provided to the LLM engine. Our
approach involves establishing a specialized prompt language for conducting
code debugging and generation to understand the vulnerability's root cause and
repair the code. Finally, we use BMC to verify the corrected version of the
code generated by the LLM. As a proof of concept, we create ESBMC-AI based on
the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained
Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C
programs. Our experimentation involved generating a dataset comprising 1000 C
code samples, each consisting of 20 to 50 lines of code. Notably, our proposed
method achieved an impressive success rate of up to 80% in repairing vulnerable
code encompassing buffer overflow and pointer dereference failures. We assert
that this automated approach can effectively incorporate into the software
development lifecycle's continuous integration and deployment (CI/CD) process.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：DialogVCS: Robust Natural Language Understanding in Dialogue System  Upgrade</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14751</p>
  <p><b>作者</b>：Zefan Cai,  Xin Zheng,  Tianyu Liu,  Xu Wang,  Haoran Meng,  Jiaqi Han,  Gang Yuan,  Binghuai Lin,  Baobao Chang,  Yunbo Cao</p>
  <p><b>备注</b>：work in progress. The first three authors contribute equally</p>
  <p><b>关键词</b>：natural language understanding, existent data accumulated, product dialogue systems, Dialogue Version Control, language understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the constant updates of the product dialogue systems, we need to retrain
the natural language understanding (NLU) model as new data from the real users
would be merged into the existent data accumulated in the last updates. Within
the newly added data, new intents would emerge and might have semantic
entanglement with the existing intents, e.g. new intents that are semantically
too specific or generic are actually subset or superset of some existing
intents in the semantic space, thus impairing the robustness of the NLU model.
As the first attempt to solve this problem, we setup a new benchmark consisting
of 4 Dialogue Version Control dataSets (DialogVCS). We formulate the intent
detection with imperfect data in the system update as a multi-label
classification task with positive but unlabeled intents, which asks the models
to recognize all the proper intents, including the ones with semantic
entanglement, in the inference. We also propose comprehensive baseline models
and conduct in-depth analyses for the benchmark, showing that the semantically
entangled intents can be effectively recognized with an automatic workflow.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：ECHo: Event Causality Inference via Human-centric Reasoning</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14740</p>
  <p><b>作者</b>：Yuxi Xie,  Guanzhen Li,  Min-Yen Kan</p>
  <p><b>备注</b>：Please find data and code at this https URL</p>
  <p><b>关键词</b>：event causality inference, causality inference grounded, event causality, causality inference, inference grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce ECHo, a diagnostic dataset of event causality inference grounded
in visual-and-linguistic social scenarios. ECHo employs real-world
human-centric deductive information collected from crime drama, bridging the
gap in multimodal reasoning towards higher social intelligence through the
elicitation of intermediate Theory-of-Mind (ToM). We propose a unified
framework aligned with the Chain-of-Thought (CoT) paradigm to assess the
reasoning capability of current AI systems. This ToM-enhanced CoT pipeline can
accommodate and integrate various large foundation models in zero-shot
visual-and-linguistic understanding. With this framework, we scrutinize the
advanced large language and multimodal models via three complementary
human-centric ECHo tasks. Further analysis demonstrates ECHo as a challenging
dataset to expose imperfections and inconsistencies in reasoning.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Optimal Control of Logically Constrained Partially Observable and  Multi-Agent Markov Decision Processes</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14736</p>
  <p><b>作者</b>：Krishna C. Kalagarla,  Dhruva Kartik,  Dongming Shen,  Rahul Jain,  Ashutosh Nayyar,  Pierluigi Nuzzo</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2203.09038</p>
  <p><b>关键词</b>：logical constraints arising, regulatory requirements, Autonomous systems, temporal logic, constraints arising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous systems often have logical constraints arising, for example, from
safety, operational, or regulatory requirements. Such constraints can be
expressed using temporal logic specifications. The system state is often
partially observable. Moreover, it could encompass a team of multiple agents
with a common objective but disparate information structures and constraints.
In this paper, we first introduce an optimal control theory for partially
observable Markov decision processes (POMDPs) with finite linear temporal logic
constraints. We provide a structured methodology for synthesizing policies that
maximize a cumulative reward while ensuring that the probability of satisfying
a temporal logic constraint is sufficiently high. Our approach comes with
guarantees on approximate reward optimality and constraint satisfaction. We
then build on this approach to design an optimal control framework for
logically constrained multi-agent settings with information asymmetry. We
illustrate the effectiveness of our approach by implementing it on several case
studies.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14735</p>
  <p><b>作者</b>：Vyoma Raman,  Eve Fleisig,  Dan Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determine performance discrepancies, standard method, method for measuring, measuring the impacts, marginalized communities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A standard method for measuring the impacts of AI on marginalized communities
is to determine performance discrepancies between specified demographic groups.
These approaches aim to address harms toward vulnerable groups, but they
obscure harm patterns faced by intersectional subgroups or shared across
demographic groups. We instead operationalize "the margins" as data points that
are statistical outliers due to having demographic attributes distant from the
"norm" and measure harms toward these outliers. We propose a Group-Based
Performance Disparity Index (GPDI) that measures the extent to which a
subdivision of a dataset into subgroups identifies those facing increased
harms. We apply our approach to detecting disparities in toxicity detection and
find that text targeting outliers is 28% to 86% more toxic for all types of
toxicity examined. We also discover that model performance is consistently
worse for demographic outliers, with disparities in error between outliers and
non-outliers ranging from 28% to 71% across toxicity types. Our outlier-based
analysis has comparable or higher GPDI than traditional subgroup-based
analyses, suggesting that outlier analysis enhances identification of subgroups
facing greater harms. Finally, we find that minoritized racial and religious
groups are most associated with outliers, which suggests that outlier analysis
is particularly beneficial for identifying harms against those groups.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：AutoDepthNet: High Frame Rate Depth Map Reconstruction using Commodity  Depth and RGB Cameras</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14731</p>
  <p><b>作者</b>：Peyman Gholami,  Robert Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Depth, Depth cameras, artificial intelligence, diverse fields, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depth cameras have found applications in diverse fields, such as computer
vision, artificial intelligence, and video gaming. However, the high latency
and low frame rate of existing commodity depth cameras impose limitations on
their applications. We propose a fast and accurate depth map reconstruction
technique to reduce latency and increase the frame rate in depth cameras. Our
approach uses only a commodity depth camera and color camera in a hybrid camera
setup; our prototype is implemented using a Kinect Azure depth camera at 30 fps
and a high-speed RGB iPhone 11 Pro camera captured at 240 fps. The proposed
network, AutoDepthNet, is an encoder-decoder model that captures frames from
the high-speed RGB camera and combines them with previous depth frames to
reconstruct a stream of high frame rate depth maps. On GPU, with a 480 x 270
output resolution, our system achieves an inference time of 8 ms, enabling
real-time use at up to 200 fps with parallel processing. AutoDepthNet can
estimate depth values with an average RMS error of 0.076, a 44.5% improvement
compared to an optical flow-based comparison method. Our method can also
improve depth map quality by estimating depth values for missing and
invalidated pixels. The proposed method can be easily applied to existing depth
cameras and facilitates the use of depth cameras in applications that require
high-speed depth estimation. We also showcase the effectiveness of the
framework in upsampling different sparse datasets e.g. video object
segmentation. As a demonstration of our method, we integrated our framework
into existing body tracking systems and demonstrated the robustness of the
proposed method in such applications.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：In-Context Demonstration Selection with Cross Entropy Difference</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14726</p>
  <p><b>作者</b>：Dan Iter,  Reid Pryzant,  Ruochen Xu,  Shuohang Wang,  Yang Liu,  Yichong Xu,  Chenguang Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：in-context, Large language models, in-context demonstrations, Large language, demonstrations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) can use in-context demonstrations to improve
performance on zero-shot tasks. However, selecting the best in-context examples
is challenging because model performance can vary widely depending on the
selected examples. We present a cross-entropy difference (CED) method for
selecting in-context demonstrations. Our method is based on the observation
that the effectiveness of in-context demonstrations negatively correlates with
the perplexity of the test example by a language model that was finetuned on
that demonstration. We utilize parameter efficient finetuning to train small
models on training data that are used for computing the cross-entropy
difference between a test example and every candidate in-context demonstration.
This metric is used to rank and select in-context demonstrations independently
for each test input. We evaluate our method on a mix-domain dataset that
combines 8 benchmarks, representing 4 text generation tasks, showing that CED
for in-context demonstration selection can improve performance for a variety of
LLMs.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create  Visual Metaphors</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14724</p>
  <p><b>作者</b>：Tuhin Chakrabarty,  Arkadiy Saakyan,  Olivia Winn,  Artemis Panagopoulou,  Yue Yang,  Marianna Apidianaki,  Smaranda Muresan</p>
  <p><b>备注</b>：ACL 2023 (Findings)</p>
  <p><b>关键词</b>：powerful rhetorical devices, communicate creative ideas, linguistic metaphors, ideas through images, powerful rhetorical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual metaphors are powerful rhetorical devices used to persuade or
communicate creative ideas through images. Similar to linguistic metaphors,
they convey meaning implicitly through symbolism and juxtaposition of the
symbols. We propose a new task of generating visual metaphors from linguistic
metaphors. This is a challenging task for diffusion-based text-to-image models,
such as DALL$\cdot$E 2, since it requires the ability to model implicit meaning
and compositionality. We propose to solve the task through the collaboration
between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3
(davinci-002) with Chain-of-Thought prompting generates text that represents a
visual elaboration of the linguistic metaphor containing the implicit meaning
and relevant objects, which is then used as input to the diffusion-based
text-to-image models.Using a human-AI collaboration framework, where humans
interact both with the LLM and the top-performing diffusion model, we create a
high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic
metaphors and their associated visual elaborations. Evaluation by professional
illustrators shows the promise of LLM-Diffusion Model collaboration for this
this http URL evaluate the utility of our Human-AI collaboration framework and the
quality of our dataset, we perform both an intrinsic human-based evaluation and
an extrinsic evaluation using visual entailment as a downstream task.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：BLIP-Diffusion: Pre-trained Subject Representation for Controllable  Text-to-Image Generation and Editing</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14720</p>
  <p><b>作者</b>：Dongxu Li,  Junnan Li,  Steven C.H. Hoi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subject, generation, text prompts, subject-driven generation, Subject-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subject-driven text-to-image generation models create novel renditions of an
input subject based on text prompts. Existing models suffer from lengthy
fine-tuning and difficulties preserving the subject fidelity. To overcome these
limitations, we introduce BLIP-Diffusion, a new subject-driven image generation
model that supports multimodal control which consumes inputs of subject images
and text prompts. Unlike other subject-driven generation models, BLIP-Diffusion
introduces a new multimodal encoder which is pre-trained to provide subject
representation. We first pre-train the multimodal encoder following BLIP-2 to
produce visual representation aligned with the text. Then we design a subject
representation learning task which enables a diffusion model to leverage such
visual representation and generates new subject renditions. Compared with
previous methods such as DreamBooth, our model enables zero-shot subject-driven
generation, and efficient fine-tuning for customized subject with up to 20x
speedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with
existing techniques such as ControlNet and prompt-to-prompt to enable novel
subject-driven generation and editing applications. Code and models will be
released at
this https URL. Project
page at this https URL.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Exploiting Correlations Between Contexts and Definitions with Multiple  Definition Modeling</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14717</p>
  <p><b>作者</b>：Linhan Zhang,  Qian Chen,  Wen Wang,  Yuxin Jiang,  Bing Li,  Wei Wang,  Xin Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced natural language, natural language applications, Single Definition Modeling, Definition modeling, Multiple Definition Modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Definition modeling is an important task in advanced natural language
applications such as understanding and conversation. Since its introduction, it
focus on generating one definition for a target word or phrase in a given
context, which we refer to as Single Definition Modeling (SDM). However, this
approach does not adequately model the correlations and patterns among
different contexts and definitions of words. In addition, the creation of a
training dataset for SDM requires significant human expertise and effort. In
this paper, we carefully design a new task called Multiple Definition Modeling
(MDM) that pool together all contexts and definition of target words. We
demonstrate the ease of creating a model as well as multiple training sets
automatically. % In the experiments, we demonstrate and analyze the benefits of
MDM, including improving SDM's performance by using MDM as the pretraining task
and its comparable performance in the zero-shot setting.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Streaming Object Detection on Fisheye Cameras for Automatic Parking</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14713</p>
  <p><b>作者</b>：Yixiong Yan,  Liangzhu Cheng,  Yongxu Li,  Xinjuan Tuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video stream object, fundamental perception function, stream object detection, fisheye camera, widely employed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fisheye cameras are widely employed in automatic parking, and the video
stream object detection (VSOD) of the fisheye camera is a fundamental
perception function to ensure the safe operation of vehicles. In past research
work, the difference between the output of the deep learning model and the
actual situation at the current moment due to the existence of delay of the
perception system is generally ignored. But the environment will inevitably
change within the delay time which may cause a potential safety hazard. In this
paper, we propose a real-time detection framework equipped with a dual-flow
perception module (dynamic and static flows) that can predict the future and
alleviate the time-lag problem. Meanwhile, we use a new scheme to evaluate
latency and accuracy. The standard bounding box is unsuitable for the object in
fisheye camera images due to the strong radial distortion of the fisheye camera
and the primary detection objects of parking perception are vehicles and
pedestrians, so we adopt the rotate bounding box and propose a new periodic
angle loss function to regress the angle of the box, which is the simple and
accurate representation method of objects. The instance segmentation ground
truth is used to supervise the training. Experiments demonstrate the
effectiveness of our approach. Code is released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Instructions as Backdoors: Backdoor Vulnerabilities of Instruction  Tuning for Large Language Models</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14710</p>
  <p><b>作者</b>：Jiashu Xu,  Mingyu Derek Ma,  Fei Wang,  Chaowei Xiao,  Muhao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve superior performance, superior performance, data, Instruction-tuned models, achieve superior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction-tuned models are trained on crowdsourcing datasets with task
instructions to achieve superior performance. However, in this work we raise
security concerns about this training paradigm. Our studies demonstrate that an
attacker can inject backdoors by issuing very few malicious instructions among
thousands of gathered data and control model behavior through data poisoning,
without even the need of modifying data instances or labels themselves. Through
such instruction attacks, the attacker can achieve over 90% attack success rate
across four commonly used NLP datasets, and cause persistent backdoors that are
easily transferred to 15 diverse datasets zero-shot. In this way, the attacker
can directly apply poisoned instructions designed for one dataset on many other
datasets. Moreover, the poisoned model cannot be cured by continual learning.
Lastly, instruction attacks show resistance to existing inference-time defense.
These findings highlight the need for more robust defenses against data
poisoning attacks in instructiontuning models and underscore the importance of
ensuring data quality in instruction crowdsourcing.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：The student becomes the master: Matching GPT3 on Scientific Factual  Error Correction</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14707</p>
  <p><b>作者</b>：Dhananjay Ashok,  Atharva Kulkarni,  Hai Pham,  Barnabás Póczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Factual Claim Correction, prohibitively high cost, creating error correction, Scientific Claim Correction, Factual Claim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the prohibitively high cost of creating error correction datasets,
most Factual Claim Correction methods rely on a powerful verification model to
guide the correction process. This leads to a significant drop in performance
in domains like Scientific Claim Correction, where good verification models do
not always exist. In this work, we introduce a claim correction system that
makes no domain assumptions and does not require a verifier but is able to
outperform existing methods by an order of magnitude -- achieving 94%
correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open
dataset, compared to the next best methods 0.5% and 1.50% respectively. Our
method leverages the power of prompting with LLMs during training to create a
richly annotated dataset that can be used for fully supervised training and
regularization. We additionally use a claim-aware decoding procedure to improve
the quality of corrected claims. Our method is competitive with the very LLM
that was used to generate the annotated dataset -- with GPT3.5 achieving 89.5%
and 60% correction accuracy on SciFact and SciFact-Open, despite using 1250
times as many parameters as our model.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：PruMUX: Augmenting Data Multiplexing with Model Compression</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14706</p>
  <p><b>作者</b>：Yushan Su,  Vishvak Murahari,  Karthik Narasimhan,  Kai Li</p>
  <p><b>备注</b>：Findings of the Association for Computational Linguistics (ACL 2023)</p>
  <p><b>关键词</b>：efficient inference, inference are critical, critical to leveraging, leveraging their capabilities, language models increase</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As language models increase in size by the day, methods for efficient
inference are critical to leveraging their capabilities for various
applications. Prior work has investigated techniques like model pruning,
knowledge distillation, and data multiplexing to increase model throughput
without sacrificing accuracy. In this paper, we combine two such methods --
structured pruning and data multiplexing -- to compound the speedup gains
obtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X
throughput improvement over BERT-base model with accuracy threshold from 80% to
74%. We further study various combinations of parameters (such as sparsity and
multiplexing factor) in the two techniques to provide a comprehensive analysis
of the tradeoff between accuracy and throughput in the resulting models. We
then propose Auto-PruMUX, a meta-level model that can predict the
high-performance parameters for pruning and multiplexing given a desired
accuracy loss budget, providing a practical method to leverage the combination
effectively.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Modeling rapid language learning by distilling Bayesian priors into  artificial neural networks</b></summary>
  <p><b>编号</b>：[427]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14701</p>
  <p><b>作者</b>：R. Thomas McCoy,  Thomas L. Griffiths</p>
  <p><b>备注</b>：21 pages plus references; 4 figures</p>
  <p><b>关键词</b>：Bayesian model, neural network, remarkably little experience, Bayesian, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans can learn languages from remarkably little experience. Developing
computational models that explain this ability has been a major challenge in
cognitive science. Bayesian models that build in strong inductive biases -
factors that guide generalization - have been successful at explaining how
humans might generalize from few examples in controlled settings but are
usually too restrictive to be tractably applied to more naturalistic data. By
contrast, neural networks have flexible representations that allow them to
learn well from naturalistic data but require many more examples than humans
receive. We show that learning from limited naturalistic data is possible with
an approach that combines the strong inductive biases of a Bayesian model with
the flexible representations of a neural network. This approach works by
distilling a Bayesian model's biases into a neural network. Like a Bayesian
model, the resulting system can learn formal linguistic patterns from a small
number of examples. Like a neural network, it can also learn aspects of English
syntax from a corpus of natural language - and it outperforms a standard neural
network at acquiring the linguistic phenomena of recursion and priming.
Bridging the divide between Bayesian models and neural networks makes it
possible to handle a broader range of learning scenarios than either approach
can handle on its own.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Can Transformers Learn to Solve Problems Recursively?</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14699</p>
  <p><b>作者</b>：Shizhuo Dylan Zhang,  Curt Tigges,  Stella Biderman,  Maxim Raginsky,  Talia Ringer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years shown, years shown promise, helping software engineers, software engineers write, engineers write programs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have in recent years shown promise for helping software
engineers write programs and even formally verify them. While semantic
information plays a crucial part in these processes, it remains unclear to what
degree popular neural architectures like transformers are capable of modeling
that information. This paper examines the behavior of neural networks learning
algorithms relevant to programs and formal verification proofs through the lens
of mechanistic interpretability, focusing in particular on structural
recursion. Structural recursion is at the heart of tasks on which symbolic
tools currently outperform neural models, like inferring semantic relations
between datatypes and emulating program behavior. We evaluate the ability of
transformer models to learn to emulate the behavior of structurally recursive
functions from input-output examples. Our evaluation includes empirical and
conceptual analyses of the limitations and capabilities of transformer models
in approximating these functions, as well as reconstructions of the ``shortcut"
algorithms the model learns. By reconstructing these algorithms, we are able to
correctly predict 91 percent of failure cases for one of the approximated
functions. Our work provides a new foundation for understanding the behavior of
neural networks that fail to solve the very tasks they are trained for.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：A Causal View of Entity Bias in (Large) Language Models</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14695</p>
  <p><b>作者</b>：Fei Wang,  Wenjie Mo,  Yiwei Wang,  Wenxuan Zhou,  Muhao Chen</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：widely affects pretrained, bias widely affects, make unfaithful predictions, Entity bias widely, mitigate entity bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity bias widely affects pretrained (large) language models, causing them
to excessively rely on (biased) parametric knowledge to make unfaithful
predictions. Although causality-inspired methods have shown great potential to
mitigate entity bias, it is hard to precisely estimate the parameters of
underlying causal models in practice. The rise of black-box LLMs also makes the
situation even worse, because of their inaccessible parameters and uncalibrated
logits. To address these problems, we propose a specific structured causal
model (SCM) whose parameters are comparatively easier to estimate. Building
upon this SCM, we propose causal intervention techniques to mitigate entity
bias for both white-box and black-box settings. The proposed causal
intervention perturbs the original entity with neighboring entities. This
intervention reduces specific biasing information pertaining to the original
entity while still preserving sufficient common predictive information from
similar entities. When evaluated on the relation extraction task, our
training-time intervention significantly improves the F1 score of RoBERTa by
5.7 points on EntRED, in which spurious shortcuts between entities and labels
are removed. Meanwhile, our in-context intervention effectively reduces the
knowledge conflicts between parametric knowledge and contextual knowledge in
GPT-3.5 and improves the F1 score by 9.14 points on a challenging test set
derived from Re-TACRED.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：ExpertPrompting: Instructing Large Language Models to be Distinguished  Experts</b></summary>
  <p><b>编号</b>：[437]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14688</p>
  <p><b>作者</b>：Benfeng Xu,  An Yang,  Junyang Lin,  Quan Wang,  Chang Zhou,  Yongdong Zhang,  Zhendong Mao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligned large language, large language model, crafting of prompts, aligned large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The answering quality of an aligned large language model (LLM) can be
drastically improved if treated with proper crafting of prompts. In this paper,
we propose ExpertPrompting to elicit the potential of LLMs to answer as
distinguished experts. We first utilize In-Context Learning to automatically
synthesize detailed and customized descriptions of the expert identity for each
specific instruction, and then ask LLMs to provide answer conditioned on such
agent background. Based on this augmented prompting strategy, we produce a new
set of instruction-following data using GPT-3.5, and train a competitive
open-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation
to show that 1) the expert data is of significantly higher quality than vanilla
answers, and 2) ExpertLLaMA outperforms existing open-source opponents and
achieves 96\% of the original ChatGPT's capability. All data and the
ExpertLLaMA model will be made publicly available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：RSRM: Reinforcement Symbolic Regression Machine</b></summary>
  <p><b>编号</b>：[460]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14656</p>
  <p><b>作者</b>：Yilong Xu,  Yang Liu,  Hao Sun</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：parsimonious math equations, symbolic regression, math, math equations, RSRM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In nature, the behaviors of many complex systems can be described by
parsimonious math equations. Automatically distilling these equations from
limited data is cast as a symbolic regression process which hitherto remains a
grand challenge. Keen efforts in recent years have been placed on tackling this
issue and demonstrated success in symbolic regression. However, there still
exist bottlenecks that current methods struggle to break when the discrete
search space tends toward infinity and especially when the underlying math
formula is intricate. To this end, we propose a novel Reinforcement Symbolic
Regression Machine (RSRM) that masters the capability of uncovering complex
math equations from only scarce data. The RSRM model is composed of three key
modules: (1) a Monte Carlo tree search (MCTS) agent that explores optimal math
expression trees consisting of pre-defined math operators and variables, (2) a
Double Q-learning block that helps reduce the feasible search space of MCTS via
properly understanding the distribution of reward, and (3) a modulated sub-tree
discovery block that heuristically learns and defines new math operators to
improve representation ability of math expression trees. Biding of these
modules yields the state-of-the-art performance of RSRM in symbolic regression
as demonstrated by multiple sets of benchmark examples. The RSRM model shows
clear superiority over several representative baseline models.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Barkour: Benchmarking Animal-level Agility with Quadruped Robots</b></summary>
  <p><b>编号</b>：[462]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14654</p>
  <p><b>作者</b>：Ken Caluwaerts,  Atil Iscen,  J. Chase Kew,  Wenhao Yu,  Tingnan Zhang,  Daniel Freeman,  Kuang-Huei Lee,  Lisa Lee,  Stefano Saliceti,  Vincent Zhuang,  Nathan Batchelor,  Steven Bohez,  Federico Casarini,  Jose Enrique Chen,  Omar Cortes,  Erwin Coumans,  Adil Dostmohamed,  Gabriel Dulac-Arnold,  Alejandro Escontrela,  Erik Frey,  Roland Hafner,  Deepali Jain,  Bauyrjan Jyenis,  Yuheng Kuang,  Edward Lee,  Linda Luu,  Ofir Nachum,  Ken Oslund,  Jason Powell,  Diego Reyes,  Francesco Romano,  Feresteh Sadeghi,  Ron Sloat,  Baruch Tabanpour,  Daniel Zheng,  Michael Neunert,  Raia Hadsell,  Nicolas Heess,  Francesco Nori,  Jeff Seto,  Carolina Parada,  Vikas Sindhwani,  Vincent Vanhoucke,  Jie Tan</p>
  <p><b>备注</b>：17 pages, 19 figures</p>
  <p><b>关键词</b>：agile locomotion strategies, Animals have evolved, evolved various agile, locomotion strategies, agility</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Animals have evolved various agile locomotion strategies, such as sprinting,
leaping, and jumping. There is a growing interest in developing legged robots
that move like their biological counterparts and show various agile skills to
navigate complex environments quickly. Despite the interest, the field lacks
systematic benchmarks to measure the performance of control policies and
hardware in agility. We introduce the Barkour benchmark, an obstacle course to
quantify agility for legged robots. Inspired by dog agility competitions, it
consists of diverse obstacles and a time based scoring mechanism. This
encourages researchers to develop controllers that not only move fast, but do
so in a controllable and versatile way. To set strong baselines, we present two
methods for tackling the benchmark. In the first approach, we train specialist
locomotion skills using on-policy reinforcement learning methods and combine
them with a high-level navigation controller. In the second approach, we
distill the specialist skills into a Transformer-based generalist locomotion
policy, named Locomotion-Transformer, that can handle various terrains and
adjust the robot's gait based on the perceived environment and robot states.
Using a custom-built quadruped robot, we demonstrate that our method can
complete the course at half the speed of a dog. We hope that our work
represents a step towards creating controllers that enable robots to reach
animal-level agility.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：A Joint Time-frequency Domain Transformer for Multivariate Time Series  Forecasting</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14649</p>
  <p><b>作者</b>：Yushu Chen,  Shengzhuo Liu,  Jinzhe Yang,  Hao Jing,  Wenlai Zhao,  Guangwen Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-frequency domain Transformer, minimizing computational demands, joint time-frequency domain, enhance predicting performance, domain Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To enhance predicting performance while minimizing computational demands,
this paper introduces a joint time-frequency domain Transformer (JTFT) for
multivariate forecasting. The method exploits the sparsity of time series in
the frequency domain using a small number of learnable frequencies to extract
temporal dependencies effectively. Alongside the frequency domain
representation, a fixed number of the most recent data points are directly
encoded in the time domain, bolstering the learning of local relationships and
mitigating the adverse effects of non-stationarity. JTFT achieves linear
complexity since the length of the internal representation remains independent
of the input sequence length. Additionally, a low-rank attention layer is
proposed to efficiently capture cross-dimensional dependencies and prevent
performance degradation due to the entanglement of temporal and channel-wise
modeling. Experiments conducted on six real-world datasets demonstrate that
JTFT outperforms state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14635</p>
  <p><b>作者</b>：Yan Zhou,  Qingkai Fang,  Yang Feng</p>
  <p><b>备注</b>：ACL 2023 main conference</p>
  <p><b>关键词</b>：translating speech signals, source language, target language, modality gap, Optimal Transport CMOT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end speech translation (ST) is the task of translating speech signals
in the source language into text in the target language. As a cross-modal task,
end-to-end ST is difficult to train with limited data. Existing methods often
try to transfer knowledge from machine translation (MT), but their performances
are restricted by the modality gap between speech and text. In this paper, we
propose Cross-modal Mixup via Optimal Transport CMOT to overcome the modality
gap. We find the alignment between speech and text sequences via optimal
transport and then mix up the sequences from different modalities at a token
level using the alignment. Experiments on the MuST-C ST benchmark demonstrate
that CMOT achieves an average BLEU of 30.0 in 8 translation directions,
outperforming previous methods. Further analysis shows CMOT can adaptively find
the alignment between modalities, which helps alleviate the modality gap
between speech and text. Code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Mixture of Prompt Experts for Generalizable and Interpretable Question  Answering</b></summary>
  <p><b>编号</b>：[476]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14628</p>
  <p><b>作者</b>：Chenglei Si,  Weijia Shi,  Chen Zhao,  Luke Zettlemoyer,  Jordan Boyd-Graber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ultimate quests, question, question types, specialized, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the ultimate quests of question answering (QA) is to deploy a system
that can answer any type of question from the users, and refrain from answering
when it does not know the answer. While recent advancements in scaling large
language models (LLMs) brought significant improvements on various QA datasets,
it remains difficult for a single model to generalize across question types
that require distinct reasoning abilities. In this paper, we first provide
empirical evidence that state-of-the-art LLMs such as Codex suffer from poor
generalizability on question types beyond those seen in the prompt. To address
this, we propose a Mixture-of-Prompt-Experts (MOPE) system that ensembles
multiple specialized LLMs. We first implement each specialized model based on
the same backbone model (Codex) but with prompts optimized for different
reasoning categories including factual, multihop, mathematical, and commonsense
reasoning. By strategically selecting the best specialized model for each given
question, our MOPE system significantly outperforms any single specialized
model on a collection of 12 QA datasets from four reasoning types. Moreover,
the attribution and agreement among specialized expert models offer greater
interpretability, allowing for better selective question answering. Our human
study further confirms that presenting the expert predictions and answer
selection process helps annotators more accurately decide when to trust the
system's output. We release all code and data to facilitate future work.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Abductive Commonsense Reasoning Exploiting Mutually Exclusive  Explanations</b></summary>
  <p><b>编号</b>：[482]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14618</p>
  <p><b>作者</b>：Wenting Zhao,  Justin T. Chiu,  Claire Cardie,  Alexander M. Rush</p>
  <p><b>备注</b>：accepted at ACL'23</p>
  <p><b>关键词</b>：aims to find, find plausible explanations, Abductive reasoning aims, Abductive reasoning, find plausible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Abductive reasoning aims to find plausible explanations for an event. This
style of reasoning is critical for commonsense tasks where there are often
multiple plausible explanations. Existing approaches for abductive reasoning in
natural language processing (NLP) often rely on manually generated annotations
for supervision; however, such annotations can be subjective and biased.
Instead of using direct supervision, this work proposes an approach for
abductive commonsense reasoning that exploits the fact that only a subset of
explanations is correct for a given context. The method uses posterior
regularization to enforce a mutual exclusion constraint, encouraging the model
to learn the distinction between fluent explanations and plausible ones. We
evaluate our approach on a diverse set of abductive reasoning datasets;
experimental results show that our approach outperforms or is comparable to
directly applying pretrained language models in a zero-shot manner and other
knowledge-augmented zero-shot methods.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：COMET-M: Reasoning about Multiple Events in Complex Sentences</b></summary>
  <p><b>编号</b>：[483]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14617</p>
  <p><b>作者</b>：Sahithya Ravi,  Raymond Ng,  Vered Shwartz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：speaker intended meaning, involves drawing commonsense, stated explicitly, speaker intended, intended meaning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the speaker's intended meaning often involves drawing
commonsense inferences to reason about what is not stated explicitly. In
multi-event sentences, it requires understanding the relationships between
events based on contextual knowledge. We propose COMET-M (Multi-Event), an
event-centric commonsense model capable of generating commonsense inferences
for a target event within a complex sentence. COMET-M builds upon COMET
(Bosselut et al., 2019), which excels at generating event-centric inferences
for simple sentences, but struggles with the complexity of multi-event
sentences prevalent in natural text. To overcome this limitation, we curate a
multi-event inference dataset of 35K human-written inferences. We trained
COMET-M on the human-written inferences and also created baselines using
automatically labeled examples. Experimental results demonstrate the
significant performance improvement of COMET-M over COMET in generating
multi-event inferences. Moreover, COMET-M successfully produces distinct
inferences for each target event, taking the complete context into
consideration. COMET-M holds promise for downstream tasks involving natural
text such as coreference resolution, dialogue, and story understanding.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Selectively Answering Ambiguous Questions</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14613</p>
  <p><b>作者</b>：Jeremy R. Cole,  Michael J.Q. Zhang,  Daniel Gillick,  Julian Martin Eisenschlos,  Bhuwan Dhingra,  Jacob Eisenstein</p>
  <p><b>备注</b>：10 pages, 5 figures, 2 pages of appendix</p>
  <p><b>关键词</b>：Trustworthy language models, Trustworthy language, answer, questions, question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trustworthy language models should abstain from answering questions when they
do not know the answer. However, the answer to a question can be unknown for a
variety of reasons. Prior research has focused on the case in which the
question is clear and the answer is unambiguous but possibly unknown. However,
the answer to a question can also be unclear due to uncertainty of the
questioner's intent or context. We investigate question answering from this
perspective, focusing on answering a subset of questions with a high degree of
accuracy, from a set of questions in which many are inherently ambiguous. In
this setting, we find that the most reliable approach to calibration involves
quantifying repetition within a set of sampled model outputs, rather than the
model's likelihood or self-verification as used in prior work. % We find this
to be the case across different types of uncertainty, varying model scales and
both with or without instruction tuning. Our results suggest that
sampling-based confidence scores help calibrate answers to relatively
unambiguous questions, with more dramatic improvements on ambiguous questions.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Inverse Reinforcement Learning with the Average Reward Criterion</b></summary>
  <p><b>编号</b>：[490]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14608</p>
  <p><b>作者</b>：Feiyang Wu,  Jingyang Ke,  Anqi Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, Reinforcement Learning, Inverse Reinforcement, IRL, IRL problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of Inverse Reinforcement Learning (IRL) with an
average-reward criterion. The goal is to recover an unknown policy and a reward
function when the agent only has samples of states and actions from an
experienced agent. Previous IRL methods assume that the expert is trained in a
discounted environment, and the discount factor is known. This work alleviates
this assumption by proposing an average-reward framework with efficient
learning algorithms. We develop novel stochastic first-order methods to solve
the IRL problem under the average-reward setting, which requires solving an
Average-reward Markov Decision Process (AMDP) as a subproblem. To solve the
subproblem, we develop a Stochastic Policy Mirror Descent (SPMD) method under
general state and action spaces that needs $\mathcal{O}(1/\varepsilon)$ steps
of gradient computation. Equipped with SPMD, we propose the Inverse Policy
Mirror Descent (IPMD) method for solving the IRL problem with a
$\mathcal{O}(1/\varepsilon^2)$ complexity. To the best of our knowledge, the
aforementioned complexity results are new in IRL. Finally, we corroborate our
analysis with numerical experiments using the MuJoCo benchmark and additional
control tasks.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Voices of Her: Analyzing Gender Differences in the AI Publication World</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14597</p>
  <p><b>作者</b>：Yiwen Ding,  Jiarui Liu,  Zhiheng Lyu,  Kun Zhang,  Bernhard Schoelkopf,  Zhijing Jin,  Rada Mihalcea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：covering diverse topics, analyzed gender bias, bias in research, covering diverse, previous studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While several previous studies have analyzed gender bias in research, we are
still missing a comprehensive analysis of gender differences in the AI
community, covering diverse topics and different development trends. Using the
AI Scholar dataset of 78K researchers in the field of AI, we identify several
gender differences: (1) Although female researchers tend to have fewer overall
citations than males, this citation difference does not hold for all
academic-age groups; (2) There exist large gender homophily in co-authorship on
AI papers; (3) Female first-authored papers show distinct linguistic styles,
such as longer text, more positive emotion words, and more catchy titles than
male first-authored papers. Our analysis provides a window into the current
demographic trends in our AI community, and encourages more gender equality and
diversity in the future. Our code and data are at
this https URL.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents</b></summary>
  <p><b>编号</b>：[503]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14590</p>
  <p><b>作者</b>：Pritika Ramu,  Sijia Wang,  Lalla Mouatadid,  Joy Rimchala,  Lifu Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：form understanding predominantly, understanding predominantly relies, necessitating extensive data, large pre-trained language, Current research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current research in form understanding predominantly relies on large
pre-trained language models, necessitating extensive data for pre-training.
However, the importance of layout structure (i.e., the spatial relationship
between the entity blocks in the visually rich document) to relation extraction
has been overlooked. In this paper, we propose REgion-Aware Relation Extraction
(RE$^2$) that leverages region-level spatial structure among the entity blocks
to improve their relation prediction. We design an edge-aware graph attention
network to learn the interaction between entities while considering their
spatial relationship defined by their region-level representations. We also
introduce a constraint objective to regularize the model towards consistency
with the inherent constraints of the relation extraction task. Extensive
experiments across various datasets, languages and domains demonstrate the
superiority of our proposed approach.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Interpretation of Time-Series Deep Models: A Survey</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14582</p>
  <p><b>作者</b>：Ziqi Zhao,  Yucheng Shi,  Shushan Wu,  Fan Yang,  Wenzhan Song,  Ninghao Liu</p>
  <p><b>备注</b>：18 pages, 3 figures, 1 table</p>
  <p><b>关键词</b>：widely researched nowadays, Deep learning models, learning models developed, Deep learning, researched nowadays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models developed for time-series associated tasks have become
more widely researched nowadays. However, due to the unintuitive nature of
time-series data, the interpretability problem -- where we understand what is
under the hood of these models -- becomes crucial. The advancement of similar
studies in computer vision has given rise to many post-hoc methods, which can
also shed light on how to explain time-series models. In this paper, we present
a wide range of post-hoc interpretation methods for time-series models based on
backpropagation, perturbation, and approximation. We also want to bring focus
onto inherently interpretable models, a novel category of interpretation where
human-understandable information is designed within the models. Furthermore, we
introduce some common evaluation metrics used for the explanations, and propose
several directions of future researches on the time-series interpretability
problem. As a highlight, our work summarizes not only the well-established
interpretation methods, but also a handful of fairly recent and under-developed
techniques, which we hope to capture their essence and spark future endeavours
to innovate and improvise.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person</b></summary>
  <p><b>编号</b>：[511]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14580</p>
  <p><b>作者</b>：Lucas Rafael Stefanel Gris,  Ricardo Marcacini,  Arnaldo Candido Junior,  Edresson Casanova,  Anderson Soares,  Sandra Maria Aluísio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：involving human-machine interactions, human-machine interactions, recently Whisper ASR, play a key, key role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic speech recognition (ASR) systems play a key role in applications
involving human-machine interactions. Despite their importance, ASR models for
the Portuguese language proposed in the last decade have limitations in
relation to the correct identification of punctuation marks in automatic
transcriptions, which hinder the use of transcriptions by other systems,
models, and even by humans. However, recently Whisper ASR was proposed by
OpenAI, a general-purpose speech recognition model that has generated great
expectations in dealing with such limitations. This chapter presents the first
study on the performance of Whisper for punctuation prediction in the
Portuguese language. We present an experimental evaluation considering both
theoretical aspects involving pausing points (comma) and complete ideas
(exclamation, question, and fullstop), as well as practical aspects involving
transcript-based topic modeling - an application dependent on punctuation marks
for promising performance. We analyzed experimental results from videos of
Museum of the Person, a virtual museum that aims to tell and preserve people's
life histories, thus discussing the pros and cons of Whisper in a real-world
scenario. Although our experiments indicate that Whisper achieves
state-of-the-art results, we conclude that some punctuation marks require
improvements, such as exclamation, semicolon and colon.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCiM DNN Accelerators</b></summary>
  <p><b>编号</b>：[525]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14561</p>
  <p><b>作者</b>：Yifan Qin,  Zheyu Yan,  Wujie Wen,  Xiaobo Sharon Hu,  Yiyu Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：utilizing non-volatile memory, accelerating deep neural, deep neural networks, utilizing non-volatile, non-volatile memory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compute-in-Memory (CiM) utilizing non-volatile memory (NVM) devices presents
a highly promising and efficient approach for accelerating deep neural networks
(DNNs). By concurrently storing network weights and performing matrix
operations within the same crossbar structure, CiM accelerators offer DNN
inference acceleration with minimal area requirements and exceptional energy
efficiency. However, the stochasticity and intrinsic variations of NVM devices
often lead to performance degradation, such as reduced classification accuracy,
compared to expected outcomes. Although several methods have been proposed to
mitigate device variation and enhance robustness, most of them rely on overall
modulation and lack constraints on the training process. Drawing inspiration
from the negative feedback mechanism, we introduce a novel training approach
that uses a multi-exit mechanism as negative feedback to enhance the
performance of DNN models in the presence of device variation. Our negative
feedback training method surpasses state-of-the-art techniques by achieving an
impressive improvement of up to 12.49% in addressing DNN robustness against
device variation.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented  Dialogues and Annotations</b></summary>
  <p><b>编号</b>：[526]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14556</p>
  <p><b>作者</b>：Tiziano Labruna,  Sofia Brenna,  Andrea Zaninello,  Bernardo Magnini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exhibited unprecedented capabilities, producing high-quality text, Large pre-trained language, pre-trained language models, Large pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models have exhibited unprecedented capabilities
in producing high-quality text via prompting techniques. This fact introduces
new possibilities for data collection and annotation, particularly in
situations where such data is scarce, complex to gather, expensive, or even
sensitive. In this paper, we explore the potential of these models to generate
and annotate goal-oriented dialogues, and conduct an in-depth analysis to
evaluate their quality. Our experiments employ ChatGPT, and encompass three
categories of goal-oriented dialogues (task-oriented, collaborative, and
explanatory), two generation modes (interactive and one-shot), and two
languages (English and Italian). Based on extensive human-based evaluations, we
demonstrate that the quality of generated dialogues and annotations is on par
with those generated by humans.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：All Roads Lead to Rome? Exploring the Invariance of Transformers'  Representations</b></summary>
  <p><b>编号</b>：[527]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14555</p>
  <p><b>作者</b>：Yuxin Ren,  Qipeng Guo,  Zhijing Jin,  Shauli Ravfogel,  Mrinmaya Sachan,  Bernhard Schölkopf,  Ryan Cotterell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bring propelling advances, NLP tasks, models bring propelling, Transformer models bring, bring propelling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer models bring propelling advances in various NLP tasks, thus
inducing lots of interpretability research on the learned representations of
the models. However, we raise a fundamental question regarding the reliability
of the representations. Specifically, we investigate whether transformers learn
essentially isomorphic representation spaces, or those that are sensitive to
the random seeds in their pretraining process. In this work, we formulate the
Bijection Hypothesis, which suggests the use of bijective methods to align
different models' representation spaces. We propose a model based on invertible
neural networks, BERT-INN, to learn the bijection more effectively than other
existing bijective methods such as the canonical correlation analysis (CCA). We
show the advantage of BERT-INN both theoretically and through extensive
experiments, and apply it to align the reproduced BERT embeddings to draw
insights that are meaningful to the interpretability research. Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and  Legal Implications</b></summary>
  <p><b>编号</b>：[528]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14553</p>
  <p><b>作者</b>：Micah Musser,  Andrew Lohn,  James X. Dempsey,  Jonathan Spring,  Ram Shankar Siva Kumar,  Brenda Leong,  Christina Liaghati,  Cindy Martinez,  Crystal D. Grant,  Daniel Rohrer,  Heather Frase,  Jonathan Elliott,  John Bansemer,  Mikel Rodriguez,  Mitt Regan,  Rumman Chowdhury,  Stefan Hermanek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Security and Emerging, Emerging Technology, Cyber Policy Center, Stanford Cyber Policy, Center for Security</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In July 2022, the Center for Security and Emerging Technology (CSET) at
Georgetown University and the Program on Geopolitics, Technology, and
Governance at the Stanford Cyber Policy Center convened a workshop of experts
to examine the relationship between vulnerabilities in artificial intelligence
systems and more traditional types of software vulnerabilities. Topics
discussed included the extent to which AI vulnerabilities can be handled under
standard cybersecurity processes, the barriers currently preventing the
accurate sharing of information about AI vulnerabilities, legal issues
associated with adversarial attacks on AI systems, and potential areas where
government support could improve AI vulnerability management and mitigation.
This report is meant to accomplish two things. First, it provides a
high-level discussion of AI vulnerabilities, including the ways in which they
are disanalogous to other types of vulnerabilities, and the current state of
affairs regarding information sharing and legal oversight of AI
vulnerabilities. Second, it attempts to articulate broad recommendations as
endorsed by the majority of participants at the workshop.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Sources of Hallucination by Large Language Models on Inference Tasks</b></summary>
  <p><b>编号</b>：[529]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14552</p>
  <p><b>作者</b>：Nick McKenna,  Tianyi Li,  Liang Cheng,  Mohammad Javad Hosseini,  Mark Johnson,  Mark Steedman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Natural Language, Large Language, capable of Natural, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are claimed to be capable of Natural Language
Inference (NLI), necessary for applied tasks like question answering and
summarization, yet this capability is under-explored. We present a series of
behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which
probe their behavior using controlled experiments. We establish two factors
which predict much of their performance, and propose that these are major
sources of hallucination in generative LLM. First, the most influential factor
is memorization of the training data. We show that models falsely label NLI
test samples as entailing when the hypothesis is attested in the training text,
regardless of the premise. We further show that named entity IDs are used as
"indices" to access the memorized data. Second, we show that LLMs exploit a
further corpus-based heuristic using the relative frequencies of words. We show
that LLMs score significantly worse on NLI test samples which do not conform to
these factors than those which do; we also discuss a tension between the two
factors, and a performance trade-off.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Sequence Modeling is a Robust Contender for Offline Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[531]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14550</p>
  <p><b>作者</b>：Prajjwal Bhargava,  Rohan Chitnis,  Alborz Geramifard,  Shagun Sodhani,  Amy Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Offline reinforcement learning, Imitation Learning, Sequence Modeling, reinforcement learning, static dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline reinforcement learning (RL) allows agents to learn effective,
return-maximizing policies from a static dataset. Three major paradigms for
offline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A key
open question is: which paradigm is preferred under what conditions? We study
this question empirically by exploring the performance of representative
algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and
Decision Transformer (DT) -- across the commonly used D4RL and Robomimic
benchmarks. We design targeted experiments to understand their behavior
concerning data suboptimality and task complexity. Our key findings are: (1)
Sequence Modeling requires more data than Q-Learning to learn competitive
policies but is more robust; (2) Sequence Modeling is a substantially better
choice than both Q-Learning and Imitation Learning in sparse-reward and
low-quality data settings; and (3) Sequence Modeling and Imitation Learning are
preferable as task horizon increases, or when data is obtained from suboptimal
human demonstrators. Based on the overall strength of Sequence Modeling, we
also investigate architectural choices and scaling trends for DT on Atari and
D4RL and make design recommendations. We find that scaling the amount of data
for DT by 5x gives a 2.5x average score improvement on Atari.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural  Machine Translation</b></summary>
  <p><b>编号</b>：[537]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14538</p>
  <p><b>作者</b>：Frédéric Odermatt,  Béni Egressy,  Roger Wattenhofer</p>
  <p><b>备注</b>：14 pages, 7 figures</p>
  <p><b>关键词</b>：paper presents, Cascade Beam Search, Beam Search, terminology constraints, translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a plug-and-play approach for translation with terminology
constraints. Terminology constraints are an important aspect of many modern
translation pipelines. In both specialized domains and newly emerging domains
(such as the COVID-19 pandemic), accurate translation of technical terms is
crucial. Recent approaches often train models to copy terminologies from the
input into the output sentence by feeding the target terminology along with the
input. But this requires expensive training whenever the underlying language
model is changed or the system should specialize to a new domain. We propose
Cascade Beam Search, a plug-and-play terminology-forcing approach that requires
no training. Cascade Beam Search has two parts: 1) logit manipulation to
increase the probability of target terminologies and 2) a cascading beam setup
based on grid beam search, where beams are grouped by the number of
terminologies they contain. We evaluate the performance of our approach by
competing against the top submissions of the WMT21 terminology translation
task. Our plug-and-play approach performs on par with the winning submissions
without using a domain-specific language model and with no additional training.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Disincentivizing Polarization in Social Networks</b></summary>
  <p><b>编号</b>：[538]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14537</p>
  <p><b>作者</b>：Christian Borgs,  Jennifer Chayes,  Christian Ikeokwu,  Ellen Vitercik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：filter bubbles, algorithmic personalization drives, social networks, personalization drives users, content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>On social networks, algorithmic personalization drives users into filter
bubbles where they rarely see content that deviates from their interests. We
present a model for content curation and personalization that avoids filter
bubbles, along with algorithmic guarantees and nearly matching lower bounds. In
our model, the platform interacts with $n$ users over $T$ timesteps, choosing
content for each user from $k$ categories. The platform receives stochastic
rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the
intuition that if some users are shown some category of content, then all users
should see at least a small amount of that content. We first analyze a naive
formalization of this intuition and show it has unintended consequences: it
leads to ``tyranny of the majority'' with the burden of diversification borne
disproportionately by those with minority interests. This leads us to our model
which distributes this burden more equitably. We require that the probability
any user is shown a particular type of content is at least $\gamma$ times the
average probability all users are shown that type of content. Full
personalization corresponds to $\gamma = 0$ and complete homogenization
corresponds to $\gamma = 1$; hence, $\gamma$ encodes a hard cap on the level of
personalization. We also analyze additional formulations where the platform can
exceed its cap but pays a penalty proportional to its constraint violation. We
provide algorithmic guarantees for optimizing recommendations subject to these
constraints. These include nearly matching upper and lower bounds for the
entire range of $\gamma \in [0,1]$ showing that the reward of a multi-agent
variant of UCB is nearly optimal. Using real-world preference data, we
empirically verify that under our model, users share the burden of
diversification with only minor utility loss under our constraints.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Detecting Propaganda Techniques in Code-Switched Social Media Text</b></summary>
  <p><b>编号</b>：[541]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14534</p>
  <p><b>作者</b>：Muhammad Umar Salman,  Asif Hanif,  Shady Shehata,  Preslav Nakov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intended to influence, influence the opinions, public to promote, Propaganda, propaganda detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Propaganda is a form of communication intended to influence the opinions and
the mindset of the public to promote a particular agenda. With the rise of
social media, propaganda has spread rapidly, leading to the need for automatic
propaganda detection systems. Most work on propaganda detection has focused on
high-resource languages, such as English, and little effort has been made to
detect propaganda for low-resource languages. Yet, it is common to find a mix
of multiple languages in social media communication, a phenomenon known as
code-switching. Code-switching combines different languages within the same
text, which poses a challenge for automatic systems. With this in mind, here we
propose the novel task of detecting propaganda techniques in code-switched
text. To support this task, we create a corpus of 1,030 texts code-switching
between English and Roman Urdu, annotated with 20 propaganda techniques, which
we make publicly available. We perform a number of experiments contrasting
different experimental setups, and we find that it is important to model the
multilinguality directly (rather than using translation) as well as to use the
right fine-tuning strategy. The code and the dataset are publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：CongFu: Conditional Graph Fusion for Drug Synergy Prediction</b></summary>
  <p><b>编号</b>：[549]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14517</p>
  <p><b>作者</b>：Oleksii Tsepa,  Bohdan Naida,  Bo Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：amplified combined effect, optimizing therapeutic outcomes, Drug synergy, presents a critical, therapeutic outcomes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Drug synergy, characterized by the amplified combined effect of multiple
drugs, presents a critical phenomenon for optimizing therapeutic outcomes.
However, limited data on drug synergy, arising from the vast number of possible
drug combinations and computational costs, motivate the need for predictive
methods. In this work, we introduce CongFu, a novel Conditional Graph Fusion
Layer, designed to predict drug synergy. CongFu employs an attention mechanism
and a bottleneck to extract local graph contexts and conditionally fuse graph
data within a global context. Its modular architecture enables flexible
replacement of layer modules, including readouts and graph encoders,
facilitating customization for diverse applications. To evaluate the
performance of CongFu, we conduct comprehensive experiments on four datasets,
encompassing three distinct setups for drug synergy prediction. Remarkably,
CongFu achieves state-of-the-art results on 11 out of 12 benchmark datasets,
demonstrating its ability to capture intricate patterns of drug synergy.
Through extensive ablation studies, we validate the significance of individual
layer components, affirming their contributions to overall predictive
performance. By addressing the challenge of predicting drug synergy in untested
drug pairs, CongFu opens new avenues for optimizing drug combinations and
advancing personalized medicine.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：RetICL: Sequential Retrieval of In-Context Examples with Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[553]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14502</p>
  <p><b>作者</b>：Alexander Scarlatos,  Andrew Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perform specific tasks, recent developments, language models focus, perform specific, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many recent developments in large language models focus on prompting them to
perform specific tasks. One effective prompting method is in-context learning,
where the model performs a (possibly new) generation/prediction task given one
(or more) examples. Past work has shown that the choice of examples can make a
large impact on task performance. However, finding good examples is not
straightforward since the definition of a representative group of examples can
vary greatly depending on the task. While there are many existing methods for
selecting in-context examples, they generally score examples independently,
ignoring the dependency between them and the order in which they are provided
to the large language model. In this work, we propose Retrieval for In-Context
Learning (RetICL), a learnable method for modeling and optimally selecting
examples sequentially for in-context learning. We frame the problem of
sequential example selection as a Markov decision process, design an example
retriever model using an LSTM, and train it using proximal policy optimization
(PPO). We validate RetICL on math problem solving datasets and show that it
outperforms both heuristic and learnable baselines, and achieves
state-of-the-art accuracy on the TabMWP dataset. We also use case studies to
show that RetICL implicitly learns representations of math problem solving
strategies.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Self-Polish: Enhance Reasoning in Large Language Models via Problem  Refinement</b></summary>
  <p><b>编号</b>：[556]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14497</p>
  <p><b>作者</b>：Zhiheng Xi,  Senjie Jin,  Yuhao Zhou,  Rui Zheng,  Songyang Gao,  Tao Gui,  Qi Zhang,  Xuanjing Huang</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：large language models, rationales and answers, shed new light, light on enhancing, capabilities of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting methods such as Chain-of-Thought (CoT) have shed new light on
enhancing the reasoning capabilities of large language models, and researchers
have extensively explored the generation process of rationales and answers.
However, they have overlooked the potential challenges posed by the poor
quality of reasoning problems, which may influence the reasoning performance
significantly. In this work, we propose Self-Polish (SP), a novel method that
facilitates the model's problem-solving process by prompting them to
progressively refine the given problems to be more comprehensible and solvable.
Specifically, the method teaches models to eliminate irrelevant information,
rearrange the logic structure and organize local conditions into new ones
parallelly. SP is orthogonal to all other prompting methods, making it
convenient to integrate with state-of-the-art techniques for further
improvement. We conduct thorough experiments on five benchmarks to illustrate
the effectiveness of the proposed method. For example, with Text-davinci-003,
our method boosts the performance of standard few-shot prompting by $8.0\%$ on
GSM8K and $17.8\%$ on MultiArith; it also improves the performance of CoT by
$6.0\%$ on GSM8K and $6.0\%$ on MathQA, respectively. Furthermore, our method
also showcases impressive performance on robustness evaluation.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：BAND: Biomedical Alert News Dataset</b></summary>
  <p><b>编号</b>：[567]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14480</p>
  <p><b>作者</b>：Zihao Fu,  Meiru Zhang,  Zaiqiao Meng,  Yannan Shen,  Anya Okhmatovskaia,  David Buckeridge,  Nigel Collier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Infectious disease outbreaks, disease outbreaks continue, health and well-being, continue to pose, pose a significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Infectious disease outbreaks continue to pose a significant threat to human
health and well-being. To improve disease surveillance and understanding of
disease spread, several surveillance systems have been developed to monitor
daily news alerts and social media. However, existing systems lack thorough
epidemiological analysis in relation to corresponding alerts or news, largely
due to the scarcity of well-annotated reports data. To address this gap, we
introduce the Biomedical Alert News Dataset (BAND), which includes 1,508
samples from existing reported news articles, open emails, and alerts, as well
as 30 epidemiology-related questions. These questions necessitate the model's
expert reasoning abilities, thereby offering valuable insights into the
outbreak of the disease. The BAND dataset brings new challenges to the NLP
world, requiring better disguise capability of the content and the ability to
infer important information. We provide several benchmark tasks, including
Named Entity Recognition (NER), Question Answering (QA), and Event Extraction
(EE), to show how existing models are capable of handling these tasks in the
epidemiology domain. To the best of our knowledge, the BAND corpus is the
largest corpus of well-annotated biomedical outbreak alert news with
elaborately designed questions, making it a valuable resource for
epidemiologists and NLP researchers alike.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Towards Massively Multi-domain Multilingual Readability Assessment</b></summary>
  <p><b>编号</b>：[573]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14463</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Mohit Chandra,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massively multi-domain multilingual, automatic readability assessment, multi-domain multilingual dataset, massively multi-domain, multi-domain multilingual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ReadMe++, a massively multi-domain multilingual dataset for
automatic readability assessment. Prior work on readability assessment has been
mostly restricted to the English language and one or two text domains.
Additionally, the readability levels of sentences used in many previous
datasets are assumed on the document-level other than sentence-level, which
raises doubt about the quality of previous evaluations. We address those gaps
in the literature by providing an annotated dataset of 6,330 sentences in
Arabic, English, and Hindi collected from 64 different domains of text. Unlike
previous datasets, ReadMe++ offers more domain and language diversity and is
manually annotated at a sentence level using the Common European Framework of
Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework
that reduces subjectivity in annotation. Our experiments demonstrate that
models fine-tuned using ReadMe++ achieve strong cross-lingual transfer
capabilities and generalization to unseen domains. ReadMe++ will be made
publicly available to the research community.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Enhancing Generation through Summarization Duality and Explicit Outline  Control</b></summary>
  <p><b>编号</b>：[576]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14459</p>
  <p><b>作者</b>：Yunzhe Li,  Qian Chen,  Weixiang Yan,  Wen Wang,  Qinglin Zhang,  Hari Sundaram</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：Automatically open-ended long, open-ended long text, poses significant challenges, significant challenges due, long text generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically open-ended long text generation poses significant challenges
due to semantic incoherence and plot implausibility. Previous works usually
alleviate this problem through outlines in the form of short phrases or
abstractive signals by designing unsupervised tasks, which tend to be unstable
and weakly interpretable.
Assuming that a summary serves as a mature outline, we introduce a two-stage,
summary-enhanced outline supervised generation framework. This framework
leverages the dual characteristics of the summarization task to improve outline
prediction, resulting in more explicit and plausible outlines. Furthermore, we
identify an underutilization issue in outline-based generation with both
standard pretrained language models (e.g., GPT-2, BART) and large language
models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit
outline control method for more effective utilization of generated outlines.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Having Beer after Prayer? Measuring Cultural Bias in Large Language  Models</b></summary>
  <p><b>编号</b>：[579]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14456</p>
  <p><b>作者</b>：Tarek Naous,  Michael J. Ryan,  Wei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models culturally biased, culturally biased, language models, language models culturally, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Are language models culturally biased? It is important that language models
conform to the cultural aspects of the communities they serve. However, we show
in this paper that language models suffer from a significant bias towards
Western culture when handling and generating text in Arabic, often preferring,
and producing Western-fitting content as opposed to the relevant Arab content.
We quantify this bias through a likelihood scoring-based metric using naturally
occurring contexts that we collect from online social media. Our experiments
reveal that both Arabic monolingual and multilingual models exhibit bias
towards Western culture in eight different cultural aspects: person names,
food, clothing, location, literature, beverage, religion, and sports. Models
also tend to exhibit more bias when prompted with Arabic sentences that are
more linguistically aligned with English. These findings raise concerns about
the cultural relevance of current language models. Our analyses show that
providing culture-indicating tokens or culturally-relevant demonstrations to
the model can help in debiasing.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Kernel Interpolation with Sparse Grids</b></summary>
  <p><b>编号</b>：[582]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14451</p>
  <p><b>作者</b>：Mohit Yadav,  Daniel Sheldon,  Cameron Musco</p>
  <p><b>备注</b>：Accepted at Neural Information Processing Systems (NeurIPS) 2022</p>
  <p><b>关键词</b>：accelerates Gaussian process, accelerates Gaussian, Gaussian process, fast linear algebra, kernel covariance function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured kernel interpolation (SKI) accelerates Gaussian process (GP)
inference by interpolating the kernel covariance function using a dense grid of
inducing points, whose corresponding kernel matrix is highly structured and
thus amenable to fast linear algebra. Unfortunately, SKI scales poorly in the
dimension of the input points, since the dense grid size grows exponentially
with the dimension. To mitigate this issue, we propose the use of sparse grids
within the SKI framework. These grids enable accurate interpolation, but with a
number of points growing more slowly with dimension. We contribute a novel
nearly linear time matrix-vector multiplication algorithm for the sparse grid
kernel matrix. Next, we describe how sparse grids can be combined with an
efficient interpolation scheme based on simplices. With these changes, we
demonstrate that SKI can be scaled to higher dimensions while maintaining
accuracy.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust  Conversational Understanding</b></summary>
  <p><b>编号</b>：[584]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14449</p>
  <p><b>作者</b>：Zheng Chen,  Ziyan Jiang,  Fan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Google Assistant, Collaborative User Index, user index, reduce user frictions, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to
understand queries with defects to ensure robust conversational understanding
and reduce user frictions. The defective queries are often induced by user
ambiguities and mistakes, or errors in the automatic speech recognition (ASR)
and natural language understanding (NLU).
Personalized query rewriting (personalized QR) targets reducing defects in
the torso and tail user query traffic, and it typically relies on an index of
past successful user interactions with the conversational AI. This paper
presents our "Collaborative Query Rewriting" approach that focuses on rewriting
novel user interactions unseen in the user history. This approach builds a
"user Feedback Interaction Graph" (FIG) consisting of historical user-entity
interactions, and leverages multi-hop customer affinity to enrich each user's
index (i.e. the Collaborative User Index) that would help cover future unseen
defective queries. To counteract the precision degradation from the enlarged
index, we introduced additional transformer layers to the L1 retrieval model
and added multi-hop affinity and guardrail features to the L2 re-ranking model.
Given the production constraints of storage cost and runtime retrieval
latency, managing the size of the Collaborative User Index is important. As the
user index can be pre-computed, we explored using a Large Language Model (LLM)
for multi-hop customer affinity retrieval on the Video/Music domains. In
particular, this paper looked into the Dolly-V2 7B model. Given limited user
index size, We found the user index derived from fine-tuned Dolly-V2 generation
significantly enhanced coverage of unseen user interactions. Consequently, this
boosted QR performance on unseen user interactions compared to the graph
traversal based user index.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Image Manipulation via Multi-Hop Instructions -- A New Dataset and  Weakly-Supervised Neuro-Symbolic Approach</b></summary>
  <p><b>编号</b>：[588]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14410</p>
  <p><b>作者</b>：Harman Singh,  Poorva Garg,  Mohit Gupta,  Kevin Shah,  Arnab Kumar Mondal,  Dinesh Khandelwal,  Parag Singla,  Dinesh Garg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Symbolic Concept Learning, natural language text, Neuro Symbolic Concept, multi-modal spaces, multiple AI applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are interested in image manipulation via natural language text -- a task
that is useful for multiple AI applications but requires complex reasoning over
multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning
(NSCL), which has been quite effective for the task of Visual Question
Answering (VQA), for the task of image manipulation. Our system referred to as
NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and
only requires weak supervision in the form of annotated data for VQA. NeuroSIM
parses an instruction into a symbolic program, based on a Domain Specific
Language (DSL) comprising of object attributes and manipulation operations,
that guides its execution. We create a new dataset for the task, and extensive
experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA
baselines that make use of supervised data for manipulation.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Deep Learning based Forecasting: a case study from the online fashion  industry</b></summary>
  <p><b>编号</b>：[590]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14406</p>
  <p><b>作者</b>：Manuel Kunz,  Stefan Birr,  Mones Raslan,  Lei Ma,  Zhen Li,  Adele Gouttes,  Mateusz Koren,  Tofigh Naghibi,  Johannes Stephan,  Mariia Bulycheva,  Matthias Grzeschik,  Armin Kekić,  Michael Narodovitch,  Kashif Rasul,  Julian Sieber,  Tim Januschowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：online fashion industry, data-driven forecasting models, fixed inventory assumption, fashion industry, industry set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Demand forecasting in the online fashion industry is particularly amendable
to global, data-driven forecasting models because of the industry's set of
particular challenges. These include the volume of data, the irregularity, the
high amount of turn-over in the catalog and the fixed inventory assumption.
While standard deep learning forecasting approaches cater for many of these,
the fixed inventory assumption requires a special treatment via controlling the
relationship between price and demand closely. In this case study, we describe
the data and our modelling approach for this forecasting problem in detail and
present empirical results that highlight the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：NeuralMatrix: Moving Entire Neural Networks to General Matrix  Multiplication for Efficient Inference</b></summary>
  <p><b>编号</b>：[591]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14405</p>
  <p><b>作者</b>：Ruiqi Sun,  Jie Zhao,  Xin He,  Yiran Li,  An Zou</p>
  <p><b>备注</b>：12 pages, 4 figures, Submitted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023)</p>
  <p><b>关键词</b>：deep neural networks, versatile deep neural, single general matrix, general matrix multiplication, introduce NeuralMatrix</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we introduce NeuralMatrix, a novel framework that enables the
computation of versatile deep neural networks (DNNs) on a single general matrix
multiplication (GEMM) accelerator. The proposed approach overcomes the
specificity limitations of ASIC-based accelerators while achieving
application-specific acceleration levels compared to general-purpose processors
such as CPUs and GPUs. We address the challenges of mapping both linear and
nonlinear operations in DNN computation to general matrix multiplications and
the impact of using a GEMM accelerator on DNN inference accuracy. Extensive
experiments are conducted on various DNN models from three popular categories
(i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results
demonstrate that DNNs suffer only up to a 2.02% accuracy loss after being
converted to general matrix multiplication, while achieving 113x to 19.44x
improvements in throughput per power compared to CPUs and GPUs.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Layer-adaptive Structured Pruning Guided by Latency</b></summary>
  <p><b>编号</b>：[592]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14403</p>
  <p><b>作者</b>：Siyuan Pan,  Linna Zhang,  Jie Zhang,  Xiaoshuang Li,  Liang Hou,  Xiaobing Tu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2010.07611, arXiv:2110.10811 by other authors</p>
  <p><b>关键词</b>：simplify network architecture, improve inference speed, pruning, inference speed, Structured pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured pruning can simplify network architecture and improve inference
speed. Combined with the underlying hardware and inference engine in which the
final model is deployed, better results can be obtained by using latency
collaborative loss function to guide network pruning together. Existing pruning
methods that optimize latency have demonstrated leading performance, however,
they often overlook the hardware features and connection in the network. To
address this problem, we propose a global importance score SP-LAMP(Structured
Pruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance
score LAMP from unstructured pruning to structured pruning. In SP-LAMP, each
layer includes a filter with an SP-LAMP score of 1, and the remaining filters
are grouped. We utilize a group knapsack solver to maximize the SP-LAMP score
under latency constraints. In addition, we improve the strategy of collect the
latency to make it more accurate. In particular, for ResNet50/ResNet18 on
ImageNet and CIFAR10, SP-LAMP is 1.28x/8.45x faster with +1.7%/-1.57% top-1
accuracy changed, respectively. Experimental results in ResNet56 on CIFAR10
demonstrate that our algorithm achieves lower latency compared to alternative
approaches while ensuring accuracy and FLOPs.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Towards credible visual model interpretation with path attribution</b></summary>
  <p><b>编号</b>：[596]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14395</p>
  <p><b>作者</b>：Naveed Akhtar,  Muhammad A. A. K. Jalwana</p>
  <p><b>备注</b>：ICML'23 paper (text improved for CV community)</p>
  <p><b>关键词</b>：visual model interpretation, interpretation tools due, post-hoc model interpretation, model interpretation tools, attribution framework stands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originally inspired by game-theory, path attribution framework stands out
among the post-hoc model interpretation tools due to its axiomatic nature.
However, recent developments show that this framework can still suffer from
counter-intuitive results. Moreover, specifically for deep visual models, the
existing path-based methods also fall short on conforming to the original
intuitions that are the basis of the claimed axiomatic properties of this
framework. We address these problems with a systematic investigation, and
pinpoint the conditions in which the counter-intuitive results can be avoided
for deep visual model interpretation with the path attribution strategy. We
also devise a scheme to preclude the conditions in which visual model
interpretation can invalidate the axiomatic properties of path attribution.
These insights are combined into a method that enables reliable visual model
interpretation. Our findings are establish empirically with multiple datasets,
models and evaluation metrics. Extensive experiments show a consistent
performance gain of our method over the baselines.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Unsupervised Spiking Neural Network Model of Prefrontal Cortex to study  Task Switching with Synaptic deficiency</b></summary>
  <p><b>编号</b>：[597]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2305.14394</p>
  <p><b>作者</b>：Ashwin Viswanathan Kannan,  Goutam Mylavarapu,  Johnson P Thomas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Spiking Neural Networks, Prefrontal Cortex, Neural Networks, understand how neurons, neurons adapt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we build a computational model of Prefrontal Cortex (PFC)
using Spiking Neural Networks (SNN) to understand how neurons adapt and respond
to tasks switched under short and longer duration of stimulus changes. We also
explore behavioral deficits arising out of the PFC lesions by simulating
lesioned states in our Spiking architecture model. Although there are some
computational models of the PFC, SNN's have not been used to model them. In
this study, we use SNN's having parameters close to biologically plausible
values and train the model using unsupervised Spike Timing Dependent Plasticity
(STDP) learning rule. Our model is based on connectionist architectures and
exhibits neural phenomena like sustained activity which helps in generating
short-term or working memory. We use these features to simulate lesions by
deactivating synaptic pathways and record the weight adjustments of learned
patterns and capture the accuracy of learning tasks in such conditions. All our
experiments are trained and recorded using a real-world Fashion MNIST (FMNIST)
dataset and through this work, we bridge the gap between bio-realistic models
and those that perform well in pattern recognition tasks</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【梳理】陆奇最新演讲实录：我的大模型世界观</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-05-25)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-05-25)"/></a><div class="content"><a class="title" href="/2023/05/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-05-25)">Arxiv每日速递(2023-05-25)</a><time datetime="2023-05-25T00:41:53.413Z" title="发表于 2023-05-25 08:41:53">2023-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【梳理】陆奇最新演讲实录：我的大模型世界观"/></a><div class="content"><a class="title" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观">【梳理】陆奇最新演讲实录：我的大模型世界观</a><time datetime="2023-05-07T11:07:45.000Z" title="发表于 2023-05-07 19:07:45">2023-05-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)"><img src="https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="变分自编码器(Variational AutoEncoder)"/></a><div class="content"><a class="title" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)">变分自编码器(Variational AutoEncoder)</a><time datetime="2023-05-05T11:28:37.000Z" title="发表于 2023-05-05 19:28:37">2023-05-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformers.generation.GenerationMixin"/></a><div class="content"><a class="title" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin">transformers.generation.GenerationMixin</a><time datetime="2023-04-08T13:42:45.000Z" title="发表于 2023-04-08 21:42:45">2023-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范"><img src="https://openaicom.imgix.net/8d14e8f0-e267-4b8b-a9f2-a79120808f5a/chatgpt.jpg?auto=compress%2Cformat&amp;fit=min&amp;fm=jpg&amp;q=80&amp;rect=0%2C0%2C2048%2C2048&amp;w=3200" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【转载】ChatGPT 标注指南：任务、数据与规范"/></a><div class="content"><a class="title" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范">【转载】ChatGPT 标注指南：任务、数据与规范</a><time datetime="2023-03-27T14:35:45.000Z" title="发表于 2023-03-27 22:35:45">2023-03-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>