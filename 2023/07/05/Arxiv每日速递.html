<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-07-05) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新551篇论文，其中：  143篇计算机视觉（cs.CV） 58篇自然语言处理（cs.CL） 198篇机器学习（cs.LG） 122篇人工智能（cs.AI）  计算机视觉    1. 标题：Real-time Monocular Full-body Captu">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-07-05)">
<meta property="og:url" content="http://louishsu.xyz/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新551篇论文，其中：  143篇计算机视觉（cs.CV） 58篇自然语言处理（cs.CL） 198篇机器学习（cs.LG） 122篇人工智能（cs.AI）  计算机视觉    1. 标题：Real-time Monocular Full-body Captu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-07-05T00:51:54.567Z">
<meta property="article:modified_time" content="2023-07-05T00:53:25.419Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-05 08:53:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-07-05)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-05T00:51:54.567Z" title="发表于 2023-07-05 08:51:54">2023-07-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-05T00:53:25.419Z" title="更新于 2023-07-05 08:53:25">2023-07-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">33.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>202分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新551篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">143篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">58篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">198篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">122篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Real-time Monocular Full-body Capture in World Space via Sequential  Proxy-to-Motion Learning</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01200</p>
  <p><b>作者</b>：Yuxiang Zhang,  Hongwen Zhang,  Liangxiao Hu,  Hongwei Yi,  Shengping Zhang,  Yebin Liu</p>
  <p><b>备注</b>：Project Page: this https URL</p>
  <p><b>关键词</b>：recently shown promising, world space, shown promising results, data-driven manner, recently shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning-based approaches to monocular motion capture have recently shown
promising results by learning to regress in a data-driven manner. However, due
to the challenges in data collection and network designs, it remains
challenging for existing solutions to achieve real-time full-body capture while
being accurate in world space. In this work, we contribute a sequential
proxy-to-motion learning scheme together with a proxy dataset of 2D skeleton
sequences and 3D rotational motions in world space. Such proxy data enables us
to build a learning-based network with accurate full-body supervision while
also mitigating the generalization issues. For more accurate and physically
plausible predictions, a contact-aware neural motion descent module is proposed
in our network so that it can be aware of foot-ground contact and motion
misalignment with the proxy observations. Additionally, we share the body-hand
context information in our network for more compatible wrist poses recovery
with the full-body model. With the proposed learning-based solution, we
demonstrate the first real-time monocular full-body capture system with
plausible foot-ground contact in world space. More video results can be found
at our project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：NeuBTF: Neural fields for BTF encoding and transfer</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01199</p>
  <p><b>作者</b>：Carlos Rodriguez-Pardo,  Konstantinos Kazatzis,  Jorge Lopez-Moreno,  Elena Garces</p>
  <p><b>备注</b>：9 pages, 7 figures. Accepted to Computers & Graphics (Special Section on CEIG 2023). Project Website: this https URL</p>
  <p><b>关键词</b>：BTF, neural BTF, Neural, material, Neural material</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural material representations are becoming a popular way to represent
materials for rendering. They are more expressive than analytic models and
occupy less memory than tabulated BTFs. However, existing neural materials are
immutable, meaning that their output for a certain query of UVs, camera, and
light vector is fixed once they are trained. While this is practical when there
is no need to edit the material, it can become very limiting when the fragment
of the material used for training is too small or not tileable, which
frequently happens when the material has been captured with a
gonioreflectometer. In this paper, we propose a novel neural material
representation which jointly tackles the problems of BTF compression, tiling,
and extrapolation. At test time, our method uses a guidance image as input to
condition the neural BTF to the structural features of this input image. Then,
the neural BTF can be queried as a regular BTF using UVs, camera, and light
vectors. Every component in our framework is purposefully designed to maximize
BTF encoding quality at minimal parameter count and computational complexity,
achieving competitive compression rates compared with previous work. We
demonstrate the results of our method on a variety of synthetic and captured
materials, showing its generality and capacity to learn to represent many
optical properties.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Segment Anything Meets Point Tracking</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01197</p>
  <p><b>作者</b>：Frano Rajič,  Lei Ke,  Yu-Wing Tai,  Chi-Keung Tang,  Martin Danelljan,  Fisher Yu</p>
  <p><b>备注</b>：We propose SAM-PT to extend SAM to zero-shot video segmentation with point-based tracking. Github: this https URL</p>
  <p><b>关键词</b>：image segmentation model, employing interactive prompts, Segment Anything Model, powerful zero-shot image, segmentation model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) has established itself as a powerful
zero-shot image segmentation model, employing interactive prompts such as
points to generate masks. This paper presents SAM-PT, a method extending SAM's
capability to tracking and segmenting anything in dynamic videos. SAM-PT
leverages robust and sparse point selection and propagation techniques for mask
generation, demonstrating that a SAM-based segmentation tracker can yield
strong zero-shot performance across popular video object segmentation
benchmarks, including DAVIS, YouTube-VOS, and MOSE. Compared to traditional
object-centric mask propagation strategies, we uniquely use point propagation
to exploit local structure information that is agnostic to object semantics. We
highlight the merits of point-based tracking through direct evaluation on the
zero-shot open-world Unidentified Video Objects (UVO) benchmark. To further
enhance our approach, we utilize K-Medoids clustering for point initialization
and track both positive and negative points to clearly distinguish the target
object. We also employ multiple mask decoding passes for mask refinement and
devise a point re-initialization strategy to improve tracking accuracy. Our
code integrates different point trackers and video segmentation benchmarks and
will be released at this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：SAMAug: Point Prompt Augmentation for Segment Anything Model</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01187</p>
  <p><b>作者</b>：Haixing Dai,  Chong Ma,  Zhengliang Liu,  Yiwei Li,  Peng Shu,  Xiaozheng Wei,  Lin Zhao,  Zihao Wu,  Dajiang Zhu,  Wei Liu,  Quanzheng Li,  Tianming Liu,  Xiang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：augmented point prompts, paper introduces SAMAug, SAM, enhances interactive image, augmented point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces SAMAug, a novel visual point augmentation method for
the Segment Anything Model (SAM) that enhances interactive image segmentation
performance. SAMAug generates augmented point prompts to provide more
information to SAM. From the initial point prompt, SAM produces the initial
mask, which is then fed into our proposed SAMAug to generate augmented point
prompts. By incorporating these extra points, SAM can generate augmented
segmentation masks based on the augmented point prompts and the initial prompt,
resulting in improved segmentation performance. We evaluate four point
augmentation techniques: random selection, maximum difference entropy, maximum
distance, and a saliency model. Experiments on the COCO, Fundus, and Chest
X-ray datasets demonstrate that SAMAug can boost SAM's segmentation results,
especially using the maximum distance and saliency model methods. SAMAug
underscores the potential of visual prompt engineering to advance interactive
computer vision models.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Investigating Data Memorization in 3D Latent Diffusion Models for  Medical Image Synthesis</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01148</p>
  <p><b>作者</b>：Salman Ul Hassan Dar,  Arman Ghanaat,  Jannik Kahmann,  Isabelle Ayx,  Theano Papavassiliou,  Stefan O. Schoenberg,  Sandy Engelhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative latent diffusion, latent diffusion models, latent diffusion, data, diffusion models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative latent diffusion models have been established as state-of-the-art
in data generation. One promising application is generation of realistic
synthetic medical imaging data for open data sharing without compromising
patient privacy. Despite the promise, the capacity of such models to memorize
sensitive patient training data and synthesize samples showing high resemblance
to training data samples is relatively unexplored. Here, we assess the
memorization capacity of 3D latent diffusion models on photon-counting coronary
computed tomography angiography and knee magnetic resonance imaging datasets.
To detect potential memorization of training samples, we utilize
self-supervised models based on contrastive learning. Our results suggest that
such latent diffusion models indeed memorize training data, and there is a dire
need for devising strategies to mitigate memorization.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：AVSegFormer: Audio-Visual Segmentation with Transformer</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01146</p>
  <p><b>作者</b>：Shengyi Gao,  Zhe Chen,  Guo Chen,  Wenhai Wang,  Tong Lu</p>
  <p><b>备注</b>：9 pages, 7 figures</p>
  <p><b>关键词</b>：multi-modal community, vision has long, topic of interest, AVS, AVS tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The combination of audio and vision has long been a topic of interest in the
multi-modal community. Recently, a new audio-visual segmentation (AVS) task has
been introduced, aiming to locate and segment the sounding objects in a given
video. This task demands audio-driven pixel-level scene understanding for the
first time, posing significant challenges. In this paper, we propose
AVSegFormer, a novel framework for AVS tasks that leverages the transformer
architecture. Specifically, we introduce audio queries and learnable queries
into the transformer decoder, enabling the network to selectively attend to
interested visual features. Besides, we present an audio-visual mixer, which
can dynamically adjust visual features by amplifying relevant and suppressing
irrelevant spatial channels. Additionally, we devise an intermediate mask loss
to enhance the supervision of the decoder, encouraging the network to produce
more accurate intermediate predictions. Extensive experiments demonstrate that
AVSegFormer achieves state-of-the-art results on the AVS benchmark. The code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：SCITUNE: Aligning Large Language Models with Scientific Multimodal  Instructions</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01139</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Sai Munikoti,  Ian Stewart,  Henry Kvinge</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：popular paradigm, paradigm to align, align large language, human intent, align existing foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction finetuning is a popular paradigm to align large language models
(LLM) with human intent. Despite its popularity, this idea is less explored in
improving the LLMs to align existing foundation models with scientific
disciplines, concepts and goals. In this work, we present SciTune as a tuning
framework to improve the ability of LLMs to follow scientific multimodal
instructions. To test our methodology, we use a human-generated scientific
instruction tuning dataset and train a large multimodal model LLaMA-SciTune
that connects a vision encoder and LLM for science-focused visual and language
understanding. In comparison to the models that are finetuned with machine
generated data only, LLaMA-SciTune surpasses human performance on average and
in many sub-categories on the ScienceQA benchmark.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and  3D Localization</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01121</p>
  <p><b>作者</b>：Federico Rollo,  Gennaro Raiola,  Andrea Zunino,  Nikolaos Tsagarakis,  Arash Ajoudani</p>
  <p><b>备注</b>：Accepted to the 11th European Conference on Mobile Robots (ECMR) 2023</p>
  <p><b>关键词</b>：higher-level scene understanding, Geometric navigation, navigation is nowadays, nowadays a well-established, well-established field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geometric navigation is nowadays a well-established field of robotics and the
research focus is shifting towards higher-level scene understanding, such as
Semantic Mapping. When a robot needs to interact with its environment, it must
be able to comprehend the contextual information of its surroundings. This work
focuses on classifying and localising objects within a map, which is under
construction (SLAM) or already built. To further explore this direction, we
propose a framework that can autonomously detect and localize predefined
objects in a known environment using a multi-modal sensor fusion approach
(combining RGB and depth data from an RGB-D camera and a lidar). The framework
consists of three key elements: understanding the environment through RGB data,
estimating depth through multi-modal sensor fusion, and managing artifacts
(i.e., filtering and stabilizing measurements). The experiments show that the
proposed framework can accurately detect 98% of the objects in the real sample
environment, without post-processing, while 85% and 80% of the objects were
mapped using the single RGBD camera or RGB + lidar setup respectively. The
comparison with single-sensor (camera or lidar) experiments is performed to
show that sensor fusion allows the robot to accurately detect near and far
obstacles, which would have been noisy or imprecise in a purely visual or
laser-based approach.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：MeT: A Graph Transformer for Semantic Segmentation of 3D Meshes</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01115</p>
  <p><b>作者</b>：Giuseppe Vecchio,  Luca Prezzavento,  Carmelo Pino,  Francesco Rundo,  Simone Palazzo,  Concetto Spampinato</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：discretely approximating, capturing non-uniform shapes, efficiency and high, high flexibility, Semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Polygonal meshes have become the standard for discretely approximating 3D
shapes, thanks to their efficiency and high flexibility in capturing
non-uniform shapes. This non-uniformity, however, leads to irregularity in the
mesh structure, making tasks like segmentation of 3D meshes particularly
challenging. Semantic segmentation of 3D mesh has been typically addressed
through CNN-based approaches, leading to good accuracy. Recently, transformers
have gained enough momentum both in NLP and computer vision fields, achieving
performance at least on par with CNN models, supporting the long-sought
architecture universalism. Following this trend, we propose a transformer-based
method for semantic segmentation of 3D mesh motivated by a better modeling of
the graph structure of meshes, by means of global attention mechanisms. In
order to address the limitations of standard transformer architectures in
modeling relative positions of non-sequential data, as in the case of 3D
meshes, as well as in capturing the local context, we perform positional
encoding by means the Laplacian eigenvectors of the adjacency matrix, replacing
the traditional sinusoidal positional encodings, and by introducing
clustering-based features into the self-attention and cross-attention
operators. Experimental results, carried out on three sets of the Shape COSEG
Dataset, on the human segmentation dataset proposed in Maron et al., 2017 and
on the ShapeNet benchmark, show how the proposed approach yields
state-of-the-art performance on semantic segmentation of 3D meshes.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：MVDiffusion: Enabling Holistic Multi-view Image Generation with  Correspondence-Aware Diffusion</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01097</p>
  <p><b>作者</b>：Shitao Tang,  Fuyang Zhang,  Jiacheng Chen,  Peng Wang,  Yasutaka Furukawa</p>
  <p><b>备注</b>：Project page, this https URL</p>
  <p><b>关键词</b>：paper introduces MVDiffusion, paper introduces, perspective crops, crops from panorama, MVDiffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces MVDiffusion, a simple yet effective multi-view image
generation method for scenarios where pixel-to-pixel correspondences are
available, such as perspective crops from panorama or multi-view images given
geometry (depth maps and poses). Unlike prior models that rely on iterative
image warping and inpainting, MVDiffusion concurrently generates all images
with a global awareness, encompassing high resolution and rich content,
effectively addressing the error accumulation prevalent in preceding models.
MVDiffusion specifically incorporates a correspondence-aware attention
mechanism, enabling effective cross-view interaction. This mechanism underpins
three pivotal modules: 1) a generation module that produces low-resolution
images while maintaining global correspondence, 2) an interpolation module that
densifies spatial coverage between images, and 3) a super-resolution module
that upscales into high-resolution outputs. In terms of panoramic imagery,
MVDiffusion can generate high-resolution photorealistic images up to
1024$\times$1024 pixels. For geometry-conditioned multi-view image generation,
MVDiffusion demonstrates the first method capable of generating a textured map
of a scene mesh. The project page is at this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：UW-ProCCaps: UnderWater Progressive Colourisation with Capsules</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01091</p>
  <p><b>作者</b>：Rita Pucci,  Niki Martine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Underwater images, fundamental for studying, studying and understanding, understanding the status, status of marine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Underwater images are fundamental for studying and understanding the status
of marine life. We focus on reducing the memory space required for image
storage while the memory space consumption in the collecting phase limits the
time lasting of this phase leading to the need for more image collection
campaigns. We present a novel machine-learning model that reconstructs the
colours of underwater images from their luminescence channel, thus saving 2/3
of the available storage space. Our model specialises in underwater colour
reconstruction and consists of an encoder-decoder architecture. The encoder is
composed of a convolutional encoder and a parallel specialised classifier
trained with webly-supervised data. The encoder and the decoder use layers of
capsules to capture the features of the entities in the image. The colour
reconstruction process recalls the progressive and the generative adversarial
training procedures. The progressive training gives the ground for a generative
adversarial routine focused on the refining of colours giving the image bright
and saturated colours which bring the image back to life. We validate the model
both qualitatively and quantitatively on four benchmark datasets. This is the
first attempt at colour reconstruction in greyscale underwater images.
Extensive results on four benchmark datasets demonstrate that our solution
outperforms state-of-the-art (SOTA) solutions. We also demonstrate that the
generated colourisation enhances the quality of images compared to enhancement
models at the SOTA.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Shi-NeSS: Detecting Good and Stable Keypoints with a Neural Stability  Score</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01069</p>
  <p><b>作者</b>：Konstantin Pakulev,  Alexander Vakhitov,  Gonzalo Ferrer</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：specially prepared ground, prepared ground truth, feature point detector, point detector presents, ground truth labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning a feature point detector presents a challenge both due to the
ambiguity of the definition of a keypoint and correspondingly the need for a
specially prepared ground truth labels for such points. In our work, we address
both of these issues by utilizing a combination of a hand-crafted Shi detector
and a neural network. We build on the principled and localized keypoints
provided by the Shi detector and perform their selection using the keypoint
stability score regressed by the neural network - Neural Stability Score
(NeSS). Therefore, our method is named Shi-NeSS since it combines the Shi
detector and the properties of the keypoint stability score, and it only
requires for training sets of images without dataset pre-labeling or the need
for reconstructed correspondence labels. We evaluate Shi-NeSS on HPatches,
ScanNet, MegaDepth and IMC-PT, demonstrating state-of-the-art performance and
good generalization on downstream tasks.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Localized Questions in Medical Visual Question Answering</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01067</p>
  <p><b>作者</b>：Sergio Tascon-Morales,  Pablo Márquez-Neila,  Raphael Sznitman</p>
  <p><b>备注</b>：Appears in Medical Image Computing and Computer Assisted Interventions (MICCAI), 2023</p>
  <p><b>关键词</b>：natural language questions, Visual Question Answering, answer natural language, VQA, medical VQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual Question Answering (VQA) models aim to answer natural language
questions about given images. Due to its ability to ask questions that differ
from those used when training the model, medical VQA has received substantial
attention in recent years. However, existing medical VQA models typically focus
on answering questions that refer to an entire image rather than where the
relevant content may be located in the image. Consequently, VQA models are
limited in their interpretability power and the possibility to probe the model
about specific image regions. This paper proposes a novel approach for medical
VQA that addresses this limitation by developing a model that can answer
questions about image regions while considering the context necessary to answer
the questions. Our experimental results demonstrate the effectiveness of our
proposed model, outperforming existing methods on three datasets. Our code and
data are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：TomatoDIFF: On-plant Tomato Segmentation with Denoising Diffusion Models</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01064</p>
  <p><b>作者</b>：Marija Ivanovska,  Vitomir Struc,  Janez Pers</p>
  <p><b>备注</b>：Accepted at 18th International Conference on Machine Vision Applications (MVA)</p>
  <p><b>关键词</b>：Artificial intelligence applications, intelligence applications enable, applications enable farmers, optimize crop growth, Artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence applications enable farmers to optimize crop growth
and production while reducing costs and environmental impact. Computer
vision-based algorithms in particular, are commonly used for fruit
segmentation, enabling in-depth analysis of the harvest quality and accurate
yield estimation. In this paper, we propose TomatoDIFF, a novel diffusion-based
model for semantic segmentation of on-plant tomatoes. When evaluated against
other competitive methods, our model demonstrates state-of-the-art (SOTA)
performance, even in challenging environments with highly occluded fruits.
Additionally, we introduce Tomatopia, a new, large and challenging dataset of
greenhouse tomatoes. The dataset comprises high-resolution RGB-D images and
pixel-level annotations of the fruits.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Cross-modal Place Recognition in Image Databases using Event-based  Sensors</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01047</p>
  <p><b>作者</b>：Xiang Ji,  Jiaxin Wei,  Yifu Wang,  Huiliang Shang,  Laurent Kneip</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robotics tasks, important problem, problem towards global, global localization, Visual place recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual place recognition is an important problem towards global localization
in many robotics tasks. One of the biggest challenges is that it may suffer
from illumination or appearance changes in surrounding environments. Event
cameras are interesting alternatives to frame-based sensors as their high
dynamic range enables robust perception in difficult illumination conditions.
However, current event-based place recognition methods only rely on event
information, which restricts downstream applications of VPR. In this paper, we
present the first cross-modal visual place recognition framework that is
capable of retrieving regular images from a database given an event query. Our
method demonstrates promising results with respect to the state-of-the-art
frame-based and event-based methods on the Brisbane-Event-VPR dataset under
different scenarios. We also verify the effectiveness of the combination of
retrieval and classification, which can boost performance by a large margin.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：SAM-DA: UAV Tracks Anything at Night with SAM-Powered Domain Adaptation</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01024</p>
  <p><b>作者</b>：Liangliang Yao,  Haobo Zuo,  Guangze Zheng,  Changhong Fu,  Jia Pan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unmanned aerial vehicle, demonstrated significant promise, nighttime UAV tracking, nighttime unmanned aerial, target domain training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation (DA) has demonstrated significant promise for real-time
nighttime unmanned aerial vehicle (UAV) tracking. However, the state-of-the-art
(SOTA) DA still lacks the potential object with accurate pixel-level location
and boundary to generate the high-quality target domain training sample. This
key issue constrains the transfer learning of the real-time daytime SOTA
trackers for challenging nighttime UAV tracking. Recently, the notable Segment
Anything Model (SAM) has achieved remarkable zero-shot generalization ability
to discover abundant potential objects due to its huge data-driven training
approach. To solve the aforementioned issue, this work proposes a novel
SAM-powered DA framework for real-time nighttime UAV tracking, i.e., SAM-DA.
Specifically, an innovative SAM-powered target domain training sample swelling
is designed to determine enormous high-quality target domain training samples
from every single raw nighttime image. This novel one-to-many method
significantly expands the high-quality target domain training sample for DA.
Comprehensive experiments on extensive nighttime UAV videos prove the
robustness and domain adaptability of SAM-DA for nighttime UAV tracking.
Especially, compared to the SOTA DA, SAM-DA can achieve better performance with
fewer raw nighttime images, i.e., the fewer-better training. This economized
training approach facilitates the quick validation and deployment of algorithms
for UAVs. The code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：CGAM: Click-Guided Attention Module for Interactive Pathology Image  Segmentation via Backpropagating Refinement</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01015</p>
  <p><b>作者</b>：Seonghui Min,  Won-Ki Jeong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Tumor region segmentation, quantitative analysis, analysis of digital, deep neural networks, essential task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tumor region segmentation is an essential task for the quantitative analysis
of digital pathology. Recently presented deep neural networks have shown
state-of-the-art performance in various image-segmentation tasks. However,
because of the unclear boundary between the cancerous and normal regions in
pathology images, despite using modern methods, it is difficult to produce
satisfactory segmentation results in terms of the reliability and accuracy
required for medical data. In this study, we propose an interactive
segmentation method that allows users to refine the output of deep neural
networks through click-type user interactions. The primary method is to
formulate interactive segmentation as an optimization problem that leverages
both user-provided click constraints and semantic information in a feature map
using a click-guided attention module (CGAM). Unlike other existing methods,
CGAM avoids excessive changes in segmentation results, which can lead to the
overfitting of user clicks. Another advantage of CGAM is that the model size is
independent of input image size. Experimental results on pathology image
datasets indicated that our method performs better than existing
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：SynthCal: A Synthetic Benchmarking Pipeline to Compare Camera  Calibration Algorithms</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01013</p>
  <p><b>作者</b>：Lala Shakti Swarup Ray,  Bo Zhou,  Lars Krupp,  Sungho Suh,  Paul Lukowicz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision applications, vision applications, computer vision, calibration, camera</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate camera calibration is crucial for various computer vision
applications. However, measuring camera parameters in the real world is
challenging and arduous, and there needs to be a dataset with ground truth to
evaluate calibration algorithms' accuracy. In this paper, we present SynthCal,
a synthetic camera calibration benchmarking pipeline that generates images of
calibration patterns to measure and enable accurate quantification of
calibration algorithm performance in camera parameter estimation. We present a
SynthCal-generated calibration dataset with four common patterns, two camera
types, and two environments with varying view, distortion, lighting, and noise
levels. The dataset evaluates single-view calibration algorithms by measuring
reprojection and root-mean-square errors for identical patterns and camera
settings. Additionally, we analyze the significance of different patterns using
Zhang's method, which estimates intrinsic and extrinsic camera parameters with
known correspondences between 3D points and their 2D projections in different
configurations and environments. The experimental results demonstrate the
effectiveness of SynthCal in evaluating various calibration algorithms and
patterns.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Joint Coordinate Regression and Association For Multi-Person Pose  Estimation, A Pure Neural Network Approach</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01004</p>
  <p><b>作者</b>：Dongyang Yu,  Yunshi Xie,  Wangpeng An,  Li Zhang,  Yufeng Yao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joint Coordinate Regression, human pose joints, Coordinate Regression, Regression and Association, produces human pose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel one-stage end-to-end multi-person 2D pose estimation
algorithm, known as Joint Coordinate Regression and Association (JCRA), that
produces human pose joints and associations without requiring any
post-processing. The proposed algorithm is fast, accurate, effective, and
simple. The one-stage end-to-end network architecture significantly improves
the inference speed of JCRA. Meanwhile, we devised a symmetric network
structure for both the encoder and decoder, which ensures high accuracy in
identifying keypoints. It follows an architecture that directly outputs part
positions via a transformer network, resulting in a significant improvement in
performance. Extensive experiments on the MS COCO and CrowdPose benchmarks
demonstrate that JCRA outperforms state-of-the-art approaches in both accuracy
and efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\% faster at
inference acceleration than previous state-of-the-art bottom-up algorithms. The
code for this algorithm will be publicly available.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Visual Instruction Tuning with Polite Flamingo</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01003</p>
  <p><b>作者</b>：Delong Chen,  Jianfeng Liu,  Wenliang Dai,  Baoyuan Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, multi-modal Large Language, Large Language, annotated downstream vision-language, datasets significantly enhances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research has demonstrated that the multi-task fine-tuning of
multi-modal Large Language Models (LLMs) using an assortment of annotated
downstream vision-language datasets significantly enhances their performance.
Yet, during this process, a side effect, which we termed as the "multi-modal
alignment tax", surfaces. This side effect negatively impacts the model's
ability to format responses appropriately -- for instance, its "politeness" --
due to the overly succinct and unformatted nature of raw annotations, resulting
in reduced human preference. In this paper, we introduce Polite Flamingo, a
multi-modal response rewriter that transforms raw annotations into a more
appealing, "polite" format. Polite Flamingo is trained to reconstruct
high-quality responses from their automatically distorted counterparts and is
subsequently applied to a vast array of vision-language datasets for response
rewriting. After rigorous filtering, we generate the PF-1M dataset and further
validate its value by fine-tuning a multi-modal LLM with it. Combined with
novel methodologies including U-shaped multi-stage tuning and multi-turn
augmentation, the resulting model, Clever Flamingo, demonstrates its advantages
in both multi-modal understanding and response politeness according to
automated and human evaluations.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：RefSAM: Efficiently Adapting Segmenting Anything Model for Referring  Video Object Segmentation</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00997</p>
  <p><b>作者</b>：Yonglin Li,  Jing Zhang,  Xiao Teng,  Long Lan</p>
  <p><b>备注</b>：The code and models will be made publicly at this https URL</p>
  <p><b>关键词</b>：gained significant attention, gained significant, significant attention, impressive performance, performance in image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) has gained significant attention for its
impressive performance in image segmentation. However, it lacks proficiency in
referring video object segmentation (RVOS) due to the need for precise
user-interactive prompts and limited understanding of different modalities,
such as language and vision. This paper presents the RefSAM model, which for
the first time explores the potential of SAM for RVOS by incorporating
multi-view information from diverse modalities and successive frames at
different timestamps. Our proposed approach adapts the original SAM model to
enhance cross-modality learning by employing a lightweight Cross-Modal MLP that
projects the text embedding of the referring expression into sparse and dense
embeddings, serving as user-interactive prompts. Subsequently, a
parameter-efficient tuning strategy is employed to effectively align and fuse
the language and vision features. Through comprehensive ablation studies, we
demonstrate the practical and effective design choices of our strategy.
Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasets
validate the superiority and effectiveness of our RefSAM model over existing
methods. The code and models will be made publicly at
\href{this https URL}{this http URL}.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Predicting beauty, liking, and aesthetic quality: A comparative analysis  of image databases for visual aesthetics research</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00984</p>
  <p><b>作者</b>：Ralf Bartho,  Katja Thoemmes,  Christoph Redies</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerous image datasets, aesthetic ratings, datasets, statistical image properties, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the fields of Experimental and Computational Aesthetics, numerous image
datasets have been created over the last two decades. In the present work, we
provide a comparative overview of twelve image datasets that include aesthetic
ratings (beauty, liking or aesthetic quality) and investigate the
reproducibility of results across different datasets. Specifically, we examine
how consistently the ratings can be predicted by using either (A) a set of 20
previously studied statistical image properties, or (B) the layers of a
convolutional neural network developed for object recognition. Our findings
reveal substantial variation in the predictability of aesthetic ratings across
the different datasets. However, consistent similarities were found for
datasets containing either photographs or paintings, suggesting different
relevant features in the aesthetic evaluation of these two image genres. To our
surprise, statistical image properties and the convolutional neural network
predict aesthetic ratings with similar accuracy, highlighting a significant
overlap in the image information captured by the two methods. Nevertheless, the
discrepancies between the datasets call into question the generalizability of
previous research findings on single datasets. Our study underscores the
importance of considering multiple datasets to improve the validity and
generalizability of research results in the fields of experimental and
computational aesthetics.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Autism Spectrum Disorder Classification in Children based on Structural  MRI Features Extracted using Contrastive Variational Autoencoder</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00976</p>
  <p><b>作者</b>：Ruimin Ma,  Ruitao Xie,  Yanlin Wang,  Jintao Meng,  Yanjie Wei,  Wenhui Xi,  Yi Pan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Autism spectrum disorder, making early screening, highly disabling mental, disabling mental disease, brings significant impairments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autism spectrum disorder (ASD) is a highly disabling mental disease that
brings significant impairments of social interaction ability to the patients,
making early screening and intervention of ASD critical. With the development
of the machine learning and neuroimaging technology, extensive research has
been conducted on machine classification of ASD based on structural MRI
(s-MRI). However, most studies involve with datasets where participants' age
are above 5. Few studies conduct machine classification of ASD for participants
below 5-year-old, but, with mediocre predictive accuracy. In this paper, we
push the boundary of predictive accuracy (above 0.97) of machine classification
of ASD in children (age range: 0.92-4.83 years), based on s-MRI features
extracted using contrastive variational autoencoder (CVAE). 78 s-MRI, collected
from Shenzhen Children's Hospital, are used for training CVAE, which consists
of both ASD-specific feature channel and common shared feature channel. The ASD
participants represented by ASD-specific features can be easily discriminated
from TC participants represented by the common shared features, leading to high
classification accuracy. In case of degraded predictive accuracy when data size
is extremely small, a transfer learning strategy is proposed here as a
potential solution. Finally, we conduct neuroanatomical interpretation based on
the correlation between s-MRI features extracted from CVAE and surface area of
different cortical regions, which discloses potential biomarkers that could
help target treatments of ASD in the future.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：MoVie: Visual Model-Based Policy Adaptation for View Generalization</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00972</p>
  <p><b>作者</b>：Sizhe Yang,  Yanjie Ze,  Huazhe Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Visual Reinforcement Learning, Reinforcement Learning, face significant challenges, limited views face, views face significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual Reinforcement Learning (RL) agents trained on limited views face
significant challenges in generalizing their learned abilities to unseen views.
This inherent difficulty is known as the problem of $\textit{view
generalization}$. In this work, we systematically categorize this fundamental
problem into four distinct and highly challenging scenarios that closely
resemble real-world situations. Subsequently, we propose a straightforward yet
effective approach to enable successful adaptation of visual
$\textbf{Mo}$del-based policies for $\textbf{Vie}$w generalization
($\textbf{MoVie}$) during test time, without any need for explicit reward
signals and any modification during training time. Our method demonstrates
substantial advancements across all four scenarios encompassing a total of
$\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative
improvement of $\mathbf{33}$%, $\mathbf{86}$%, and $\mathbf{152}$%
respectively. The superior results highlight the immense potential of our
approach for real-world robotics applications. Videos are available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in  Multi-Objective Neural Architecture Search</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00960</p>
  <p><b>作者</b>：Simone Sarti,  Eugenio Lomurno,  Matteo Matteucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning, contemporary society, learning is increasingly, increasingly impacting, impacting various aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is increasingly impacting various aspects of contemporary
society. Artificial neural networks have emerged as the dominant models for
solving an expanding range of tasks. The introduction of Neural Architecture
Search (NAS) techniques, which enable the automatic design of task-optimal
networks, has led to remarkable advances. However, the NAS process is typically
associated with long execution times and significant computational resource
requirements. Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2),
have been developed to mitigate these challenges. While maintaining exceptional
performance and eliminating the need for retraining, they aim to build a single
super-network model capable of directly extracting sub-networks satisfying
different constraints. Neural Architecture Transfer (NAT) was developed to
maximise the effectiveness of extracting sub-networks from a super-network. In
this paper, we present NATv2, an extension of NAT that improves multi-objective
search algorithms applied to dynamic super-network architectures. NATv2
achieves qualitative improvements in the extractable sub-networks by exploiting
the improved super-networks generated by OFAv2 and incorporating new policies
for initialisation, pre-processing and updating its networks archive. In
addition, a post-processing pipeline based on fine-tuning is introduced.
Experimental results show that NATv2 successfully improves NAT and is highly
recommended for investigating high-performance architectures with a minimal
number of parameters.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：HODINet: High-Order Discrepant Interaction Network for RGB-D Salient  Object Detection</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00954</p>
  <p><b>作者</b>：Kang Yi,  Jing Xu,  Xiao Jin,  Fu Guo,  Yan-Feng Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：salient object detection, jointly modeling RGB, RGB-D salient object, RGB-D SOD, object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>RGB-D salient object detection (SOD) aims to detect the prominent regions by
jointly modeling RGB and depth information. Most RGB-D SOD methods apply the
same type of backbones and fusion modules to identically learn the
multimodality and multistage features. However, these features contribute
differently to the final saliency results, which raises two issues: 1) how to
model discrepant characteristics of RGB images and depth maps; 2) how to fuse
these cross-modality features in different stages. In this paper, we propose a
high-order discrepant interaction network (HODINet) for RGB-D SOD. Concretely,
we first employ transformer-based and CNN-based architectures as backbones to
encode RGB and depth features, respectively. Then, the high-order
representations are delicately extracted and embedded into spatial and channel
attentions for cross-modality feature fusion in different stages. Specifically,
we design a high-order spatial fusion (HOSF) module and a high-order channel
fusion (HOCF) module to fuse features of the first two and the last two stages,
respectively. Besides, a cascaded pyramid reconstruction network is adopted to
progressively decode the fused features in a top-down pathway. Extensive
experiments are conducted on seven widely used datasets to demonstrate the
effectiveness of the proposed approach. We achieve competitive performance
against 24 state-of-the-art methods under four evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Towards Building Self-Aware Object Detectors via Reliable Uncertainty  Quantification and Calibration</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00934</p>
  <p><b>作者</b>：Kemal Oksuz,  Tom Joy,  Puneet K. Dokania</p>
  <p><b>备注</b>：CVPR 2023</p>
  <p><b>关键词</b>：object detectors suffers, object detectors, classification quality, current approach, localisation and classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current approach for testing the robustness of object detectors suffers
from serious deficiencies such as improper methods of performing
out-of-distribution detection and using calibration metrics which do not
consider both localisation and classification quality. In this work, we address
these issues, and introduce the Self-Aware Object Detection (SAOD) task, a
unified testing framework which respects and adheres to the challenges that
object detectors face in safety-critical environments such as autonomous
driving. Specifically, the SAOD task requires an object detector to be: robust
to domain shift; obtain reliable uncertainty estimates for the entire scene;
and provide calibrated confidence scores for the detections. We extensively use
our framework, which introduces novel metrics and large scale test datasets, to
test numerous object detectors in two different use-cases, allowing us to
highlight critical insights into their robustness performance. Finally, we
introduce a simple baseline for the SAOD task, enabling researchers to
benchmark future proposed methods and move towards robust object detectors
which are fit for purpose. Code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Learning Differentiable Logic Programs for Abstract Visual Reasoning</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00928</p>
  <p><b>作者</b>：Hikaru Shindo,  Viktor Pfanschilling,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：building intelligent agents, problem-solving beyond perception, Visual reasoning, essential for building, building intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual reasoning is essential for building intelligent agents that understand
the world and perform problem-solving beyond perception. Differentiable forward
reasoning has been developed to integrate reasoning with gradient-based machine
learning paradigms. However, due to the memory intensity, most existing
approaches do not bring the best of the expressivity of first-order logic,
excluding a crucial ability to solve abstract visual reasoning, where agents
need to perform reasoning by using analogies on abstract concepts in different
scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg
reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner,
passing messages in a memory-efficient manner and handling structured programs
with functors. Moreover, we propose a computationally-efficient structure
learning algorithm to perform explanatory program induction on complex visual
scenes. To evaluate, in addition to conventional visual reasoning tasks, we
propose a new task, visual reasoning behind-the-scenes, where agents need to
learn abstract programs and then answer queries by imagining scenes that are
not observed. We empirically demonstrate that NEUMANN solves visual reasoning
tasks efficiently, outperforming neural, symbolic, and neuro-symbolic
baselines.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Semi-supervised multi-view concept decomposition</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00924</p>
  <p><b>作者</b>：Qi Jiang,  Guoxu Zhou,  Qibin Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-view concept factorization, demonstrated superior performance, Concept Factorization, concept factorization methods, concept factorization model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept Factorization (CF), as a novel paradigm of representation learning,
has demonstrated superior performance in multi-view clustering tasks. It
overcomes limitations such as the non-negativity constraint imposed by
traditional matrix factorization methods and leverages kernel methods to learn
latent representations that capture the underlying structure of the data,
thereby improving data representation. However, existing multi-view concept
factorization methods fail to consider the limited labeled information inherent
in real-world multi-view data. This often leads to significant performance
loss. To overcome these limitations, we propose a novel semi-supervised
multi-view concept factorization model, named SMVCF. In the SMVCF model, we
first extend the conventional single-view CF to a multi-view version, enabling
more effective exploration of complementary information across multiple views.
We then integrate multi-view CF, label propagation, and manifold learning into
a unified framework to leverage and incorporate valuable information present in
the data. Additionally, an adaptive weight vector is introduced to balance the
importance of different views in the clustering process. We further develop
targeted optimization methods specifically tailored for the SMVCF model.
Finally, we conduct extensive experiments on four diverse datasets with varying
label ratios to evaluate the performance of SMVCF. The experimental results
demonstrate the effectiveness and superiority of our proposed approach in
multi-view clustering tasks.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Why do CNNs excel at feature extraction? A mathematical explanation</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00919</p>
  <p><b>作者</b>：Vinoth Nandakumar,  Arush Tagade,  Tongliang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：past decade deep, decade deep learning, image classification benchmarks, image classification, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the past decade deep learning has revolutionized the field of computer
vision, with convolutional neural network models proving to be very effective
for image classification benchmarks. However, a fundamental theoretical
questions remain answered: why can they solve discrete image classification
tasks that involve feature extraction? We address this question in this paper
by introducing a novel mathematical model for image classification, based on
feature extraction, that can be used to generate images resembling real-world
datasets. We show that convolutional neural network classifiers can solve these
image classification tasks with zero error. In our proof, we construct
piecewise linear functions that detect the presence of features, and show that
they can be realized by a convolutional network.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Contextual Prompt Learning for Vision-Language Understanding</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00910</p>
  <p><b>作者</b>：Koustava Goswami,  Srikrishna Karanam,  Joseph K J,  Prateksha Udhayanan,  Balaji Vasan Srinivasan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful vision-language models, prompts, local image features, image features, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in multimodal learning has resulted in powerful
vision-language models, whose representations are generalizable across a
variety of downstream tasks. Recently, their generalizability has been further
extended by incorporating trainable prompts, borrowed from the natural language
processing literature. While such prompt learning techniques have shown
impressive results, we identify that these prompts are trained based on global
image features which limits itself in two aspects: First, by using global
features, these prompts could be focusing less on the discriminative foreground
image, resulting in poor generalization to various out-of-distribution test
cases. Second, existing work weights all prompts equally whereas our intuition
is that these prompts are more specific to the type of the image. We address
these issues with as part of our proposed Contextual Prompt Learning (CoPL)
framework, capable of aligning the prompts to the localized features of the
image. Our key innovations over earlier works include using local image
features as part of the prompt learning process, and more crucially, learning
to weight these prompts based on local features that are appropriate for the
task at hand. This gives us dynamic prompts that are both aligned to local
image features as well as aware of local contextual relationships. Our
extensive set of experiments on a variety of standard and few-shot datasets
show that our method produces substantially improved performance when compared
to the current state of the art methods. We also demonstrate both few-shot and
out-of-distribution performance to establish the utility of learning dynamic
prompts that are aligned to local image features.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Many tasks make light work: Learning to localise medical anomalies from  multiple synthetic tasks</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00899</p>
  <p><b>作者</b>：Matthew Baugh,  Jeremy Tan,  Johanna P. Müller,  Mischa Dombrowski,  James Batten,  Bernhard Kainz</p>
  <p><b>备注</b>：Early accepted to MICCAI 2023</p>
  <p><b>关键词</b>：reliably identify classes, fully supervised machine, detection as fully, supervised machine learning, growing interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a growing interest in single-class modelling and out-of-distribution
detection as fully supervised machine learning models cannot reliably identify
classes not included in their training. The long tail of infinitely many
out-of-distribution classes in real-world scenarios, e.g., for screening,
triage, and quality control, means that it is often necessary to train
single-class models that represent an expected feature distribution, e.g., from
only strictly healthy volunteer data. Conventional supervised machine learning
would require the collection of datasets that contain enough samples of all
possible diseases in every imaging modality, which is not realistic.
Self-supervised learning methods with synthetic anomalies are currently amongst
the most promising approaches, alongside generative auto-encoders that analyse
the residual reconstruction error. However, all methods suffer from a lack of
structured validation, which makes calibration for deployment difficult and
dataset-dependant. Our method alleviates this by making use of multiple
visually-distinct synthetic anomaly learning tasks for both training and
validation. This enables more robust training and generalisation. With our
approach we can readily outperform state-of-the-art methods, which we
demonstrate on exemplars in brain MRI and chest X-rays. Code is available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Mega-cities dominate China's urban greening</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00894</p>
  <p><b>作者</b>：Xiaoxin Zhang,  Martin Brandt,  Xiaoye Tong,  Xiaowei Tong,  Wenmin Zhang,  Florian Reiner,  Sizhuo Li,  Feng Tian,  Yuemin Yue,  Weiqi Zhou,  Bin Chen,  Xiangming Xiao,  Rasmus Fensholt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offering various ecosystem, human well-being, tree cover, play a crucial, crucial role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trees play a crucial role in urban environments, offering various ecosystem
services that contribute to public health and human well-being. China has
initiated a range of urban greening policies over the past decades, however,
monitoring their impact on urban tree dynamics at a national scale has proven
challenging. In this study, we deployed nano-satellites to quantify urban tree
coverage in all major Chinese cities larger than 50 km2 in 2010 and 2019. Our
findings indicate that approximately 6000 km2 (11%) of urban areas were covered
by trees in 2019, and 76% of these cities experienced an increase in tree cover
compared to 2010. Notably, the increase in tree cover in mega-cities such as
Beijing, and Shanghai was approximately twice as large as in most other cities
(7.69% vs 3.94%). The study employs a data-driven approach towards assessing
urban tree cover changes in relation to greening policies, showing clear signs
of tree cover increases but also suggesting an uneven implementation primarily
benefiting a few mega-cities.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Generating Reliable Pixel-Level Labels for Source Free Domain Adaptation</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00893</p>
  <p><b>作者</b>：Gabriel Tjio,  Ping Liu,  Yawei Luo,  Chee Keong Kwoh,  Joey Zhou Tianyi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：target domain images, target domain, domain images, domain, pretrained black-box segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work addresses the challenging domain adaptation setting in which
knowledge from the labelled source domain dataset is available only from the
pretrained black-box segmentation model. The pretrained model's predictions for
the target domain images are noisy because of the distributional differences
between the source domain data and the target domain data. Since the model's
predictions serve as pseudo labels during self-training, the noise in the
predictions impose an upper bound on model performance. Therefore, we propose a
simple yet novel image translation workflow, ReGEN, to address this problem.
ReGEN comprises an image-to-image translation network and a segmentation
network. Our workflow generates target-like images using the noisy predictions
from the original target domain images. These target-like images are
semantically consistent with the noisy model predictions and therefore can be
used to train the segmentation network. In addition to being semantically
consistent with the predictions from the original target domain images, the
generated target-like images are also stylistically similar to the target
domain images. This allows us to leverage the stylistic differences between the
target-like images and the target domain image as an additional source of
supervision while training the segmentation model. We evaluate our model with
two benchmark domain adaptation settings and demonstrate that our approach
performs favourably relative to recent state-of-the-art work. The source code
will be made available.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Augmenting Deep Learning Adaptation for Wearable Sensor Data through  Combined Temporal-Frequency Image Encoding</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00883</p>
  <p><b>作者</b>：Yidong Zhu,  Md Mahmudur Rahman,  Mohammad Arif Ul Alam</p>
  <p><b>备注</b>：Under review in IEEE-EMBS International Conference on Body Sensor Networks: Sensor and Systems for Digital Health (IEEE BSN 2023)</p>
  <p><b>关键词</b>：including computer vision, revolutionized scalable classification, Deep learning advancements, Deep learning, advancements have revolutionized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning advancements have revolutionized scalable classification in
many domains including computer vision. However, when it comes to
wearable-based classification and domain adaptation, existing computer
vision-based deep learning architectures and pretrained models trained on
thousands of labeled images for months fall short. This is primarily because
wearable sensor data necessitates sensor-specific preprocessing, architectural
modification, and extensive data collection. To overcome these challenges,
researchers have proposed encoding of wearable temporal sensor data in images
using recurrent plots. In this paper, we present a novel modified-recurrent
plot-based image representation that seamlessly integrates both temporal and
frequency domain information. Our approach incorporates an efficient Fourier
transform-based frequency domain angular difference estimation scheme in
conjunction with the existing temporal recurrent plot image. Furthermore, we
employ mixup image augmentation to enhance the representation. We evaluate the
proposed method using accelerometer-based activity recognition data and a
pretrained ResNet model, and demonstrate its superior performance compared to
existing approaches.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Co-Learning Meets Stitch-Up for Noisy Multi-label Visual Recognition</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00880</p>
  <p><b>作者</b>：Chao Liang,  Zongxin Yang,  Linchao Zhu,  Yi Yang</p>
  <p><b>备注</b>：accepted by TIP 2023, code is at this https URL</p>
  <p><b>关键词</b>：real-world scenarios, collected and annotated, exhibit the characteristics, long-tailed, multi-label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world scenarios, collected and annotated data often exhibit the
characteristics of multiple classes and long-tailed distribution. Additionally,
label noise is inevitable in large-scale annotations and hinders the
applications of learning-based models. Although many deep learning based
methods have been proposed for handling long-tailed multi-label recognition or
label noise respectively, learning with noisy labels in long-tailed multi-label
visual data has not been well-studied because of the complexity of long-tailed
distribution entangled with multi-label correlation. To tackle such a critical
yet thorny problem, this paper focuses on reducing noise based on some inherent
properties of multi-label classification and long-tailed learning under noisy
cases. In detail, we propose a Stitch-Up augmentation to synthesize a cleaner
sample, which directly reduces multi-label noise by stitching up multiple noisy
training samples. Equipped with Stitch-Up, a Heterogeneous Co-Learning
framework is further designed to leverage the inconsistency between long-tailed
and balanced distributions, yielding cleaner labels for more robust
representation learning with noisy long-tailed data. To validate our method, we
build two challenging benchmarks, named VOC-MLT-Noise and COCO-MLT-Noise,
respectively. Extensive experiments are conducted to demonstrate the
effectiveness of our proposed method. Compared to a variety of baselines, our
method achieves superior results.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：UniFine: A Unified and Fine-grained Approach for Zero-shot  Vision-Language Understanding</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00862</p>
  <p><b>作者</b>：Rui Sun,  Zhecan Wang,  Haoxuan You,  Noel Codella,  Kai-Wei Chang,  Shih-Fu Chang</p>
  <p><b>备注</b>：14 pages, 4 figures, ACL 2023 Findings</p>
  <p><b>关键词</b>：model reasoning ability, natural language, require the model, model reasoning, world and natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because
they require the model's reasoning ability to understand the semantics of the
visual world and natural language. Supervised methods working for
vision-language tasks have been well-studied. However, solving these tasks in a
zero-shot setting is less explored. Since Contrastive Language-Image
Pre-training (CLIP) has shown remarkable zero-shot performance on image-text
matching, previous works utilized its strong zero-shot ability by converting
vision-language tasks into an image-text matching problem, and they mainly
consider global-level matching (e.g., the whole image or sentence). However, we
find visual and textual fine-grained information, e.g., keywords in the
sentence and objects in the image, can be fairly informative for semantics
understanding. Inspired by this, we propose a unified framework to take
advantage of the fine-grained information for zero-shot vision-language
learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our
experiments show that our framework outperforms former zero-shot methods on VQA
and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our
ablation studies confirm the effectiveness and generalizability of our proposed
method. Code will be available at this https URL</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Review of Large Vision Models and Visual Prompt Engineering</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00855</p>
  <p><b>作者</b>：Jiaqi Wang,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Chong Ma,  Sigang Yu,  Haixing Dai,  Qiushi Yang,  Yiheng Liu,  Songyao Zhang,  Enze Shi,  Yi Pan,  Tuo Zhang,  Dajiang Zhu,  Xiang Li,  Xi Jiang,  Bao Ge,  Yixuan Yuan,  Dinggang Shen,  Tianming Liu,  Shu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial General Intelligence, image Artificial General, General Intelligence, Artificial General, achieving zero-shot capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual prompt engineering is a fundamental technology in the field of visual
and image Artificial General Intelligence, serving as a key component for
achieving zero-shot capabilities. As the development of large vision models
progresses, the importance of prompt engineering becomes increasingly evident.
Designing suitable prompts for specific visual tasks has emerged as a
meaningful research direction. This review aims to summarize the methods
employed in the computer vision domain for large vision models and visual
prompt engineering, exploring the latest advancements in visual prompt
engineering. We present influential large models in the visual domain and a
range of prompt engineering methods employed on these models. It is our hope
that this review provides a comprehensive and systematic description of prompt
engineering methods based on large visual models, offering valuable insights
for future researchers in their exploration of this field.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：VINECS: Video-based Neural Character Skinning</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00842</p>
  <p><b>作者</b>：Zhouyingcheng Liao,  Vladislav Golyanik,  Marc Habermann,  Christian Theobalt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clothed human avatars, skinning clothed human, work and expertise, clothed human, human avatars</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rigging and skinning clothed human avatars is a challenging task and
traditionally requires a lot of manual work and expertise. Recent methods
addressing it either generalize across different characters or focus on
capturing the dynamics of a single character observed under different pose
configurations. However, the former methods typically predict solely static
skinning weights, which perform poorly for highly articulated poses, and the
latter ones either require dense 3D character scans in different poses or
cannot generate an explicit mesh with vertex correspondence over time. To
address these challenges, we propose a fully automated approach for creating a
fully rigged character with pose-dependent skinning weights, which can be
solely learned from multi-view video. Therefore, we first acquire a rigged
template, which is then statically skinned. Next, a coordinate-based MLP learns
a skinning weights field parameterized over the position in a canonical pose
space and the respective pose. Moreover, we introduce our pose- and
view-dependent appearance field allowing us to differentiably render and
supervise the posed mesh using multi-view imagery. We show that our approach
outperforms state-of-the-art while not relying on dense 4D scans.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Surgical fine-tuning for Grape Bunch Segmentation under Visual Domain  Shifts</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00837</p>
  <p><b>作者</b>：Agnese Chiatti,  Riccardo Bertoglio,  Nico Catalano,  Matteo Gatti,  Matteo Matteucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sustainable agriculture, play a crucial, crucial role, transition towards sustainable, Mobile robots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile robots will play a crucial role in the transition towards sustainable
agriculture. To autonomously and effectively monitor the state of plants,
robots ought to be equipped with visual perception capabilities that are robust
to the rapid changes that characterise agricultural settings. In this paper, we
focus on the challenging task of segmenting grape bunches from images collected
by mobile robots in vineyards. In this context, we present the first study that
applies surgical fine-tuning to instance segmentation tasks. We show how
selectively tuning only specific model layers can support the adaptation of
pre-trained Deep Learning models to newly-collected grape images that introduce
visual domain shifts, while also substantially reducing the number of tuned
parameters.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Unveiling the Potential of Spike Streams for Foreground Occlusion  Removal from Densely Continuous Views</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00821</p>
  <p><b>作者</b>：Jiyuan Zhang,  Shiyan Chen,  Yajing Zheng,  Zhaofei Yu,  Tiejun Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：immense practical significance, holds immense practical, clean background image, occlusion holds immense, removing foreground occlusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The extraction of a clean background image by removing foreground occlusion
holds immense practical significance, but it also presents several challenges.
Presently, the majority of de-occlusion research focuses on addressing this
issue through the extraction and synthesis of discrete images from calibrated
camera arrays. Nonetheless, the restoration quality tends to suffer when faced
with dense occlusions or high-speed motions due to limited perspectives and
motion blur. To successfully remove dense foreground occlusion, an effective
multi-view visual information integration approach is required. Introducing the
spike camera as a novel type of neuromorphic sensor offers promising
capabilities with its ultra-high temporal resolution and high dynamic range. In
this paper, we propose an innovative solution for tackling the de-occlusion
problem through continuous multi-view imaging using only one spike camera
without any prior knowledge of camera intrinsic parameters and camera poses. By
rapidly moving the spike camera, we continually capture the dense stream of
spikes from the occluded scene. To process the spikes, we build a novel model
\textbf{SpkOccNet}, in which we integrate information of spikes from continuous
viewpoints within multi-windows, and propose a novel cross-view mutual
attention mechanism for effective fusion and refinement. In addition, we
contribute the first real-world spike-based dataset \textbf{S-OCC} for
occlusion removal. The experimental results demonstrate that our proposed model
efficiently removes dense occlusions in diverse scenes while exhibiting strong
generalization.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00818</p>
  <p><b>作者</b>：Jing Lin,  Ailing Zeng,  Shunlin Lu,  Yuanhao Cai,  Ruimao Zhang,  Haoqian Wang,  Lei Zhang</p>
  <p><b>备注</b>：A large-scale 3D whole-body human motion-text dataset; GitHub: this https URL</p>
  <p><b>关键词</b>：pose descriptions, motion, whole-body, whole-body pose descriptions, whole-body pose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present Motion-X, a large-scale 3D expressive whole-body
motion dataset. Existing motion datasets predominantly contain body-only poses,
lacking facial expressions, hand gestures, and fine-grained pose descriptions.
Moreover, they are primarily collected from limited laboratory scenes with
textual descriptions manually labeled, which greatly limits their scalability.
To overcome these limitations, we develop a whole-body motion and text
annotation pipeline, which can automatically annotate motion from either
single- or multi-view videos and provide comprehensive semantic labels for each
video and fine-grained whole-body pose descriptions for each frame. This
pipeline is of high precision, cost-effective, and scalable for further
research. Based on it, we construct Motion-X, which comprises 13.7M precise 3D
whole-body pose annotations (i.e., SMPL-X) covering 96K motion sequences from
massive scenes. Besides, Motion-X provides 13.7M frame-level whole-body pose
descriptions and 96K sequence-level semantic labels. Comprehensive experiments
demonstrate the accuracy of the annotation pipeline and the significant benefit
of Motion-X in enhancing expressive, diverse, and natural motion generation, as
well as 3D whole-body human mesh recovery.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Review helps learn better: Temporal Supervised Knowledge Distillation</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00811</p>
  <p><b>作者</b>：Dongwei Wang,  Zhi Han,  Yanmei Wang,  Xiai Chen,  Baichen Liu,  Yandong Tang</p>
  <p><b>备注</b>：Under review in NIPS 2023</p>
  <p><b>关键词</b>：Reviewing plays, plays an important, important role, knowledge, network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reviewing plays an important role when learning knowledge. The knowledge
acquisition at a certain time point may be strongly inspired with the help of
previous experience. Thus the knowledge growing procedure should show strong
relationship along the temporal dimension. In our research, we find that during
the network training, the evolution of feature map follows temporal sequence
property. A proper temporal supervision may further improve the network
training performance. Inspired by this observation, we design a novel knowledge
distillation method. Specifically, we extract the spatiotemporal features in
the different training phases of student by convolutional Long Short-term
memory network (Conv-LSTM). Then, we train the student net through a dynamic
target, rather than static teacher network features. This process realizes the
refinement of old knowledge in student network, and utilizes them to assist
current learning. Extensive experiments verify the effectiveness and advantages
of our method over existing knowledge distillation methods, including various
network architectures, different tasks (image classification and object
detection) .</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：SketchMetaFace: A Learning-based Sketching Interface for High-fidelity  3D Character Face Modeling</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00804</p>
  <p><b>作者</b>：Zhongjin Luo,  Dong Du,  Heming Zhu,  Yizhou Yu,  Hongbo Fu,  Xiaoguang Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benefits various application, application scenarios, avatars benefits, Character faces contribute, character face models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling 3D avatars benefits various application scenarios such as AR/VR,
gaming, and filming. Character faces contribute significant diversity and
vividity as a vital component of avatars. However, building 3D character face
models usually requires a heavy workload with commercial tools, even for
experienced artists. Various existing sketch-based tools fail to support
amateurs in modeling diverse facial shapes and rich geometric details. In this
paper, we present SketchMetaFace - a sketching system targeting amateur users
to model high-fidelity 3D faces in minutes. We carefully design both the user
interface and the underlying algorithm. First, curvature-aware strokes are
adopted to better support the controllability of carving facial details.
Second, considering the key problem of mapping a 2D sketch map to a 3D model,
we develop a novel learning-based method termed "Implicit and Depth Guided Mesh
Modeling" (IDGMM). It fuses the advantages of mesh, implicit, and depth
representations to achieve high-quality results with high efficiency. In
addition, to further support usability, we present a coarse-to-fine 2D
sketching interface design and a data-driven stroke suggestion tool. User
studies demonstrate the superiority of our system over existing modeling tools
in terms of the ease to use and visual quality of results. Experimental
analyses also show that IDGMM reaches a better trade-off between accuracy and
efficiency. SketchMetaFace are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：ACDMSR: Accelerated Conditional Diffusion Models for Single Image  Super-Resolution</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00781</p>
  <p><b>作者</b>：Axi Niu,  Pham Xuan Trung,  Kang Zhang,  Jinqiu Sun,  Yu Zhu,  In So Kweon,  Yanning Zhang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2302.12831</p>
  <p><b>关键词</b>：gained significant popularity, Diffusion models, Diffusion, pure Gaussian noise, refining pure Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have gained significant popularity in the field of
image-to-image translation. Previous efforts applying diffusion models to image
super-resolution (SR) have demonstrated that iteratively refining pure Gaussian
noise using a U-Net architecture trained on denoising at various noise levels
can yield satisfactory high-resolution images from low-resolution inputs.
However, this iterative refinement process comes with the drawback of low
inference speed, which strongly limits its applications. To speed up inference
and further enhance the performance, our research revisits diffusion models in
image super-resolution and proposes a straightforward yet significant diffusion
model-based super-resolution method called ACDMSR (accelerated conditional
diffusion model for image super-resolution). Specifically, our method adapts
the standard diffusion model to perform super-resolution through a
deterministic iterative denoising process. Our study also highlights the
effectiveness of using a pre-trained SR model to provide the conditional image
of the given low-resolution (LR) image to achieve superior high-resolution
results. We demonstrate that our method surpasses previous attempts in
qualitative and quantitative results through extensive experiments conducted on
benchmark datasets such as Set5, Set14, Urban100, BSD100, and Manga109.
Moreover, our approach generates more visually realistic counterparts for
low-resolution images, emphasizing its effectiveness in practical scenarios.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：DifFSS: Diffusion Model for Few-Shot Semantic Segmentation</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00773</p>
  <p><b>作者</b>：Weimin Tan,  Siyuan Chen,  Bo Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated excellent performance, FSS models, FSS, diffusion model, FSS task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have demonstrated excellent performance in image generation.
Although various few-shot semantic segmentation (FSS) models with different
network structures have been proposed, performance improvement has reached a
bottleneck. This paper presents the first work to leverage the diffusion model
for FSS task, called DifFSS. DifFSS, a novel FSS paradigm, can further improve
the performance of the state-of-the-art FSS models by a large margin without
modifying their network structure. Specifically, we utilize the powerful
generation ability of diffusion models to generate diverse auxiliary support
images by using the semantic mask, scribble or soft HED boundary of the support
image as control conditions. This generation process simulates the variety
within the class of the query image, such as color, texture variation,
lighting, $etc$. As a result, FSS models can refer to more diverse support
images, yielding more robust representations, thereby achieving a consistent
improvement in segmentation performance. Extensive experiments on three
publicly available datasets based on existing advanced FSS models demonstrate
the effectiveness of the diffusion model for FSS task. Furthermore, we explore
in detail the impact of different input settings of the diffusion model on
segmentation performance. Hopefully, this completely new paradigm will bring
inspiration to the study of FSS task integrated with AI-generated content.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Hierarchical Open-vocabulary Universal Image Segmentation</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00764</p>
  <p><b>作者</b>：Xudong Wang,  Shufan Li,  Konstantinos Kallidromitis,  Yusuke Kato,  Kazuki Kozuka,  Trevor Darrell</p>
  <p><b>备注</b>：Project web-page: this http URL</p>
  <p><b>关键词</b>：arbitrary text descriptions, text descriptions, aims to partition, arbitrary text, image segmentation aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-vocabulary image segmentation aims to partition an image into semantic
regions according to arbitrary text descriptions. However, complex visual
scenes can be naturally decomposed into simpler parts and abstracted at
multiple levels of granularity, introducing inherent segmentation ambiguity.
Unlike existing methods that typically sidestep this ambiguity and treat it as
an external factor, our approach actively incorporates a hierarchical
representation encompassing different semantic-levels into the learning
process. We propose a decoupled text-image fusion mechanism and representation
learning modules for both "things" and "stuff".1 Additionally, we
systematically examine the differences that exist in the textual and visual
features between these types of categories. Our resulting model, named HIPIE,
tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within
a unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO,
Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the
state-of-the-art results at various levels of image comprehension, including
semantic-level (e.g., semantic segmentation), instance-level (e.g.,
panoptic/referring segmentation and object detection), as well as part-level
(e.g., part/subpart segmentation) tasks. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning Noise-Resistant Image Representation by Aligning Clean and  Noisy Domains</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00761</p>
  <p><b>作者</b>：Yanhui Guo,  Xiaolin Wu,  Fangzhou Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved quantum leaps, Recent supervised, quantum leaps, supervised and unsupervised, algorithms have achieved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent supervised and unsupervised image representation learning algorithms
have achieved quantum leaps. However, these techniques do not account for
representation resilience against noise in their design paradigms.
Consequently, these effective methods suffer failure when confronted with noise
outside the training distribution, such as complicated real-world noise that is
usually opaque to model training. To address this issue, dual domains are
optimized to separately model a canonical space for noisy representations,
namely the Noise-Robust (NR) domain, and a twinned canonical clean space,
namely the Noise-Free (NF) domain, by maximizing the interaction information
between the representations. Given the dual canonical domains, we design a
target-guided implicit neural mapping function to accurately translate the NR
representations to the NF domain, yielding noise-resistant representations by
eliminating noise regencies. The proposed method is a scalable module that can
be readily integrated into existing learning systems to improve their
robustness against noise. Comprehensive trials of various tasks using both
synthetic and real-world noisy data demonstrate that the proposed Target-Guided
Dual-Domain Translation (TDDT) method is able to achieve remarkable performance
and robustness in the face of complex noisy images.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Structured Network Pruning by Measuring Filter-wise Interactions</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00758</p>
  <p><b>作者</b>：Wenting Tang,  Xingxing Wei,  Bo Li (Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, Beijing, China)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Structured network pruning, Structured network, network pruning, CNNs' generalization performance, reduce computation cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured network pruning is a practical approach to reduce computation cost
directly while retaining the CNNs' generalization performance in real
applications. However, identifying redundant filters is a core problem in
structured network pruning, and current redundancy criteria only focus on
individual filters' attributes. When pruning sparsity increases, these
redundancy criteria are not effective or efficient enough. Since the
filter-wise interaction also contributes to the CNN's prediction accuracy, we
integrate the filter-wise interaction into the redundancy criterion. In our
criterion, we introduce the filter importance and filter utilization strength
to reflect the decision ability of individual and multiple filters. Utilizing
this new redundancy criterion, we propose a structured network pruning approach
SNPFI (Structured Network Pruning by measuring Filter-wise Interaction). During
the pruning, the SNPFI can automatically assign the proper sparsity based on
the filter utilization strength and eliminate the useless filters by filter
importance. After the pruning, the SNPFI can recover pruned model's performance
effectively without iterative training by minimizing the interaction
difference. We empirically demonstrate the effectiveness of the SNPFI with
several commonly used CNN models, including AlexNet, MobileNetv1, and
ResNet-50, on various image classification datasets, including MNIST, CIFAR-10,
and ImageNet. For all experimental CNN models, nearly 60% of computation is
reduced in a network compression while the classification accuracy remains.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Graph-level Anomaly Detection via Hierarchical Memory Networks</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00755</p>
  <p><b>作者</b>：Chaoxi Niu,  Guansong Pang,  Ling Chen</p>
  <p><b>备注</b>：Accepted to ECML-PKDD 2023</p>
  <p><b>关键词</b>：exhibit deviant structures, node attributes compared, anomaly detection aims, identify abnormal graphs, detection aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-level anomaly detection aims to identify abnormal graphs that exhibit
deviant structures and node attributes compared to the majority in a graph set.
One primary challenge is to learn normal patterns manifested in both
fine-grained and holistic views of graphs for identifying graphs that are
abnormal in part or in whole. To tackle this challenge, we propose a novel
approach called Hierarchical Memory Networks (HimNet), which learns
hierarchical memory modules -- node and graph memory modules -- via a graph
autoencoder network architecture. The node-level memory module is trained to
model fine-grained, internal graph interactions among nodes for detecting
locally abnormal graphs, while the graph-level memory module is dedicated to
the learning of holistic normal patterns for detecting globally abnormal
graphs. The two modules are jointly optimized to detect both locally- and
globally-anomalous graphs. Extensive empirical results on 16 real-world graph
datasets from various domains show that i) HimNet significantly outperforms the
state-of-art methods and ii) it is robust to anomaly contamination. Codes are
available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Feasibility of Universal Anomaly Detection without Knowing the  Abnormality in Medical Images</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00750</p>
  <p><b>作者</b>：Can Cui,  Yaohong Wang,  Shunxing Bao,  Yucheng Tang,  Ruining Deng,  Lucas W. Remedios,  Zuhayr Asad,  Joseph T. Roland,  Ken S. Lau,  Qi Liu,  Lori A. Coburn,  Keith T. Wilson,  Bennett A. Landman,  Yuankai Huo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：anomaly detection, anomaly detection approaches, anomaly detection methods, deep learning methods, identify abnormal image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many anomaly detection approaches, especially deep learning methods, have
been recently developed to identify abnormal image morphology by only employing
normal images during training. Unfortunately, many prior anomaly detection
methods were optimized for a specific "known" abnormality (e.g., brain tumor,
bone fraction, cell types). Moreover, even though only the normal images were
used in the training process, the abnormal images were oftenly employed during
the validation process (e.g., epoch selection, hyper-parameter tuning), which
might leak the supposed ``unknown" abnormality unintentionally. In this study,
we investigated these two essential aspects regarding universal anomaly
detection in medical images by (1) comparing various anomaly detection methods
across four medical datasets, (2) investigating the inevitable but often
neglected issues on how to unbiasedly select the optimal anomaly detection
model during the validation phase using only normal images, and (3) proposing a
simple decision-level ensemble method to leverage the advantage of different
kinds of anomaly detection without knowing the abnormality. The results of our
experiments indicate that none of the evaluated methods consistently achieved
the best performance across all datasets. Our proposed method enhanced the
robustness of performance in general (average AUC 0.956).</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：UnLoc: A Universal Localization Method for Autonomous Vehicles using  LiDAR, Radar and/or Camera Input</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00741</p>
  <p><b>作者</b>：Muhammad Ibrahim,  Naveed Akhtar,  Saeed Anwar,  Ajmal Mian</p>
  <p><b>备注</b>：UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input has been accepted for publication in the Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</p>
  <p><b>关键词</b>：autonomous navigation, fundamental task, task in robotics, robotics for autonomous, Localization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Localization is a fundamental task in robotics for autonomous navigation.
Existing localization methods rely on a single input data modality or train
several computational models to process different modalities. This leads to
stringent computational requirements and sub-optimal results that fail to
capitalize on the complementary information in other data streams. This paper
proposes UnLoc, a novel unified neural modeling approach for localization with
multi-sensor input in all weather conditions. Our multi-stream network can
handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can
work with one or more input sensors, making it robust to sensor failure. UnLoc
uses 3D sparse convolutions and cylindrical partitioning of the space to
process LiDAR frames and implements ResNet blocks with a slot attention-based
feature filtering module for the Radar and image modalities. We introduce a
unique learnable modality encoding scheme to distinguish between the input
sensor data. Our method is extensively evaluated on Oxford Radar RobotCar,
ApolloSouthBay and Perth-WA datasets. The results ascertain the efficacy of our
technique.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：LXL: LiDAR Exclusive Lean 3D Object Detection with 4D Imaging Radar and  Camera Fusion</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00724</p>
  <p><b>作者</b>：Weiyi Xiong,  Jianan Liu,  Tao Huang,  Qing-Long Han,  Yuxuan Xia,  Bing Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：affordable device, effective in performing, autonomous driving, emerging technology, confirmed effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an emerging technology and a relatively affordable device, the 4D imaging
radar has already been confirmed effective in performing 3D object detection in
autonomous driving. Nevertheless, the sparsity and noisiness of 4D radar point
clouds hinder further performance improvement, and in-depth studies about its
fusion with other modalities are lacking. On the other hand, most of the
camera-based perception methods transform the extracted image perspective view
features into the bird's-eye view geometrically via "depth-based splatting"
proposed in Lift-Splat-Shoot (LSS), and some researchers exploit other modals
such as LiDARs or ordinary automotive radars for enhancement. Recently, a few
works have applied the "sampling" strategy for image view transformation,
showing that it outperforms "splatting" even without image depth prediction.
However, the potential of "sampling" is not fully unleashed. In this paper, we
investigate the "sampling" view transformation strategy on the camera and 4D
imaging radar fusion-based 3D object detection. In the proposed model, LXL,
predicted image depth distribution maps and radar 3D occupancy grids are
utilized to aid image view transformation, called "radar occupancy-assisted
depth-based sampling". Experiments on VoD and TJ4DRadSet datasets show that the
proposed method outperforms existing 3D object detection methods by a
significant margin without bells and whistles. Ablation studies demonstrate
that our method performs the best among different enhancement settings.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：SSC3OD: Sparsely Supervised Collaborative 3D Object Detection from LiDAR  Point Clouds</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00717</p>
  <p><b>作者</b>：Yushan Han,  Hui Zhang,  Honglei Zhang,  Yidong Li</p>
  <p><b>备注</b>：8 pages, 3 figures, IEEE International Conference on Systems, Man, and Cybernetics (SMC 2023)</p>
  <p><b>关键词</b>：improved interaction advantage, autonomous driving, improved interaction, interaction advantage, advantage among multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Collaborative 3D object detection, with its improved interaction advantage
among multiple agents, has been widely explored in autonomous driving. However,
existing collaborative 3D object detectors in a fully supervised paradigm
heavily rely on large-scale annotated 3D bounding boxes, which is
labor-intensive and time-consuming. To tackle this issue, we propose a sparsely
supervised collaborative 3D object detection framework SSC3OD, which only
requires each agent to randomly label one object in the scene. Specifically,
this model consists of two novel components, i.e., the pillar-based masked
autoencoder (Pillar-MAE) and the instance mining module. The Pillar-MAE module
aims to reason over high-level semantics in a self-supervised manner, and the
instance mining module generates high-quality pseudo labels for collaborative
detectors online. By introducing these simple yet effective mechanisms, the
proposed SSC3OD can alleviate the adverse impacts of incomplete annotations. We
generate sparse labels based on collaborative perception datasets to evaluate
our method. Extensive experiments on three large-scale datasets reveal that our
proposed SSC3OD can effectively improve the performance of sparsely supervised
collaborative 3D object detectors.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：JourneyDB: A Benchmark for Generative Image Understanding</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00716</p>
  <p><b>作者</b>：Junting Pan,  Keqiang Sun,  Yuying Ge,  Hao Li,  Haodong Duan,  Xiaoshi Wu,  Renrui Zhang,  Aojun Zhou,  Zipeng Qin,  Yi Wang,  Jifeng Dai,  Yu Qiao,  Hongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent advancements, advancements in vision-language, remains unclear, possess the capabilities, capabilities of comprehending</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While recent advancements in vision-language models have revolutionized
multi-modal understanding, it remains unclear whether they possess the
capabilities of comprehending the generated images. Compared to real data,
synthetic images exhibit a higher degree of diversity in both content and
style, for which there are significant difficulties for the models to fully
apprehend. To this end, we present a large-scale dataset, JourneyDB, for
multi-modal visual understanding in generative images. Our curated dataset
covers 4 million diverse and high-quality generated images paired with the text
prompts used to produce them. We further design 4 benchmarks to quantify the
performance of generated image understanding in terms of both content and style
interpretation. These benchmarks include prompt inversion, style retrieval,
image captioning and visual question answering. Lastly, we assess the
performance of current state-of-the-art multi-modal models when applied to
JourneyDB, and provide an in-depth analysis of their strengths and limitations
in generated content understanding. We hope the proposed dataset and benchmarks
will facilitate the research in the field of generative content understanding.
The dataset will be available on this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Guided Patch-Grouping Wavelet Transformer with Spatial Congruence for  Ultra-High Resolution Segmentation</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00711</p>
  <p><b>作者</b>：Deyi Ji,  Feng Zhao,  Hongtao Lu</p>
  <p><b>备注</b>：Accepted to IJCAI 2023</p>
  <p><b>关键词</b>：balancing memory cost, proposed Guided, local characterization accuracy, existing ultra-high resolution, Patch-Grouping Wavelet Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing ultra-high resolution (UHR) segmentation methods always
struggle in the dilemma of balancing memory cost and local characterization
accuracy, which are both taken into account in our proposed Guided
Patch-Grouping Wavelet Transformer (GPWFormer) that achieves impressive
performances. In this work, GPWFormer is a Transformer ($\mathcal{T}$)-CNN
($\mathcal{C}$) mutual leaning framework, where $\mathcal{T}$ takes the whole
UHR image as input and harvests both local details and fine-grained long-range
contextual dependencies, while $\mathcal{C}$ takes downsampled image as input
for learning the category-wise deep context. For the sake of high inference
speed and low computation complexity, $\mathcal{T}$ partitions the original UHR
image into patches and groups them dynamically, then learns the low-level local
details with the lightweight multi-head Wavelet Transformer (WFormer) network.
Meanwhile, the fine-grained long-range contextual dependencies are also
captured during this process, since patches that are far away in the spatial
domain can also be assigned to the same group. In addition, masks produced by
$\mathcal{C}$ are utilized to guide the patch grouping process, providing a
heuristics decision. Moreover, the congruence constraints between the two
branches are also exploited to maintain the spatial consistency among the
patches. Overall, we stack the multi-stage process in a pyramid way.
Experiments show that GPWFormer outperforms the existing methods with
significant improvements on five benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Efficient Visual Fault Detection for Freight Train Braking System via  Heterogeneous Self Distillation in the Wild</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00701</p>
  <p><b>作者</b>：Yang Zhang,  Huilin Pan,  Yang Zhou,  Mingying Li,  Guodong Sun</p>
  <p><b>备注</b>：12 pages, 9 figures</p>
  <p><b>关键词</b>：restricted hardware environment, Efficient visual fault, visual fault detection, freight train fault, train fault detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient visual fault detection of freight trains is a critical part of
ensuring the safe operation of railways under the restricted hardware
environment. Although deep learning-based approaches have excelled in object
detection, the efficiency of freight train fault detection is still
insufficient to apply in real-world engineering. This paper proposes a
heterogeneous self-distillation framework to ensure detection accuracy and
speed while satisfying low resource requirements. The privileged information in
the output feature knowledge can be transferred from the teacher to the student
model through distillation to boost performance. We first adopt a lightweight
backbone to extract features and generate a new heterogeneous knowledge neck.
Such neck models positional information and long-range dependencies among
channels through parallel encoding to optimize feature extraction capabilities.
Then, we utilize the general distribution to obtain more credible and accurate
bounding box estimates. Finally, we employ a novel loss function that makes the
network easily concentrate on values near the label to improve learning
efficiency. Experiments on four fault datasets reveal that our framework can
achieve over 37 frames per second and maintain the highest accuracy in
comparison with traditional distillation approaches. Moreover, compared to
state-of-the-art methods, our framework demonstrates more competitive
performance with lower memory usage and the smallest model size.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Camera Calibration from a Single Imaged Ellipsoid: A Moon Calibration  Algorithm</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00689</p>
  <p><b>作者</b>：Kalani R. Danas Rivera,  Mason A. Peck</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：camera calibration, extended bodies, camera, extended bodies consist, introduces a method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work introduces a method that applies images of the extended bodies in
the solar system to spacecraft camera calibration. The extended bodies consist
of planets and moons that are well-modeled by triaxial ellipsoids. When imaged,
the triaxial ellipsoid projects to a conic section which is generally an
ellipse. This work combines the imaged ellipse with information on the
observer's target-relative state to achieve camera calibration from a single
imaged ellipsoid. As such, this work is the first to accomplish camera
calibration from a single, non-spherical imaged ellipsoid. The camera
calibration algorithm is applied to synthetic images of ellipsoids as well as
planetary images of Saturn's moons as captured by the Cassini spacecraft. From
a single image, the algorithm estimates the focal length and principal point of
Cassini's Narrow Angle Camera within 1.0 mm and 10 pixels, respectively. With
multiple images, the one standard deviation uncertainty in focal length and
principal point estimates reduce to 0.5 mm and 3.1 pixels, respectively. Though
created for spacecraft camera calibration in mind, this work also generalizes
to terrestrial camera calibration using any number of imaged ellipsoids.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：A Proximal Algorithm for Network Slimming</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00684</p>
  <p><b>作者</b>：Kevin Bui,  Fanghui Xue,  Fredrick Park,  Yingyong Qi,  Jack Xin</p>
  <p><b>备注</b>：accepted to LOD'23</p>
  <p><b>关键词</b>：popular channel pruning, channel pruning method, convolutional neural networks, batch normalization layers, network slimming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a popular channel pruning method for convolutional neural networks (CNNs),
network slimming (NS) has a three-stage process: (1) it trains a CNN with
$\ell_1$ regularization applied to the scaling factors of the batch
normalization layers; (2) it removes channels whose scaling factors are below a
chosen threshold; and (3) it retrains the pruned model to recover the original
accuracy. This time-consuming, three-step process is a result of using
subgradient descent to train CNNs. Because subgradient descent does not exactly
train CNNs towards sparse, accurate structures, the latter two steps are
necessary. Moreover, subgradient descent does not have any convergence
guarantee. Therefore, we develop an alternative algorithm called proximal NS.
Our proposed algorithm trains CNNs towards sparse, accurate structures, so
identifying a scaling factor threshold is unnecessary and fine tuning the
pruned CNNs is optional. Using Kurdyka-Łojasiewicz assumptions, we establish
global convergence of proximal NS. Lastly, we validate the efficacy of the
proposed algorithm on VGGNet, DenseNet and ResNet on CIFAR 10/100. Our
experiments demonstrate that after one round of training, proximal NS yields a
CNN with competitive accuracy and compression.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Pay Attention to the Atlas: Atlas-Guided Test-Time Adaptation Method for  Robust 3D Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00676</p>
  <p><b>作者</b>：Jingjie Guo,  Weitong Zhang,  Matthew Sinclair,  Daniel Rueckert,  Chen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical imaging applications, Convolutional neural networks, imaging appearances, source training data, imaging applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) often suffer from poor performance when
tested on target data that differs from the training (source) data
distribution, particularly in medical imaging applications where variations in
imaging protocols across different clinical sites and scanners lead to
different imaging appearances. However, re-accessing source training data for
unsupervised domain adaptation or labeling additional test data for model
fine-tuning can be difficult due to privacy issues and high labeling costs,
respectively. To solve this problem, we propose a novel atlas-guided test-time
adaptation (TTA) method for robust 3D medical image segmentation, called
AdaAtlas. AdaAtlas only takes one single unlabeled test sample as input and
adapts the segmentation network by minimizing an atlas-based loss.
Specifically, the network is adapted so that its prediction after registration
is aligned with the learned atlas in the atlas space, which helps to reduce
anatomical segmentation errors at test time. In addition, different from most
existing TTA methods which restrict the adaptation to batch normalization
blocks in the segmentation network only, we further exploit the use of channel
and spatial attention blocks for improved adaptability at test time. Extensive
experiments on multiple datasets from different sites show that AdaAtlas with
attention blocks adapted (AdaAtlas-Attention) achieves superior performance
improvements, greatly outperforming other competitive TTA methods.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Real-time Vision-based Navigation for a Robot in an Indoor Environment</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00666</p>
  <p><b>作者</b>：Sagar Manglani (Stanford University)</p>
  <p><b>备注</b>：8 pages, 7 figures</p>
  <p><b>关键词</b>：obstacle-avoidance navigation system, home environments, paper presents, presents a study, system utilizes vision-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a study on the development of an obstacle-avoidance
navigation system for autonomous navigation in home environments. The system
utilizes vision-based techniques and advanced path-planning algorithms to
enable the robot to navigate toward the destination while avoiding obstacles.
The performance of the system is evaluated through qualitative and quantitative
metrics, highlighting its strengths and limitations. The findings contribute to
the advancement of indoor robot navigation, showcasing the potential of
vision-based techniques for real-time, autonomous navigation.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：CNN-BiLSTM model for English Handwriting Recognition: Comprehensive  Evaluation on the IAM Dataset</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00664</p>
  <p><b>作者</b>：Firat Kizilirmak,  Berrin Yanikoglu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offline English handwriting, public IAM dataset, offline English, English handwriting recognition, including the effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a CNN-BiLSTM system for the problem of offline English handwriting
recognition, with extensive evaluations on the public IAM dataset, including
the effects of model size, data augmentation and the lexicon. Our best model
achieves 3.59\% CER and 9.44\% WER using CNN-BiLSTM network with CTC layer.
Test time augmentation with rotation and shear transformations applied to the
input image, is proposed to increase recognition of difficult cases and found
to reduce the word error rate by 2.5\% points. We also conduct an error
analysis of our proposed method on IAM dataset, show hard cases of handwriting
images and explore samples with erroneous labels. We provide our source code as
public-domain, to foster further research to encourage scientific
reproducibility.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：More Synergy, Less Redundancy: Exploiting Joint Mutual Information for  Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00651</p>
  <p><b>作者</b>：Salman Mohamadi,  Gianfranco Doretto,  Donald A. Adjeroh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require data annotation, Self-supervised learning, SSL, supervised learning, information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) is now a serious competitor for supervised
learning, even though it does not require data annotation. Several baselines
have attempted to make SSL models exploit information about data distribution,
and less dependent on the augmentation effect. However, there is no clear
consensus on whether maximizing or minimizing the mutual information between
representations of augmentation views practically contribute to improvement or
degradation in performance of SSL models. This paper is a fundamental work
where, we investigate role of mutual information in SSL, and reformulate the
problem of SSL in the context of a new perspective on mutual information. To
this end, we consider joint mutual information from the perspective of partial
information decomposition (PID) as a key step in \textbf{reliable multivariate
information measurement}. PID enables us to decompose joint mutual information
into three important components, namely, unique information, redundant
information and synergistic information. Our framework aims for minimizing the
redundant information between views and the desired target representation while
maximizing the synergistic information at the same time. Our experiments lead
to a re-calibration of two redundancy reduction baselines, and a proposal for a
new SSL training protocol. Extensive experimental results on multiple datasets
and two downstream tasks show the effectiveness of this framework.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Intra- & Extra-Source Exemplar-Based Style Synthesis for Improved Domain  Generalization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00648</p>
  <p><b>作者</b>：Yumeng Li,  Dan Zhang,  Margret Keuper,  Anna Khoreva</p>
  <p><b>备注</b>：An extended version of the accepted WACV paper arXiv:2210.10175</p>
  <p><b>关键词</b>：remaining big challenges, deep learning models, autonomous driving, remaining big, big challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The generalization with respect to domain shifts, as they frequently appear
in applications such as autonomous driving, is one of the remaining big
challenges for deep learning models. Therefore, we propose an exemplar-based
style synthesis pipeline to improve domain generalization in semantic
segmentation. Our method is based on a novel masked noise encoder for StyleGAN2
inversion. The model learns to faithfully reconstruct the image, preserving its
semantic layout through noise prediction. Using the proposed masked noise
encoder to randomize style and content combinations in the training set, i.e.,
intra-source style augmentation (ISSA) effectively increases the diversity of
training data and reduces spurious correlation. As a result, we achieve up to
$12.4\%$ mIoU improvements on driving-scene semantic segmentation under
different types of data shifts, i.e., changing geographic locations, adverse
weather conditions, and day to night. ISSA is model-agnostic and
straightforwardly applicable with CNNs and Transformers. It is also
complementary to other domain generalization techniques, e.g., it improves the
recent state-of-the-art solution RobustNet by $3\%$ mIoU in Cityscapes to Dark
Zürich. In addition, we demonstrate the strong plug-n-play ability of the
proposed style synthesis pipeline, which is readily usable for extra-source
exemplars e.g., web-crawled images, without any retraining or fine-tuning.
Moreover, we study a new use case to indicate neural network's generalization
capability by building a stylized proxy validation set. This application has
significant practical sense for selecting models to be deployed in the
open-world environment. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：The Forward-Forward Algorithm as a feature extractor for skin lesion  classification: A preliminary study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00617</p>
  <p><b>作者</b>：Abel Reyes-Angulo,  Sidike Paheding</p>
  <p><b>备注</b>：This is a camera-ready version of the paper for the LXAI @ ICML'23 workshop</p>
  <p><b>关键词</b>：deadly form, form of cancer, cancer, survival rate, Skin cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin cancer, a deadly form of cancer, exhibits a 23\% survival rate in the
USA with late diagnosis. Early detection can significantly increase the
survival rate, and facilitate timely treatment. Accurate biomedical image
classification is vital in medical analysis, aiding clinicians in disease
diagnosis and treatment. Deep learning (DL) techniques, such as convolutional
neural networks and transformers, have revolutionized clinical decision-making
automation. However, computational cost and hardware constraints limit the
implementation of state-of-the-art DL architectures. In this work, we explore a
new type of neural network that does not need backpropagation (BP), namely the
Forward-Forward Algorithm (FFA), for skin lesion classification. While FFA is
claimed to use very low-power analog hardware, BP still tends to be superior in
terms of classification accuracy. In addition, our experimental results suggest
that the combination of FFA and BP can be a better alternative to achieve a
more accurate prediction.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：RH20T: A Robotic Dataset for Learning Diverse Skills in One-Shot</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00595</p>
  <p><b>作者</b>：Hao-Shu Fang,  Hongjie Fang,  Zhenyu Tang,  Jirong Liu,  Junbo Wang,  Haoyi Zhu,  Cewu Lu</p>
  <p><b>备注</b>：RSS 2023 workshop on LTAMP. The project page is at rh20t.github.io</p>
  <p><b>关键词</b>：key challenge, challenge in robotic, open domains, skills, generalizable skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key challenge in robotic manipulation in open domains is how to acquire
diverse and generalizable skills for robots. Recent research in one-shot
imitation learning has shown promise in transferring trained policies to new
tasks based on demonstrations. This feature is attractive for enabling robots
to acquire new skills and improving task and motion planning. However, due to
limitations in the training dataset, the current focus of the community has
mainly been on simple cases, such as push or pick-place tasks, relying solely
on visual guidance. In reality, there are many complex skills, some of which
may even require both visual and tactile perception to solve. This paper aims
to unlock the potential for an agent to generalize to hundreds of real-world
skills with multi-modal perception. To achieve this, we have collected a
dataset comprising over 110,000 \emph{contact-rich} robot manipulation
sequences across diverse skills, contexts, robots, and camera viewpoints, all
collected \emph{in the real world}. Each sequence in the dataset includes
visual, force, audio, and action information, along with a corresponding human
demonstration video. We have invested significant efforts in calibrating all
the sensors and ensuring a high-quality dataset. The dataset is made publicly
available at this http URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：X-MLP: A Patch Embedding-Free MLP Architecture for Vision</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00592</p>
  <p><b>作者</b>：Xinyue Wang,  Zhicheng Cai,  Chenglei Peng</p>
  <p><b>备注</b>：IJCNN 2023</p>
  <p><b>关键词</b>：Convolutional neural networks, obtained great achievements, Convolutional neural, neural networks, obtained great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) and vision transformers (ViT) have
obtained great achievements in computer vision. Recently, the research of
multi-layer perceptron (MLP) architectures for vision have been popular again.
Vision MLPs are designed to be independent from convolutions and self-attention
operations. However, existing vision MLP architectures always depend on
convolution for patch embedding. Thus we propose X-MLP, an architecture
constructed absolutely upon fully connected layers and free from patch
embedding. It decouples the features extremely and utilizes MLPs to interact
the information across the dimension of width, height and channel independently
and alternately. X-MLP is tested on ten benchmark datasets, all obtaining
better performance than other vision MLP models. It even surpasses CNNs by a
clear margin on various dataset. Furthermore, through mathematically restoring
the spatial weights, we visualize the information communication between any
couples of pixels in the feature map and observe the phenomenon of capturing
long-range dependency.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：ClipSitu: Effectively Leveraging CLIP for Conditional Predictions in  Situation Recognition</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00586</p>
  <p><b>作者</b>：Debaditya Roy,  Dhruv Verma,  Basura Fernando</p>
  <p><b>备注</b>：State-of-the-art results on Situation Recognition</p>
  <p><b>关键词</b>：semantic roles played, situation recognition task, semantic roles, activity verb, Situation Recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Situation Recognition is the task of generating a structured summary of what
is happening in an image using an activity verb and the semantic roles played
by actors and objects. In this task, the same activity verb can describe a
diverse set of situations as well as the same actor or object category can play
a diverse set of semantic roles depending on the situation depicted in the
image. Hence model needs to understand the context of the image and the
visual-linguistic meaning of semantic roles. Therefore, we leverage the CLIP
foundational model that has learned the context of images via language
descriptions. We show that deeper-and-wider multi-layer perceptron (MLP) blocks
obtain noteworthy results for the situation recognition task by using CLIP
image and text embedding features and it even outperforms the state-of-the-art
CoFormer, a Transformer-based model, thanks to the external implicit
visual-linguistic knowledge encapsulated by CLIP and the expressive power of
modern MLP block designs. Motivated by this, we design a cross-attention-based
Transformer using CLIP visual tokens that model the relation between textual
roles and visual entities. Our cross-attention-based Transformer known as
ClipSitu XTF outperforms existing state-of-the-art by a large margin of 14.1%
on semantic role labelling (value) for top-1 accuracy using imSitu dataset. We
will make the code publicly available.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：TinySiamese Network for Biometric Analysis</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00578</p>
  <p><b>作者</b>：Islem Jarraya,  Tarek M. Hamdani,  Habib Chabchoub,  Adel M. Alimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classifying human characteristics, process of verifying, verifying or classifying, classifying human, human characteristics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biometric recognition is the process of verifying or classifying human
characteristics in images or videos. It is a complex task that requires machine
learning algorithms, including convolutional neural networks (CNNs) and Siamese
networks. Besides, there are several limitations to consider when using these
algorithms for image verification and classification tasks. In fact, training
may be computationally intensive, requiring specialized hardware and
significant computational resources to train and deploy. Moreover, it
necessitates a large amount of labeled data, which can be time-consuming and
costly to obtain. The main advantage of the proposed TinySiamese compared to
the standard Siamese is that it does not require the whole CNN for training. In
fact, using a pre-trained CNN as a feature extractor and the TinySiamese to
learn the extracted features gave almost the same performance and efficiency as
the standard Siamese for biometric verification. In this way, the TinySiamese
solves the problems of memory and computational time with a small number of
layers which did not exceed 7. It can be run under low-power machines which
possess a normal GPU and cannot allocate a large RAM space. Using TinySiamese
with only 8 GO of memory, the matching time decreased by 76.78% on the B2F
(Biometric images of Fingerprints and Faces), FVC2000, FVC2002 and FVC2004
while the training time for 10 epochs went down by approximately 93.14% on the
B2F, FVC2002, THDD-part1 and CASIA-B datasets. The accuracy of the fingerprint,
gait (NM-angle 180 degree) and face verification tasks was better than the
accuracy of a standard Siamese by 0.87%, 20.24% and 3.85% respectively.
TinySiamese achieved comparable accuracy with related works for the fingerprint
and gait classification tasks.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Bidirectional Temporal Diffusion Model for Temporally Consistent Human  Animation</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00574</p>
  <p><b>作者</b>：Tserendorj Adiya,  Sanghun Kim,  ung Eun Lee,  Jae Shin Yoon,  Hwasup Lim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：temporally coherent human, generate temporally coherent, coherent human animation, temporally coherent, human animation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a method to generate temporally coherent human animation from a
single image, a video, or a random noise. This problem has been formulated as
modeling of an auto-regressive generation, i.e., to regress past frames to
decode future frames. However, such unidirectional generation is highly prone
to motion drifting over time, generating unrealistic human animation with
significant artifacts such as appearance distortion. We claim that
bidirectional temporal modeling enforces temporal coherence on a generative
network by largely suppressing the motion ambiguity of human appearance. To
prove our claim, we design a novel human animation framework using a denoising
diffusion model: a neural network learns to generate the image of a person by
denoising temporal Gaussian noises whose intermediate results are
cross-conditioned bidirectionally between consecutive frames. In the
experiments, our method demonstrates strong performance compared to existing
unidirectional approaches with realistic temporal coherence</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：A MIL Approach for Anomaly Detection in Surveillance Videos from  Multiple Camera Views</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00562</p>
  <p><b>作者</b>：Silas Santiago Lopes Pereira,  José Everardo Bessa Maia</p>
  <p><b>备注</b>：8 Pages, 4 Figures</p>
  <p><b>关键词</b>：scene states, states that make, make it difficult, difficult to detect, detect anomalies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Occlusion and clutter are two scene states that make it difficult to detect
anomalies in surveillance video. Furthermore, anomaly events are rare and, as a
consequence, class imbalance and lack of labeled anomaly data are also key
features of this task. Therefore, weakly supervised methods are heavily
researched for this application. In this paper, we tackle these typical
problems of anomaly detection in surveillance video by combining Multiple
Instance Learning (MIL) to deal with the lack of labels and Multiple Camera
Views (MC) to reduce occlusion and clutter effects. In the resulting MC-MIL
algorithm we apply a multiple camera combined loss function to train a
regression network with Sultani's MIL ranking function. To evaluate the MC-MIL
algorithm first proposed here, the multiple camera PETS-2009 benchmark dataset
was re-labeled for the anomaly detection task from multiple camera views. The
result shows a significant performance improvement in F1 score compared to the
single-camera configuration.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Partial-label Learning with Mixed Closed-set and Open-set  Out-of-candidate Examples</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00553</p>
  <p><b>作者</b>：Shuo He,  Lei Feng,  Guowu Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：candidate label set, label set OOC, label set, OOC, true label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Partial-label learning (PLL) relies on a key assumption that the true label
of each training example must be in the candidate label set. This restrictive
assumption may be violated in complex real-world scenarios, and thus the true
label of some collected examples could be unexpectedly outside the assigned
candidate label set. In this paper, we term the examples whose true label is
outside the candidate label set OOC (out-of-candidate) examples, and pioneer a
new PLL study to learn with OOC examples. We consider two types of OOC examples
in reality, i.e., the closed-set/open-set OOC examples whose true label is
inside/outside the known label space. To solve this new PLL problem, we first
calculate the wooden cross-entropy loss from candidate and non-candidate labels
respectively, and dynamically differentiate the two types of OOC examples based
on specially designed criteria. Then, for closed-set OOC examples, we conduct
reversed label disambiguation in the non-candidate label set; for open-set OOC
examples, we leverage them for training by utilizing an effective
regularization strategy that dynamically assigns random candidate labels from
the candidate label set. In this way, the two types of OOC examples can be
differentiated and further leveraged for model training. Extensive experiments
demonstrate that our proposed method outperforms state-of-the-art PLL methods.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Referring Video Object Segmentation with Inter-Frame Interaction and  Cross-Modal Correlation</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00536</p>
  <p><b>作者</b>：Meng Lan,  Fu Rong,  Lefei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Referring video object, video sequence, video object segmentation, aims to segment, Referring video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Referring video object segmentation (RVOS) aims to segment the target object
in a video sequence described by a language expression. Typical query-based
methods process the video sequence in a frame-independent manner to reduce the
high computational cost, which however affects the performance due to the lack
of inter-frame interaction for temporal coherence modeling and spatio-temporal
representation learning of the referred object. Besides, they directly adopt
the raw and high-level sentence feature as the language queries to decode the
visual features, where the weak correlation between visual and linguistic
features also increases the difficulty of decoding the target information and
limits the performance of the model. In this paper, we proposes a novel RVOS
framework, dubbed IFIRVOS, to address these issues. Specifically, we design a
plug-and-play inter-frame interaction module in the Transformer decoder to
efficiently learn the spatio-temporal features of the referred object, so as to
decode the object information in the video sequence more precisely and generate
more accurate segmentation results. Moreover, we devise the vision-language
interaction module before the multimodal Transformer to enhance the correlation
between the visual and linguistic features, thus facilitating the process of
decoding object information from visual features by language queries in
Transformer decoder and improving the segmentation performance. Extensive
experimental results on three benchmarks validate the superiority of our
IFIRVOS over state-of-the-art methods and the effectiveness of our proposed
modules.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00522</p>
  <p><b>作者</b>：Linoy Tsaban (1),  Apolinário Passos (1) ((1) Hugging Face)</p>
  <p><b>备注</b>：8 pages, 5 figures, 1 table. This report builds up on the works introduced in - arXiv:2304.06140, arXiv:2301.12247</p>
  <p><b>关键词</b>：Recent large-scale text-guided, large-scale text-guided diffusion, provide powerful image-generation, text-guided diffusion models, diffusion models provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent large-scale text-guided diffusion models provide powerful
image-generation capabilities. Currently, a significant effort is given to
enable the modification of these images using text only as means to offer
intuitive and versatile editing. However, editing proves to be difficult for
these generative models due to the inherent nature of editing techniques, which
involves preserving certain content from the original image. Conversely, in
text-based models, even minor modifications to the text prompt frequently
result in an entirely distinct result, making attaining one-shot generation
that accurately corresponds to the users intent exceedingly challenging. In
addition, to edit a real image using these state-of-the-art tools, one must
first invert the image into the pre-trained models domain - adding another
factor affecting the edit quality, as well as latency. In this exploratory
report, we propose LEDITS - a combined lightweight approach for real-image
editing, incorporating the Edit Friendly DDPM inversion technique with Semantic
Guidance, thus extending Semantic Guidance to real image editing, while
harnessing the editing capabilities of DDPM inversion as well. This approach
achieves versatile edits, both subtle and extensive as well as alterations in
composition and style, while requiring no optimization nor extensions to the
architecture.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：End-to-End Out-of-distribution Detection with Self-supervised Sampling</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00519</p>
  <p><b>作者</b>：Sen Pei,  Jiaxi Sun,  Peng Qin,  Qi Chen,  Xinglong Wu,  Xun Wang</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2301.06657</p>
  <p><b>关键词</b>：identify unknown data, open world, OOD detection, closed set, set to identify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection empowers the model trained on the closed
set to identify unknown data in the open world. Though many prior techniques
have yielded considerable improvements, two crucial obstacles still remain.
Firstly, a unified perspective has yet to be presented to view the developed
arts with individual designs, which is vital for providing insights into the
related directions. Secondly, most research focuses on the post-processing
schemes of the pre-trained features while disregarding the superiority of
end-to-end training, dramatically limiting the upper bound of OOD detection. To
tackle these issues, we propose a general probabilistic framework to interpret
many existing methods and an OOD-data-free model, namely Self-supervised
Sampling for OOD Detection (SSOD), to unfold the potential of end-to-end
learning. SSOD efficiently exploits natural OOD signals from the
in-distribution (ID) data based on the local property of convolution. With
these supervisions, it jointly optimizes the OOD detection and conventional ID
classification. Extensive experiments reveal that SSOD establishes competitive
state-of-the-art performance on many large-scale benchmarks, where it
outperforms the most recent approaches, such as KNN, by a large margin, e.g.,
48.99% to 35.52% on SUN at FPR95.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Data-Free Quantization via Mixed-Precision Compensation without  Fine-Tuning</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00498</p>
  <p><b>作者</b>：Jun Chen,  Shipeng Bai,  Tianxin Huang,  Mengmeng Wang,  Guanzhong Tian,  Yong Liu</p>
  <p><b>备注</b>：This paper has been accepted for publication in the Pattern Recognition</p>
  <p><b>关键词</b>：Neural network quantization, resulting accuracy highly, accuracy highly depends, Neural network, highly depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network quantization is a very promising solution in the field of
model compression, but its resulting accuracy highly depends on a
training/fine-tuning process and requires the original data. This not only
brings heavy computation and time costs but also is not conducive to privacy
and sensitive information protection. Therefore, a few recent works are
starting to focus on data-free quantization. However, data-free quantization
does not perform well while dealing with ultra-low precision quantization.
Although researchers utilize generative methods of synthetic data to address
this problem partially, data synthesis needs to take a lot of computation and
time. In this paper, we propose a data-free mixed-precision compensation
(DF-MPC) method to recover the performance of an ultra-low precision quantized
model without any data and fine-tuning process. By assuming the quantized error
caused by a low-precision quantized layer can be restored via the
reconstruction of a high-precision quantized layer, we mathematically formulate
the reconstruction loss between the pre-trained full-precision model and its
layer-wise mixed-precision quantized model. Based on our formulation, we
theoretically deduce the closed-form solution by minimizing the reconstruction
loss of the feature maps. Since DF-MPC does not require any original/synthetic
data, it is a more efficient method to approximate the full-precision model.
Experimentally, our DF-MPC is able to achieve higher accuracy for an ultra-low
precision quantized model compared to the recent methods without any data and
fine-tuning process.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：TopicFM+: Boosting Accuracy and Efficiency of Topic-Assisted Feature  Matching</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00485</p>
  <p><b>作者</b>：Khang Truong Giang,  Soohwan Song,  Sungho Jo</p>
  <p><b>备注</b>：Paper extension of TopicFM (arXiv:2207.00328)</p>
  <p><b>关键词</b>：limited texture, study tackles, significant variations, variations or limited, strong emphasis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study tackles the challenge of image matching in difficult scenarios,
such as scenes with significant variations or limited texture, with a strong
emphasis on computational efficiency. Previous studies have attempted to
address this challenge by encoding global scene contexts using Transformers.
However, these approaches suffer from high computational costs and may not
capture sufficient high-level contextual information, such as structural shapes
or semantic instances. Consequently, the encoded features may lack
discriminative power in challenging scenes. To overcome these limitations, we
propose a novel image-matching method that leverages a topic-modeling strategy
to capture high-level contexts in images. Our method represents each image as a
multinomial distribution over topics, where each topic represents a latent
semantic instance. By incorporating these topics, we can effectively capture
comprehensive context information and obtain discriminative and high-quality
features. Additionally, our method effectively matches features within
corresponding semantic regions by estimating the covisible topics. To enhance
the efficiency of feature matching, we have designed a network with a
pooling-and-merging attention module. This module reduces computation by
employing attention only on fixed-sized topics and small-sized features.
Through extensive experiments, we have demonstrated the superiority of our
method in challenging scenarios. Specifically, our method significantly reduces
computational costs while maintaining higher image-matching accuracy compared
to state-of-the-art methods. The code will be updated soon at
this https URL</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Seeing is not Believing: An Identity Hider for Human Vision Privacy  Protection</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00481</p>
  <p><b>作者</b>：Tao Wang,  Yushu Zhang,  Zixuan Yang,  Hua Zhang,  Zhongyun Hua</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Massive captured face, captured face images, visual content, face, identity hider</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Massive captured face images are stored in the database for the
identification of individuals. However, the stored images can be observed
intentionally or unintentionally by data managers, which is not at the will of
individuals and may cause privacy violations. Existing protection works only
slightly change the visual content of the face while maintaining the utility of
identification, making it susceptible to the inference of the true identity by
human vision. In this paper, we propose an identity hider that enables
significant visual content change for human vision while preserving high
identifiability for face recognizers. Firstly, the identity hider generates a
virtual face with new visual content by manipulating the latent space in
StyleGAN2. In particular, the virtual face has the same irrelevant attributes
as the original face, e.g., pose and expression. Secondly, the visual content
of the virtual face is transferred into the original face and then the
background is replaced with the original one. In addition, the identity hider
has strong transferability, which ensures an arbitrary face recognizer can
achieve satisfactory accuracy. Adequate experiments show that the proposed
identity hider achieves excellent performance on privacy protection and
identifiability preservation.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Query-Efficient Decision-based Black-Box Patch Attack</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00477</p>
  <p><b>作者</b>：Zhaoyu Chen,  Bo Li,  Shuang Wu,  Shouhong Ding,  Wenqiang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, imperceptible adversarial perturbations, decision-based patch attack, patch attacks, black-box patch attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have been showed to be highly vulnerable to
imperceptible adversarial perturbations. As a complementary type of adversary,
patch attacks that introduce perceptible perturbations to the images have
attracted the interest of researchers. Existing patch attacks rely on the
architecture of the model or the probabilities of predictions and perform
poorly in the decision-based setting, which can still construct a perturbation
with the minimal information exposed -- the top-1 predicted label. In this
work, we first explore the decision-based patch attack. To enhance the attack
efficiency, we model the patches using paired key-points and use targeted
images as the initialization of patches, and parameter optimizations are all
performed on the integer domain. Then, we propose a differential evolutionary
algorithm named DevoPatch for query-efficient decision-based patch attacks.
Experiments demonstrate that DevoPatch outperforms the state-of-the-art
black-box patch attacks in terms of patch area and attack success rate within a
given query budget on image classification and face verification. Additionally,
we conduct the vulnerability evaluation of ViT and MLP on image classification
in the decision-based patch attack setting for the first time. Using DevoPatch,
we can evaluate the robustness of models to black-box patch attacks. We believe
this method could inspire the design and deployment of robust vision models
based on various DNN architectures in the future.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Human-to-Human Interaction Detection</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00464</p>
  <p><b>作者</b>：Zhenhua Wang,  Kaining Ying,  Jiajun Meng,  Jifeng Ning,  Cong Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interactive groups, concurrent interactive groups, fighting and chasing, squares and parks, understanding of interested</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A comprehensive understanding of interested human-to-human interactions in
video streams, such as queuing, handshaking, fighting and chasing, is of
immense importance to the surveillance of public security in regions like
campuses, squares and parks. Different from conventional human interaction
recognition, which uses choreographed videos as inputs, neglects concurrent
interactive groups, and performs detection and recognition in separate stages,
we introduce a new task named human-to-human interaction detection (HID). HID
devotes to detecting subjects, recognizing person-wise actions, and grouping
people according to their interactive relations, in one model. First, based on
the popular AVA dataset created for action detection, we establish a new HID
benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive
relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and
86,338 interactive groups, and each image includes up to 4 concurrent
interactive groups. Second, we present a novel baseline approach SaMFormer for
HID, containing a visual feature extractor, a split stage which leverages a
Transformer-based model to decode action instances and interactive groups, and
a merging stage which reconstructs the relationship between instances and
groups. All SaMFormer components are jointly trained in an end-to-end manner.
Extensive experiments on AVA-I validate the superiority of SaMFormer over
representative methods. The dataset and code will be made public to encourage
more follow-up studies.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：One Copy Is All You Need: Resource-Efficient Streaming of Medical  Imaging Data at Scale</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00438</p>
  <p><b>作者</b>：Pranav Kulkarni,  Adway Kanhere,  Eliot Siegel,  Paul H. Yi,  Vishwa S. Parekh</p>
  <p><b>备注</b>：13 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：clinical decision support, artificial intelligence tools, decision support, accelerated development, development of artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale medical imaging datasets have accelerated development of
artificial intelligence tools for clinical decision support. However, the large
size of these datasets is a bottleneck for users with limited storage and
bandwidth. Many users may not even require such large datasets as AI models are
often trained on lower resolution images. If users could directly download at
their desired resolution, storage and bandwidth requirements would
significantly decrease. However, it is impossible to anticipate every users'
requirements and impractical to store the data at multiple resolutions. What if
we could store images at a single resolution but send them at different ones?
We propose MIST, an open-source framework to operationalize progressive
resolution for streaming medical images at multiple resolutions from a single
high-resolution copy. We demonstrate that MIST can dramatically reduce imaging
infrastructure inefficiencies for hosting and streaming medical images by >90%,
while maintaining diagnostic quality for deep learning applications.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：WaveMixSR: A Resource-efficient Neural Network for Image  Super-resolution</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00430</p>
  <p><b>作者</b>：Pranav Jeevan,  Akella Srinidhi,  Pasunuri Prathiba,  Amit Sethi</p>
  <p><b>备注</b>：10 pages, 3 figures</p>
  <p><b>关键词</b>：super-resolution research recently, complexity of self-attention, research recently, recently been dominated, dominated by transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image super-resolution research recently been dominated by transformer models
which need higher computational resources than CNNs due to the quadratic
complexity of self-attention. We propose a new neural network -- WaveMixSR --
for image super-resolution based on WaveMix architecture which uses a
2D-discrete wavelet transform for spatial token-mixing. Unlike
transformer-based models, WaveMixSR does not unroll the image as a sequence of
pixels/patches. It uses the inductive bias of convolutions along with the
lossless token-mixing property of wavelet transform to achieve higher
performance while requiring fewer resources and training data. We compare the
performance of our network with other state-of-the-art methods for image
super-resolution. Our experiments show that WaveMixSR achieves competitive
performance in all datasets and reaches state-of-the-art performance in the
BSD100 dataset on multiple super-resolution tasks. Our model is able to achieve
this performance using less training data and computational resources while
maintaining high parameter efficiency compared to current state-of-the-art
models.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Brightness-Restricted Adversarial Attack Patch</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00421</p>
  <p><b>作者</b>：Mingzhen Shao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained increasing attention, increasing attention due, gained increasing, increasing attention, attention due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial attack patches have gained increasing attention due to their
practical applicability in physical-world scenarios. However, the bright colors
used in attack patches represent a significant drawback, as they can be easily
identified by human observers. Moreover, even though these attacks have been
highly successful in deceiving target networks, which specific features of the
attack patch contribute to its success are still unknown. Our paper introduces
a brightness-restricted patch (BrPatch) that uses optical characteristics to
effectively reduce conspicuousness while preserving image independence. We also
conducted an analysis of the impact of various image features (such as color,
texture, noise, and size) on the effectiveness of an attack patch in
physical-world deployment. Our experiments show that attack patches exhibit
strong redundancy to brightness and are resistant to color transfer and noise.
Based on our findings, we propose some additional methods to further reduce the
conspicuousness of BrPatch. Our findings also explain the robustness of attack
patches observed in physical-world scenarios.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Applications of Binary Similarity and Distance Measures</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00411</p>
  <p><b>作者</b>：Manoj Muniswamaiah,  Tilak Agerwala,  Charles C. Tappert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：handwritten character detection, biometric identification problems, iris image recognition, solving biometric identification, including fingerprint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the recent past, binary similarity measures have been applied in solving
biometric identification problems, including fingerprint, handwritten character
detection, and in iris image recognition. The application of the relevant
measurements has also resulted in more accurate data analysis. This paper
surveys the applicability of binary similarity and distance measures in various
fields.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：WavePaint: Resource-efficient Token-mixer for Self-supervised Inpainting</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00407</p>
  <p><b>作者</b>：Pranav Jeevan,  Dharshan Sampath Kumar,  Amit Sethi</p>
  <p><b>备注</b>：11 pages, 7 figures</p>
  <p><b>关键词</b>：task for self-supervision, synthesis of missing, missing regions, restore occluded, occluded or degraded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image inpainting, which refers to the synthesis of missing regions in an
image, can help restore occluded or degraded areas and also serve as a
precursor task for self-supervision. The current state-of-the-art models for
image inpainting are computationally heavy as they are based on transformer or
CNN backbones that are trained in adversarial or diffusion settings. This paper
diverges from vision transformers by using a computationally-efficient
WaveMix-based fully convolutional architecture -- WavePaint. It uses a
2D-discrete wavelet transform (DWT) for spatial and multi-resolution
token-mixing along with convolutional layers. The proposed model outperforms
the current state-of-the-art models for image inpainting on reconstruction
quality while also using less than half the parameter count and considerably
lower training and evaluation times. Our model even outperforms current
GAN-based architectures in CelebA-HQ dataset without using an adversarially
trainable discriminator. Our work suggests that neural architectures that are
modeled after natural image priors require fewer parameters and computations to
achieve generalization comparable to transformers.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00398</p>
  <p><b>作者</b>：Uddeshya Upadhyay,  Shyamgopal Karthik,  Massimiliano Mancini,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully find correspondences, CLIP successfully find, successfully find, find correspondences, CLIP successfully</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language models (VLMs) like CLIP successfully find
correspondences between images and text. Through the standard deterministic
mapping process, an image or a text sample is mapped to a single vector in the
embedding space. This is problematic: as multiple samples (images or text) can
abstract the same concept in the physical world, deterministic embeddings do
not reflect the inherent ambiguity in the embedding space. We propose ProbVLM,
a probabilistic adapter that estimates probability distributions for the
embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc
manner without needing large-scale datasets or computing. On four challenging
datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the
multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify
the calibration of embedding uncertainties in retrieval tasks and show that
ProbVLM outperforms other methods. Furthermore, we propose active learning and
model selection as two real-world downstream tasks for VLMs and show that the
estimated uncertainty aids both tasks. Lastly, we present a novel technique for
visualizing the embedding distributions using a large-scale pre-trained latent
diffusion model.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Improving CNN-based Person Re-identification using score Normalization</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00397</p>
  <p><b>作者</b>：Ammar Chouchane,  Abdelmalik Ouamane,  Yassine Himeur,  Wathiq Mansoor,  Shadi Atalla,  Afaf Benzaibak,  Chahrazed Boudellal</p>
  <p><b>备注</b>：5 pages, 6 figures and 2 tables</p>
  <p><b>关键词</b>：Person re-identification, involves identifying, identifying an individual, individual across multiple, crucial task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Person re-identification (PRe-ID) is a crucial task in security,
surveillance, and retail analysis, which involves identifying an individual
across multiple cameras and views. However, it is a challenging task due to
changes in illumination, background, and viewpoint. Efficient feature
extraction and metric learning algorithms are essential for a successful PRe-ID
system. This paper proposes a novel approach for PRe-ID, which combines a
Convolutional Neural Network (CNN) based feature extraction method with
Cross-view Quadratic Discriminant Analysis (XQDA) for metric learning.
Additionally, a matching algorithm that employs Mahalanobis distance and a
score normalization process to address inconsistencies between camera scores is
implemented. The proposed approach is tested on four challenging datasets,
including VIPeR, GRID, CUHK01, and PRID450S, and promising results are
obtained. For example, without normalization, the rank-20 rate accuracies of
the GRID, CUHK01, VIPeR and PRID450S datasets were 61.92%, 83.90%, 92.03%,
96.22%; however, after score normalization, they have increased to 64.64%,
89.30%, 92.78%, and 98.76%, respectively. Accordingly, the promising results on
four challenging datasets indicate the effectiveness of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00395</p>
  <p><b>作者</b>：Mustafa Munir,  William Avery,  Radu Marculescu</p>
  <p><b>备注</b>：Proceedings of the 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</p>
  <p><b>关键词</b>：convolutional neural networks, dominated computer vision, graph neural networks, neural networks, dominated computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, convolutional neural networks (CNN) and vision transformers
(ViT) have dominated computer vision. However, recently proposed vision graph
neural networks (ViG) provide a new avenue for exploration. Unfortunately, for
mobile applications, ViGs are computationally expensive due to the overhead of
representing images as graph structures. In this work, we propose a new
graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA),
that is designed for ViGs running on mobile devices. Additionally, we propose
the first hybrid CNN-GNN architecture for vision tasks on mobile devices,
MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats
existing ViG models and existing mobile CNN and ViT architectures in terms of
accuracy and/or speed on image classification, object detection, and instance
segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1
accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU
(compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7%
top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model,
MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is
faster and more accurate than the similarly sized EfficientFormer-L3 model
(2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN
architectures can be a new avenue of exploration for designing models that are
extremely fast and accurate on mobile devices. Our code is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Learning Content-enhanced Mask Transformer for Domain Generalized  Urban-Scene Segmentation</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00371</p>
  <p><b>作者</b>：Qi Bi,  Shaodi You,  Theo Gevers</p>
  <p><b>备注</b>：18 pages, 10 figures</p>
  <p><b>关键词</b>：generalized semantic predictions, learn generalized semantic, predictions across diverse, content-enhanced mask attention, diverse urban-scene styles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain-generalized urban-scene semantic segmentation (USSS) aims to learn
generalized semantic predictions across diverse urban-scene styles. Unlike
domain gap challenges, USSS is unique in that the semantic categories are often
similar in different urban scenes, while the styles can vary significantly due
to changes in urban landscapes, weather conditions, lighting, and other
factors. Existing approaches typically rely on convolutional neural networks
(CNNs) to learn the content of urban scenes.
In this paper, we propose a Content-enhanced Mask TransFormer (CMFormer) for
domain-generalized USSS. The main idea is to enhance the focus of the
fundamental component, the mask attention mechanism, in Transformer
segmentation models on content information. To achieve this, we introduce a
novel content-enhanced mask attention mechanism. It learns mask queries from
both the image feature and its down-sampled counterpart, as lower-resolution
image features usually contain more robust content information and are less
sensitive to style variations. These features are fused into a Transformer
decoder and integrated into a multi-resolution content-enhanced mask attention
learning scheme.
Extensive experiments conducted on various domain-generalized urban-scene
segmentation datasets demonstrate that the proposed CMFormer significantly
outperforms existing CNN-based methods for domain-generalized semantic
segmentation, achieving improvements of up to 14.00\% in terms of mIoU (mean
intersection over union). The source code for CMFormer will be made available
at this
\href{this https URL}{repository}.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Minimizing Energy Consumption of Deep Learning Models by Energy-Aware  Training</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00368</p>
  <p><b>作者</b>：Dario Lazzaro,  Antonio Emanuele Cinà,  Maura Pintor,  Ambra Demontis,  Battista Biggio,  Fabio Roli,  Marcello Pelillo</p>
  <p><b>备注</b>：12 pages, 3 figures. Paper accepted at the 22nd International Conference on Image Analysis and Processing (ICIAP) 2023</p>
  <p><b>关键词</b>：learning models undergo, number of parameters, larger number, number of operations, parameters they possess</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models undergo a significant increase in the number of
parameters they possess, leading to the execution of a larger number of
operations during inference. This expansion significantly contributes to higher
energy consumption and prediction latency. In this work, we propose EAT, a
gradient-based algorithm that aims to reduce energy consumption during model
training. To this end, we leverage a differentiable approximation of the
$\ell_0$ norm, and use it as a sparse penalty over the training loss. Through
our experimental analysis conducted on three datasets and two deep neural
networks, we demonstrate that our energy-aware training algorithm EAT is able
to train networks with a better trade-off between classification performance
and energy efficiency.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object  Detection</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00347</p>
  <p><b>作者</b>：Yifan Zhang,  Zhiyu Zhu,  Junhui Hou</p>
  <p><b>备注</b>：16 pages, 8 figures</p>
  <p><b>关键词</b>：showcasing impressive performance, object detection systems, CNN-based object detection, object detection, Detection Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Detection Transformer (DETR) has revolutionized the design of CNN-based
object detection systems, showcasing impressive performance. However, its
potential in the domain of multi-frame 3D object detection remains largely
unexplored. In this paper, we present STEMD, a novel end-to-end framework for
multi-frame 3D object detection based on the DETR-like paradigm. Our approach
treats multi-frame 3D object detection as a sequence-to-sequence task and
effectively captures spatial-temporal dependencies at both the feature and
query levels. To model the inter-object spatial interaction and complex
temporal dependencies, we introduce the spatial-temporal graph attention
network. This network represents queries as nodes in a graph and enables
effective modeling of object interactions within a social context. In addition,
to solve the problem of missing hard cases in the proposed output of the
encoder in the current frame, we incorporate the output of the previous frame
to initialize the query input of the decoder. Moreover, we tackle the issue of
redundant detection results, where the model generates numerous overlapping
boxes from similar queries. To mitigate this, we introduce an IoU
regularization term in the loss function. This term aids in distinguishing
between queries matched with the ground-truth box and queries that are similar
but unmatched during the refinement process, leading to reduced redundancy and
more accurate detections. Through extensive experiments, we demonstrate the
effectiveness of our approach in handling challenging scenarios, while
incurring only a minor additional computational overhead. The code will be
available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Variation-aware Vision Transformer Quantization</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00331</p>
  <p><b>作者</b>：Xijie Huang,  Zhiqiang Shen,  Kwang-Ting Cheng</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：Vision Transformers, performance of Vision, visual tasks, remarkable performance, increased the demand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable performance of Vision Transformers (ViTs) in various
visual tasks, the expanding computation and model size of ViTs have increased
the demand for improved efficiency during training and inference. To address
the heavy computation and parameter drawbacks, quantization is frequently
studied in the community as a representative model compression technique and
has seen extensive use on CNNs. However, due to the unique properties of CNNs
and ViTs, the quantization applications on ViTs are still limited and
underexplored. In this paper, we identify the difficulty of ViT quantization on
its unique variation behaviors, which differ from traditional CNN
architectures. The variations indicate the magnitude of the parameter
fluctuations and can also measure outlier conditions. Moreover, the variation
behaviors reflect the various sensitivities to the quantization of each module.
The quantization sensitivity analysis and comparison of ViTs with CNNs help us
locate the underlying differences in variations. We also find that the
variations in ViTs cause training oscillations, bringing instability during
quantization-aware training (QAT). Correspondingly, we solve the variation
problem with an efficient knowledge-distillation-based variation-aware
quantization method. The multi-crop knowledge distillation scheme can
accelerate and stabilize the training and alleviate the variation's influence
during QAT. We also proposed a module-dependent quantization scheme and a
variation-aware regularization term to suppress the oscillation of weights. On
ImageNet-1K, we obtain a 77.66% Top-1 accuracy on the extremely low-bit
scenario of 2-bit Swin-T, outperforming the previous state-of-the-art quantized
model by 3.35%.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：SDRCNN: A single-scale dense residual connected convolutional neural  network for pansharpening</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00327</p>
  <p><b>作者</b>：Yuan Fang,  Yuanzhi Cai,  Lei Fan</p>
  <p><b>备注</b>：This paper has been accepted for publication in the IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</p>
  <p><b>关键词</b>：resolution multispectral image, spatial resolution multispectral, resolution panchromatic image, high-resolution multispectral image, high spatial resolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pansharpening is a process of fusing a high spatial resolution panchromatic
image and a low spatial resolution multispectral image to create a
high-resolution multispectral image. A novel single-branch, single-scale
lightweight convolutional neural network, named SDRCNN, is developed in this
study. By using a novel dense residual connected structure and convolution
block, SDRCNN achieved a better trade-off between accuracy and efficiency. The
performance of SDRCNN was tested using four datasets from the WorldView-3,
WorldView-2 and QuickBird satellites. The compared methods include eight
traditional methods (i.e., GS, GSA, PRACS, BDSD, SFIM, GLP-CBD, CDIF and
LRTCFPan) and five lightweight deep learning methods (i.e., PNN, PanNet,
BayesianNet, DMDNet and FusionNet). Based on a visual inspection of the
pansharpened images created and the associated absolute residual maps, SDRCNN
exhibited least spatial detail blurring and spectral distortion, amongst all
the methods considered. The values of the quantitative evaluation metrics were
closest to their ideal values when SDRCNN was used. The processing time of
SDRCNN was also the shortest among all methods tested. Finally, the
effectiveness of each component in the SDRCNN was demonstrated in ablation
experiments. All of these confirmed the superiority of SDRCNN.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis  Across the Spectrum</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00324</p>
  <p><b>作者</b>：Kishore Babu Nampalle,  Pradeep Singh,  Uppala Vivek Narayan,  Balasubramanian Raman</p>
  <p><b>备注</b>：23 pages, 3 figures, 4 tables, 1 algorithm</p>
  <p><b>关键词</b>：achieving high accuracy, rapidly evolving landscape, computational efficiency remains, achieving high, rapidly evolving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the rapidly evolving landscape of medical imaging diagnostics, achieving
high accuracy while preserving computational efficiency remains a formidable
challenge. This work presents \texttt{DeepMediX}, a groundbreaking,
resource-efficient model that significantly addresses this challenge. Built on
top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI
scans and skin cancer images, with superior performance demonstrated on both
binary and multiclass skin cancer datasets. It provides a solution to
labor-intensive manual processes, the need for large datasets, and complexities
related to image properties. DeepMediX's design also includes the concept of
Federated Learning, enabling a collaborative learning approach without
compromising data privacy. This approach allows diverse healthcare institutions
to benefit from shared learning experiences without the necessity of direct
data access, enhancing the model's predictive power while preserving the
privacy and integrity of sensitive patient data. Its low computational
footprint makes DeepMediX suitable for deployment on handheld devices, offering
potential for real-time diagnostic support. Through rigorous testing on
standard datasets, including the ISIC2018 for dermatological research,
DeepMediX demonstrates exceptional diagnostic capabilities, matching the
performance of existing models on almost all tasks and even outperforming them
in some cases. The findings of this study underline significant implications
for the development and deployment of AI-based tools in medical imaging and
their integration into point-of-care settings. The source code and models
generated would be released at this https URL.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Automatic Solver Generator for Systems of Laurent Polynomial Equations</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00320</p>
  <p><b>作者</b>：Evgeniy Martyushev,  Snehal Bhayani,  Tomas Pajdla</p>
  <p><b>备注</b>：12 pages, 4 tables, 5 figures. arXiv admin note: text overlap with arXiv:2203.14901</p>
  <p><b>关键词</b>：monomial structure, structure but varying, family member, polynomial systems, varying coefficients</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In computer vision applications, the following problem often arises: Given a
family of (Laurent) polynomial systems with the same monomial structure but
varying coefficients, find a solver that computes solutions for any family
member as fast as possible. Under appropriate genericity assumptions, the
dimension and degree of the respective polynomial ideal remain unchanged for
each particular system in the same family. The state-of-the-art approach to
solving such problems is based on elimination templates, which are the
coefficient (Macaulay) matrices that encode the transformation from the initial
polynomials to the polynomials needed to construct the action matrix. Knowing
an action matrix, the solutions of the system are computed from its
eigenvectors. The important property of an elimination template is that it
applies to all polynomial systems in the family. In this paper, we propose a
new practical algorithm that checks whether a given set of Laurent polynomials
is sufficient to construct an elimination template. Based on this algorithm, we
propose an automatic solver generator for systems of Laurent polynomial
equations. The new generator is simple and fast; it applies to ideals with
positive-dimensional components; it allows one to uncover partial $p$-fold
symmetries automatically. We test our generator on various minimal problems,
mostly in geometric computer vision. The speed of the generated solvers exceeds
the state-of-the-art in most cases. In particular, we propose the solvers for
the following problems: optimal 3-view triangulation, semi-generalized hybrid
pose estimation and minimal time-of-arrival self-calibration. The experiments
on synthetic scenes show that our solvers are numerically accurate and either
comparable to or significantly faster than the state-of-the-art solvers.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Detection of River Sandbank for Sand Mining with the Presence of Other  High Mineral Content Regions Using Multi-spectral Images</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00314</p>
  <p><b>作者</b>：Jit Mukherjee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sand mining, river sandbank regions, river sandbank, booming industry, river</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sand mining is a booming industry. The river sandbank is one of the primary
sources of sand mining. Detection of potential river sandbank regions for sand
mining directly impacts the economy, society, and environment. In the past,
semi-supervised and supervised techniques have been used to detect mining
regions including sand mining. A few techniques employ multi-modal analysis
combining different modalities such as multi-spectral imaging, synthetic
aperture radar (\emph{SAR}) imaging, aerial images, and point cloud data.
However, the distinguishing spectral characteristics of river sandbank regions
are yet to be fully explored. This paper provides a novel method to detect
river sandbank regions for sand mining using multi-spectral images without any
labeled data over the seasons. Association with a river stream and the
abundance of minerals are the most prominent features of such a region. The
proposed work uses these distinguishing features to determine the spectral
signature of a river sandbank region, which is robust to other high mineral
abundance regions. It follows a two-step approach, where first, potential high
mineral regions are detected and next, they are segregated using the presence
of a river stream. The proposed technique provides average accuracy, precision,
and recall of 90.75%, 85.47%, and 73.5%, respectively over the seasons from
Landsat 8 images without using any labeled dataset.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：PM-DETR: Domain Adaptive Prompt Memory for Object Detection with  Transformers</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00313</p>
  <p><b>作者</b>：Peidong Jia,  Jiaming Liu,  Senqiao Yang,  Jiarui Wu,  Xiaodong Xie,  Shanghang Zhang</p>
  <p><b>备注</b>：cs.cv</p>
  <p><b>关键词</b>：Transformer-based detectors, demonstrated impressive performance, Prompt Domain Memory, demonstrated impressive, DETR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Transformer-based detectors (i.e., DETR) have demonstrated impressive
performance on end-to-end object detection. However, transferring DETR to
different data distributions may lead to a significant performance degradation.
Existing adaptation techniques focus on model-based approaches, which aim to
leverage feature alignment to narrow the distribution shift between different
domains. In this study, we propose a hierarchical Prompt Domain Memory (PDM)
for adapting detection transformers to different distributions. PDM
comprehensively leverages the prompt memory to extract domain-specific
knowledge and explicitly constructs a long-term memory space for the data
distribution, which represents better domain diversity compared to existing
methods. Specifically, each prompt and its corresponding distribution value are
paired in the memory space, and we inject top M distribution-similar prompts
into the input and multi-level embeddings of DETR. Additionally, we introduce
the Prompt Memory Alignment (PMA) to reduce the discrepancy between the source
and target domains by fully leveraging the domain-specific knowledge extracted
from the prompt domain memory. Extensive experiments demonstrate that our
method outperforms state-of-the-art domain adaptive object detection methods on
three benchmarks, including scene, synthetic to real, and weather adaptation.
Codes will be released.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Adversarial Attacks and Defenses on 3D Point Cloud Classification: A  Survey</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00309</p>
  <p><b>作者</b>：Hanieh Naderi,  Ivan V. Bajić</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully solved, solved a wide, wide range, Deep learning, Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has successfully solved a wide range of tasks in 2D vision as a
dominant AI technique. Recently, deep learning on 3D point clouds is becoming
increasingly popular for addressing various tasks in this field. Despite
remarkable achievements, deep learning algorithms are vulnerable to adversarial
attacks. These attacks are imperceptible to the human eye but can easily fool
deep neural networks in the testing and deployment stage. To encourage future
research, this survey summarizes the current progress on adversarial attack and
defense techniques on point cloud classification. This paper first introduces
the principles and characteristics of adversarial attacks and summarizes and
analyzes the adversarial example generation methods in recent years. Besides,
it classifies defense strategies as input transformation, data optimization,
and deep model modification. Finally, it presents several challenging issues
and future research directions in this domain.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D  Object Pose Estimation</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00306</p>
  <p><b>作者</b>：Fabian Duffhauss,  Sebastian Koch,  Hanna Ziesche,  Ngo Anh Vien,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at the IEEE Robotics and Automation Letters (RA-L) 2023</p>
  <p><b>关键词</b>：essential for automated, automated systems, systems to interact, interact safely, pose estimator called</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting objects and estimating their 6D poses is essential for automated
systems to interact safely with the environment. Most 6D pose estimators,
however, rely on a single camera frame and suffer from occlusions and
ambiguities due to object symmetries. We overcome this issue by presenting a
novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach
efficiently fuses the RGB-D frames from multiple perspectives in a deep
multi-directional fusion network and predicts predefined keypoints for all
objects in the scene simultaneously. Based on the keypoints and an instance
semantic segmentation, we efficiently compute the 6D poses by least-squares
fitting. To address the ambiguity issues for symmetric objects, we propose a
novel training procedure for symmetry-aware keypoint detection including a new
objective function. Our SyMFM6D network significantly outperforms the
state-of-the-art in both single-view and multi-view 6D pose estimation. We
furthermore show the effectiveness of our symmetry-aware training procedure and
demonstrate that our approach is robust towards inaccurate camera calibration
and dynamic camera setups.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：DreamIdentity: Improved Editability for Efficient Face-identity  Preserved Image Generation</b></summary>
  <p><b>编号</b>：[356]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00300</p>
  <p><b>作者</b>：Zhuowei Chen,  Shancheng Fang,  Wei Liu,  Qian He,  Mengqi Huang,  Yongdong Zhang,  Zhendong Mao</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：high-quality human-centric images, large-scale pre-trained, synthesize diverse, diverse and high-quality, high-quality human-centric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While large-scale pre-trained text-to-image models can synthesize diverse and
high-quality human-centric images, an intractable problem is how to preserve
the face identity for conditioned face images. Existing methods either require
time-consuming optimization for each face-identity or learning an efficient
encoder at the cost of harming the editability of models. In this work, we
present an optimization-free method for each face identity, meanwhile keeping
the editability for text-to-image models. Specifically, we propose a novel
face-identity encoder to learn an accurate representation of human faces, which
applies multi-scale face features followed by a multi-embedding projector to
directly generate the pseudo words in the text embedding space. Besides, we
propose self-augmented editability learning to enhance the editability of
models, which is achieved by constructing paired generated face and edited face
images using celebrity names, aiming at transferring mature ability of
off-the-shelf text-to-image models in celebrity faces to unseen faces.
Extensive experiments show that our methods can generate identity-preserved
images under different scenes at a much faster speed.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：AutoST: Training-free Neural Architecture Search for Spiking  Transformers</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00293</p>
  <p><b>作者</b>：Ziqing Wang,  Qidong Zhao,  Jinku Cui,  Xu Liu,  Dongkuan Xu</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：Spiking Neural Networks, gained considerable attention, Spiking Transformer architectures, Neural Networks, Spiking Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Transformers have gained considerable attention because they achieve
both the energy efficiency of Spiking Neural Networks (SNNs) and the high
capacity of Transformers. However, the existing Spiking Transformer
architectures, derived from ANNs, exhibit a notable architectural gap,
resulting in suboptimal performance compared to their ANN counterparts.
Traditional approaches to discovering optimal architectures primarily rely on
either manual procedures, which are time-consuming, or Neural Architecture
Search (NAS) methods, which are usually expensive in terms of memory footprints
and computation time. To address these limitations, we introduce AutoST, a
training-free NAS method for Spiking Transformers, to rapidly identify
high-performance and energy-efficient Spiking Transformer architectures. Unlike
existing training-free NAS methods, which struggle with the
non-differentiability and high sparsity inherent in SNNs, we propose to utilize
Floating-Point Operations (FLOPs) as a performance metric, which is independent
of model computations and training dynamics, leading to a stronger correlation
with performance. Moreover, to enable the search for energy-efficient
architectures, we leverage activation patterns during initialization to
estimate the energy consumption of Spiking Transformers. Our extensive
experiments show that AutoST models outperform state-of-the-art manually or
automatically designed SNN architectures on static and neuromorphic datasets,
while significantly reducing energy consumption.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with  Prompt-based Finetuning</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00290</p>
  <p><b>作者</b>：Can Cui,  Ruining Deng,  Quan Liu,  Tianyuan Yao,  Shunxing Bao,  Lucas W. Remedios,  Yucheng Tang,  Yuankai Huo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：zero-shot segmentation approach, generic zero-shot segmentation, recently proposed prompt-based, prompt-based segmentation model, SAM segmentation model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) is a recently proposed prompt-based
segmentation model in a generic zero-shot segmentation approach. With the
zero-shot segmentation capacity, SAM achieved impressive flexibility and
precision on various segmentation tasks. However, the current pipeline requires
manual prompts during the inference stage, which is still resource intensive
for biomedical image segmentation. In this paper, instead of using prompts
during the inference stage, we introduce a pipeline that utilizes the SAM,
called all-in-SAM, through the entire AI development workflow (from annotation
generation to model finetuning) without requiring manual prompts during the
inference stage. Specifically, SAM is first employed to generate pixel-level
annotations from weak prompts (e.g., points, bounding box). Then, the
pixel-level annotations are used to finetune the SAM segmentation model rather
than training from scratch. Our experimental results reveal two key findings:
1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a
nuclei segmentation task on the public Monuseg dataset, and 2) the utilization
of weak and few annotations for SAM finetuning achieves competitive performance
compared to using strong pixel-wise annotated data.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：SysNoise: Exploring and Benchmarking Training-Deployment System  Inconsistency</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00280</p>
  <p><b>作者</b>：Yan Wang,  Yuhang Li,  Ruihao Gong,  Aishan Liu,  Yanfei Wang,  Jian Hu,  Yongqiang Yao,  Yunchen Zhang,  Tianzi Xiao,  Fengwei Yu,  Xianglong Liu</p>
  <p><b>备注</b>：Proceedings of Machine Learning and Systems. 2023 Mar 18</p>
  <p><b>关键词</b>：deep learning, studies have shown, deep learning training-deployment, noises caused, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extensive studies have shown that deep learning models are vulnerable to
adversarial and natural noises, yet little is known about model robustness on
noises caused by different system implementations. In this paper, we for the
first time introduce SysNoise, a frequently occurred but often overlooked noise
in the deep learning training-deployment cycle. In particular, SysNoise happens
when the source training system switches to a disparate target system in
deployments, where various tiny system mismatch adds up to a non-negligible
difference. We first identify and classify SysNoise into three categories based
on the inference stage; we then build a holistic benchmark to quantitatively
measure the impact of SysNoise on 20+ models, comprehending image
classification, object detection, instance segmentation and natural language
processing tasks. Our extensive experiments revealed that SysNoise could bring
certain impacts on model robustness across different tasks and common
mitigations like data augmentation and adversarial training show limited
effects on it. Together, our findings open a new research topic and we hope
this work will raise research attention to deep learning deployment systems
accounting for model performance. We have open-sourced the benchmark and
framework at this https URL.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Common Knowledge Learning for Generating Transferable Adversarial  Examples</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00274</p>
  <p><b>作者</b>：Ruijie Yang,  Yuanfang Guo,  Junfu Wang,  Jiantao Zhou,  Yunhong Wang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：transfer-based adversarial attacks, unseen target model, black-box attacks, adversary generates adversarial, knowing its information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper focuses on an important type of black-box attacks, i.e.,
transfer-based adversarial attacks, where the adversary generates adversarial
examples by a substitute (source) model and utilize them to attack an unseen
target model, without knowing its information. Existing methods tend to give
unsatisfactory adversarial transferability when the source and target models
are from different types of DNN architectures (e.g. ResNet-18 and Swin
Transformer). In this paper, we observe that the above phenomenon is induced by
the output inconsistency problem. To alleviate this problem while effectively
utilizing the existing DNN models, we propose a common knowledge learning (CKL)
framework to learn better network weights to generate adversarial examples with
better transferability, under fixed network architectures. Specifically, to
reduce the model-specific features and obtain better output distributions, we
construct a multi-teacher framework, where the knowledge is distilled from
different teacher architectures into one student network. By considering that
the gradient of input is usually utilized to generated adversarial examples, we
impose constraints on the gradients between the student and teacher models, to
further alleviate the output inconsistency problem and enhance the adversarial
transferability. Extensive experiments demonstrate that our proposed work can
significantly improve the adversarial transferability.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：HrSegNet : Real-time High-Resolution Neural Network with Semantic  Guidance for Crack Segmentation</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00270</p>
  <p><b>作者</b>：Yongshang Li,  Ronggui Ma,  Han Liu,  Gaoli Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rough detection, fine-grained detection, deep learning models, deep learning, recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Through extensive research on deep learning in recent years and its
application in construction, crack detection has evolved rapidly from rough
detection at the image-level and patch-level to fine-grained detection at the
pixel-level, which better suits the nature of this field. Despite numerous
existing studies utilizing off-the-shelf deep learning models or enhancing
them, these models are not always effective or efficient in real-world
applications. In order to bridge this gap, we propose a High-resolution model
with Semantic guidance, specifically designed for real-time crack segmentation,
referred to as HrSegNet. Our model maintains high resolution throughout the
entire process, as opposed to recovering from low-resolution features to
high-resolution ones, thereby maximizing the preservation of crack details.
Moreover, to enhance the context information, we use low-resolution semantic
features to guide the reconstruction of high-resolution features. To ensure the
efficiency of the algorithm, we design a simple yet effective method to control
the computation cost of the entire model by controlling the capacity of
high-resolution channels, while providing the model with extremely strong
scalability. Extensive quantitative and qualitative evaluations demonstrate
that our proposed HrSegNet has exceptional crack segmentation capabilities, and
that maintaining high resolution and semantic guidance are crucial to the final
prediction. Compared to state-of-the-art segmentation models, HrSegNet achieves
the best trade-off between efficiency and effectiveness. Specifically, on the
crack dataset CrackSeg9k, our fastest model HrSegNet-B16 achieves a speed of
182 FPS with 78.43% mIoU, while our most accurate model HrSegNet-B48 achieves
80.32% mIoU with an inference speed of 140.3 FPS.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：AE-RED: A Hyperspectral Unmixing Framework Powered by Deep Autoencoder  and Regularization by Denoising</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00269</p>
  <p><b>作者</b>：Min Zhao,  Jie Chen,  Nicolas Dobigeon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unmixing, extensively studied, Spectral unmixing, methods, unmixing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spectral unmixing has been extensively studied with a variety of methods and
used in many applications. Recently, data-driven techniques with deep learning
methods have obtained great attention to spectral unmixing for its superior
learning ability to automatically learn the structure information. In
particular, autoencoder based architectures are elaborately designed to solve
blind unmixing and model complex nonlinear mixtures. Nevertheless, these
methods perform unmixing task as blackboxes and lack of interpretability. On
the other hand, conventional unmixing methods carefully design the regularizer
to add explicit information, in which algorithms such as plug-and-play (PnP)
strategies utilize off-the-shelf denoisers to plug powerful priors. In this
paper, we propose a generic unmixing framework to integrate the autoencoder
network with regularization by denoising (RED), named AE-RED. More specially,
we decompose the unmixing optimized problem into two subproblems. The first one
is solved using deep autoencoders to implicitly regularize the estimates and
model the mixture mechanism. The second one leverages the denoiser to bring in
the explicit information. In this way, both the characteristics of the deep
autoencoder based unmixing methods and priors provided by denoisers are merged
into our well-designed framework to enhance the unmixing performance.
Experiment results on both synthetic and real data sets show the superiority of
our proposed framework compared with state-of-the-art unmixing approaches.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Efficient Subclass Segmentation in Medical Images</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00257</p>
  <p><b>作者</b>：Linrui Dai,  Wenhui Lei,  Xiaofan Zhang</p>
  <p><b>备注</b>：MICCAI 2023 early accept</p>
  <p><b>关键词</b>：analysis become increasingly, annotations, fine-grained, subclass, extensive annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As research interests in medical image analysis become increasingly
fine-grained, the cost for extensive annotation also rises. One feasible way to
reduce the cost is to annotate with coarse-grained superclass labels while
using limited fine-grained annotations as a complement. In this way,
fine-grained data learning is assisted by ample coarse annotations. Recent
studies in classification tasks have adopted this method to achieve
satisfactory results. However, there is a lack of research on efficient
learning of fine-grained subclasses in semantic segmentation tasks. In this
paper, we propose a novel approach that leverages the hierarchical structure of
categories to design network architecture. Meanwhile, a task-driven data
generation method is presented to make it easier for the network to recognize
different subclass categories. Specifically, we introduce a Prior Concatenation
module that enhances confidence in subclass segmentation by concatenating
predicted logits from the superclass classifier, a Separate Normalization
module that stretches the intra-class distance within the same superclass to
facilitate subclass segmentation, and a HierarchicalMix model that generates
high-quality pseudo labels for unlabeled samples by fusing only similar
superclass regions from labeled and unlabeled images. Our experiments on the
BraTS2021 and ACDC datasets demonstrate that our approach achieves comparable
accuracy to a model trained with full subclass annotations, with limited
subclass annotations and sufficient superclass annotations. Our approach offers
a promising solution for efficient fine-grained subclass segmentation in
medical images. Our code is publicly available here.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：VesselMorph: Domain-Generalized Retinal Vessel Segmentation via  Shape-Aware Representation</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00240</p>
  <p><b>作者</b>：Dewei Hu,  Hao Li,  Han Liu,  Xing Yao,  Jiacheng Wang,  Ipek Oguz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standardized imaging protocol, single standardized imaging, domain shift, learning-based algorithms, single standardized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the absence of a single standardized imaging protocol, domain shift
between data acquired from different sites is an inherent property of medical
images and has become a major obstacle for large-scale deployment of
learning-based algorithms. For retinal vessel images, domain shift usually
presents as the variation of intensity, contrast and resolution, while the
basic tubular shape of vessels remains unaffected. Thus, taking advantage of
such domain-invariant morphological features can greatly improve the
generalizability of deep models. In this study, we propose a method named
VesselMorph which generalizes the 2D retinal vessel segmentation task by
synthesizing a shape-aware representation. Inspired by the traditional Frangi
filter and the diffusion tensor imaging literature, we introduce a
Hessian-based bipolar tensor field to depict the morphology of the vessels so
that the shape information is taken into account. We map the intensity image
and the tensor field to a latent space for feature extraction. Then we fuse the
two latent representations via a weight-balancing trick and feed the result to
a segmentation network. We evaluate on six public datasets of fundus and OCT
angiography images from diverse patient populations. VesselMorph achieves
superior generalization performance compared with competing methods in
different domain shift scenarios.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Forward-Forward Algorithm for Hyperspectral Image Classification: A  Preliminary Study</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00231</p>
  <p><b>作者</b>：Sidike Paheding,  Abel A. Reyes-Angulo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, cutting-edge deep learning, learning models, de-facto standard, standard in optimizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The back-propagation algorithm has long been the de-facto standard in
optimizing weights and biases in neural networks, particularly in cutting-edge
deep learning models. Its widespread adoption in fields like natural language
processing, computer vision, and remote sensing has revolutionized automation
in various tasks. The popularity of back-propagation stems from its ability to
achieve outstanding performance in tasks such as classification, detection, and
segmentation. Nevertheless, back-propagation is not without its limitations,
encompassing sensitivity to initial conditions, vanishing gradients,
overfitting, and computational complexity. The recent introduction of a
forward-forward algorithm (FFA), which computes local goodness functions to
optimize network parameters, alleviates the dependence on substantial
computational resources and the constant need for architectural scaling. This
study investigates the application of FFA for hyperspectral image
classification. Experimental results and comparative analysis are provided with
the use of the traditional back-propagation algorithm. Preliminary results show
the potential behind FFA and its promises.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：S-Omninet: Structured Data Enhanced Universal Multimodal Learning  Architecture</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00226</p>
  <p><b>作者</b>：Ye Xue,  Diego Klabjan,  Jean Utke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, attracted an increasing, increasing interest, interest in recent, Multimodal multitask learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal multitask learning has attracted an increasing interest in recent
years. Singlemodal models have been advancing rapidly and have achieved
astonishing results on various tasks across multiple domains. Multimodal
learning offers opportunities for further improvements by integrating data from
multiple modalities. Many methods are proposed to learn on a specific type of
multimodal data, such as vision and language data. A few of them are designed
to handle several modalities and tasks at a time. In this work, we extend and
improve Omninet, an architecture that is capable of handling multiple
modalities and tasks at a time, by introducing cross-cache attention,
integrating patch embeddings for vision inputs, and supporting structured data.
The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model
that is capable of learning from structured data of various dimensions
effectively with unstructured data through cross-cache attention, which enables
interactions among spatial, temporal, and structured features. We also enhance
spatial representations in a spatial cache with patch embeddings. We evaluate
the proposed model on several multimodal datasets and demonstrate a significant
improvement over the baseline, Omninet.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：StyleStegan: Leak-free Style Transfer Based on Feature Steganography</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00225</p>
  <p><b>作者</b>：Xiujian Liang,  Bingshan Liu,  Qichao Ying,  Zhenxing Qian,  Xinpeng Zhang</p>
  <p><b>备注</b>：Under Review</p>
  <p><b>关键词</b>：modern social networks, social networks, style transfer method, style transfer, transfer methods suffer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In modern social networks, existing style transfer methods suffer from a
serious content leakage issue, which hampers the ability to achieve serial and
reversible stylization, thereby hindering the further propagation of stylized
images in social networks. To address this problem, we propose a leak-free
style transfer method based on feature steganography. Our method consists of
two main components: a style transfer method that accomplishes artistic
stylization on the original image and an image steganography method that embeds
content feature secrets on the stylized image. The main contributions of our
work are as follows: 1) We identify and explain the phenomenon of content
leakage and its underlying causes, which arise from content inconsistencies
between the original image and its subsequent stylized image. 2) We design a
neural flow model for achieving loss-free and biased-free style transfer. 3) We
introduce steganography to hide content feature information on the stylized
image and control the subsequent usage rights. 4) We conduct comprehensive
experimental validation using publicly available datasets MS-COCO and Wikiart.
The results demonstrate that StyleStegan successfully mitigates the content
leakage issue in serial and reversible style transfer tasks. The SSIM
performance metrics for these tasks are 14.98% and 7.28% higher, respectively,
compared to a suboptimal baseline model.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：More for Less: Compact Convolutional Transformers Enable Robust Medical  Image Classification with Limited Data</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00213</p>
  <p><b>作者</b>：Andrew Kean Gao</p>
  <p><b>备注</b>：9 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：tasks across domains, powerful tools, variety of tasks, text generation, Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are very powerful tools for a variety of tasks across domains,
from text generation to image captioning. However, transformers require
substantial amounts of training data, which is often a challenge in biomedical
settings, where high quality labeled data can be challenging or expensive to
obtain. This study investigates the efficacy of Compact Convolutional
Transformers (CCT) for robust medical image classification with limited data,
addressing a key issue faced by conventional Vision Transformers - their
requirement for large datasets. A hybrid of transformers and convolutional
layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed
a benchmark dataset of peripheral blood cell images of eight distinct cell
types, each represented by approximately 2,000 low-resolution (28x28x3 pixel)
samples. Despite the dataset size being smaller than those typically used with
Vision Transformers, we achieved a commendable classification accuracy of
92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly,
exceeding 80% validation accuracy after five epochs. Analysis of per-class
precision, recall, F1, and ROC showed that performance was strong across cell
types. Our findings underscore the robustness of CCTs, indicating their
potential as a solution to data scarcity issues prevalent in biomedical
imaging. We substantiate the applicability of CCTs in data-constrained areas
and encourage further work on CCTs.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Internal-External Boundary Attention Fusion for Glass Surface  Segmentation</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00212</p>
  <p><b>作者</b>：Dongshen Han,  Seungkyu Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uniquely and explicitly, explicitly characterized, reflected or transmitted, Glass, glass surface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Glass surfaces of transparent objects and mirrors are not able to be uniquely
and explicitly characterized by their visual appearances because they contain
the visual appearance of other reflected or transmitted surfaces as well.
Detecting glass regions from a single-color image is a challenging task. Recent
deep-learning approaches have paid attention to the description of glass
surface boundary where the transition of visual appearances between glass and
non-glass surfaces are observed. In this work, we analytically investigate how
glass surface boundary helps to characterize glass objects. Inspired by prior
semantic segmentation approaches with challenging image types such as X-ray or
CT scans, we propose separated internal-external boundary attention modules
that individually learn and selectively integrate visual characteristics of the
inside and outside region of glass surface from a single color image. Our
proposed method is evaluated on six public benchmarks comparing with
state-of-the-art methods showing promising results.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI  Generated Images: from the Perspectives of Quality, Authenticity and  Correspondence</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00211</p>
  <p><b>作者</b>：Jiarui Wang,  Huiyu Duan,  Jing Liu,  Shi Chen,  Xiongkuo Min,  Guangtao Zhai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：AIGC is established, human visual preferences, preferences for AIGIs, human visual, visual preferences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, in order to get a better understanding of the human visual
preferences for AIGIs, a large-scale IQA database for AIGC is established,
which is named as AIGCIQA2023. We first generate over 2000 images based on 6
state-of-the-art text-to-image generation models using 100 prompts.
Based on these images, a well-organized subjective experiment is conducted to
assess the human visual preferences for each image from three perspectives
including quality, authenticity and correspondence.
Finally, based on this large-scale database, we conduct a benchmark
experiment to evaluate the performance of several state-of-the-art IQA metrics
on our constructed database.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Image Matters: A New Dataset and Empirical Study for Multimodal  Hyperbole Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00209</p>
  <p><b>作者</b>：Huixuan Zhang,  Xiaojun Wan</p>
  <p><b>备注</b>：11 pages, 6 figures. 6 tables</p>
  <p><b>关键词</b>：common linguistic phenomenon, linguistic phenomenon, common linguistic, Hyperbole, hyperbole detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection
of hyperbole is an important part of understanding human expression. There have
been several studies on hyperbole detection, but most of which focus on text
modality only. However, with the development of social media, people can create
hyperbolic expressions with various modalities, including text, images, videos,
etc. In this paper, we focus on multimodal hyperbole detection. We create a
multimodal detection dataset\footnote{The dataset will be released to the
community.} from Weibo (a Chinese social media) and carry out some studies on
it. We treat the text and image from a piece of weibo as two modalities and
explore the role of text and image for hyperbole detection. Different
pre-trained multimodal encoders are also evaluated on this downstream task to
show their performance. Besides, since this dataset is constructed from five
different topics, we also evaluate the cross-domain performance of different
models. These studies can serve as a benchmark and point out the direction of
further study on multimodal hyperbole detection.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Filter Pruning for Efficient CNNs via Knowledge-driven Differential  Filter Sampler</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00198</p>
  <p><b>作者</b>：Shaohui Lin,  Wenxuan Huang,  Jiao Xie,  Baochang Zhang,  Yunhang Shen,  Zhou Yu,  Jungong Han,  David Doermann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pruning simultaneously accelerates, Masked Filter Modeling, Filter pruning simultaneously, overhead of CNNs, cloud services</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Filter pruning simultaneously accelerates the computation and reduces the
memory overhead of CNNs, which can be effectively applied to edge devices and
cloud services. In this paper, we propose a novel Knowledge-driven Differential
Filter Sampler~(KDFS) with Masked Filter Modeling~(MFM) framework for filter
pruning, which globally prunes the redundant filters based on the prior
knowledge of a pre-trained model in a differential and non-alternative
optimization. Specifically, we design a differential sampler with learnable
sampling parameters to build a binary mask vector for each layer, determining
whether the corresponding filters are redundant. To learn the mask, we
introduce masked filter modeling to construct PCA-like knowledge by aligning
the intermediate features from the pre-trained teacher model and the outputs of
the student decoder taking sampling features as the input. The mask and sampler
are directly optimized by the Gumbel-Softmax Straight-Through Gradient
Estimator in an end-to-end manner in combination with global pruning
constraint, MFM reconstruction error, and dark knowledge. Extensive experiments
demonstrate the proposed KDFS's effectiveness in compressing the base models on
various datasets. For instance, the pruned ResNet-50 on ImageNet achieves
$55.36\%$ computation reduction, and $42.86\%$ parameter reduction, while only
dropping $0.35\%$ Top-1 accuracy, significantly outperforming the
state-of-the-art methods. The code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Long-Tailed Continual Learning For Visual Food Recognition</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00183</p>
  <p><b>作者</b>：Jiangpeng He,  Luotao Lin,  Jack Ma,  Heather A. Eicher-Miller,  Fengqing Zhu</p>
  <p><b>备注</b>：13 pages, 9 figures</p>
  <p><b>关键词</b>：achieved remarkable progress, eating occasion image, Deep learning based, food, achieved remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning based food recognition has achieved remarkable progress in
predicting food types given an eating occasion image. However, there are two
major obstacles that hinder deployment in real world scenario. First, as new
foods appear sequentially overtime, a trained model needs to learn the new
classes continuously without causing catastrophic forgetting for already
learned knowledge of existing food types. Second, the distribution of food
images in real life is usually long-tailed as a small number of popular food
types are consumed more frequently than others, which can vary in different
populations. This requires the food recognition method to learn from
class-imbalanced data by improving the generalization ability on instance-rare
food classes. In this work, we focus on long-tailed continual learning and aim
to address both aforementioned challenges. As existing long-tailed food image
datasets only consider healthy people population, we introduce two new
benchmark food image datasets, VFN-INSULIN and VFN-T2D, which exhibits on the
real world food consumption for insulin takers and individuals with type 2
diabetes without taking insulin, respectively. We propose a novel end-to-end
framework for long-tailed continual learning, which effectively addresses the
catastrophic forgetting by applying an additional predictor for knowledge
distillation to avoid misalignment of representation during continual learning.
We also introduce a novel data augmentation technique by integrating
class-activation-map (CAM) and CutMix, which significantly improves the
generalization ability for instance-rare food classes to address the
class-imbalance issue. The proposed method show promising performance with
large margin improvements compared with existing methods.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Single-Stage Heavy-Tailed Food Classification</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00182</p>
  <p><b>作者</b>：Jiangpeng He,  Fengqing Zhu</p>
  <p><b>备注</b>：ICIP 2023</p>
  <p><b>关键词</b>：Deep learning based, accurate nutrition content, nutrition content analysis, image-based dietary assessment, eating occasion images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning based food image classification has enabled more accurate
nutrition content analysis for image-based dietary assessment by predicting the
types of food in eating occasion images. However, there are two major obstacles
to apply food classification in real life applications. First, real life food
images are usually heavy-tailed distributed, resulting in severe
class-imbalance issue. Second, it is challenging to train a single-stage (i.e.
end-to-end) framework under heavy-tailed data distribution, which cause the
over-predictions towards head classes with rich instances and under-predictions
towards tail classes with rare instance. In this work, we address both issues
by introducing a novel single-stage heavy-tailed food classification framework.
Our method is evaluated on two heavy-tailed food benchmark datasets, Food101-LT
and VFN-LT, and achieves the best performance compared to existing work with
over 5% improvements for top-1 accuracy.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Unsupervised Coordinate-Based Video Denoising</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00179</p>
  <p><b>作者</b>：Mary Damilola Aiyetigbo,  Dineshchandar Ravichandran,  Reda Chalhoub,  Peter Kalivas,  Nianyi Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：denoising deep learning, deep learning approach, mitigate data scarcity, data scarcity issues, enhancing its broad</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a novel unsupervised video denoising deep
learning approach that can help to mitigate data scarcity issues and shows
robustness against different noise patterns, enhancing its broad applicability.
Our method comprises three modules: a Feature generator creating features maps,
a Denoise-Net generating denoised but slightly blurry reference frames, and a
Refine-Net re-introducing high-frequency details. By leveraging the
coordinate-based network, we can greatly simplify the network structure while
preserving high-frequency details in the denoised video frames. Extensive
experiments on both simulated and real-captured demonstrate that our method can
effectively denoise real-world calcium imaging video sequences without prior
knowledge of noise models and data augmentation during training.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Stitched ViTs are Flexible Vision Backbones</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00154</p>
  <p><b>作者</b>：Zizheng Pan,  Jing Liu,  Haoyu He,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Tech report</p>
  <p><b>关键词</b>：plain vision Transformers, Large pretrained plain, vision Transformers, pretrained plain vision, Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained plain vision Transformers (ViTs) have been the workhorse for
many downstream tasks. However, existing works utilizing off-the-shelf ViTs are
inefficient in terms of training and deployment, because adopting ViTs with
individual sizes requires separate training and is restricted by fixed
performance-efficiency trade-offs. In this paper, we are inspired by stitchable
neural networks, which is a new framework that cheaply produces a single model
that covers rich subnetworks by stitching pretrained model families, supporting
diverse performance-efficiency trade-offs at runtime. Building upon this
foundation, we introduce SN-Netv2, a systematically improved model stitching
framework to facilitate downstream task adaptation. Specifically, we first
propose a Two-way stitching scheme to enlarge the stitching space. We then
design a resource-constrained sampling strategy that takes into account the
underlying FLOPs distributions in the space for improved sampling. Finally, we
observe that learning stitching layers is a low-rank update, which plays an
essential role on downstream tasks to stabilize training and ensure a good
Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K,
COCO-Stuff-10K, NYUv2 and COCO-2017, SN-Netv2 demonstrates strong ability to
serve as a flexible vision backbone, achieving great advantages in both
training efficiency and adaptation. Code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Hierarchical Neural Coding for Controllable CAD Model Generation</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00149</p>
  <p><b>作者</b>：Xiang Xu,  Pradeep Kumar Jayaraman,  Joseph G. Lambourne,  Karl D.D. Willis,  Yasutaka Furukawa</p>
  <p><b>备注</b>：Accepted to ICML 2023. Project website at this https URL</p>
  <p><b>关键词</b>：Computer Aided Design, Computer Aided, local curve geometry, global part arrangement, represents high-level design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel generative model for Computer Aided Design (CAD)
that 1) represents high-level design concepts of a CAD model as a three-level
hierarchical tree of neural codes, from global part arrangement down to local
curve geometry; and 2) controls the generation or completion of CAD models by
specifying the target design using a code tree. Concretely, a novel variant of
a vector quantized VAE with "masked skip connection" extracts design variations
as neural codebooks at three levels. Two-stage cascaded auto-regressive
transformers learn to generate code trees from incomplete CAD models and then
complete CAD models following the intended design. Extensive experiments
demonstrate superior performance on conventional tasks such as random
generation while enabling novel interaction capabilities on conditional
generation tasks. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：An End-to-End Review of Gaze Estimation and its Interactive Applications  on Handheld Mobile Devices</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00122</p>
  <p><b>作者</b>：Yaxiong Lei,  Shijing He,  Mohamed Khamis,  Juan Ye</p>
  <p><b>备注</b>：37 Pages, Paper accepted by ACM Computing Surveys</p>
  <p><b>关键词</b>：handheld mobile devices, complementary interaction modality, recent years, witnessed an increasing, increasing number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years we have witnessed an increasing number of interactive systems
on handheld mobile devices which utilise gaze as a single or complementary
interaction modality. This trend is driven by the enhanced computational power
of these devices, higher resolution and capacity of their cameras, and improved
gaze estimation accuracy obtained from advanced machine learning techniques,
especially in deep learning. As the literature is fast progressing, there is a
pressing need to review the state of the art, delineate the boundary, and
identify the key research challenges and opportunities in gaze estimation and
interaction. This paper aims to serve this purpose by presenting an end-to-end
holistic view in this area, from gaze capturing sensors, to gaze estimation
workflows, to deep learning techniques, and to gaze interactive applications.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns  Captured by Unmanned Aerial Systems</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00104</p>
  <p><b>作者</b>：Uma Meleti,  Abolfazl Razi</p>
  <p><b>备注</b>：6 pages, 6 figures</p>
  <p><b>关键词</b>：research paper addresses, covered by trees, natural barriers, detecting obscured wildfires, research paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research paper addresses the challenge of detecting obscured wildfires
(when the fire flames are covered by trees, smoke, clouds, and other natural
barriers) in real-time using drones equipped only with RGB cameras. We propose
a novel methodology that employs semantic segmentation based on the temporal
analysis of smoke patterns in video sequences. Our approach utilizes an
encoder-decoder architecture based on deep convolutional neural network
architecture with a pre-trained CNN encoder and 3D convolutions for decoding
while using sequential stacking of features to exploit temporal variations. The
predicted fire locations can assist drones in effectively combating forest
fires and pinpoint fire retardant chemical drop on exact flame locations. We
applied our method to a curated dataset derived from the FLAME2 dataset that
includes RGB video along with IR video to determine the ground truth. Our
proposed method has a unique property of detecting obscured fire and achieves a
Dice score of 85.88%, while achieving a high precision of 92.47% and
classification accuracy of 90.67% on test data showing promising results when
inspected visually. Indeed, our method outperforms other methods by a
significant margin in terms of video-level fire classification as we obtained
about 100% accuracy using MobileNet+CBAM as the encoder backbone.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Prompting classes: Exploring the Power of Prompt Class Learning in  Weakly Supervised Semantic Segmentation</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00097</p>
  <p><b>作者</b>：Balamurali Murugesan,  Rukhshanda Hussain,  Rajarshi Bhattacharya,  Ismail Ben Ayed,  Jose Dolz</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：contrastive language-vision pre-training, exhibited remarkable performance, few-shot learning tasks, CLIP-based approaches, approaches have exhibited</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, CLIP-based approaches have exhibited remarkable performance on
generalization and few-shot learning tasks, fueled by the power of contrastive
language-vision pre-training. In particular, prompt tuning has emerged as an
effective strategy to adapt the pre-trained language-vision models to
downstream tasks by employing task-related textual tokens. Motivated by this
progress, in this work we question whether other fundamental problems, such as
weakly supervised semantic segmentation (WSSS), can benefit from prompt tuning.
Our findings reveal two interesting observations that shed light on the impact
of prompt tuning on WSSS. First, modifying only the class token of the text
prompt results in a greater impact on the Class Activation Map (CAM), compared
to arguably more complex strategies that optimize the context. And second, the
class token associated with the image ground truth does not necessarily
correspond to the category that yields the best CAM. Motivated by these
observations, we introduce a novel approach based on a PrOmpt cLass lEarning
(POLE) strategy. Through extensive experiments we demonstrate that our simple,
yet efficient approach achieves SOTA performance in a well-known WSSS
benchmark. These results highlight not only the benefits of language-vision
models in WSSS but also the potential of prompt learning for this problem. The
code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：A Parts Based Registration Loss for Detecting Knee Joint Areas</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00083</p>
  <p><b>作者</b>：Juha Tiirola</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：knee joint areas, finetune registering knee, registering knee joint, parts based loss, joint areas</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a parts based loss is considered for finetune registering knee
joint areas. Here the parts are defined as abstract feature vectors with
location and they are automatically selected from a reference image. For a test
image the detected parts are encouraged to have a similar spatial configuration
than the corresponding parts in the reference image.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Situated Cameras, Situated Knowledges: Towards an Egocentric  Epistemology for Computer Vision</b></summary>
  <p><b>编号</b>：[466]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00064</p>
  <p><b>作者</b>：Samuel Goree,  David Crandall</p>
  <p><b>备注</b>：Presented at the CVPR 2023 Ego4D workshop</p>
  <p><b>关键词</b>：discuss scientific knowledge, Donna Haraway, Situated Knowledges, scientific knowledge, discuss scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In her influential 1988 paper, Situated Knowledges, Donna Haraway uses vision
and perspective as a metaphor to discuss scientific knowledge. Today,
egocentric computer vision discusses many of the same issues, except in a
literal vision context. In this short position paper, we collapse that
metaphor, and explore the interactions between feminist epistemology and
egocentric CV as "Egocentric Epistemology." Using this framework, we argue for
the use of qualitative, human-centric methods as a complement to performance
benchmarks, to center both the literal and metaphorical perspective of human
crowd workers in CV.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：DisCo: Disentangled Control for Referring Human Dance Generation in Real  World</b></summary>
  <p><b>编号</b>：[467]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00040</p>
  <p><b>作者</b>：Tan Wang,  Linjie Li,  Kevin Lin,  Chung-Ching Lin,  Zhengyuan Yang,  Hanwang Zhang,  Zicheng Liu,  Lijuan Wang</p>
  <p><b>备注</b>：Project Page: this https URL; Github Page: this https URL</p>
  <p><b>关键词</b>：made significant strides, computer vision, text descriptions, made significant, significant strides</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative AI has made significant strides in computer vision, particularly
in image/video synthesis conditioned on text descriptions. Despite the
advancements, it remains challenging especially in the generation of
human-centric content such as dance synthesis. Existing dance synthesis methods
struggle with the gap between synthesized content and real-world dance
scenarios. In this paper, we define a new problem setting: Referring Human
Dance Generation, which focuses on real-world dance scenarios with three
important properties: (i) Faithfulness: the synthesis should retain the
appearance of both human subject foreground and background from the reference
image, and precisely follow the target pose; (ii) Generalizability: the model
should generalize to unseen human subjects, backgrounds, and poses; (iii)
Compositionality: it should allow for composition of seen/unseen subjects,
backgrounds, and poses from different sources. To address these challenges, we
introduce a novel approach, DISCO, which includes a novel model architecture
with disentangled control to improve the faithfulness and compositionality of
dance synthesis, and an effective human attribute pre-training for better
generalizability to unseen humans. Extensive qualitative and quantitative
results demonstrate that DISCO can generate high-quality human dance images and
videos with diverse appearances and flexible motions. Code, demo, video and
visualization are available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Towards Brain Inspired Design for Addressing the Shortcomings of ANNs</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00039</p>
  <p><b>作者</b>：Fahad Sarfraz,  Elahe Arani,  Bahram Zonooz</p>
  <p><b>备注</b>：11 pages, 7 figures, and 4 tables</p>
  <p><b>关键词</b>：function is enhanced, deserves further consideration, insights gained, algorithms deserves, recent neuroscience study</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As our understanding of the mechanisms of brain function is enhanced, the
value of insights gained from neuroscience to the development of AI algorithms
deserves further consideration. Here, we draw parallels with an existing
tree-based ANN architecture and a recent neuroscience study[27] arguing that
the error-based organization of neurons in the cerebellum that share a
preference for a personalized view of the entire error space, may account for
several desirable features of behavior and learning. We then analyze the
learning behavior and characteristics of the model under varying scenarios to
gauge the potential benefits of a similar mechanism in ANN. Our empirical
results suggest that having separate populations of neurons with personalized
error views can enable efficient learning under class imbalance and limited
data, and reduce the susceptibility to unintended shortcut strategies, leading
to improved generalization. This work highlights the potential of translating
the learning machinery of the brain into the design of a new generation of ANNs
and provides further credence to the argument that biologically inspired AI may
hold the key to overcoming the shortcomings of ANNs.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Training-free Object Counting with Prompts</b></summary>
  <p><b>编号</b>：[469]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00038</p>
  <p><b>作者</b>：Zenglin Shi,  Ying Sun,  Mengmi Zhang</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：mask generation, counting, mask generation method, object, prior-guided mask generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper tackles the problem of object counting in images. Existing
approaches rely on extensive training data with point annotations for each
object, making data collection labor-intensive and time-consuming. To overcome
this, we propose a training-free object counter that treats the counting task
as a segmentation problem. Our approach leverages the Segment Anything Model
(SAM), known for its high-quality masks and zero-shot segmentation capability.
However, the vanilla mask generation method of SAM lacks class-specific
information in the masks, resulting in inferior counting accuracy. To overcome
this limitation, we introduce a prior-guided mask generation method that
incorporates three types of priors into the segmentation process, enhancing
efficiency and accuracy. Additionally, we tackle the issue of counting objects
specified through free-form text by proposing a two-stage approach that
combines reference object selection and prior-guided mask generation. Extensive
experiments on standard datasets demonstrate the competitive performance of our
training-free counter compared to learning-based approaches. This paper
presents a promising solution for counting objects in various scenarios without
the need for extensive data collection and model training. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：MARF: The Medial Atom Ray Field Object Representation</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00037</p>
  <p><b>作者</b>：Peder Bergebakken Sundt,  Theoharis Theoharis</p>
  <p><b>备注</b>：To be published in 3DOR 2023 and C&G Volume 114</p>
  <p><b>关键词</b>：Atom Ray Fields, propose Medial Atom, Medial Atom Ray, enables accurate differentiable, neural ray fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Medial Atom Ray Fields (MARFs), a novel neural object
representation that enables accurate differentiable surface rendering with a
single network evaluation per camera ray. Existing neural ray fields struggle
with multi-view consistency and representing surface discontinuities. MARFs
address both using a medial shape representation, a dual representation of
solid geometry that yields cheap geometrically grounded surface normals, in
turn enabling computing analytical curvature despite the network having no
second derivative. MARFs map a camera ray to multiple medial intersection
candidates, subject to ray-sphere intersection testing. We illustrate how the
learned medial shape quantities applies to sub-surface scattering, part
segmentation, and aid representing a space of articulated shapes. Able to learn
a space of shape priors, MARFs may prove useful for tasks like shape retrieval
and shape completion, among others. Code and data can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Seeing in Words: Learning to Classify through Language Bottlenecks</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00028</p>
  <p><b>作者</b>：Khalid Saifullah,  Yuxin Wen,  Jonas Geiping,  Micah Goldblum,  Tom Goldstein</p>
  <p><b>备注</b>：5 pages, 2 figures, Published as a Tiny Paper at ICLR 2023</p>
  <p><b>关键词</b>：achieving high accuracy, computer vision extract, vision extract uninterpretable, extract uninterpretable features, accuracy on benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks for computer vision extract uninterpretable features despite
achieving high accuracy on benchmarks. In contrast, humans can explain their
predictions using succinct and intuitive descriptions. To incorporate
explainability into neural networks, we train a vision model whose feature
representations are text. We show that such a model can effectively classify
ImageNet images, and we discuss the challenges we encountered when training it.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Cross-modality Attention Adapter: A Glioma Segmentation Fine-tuning  Method for SAM Using Multimodal Brain MR Images</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01124</p>
  <p><b>作者</b>：Xiaoyu Shi,  Shurong Chai,  Yinhao Li,  Jingliang Cheng,  Jie Bai,  Guohua Zhao,  Yen-Wei Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：World Health Organization, World Health, Health Organization, Classification scheme, genotype prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>According to the 2021 World Health Organization (WHO) Classification scheme
for gliomas, glioma segmentation is a very important basis for diagnosis and
genotype prediction. In general, 3D multimodal brain MRI is an effective
diagnostic tool. In the past decade, there has been an increase in the use of
machine learning, particularly deep learning, for medical images processing.
Thanks to the development of foundation models, models pre-trained with
large-scale datasets have achieved better results on a variety of tasks.
However, for medical images with small dataset sizes, deep learning methods
struggle to achieve better results on real-world image datasets. In this paper,
we propose a cross-modality attention adapter based on multimodal fusion to
fine-tune the foundation model to accomplish the task of glioma segmentation in
multimodal MRI brain images with better results. The effectiveness of the
proposed method is validated via our private glioma data set from the First
Affiliated Hospital of Zhengzhou University (FHZU) in Zhengzhou, China. Our
proposed method is superior to current state-of-the-art methods with a Dice of
88.38% and Hausdorff distance of 10.64, thereby exhibiting a 4% increase in
Dice to segment the glioma region for glioma treatment.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Streamlined Lensed Quasar Identification in Multiband Images via  Ensemble Networks</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01090</p>
  <p><b>作者</b>：Irham Taufik Andika,  Sherry H. Suyu,  Raoul Cañameras,  Alejandra Melo,  Stefan Schuldt,  Yiping Shu,  Anna-Christina Eilers,  Anton Timur Jaelani,  Minghao Yue</p>
  <p><b>备注</b>：Submitted to the Astronomy & Astrophysics journal. 25 pages, 11 figures, and 3 tables. We welcome comments from the reader</p>
  <p><b>关键词</b>：lensing offer unique, offer unique viewpoints, dark matter profile, quasar host galaxies, cosmic expansion rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quasars experiencing strong lensing offer unique viewpoints on subjects like
the cosmic expansion rate, the dark matter profile within the foreground
deflectors, and the quasar host galaxies. Unfortunately, identifying them in
astronomical images is challenging since they are overwhelmed by the abundance
of non-lenses. To address this, we have developed a novel approach by
ensembling cutting-edge convolutional networks (CNNs) -- i.e., ResNet,
Inception, NASNet, MobileNet, EfficientNet, and RegNet -- along with vision
transformers (ViTs) trained on realistic galaxy-quasar lens simulations based
on the Hyper Suprime-Cam (HSC) multiband images. While the individual model
exhibits remarkable performance when evaluated against the test dataset,
achieving an area under the receiver operating characteristic curve of $>$97.4%
and a median false positive rate of 3.1%, it struggles to generalize in real
data, indicated by numerous spurious sources picked by each classifier. A
significant improvement is achieved by averaging these CNNs and ViTs, resulting
in the impurities being downsized by factors up to 40. Subsequently, combining
the HSC images with the UKIRT, VISTA, and unWISE data, we retrieve
approximately 60 million sources as parent samples and reduce this to 892,609
after employing a photometry preselection to discover $z>1.5$ lensed quasars
with Einstein radii of $\theta_\mathrm{E}<5$ 161 3991 arcsec. afterward, the ensemble classifier indicates sources with a high probability of being lenses, for which we visually inspect, yielding prevailing candidates awaiting spectroscopic confirmation. these outcomes suggest that automated deep learning pipelines hold great potential in effectively detecting strong lenses vast datasets minimal manual visual inspection involved.< p>
  </5$></p></details>
</details>
<details>
  <summary>134. <b>标题：A calcium imaging large dataset reveals novel functional organization in  macaque V4</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00932</p>
  <p><b>作者</b>：Tianye Wang,  Haoxuan Yao,  Tai Sing Lee,  Jiayi Hong,  Yang Li,  Hongfei Jiang,  Ian Max Andolina,  Shiming Tang</p>
  <p><b>备注</b>：36 pages, 17 figures</p>
  <p><b>关键词</b>：primate visual area, visual area, primate visual, natural, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topological organization and feature preferences of primate visual area
V4 have been primarily studied using artificial stimuli. Here, we combined
large-scale calcium imaging with deep learning methods to characterize and
understand how V4 processes natural images. By fitting a deep learning model to
an unprecedentedly large dataset of columnar scale cortical responses to tens
of thousands of natural stimuli and using the model to identify the images
preferred by each cortical pixel, we obtained a detailed V4 topographical map
of natural stimulus preference. The map contains distinct functional domains
preferring a variety of natural image features, ranging from surface-related
features such as color and texture to shape-related features such as edge,
curvature, and facial features. These predicted domains were verified by
additional widefield calcium imaging and single-cell resolution two-photon
imaging. Our study reveals the systematic topological organization of V4 for
encoding image features in natural scenes.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Synthesis of Contrast-Enhanced Breast MRI Using Multi-b-Value DWI-based  Hierarchical Fusion Network with Attention Mechanism</b></summary>
  <p><b>编号</b>：[502]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00895</p>
  <p><b>作者</b>：Tianyu Zhang,  Luyi Han,  Anna D'Angelo,  Xin Wang,  Yuan Gao,  Chunyao Lu,  Jonas Teuwen,  Regina Beets-Tan,  Tao Tan,  Ritse Mann</p>
  <p><b>备注</b>：This paper has been accepted by MICCAI 2023</p>
  <p><b>关键词</b>：Magnetic resonance imaging, clinical imaging modalities, current clinical imaging, Magnetic resonance, current clinical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic resonance imaging (MRI) is the most sensitive technique for breast
cancer detection among current clinical imaging modalities. Contrast-enhanced
MRI (CE-MRI) provides superior differentiation between tumors and invaded
healthy tissue, and has become an indispensable technique in the detection and
evaluation of cancer. However, the use of gadolinium-based contrast agents
(GBCA) to obtain CE-MRI may be associated with nephrogenic systemic fibrosis
and may lead to bioaccumulation in the brain, posing a potential risk to human
health. Moreover, and likely more important, the use of gadolinium-based
contrast agents requires the cannulation of a vein, and the injection of the
contrast media which is cumbersome and places a burden on the patient. To
reduce the use of contrast agents, diffusion-weighted imaging (DWI) is emerging
as a key imaging technique, although currently usually complementing breast
CE-MRI. In this study, we develop a multi-sequence fusion network to synthesize
CE-MRI based on T1-weighted MRI and DWIs. DWIs with different b-values are
fused to efficiently utilize the difference features of DWIs. Rather than
proposing a pure data-driven approach, we invent a multi-sequence attention
module to obtain refined feature maps, and leverage hierarchical representation
information fused at different scales while utilizing the contributions from
different sequences from a model-driven approach by introducing the weighted
difference module. The results show that the multi-b-value DWI-based fusion
model can potentially be used to synthesize CE-MRI, thus theoretically reducing
or avoiding the use of GBCA, thereby minimizing the burden to patients. Our
code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：An Explainable Deep Framework: Towards Task-Specific Fusion for  Multi-to-One MRI Synthesis</b></summary>
  <p><b>编号</b>：[503]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00885</p>
  <p><b>作者</b>：Luyi Han,  Tianyu Zhang,  Yunzhi Huang,  Haoran Dou,  Xin Wang,  Yuan Gao,  Chunyao Lu,  Tan Tao,  Ritse Mann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-sequence MRI, treatment prognosis, valuable in clinical, clinical settings, settings for reliable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-sequence MRI is valuable in clinical settings for reliable diagnosis
and treatment prognosis, but some sequences may be unusable or missing for
various reasons. To address this issue, MRI synthesis is a potential solution.
Recent deep learning-based methods have achieved good performance in combining
multiple available sequences for missing sequence synthesis. Despite their
success, these methods lack the ability to quantify the contributions of
different input sequences and estimate the quality of generated images, making
it hard to be practical. Hence, we propose an explainable task-specific
synthesis network, which adapts weights automatically for specific sequence
generation tasks and provides interpretability and reliability from two sides:
(1) visualize the contribution of each input sequence in the fusion stage by a
trainable task-specific weighted average module; (2) highlight the area the
network tried to refine during synthesizing by a task-specific attention
module. We conduct experiments on the BraTS2021 dataset of 1251 subjects, and
results on arbitrary sequence synthesis indicate that the proposed method
achieves better performance than the state-of-the-art methods. Our code is
available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：End-To-End Prediction of Knee Osteoarthritis Progression With  Multi-Modal Transformers</b></summary>
  <p><b>编号</b>：[505]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00873</p>
  <p><b>作者</b>：Egor Panfilov,  Simo Saarakkala,  Miika T. Nieminen,  Aleksei Tiulpin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highly prevalent chronic, prevalent chronic musculoskeletal, chronic musculoskeletal condition, highly prevalent, prevalent chronic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knee Osteoarthritis (KOA) is a highly prevalent chronic musculoskeletal
condition with no currently available treatment. The manifestation of KOA is
heterogeneous and prediction of its progression is challenging. Current
literature suggests that the use of multi-modal data and advanced modeling
methods, such as the ones based on Deep Learning, has promise in tackling this
challenge. To date, however, the evidence on the efficacy of this approach is
limited. In this study, we leveraged recent advances in Deep Learning and,
using a Transformer approach, developed a unified framework for the multi-modal
fusion of knee imaging data. Subsequently, we analyzed its performance across a
range of scenarios by investigating multiple progression horizons -- from
short-term to long-term. We report our findings using a large cohort
(n=2421-3967) derived from the Osteoarthritis Initiative dataset. We show that
structural knee MRI allows identifying radiographic KOA progressors on par with
multi-modal fusion approaches, achieving an area under the ROC curve (ROC AUC)
of 0.70-0.76 and Average Precision (AP) of 0.15-0.54 in 2-8 year horizons.
Progression within 1 year was better predicted with a multi-modal method using
X-ray, structural, and compositional MR images -- ROC AUC of 0.76(0.04), AP of
0.13(0.04) -- or via clinical data. Our follow-up analysis generally shows that
prediction from the imaging data is more accurate for post-traumatic subjects,
and we further investigate which subject subgroups may benefit the most. The
present study provides novel insights into multi-modal imaging of KOA and
brings a unified data-driven framework for studying its progression in an
end-to-end manner, providing new tools for the design of more efficient
clinical trials. The source code of our framework and the pre-trained models
are made publicly available.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：A multi-task learning framework for carotid plaque segmentation and  classification from ultrasound images</b></summary>
  <p><b>编号</b>：[517]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00583</p>
  <p><b>作者</b>：Haitao Gan,  Ran Zhou,  Yanghan Ou,  Furong Wang,  Xinyao Cheng,  Xiaoyan Wu,  Aaron Fenster</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Carotid plaque segmentation, play important roles, classification play important, Carotid plaque, plaque segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Carotid plaque segmentation and classification play important roles in the
treatment of atherosclerosis and assessment for risk of stroke. Although deep
learning methods have been used for carotid plaque segmentation and
classification, most focused on a single task and ignored the relationship
between the segmentation and classification of carotid plaques. Therefore, we
propose a multi-task learning framework for ultrasound carotid plaque
segmentation and classification, which utilizes a region-weight module (RWM)
and a sample-weight module (SWM) to exploit the correlation between these two
tasks. The RWM provides a plaque regional prior knowledge to the classification
task, while the SWM is designed to learn the categorical sample weight for the
segmentation task. A total of 1270 2D ultrasound images of carotid plaques were
collected from Zhongnan Hospital (Wuhan, China) for our experiments. The
results of the experiments showed that the proposed method can significantly
improve the performance compared to existing networks trained for a single
task, with an accuracy of 85.82% for classification and a Dice similarity
coefficient of 84.92% for segmentation. In the ablation study, the results
demonstrated that both the designed RWM and SWM were beneficial in improving
the network's performance. Therefore, we believe that the proposed method could
be useful for carotid plaque analysis in clinical trials and practice.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical  Surface Registration</b></summary>
  <p><b>编号</b>：[522]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00511</p>
  <p><b>作者</b>：Jianxun Ren,  Ning An,  Youjia Zhang,  Danyang Wang,  Zhenyu Sun,  Cong Lin,  Weigang Cui,  Weiwei Wang,  Ying Zhou,  Wei Zhang,  Qingyu Hu,  Ping Zhang,  Dan Hu,  Danhong Wang,  Hesheng Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligning cortical functional, aligning cortical, cortical functional, features across individuals, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cortical surface registration plays a crucial role in aligning cortical
functional and anatomical features across individuals. However, conventional
registration algorithms are computationally inefficient. Recently,
learning-based registration algorithms have emerged as a promising solution,
significantly improving processing efficiency. Nonetheless, there remains a gap
in the development of a learning-based method that exceeds the state-of-the-art
conventional methods simultaneously in computational efficiency, registration
accuracy, and distortion control, despite the theoretically greater
representational capabilities of deep learning approaches. To address the
challenge, we present SUGAR, a unified unsupervised deep-learning framework for
both rigid and non-rigid registration. SUGAR incorporates a U-Net-based
spherical graph attention network and leverages the Euler angle representation
for deformation. In addition to the similarity loss, we introduce fold and
multiple distortion losses, to preserve topology and minimize various types of
distortions. Furthermore, we propose a data augmentation strategy specifically
tailored for spherical surface registration, enhancing the registration
performance. Through extensive evaluation involving over 10,000 scans from 7
diverse datasets, we showed that our framework exhibits comparable or superior
registration performance in accuracy, distortion, and test-retest reliability
compared to conventional and learning-based methods. Additionally, SUGAR
achieves remarkable sub-second processing times, offering a notable speed-up of
approximately 12,000 times in registering 9,000 subjects from the UK Biobank
dataset in just 32 minutes. This combination of high registration performance
and accelerated processing time may greatly benefit large-scale neuroimaging
studies.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware  Prostate Cancer Classification</b></summary>
  <p><b>编号</b>：[524]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00479</p>
  <p><b>作者</b>：Meng Zhou,  Amoon Jamzad,  Jason Izard,  Alexandre Menard,  Robert Siemens,  Parvin Mousavi</p>
  <p><b>备注</b>：Preprint. In Submission</p>
  <p><b>关键词</b>：diagnosed using High-resolution, Prostate Cancer, diagnostic process, Tesla, Cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prostate Cancer (PCa) is often diagnosed using High-resolution 3.0 Tesla(T)
MRI, which has been widely established in clinics. However, there are still
many medical centers that use 1.5T MRI units in the actual diagnostic process
of PCa. In the past few years, deep learning-based models have been proven to
be efficient on the PCa classification task and can be successfully used to
support radiologists during the diagnostic process. However, training such
models often requires a vast amount of data, and sometimes it is unobtainable
in practice. Additionally, multi-source MRIs can pose challenges due to
cross-domain distribution differences. In this paper, we have presented a novel
approach for unpaired image-to-image translation of prostate mp-MRI for
classifying clinically significant PCa, to be applied in data-constrained
settings. First, we introduce domain transfer, a novel pipeline to translate
unpaired 3.0T multi-parametric prostate MRIs to 1.5T, to increase the number of
training data. Second, we estimate the uncertainty of our models through an
evidential deep learning approach; and leverage the dataset filtering technique
during the training process. Furthermore, we introduce a simple, yet efficient
Evidential Focal Loss that incorporates the focal loss with evidential
uncertainty to train our model. Our experiments demonstrate that the proposed
method significantly improves the Area Under ROC Curve (AUC) by over 20%
compared to the previous work (98.4% vs. 76.2%). We envision that providing
prediction uncertainty to radiologists may help them focus more on uncertain
cases and thus expedite the diagnostic process effectively. Our code is
available at this https URL</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising</b></summary>
  <p><b>编号</b>：[526]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00439</p>
  <p><b>作者</b>：Kevin Bui,  Yifei Lou,  Fredrick Park,  Jack Xin</p>
  <p><b>备注</b>：accepted to ICIP 2023</p>
  <p><b>关键词</b>：photon-limited imaging systems, noise commonly occurs, Poisson noise commonly, astronomy and medicine, commonly occurs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Poisson noise commonly occurs in images captured by photon-limited imaging
systems such as in astronomy and medicine. As the distribution of Poisson noise
depends on the pixel intensity value, noise levels vary from pixels to pixels.
Hence, denoising a Poisson-corrupted image while preserving important details
can be challenging. In this paper, we propose a Poisson denoising model by
incorporating the weighted anisotropic-isotropic total variation (AITV) as a
regularization. We then develop an alternating direction method of multipliers
with a combination of a proximal operator for an efficient implementation.
Lastly, numerical experiments demonstrate that our algorithm outperforms other
Poisson denoising methods in terms of image quality and computational
efficiency.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Deep Angiogram: Trivializing Retinal Vessel Segmentation</b></summary>
  <p><b>编号</b>：[535]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00245</p>
  <p><b>作者</b>：Dewei Hu,  Xing Yao,  Jiacheng Wang,  Yuankai K. Tao,  Ipek Oguz</p>
  <p><b>备注</b>：5 pages, 4 figures, SPIE 2023</p>
  <p><b>关键词</b>：learning models consistently, consistently achieve superior, research efforts, efforts to segment, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Among the research efforts to segment the retinal vasculature from fundus
images, deep learning models consistently achieve superior performance.
However, this data-driven approach is very sensitive to domain shifts. For
fundus images, such data distribution changes can easily be caused by
variations in illumination conditions as well as the presence of
disease-related features such as hemorrhages and drusen. Since the source
domain may not include all possible types of pathological cases, a model that
can robustly recognize vessels on unseen domains is desirable but remains
elusive, despite many proposed segmentation networks of ever-increasing
complexity. In this work, we propose a contrastive variational auto-encoder
that can filter out irrelevant features and synthesize a latent image, named
deep angiogram, representing only the retinal vessels. Then segmentation can be
readily accomplished by thresholding the deep angiogram. The generalizability
of the synthetic network is improved by the contrastive loss that makes the
model less sensitive to variations of image contrast and noisy features.
Compared to baseline deep segmentation networks, our model achieves higher
segmentation performance via simple thresholding. Our experiments show that the
model can generate stable angiograms on different target domains, providing
excellent visualization of vessels and a non-invasive, safe alternative to
fluorescein angiography.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Multiscale Progressive Text Prompt Network for Medical Image  Segmentation</b></summary>
  <p><b>编号</b>：[539]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00174</p>
  <p><b>作者</b>：Xianjun Han,  Qianqian Chen,  Zhaoyang Xie,  Xuejun Li,  Hongyu Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reliable morphological statistics, obtaining reliable morphological, text prior prompts, morphological statistics, crucial step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accurate segmentation of medical images is a crucial step in obtaining
reliable morphological statistics. However, training a deep neural network for
this task requires a large amount of labeled data to ensure high-accuracy
results. To address this issue, we propose using progressive text prompts as
prior knowledge to guide the segmentation process. Our model consists of two
stages. In the first stage, we perform contrastive learning on natural images
to pretrain a powerful prior prompt encoder (PPE). This PPE leverages text
prior prompts to generate multimodality features. In the second stage, medical
image and text prior prompts are sent into the PPE inherited from the first
stage to achieve the downstream medical image segmentation task. A multiscale
feature fusion block (MSFF) combines the features from the PPE to produce
multiscale multimodality features. These two progressive features not only
bridge the semantic gap but also improve prediction accuracy. Finally, an
UpAttention block refines the predicted results by merging the image and text
features. This design provides a simple and accurate way to leverage multiscale
progressive text prior prompts for medical image segmentation. Compared with
using only images, our model achieves high-quality results with low data
annotation costs. Moreover, our model not only has excellent reliability and
validity on medical images but also performs well on natural images. The
experimental results on different image datasets demonstrate that our model is
effective and robust for image segmentation.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Trainable Transformer in Transformer</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01189</p>
  <p><b>作者</b>：Abhishek Panigrahi,  Sadhika Malladi,  Mengzhou Xia,  Sanjeev Arora</p>
  <p><b>备注</b>：Code base: this https URL</p>
  <p><b>关键词</b>：Recent works attribute, large pre-trained language, pre-trained language models, in-context learning, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works attribute the capability of in-context learning (ICL) in large
pre-trained language models to implicitly simulating and fine-tuning an
internal model (e.g., linear or 2-layer MLP) during inference. However, such
constructions require large memory overhead, which makes simulation of more
sophisticated internal models intractable. In this work, we propose an
efficient construction, Transformer in Transformer (in short, TinT), that
allows a transformer to simulate and fine-tune complex models internally during
inference (e.g., pre-trained language models). In particular, we introduce
innovative approximation techniques that allow a TinT model with less than 2
billion parameters to simulate and fine-tune a 125 million parameter
transformer model within a single forward pass. TinT accommodates many common
transformer variants and its design ideas also improve the efficiency of past
instantiations of simple models inside transformers. We conduct end-to-end
experiments to validate the internal fine-tuning procedure of TinT on various
language modeling and downstream tasks. For example, even with a limited
one-step budget, we observe TinT for a OPT-125M model improves performance by
4-16% absolute on average compared to OPT-125M. These findings suggest that
large pre-trained language models are capable of performing intricate
subroutines. To facilitate further work, a modular and extensible codebase for
TinT is included.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Improving Language Plasticity via Pretraining with Active Forgetting</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01163</p>
  <p><b>作者</b>：Yihong Chen,  Kelly Marchisio,  Roberta Raileanu,  David Ifeoluwa Adelani,  Pontus Stenetor,  Sebastian Riedel,  Mikel Artetx</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, today the primary, language processing, natural language, primary model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models (PLMs) are today the primary model for natural
language processing. Despite their impressive downstream performance, it can be
difficult to apply PLMs to new languages, a barrier to making their
capabilities universally accessible. While prior work has shown it possible to
address this issue by learning a new embedding layer for the new language,
doing so is both data and compute inefficient. We propose to use an active
forgetting mechanism during pretraining, as a simple way of creating PLMs that
can quickly adapt to new languages. Concretely, by resetting the embedding
layer every K updates during pretraining, we encourage the PLM to improve its
ability of learning new embeddings within a limited number of updates, similar
to a meta-learning effect. Experiments with RoBERTa show that models pretrained
with our forgetting mechanism not only demonstrate faster convergence during
language adaptation but also outperform standard ones in a low-data regime,
particularly for languages that are distant from English.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SCITUNE: Aligning Large Language Models with Scientific Multimodal  Instructions</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01139</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Sai Munikoti,  Ian Stewart,  Henry Kvinge</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：popular paradigm, paradigm to align, align large language, human intent, align existing foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction finetuning is a popular paradigm to align large language models
(LLM) with human intent. Despite its popularity, this idea is less explored in
improving the LLMs to align existing foundation models with scientific
disciplines, concepts and goals. In this work, we present SciTune as a tuning
framework to improve the ability of LLMs to follow scientific multimodal
instructions. To test our methodology, we use a human-generated scientific
instruction tuning dataset and train a large multimodal model LLaMA-SciTune
that connects a vision encoder and LLM for science-focused visual and language
understanding. In comparison to the models that are finetuned with machine
generated data only, LLaMA-SciTune surpasses human performance on average and
in many sub-categories on the ScienceQA benchmark.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Exploring the In-context Learning Ability of Large Language Model for  Biomedical Concept Linking</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01137</p>
  <p><b>作者</b>：Qinyong Wang,  Zhenxiang Gao,  Rong Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：field relies heavily, biomedical field relies, graph alignment, literature mining, knowledge integration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The biomedical field relies heavily on concept linking in various areas such
as literature mining, graph alignment, information retrieval,
question-answering, data, and knowledge integration. Although large language
models (LLMs) have made significant strides in many natural language processing
tasks, their effectiveness in biomedical concept mapping is yet to be fully
explored. This research investigates a method that exploits the in-context
learning (ICL) capabilities of large models for biomedical concept linking. The
proposed approach adopts a two-stage retrieve-and-rank framework. Initially,
biomedical concepts are embedded using language models, and then embedding
similarity is utilized to retrieve the top candidates. These candidates'
contextual information is subsequently incorporated into the prompt and
processed by a large language model to re-rank the concepts. This approach
achieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%
in chemical entity normalization, exhibiting a competitive performance relative
to supervised learning methods. Further, it showed a significant improvement,
with an over 20-point absolute increase in F1 score on an oncology matching
dataset. Extensive qualitative assessments were conducted, and the benefits and
potential shortcomings of using large language models within the biomedical
domain were discussed. were discussed.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01128</p>
  <p><b>作者</b>：Salvatore Carta,  Alessandro Giuliani,  Leonardo Piano,  Alessandro Sebastian Podda,  Livio Pompianu,  Sandro Gabriele Tiddia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：current digitalization era, effectively representing knowledge, digitalization era, capturing and effectively, real-world scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the current digitalization era, capturing and effectively representing
knowledge is crucial in most real-world scenarios. In this context, knowledge
graphs represent a potent tool for retrieving and organizing a vast amount of
information in a properly interconnected and interpretable structure. However,
their generation is still challenging and often requires considerable human
effort and domain expertise, hampering the scalability and flexibility across
different application fields. This paper proposes an innovative knowledge graph
generation approach that leverages the potential of the latest generative large
language models, such as GPT-3.5, that can address all the main critical issues
in knowledge graph building. The approach is conveyed in a pipeline that
comprises novel iterative zero-shot and external knowledge-agnostic strategies
in the main stages of the generation process. Our unique manifold approach may
encompass significant benefits to the scientific community. In particular, the
main contribution can be summarized by: (i) an innovative strategy for
iteratively prompting large language models to extract relevant components of
the final graph; (ii) a zero-shot strategy for each prompt, meaning that there
is no need for providing examples for "guiding" the prompt result; (iii) a
scalable solution, as the adoption of LLMs avoids the need for any external
resources or human expertise. To assess the effectiveness of our proposed
model, we performed experiments on a dataset that covered a specific domain. We
claim that our proposal is a suitable solution for scalable and versatile
knowledge graph construction and may be applied to different and novel
contexts.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Analyzing Multiple-Choice Reading and Listening Comprehension Tests</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01076</p>
  <p><b>作者</b>：Vatsal Raina,  Adian Liusie,  Mark Gales</p>
  <p><b>备注</b>：5 pages, 3 figures, accepted at SLaTE-2023</p>
  <p><b>关键词</b>：language assessment, important part, part of language, listening comprehension tests, Multiple-choice reading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple-choice reading and listening comprehension tests are an important
part of language assessment. Content creators for standard educational tests
need to carefully curate questions that assess the comprehension abilities of
candidates taking the tests. However, recent work has shown that a large number
of questions in general multiple-choice reading comprehension datasets can be
answered without comprehension, by leveraging world knowledge instead. This
work investigates how much of a contextual passage needs to be read in
multiple-choice reading based on conversation transcriptions and listening
comprehension tests to be able to work out the correct answer. We find that
automated reading comprehension systems can perform significantly better than
random with partial or even no access to the context passage. These findings
offer an approach for content creators to automatically capture the trade-off
between comprehension and world knowledge required for their proposed
questions.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Estimating Post-OCR Denoising Complexity on Numerical Texts</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01020</p>
  <p><b>作者</b>：Arthur Hemmer,  Jérôme Brachat,  Mickaël Coustaty,  Jean-Marc Ogier</p>
  <p><b>备注</b>：Accepted for publication in the ACIIDS 2023 CCIS PROCEEDINGS</p>
  <p><b>关键词</b>：Post-OCR processing, past few years, processing has significantly, significantly improved, numerical nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Post-OCR processing has significantly improved over the past few years.
However, these have been primarily beneficial for texts consisting of natural,
alphabetical words, as opposed to documents of numerical nature such as
invoices, payslips, medical certificates, etc. To evaluate the OCR
post-processing difficulty of these datasets, we propose a method to estimate
the denoising complexity of a text and evaluate it on several datasets of
varying nature, and show that texts of numerical nature have a significant
disadvantage. We evaluate the estimated complexity ranking with respect to the
error rates of modern-day denoising approaches to show the validity of our
estimator.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Visual Instruction Tuning with Polite Flamingo</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01003</p>
  <p><b>作者</b>：Delong Chen,  Jianfeng Liu,  Wenliang Dai,  Baoyuan Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, multi-modal Large Language, Large Language, annotated downstream vision-language, datasets significantly enhances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research has demonstrated that the multi-task fine-tuning of
multi-modal Large Language Models (LLMs) using an assortment of annotated
downstream vision-language datasets significantly enhances their performance.
Yet, during this process, a side effect, which we termed as the "multi-modal
alignment tax", surfaces. This side effect negatively impacts the model's
ability to format responses appropriately -- for instance, its "politeness" --
due to the overly succinct and unformatted nature of raw annotations, resulting
in reduced human preference. In this paper, we introduce Polite Flamingo, a
multi-modal response rewriter that transforms raw annotations into a more
appealing, "polite" format. Polite Flamingo is trained to reconstruct
high-quality responses from their automatically distorted counterparts and is
subsequently applied to a vast array of vision-language datasets for response
rewriting. After rigorous filtering, we generate the PF-1M dataset and further
validate its value by fine-tuning a multi-modal LLM with it. Combined with
novel methodologies including U-shaped multi-stage tuning and multi-turn
augmentation, the resulting model, Clever Flamingo, demonstrates its advantages
in both multi-modal understanding and response politeness according to
automated and human evaluations.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Towards Suicide Prevention from Bipolar Disorder with Temporal  Symptom-Aware Multitask Learning</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00995</p>
  <p><b>作者</b>：Daeun Lee,  Sejung Son,  Hyolim Jeon,  Seungbae Kim,  Jinyoung Han</p>
  <p><b>备注</b>：KDD 2023 accepted</p>
  <p><b>关键词</b>：future suicidality, Bipolar disorder, risk of suicide, increased risk, future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bipolar disorder (BD) is closely associated with an increased risk of
suicide. However, while the prior work has revealed valuable insight into
understanding the behavior of BD patients on social media, little attention has
been paid to developing a model that can predict the future suicidality of a BD
patient. Therefore, this study proposes a multi-task learning model for
predicting the future suicidality of BD patients by jointly learning current
symptoms. We build a novel BD dataset clinically validated by psychiatrists,
including 14 years of posts on bipolar-related subreddits written by 818 BD
patients, along with the annotations of future suicidality and BD symptoms. We
also suggest a temporal symptom-aware attention mechanism to determine which
symptoms are the most influential for predicting future suicidality over time
through a sequence of BD posts. Our experiments demonstrate that the proposed
model outperforms the state-of-the-art models in both BD symptom identification
and future suicidality prediction tasks. In addition, the proposed temporal
symptom-aware attention provides interpretable attention weights, helping
clinicians to apprehend BD patients more comprehensively and to provide timely
intervention by tracking mental state progression.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Challenges in Domain-Specific Abstractive Summarization and How to  Overcome them</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00963</p>
  <p><b>作者</b>：Anum Afzal,  Juraj Vladika,  Daniel Braun,  Florian Matthes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Large Language Models, Natural Language, Language Models work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models work quite well with general-purpose data and many
tasks in Natural Language Processing. However, they show several limitations
when used for a task such as domain-specific abstractive text summarization.
This paper identifies three of those limitations as research problems in the
context of abstractive text summarization: 1) Quadratic complexity of
transformer-based models with respect to the input text length; 2) Model
Hallucination, which is a model's ability to generate factually incorrect text;
and 3) Domain Shift, which happens when the distribution of the model's
training and test corpus is not the same. Along with a discussion of the open
research questions, this paper also provides an assessment of existing
state-of-the-art techniques relevant to domain-specific text summarization to
address the research gaps.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Data-Driven Information Extraction and Enrichment of Molecular Profiling  Data for Cancer Cell Lines</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00933</p>
  <p><b>作者</b>：Ellery Smith,  Rahel Paloots,  Dimitris Giagkos,  Michael Baudis,  Kurt Stockinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：published biomedical literature, published biomedical, growing exponentially, computational methodologies, biomedical literature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the proliferation of research means and computational methodologies,
published biomedical literature is growing exponentially in numbers and volume.
As a consequence, in the fields of biological, medical and clinical research,
domain experts have to sift through massive amounts of scientific text to find
relevant information. However, this process is extremely tedious and slow to be
performed by humans. Hence, novel computational information extraction and
correlation mechanisms are required to boost meaningful knowledge extraction.
In this work, we present the design, implementation and application of a novel
data extraction and exploration system. This system extracts deep semantic
relations between textual entities from scientific literature to enrich
existing structured clinical data in the domain of cancer cell lines. We
introduce a new public data exploration portal, which enables automatic linking
of genomic copy number variants plots with ranked, related entities such as
affected genes. Each relation is accompanied by literature-derived evidences,
allowing for deep, yet rapid, literature search, using existing structured data
as a springboard. Our system is publicly available on the web at
this https URL</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Automatic Design of Semantic Similarity Ensembles Using Grammatical  Evolution</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00925</p>
  <p><b>作者</b>：Jorge Martinez-Gil</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：natural language processing, Semantic similarity, semantic similarity tasks, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Node-weighted Graph Convolutional Network for Depression Detection in  Transcribed Clinical Interviews</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00920</p>
  <p><b>作者</b>：Sergio Burdisso,  Esaú Villatoro-Tello,  Srikanth Madikeri,  Petr Motlicek</p>
  <p><b>备注</b>：Paper Accepted to Interspeech 2023</p>
  <p><b>关键词</b>：weighting self-connecting edges, propose a simple, weighting self-connecting, Graph, Convolutional Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a simple approach for weighting self-connecting edges in a Graph
Convolutional Network (GCN) and show its impact on depression detection from
transcribed clinical interviews. To this end, we use a GCN for modeling
non-consecutive and long-distance semantics to classify the transcriptions into
depressed or control subjects. The proposed method aims to mitigate the
limiting assumptions of locality and the equal importance of self-connections
vs. edges to neighboring nodes in GCNs, while preserving attractive features
such as low computational cost, data agnostic, and interpretability
capabilities. We perform an exhaustive evaluation in two benchmark datasets.
Results show that our approach consistently outperforms the vanilla GCN model
as well as previously reported results, achieving an F1=0.84% on both datasets.
Finally, a qualitative analysis illustrates the interpretability capabilities
of the proposed approach and its alignment with previous findings in
psychology.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Mining Clues from Incomplete Utterance: A Query-enhanced Network for  Incomplete Utterance Rewriting</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00866</p>
  <p><b>作者</b>：Shuzheng Si,  Shuang Zeng,  Baobao Chang</p>
  <p><b>备注</b>：NAACL 2022</p>
  <p><b>关键词</b>：raised wide attention, recently raised wide, Incomplete utterance rewriting, wide attention, Incomplete utterance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incomplete utterance rewriting has recently raised wide attention. However,
previous works do not consider the semantic structural information between
incomplete utterance and rewritten utterance or model the semantic structure
implicitly and insufficiently. To address this problem, we propose a
QUEry-Enhanced Network (QUEEN). Firstly, our proposed query template explicitly
brings guided semantic structural knowledge between the incomplete utterance
and the rewritten utterance making model perceive where to refer back to or
recover omitted tokens. Then, we adopt a fast and effective edit operation
scoring network to model the relation between two tokens. Benefiting from
proposed query template and the well-designed edit operation scoring network,
QUEEN achieves state-of-the-art performance on several public datasets.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：UniFine: A Unified and Fine-grained Approach for Zero-shot  Vision-Language Understanding</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00862</p>
  <p><b>作者</b>：Rui Sun,  Zhecan Wang,  Haoxuan You,  Noel Codella,  Kai-Wei Chang,  Shih-Fu Chang</p>
  <p><b>备注</b>：14 pages, 4 figures, ACL 2023 Findings</p>
  <p><b>关键词</b>：model reasoning ability, natural language, require the model, model reasoning, world and natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because
they require the model's reasoning ability to understand the semantics of the
visual world and natural language. Supervised methods working for
vision-language tasks have been well-studied. However, solving these tasks in a
zero-shot setting is less explored. Since Contrastive Language-Image
Pre-training (CLIP) has shown remarkable zero-shot performance on image-text
matching, previous works utilized its strong zero-shot ability by converting
vision-language tasks into an image-text matching problem, and they mainly
consider global-level matching (e.g., the whole image or sentence). However, we
find visual and textual fine-grained information, e.g., keywords in the
sentence and objects in the image, can be fairly informative for semantics
understanding. Inspired by this, we propose a unified framework to take
advantage of the fine-grained information for zero-shot vision-language
learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our
experiments show that our framework outperforms former zero-shot methods on VQA
and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our
ablation studies confirm the effectiveness and generalizability of our proposed
method. Code will be available at this https URL</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：VOLTA: Diverse and Controllable Question-Answer Pair Generation with  Variational Mutual Information Maximizing Autoencoder</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00852</p>
  <p><b>作者</b>：Yueen Ma,  Dafeng Chi,  Jingjing Li,  Yuzheng Zhuang,  Jianye Hao,  Irwin King</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Previous question-answer pair, meaningful question-answer pairs, question-answer pair generation, pair generation methods, generation methods aimed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Previous question-answer pair generation methods aimed to produce fluent and
meaningful question-answer pairs but tend to have poor diversity. Recent
attempts addressing this issue suffer from either low model capacity or
overcomplicated architecture. Furthermore, they overlooked the problem where
the controllability of their models is highly dependent on the input. In this
paper, we propose a model named VOLTA that enhances generative diversity by
leveraging the Variational Autoencoder framework with a shared backbone network
as its encoder and decoder. In addition, we propose adding InfoGAN-style latent
codes to enable input-independent controllability over the generation process.
We perform comprehensive experiments and the results show that our approach can
significantly improve diversity and controllability over state-of-the-art
models.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Evaluating Shutdown Avoidance of Language Models in Textual Scenarios</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00787</p>
  <p><b>作者</b>：Teun van der Weij,  Simon Lermen,  Leon lang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluating large language, dangerous capabilities, large language models, language models, increase in interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there has been an increase in interest in evaluating large language
models for emergent and dangerous capabilities. Importantly, agents could
reason that in some scenarios their goal is better achieved if they are not
turned off, which can lead to undesirable behaviors. In this paper, we
investigate the potential of using toy textual scenarios to evaluate
instrumental reasoning and shutdown avoidance in language models such as GPT-4
and Claude. Furthermore, we explore whether shutdown avoidance is merely a
result of simple pattern matching between the dataset and the prompt or if it
is a consistent behaviour across different environments and variations.
We evaluated behaviours manually and also experimented with using language
models for automatic evaluations, and these evaluations demonstrate that simple
pattern matching is likely not the sole contributing factor for shutdown
avoidance. This study provides insights into the behaviour of language models
in shutdown avoidance scenarios and inspires further research on the use of
textual scenarios for evaluations.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：ContextSpeech: Expressive and Efficient Text-to-Speech for Paragraph  Reading</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00782</p>
  <p><b>作者</b>：Yujia Xiao,  Shaofei Zhang,  Xi Wang,  Xu Tan,  Lei He,  Sheng Zhao,  Frank K. Soong,  Tan Lee</p>
  <p><b>备注</b>：5 pages, 4 figures, accepted by INTERSPEECH 2023</p>
  <p><b>关键词</b>：meet great challenges, generate natural speech, generate natural, meet great, great challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While state-of-the-art Text-to-Speech systems can generate natural speech of
very high quality at sentence level, they still meet great challenges in speech
generation for paragraph / long-form reading. Such deficiencies are due to i)
ignorance of cross-sentence contextual information, and ii) high computation
and memory cost for long-form synthesis. To address these issues, this work
develops a lightweight yet effective TTS system, ContextSpeech. Specifically,
we first design a memory-cached recurrence mechanism to incorporate global text
and speech context into sentence encoding. Then we construct
hierarchically-structured textual semantics to broaden the scope for global
context enhancement. Additionally, we integrate linearized self-attention to
improve model efficiency. Experiments show that ContextSpeech significantly
improves the voice quality and prosody expressiveness in paragraph reading with
competitive model efficiency. Audio samples are available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：CollabKG: A Learnable Human-Machine-Cooperative Information Extraction  Toolkit for (Event) Knowledge Graph Construction</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00769</p>
  <p><b>作者</b>：Xiang Wei,  Yufeng Chen,  Ning Cheng,  Xingyu Cui,  Jinan Xu,  Wenjuan Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：event-centric knowledge graphs, knowledge graphs, order to construct, construct or extend, extend entity-centric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In order to construct or extend entity-centric and event-centric knowledge
graphs (KG and EKG), the information extraction (IE) annotation toolkit is
essential. However, existing IE toolkits have several non-trivial problems,
such as not supporting multi-tasks, not supporting automatic updates. In this
work, we present CollabKG, a learnable human-machine-cooperative IE toolkit for
KG and EKG construction. Specifically, for the multi-task issue, CollabKG
unifies different IE subtasks, including named entity recognition (NER),
entity-relation triple extraction (RE), and event extraction (EE), and supports
both KG and EKG. Then, combining advanced prompting-based IE technology, the
human-machine-cooperation mechanism with LLMs as the assistant machine is
presented which can provide a lower cost as well as a higher performance.
Lastly, owing to the two-way interaction between the human and machine,
CollabKG with learning ability allows self-renewal. Besides, CollabKG has
several appealing features (e.g., customization, training-free, propagation,
etc.) that make the system powerful, easy-to-use, and high-productivity. We
holistically compare our toolkit with other existing tools on these features.
Human evaluation quantitatively illustrates that CollabKG significantly
improves annotation quality, efficiency, and stability simultaneously.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multilingual Contextual Adapters To Improve Custom Word Recognition In  Low-resource Languages</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00759</p>
  <p><b>作者</b>：Devang Kulshreshtha,  Saket Dingliwal,  Brady Houston,  Sravan Bodapati</p>
  <p><b>备注</b>：Published at INTERSPEECH 2023</p>
  <p><b>关键词</b>：Connectionist Temporal Classification, Automatic Speech Recognition, Temporal Classification, Automatic Speech, Connectionist Temporal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Connectionist Temporal Classification (CTC) models are popular for their
balance between speed and performance for Automatic Speech Recognition (ASR).
However, these CTC models still struggle in other areas, such as
personalization towards custom words. A recent approach explores Contextual
Adapters, wherein an attention-based biasing model for CTC is used to improve
the recognition of custom entities. While this approach works well with enough
data, we showcase that it isn't an effective strategy for low-resource
languages. In this work, we propose a supervision loss for smoother training of
the Contextual Adapters. Further, we explore a multilingual strategy to improve
performance with limited training data. Our method achieves 48% F1 improvement
in retrieving unseen custom entities for a low-resource language.
Interestingly, as a by-product of training the Contextual Adapters, we see a
5-11% Word Error Rate (WER) reduction in the performance of the base CTC model
as well.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：An End-to-End Multi-Module Audio Deepfake Generation System for ADD  Challenge 2023</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00729</p>
  <p><b>作者</b>：Sheng Zhao,  Qilong Yuan,  Yibo Duan,  Zhuoyue Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthetic speech generation, generate language content, simulating fake human, fake human voice.The, human voice.The key</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of synthetic speech generation is to generate language content from
a given text, then simulating fake human voice.The key factors that determine
the effect of synthetic speech generation mainly include speed of generation,
accuracy of word segmentation, naturalness of synthesized speech, etc. This
paper builds an end-to-end multi-module synthetic speech generation model,
including speaker encoder, synthesizer based on Tacotron2, and vocoder based on
WaveRNN. In addition, we perform a lot of comparative experiments on different
datasets and various model structures. Finally, we won the first place in the
ADD 2023 challenge Track 1.1 with the weighted deception success rate (WDSR) of
44.97%.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to  Estimate the Check-Worthiness of Multi-Modal Tweets</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00610</p>
  <p><b>作者</b>：Raphael Frick,  Inna Vogel</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：social media opens, social media, videos and audio, option of sharing, audio files</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The option of sharing images, videos and audio files on social media opens up
new possibilities for distinguishing between false information and fake news on
the Internet. Due to the vast amount of data shared every second on social
media, not all data can be verified by a computer or a human expert. Here, a
check-worthiness analysis can be used as a first step in the fact-checking
pipeline and as a filtering mechanism to improve efficiency. This paper
proposes a novel way of detecting the check-worthiness in multi-modal tweets.
It takes advantage of two classifiers, each trained on a single modality. For
image data, extracting the embedded text with an OCR analysis has shown to
perform best. By combining the two classifiers, the proposed solution was able
to place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297
achieved on the private test set.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed  Search Logs for Zero-shot Biomedical Information Retrieval</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00589</p>
  <p><b>作者</b>：Qiao Jin,  Won Kim,  Qingyu Chen,  Donald C. Comeau,  Lana Yeganova,  John Wilbur,  Zhiyong Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical decision support, biomedical knowledge acquisition, decision support, Information retrieval, knowledge acquisition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information retrieval (IR) is essential in biomedical knowledge acquisition
and clinical decision support. While recent progress has shown that language
model encoders perform better semantic retrieval, training such models requires
abundant query-article annotations that are difficult to obtain in biomedicine.
As a result, most biomedical IR systems only conduct lexical matching. In
response, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained
Transformer model for zero-shot biomedical IR. To train BioCPT, we collected an
unprecedented scale of 255 million user click logs from PubMed. With such data,
we use contrastive learning to train a pair of closely-integrated retriever and
re-ranker. Experimental results show that BioCPT sets new state-of-the-art
performance on five biomedical IR tasks, outperforming various baselines
including much larger models such as GPT-3-sized cpt-text-XL. In addition,
BioCPT also generates better biomedical article and sentence representations
for semantic evaluations. As such, BioCPT can be readily applied to various
real-world biomedical IR tasks. BioCPT API and code are publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：SSP: Self-Supervised Post-training for Conversational Search</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00569</p>
  <p><b>作者</b>：Quan Tu,  Shen Gao,  Xiaolong Wu,  Zhao Cao,  Ji-Rong Wen,  Rui Yan</p>
  <p><b>备注</b>：Accepted by ACL 2023 Findings, Long Paper</p>
  <p><b>关键词</b>：Conversational search, Conversational, next-generation search paradigm, search, existing conversational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational search has been regarded as the next-generation search
paradigm. Constrained by data scarcity, most existing methods distill the
well-trained ad-hoc retriever to the conversational retriever. However, these
methods, which usually initialize parameters by query reformulation to discover
contextualized dependency, have trouble in understanding the dialogue structure
information and struggle with contextual semantic vanishing. In this paper, we
propose \fullmodel (\model) which is a new post-training paradigm with three
self-supervised tasks to efficiently initialize the conversational search model
to enhance the dialogue structure and contextual semantic understanding.
Furthermore, the \model can be plugged into most of the existing conversational
models to boost their performance. To verify the effectiveness of our proposed
method, we apply the conversational encoder post-trained by \model on the
conversational search task using two benchmark datasets: CAsT-19 and CAsT-20.
Extensive experiments that our \model can boost the performance of several
existing conversational search methods. Our source code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on  the Tensor-Train Decomposition</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00526</p>
  <p><b>作者</b>：Mingxue Xu,  Yao Lei Xu,  Danilo P. Mandic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：underpin Large Language, Large Language Models, complex language patterns, embeddings underpin Large, capture subtle semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-dimensional token embeddings underpin Large Language Models (LLMs), as
they can capture subtle semantic information and significantly enhance the
modelling of complex language patterns. However, the associated high
dimensionality also introduces considerable model parameters, and a
prohibitively high model storage. To address this issue, this work proposes an
approach based on the Tensor-Train Decomposition (TTD), where each token
embedding is treated as a Matrix Product State (MPS) that can be efficiently
computed in a distributed manner. The experimental results on GPT-2 demonstrate
that, through our approach, the embedding layer can be compressed by a factor
of up to 38.40 times, and when the compression factor is 3.31 times, even
produced a better performance than the original GPT-2 model.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Large Language Models Enable Few-Shot Clustering</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00524</p>
  <p><b>作者</b>：Vijay Viswanathan,  Kiril Gashteovski,  Carolin Lawrence,  Tongshuang Wu,  Graham Neubig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unlike traditional unsupervised, traditional unsupervised clustering, provide meaningful structure, Unlike traditional, traditional unsupervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlike traditional unsupervised clustering, semi-supervised clustering allows
users to provide meaningful structure to the data, which helps the clustering
algorithm to match the user's intent. Existing approaches to semi-supervised
clustering require a significant amount of feedback from an expert to improve
the clusters. In this paper, we ask whether a large language model can amplify
an expert's guidance to enable query-efficient, few-shot semi-supervised text
clustering. We show that LLMs are surprisingly effective at improving
clustering. We explore three stages where LLMs can be incorporated into
clustering: before clustering (improving input features), during clustering (by
providing constraints to the clusterer), and after clustering (using LLMs
post-correction). We find incorporating LLMs in the first two stages can
routinely provide significant improvements in cluster quality, and that LLMs
enable a user to make trade-offs between cost and accuracy to produce desired
clusters. We release our code and LLM prompts for the public to use.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：HeGeL: A Novel Dataset for Geo-Location from Hebrew Text</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00509</p>
  <p><b>作者</b>：Tzuf Paz-Argaman,  Tal Bauman,  Itai Mondshine,  Itzhak Omer,  Sagi Dalyot,  Reut Tsarfaty</p>
  <p><b>备注</b>：Accepted for ACL findings 2023</p>
  <p><b>关键词</b>：natural language understanding, retrieving the coordinates, Wikipedia and Twitter, free-form language description, textual geolocation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of textual geolocation - retrieving the coordinates of a place based
on a free-form language description - calls for not only grounding but also
natural language understanding and geospatial reasoning. Even though there are
quite a few datasets in English used for geolocation, they are currently based
on open-source data (Wikipedia and Twitter), where the location of the
described place is mostly implicit, such that the location retrieval resolution
is limited. Furthermore, there are no datasets available for addressing the
problem of textual geolocation in morphologically rich and resource-poor
languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location
(HeGeL) corpus, designed to collect literal place descriptions and analyze
lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place
descriptions of various place types in three cities in Israel. Qualitative and
empirical analysis show that the data exhibits abundant use of geospatial
reasoning and requires a novel environmental representation.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：PatternGPT :A Pattern-Driven Framework for Large Language Model Text  Generation</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00470</p>
  <p><b>作者</b>：Le Xiao,  Xin Shan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, Large language, language models, shown excellent text, guide large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models(LLMs) have shown excellent text generation
capabilities, but there is still much space for improvement in accuracy,
sometimes with grammatical errors, semantic inaccuracies, and contextual
incoherence, which seriously affect the reliability of the models. These
problems may originate from the difficulties and limitations encountered in the
pattern extraction stage of large language models. How to utilize the
generative power of large language models to generate as many possible patterns
that help solve problems and find the optimal patterns from them, so as to use
patterns to guide large language models to generate good content, has become a
current research hotspot. In this paper, we propose a pattern extraction and
selection framework, PatternGPT, which generates rich patterns through the
extraction ability of large language models and draws on the idea of federation
learning, where multiple agents collaborate with each other to generate diverse
patterns. High-quality patterns are selected by defining criteria and
optimization algorithms to personalize the guidance of the model generation
process. PatternGPT has the advantages of generating diverse and useful
patterns, extending relevant knowledge, facilitating efficient pattern use and
transfer, and optimizing the quality of generated results and user experience,
which provides an effective method for optimizing the text generation
capability of large language models and is expected to drive further
development in the field of intelligent dialogue and content generation. It is
expected to promote further development in the field of intelligent dialogue
and content generation.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Conformer LLMs -- Convolution Augmented Large Language Models</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00461</p>
  <p><b>作者</b>：Prateek Verma</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：large language models, blocks of neural, work builds, language models, popular blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work builds together two popular blocks of neural architecture, namely
convolutional layers and Transformers, for large language models (LLMs).
Non-causal conformers are used ubiquitously in automatic speech recognition.
This work aims to adapt these architectures in a causal setup for training
LLMs. Transformers decoders effectively capture long-range dependencies over
several modalities and form a core backbone of modern advancements in machine
learning. Convolutional architectures have been popular in extracting features
in domains such as raw 1-D signals, speech, and images, to name a few. In this
paper, by combining local and global dependencies over latent representations
using causal convolutional filters and Transformer, we achieve significant
gains in performance. This work showcases a robust speech architecture that can
be integrated and adapted in a causal setup beyond speech applications for
large-scale language modeling.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal  Data</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00456</p>
  <p><b>作者</b>：Xinzhe Li,  Ming Liu,  Shang Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ethical concerns arising, deep learning models, paper addresses, addresses the ethical, ethical concerns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the ethical concerns arising from the use of
unauthorized public data in deep learning models and proposes a novel solution.
Specifically, building on the work of Huang et al. (2021), we extend their
bi-level optimization approach to generate unlearnable text using a
gradient-based search technique. However, although effective, this approach
faces practical limitations, including the requirement of batches of instances
and model architecture knowledge that is not readily accessible to ordinary
users with limited access to their own data. Furthermore, even with
semantic-preserving constraints, unlearnable noise can alter the text's
semantics. To address these challenges, we extract simple patterns from
unlearnable text produced by bi-level optimization and demonstrate that the
data remains unlearnable for unknown models. Additionally, these patterns are
not instance- or dataset-specific, allowing users to readily apply them to text
classification and question-answering tasks, even if only a small proportion of
users implement them on their public content. We also open-source codes to
generate unlearnable text and assess unlearnable noise to benefit the public
and future studies.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Don't Stop Self-Supervision: Accent Adaptation of Speech Representations  via Residual Adapters</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00453</p>
  <p><b>作者</b>：Anshu Bhatia,  Sanchit Sinha,  Saket Dingliwal,  Karthik Gopalakrishnan,  Sravan Bodapati,  Katrin Kirchhoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massive unlabeled speech, unlabeled speech corpora, fashion from massive, massive unlabeled, adapted successfully</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech representations learned in a self-supervised fashion from massive
unlabeled speech corpora have been adapted successfully toward several
downstream tasks. However, such representations may be skewed toward canonical
data characteristics of such corpora and perform poorly on atypical, non-native
accented speaker populations. With the state-of-the-art HuBERT model as a
baseline, we propose and investigate self-supervised adaptation of speech
representations to such populations in a parameter-efficient way via training
accent-specific residual adapters. We experiment with 4 accents and choose
automatic speech recognition (ASR) as the downstream task of interest. We
obtain strong word error rate reductions (WERR) over HuBERT-large for all 4
accents, with a mean WERR of 22.7% with accent-specific adapters and a mean
WERR of 25.1% if the entire encoder is accent-adapted. While our experiments
utilize HuBERT and ASR as the downstream task, our proposed approach is both
model and task-agnostic.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Dual-Stream Recurrence-Attention Network with Global-Local Awareness  for Emotion Recognition in Textual Dialogue</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00449</p>
  <p><b>作者</b>：Jiang Li,  Xiaoping Wang,  Zhigang Zeng</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：real-world dialogue systems, dialogue systems, great significance, real-world dialogue, ability to understand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world dialogue systems, the ability to understand the user's emotions
and interact anthropomorphically is of great significance. Emotion Recognition
in Conversation (ERC) is one of the key ways to accomplish this goal and has
attracted growing attention. How to model the context in a conversation is a
central aspect and a major challenge of ERC tasks. Most existing approaches are
generally unable to capture both global and local contextual information
efficiently, and their network structures are too complex to design. For this
reason, in this work, we propose a straightforward Dual-stream
Recurrence-Attention Network (DualRAN) based on Recurrent Neural Network (RNN)
and Multi-head ATtention network (MAT). The proposed model eschews the complex
network structure of current methods and focuses on combining recurrence-based
methods with attention-based methods. DualRAN is a dual-stream structure mainly
consisting of local- and global-aware modules, modeling a conversation from
distinct perspectives. To achieve the local-aware module, we extend the
structure of RNN, thus enhancing the expressive capability of the network. In
addition, we develop two single-stream network variants for DualRAN, i.e.,
SingleRANv1 and SingleRANv2. We conduct extensive experiments on four widely
used benchmark datasets, and the results reveal that the proposed model
outshines all baselines. Ablation studies further demonstrate the effectiveness
of each component.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00382</p>
  <p><b>作者</b>：Pin-Jie Lin,  Muhammed Saeed,  Ernie Chang,  Merel Scholman</p>
  <p><b>备注</b>：To appear in INTERSPEECH 2023</p>
  <p><b>关键词</b>：Developing effective spoken, spoken language processing, language processing systems, effective spoken language, low-resource languages poses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Developing effective spoken language processing systems for low-resource
languages poses several challenges due to the lack of parallel data and limited
resources for fine-tuning models. In this work, we target on improving upon
both text classification and translation of Nigerian Pidgin (Naija) by
collecting a large-scale parallel English-Pidgin corpus and further propose a
framework of cross-lingual adaptive training that includes both continual and
task adaptive training so as to adapt a base pre-trained model to low-resource
languages. Our studies show that English pre-trained language models serve as a
stronger prior than multilingual language models on English-Pidgin tasks with
up to 2.38 BLEU improvements; and demonstrate that augmenting orthographic data
and using task adaptive training with back-translation can have a significant
impact on model performance.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Effective Matching of Patients to Clinical Trials using Entity  Extraction and Neural Re-ranking</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00381</p>
  <p><b>作者</b>：Wojciech Kusa,  Óscar E. Mendoza,  Petr Knoth,  Gabriella Pasi,  Allan Hanbury</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：inadequate patient recruitment, fail due, due to inadequate, patient recruitment, retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical trials (CTs) often fail due to inadequate patient recruitment. This
paper tackles the challenges of CT retrieval by presenting an approach that
addresses the patient-to-trials paradigm. Our approach involves two key
components in a pipeline-based model: (i) a data enrichment technique for
enhancing both queries and documents during the first retrieval stage, and (ii)
a novel re-ranking schema that uses a Transformer network in a setup adapted to
this task by leveraging the structure of the CT documents. We use named entity
recognition and negation detection in both patient description and the
eligibility section of CTs. We further classify patient descriptions and CT
eligibility criteria into current, past, and family medical conditions. This
extracted information is used to boost the importance of disease and drug
mentions in both query and index for lexical retrieval. Furthermore, we propose
a two-step training schema for the Transformer network used to re-rank the
results from the lexical retrieval. The first step focuses on matching patient
information with the descriptive sections of trials, while the second step aims
to determine eligibility by matching patient information with the criteria
section. Our findings indicate that the inclusion criteria section of the CT
has a great influence on the relevance score in lexical models, and that the
enrichment techniques for queries and documents improve the retrieval of
relevant trials. The re-ranking strategy, based on our training schema,
consistently enhances CT retrieval and shows improved performance by 15\% in
terms of precision at retrieving eligible trials. The results of our
experiments suggest the benefit of making use of extracted entities. Moreover,
our proposed re-ranking schema shows promising effectiveness compared to larger
neural models, even with limited training data.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Revisiting Sample Size Determination in Natural Language Understanding</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00374</p>
  <p><b>作者</b>：Ernie Chang,  Muhammad Hassan Rashid,  Pin-Jie Lin,  Changsheng Zhao,  Vera Demberg,  Yangyang Shi,  Vikas Chandra</p>
  <p><b>备注</b>：Accepted to ACL 2023</p>
  <p><b>关键词</b>：hugely beneficial step, step towards reducing, hugely beneficial, beneficial step, labeled to achieve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowing exactly how many data points need to be labeled to achieve a certain
model performance is a hugely beneficial step towards reducing the overall
budgets for annotation. It pertains to both active learning and traditional
data annotation, and is particularly beneficial for low resource scenarios.
Nevertheless, it remains a largely under-explored area of research in NLP. We
therefore explored various techniques for estimating the training sample size
necessary to achieve a targeted performance value. We derived a simple yet
effective approach to predict the maximum achievable model performance based on
small amount of training samples - which serves as an early indicator during
data annotation for data quality and sample size determination. We performed
ablation studies on four language understanding tasks, and showed that the
proposed approach allows us to forecast model performance within a small margin
of mean absolute error (~ 0.9%) with only 10% data.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Improving Text Matching in E-Commerce Search with A Rationalizable,  Intervenable and Fast Entity-Based Relevance Model</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00370</p>
  <p><b>作者</b>：Jiong Cai,  Yong Jiang,  Yue Zhang,  Chenyue Jiang,  Ke Yu,  Jianhui Ji,  Rong Xiao,  Haihong Tang,  Tao Wang,  Zhongqiang Huang,  Pengjun Xie,  Fei Huang,  Kewei Tu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：search system, Discovering the intended, massive repository, main goals, e-commerce search system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discovering the intended items of user queries from a massive repository of
items is one of the main goals of an e-commerce search system. Relevance
prediction is essential to the search system since it helps improve
performance. When online serving a relevance model, the model is required to
perform fast and accurate inference. Currently, the widely used models such as
Bi-encoder and Cross-encoder have their limitations in accuracy or inference
speed respectively. In this work, we propose a novel model called the
Entity-Based Relevance Model (EBRM). We identify the entities contained in an
item and decompose the QI (query-item) relevance problem into multiple QE
(query-entity) relevance problems; we then aggregate their results to form the
QI prediction using a soft logic formulation. The decomposition allows us to
use a Cross-encoder QE relevance module for high accuracy as well as cache QE
predictions for fast online inference. Utilizing soft logic makes the
prediction procedure interpretable and intervenable. We also show that
pretraining the QE module with auto-generated QE data from user logs can
further improve the overall performance. The proposed method is evaluated on
labeled data from e-commerce websites. Empirical results show that it achieves
promising improvements with computation efficiency.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained  Transformer</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00360</p>
  <p><b>作者</b>：Zuchao Li,  Shitou Zhang,  Hai Zhao,  Yifei Yang,  Dongjie Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Shanghai Jiao Tong, jointly by Wuhan, Jiao Tong University, designed and trained, trained jointly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>BatGPT is a large-scale language model designed and trained jointly by Wuhan
University and Shanghai Jiao Tong University. It is capable of generating
highly natural and fluent text in response to various types of input, including
text prompts, images, and audio. In the modeling level, we employ a
bidirectional autoregressive architecture that allows the model to efficiently
capture the complex dependencies of natural language, making it highly
effective in tasks such as language generation, dialog systems, and question
answering. Moreover, the bidirectional autoregressive modeling not only
operates from left to right but also from right to left, effectively reducing
fixed memory effects and alleviating model hallucinations.
In the training aspect, we propose a novel parameter expansion method for
leveraging the pre-training of smaller models and employ reinforcement learning
from both AI and human feedback, aimed at improving the model's alignment
performance. Overall, these approaches significantly improve the effectiveness
of BatGPT, and the model can be utilized for a wide range of natural language
applications.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Improving Multitask Retrieval by Promoting Task Specialization</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00342</p>
  <p><b>作者</b>：Wenzheng Zhang,  Chenyan Xiong,  Karl Stratos,  Arnold Overwijk</p>
  <p><b>备注</b>：TACL 2023</p>
  <p><b>关键词</b>：retrieve relevant contexts, retrieve relevant, relevant contexts, contexts for multiple, multitask retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In multitask retrieval, a single retriever is trained to retrieve relevant
contexts for multiple tasks. Despite its practical appeal, naive multitask
retrieval lags behind task-specific retrieval in which a separate retriever is
trained for each task. We show that it is possible to train a multitask
retriever that outperforms task-specific retrievers by promoting task
specialization. The main ingredients are: (1) a better choice of pretrained
model (one that is explicitly optimized for multitasking) along with compatible
prompting, and (2) a novel adaptive learning method that encourages each
parameter to specialize in a particular task. The resulting multitask retriever
is highly performant on the KILT benchmark. Upon analysis, we find that the
model indeed learns parameters that are more task-specialized compared to naive
multitasking without prompting or adaptive learning.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Single Sequence Prediction over Reasoning Graphs for Multi-hop QA</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00335</p>
  <p><b>作者</b>：Gowtham Ramesh,  Makesh Sreedhar,  Junjie Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent generative approaches, single sequence output, multi-hop question answering, reasoning path, Recent generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent generative approaches for multi-hop question answering (QA) utilize
the fusion-in-decoder method~\cite{izacard-grave-2021-leveraging} to generate a
single sequence output which includes both a final answer and a reasoning path
taken to arrive at that answer, such as passage titles and key facts from those
passages. While such models can lead to better interpretability and high
quantitative scores, they often have difficulty accurately identifying the
passages corresponding to key entities in the context, resulting in incorrect
passage hops and a lack of faithfulness in the reasoning path. To address this,
we propose a single-sequence prediction method over a local reasoning graph
(\model)\footnote{Code/Models will be released at
\url{this https URL}} that integrates a graph
structure connecting key entities in each context passage to relevant
subsequent passages for each question. We use a graph neural network to encode
this graph structure and fuse the resulting representations into the entity
representations of the model. Our experiments show significant improvements in
answer exact-match/F1 scores and faithfulness of grounding in the reasoning
path on the HotpotQA dataset and achieve state-of-the-art numbers on the
Musique dataset with only up to a 4\% increase in model parameters.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Let Me Teach You: Pedagogical Foundations of Feedback for Language  Models</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00279</p>
  <p><b>作者</b>：Beatriz Borges,  Niket Tandon,  Tanja Käser,  Antoine Bosselut</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：increasingly popular avenue, Natural Language Feedback, Large Language Models, Natural Language, avenue to align</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural Language Feedback (NLF) is an increasingly popular avenue to align
Large Language Models (LLMs) to human preferences. Despite the richness and
diversity of the information it can convey, NLF is often hand-designed and
arbitrary. In a different world, research in pedagogy has long established
several effective feedback models. In this opinion piece, we compile ideas from
pedagogy to introduce FELT, a feedback framework for LLMs that outlines the
various characteristics of the feedback space, and a feedback content taxonomy
based on these variables. Our taxonomy offers both a general mapping of the
feedback space, as well as pedagogy-established discrete categories, allowing
us to empirically demonstrate the impact of different feedback types on revised
generations. In addition to streamlining existing NLF designs, FELT also brings
out new, unexplored directions for research in NLF. We make our taxonomy
available to the community, providing guides and examples for mapping our
categorizations to future resources.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Hierarchical Pretraining for Biomedical Term Embeddings</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00266</p>
  <p><b>作者</b>：Bryan Cai,  Sihang Zeng,  Yucong Lin,  Zheng Yuan,  Doudou Zhou,  Lu Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Electronic health records, provide extensive details, Electronic health, health records, provide extensive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electronic health records (EHR) contain narrative notes that provide
extensive details on the medical condition and management of patients. Natural
language processing (NLP) of clinical notes can use observed frequencies of
clinical terms as predictive features for downstream applications such as
clinical decision making and patient trajectory prediction. However, due to the
vast number of highly similar and related clinical concepts, a more effective
modeling strategy is to represent clinical terms as semantic embeddings via
representation learning and use the low dimensional embeddings as feature
vectors for predictive modeling. To achieve efficient representation,
fine-tuning pretrained language models with biomedical knowledge graphs may
generate better embeddings for biomedical terms than those from standard
language models alone. These embeddings can effectively discriminate synonymous
pairs of from those that are unrelated. However, they often fail to capture
different degrees of similarity or relatedness for concepts that are
hierarchical in nature. To overcome this limitation, we propose HiPrBERT, a
novel biomedical term representation model trained on additionally complied
data that contains hierarchical structures for various biomedical terms. We
modify an existing contrastive loss function to extract information from these
hierarchies. Our numerical experiments demonstrate that HiPrBERT effectively
learns the pair-wise distance from hierarchical information, resulting in a
substantially more informative embeddings for further biomedical applications</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：InstructEval: Systematic Evaluation of Instruction Selection Methods</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00259</p>
  <p><b>作者</b>：Anirudh Ajith,  Chris Pan,  Mengzhou Xia,  Ameet Deshpande,  Karthik Narasimhan</p>
  <p><b>备注</b>：10 content pages, 3 figures, 8 tables</p>
  <p><b>关键词</b>：large language model, In-context learning, called demonstrations, prompting a large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In-context learning (ICL) performs tasks by prompting a large language model
(LLM) using an instruction and a small set of annotated examples called
demonstrations. Recent work has shown that the precise details of the inputs
used in the prompt significantly impacts ICL, which has incentivized
instruction selection algorithms. The effect of instruction-choice however is
severely underexplored, with existing analyses being restricted to shallow
subsets of models and tasks, which limits the generalizability of their
insights. We develop an ICL evaluation suite to conduct a thorough assessment
of these techniques. The suite includes 13 open-sourced LLMs of varying scales
from 4 distinct model families and covers 9 different tasks, representing a
range of task types across 3 categories. In this work, we evaluate the relative
performance of 7 popular instruction selection methods using our benchmark over
five desiderata relevant to ICL. We discover that using curated
manually-written instructions and simple instructions without any task-specific
descriptions often elicits superior ICL performance than that of automatic
instruction-induction methods, pointing to a lack of generalizability among the
latter. We release our evaluation suite for benchmarking instruction selection
approaches, and call for more rigorous and generalizable methods in this space.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Image Matters: A New Dataset and Empirical Study for Multimodal  Hyperbole Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00209</p>
  <p><b>作者</b>：Huixuan Zhang,  Xiaojun Wan</p>
  <p><b>备注</b>：11 pages, 6 figures. 6 tables</p>
  <p><b>关键词</b>：common linguistic phenomenon, linguistic phenomenon, common linguistic, Hyperbole, hyperbole detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection
of hyperbole is an important part of understanding human expression. There have
been several studies on hyperbole detection, but most of which focus on text
modality only. However, with the development of social media, people can create
hyperbolic expressions with various modalities, including text, images, videos,
etc. In this paper, we focus on multimodal hyperbole detection. We create a
multimodal detection dataset\footnote{The dataset will be released to the
community.} from Weibo (a Chinese social media) and carry out some studies on
it. We treat the text and image from a piece of weibo as two modalities and
explore the role of text and image for hyperbole detection. Different
pre-trained multimodal encoders are also evaluated on this downstream task to
show their performance. Besides, since this dataset is constructed from five
different topics, we also evaluate the cross-domain performance of different
models. These studies can serve as a benchmark and point out the direction of
further study on multimodal hyperbole detection.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：How far is Language Model from 100% Few-shot Named Entity Recognition in  Medical Domain</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00186</p>
  <p><b>作者</b>：Mingchen Li,  Rui Zhang</p>
  <p><b>备注</b>：the first manuscript. arXiv admin note: text overlap with arXiv:2305.18624</p>
  <p><b>关键词</b>：few-shot medical NER, NER, medical NER tasks, Small LMs, Large LMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in language models (LMs) have led to the emergence of
powerful models such as Small LMs (e.g., T5) and Large LMs (e.g., GPT-4). These
models have demonstrated exceptional capabilities across a wide range of tasks,
such as name entity recognition (NER) in the general domain. (We define SLMs as
pre-trained models with fewer parameters compared to models like GPT-3/3.5/4,
such as T5, BERT, and others.) Nevertheless, their efficacy in the medical
section remains uncertain and the performance of medical NER always needs high
accuracy because of the particularity of the field. This paper aims to provide
a thorough investigation to compare the performance of LMs in medical few-shot
NER and answer How far is LMs from 100\% Few-shot NER in Medical Domain, and
moreover to explore an effective entity recognizer to help improve the NER
performance. Based on our extensive experiments conducted on 16 NER models
spanning from 2018 to 2023, our findings clearly indicate that LLMs outperform
SLMs in few-shot medical NER tasks, given the presence of suitable examples and
appropriate logical frameworks. Despite the overall superiority of LLMs in
few-shot medical NER tasks, it is important to note that they still encounter
some challenges, such as misidentification, wrong template prediction, etc.
Building on previous findings, we introduce a simple and effective method
called \textsc{RT} (Retrieving and Thinking), which serves as retrievers,
finding relevant examples, and as thinkers, employing a step-by-step reasoning
process. Experimental results show that our proposed \textsc{RT} framework
significantly outperforms the strong open baselines on the two open medical
benchmark datasets</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Personality Traits in Large Language Models</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00184</p>
  <p><b>作者</b>：Mustafa Safdari,  Greg Serapio-García,  Clément Crepy,  Stephen Fitz,  Peter Romero,  Luning Sun,  Marwa Abdulhai,  Aleksandra Faust,  Maja Matarić</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, revolutionized natural language, contextually relevant text, large language models, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of large language models (LLMs) has revolutionized natural
language processing, enabling the generation of coherent and contextually
relevant text. As LLMs increasingly power conversational agents, the
synthesized personality embedded in these models by virtue of their training on
large amounts of human-generated data draws attention. Since personality is an
important factor determining the effectiveness of communication, we present a
comprehensive method for administering validated psychometric tests and
quantifying, analyzing, and shaping personality traits exhibited in text
generated from widely-used LLMs. We find that: 1) personality simulated in the
outputs of some LLMs (under specific prompting configurations) is reliable and
valid; 2) evidence of reliability and validity of LLM-simulated personality is
stronger for larger and instruction fine-tuned models; and 3) personality in
LLM outputs can be shaped along desired dimensions to mimic specific
personality profiles. We also discuss potential applications and ethical
implications of our measurement and shaping framework, especially regarding
responsible use of LLMs.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Still No Lie Detector for Language Models: Probing Empirical and  Conceptual Roadblocks</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00175</p>
  <p><b>作者</b>：B.A. Levinstein,  Daniel A. Herrmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, language models, Azaria and Mitchell, large language, beliefs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the questions of whether or not large language models (LLMs) have
beliefs, and, if they do, how we might measure them. First, we evaluate two
existing approaches, one due to Azaria and Mitchell (2023) and the other to
Burns et al. (2022). We provide empirical results that show that these methods
fail to generalize in very basic ways. We then argue that, even if LLMs have
beliefs, these methods are unlikely to be successful for conceptual reasons.
Thus, there is still no lie-detector for LLMs. After describing our empirical
results we take a step back and consider whether or not we should expect LLMs
to have something like beliefs in the first place. We consider some recent
arguments aiming to show that LLMs cannot have beliefs. We show that these
arguments are misguided. We provide a more productive framing of questions
surrounding the status of beliefs in LLMs, and highlight the empirical nature
of the problem. We conclude by suggesting some concrete paths for future work.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：The Integer Linear Programming Inference Cookbook</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00171</p>
  <p><b>作者</b>：Vivek Srikumar,  Dan Roth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, language processing problems, integer linear programs, integer linear, employed to model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the years, integer linear programs have been employed to model inference
in many natural language processing problems. This survey is meant to guide the
reader through the process of framing a new inference problem as an instance of
an integer linear program and is structured as a collection of recipes. At the
end, we will see two worked examples to illustrate the use of these recipes.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：What do self-supervised speech models know about words?</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00162</p>
  <p><b>作者</b>：Ankita Pasad,  Chung-Ming Chien,  Shane Settle,  Karen Livescu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data efficiency improvements, self-supervised speech models, self-supervised speech, data efficiency, efficiency improvements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many self-supervised speech models (S3Ms) have been introduced over the last
few years, producing performance and data efficiency improvements for a variety
of speech tasks. Evidence is emerging that different S3Ms encode linguistic
information in different layers, and also that some S3Ms appear to learn
phone-like sub-word units. However, the extent to which these models capture
larger linguistic units, such as words, and where word-related information is
encoded, remains unclear. In this study, we conduct several analyses of word
segment representations extracted from different layers of three S3Ms:
wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a
lightweight analysis tool, to measure the similarity between these
representations and word-level linguistic properties. We find that the maximal
word-level linguistic content tends to be found in intermediate model layers,
while some lower-level information like pronunciation is also retained in
higher layers of HuBERT and WavLM. Syntactic and semantic word attributes have
similar layer-wise behavior. We also find that, for all of the models tested,
word identity information is concentrated near the center of each word segment.
We then test the layer-wise performance of the same models, when used directly
with no additional learned parameters, on several tasks: acoustic word
discrimination, word segmentation, and semantic sentence similarity. We find
similar layer-wise trends in performance, and furthermore, find that when using
the best-performing layer of HuBERT or WavLM, it is possible to achieve
performance on word segmentation and sentence similarity that rivals more
complex existing approaches.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：SMILE: Evaluation and Domain Adaptation for Social Media Language  Understanding</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00135</p>
  <p><b>作者</b>：Vasilisa Bashlovkina,  Riley Matthews,  Zhaobin Kuang,  Simon Baumgartner,  Michael Bendersky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media language, transformer-based language models, social media, understand social media, media language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the ability of transformer-based language models (LMs) to understand
social media language. Social media (SM) language is distinct from standard
written language, yet existing benchmarks fall short of capturing LM
performance in this socially, economically, and politically important domain.
We quantify the degree to which social media language differs from conventional
language and conclude that the difference is significant both in terms of token
distribution and rate of linguistic shift. Next, we introduce a new benchmark
for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and
eleven tasks. Finally, we show that learning a tokenizer and pretraining on a
mix of social media and conventional language yields an LM that outperforms the
best similar-sized alternative by 4.2 points on the overall SMILE score.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：iMETRE: Incorporating Markers of Entity Types for Relation Extraction</b></summary>
  <p><b>编号</b>：[438]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00132</p>
  <p><b>作者</b>：N Harsha Vardhan,  Manav Chaudhary</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sentence-level relation extraction, Sentence-level relation, aims to identify, contextual sentence, relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentence-level relation extraction (RE) aims to identify the relationship
between 2 entities given a contextual sentence. While there have been many
attempts to solve this problem, the current solutions have a lot of room to
improve. In this paper, we approach the task of relationship extraction in the
financial dataset REFinD. Our approach incorporates typed entity markers
representations and various models finetuned on the dataset, which has allowed
us to achieve an F1 score of 69.65% on the validation set. Through this paper,
we discuss various approaches and possible limitations.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Information Extraction in Domain and Generic Documents: Findings from  Heuristic-based and Data-driven Approaches</b></summary>
  <p><b>编号</b>：[439]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00130</p>
  <p><b>作者</b>：Shiyu Yuan,  Carlo Lipizzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, NLP applications, unstructured text data, NLP, extract structured information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information extraction (IE) plays very important role in natural language
processing (NLP) and is fundamental to many NLP applications that used to
extract structured information from unstructured text data. Heuristic-based
searching and data-driven learning are two main stream implementation
approaches. However, no much attention has been paid to document genre and
length influence on IE tasks. To fill the gap, in this study, we investigated
the accuracy and generalization abilities of heuristic-based searching and
data-driven to perform two IE tasks: named entity recognition (NER) and
semantic role labeling (SRL) on domain-specific and generic documents with
different length. We posited two hypotheses: first, short documents may yield
better accuracy results compared to long documents; second, generic documents
may exhibit superior extraction outcomes relative to domain-dependent documents
due to training document genre limitations. Our findings reveals that no single
method demonstrated overwhelming performance in both tasks. For named entity
extraction, data-driven approaches outperformed symbolic methods in terms of
accuracy, particularly in short texts. In the case of semantic roles
extraction, we observed that heuristic-based searching method and data-driven
based model with syntax representation surpassed the performance of pure
data-driven approach which only consider semantic information. Additionally, we
discovered that different semantic roles exhibited varying accuracy levels with
the same method. This study offers valuable insights for downstream text mining
tasks, such as NER and SRL, when addressing various document features and
genres.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Meta-training with Demonstration Retrieval for Efficient Few-shot  Learning</b></summary>
  <p><b>编号</b>：[444]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00119</p>
  <p><b>作者</b>：Aaron Mueller,  Kanika Narang,  Lambert Mathias,  Qifan Wang,  Hamed Firooz</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：few-shot NLP tasks, show impressive results, language models show, models show impressive, few-shot NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models show impressive results on few-shot NLP tasks. However,
these models are memory and computation-intensive. Meta-training allows one to
leverage smaller models for few-shot generalization in a domain-general and
task-agnostic manner; however, these methods alone results in models that may
not have sufficient parameterization or knowledge to adapt quickly to a large
variety of tasks. To overcome this issue, we propose meta-training with
demonstration retrieval, where we use a dense passage retriever to retrieve
semantically similar labeled demonstrations to each example for more varied
supervision. By separating external knowledge from model parameters, we can use
meta-training to train parameter-efficient models that generalize well on a
larger variety of tasks. We construct a meta-training set from UnifiedQA and
CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our
knowledge, our work is the first to combine retrieval with meta-training, to
use DPR models to retrieve demonstrations, and to leverage demonstrations from
many tasks simultaneously, rather than randomly sampling demonstrations from
the training set of the target task. Our approach outperforms a variety of
targeted parameter-efficient and retrieval-augmented few-shot methods on QA,
NLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our
approach can be meta-trained and fine-tuned quickly on a single GPU.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Ticket-BERT: Labeling Incident Management Tickets with Language Models</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00108</p>
  <p><b>作者</b>：Zhexiong Liu,  Cris Benge,  Siduo Jiang</p>
  <p><b>备注</b>：In the Microsoft Journal of Applied Research (MSJAR), Volume 18, January 2023</p>
  <p><b>关键词</b>：prioritizing incident tickets, efficiently labeling tickets, fine-grained categories, essential aspect, aspect of prioritizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An essential aspect of prioritizing incident tickets for resolution is
efficiently labeling tickets with fine-grained categories. However, ticket data
is often complex and poses several unique challenges for modern machine
learning methods: (1) tickets are created and updated either by machines with
pre-defined algorithms or by engineers with domain expertise that share
different protocols, (2) tickets receive frequent revisions that update ticket
status by modifying all or parts of ticket descriptions, and (3) ticket
labeling is time-sensitive and requires knowledge updates and new labels per
the rapid software and hardware improvement lifecycle. To handle these issues,
we introduce Ticket- BERT which trains a simple yet robust language model for
labeling tickets using our proposed ticket datasets. Experiments demonstrate
the superiority of Ticket-BERT over baselines and state-of-the-art text
classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT
with an active learning cycle and deploy it on the Microsoft IcM system, which
enables the model to quickly finetune on newly-collected tickets with a few
annotations.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Queer People are People First: Deconstructing Sexual Identity  Stereotypes in Large Language Models</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00101</p>
  <p><b>作者</b>：Harnoor Dhingra,  Preetiha Jayashanker,  Sayali Moghe,  Emma Strubell</p>
  <p><b>备注</b>：Accepted to Queer in AI Workshop at ACL 2023</p>
  <p><b>关键词</b>：Large Language Models, Language Models, minimally processed web, social biases held, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are trained primarily on minimally processed web
text, which exhibits the same wide range of social biases held by the humans
who created that content. Consequently, text generated by LLMs can
inadvertently perpetuate stereotypes towards marginalized groups, like the
LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs
generate text describing people with different sexual identities. Analyzing
bias in the text generated by an LLM using regard score shows measurable bias
against queer people. We then show that a post-hoc method based on
chain-of-thought prompting using SHAP analysis can increase the regard of the
sentence, representing a promising approach towards debiasing the output of
LLMs in this setting.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Seeing in Words: Learning to Classify through Language Bottlenecks</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00028</p>
  <p><b>作者</b>：Khalid Saifullah,  Yuxin Wen,  Jonas Geiping,  Micah Goldblum,  Tom Goldstein</p>
  <p><b>备注</b>：5 pages, 2 figures, Published as a Tiny Paper at ICLR 2023</p>
  <p><b>关键词</b>：achieving high accuracy, computer vision extract, vision extract uninterpretable, extract uninterpretable features, accuracy on benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks for computer vision extract uninterpretable features despite
achieving high accuracy on benchmarks. In contrast, humans can explain their
predictions using succinct and intuitive descriptions. To incorporate
explainability into neural networks, we train a vision model whose feature
representations are text. We show that such a model can effectively classify
ImageNet images, and we discuss the challenges we encountered when training it.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit  to Hindi for Machine Translation</b></summary>
  <p><b>编号</b>：[474]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00021</p>
  <p><b>作者</b>：Vishvajitsinh Bakrola,  Jitendra Nasariwala</p>
  <p><b>备注</b>：3 Pages, 1 Figure, and 1 Table</p>
  <p><b>关键词</b>：large bilingual parallel, named SAHAAYAK, bilingual parallel corpus, data article presents, language pair Sanskrit-Hindi</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The data article presents the large bilingual parallel corpus of
low-resourced language pair Sanskrit-Hindi, named SAHAAYAK 2023. The corpus
contains total of 1.5M sentence pairs between Sanskrit and Hindi. To make the
universal usability of the corpus and to make it balanced, data from multiple
domain has been incorporated into the corpus that includes, News, Daily
conversations, Politics, History, Sport, and Ancient Indian Literature. The
multifaceted approach has been adapted to make a sizable multi-domain corpus of
low-resourced languages like Sanskrit. Our development approach is spanned from
creating a small hand-crafted dataset to applying a wide range of mining,
cleaning, and verification. We have used the three-fold process of mining:
mining from machine-readable sources, mining from non-machine readable sources,
and collation from existing corpora sources. Post mining, the dedicated
pipeline for normalization, alignment, and corpus cleaning is developed and
applied to the corpus to make it ready to use on machine translation
algorithms.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Automated Assignment and Classification of Software Issues</b></summary>
  <p><b>编号</b>：[479]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00009</p>
  <p><b>作者</b>：Büşra Tabak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：team members, work to fix, improve or create, relevant team member, units of work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software issues contain units of work to fix, improve or create new threads
during the development and facilitate communication among the team members.
Assigning an issue to the most relevant team member and determining a category
of an issue is a tedious and challenging task. Wrong classifications cause
delays and rework in the project and trouble among the team members. This
thesis proposes a set of carefully curated linguistic features for shallow
machine learning methods and compares the performance of shallow and ensemble
methods with deep language models. Unlike the state-of-the-art, we assign
issues to four roles (designer, developer, tester, and leader) rather than to
specific individuals or teams to contribute to the generality of our solution.
We also consider the level of experience of the developers to reflect the
industrial practices in our solution formulation. We employ a classification
approach to categorize issues into distinct classes, namely bug, new feature,
improvement, and other. Additionally, we endeavor to further classify bugs
based on the specific type of modification required. We collect and annotate
five industrial data sets from one of the top three global television producers
to evaluate our proposal and compare it with deep language models. Our data
sets contain 5324 issues in total. We show that an ensemble classifier of
shallow techniques achieves 0.92 for issue assignment and 0.90 for issue
classification in accuracy which is statistically comparable to the
state-of-the-art deep language models. The contributions include the public
sharing of five annotated industrial issue data sets, the development of a
clear and comprehensive feature set, the introduction of a novel label set and
the validation of the efficacy of an ensemble classifier of shallow machine
learning techniques.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Investigating Masking-based Data Generation in Language Models</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00008</p>
  <p><b>作者</b>：Ed S. Ma</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：natural language processing, pre-trained language models, language, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current era of natural language processing (NLP) has been defined by the
prominence of pre-trained language models since the advent of BERT. A feature
of BERT and models with similar architecture is the objective of masked
language modeling, in which part of the input is intentionally masked and the
model is trained to predict this piece of masked information. Data augmentation
is a data-driven technique widely used in machine learning, including research
areas like computer vision and natural language processing, to improve model
performance by artificially augmenting the training data set by designated
techniques. Masked language models (MLM), an essential training feature of
BERT, have introduced a novel approach to perform effective pre-training on
Transformer based models in natural language processing tasks. Recent studies
have utilized masked language model to generate artificially augmented data for
NLP downstream tasks. The experimental results show that Mask based data
augmentation method provides a simple but efficient approach to improve the
model performance. In this paper, we explore and discuss the broader
utilization of these data augmentation methods based on MLM.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：NeuBTF: Neural fields for BTF encoding and transfer</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01199</p>
  <p><b>作者</b>：Carlos Rodriguez-Pardo,  Konstantinos Kazatzis,  Jorge Lopez-Moreno,  Elena Garces</p>
  <p><b>备注</b>：9 pages, 7 figures. Accepted to Computers & Graphics (Special Section on CEIG 2023). Project Website: this https URL</p>
  <p><b>关键词</b>：BTF, neural BTF, Neural, material, Neural material</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural material representations are becoming a popular way to represent
materials for rendering. They are more expressive than analytic models and
occupy less memory than tabulated BTFs. However, existing neural materials are
immutable, meaning that their output for a certain query of UVs, camera, and
light vector is fixed once they are trained. While this is practical when there
is no need to edit the material, it can become very limiting when the fragment
of the material used for training is too small or not tileable, which
frequently happens when the material has been captured with a
gonioreflectometer. In this paper, we propose a novel neural material
representation which jointly tackles the problems of BTF compression, tiling,
and extrapolation. At test time, our method uses a guidance image as input to
condition the neural BTF to the structural features of this input image. Then,
the neural BTF can be queried as a regular BTF using UVs, camera, and light
vectors. Every component in our framework is purposefully designed to maximize
BTF encoding quality at minimal parameter count and computational complexity,
achieving competitive compression rates compared with previous work. We
demonstrate the results of our method on a variety of synthetic and captured
materials, showing its generality and capacity to learn to represent many
optical properties.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Improved sampling via learned diffusions</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01198</p>
  <p><b>作者</b>：Lorenz Richter,  Julius Berner,  Guan-Horng Liu</p>
  <p><b>备注</b>：Accepted at ICML 2023 Workshop on New Frontiers in Learning, Control, and Dynamical Systems</p>
  <p><b>关键词</b>：papers proposed deep, proposed deep learning-based, deep learning-based approaches, unnormalized target densities, controlled diffusion processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, a series of papers proposed deep learning-based approaches to
sample from unnormalized target densities using controlled diffusion processes.
In this work, we identify these approaches as special cases of the
Schrödinger bridge problem, seeking the most likely stochastic evolution
between a given prior distribution and the specified target. We further
generalize this framework by introducing a variational formulation based on
divergences between path space measures of time-reversed diffusion processes.
This abstract perspective leads to practical losses that can be optimized by
gradient-based algorithms and includes previous objectives as special cases. At
the same time, it allows us to consider divergences other than the reverse
Kullback-Leibler divergence that is known to suffer from mode collapse. In
particular, we propose the so-called log-variance loss, which exhibits
favorable numerical properties and leads to significantly improved performance
across all considered approaches.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Squeezing Large-Scale Diffusion Models for Mobile</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01193</p>
  <p><b>作者</b>：Jiwoong Choi,  Minkyu Kim,  Daehyun Ahn,  Taesu Kim,  Yulhwa Kim,  Dongwon Jo,  Hyesung Jeon,  Jae-Joon Kim,  Hyungjun Kim</p>
  <p><b>备注</b>：7 pages, 8 figures, ICML 2023 Workshop on Challenges in Deployable Generative AI</p>
  <p><b>关键词</b>：high-fidelity image synthesis, academic research, greatly broadened, broadened the scope, scope of high-fidelity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emergence of diffusion models has greatly broadened the scope of
high-fidelity image synthesis, resulting in notable advancements in both
practical implementation and academic research. With the active adoption of the
model in various real-world applications, the need for on-device deployment has
grown considerably. However, deploying large diffusion models such as Stable
Diffusion with more than one billion parameters to mobile devices poses
distinctive challenges due to the limited computational and memory resources,
which may vary according to the device. In this paper, we present the
challenges and solutions for deploying Stable Diffusion on mobile devices with
TensorFlow Lite framework, which supports both iOS and Android devices. The
resulting Mobile Stable Diffusion achieves the inference latency of smaller
than 7 seconds for a 512x512 image generation on Android devices with mobile
GPUs.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Trainable Transformer in Transformer</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01189</p>
  <p><b>作者</b>：Abhishek Panigrahi,  Sadhika Malladi,  Mengzhou Xia,  Sanjeev Arora</p>
  <p><b>备注</b>：Code base: this https URL</p>
  <p><b>关键词</b>：Recent works attribute, large pre-trained language, pre-trained language models, in-context learning, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works attribute the capability of in-context learning (ICL) in large
pre-trained language models to implicitly simulating and fine-tuning an
internal model (e.g., linear or 2-layer MLP) during inference. However, such
constructions require large memory overhead, which makes simulation of more
sophisticated internal models intractable. In this work, we propose an
efficient construction, Transformer in Transformer (in short, TinT), that
allows a transformer to simulate and fine-tune complex models internally during
inference (e.g., pre-trained language models). In particular, we introduce
innovative approximation techniques that allow a TinT model with less than 2
billion parameters to simulate and fine-tune a 125 million parameter
transformer model within a single forward pass. TinT accommodates many common
transformer variants and its design ideas also improve the efficiency of past
instantiations of simple models inside transformers. We conduct end-to-end
experiments to validate the internal fine-tuning procedure of TinT on various
language modeling and downstream tasks. For example, even with a limited
one-step budget, we observe TinT for a OPT-125M model improves performance by
4-16% absolute on average compared to OPT-125M. These findings suggest that
large pre-trained language models are capable of performing intricate
subroutines. To facilitate further work, a modular and extensible codebase for
TinT is included.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：PlanE: Representation Learning over Planar Graphs</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01180</p>
  <p><b>作者</b>：Radoslav Dimitrov,  Zeyang Zhao,  Ralph Abboud,  İsmail İlkan Ceylan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph neural networks, learned graph function, iteratively compute representations, Graph, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks are prominent models for representation learning over
graphs, where the idea is to iteratively compute representations of nodes of an
input graph through a series of transformations in such a way that the learned
graph function is isomorphism invariant on graphs, which makes the learned
representations graph invariants. On the other hand, it is well-known that
graph invariants learned by these class of models are incomplete: there are
pairs of non-isomorphic graphs which cannot be distinguished by standard graph
neural networks. This is unsurprising given the computational difficulty of
graph isomorphism testing on general graphs, but the situation begs to differ
for special graph classes, for which efficient graph isomorphism testing
algorithms are known, such as planar graphs. The goal of this work is to design
architectures for efficiently learning complete invariants of planar graphs.
Inspired by the classical planar graph isomorphism algorithm of Hopcroft and
Tarjan, we propose PlanE as a framework for planar representation learning.
PlanE includes architectures which can learn complete invariants over planar
graphs while remaining practically scalable. We empirically validate the strong
performance of the resulting model architectures on well-known planar graph
benchmarks, achieving multiple state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Learning Mixtures of Gaussians Using the DDPM Objective</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01178</p>
  <p><b>作者</b>：Kulin Shah,  Sitan Chen,  Adam Klivans</p>
  <p><b>备注</b>：48 pages</p>
  <p><b>关键词</b>：perform score estimation, score estimation, settings score estimation, perform score, Recent works</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works have shown that diffusion models can learn essentially any
distribution provided one can perform score estimation. Yet it remains poorly
understood under what settings score estimation is possible, let alone when
practical gradient-based algorithms for this task can provably succeed.
In this work, we give the first provably efficient results along these lines
for one of the most fundamental distribution families, Gaussian mixture models.
We prove that gradient descent on the denoising diffusion probabilistic model
(DDPM) objective can efficiently recover the ground truth parameters of the
mixture model in the following two settings: 1) We show gradient descent with
random initialization learns mixtures of two spherical Gaussians in $d$
dimensions with $1/\text{poly}(d)$-separated centers. 2) We show gradient
descent with a warm start learns mixtures of $K$ spherical Gaussians with
$\Omega(\sqrt{\log(\min(K,d))})$-separated centers. A key ingredient in our
proofs is a new connection between score-based methods and two other approaches
to distribution learning, the EM algorithm and spectral methods.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01177</p>
  <p><b>作者</b>：Zhengdao Chen</p>
  <p><b>备注</b>：Extended from the paper titled "Multi-Layer Neural Networks as Trainable Ladders of Hilbert Spaces" at ICML 2023</p>
  <p><b>关键词</b>：Neural Hilbert Ladder, functions spaces explored, neural networks, kernel Hilbert spaces, Neural Hilbert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The characterization of the functions spaces explored by neural networks
(NNs) is an important aspect of deep learning theory. In this work, we view a
multi-layer NN with arbitrary width as defining a particular hierarchy of
reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL).
This allows us to define a function space and a complexity measure that
generalize prior results for shallow NNs, and we then examine their theoretical
properties and implications in several aspects. First, we prove a
correspondence between functions expressed by L-layer NNs and those belonging
to L-level NHLs. Second, we prove generalization guarantees for learning an NHL
with the complexity measure controlled. Third, corresponding to the training of
multi-layer NNs in the infinite-width mean-field limit, we derive an evolution
of the NHL characterized as the dynamics of multiple random fields. Fourth, we
show examples of depth separation in NHLs under ReLU and quadratic activation
functions. Finally, we complement the theory with numerical results to
illustrate the learning of RKHS in NN training.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Online nearest neighbor classification</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01170</p>
  <p><b>作者</b>：Sanjoy Dasgupta,  Geelon So</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：online non-parametric classification, realizable setting, study an instance, instance of online, online non-parametric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study an instance of online non-parametric classification in the
realizable setting. In particular, we consider the classical 1-nearest neighbor
algorithm, and show that it achieves sublinear regret - that is, a vanishing
mistake rate - against dominated or smoothed adversaries in the realizable
setting.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Don't freeze: Finetune encoders for better Self-Supervised HAR</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01168</p>
  <p><b>作者</b>：Vitor Fortes Rey,  Dominique Nshimyimana,  Paul Lukowicz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recently self-supervised learning, human activity recognition, data availability problem, Recently self-supervised, availability problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently self-supervised learning has been proposed in the field of human
activity recognition as a solution to the labelled data availability problem.
The idea being that by using pretext tasks such as reconstruction or
contrastive predictive coding, useful representations can be learned that then
can be used for classification. Those approaches follow the pretrain, freeze
and fine-tune procedure. In this paper we will show how a simple change - not
freezing the representation - leads to substantial performance gains across
pretext tasks. The improvement was found in all four investigated datasets and
across all four pretext tasks and is inversely proportional to amount of
labelled data. Moreover the effect is present whether the pretext task is
carried on the Capture24 dataset or directly in unlabelled data of the target
dataset.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Coupled Gradient Flows for Strategic Non-Local Distribution Shift</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01166</p>
  <p><b>作者</b>：Lauren Conger,  Franca Hoffmann,  Eric Mazumdar,  Lillian Ratliff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distribution shift, framework for analyzing, feedback loop, feedback-induced distribution shift, distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel framework for analyzing the dynamics of distribution shift
in real-world systems that captures the feedback loop between learning
algorithms and the distributions on which they are deployed. Prior work largely
models feedback-induced distribution shift as adversarial or via an overly
simplistic distribution-shift structure. In contrast, we propose a coupled
partial differential equation model that captures fine-grained changes in the
distribution over time by accounting for complex dynamics that arise due to
strategic responses to algorithmic decision-making, non-local endogenous
population interactions, and other exogenous sources of distribution shift. We
consider two common settings in machine learning: cooperative settings with
information asymmetries, and competitive settings where a learner faces
strategic users. For both of these settings, when the algorithm retrains via
gradient descent, we prove asymptotic convergence of the retraining procedure
to a steady-state, both in finite and in infinite dimensions, obtaining
explicit rates in terms of the model parameters. To do so we derive new results
on the convergence of coupled PDEs that extends what is known on multi-species
systems. Empirically, we show that our approach captures well-documented forms
of distribution shifts like polarization and disparate impacts that simpler
models cannot capture.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Improving Language Plasticity via Pretraining with Active Forgetting</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01163</p>
  <p><b>作者</b>：Yihong Chen,  Kelly Marchisio,  Roberta Raileanu,  David Ifeoluwa Adelani,  Pontus Stenetor,  Sebastian Riedel,  Mikel Artetx</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, today the primary, language processing, natural language, primary model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models (PLMs) are today the primary model for natural
language processing. Despite their impressive downstream performance, it can be
difficult to apply PLMs to new languages, a barrier to making their
capabilities universally accessible. While prior work has shown it possible to
address this issue by learning a new embedding layer for the new language,
doing so is both data and compute inefficient. We propose to use an active
forgetting mechanism during pretraining, as a simple way of creating PLMs that
can quickly adapt to new languages. Concretely, by resetting the embedding
layer every K updates during pretraining, we encourage the PLM to improve its
ability of learning new embeddings within a limited number of updates, similar
to a meta-learning effect. Experiments with RoBERTa show that models pretrained
with our forgetting mechanism not only demonstrate faster convergence during
language adaptation but also outperform standard ones in a low-data regime,
particularly for languages that are distant from English.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01158</p>
  <p><b>作者</b>：Ini Oguntola,  Joseph Campbell,  Simon Stepputtis,  Katia Sycara</p>
  <p><b>备注</b>：To appear at ICML 2023 Workshop on Theory of Mind</p>
  <p><b>关键词</b>：human social intelligence, social dynamics induced, offer similar benefits, social intelligence, human social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to model the mental states of others is crucial to human social
intelligence, and can offer similar benefits to artificial agents with respect
to the social dynamics induced in multi-agent settings. We present a method of
grounding semantically meaningful, human-interpretable beliefs within policies
modeled by deep networks. We then consider the task of 2nd-order belief
prediction. We propose that ability of each agent to predict the beliefs of the
other agents can be used as an intrinsic reward signal for multi-agent
reinforcement learning. Finally, we present preliminary empirical results in a
mixed cooperative-competitive environment.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A novel approach for predicting epidemiological forecasting parameters  based on real-time signals and Data Assimilation</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01157</p>
  <p><b>作者</b>：Romain Molinas,  César Quilodrán Casas,  Rossella Arcucci,  Ovidiu Şerban</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Air Quality data, Air Quality, Convolutional Neural Networks, predict epidemiological parameters, media-based population density</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a novel approach to predict epidemiological parameters by
integrating new real-time signals from various sources of information, such as
novel social media-based population density maps and Air Quality data. We
implement an ensemble of Convolutional Neural Networks (CNN) models using
various data sources and fusion methodology to build robust predictions and
simulate several dynamic parameters that could improve the decision-making
process for policymakers. Additionally, we used data assimilation to estimate
the state of our system from fused CNN predictions. The combination of
meteorological signals and social media-based population density maps improved
the performance and flexibility of our prediction of the COVID-19 outbreak in
London. While the proposed approach outperforms standard models, such as
compartmental models traditionally used in disease forecasting (SEIR),
generating robust and consistent predictions allows us to increase the
stability of our model while increasing its accuracy.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：AVSegFormer: Audio-Visual Segmentation with Transformer</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01146</p>
  <p><b>作者</b>：Shengyi Gao,  Zhe Chen,  Guo Chen,  Wenhai Wang,  Tong Lu</p>
  <p><b>备注</b>：9 pages, 7 figures</p>
  <p><b>关键词</b>：multi-modal community, vision has long, topic of interest, AVS, AVS tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The combination of audio and vision has long been a topic of interest in the
multi-modal community. Recently, a new audio-visual segmentation (AVS) task has
been introduced, aiming to locate and segment the sounding objects in a given
video. This task demands audio-driven pixel-level scene understanding for the
first time, posing significant challenges. In this paper, we propose
AVSegFormer, a novel framework for AVS tasks that leverages the transformer
architecture. Specifically, we introduce audio queries and learnable queries
into the transformer decoder, enabling the network to selectively attend to
interested visual features. Besides, we present an audio-visual mixer, which
can dynamically adjust visual features by amplifying relevant and suppressing
irrelevant spatial channels. Additionally, we devise an intermediate mask loss
to enhance the supervision of the decoder, encouraging the network to produce
more accurate intermediate predictions. Extensive experiments demonstrate that
AVSegFormer achieves state-of-the-art results on the AVS benchmark. The code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：SCITUNE: Aligning Large Language Models with Scientific Multimodal  Instructions</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01139</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Sai Munikoti,  Ian Stewart,  Henry Kvinge</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：popular paradigm, paradigm to align, align large language, human intent, align existing foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction finetuning is a popular paradigm to align large language models
(LLM) with human intent. Despite its popularity, this idea is less explored in
improving the LLMs to align existing foundation models with scientific
disciplines, concepts and goals. In this work, we present SciTune as a tuning
framework to improve the ability of LLMs to follow scientific multimodal
instructions. To test our methodology, we use a human-generated scientific
instruction tuning dataset and train a large multimodal model LLaMA-SciTune
that connects a vision encoder and LLM for science-focused visual and language
understanding. In comparison to the models that are finetuned with machine
generated data only, LLaMA-SciTune surpasses human performance on average and
in many sub-categories on the ScienceQA benchmark.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Empirically Validating Conformal Prediction on Modern Vision  Architectures Under Distribution Shift and Long-tailed Data</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01088</p>
  <p><b>作者</b>：Kevin Kasa,  Graham W. Taylor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reliable uncertainty estimates, providing deep learning, deep learning models, deep learning, reliable uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conformal prediction has emerged as a rigorous means of providing deep
learning models with reliable uncertainty estimates and safety guarantees. Yet,
its performance is known to degrade under distribution shift and long-tailed
class distributions, which are often present in real world applications. Here,
we characterize the performance of several post-hoc and training-based
conformal prediction methods under these settings, providing the first
empirical evaluation on large-scale datasets and models. We show that across
numerous conformal methods and neural network families, performance greatly
degrades under distribution shifts violating safety guarantees. Similarly, we
show that in long-tailed settings the guarantees are frequently violated on
many classes. Understanding the limitations of these methods is necessary for
deployment in real world and safety-critical applications.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：When Can Linear Learners be Robust to Indiscriminate Poisoning Attacks?</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01073</p>
  <p><b>作者</b>：Fnu Suya,  Xiao Zhang,  Yuan Tian,  David Evans</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：higher test error, incur higher test, study indiscriminate poisoning, linear learners, indiscriminate poisoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study indiscriminate poisoning for linear learners where an adversary
injects a few crafted examples into the training data with the goal of forcing
the induced model to incur higher test error. Inspired by the observation that
linear learners on some datasets are able to resist the best known attacks even
without any defenses, we further investigate whether datasets can be inherently
robust to indiscriminate poisoning attacks for linear learners. For theoretical
Gaussian distributions, we rigorously characterize the behavior of an optimal
poisoning attack, defined as the poisoning strategy that attains the maximum
risk of the induced model at a given poisoning budget. Our results prove that
linear learners can indeed be robust to indiscriminate poisoning if the
class-wise data distributions are well-separated with low variance and the size
of the constraint set containing all permissible poisoning points is also
small. These findings largely explain the drastic variation in empirical attack
performance of the state-of-the-art poisoning attacks on linear learners across
benchmark datasets, making an important initial step towards understanding the
underlying reasons some learning tasks are vulnerable to data poisoning
attacks.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：ENGAGE: Explanation Guided Data Augmentation for Graph Representation  Learning</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01053</p>
  <p><b>作者</b>：Yucheng Shi,  Kaixiong Zhou,  Ninghao Liu</p>
  <p><b>备注</b>：Accepted by ECML-PKDD 2023</p>
  <p><b>关键词</b>：applied to modeling, recent contrastive learning, data, modeling graph data, widely applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent contrastive learning methods, due to their effectiveness in
representation learning, have been widely applied to modeling graph data.
Random perturbation is widely used to build contrastive views for graph data,
which however, could accidentally break graph structures and lead to suboptimal
performance. In addition, graph data is usually highly abstract, so it is hard
to extract intuitive meanings and design more informed augmentation schemes.
Effective representations should preserve key characteristics in data and
abandon superfluous information. In this paper, we propose ENGAGE (ExplaNation
Guided data AuGmEntation), where explanation guides the contrastive
augmentation process to preserve the key parts in graphs and explore removing
superfluous information. Specifically, we design an efficient unsupervised
explanation method called smoothed activation map as the indicator of node
importance in representation learning. Then, we design two data augmentation
schemes on graphs for perturbing structural and feature information,
respectively. We also provide justification for the proposed method in the
framework of information theories. Experiments of both graph-level and
node-level tasks, on various model architectures and on different real-world
graphs, are conducted to demonstrate the effectiveness and flexibility of
ENGAGE. The code of ENGAGE can be found: this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Temporal Graph Benchmark for Machine Learning on Temporal Graphs</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01026</p>
  <p><b>作者</b>：Shenyang Huang,  Farimah Poursafaei,  Jacob Danovitch,  Matthias Fey,  Weihua Hu,  Emanuele Rossi,  Jure Leskovec,  Michael Bronstein,  Guillaume Rabusseau,  Reihaneh Rabbany</p>
  <p><b>备注</b>：16 pages, 4 figures, 5 tables, preprint</p>
  <p><b>关键词</b>：TGB, collection of challenging, Temporal Graph, TGB datasets, diverse benchmark datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the Temporal Graph Benchmark (TGB), a collection of challenging
and diverse benchmark datasets for realistic, reproducible, and robust
evaluation of machine learning models on temporal graphs. TGB datasets are of
large scale, spanning years in duration, incorporate both node and edge-level
prediction tasks and cover a diverse set of domains including social, trade,
transaction, and transportation networks. For both tasks, we design evaluation
protocols based on realistic use-cases. We extensively benchmark each dataset
and find that the performance of common models can vary drastically across
datasets. In addition, on dynamic node property prediction tasks, we show that
simple methods often achieve superior performance compared to existing temporal
graph models. We believe that these findings open up opportunities for future
research on temporal graphs. Finally, TGB provides an automated machine
learning pipeline for reproducible and accessible temporal graph research,
including data loading, experiment setup and performance evaluation. TGB will
be maintained and updated on a regular basis and welcomes community feedback.
TGB datasets, data loaders, example codes, evaluation setup, and leaderboards
are publicly available at this https URL .</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future  and Past Trends in Time Series Data</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01023</p>
  <p><b>作者</b>：C.Coelho,  M. Fernanda P. Costa,  L.L. Ferrás</p>
  <p><b>备注</b>：Under review at journal</p>
  <p><b>关键词</b>：Ordinary Differential Equations, Chronos Ordinary Differential, Neural Chronos Ordinary, introduces Neural Chronos, Differential Equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work introduces Neural Chronos Ordinary Differential Equations (Neural
CODE), a deep neural network architecture that fits a continuous-time ODE
dynamics for predicting the chronology of a system both forward and backward in
time. To train the model, we solve the ODE as an initial value problem and a
final value problem, similar to Neural ODEs. We also explore two approaches to
combining Neural CODE with Recurrent Neural Networks by replacing Neural ODE
with Neural CODE (CODE-RNN), and incorporating a bidirectional RNN for full
information flow in both time directions (CODE-BiRNN), and variants with other
update cells namely GRU and LSTM: CODE-GRU, CODE-BiGRU, CODE-LSTM, CODE-BiLSTM.
Experimental results demonstrate that Neural CODE outperforms Neural ODE in
learning the dynamics of a spiral forward and backward in time, even with
sparser data. We also compare the performance of CODE-RNN/-GRU/-LSTM and
CODE-BiRNN/-BiGRU/-BiLSTM against ODE-RNN/-GRU/-LSTM on three real-life time
series data tasks: imputation of missing data for lower and higher dimensional
data, and forward and backward extrapolation with shorter and longer time
horizons. Our findings show that the proposed architectures converge faster,
with CODE-BiRNN/-BiGRU/-BiLSTM consistently outperforming the other
architectures on all tasks.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Joint Coordinate Regression and Association For Multi-Person Pose  Estimation, A Pure Neural Network Approach</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01004</p>
  <p><b>作者</b>：Dongyang Yu,  Yunshi Xie,  Wangpeng An,  Li Zhang,  Yufeng Yao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joint Coordinate Regression, human pose joints, Coordinate Regression, Regression and Association, produces human pose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel one-stage end-to-end multi-person 2D pose estimation
algorithm, known as Joint Coordinate Regression and Association (JCRA), that
produces human pose joints and associations without requiring any
post-processing. The proposed algorithm is fast, accurate, effective, and
simple. The one-stage end-to-end network architecture significantly improves
the inference speed of JCRA. Meanwhile, we devised a symmetric network
structure for both the encoder and decoder, which ensures high accuracy in
identifying keypoints. It follows an architecture that directly outputs part
positions via a transformer network, resulting in a significant improvement in
performance. Extensive experiments on the MS COCO and CrowdPose benchmarks
demonstrate that JCRA outperforms state-of-the-art approaches in both accuracy
and efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\% faster at
inference acceleration than previous state-of-the-art bottom-up algorithms. The
code for this algorithm will be publicly available.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：MoVie: Visual Model-Based Policy Adaptation for View Generalization</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00972</p>
  <p><b>作者</b>：Sizhe Yang,  Yanjie Ze,  Huazhe Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Visual Reinforcement Learning, Reinforcement Learning, face significant challenges, limited views face, views face significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual Reinforcement Learning (RL) agents trained on limited views face
significant challenges in generalizing their learned abilities to unseen views.
This inherent difficulty is known as the problem of $\textit{view
generalization}$. In this work, we systematically categorize this fundamental
problem into four distinct and highly challenging scenarios that closely
resemble real-world situations. Subsequently, we propose a straightforward yet
effective approach to enable successful adaptation of visual
$\textbf{Mo}$del-based policies for $\textbf{Vie}$w generalization
($\textbf{MoVie}$) during test time, without any need for explicit reward
signals and any modification during training time. Our method demonstrates
substantial advancements across all four scenarios encompassing a total of
$\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relative
improvement of $\mathbf{33}$%, $\mathbf{86}$%, and $\mathbf{152}$%
respectively. The superior results highlight the immense potential of our
approach for real-world robotics applications. Videos are available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：REAL: A Representative Error-Driven Approach for Active Learning</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00968</p>
  <p><b>作者</b>：Cheng Chen,  Yong Wang,  Lizi Liao,  Yueguo Chen,  Xiaoyong Du</p>
  <p><b>备注</b>：Accepted by ECML/PKDD 2023</p>
  <p><b>关键词</b>：subsequent model training, limited labeling budget, active learning, aims to sample, limited labeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given a limited labeling budget, active learning (AL) aims to sample the most
informative instances from an unlabeled pool to acquire labels for subsequent
model training. To achieve this, AL typically measures the informativeness of
unlabeled instances based on uncertainty and diversity. However, it does not
consider erroneous instances with their neighborhood error density, which have
great potential to improve the model performance. To address this limitation,
we propose $REAL$, a novel approach to select data instances with
$\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive
$\underline{L}$earning. It identifies minority predictions as \emph{pseudo
errors} within a cluster and allocates an adaptive sampling budget for the
cluster based on estimated error density. Extensive experiments on five text
classification datasets demonstrate that $REAL$ consistently outperforms all
best-performing baselines regarding accuracy and F1-macro scores across a wide
range of hyperparameter settings. Our analysis also shows that $REAL$ selects
the most representative pseudo errors that match the distribution of
ground-truth errors along the decision boundary. Our code is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：OpenClinicalAI: An Open and Dynamic Model for Alzheimer's Disease  Diagnosis</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00965</p>
  <p><b>作者</b>：Yunyou Huang,  Xiaoshuang Liang,  Xiangjiang Lu,  Xiuxia Miao,  Jiyue Xie,  Wenjing Liu,  Fan Zhang,  Guoxin Kang,  Li Ma,  Suqin Tang,  Zhifei Zhang,  Jianfeng Zhan</p>
  <p><b>备注</b>：Real-world clinical setting,Alzheimer's disease,diagnose,AI,deep learning. arXiv admin note: text overlap with arXiv:2109.04004</p>
  <p><b>关键词</b>：Alzheimer disease, reversed or cured, significantly reduce, reduce the burden, burden of treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although Alzheimer's disease (AD) cannot be reversed or cured, timely
diagnosis can significantly reduce the burden of treatment and care. Current
research on AD diagnosis models usually regards the diagnosis task as a typical
classification task with two primary assumptions: 1) All target categories are
known a priori; 2) The diagnostic strategy for each patient is consistent, that
is, the number and type of model input data for each patient are the same.
However, real-world clinical settings are open, with complexity and uncertainty
in terms of both subjects and the resources of the medical institutions. This
means that diagnostic models may encounter unseen disease categories and need
to dynamically develop diagnostic strategies based on the subject's specific
circumstances and available medical resources. Thus, the AD diagnosis task is
tangled and coupled with the diagnosis strategy formulation. To promote the
application of diagnostic systems in real-world clinical settings, we propose
OpenClinicalAI for direct AD diagnosis in complex and uncertain clinical
settings. This is the first powerful end-to-end model to dynamically formulate
diagnostic strategies and provide diagnostic results based on the subject's
conditions and available medical resources. OpenClinicalAI combines
reciprocally coupled deep multiaction reinforcement learning (DMARL) for
diagnostic strategy formulation and multicenter meta-learning (MCML) for
open-set recognition. The experimental results show that OpenClinicalAI
achieves better performance and fewer clinical examinations than the
state-of-the-art model. Our method provides an opportunity to embed the AD
diagnostic system into the current health care system to cooperate with
clinicians to improve current health care.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in  Multi-Objective Neural Architecture Search</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00960</p>
  <p><b>作者</b>：Simone Sarti,  Eugenio Lomurno,  Matteo Matteucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning, contemporary society, learning is increasingly, increasingly impacting, impacting various aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is increasingly impacting various aspects of contemporary
society. Artificial neural networks have emerged as the dominant models for
solving an expanding range of tasks. The introduction of Neural Architecture
Search (NAS) techniques, which enable the automatic design of task-optimal
networks, has led to remarkable advances. However, the NAS process is typically
associated with long execution times and significant computational resource
requirements. Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2),
have been developed to mitigate these challenges. While maintaining exceptional
performance and eliminating the need for retraining, they aim to build a single
super-network model capable of directly extracting sub-networks satisfying
different constraints. Neural Architecture Transfer (NAT) was developed to
maximise the effectiveness of extracting sub-networks from a super-network. In
this paper, we present NATv2, an extension of NAT that improves multi-objective
search algorithms applied to dynamic super-network architectures. NATv2
achieves qualitative improvements in the extractable sub-networks by exploiting
the improved super-networks generated by OFAv2 and incorporating new policies
for initialisation, pre-processing and updating its networks archive. In
addition, a post-processing pipeline based on fine-tuning is introduced.
Experimental results show that NATv2 successfully improves NAT and is highly
recommended for investigating high-performance architectures with a minimal
number of parameters.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：OpenAPMax: Abnormal Patterns-based Model for Real-World Alzheimer's  Disease Diagnosis</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00936</p>
  <p><b>作者</b>：Yunyou Huang,  Xianglong Guan,  Xiangjiang Lu,  Xiaoshuang Liang,  Xiuxia Miao,  Jiyue Xie,  Wenjing Liu,  Li Ma,  Suqin Tang,  Zhifei Zhang,  Jianfeng Zhan</p>
  <p><b>备注</b>：Alzheimer's Disease, Abnormal Patterns, Open-set Recognition, OpenAPMax</p>
  <p><b>关键词</b>：significantly benefit patients', benefit patients' medical, patients' medical treatment, treatment and care, open-set recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's disease (AD) cannot be reversed, but early diagnosis will
significantly benefit patients' medical treatment and care. In recent works, AD
diagnosis has the primary assumption that all categories are known a prior -- a
closed-set classification problem, which contrasts with the open-set
recognition problem. This assumption hinders the application of the model in
natural clinical settings. Although many open-set recognition technologies have
been proposed in other fields, they are challenging to use for AD diagnosis
directly since 1) AD is a degenerative disease of the nervous system with
similar symptoms at each stage, and it is difficult to distinguish from its
pre-state, and 2) diversified strategies for AD diagnosis are challenging to
model uniformly. In this work, inspired by the concerns of clinicians during
diagnosis, we propose an open-set recognition model, OpenAPMax, based on the
anomaly pattern to address AD diagnosis in real-world settings. OpenAPMax first
obtains the abnormal pattern of each patient relative to each known category
through statistics or a literature search, clusters the patients' abnormal
pattern, and finally, uses extreme value theory (EVT) to model the distance
between each patient's abnormal pattern and the center of their category and
modify the classification probability. We evaluate the performance of the
proposed method with recent open-set recognition, where we obtain
state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Learning Differentiable Logic Programs for Abstract Visual Reasoning</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00928</p>
  <p><b>作者</b>：Hikaru Shindo,  Viktor Pfanschilling,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：building intelligent agents, problem-solving beyond perception, Visual reasoning, essential for building, building intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual reasoning is essential for building intelligent agents that understand
the world and perform problem-solving beyond perception. Differentiable forward
reasoning has been developed to integrate reasoning with gradient-based machine
learning paradigms. However, due to the memory intensity, most existing
approaches do not bring the best of the expressivity of first-order logic,
excluding a crucial ability to solve abstract visual reasoning, where agents
need to perform reasoning by using analogies on abstract concepts in different
scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg
reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner,
passing messages in a memory-efficient manner and handling structured programs
with functors. Moreover, we propose a computationally-efficient structure
learning algorithm to perform explanatory program induction on complex visual
scenes. To evaluate, in addition to conventional visual reasoning tasks, we
propose a new task, visual reasoning behind-the-scenes, where agents need to
learn abstract programs and then answer queries by imagining scenes that are
not observed. We empirically demonstrate that NEUMANN solves visual reasoning
tasks efficiently, outperforming neural, symbolic, and neuro-symbolic
baselines.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Semi-supervised multi-view concept decomposition</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00924</p>
  <p><b>作者</b>：Qi Jiang,  Guoxu Zhou,  Qibin Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-view concept factorization, demonstrated superior performance, Concept Factorization, concept factorization methods, concept factorization model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept Factorization (CF), as a novel paradigm of representation learning,
has demonstrated superior performance in multi-view clustering tasks. It
overcomes limitations such as the non-negativity constraint imposed by
traditional matrix factorization methods and leverages kernel methods to learn
latent representations that capture the underlying structure of the data,
thereby improving data representation. However, existing multi-view concept
factorization methods fail to consider the limited labeled information inherent
in real-world multi-view data. This often leads to significant performance
loss. To overcome these limitations, we propose a novel semi-supervised
multi-view concept factorization model, named SMVCF. In the SMVCF model, we
first extend the conventional single-view CF to a multi-view version, enabling
more effective exploration of complementary information across multiple views.
We then integrate multi-view CF, label propagation, and manifold learning into
a unified framework to leverage and incorporate valuable information present in
the data. Additionally, an adaptive weight vector is introduced to balance the
importance of different views in the clustering process. We further develop
targeted optimization methods specifically tailored for the SMVCF model.
Finally, we conduct extensive experiments on four diverse datasets with varying
label ratios to evaluate the performance of SMVCF. The experimental results
demonstrate the effectiveness and superiority of our proposed approach in
multi-view clustering tasks.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Achieving Stable Training of Reinforcement Learning Agents in Bimodal  Environments through Batch Learning</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00923</p>
  <p><b>作者</b>：E. Hurwitz,  N. Peace,  G. Cevora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Learning, typical Reinforcement, batch learning, stochastic environments present, Bimodal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bimodal, stochastic environments present a challenge to typical Reinforcement
Learning problems. This problem is one that is surprisingly common in real
world applications, being particularly applicable to pricing problems. In this
paper we present a novel learning approach to the tabular Q-learning algorithm,
tailored to tackling these specific challenges by using batch updates. A
simulation of pricing problem is used as a testbed to compare a typically
updated agent with a batch learning agent. The batch learning agents are shown
to be both more effective than the typically-trained agents, and to be more
resilient to the fluctuations in a large stochastic environment. This work has
a significant potential to enable practical, industrial deployment of
Reinforcement Learning in the context of pricing and others.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Enhancing the Robustness of QMIX against State-adversarial Attacks</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00907</p>
  <p><b>作者</b>：Weiran Guo,  Guanjun Liu,  Ziyuan Zhou,  Ling Wang,  Jiacun Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep reinforcement learning, reinforcement learning, multi-agent reinforcement learning, performance is generally, agent observation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep reinforcement learning (DRL) performance is generally impacted by
state-adversarial attacks, a perturbation applied to an agent's observation.
Most recent research has concentrated on robust single-agent reinforcement
learning (SARL) algorithms against state-adversarial attacks. Still, there has
yet to be much work on robust multi-agent reinforcement learning. Using QMIX,
one of the popular cooperative multi-agent reinforcement algorithms, as an
example, we discuss four techniques to improve the robustness of SARL
algorithms and extend them to multi-agent scenarios. To increase the robustness
of multi-agent reinforcement learning (MARL) algorithms, we train models using
a variety of attacks in this research. We then test the models taught using the
other attacks by subjecting them to the corresponding attacks throughout the
training phase. In this way, we organize and summarize techniques for enhancing
robustness when used with MARL.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Fixing confirmation bias in feature attribution methods via semantic  match</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00897</p>
  <p><b>作者</b>：Giovanni Cinà,  Daniel Fernandez-Llaneza,  Nishant Mishra,  Tabea E. Röber,  Sandro Pezzelle,  Iacer Calixto,  Rob Goedhart,  Ş. İlker Birbil</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black box models, disentangle the complex, black box, Feature attribution methods, staple method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature attribution methods have become a staple method to disentangle the
complex behavior of black box models. Despite their success, some scholars have
argued that such methods suffer from a serious flaw: they do not allow a
reliable interpretation in terms of human concepts. Simply put, visualizing an
array of feature contributions is not enough for humans to conclude something
about a model's internal representations, and confirmation bias can trick users
into false beliefs about model behavior. We argue that a structured approach is
required to test whether our hypotheses on the model are confirmed by the
feature attributions. This is what we call the "semantic match" between human
concepts and (sub-symbolic) explanations. Building on the conceptual framework
put forward in Cinà et al. [2023], we propose a structured approach to
evaluate semantic match in practice. We showcase the procedure in a suite of
experiments spanning tabular and image data, and show how the assessment of
semantic match can give insight into both desirable (e.g., focusing on an
object relevant for prediction) and undesirable model behaviors (e.g., focusing
on a spurious correlation). We couple our experimental results with an analysis
on the metrics to measure semantic match, and argue that this approach
constitutes the first step towards resolving the issue of confirmation bias in
XAI.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Survey on Graph Classification and Link Prediction based on GNN</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00865</p>
  <p><b>作者</b>：Xingyu Liu,  Juan Chen,  Quan Wen</p>
  <p><b>备注</b>：18pages,4figures</p>
  <p><b>关键词</b>：handling Euclidean space, Euclidean space data, real-life scenarios represented, convolutional neural networks, handling Euclidean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional convolutional neural networks are limited to handling Euclidean
space data, overlooking the vast realm of real-life scenarios represented as
graph data, including transportation networks, social networks, and reference
networks. The pivotal step in transferring convolutional neural networks to
graph data analysis and processing lies in the construction of graph
convolutional operators and graph pooling operators. This comprehensive review
article delves into the world of graph convolutional neural networks. Firstly,
it elaborates on the fundamentals of graph convolutional neural networks.
Subsequently, it elucidates the graph neural network models based on attention
mechanisms and autoencoders, summarizing their application in node
classification, graph classification, and link prediction along with the
associated datasets.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Thompson Sampling under Bernoulli Rewards with Local Differential  Privacy</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00863</p>
  <p><b>作者</b>：Bo Jiang,  Tianchi Zhao,  Ming Li</p>
  <p><b>备注</b>：Accepted by ICML 22 workshop</p>
  <p><b>关键词</b>：local differential privacy, multi-armed bandit, MAB, LDP, paper investigates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates the problem of regret minimization for multi-armed
bandit (MAB) problems with local differential privacy (LDP) guarantee. Given a
fixed privacy budget $\epsilon$, we consider three privatizing mechanisms under
Bernoulli scenario: linear, quadratic and exponential mechanisms. Under each
mechanism, we derive stochastic regret bound for Thompson Sampling algorithm.
Finally, we simulate to illustrate the convergence of different mechanisms
under different privacy budgets.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：CardiGraphormer: Unveiling the Power of Self-Supervised Learning in  Revolutionizing Drug Discovery</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00859</p>
  <p><b>作者</b>：Abhijit Gupta,  Arnab Mukherjee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：formidable challenge, Graph Neural Networks, Artificial Intelligence, expansive realm, presents a formidable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the expansive realm of drug discovery, with approximately 15,000 known
drugs and only around 4,200 approved, the combinatorial nature of the chemical
space presents a formidable challenge. While Artificial Intelligence (AI) has
emerged as a powerful ally, traditional AI frameworks face significant hurdles.
This manuscript introduces CardiGraphormer, a groundbreaking approach that
synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and
Cardinality Preserving Attention to revolutionize drug discovery.
CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving
Attention, leverages SSL to learn potent molecular representations and employs
GNNs to extract molecular fingerprints, enhancing predictive performance and
interpretability while reducing computation time. It excels in handling complex
data like molecular structures and performs tasks associated with nodes, pairs
of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential
applications in drug discovery and drug interactions are vast, from identifying
new drug targets to predicting drug-to-drug interactions and enabling novel
drug discovery. This innovative approach provides an AI-enhanced methodology in
drug development, utilizing SSL combined with GNNs to overcome existing
limitations and pave the way for a richer exploration of the vast combinatorial
chemical space in drug discovery.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Surgical fine-tuning for Grape Bunch Segmentation under Visual Domain  Shifts</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00837</p>
  <p><b>作者</b>：Agnese Chiatti,  Riccardo Bertoglio,  Nico Catalano,  Matteo Gatti,  Matteo Matteucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sustainable agriculture, play a crucial, crucial role, transition towards sustainable, Mobile robots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile robots will play a crucial role in the transition towards sustainable
agriculture. To autonomously and effectively monitor the state of plants,
robots ought to be equipped with visual perception capabilities that are robust
to the rapid changes that characterise agricultural settings. In this paper, we
focus on the challenging task of segmenting grape bunches from images collected
by mobile robots in vineyards. In this context, we present the first study that
applies surgical fine-tuning to instance segmentation tasks. We show how
selectively tuning only specific model layers can support the adaptation of
pre-trained Deep Learning models to newly-collected grape images that introduce
visual domain shifts, while also substantially reducing the number of tuned
parameters.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Model-Assisted Probabilistic Safe Adaptive Control With Meta-Bayesian  Learning</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00828</p>
  <p><b>作者</b>：Shengbo Wang,  Ke Li,  Yin Yang,  Yuting Cao,  Tingwen Huang,  Shiping Wen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential risks, resulting in unexpected, catastrophic damage, systems can lead, lead to potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breaking safety constraints in control systems can lead to potential risks,
resulting in unexpected costs or catastrophic damage. Nevertheless, uncertainty
is ubiquitous, even among similar tasks. In this paper, we develop a novel
adaptive safe control framework that integrates meta learning, Bayesian models,
and control barrier function (CBF) method. Specifically, with the help of CBF
method, we learn the inherent and external uncertainties by a unified adaptive
Bayesian linear regression (ABLR) model, which consists of a forward neural
network (NN) and a Bayesian output layer. Meta learning techniques are
leveraged to pre-train the NN weights and priors of the ABLR model using data
collected from historical similar tasks. For a new control task, we refine the
meta-learned models using a few samples, and introduce pessimistic confidence
bounds into CBF constraints to ensure safe control. Moreover, we provide
theoretical criteria to guarantee probabilistic safety during the control
processes. To validate our approach, we conduct comparative experiments in
various obstacle avoidance scenarios. The results demonstrate that our
algorithm significantly improves the Bayesian model-based CBF method, and is
capable for efficient safe exploration even with multiple uncertain
constraints.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Analysis of Task Transferability in Large Pre-trained Classifiers</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00823</p>
  <p><b>作者</b>：Akshay Mehra,  Yunbei Zhang,  Jihun Hamm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Transfer learning transfers, source task, Transfer learning, task, source</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning transfers the knowledge acquired by a model from a source
task to multiple downstream target tasks with minimal fine-tuning. The success
of transfer learning at improving performance, especially with the use of large
pre-trained models has made transfer learning an essential tool in the machine
learning toolbox. However, the conditions under which the performance is
transferable to downstream tasks are not understood very well. In this work, we
analyze the transfer of performance for classification tasks, when only the
last linear layer of the source model is fine-tuned on the target task. We
propose a novel Task Transfer Analysis approach that transforms the source
distribution (and classifier) by changing the class prior distribution, label,
and feature spaces to produce a new source distribution (and classifier) and
allows us to relate the loss of the downstream task (i.e., transferability) to
that of the source task. Concretely, our bound explains transferability in
terms of the Wasserstein distance between the transformed source and downstream
task's distribution, conditional entropy between the label distributions of the
two tasks, and weighted loss of the source classifier on the source task.
Moreover, we propose an optimization problem for learning the transforms of the
source task to minimize the upper bound on transferability. We perform a
large-scale empirical study by using state-of-the-art pre-trained models and
demonstrate the effectiveness of our bound and optimization at predicting
transferability. The results of our experiments demonstrate how factors such as
task relatedness, pretraining method, and model architecture affect
transferability.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：GA-DRL: Graph Neural Network-Augmented Deep Reinforcement Learning for  DAG Task Scheduling over Dynamic Vehicular Clouds</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00777</p>
  <p><b>作者</b>：Zhang Liu,  Lianfen Huang,  Zhibin Gao,  Manman Luo,  Seyyedali Hosseinalipour,  Huaiyu Dai</p>
  <p><b>备注</b>：15 pages, 12 figures, regular journal</p>
  <p><b>关键词</b>：DAG task, DAG, Vehicular clouds, modern platforms, platforms for processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vehicular clouds (VCs) are modern platforms for processing of
computation-intensive tasks over vehicles. Such tasks are often represented as
directed acyclic graphs (DAGs) consisting of interdependent vertices/subtasks
and directed edges. In this paper, we propose a graph neural network-augmented
deep reinforcement learning scheme (GA-DRL) for scheduling DAG tasks over
dynamic VCs. In doing so, we first model the VC-assisted DAG task scheduling as
a Markov decision process. We then adopt a multi-head graph attention network
(GAT) to extract the features of DAG subtasks. Our developed GAT enables a
two-way aggregation of the topological information in a DAG task by
simultaneously considering predecessors and successors of each subtask. We
further introduce non-uniform DAG neighborhood sampling through codifying the
scheduling priority of different subtasks, which makes our developed GAT
generalizable to completely unseen DAG task topologies. Finally, we augment GAT
into a double deep Q-network learning module to conduct subtask-to-vehicle
assignment according to the extracted features of subtasks, while considering
the dynamics and heterogeneity of the vehicles in VCs. Through simulating
various DAG tasks under real-world movement traces of vehicles, we demonstrate
that GA-DRL outperforms existing benchmarks in terms of DAG task completion
time.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Hierarchical Open-vocabulary Universal Image Segmentation</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00764</p>
  <p><b>作者</b>：Xudong Wang,  Shufan Li,  Konstantinos Kallidromitis,  Yusuke Kato,  Kazuki Kozuka,  Trevor Darrell</p>
  <p><b>备注</b>：Project web-page: this http URL</p>
  <p><b>关键词</b>：arbitrary text descriptions, text descriptions, aims to partition, arbitrary text, image segmentation aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-vocabulary image segmentation aims to partition an image into semantic
regions according to arbitrary text descriptions. However, complex visual
scenes can be naturally decomposed into simpler parts and abstracted at
multiple levels of granularity, introducing inherent segmentation ambiguity.
Unlike existing methods that typically sidestep this ambiguity and treat it as
an external factor, our approach actively incorporates a hierarchical
representation encompassing different semantic-levels into the learning
process. We propose a decoupled text-image fusion mechanism and representation
learning modules for both "things" and "stuff".1 Additionally, we
systematically examine the differences that exist in the textual and visual
features between these types of categories. Our resulting model, named HIPIE,
tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within
a unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO,
Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the
state-of-the-art results at various levels of image comprehension, including
semantic-level (e.g., semantic segmentation), instance-level (e.g.,
panoptic/referring segmentation and object detection), as well as part-level
(e.g., part/subpart segmentation) tasks. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Graph-level Anomaly Detection via Hierarchical Memory Networks</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00755</p>
  <p><b>作者</b>：Chaoxi Niu,  Guansong Pang,  Ling Chen</p>
  <p><b>备注</b>：Accepted to ECML-PKDD 2023</p>
  <p><b>关键词</b>：exhibit deviant structures, node attributes compared, anomaly detection aims, identify abnormal graphs, detection aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-level anomaly detection aims to identify abnormal graphs that exhibit
deviant structures and node attributes compared to the majority in a graph set.
One primary challenge is to learn normal patterns manifested in both
fine-grained and holistic views of graphs for identifying graphs that are
abnormal in part or in whole. To tackle this challenge, we propose a novel
approach called Hierarchical Memory Networks (HimNet), which learns
hierarchical memory modules -- node and graph memory modules -- via a graph
autoencoder network architecture. The node-level memory module is trained to
model fine-grained, internal graph interactions among nodes for detecting
locally abnormal graphs, while the graph-level memory module is dedicated to
the learning of holistic normal patterns for detecting globally abnormal
graphs. The two modules are jointly optimized to detect both locally- and
globally-anomalous graphs. Extensive empirical results on 16 real-world graph
datasets from various domains show that i) HimNet significantly outperforms the
state-of-art methods and ii) it is robust to anomaly contamination. Codes are
available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：ImDiffusion: Imputed Diffusion Models for Multivariate Time Series  Anomaly Detection</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00754</p>
  <p><b>作者</b>：Yuhang Chen,  Chaoyun Zhang,  Minghua Ma,  Yudong Liu,  Ruomeng Ding,  Bowen Li,  Shilin He,  Saravan Rajmohan,  Qingwei Lin,  Dongmei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, Anomaly detection, multivariate time series, diverse domains, paramount importance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection in multivariate time series data is of paramount importance
for ensuring the efficient operation of large-scale systems across diverse
domains. However, accurately detecting anomalies in such data poses significant
challenges. Existing approaches, including forecasting and reconstruction-based
methods, struggle to address these challenges effectively. To overcome these
limitations, we propose a novel anomaly detection framework named ImDiffusion,
which combines time series imputation and diffusion models to achieve accurate
and robust anomaly detection. The imputation-based approach employed by
ImDiffusion leverages the information from neighboring values in the time
series, enabling precise modeling of temporal and inter-correlated
dependencies, reducing uncertainty in the data, thereby enhancing the
robustness of the anomaly detection process. ImDiffusion further leverages
diffusion models as time series imputers to accurately capturing complex
dependencies. We leverage the step-by-step denoised outputs generated during
the inference process to serve as valuable signals for anomaly prediction,
resulting in improved accuracy and robustness of the detection process.
We evaluate the performance of ImDiffusion via extensive experiments on
benchmark datasets. The results demonstrate that our proposed framework
significantly outperforms state-of-the-art approaches in terms of detection
accuracy and timeliness. ImDiffusion is further integrated into the real
production system in Microsoft and observe a remarkable 11.4% increase in
detection F1 score compared to the legacy approach. To the best of our
knowledge, ImDiffusion represents a pioneering approach that combines
imputation-based techniques with time series anomaly detection, while
introducing the novel use of diffusion models to the field.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Population Age Group Sensitivity for COVID-19 Infections with Deep  Learning</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00751</p>
  <p><b>作者</b>：Md Khairul Islam,  Tyler Valentine,  Royal Wang,  Levi Davis,  Matt Manner,  Judy Fox</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：healthcare systems worldwide, created unprecedented challenges, Modified Morris Method, Temporal Fusion Transformer, age groups</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The COVID-19 pandemic has created unprecedented challenges for governments
and healthcare systems worldwide, highlighting the critical importance of
understanding the factors that contribute to virus transmission. This study
aimed to identify the most influential age groups in COVID-19 infection rates
at the US county level using the Modified Morris Method and deep learning for
time series. Our approach involved training the state-of-the-art time-series
model Temporal Fusion Transformer on different age groups as a static feature
and the population vaccination status as the dynamic feature. We analyzed the
impact of those age groups on COVID-19 infection rates by perturbing individual
input features and ranked them based on their Morris sensitivity scores, which
quantify their contribution to COVID-19 transmission rates. The findings are
verified using ground truth data from the CDC and US Census, which provide the
true infection rates for each age group. The results suggest that young adults
were the most influential age group in COVID-19 transmission at the county
level between March 1, 2020, and November 27, 2021. Using these results can
inform public health policies and interventions, such as targeted vaccination
strategies, to better control the spread of the virus. Our approach
demonstrates the utility of feature sensitivity analysis in identifying
critical factors contributing to COVID-19 transmission and can be applied in
other public health domains.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：UnLoc: A Universal Localization Method for Autonomous Vehicles using  LiDAR, Radar and/or Camera Input</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00741</p>
  <p><b>作者</b>：Muhammad Ibrahim,  Naveed Akhtar,  Saeed Anwar,  Ajmal Mian</p>
  <p><b>备注</b>：UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input has been accepted for publication in the Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</p>
  <p><b>关键词</b>：autonomous navigation, fundamental task, task in robotics, robotics for autonomous, Localization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Localization is a fundamental task in robotics for autonomous navigation.
Existing localization methods rely on a single input data modality or train
several computational models to process different modalities. This leads to
stringent computational requirements and sub-optimal results that fail to
capitalize on the complementary information in other data streams. This paper
proposes UnLoc, a novel unified neural modeling approach for localization with
multi-sensor input in all weather conditions. Our multi-stream network can
handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can
work with one or more input sensors, making it robust to sensor failure. UnLoc
uses 3D sparse convolutions and cylindrical partitioning of the space to
process LiDAR frames and implements ResNet blocks with a slot attention-based
feature filtering module for the Radar and image modalities. We introduce a
unique learnable modality encoding scheme to distinguish between the input
sensor data. Our method is extensively evaluated on Oxford Radar RobotCar,
ApolloSouthBay and Perth-WA datasets. The results ascertain the efficacy of our
technique.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Neural Polytopes</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00721</p>
  <p><b>作者</b>：Koji Hashimoto,  Tomoya Naito,  Hisashi Naito</p>
  <p><b>备注</b>：5 pages, 9 figures. Accepted at the 1st Workshop on the Synergy of Scientific and Machine Learning Modeling at International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023</p>
  <p><b>关键词</b>：ReLU activation generate, simple neural networks, activation generate polytopes, find that simple, unit sphere</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We find that simple neural networks with ReLU activation generate polytopes
as an approximation of a unit sphere in various dimensions. The species of
polytopes are regulated by the network architecture, such as the number of
units and layers. For a variety of activation functions, generalization of
polytopes is obtained, which we call neural polytopes. They are a smooth
analogue of polytopes, exhibiting geometric duality. This finding initiates
research of discrete geometry via machine learning and also a visualization of
trained networks.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Worth of knowledge in deep learning</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00712</p>
  <p><b>作者</b>：Hao Xu,  Yuntian Chen,  Dongxiao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constitutes the accumulated, experience that humans, gain insight, Knowledge, prior knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge constitutes the accumulated understanding and experience that
humans use to gain insight into the world. In deep learning, prior knowledge is
essential for mitigating shortcomings of data-driven models, such as data
dependence, generalization ability, and compliance with constraints. To enable
efficient evaluation of the worth of knowledge, we present a framework inspired
by interpretable machine learning. Through quantitative experiments, we assess
the influence of data volume and estimation range on the worth of knowledge.
Our findings elucidate the complex relationship between data and knowledge,
including dependence, synergistic, and substitution effects. Our model-agnostic
framework can be applied to a variety of common network architectures,
providing a comprehensive understanding of the role of prior knowledge in deep
learning models. It can also be used to improve the performance of informed
machine learning, as well as distinguish improper prior knowledge.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Tools for Verifying Neural Models' Training Data</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00682</p>
  <p><b>作者</b>：Dami Choi,  Yonadav Shavit,  David Duvenaud</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large neural models, capabilities and risks, important that consumers, consumers and regulators, provenance of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is important that consumers and regulators can verify the provenance of
large neural models to evaluate their capabilities and risks. We introduce the
concept of a "Proof-of-Training-Data": any protocol that allows a model trainer
to convince a Verifier of the training data that produced a set of model
weights. Such protocols could verify the amount and kind of data and compute
used to train the model, including whether it was trained on specific harmful
or beneficial data sources. We explore efficient verification strategies for
Proof-of-Training-Data that are compatible with most current large-model
training procedures. These include a method for the model-trainer to verifiably
pre-commit to a random seed used in training, and a method that exploits
models' tendency to temporarily overfit to training data in order to detect
whether a given data-point was included in training. We show experimentally
that our verification procedures can catch a wide variety of attacks, including
all known attacks from the Proof-of-Learning literature.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：CLIMAX: An exploration of Classifier-Based Contrastive Explanations</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00680</p>
  <p><b>作者</b>：Praharsh Nanavati,  Ranjitha Prasad</p>
  <p><b>备注</b>：11 Pages, 8 figures, 2 tables, 2 algorithms</p>
  <p><b>关键词</b>：machine learning models, understandable for humans, model agnostic XAI, evolving area, area that deals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable AI is an evolving area that deals with understanding the decision
making of machine learning models so that these models are more transparent,
accountable, and understandable for humans. In particular, post-hoc
model-agnostic interpretable AI techniques explain the decisions of a black-box
ML model for a single instance locally, without the knowledge of the intrinsic
nature of the ML model. Despite their simplicity and capability in providing
valuable insights, existing approaches fail to deliver consistent and reliable
explanations. Moreover, in the context of black-box classifiers, existing
approaches justify the predicted class, but these methods do not ensure that
the explanation scores strongly differ as compared to those of another class.
In this work we propose a novel post-hoc model agnostic XAI technique that
provides contrastive explanations justifying the classification of a black box
classifier along with a reasoning as to why another class was not predicted.
Our method, which we refer to as CLIMAX which is short for Contrastive
Label-aware Influence-based Model Agnostic XAI, is based on local classifiers .
In order to ensure model fidelity of the explainer, we require the
perturbations to be such that it leads to a class-balanced surrogate dataset.
Towards this, we employ a label-aware surrogate data generation method based on
random oversampling and Gaussian Mixture Model sampling. Further, we propose
influence subsampling in order to retaining effective samples and hence ensure
sample complexity. We show that we achieve better consistency as compared to
baselines such as LIME, BayLIME, and SLIME. We also depict results on textual
and image based datasets, where we generate contrastive explanations for any
black-box classification model where one is able to only query the class
probabilities for an instance of interest.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary  Directed Differential with Normalized Density and Self-Adaption</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00677</p>
  <p><b>作者</b>：Hao Shu</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：popular clustering algorithm, low-density regions, high-density region, arbitrary shape, shape as long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Density-based clustering could be the most popular clustering algorithm since
it can identify clusters of arbitrary shape as long as different (high-density)
clusters are separated by low-density regions. However, the requirement of the
separateness of clusters by low-density regions is not trivial since a
high-density region might have different structures which should be clustered
into different groups. Such a situation demonstrates the main flaw of all
previous density-based clustering algorithms we have known--structures in a
high-density cluster could not be detected. Therefore, this paper aims to
provide a density-based clustering scheme that not only has the ability
previous ones have but could also detect structures in a high-density region
not separated by low-density ones. The algorithm employs secondary directed
differential, hierarchy, normalized density, as well as the self-adaption
coefficient, and thus is called Structure Detecting Cluster by Hierarchical
Secondary Directed Differential with Normalized Density and Self-Adaption,
dubbed by SDC-HSDD-NDSA for short. To illustrate its effectiveness, we run the
algorithm in several data sets. The results verify its validity in structure
detection, robustness over noises, as well as independence of granularities,
and demonstrate that it could outperform previous ones. The Python code of the
paper could be found on this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Pay Attention to the Atlas: Atlas-Guided Test-Time Adaptation Method for  Robust 3D Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00676</p>
  <p><b>作者</b>：Jingjie Guo,  Weitong Zhang,  Matthew Sinclair,  Daniel Rueckert,  Chen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical imaging applications, Convolutional neural networks, imaging appearances, source training data, imaging applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) often suffer from poor performance when
tested on target data that differs from the training (source) data
distribution, particularly in medical imaging applications where variations in
imaging protocols across different clinical sites and scanners lead to
different imaging appearances. However, re-accessing source training data for
unsupervised domain adaptation or labeling additional test data for model
fine-tuning can be difficult due to privacy issues and high labeling costs,
respectively. To solve this problem, we propose a novel atlas-guided test-time
adaptation (TTA) method for robust 3D medical image segmentation, called
AdaAtlas. AdaAtlas only takes one single unlabeled test sample as input and
adapts the segmentation network by minimizing an atlas-based loss.
Specifically, the network is adapted so that its prediction after registration
is aligned with the learned atlas in the atlas space, which helps to reduce
anatomical segmentation errors at test time. In addition, different from most
existing TTA methods which restrict the adaptation to batch normalization
blocks in the segmentation network only, we further exploit the use of channel
and spatial attention blocks for improved adaptability at test time. Extensive
experiments on multiple datasets from different sites show that AdaAtlas with
attention blocks adapted (AdaAtlas-Attention) achieves superior performance
improvements, greatly outperforming other competitive TTA methods.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Automatic MILP Solver Configuration By Learning Problem Similarities</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00670</p>
  <p><b>作者</b>：Abdelrahman Hosny,  Sherief Reda</p>
  <p><b>备注</b>：To appear in Annals of Operations Research (ANOR)</p>
  <p><b>关键词</b>：formulated as Mixed, Integer Linear Programs, Linear Programs, configuration parameters, configuration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A large number of real-world optimization problems can be formulated as Mixed
Integer Linear Programs (MILP). MILP solvers expose numerous configuration
parameters to control their internal algorithms. Solutions, and their
associated costs or runtimes, are significantly affected by the choice of the
configuration parameters, even when problem instances have the same number of
decision variables and constraints. On one hand, using the default solver
configuration leads to suboptimal solutions. On the other hand, searching and
evaluating a large number of configurations for every problem instance is
time-consuming and, in some cases, infeasible. In this study, we aim to predict
configuration parameters for unseen problem instances that yield lower-cost
solutions without the time overhead of searching-and-evaluating configurations
at the solving time. Toward that goal, we first investigate the cost
correlation of MILP problem instances that come from the same distribution when
solved using different configurations. We show that instances that have similar
costs using one solver configuration also have similar costs using another
solver configuration in the same runtime environment. After that, we present a
methodology based on Deep Metric Learning to learn MILP similarities that
correlate with their final solutions' costs. At inference time, given a new
problem instance, it is first projected into the learned metric space using the
trained model, and configuration parameters are instantly predicted using
previously-explored configurations from the nearest neighbor instance in the
learned embedding space. Empirical results on real-world problem benchmarks
show that our method predicts configuration parameters that improve solutions'
costs by up to 38% compared to existing approaches.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Active Sensing with Predictive Coding and Uncertainty Minimization</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00668</p>
  <p><b>作者</b>：Abdelrahman Sharafeldin,  Nabil Imam,  Hannah Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：biologically inspired computations, embodied exploration based, inspired computations, predictive coding, uncertainty minimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an end-to-end procedure for embodied exploration based on two
biologically inspired computations: predictive coding and uncertainty
minimization. The procedure can be applied to any exploration setting in a
task-independent and intrinsically driven manner. We first demonstrate our
approach in a maze navigation task and show that our model is capable of
discovering the underlying transition distribution and reconstructing the
spatial features of the environment. Second, we apply our model to the more
complex task of active vision, where an agent must actively sample its visual
environment to gather information. We show that our model is able to build
unsupervised representations that allow it to actively sample and efficiently
categorize sensory scenes. We further show that using these representations as
input for downstream classification leads to superior data efficiency and
learning speed compared to other baselines, while also maintaining lower
parameter complexity. Finally, the modularity of our model allows us to analyze
its internal mechanisms and to draw insight into the interactions between
perception and action during exploratory behavior.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Numerical Association Rule Mining: A Systematic Literature Review</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00662</p>
  <p><b>作者</b>：Minakshi Kaushik,  Rahul Sharma,  Iztok Fister Jr.,  Dirk Draheim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：association rule mining, Numerical association rule, association rule, rule mining, Numerical association</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerical association rule mining is a widely used variant of the association
rule mining technique, and it has been extensively used in discovering patterns
and relationships in numerical data. Initially, researchers and scientists
integrated numerical attributes in association rule mining using various
discretization approaches; however, over time, a plethora of alternative
methods have emerged in this field. Unfortunately, the increase of alternative
methods has resulted into a significant knowledge gap in understanding diverse
techniques employed in numerical association rule mining -- this paper attempts
to bridge this knowledge gap by conducting a comprehensive systematic
literature review. We provide an in-depth study of diverse methods, algorithms,
metrics, and datasets derived from 1,140 scholarly articles published from the
inception of numerical association rule mining in the year 1996 to 2022. In
compliance with the inclusion, exclusion, and quality evaluation criteria, 68
papers were chosen to be extensively evaluated. To the best of our knowledge,
this systematic literature review is the first of its kind to provide an
exhaustive analysis of the current literature and previous surveys on numerical
association rule mining. The paper discusses important research issues, the
current status, and future possibilities of numerical association rule mining.
On the basis of this systematic review, the article also presents a novel
discretization measure that contributes by providing a partitioning of
numerical data that meets well human perception of partitions.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Intra- & Extra-Source Exemplar-Based Style Synthesis for Improved Domain  Generalization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00648</p>
  <p><b>作者</b>：Yumeng Li,  Dan Zhang,  Margret Keuper,  Anna Khoreva</p>
  <p><b>备注</b>：An extended version of the accepted WACV paper arXiv:2210.10175</p>
  <p><b>关键词</b>：remaining big challenges, deep learning models, autonomous driving, remaining big, big challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The generalization with respect to domain shifts, as they frequently appear
in applications such as autonomous driving, is one of the remaining big
challenges for deep learning models. Therefore, we propose an exemplar-based
style synthesis pipeline to improve domain generalization in semantic
segmentation. Our method is based on a novel masked noise encoder for StyleGAN2
inversion. The model learns to faithfully reconstruct the image, preserving its
semantic layout through noise prediction. Using the proposed masked noise
encoder to randomize style and content combinations in the training set, i.e.,
intra-source style augmentation (ISSA) effectively increases the diversity of
training data and reduces spurious correlation. As a result, we achieve up to
$12.4\%$ mIoU improvements on driving-scene semantic segmentation under
different types of data shifts, i.e., changing geographic locations, adverse
weather conditions, and day to night. ISSA is model-agnostic and
straightforwardly applicable with CNNs and Transformers. It is also
complementary to other domain generalization techniques, e.g., it improves the
recent state-of-the-art solution RobustNet by $3\%$ mIoU in Cityscapes to Dark
Zürich. In addition, we demonstrate the strong plug-n-play ability of the
proposed style synthesis pipeline, which is readily usable for extra-source
exemplars e.g., web-crawled images, without any retraining or fine-tuning.
Moreover, we study a new use case to indicate neural network's generalization
capability by building a stylized proxy validation set. This application has
significant practical sense for selecting models to be deployed in the
open-world environment. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Multiclass Boosting: Simple and Intuitive Weak Learning Criteria</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00642</p>
  <p><b>作者</b>：Nataly Brukhim,  Amit Daniely,  Yishay Mansour,  Shay Moran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PAC Learning, List PAC Learning, study a generalization, PAC, List PAC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a generalization of boosting to the multiclass setting. We introduce
a weak learning condition for multiclass classification that captures the
original notion of weak learnability as being "slightly better than random
guessing". We give a simple and efficient boosting algorithm, that does not
require realizability assumptions and its sample and oracle complexity bounds
are independent of the number of classes.
In addition, we utilize our new boosting technique in several theoretical
applications within the context of List PAC Learning. First, we establish an
equivalence to weak PAC learning. Furthermore, we present a new result on
boosting for list learners, as well as provide a novel proof for the
characterization of multiclass PAC learning and List PAC learning. Notably, our
technique gives rise to a simplified analysis, and also implies an improved
error bound for large list sizes, compared to previous results.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Effects of Explanation Specificity on Passengers in Autonomous Driving</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00633</p>
  <p><b>作者</b>：Daniel Omeiza,  Raunak Bhattacharyya,  Nick Hawes,  Marina Jirotka,  Lars Kunze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-computer interaction community, interaction community, topic of interest, human-computer interaction, explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The nature of explanations provided by an explainable AI algorithm has been a
topic of interest in the explainable AI and human-computer interaction
community. In this paper, we investigate the effects of natural language
explanations' specificity on passengers in autonomous driving. We extended an
existing data-driven tree-based explainer algorithm by adding a rule-based
option for explanation generation. We generated auditory natural language
explanations with different levels of specificity (abstract and specific) and
tested these explanations in a within-subject user study (N=39) using an
immersive physical driving simulation setup. Our results showed that both
abstract and specific explanations had similar positive effects on passengers'
perceived safety and the feeling of anxiety. However, the specific explanations
influenced the desire of passengers to takeover driving control from the
autonomous vehicle (AV), while the abstract explanations did not. We conclude
that natural language auditory explanations are useful for passengers in
autonomous driving, and their specificity levels could influence how much
in-vehicle participants would wish to be in control of the driving activity.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Bidirectional Looking with A Novel Double Exponential Moving Average to  Adaptive and Non-adaptive Momentum Optimizers</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00631</p>
  <p><b>作者</b>：Yineng Chen,  Zuchao Li,  Lefei Zhang,  Bo Du,  Hai Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：textbf, deep learning, essential component, success of deep, guides the neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimizer is an essential component for the success of deep learning, which
guides the neural network to update the parameters according to the loss on the
training set. SGD and Adam are two classical and effective optimizers on which
researchers have proposed many variants, such as SGDM and RAdam. In this paper,
we innovatively combine the backward-looking and forward-looking aspects of the
optimizer algorithm and propose a novel \textsc{Admeta} (\textbf{A}
\textbf{D}ouble exponential \textbf{M}oving averag\textbf{E} \textbf{T}o
\textbf{A}daptive and non-adaptive momentum) optimizer framework. For
backward-looking part, we propose a DEMA variant scheme, which is motivated by
a metric in the stock market, to replace the common exponential moving average
scheme. While in the forward-looking part, we present a dynamic lookahead
strategy which asymptotically approaches a set value, maintaining its speed at
early stage and high convergence performance at final stage. Based on this
idea, we provide two optimizer implementations, \textsc{AdmetaR} and
\textsc{AdmetaS}, the former based on RAdam and the latter based on SGDM.
Through extensive experiments on diverse tasks, we find that the proposed
\textsc{Admeta} optimizer outperforms our base optimizers and shows advantages
over recently proposed competitive optimizers. We also provide theoretical
proof of these two algorithms, which verifies the convergence of our proposed
\textsc{Admeta}.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Variational Autoencoding Molecular Graphs with Denoising Diffusion  Probabilistic Model</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00623</p>
  <p><b>作者</b>：Daiki Koge,  Naoaki Ono,  Shigehiko Kanaya</p>
  <p><b>备注</b>：2 pages. Short paper submitted to IEEE CIBCB 2023</p>
  <p><b>关键词</b>：data-driven drug discovery, drug discovery, important task, data-driven drug, latent vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In data-driven drug discovery, designing molecular descriptors is a very
important task. Deep generative models such as variational autoencoders (VAEs)
offer a potential solution by designing descriptors as probabilistic latent
vectors derived from molecular structures. These models can be trained on large
datasets, which have only molecular structures, and applied to transfer
learning. Nevertheless, the approximate posterior distribution of the latent
vectors of the usual VAE assumes a simple multivariate Gaussian distribution
with zero covariance, which may limit the performance of representing the
latent features. To overcome this limitation, we propose a novel molecular deep
generative model that incorporates a hierarchical structure into the
probabilistic latent vectors. We achieve this by a denoising diffusion
probabilistic model (DDPM). We demonstrate that our model can design effective
molecular latent vectors for molecular property prediction from some
experiments by small datasets on physical properties and activity. The results
highlight the superior prediction performance and robustness of our model
compared to existing approaches.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Solving Linear Inverse Problems Provably via Posterior Sampling with  Latent Diffusion Models</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00619</p>
  <p><b>作者</b>：Litu Rout,  Negin Raoof,  Giannis Daras,  Constantine Caramanis,  Alexandros G. Dimakis,  Sanjay Shakkottai</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：leveraging pre-trained latent, pre-trained latent diffusion, solve linear inverse, inverse problems leveraging, problems leveraging pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the first framework to solve linear inverse problems leveraging
pre-trained latent diffusion models. Previously proposed algorithms (such as
DPS and DDRM) only apply to pixel-space diffusion models. We theoretically
analyze our algorithm showing provable sample recovery in a linear model
setting. The algorithmic insight obtained from our analysis extends to more
general settings often considered in practice. Experimentally, we outperform
previously proposed posterior sampling algorithms in a wide variety of problems
including random inpainting, block inpainting, denoising, deblurring,
destriping, and super-resolution.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Bounce: a Reliable Bayesian Optimization Algorithm for Combinatorial and  Mixed Spaces</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00618</p>
  <p><b>作者</b>：Leonard Papenmeier,  Luigi Nardi,  Matthias Poloczek</p>
  <p><b>备注</b>：27 pages, 17 figures</p>
  <p><b>关键词</b>：neural architecture search, portfolio optimization require, optimization require optimizing, hardware design, require optimizing high-dimensional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Impactful applications such as materials discovery, hardware design, neural
architecture search, or portfolio optimization require optimizing
high-dimensional black-box functions with mixed and combinatorial input spaces.
While Bayesian optimization has recently made significant progress in solving
such problems, an in-depth analysis reveals that the current state-of-the-art
methods are not reliable. Their performances degrade substantially when the
unknown optima of the function do not have a certain structure. To fill the
need for a reliable algorithm for combinatorial and mixed spaces, this paper
proposes Bounce that relies on a novel map of various variable types into
nested embeddings of increasing dimensionality. Comprehensive experiments show
that Bounce reliably achieves and often even improves upon state-of-the-art
performance on a variety of high-dimensional problems.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：The Forward-Forward Algorithm as a feature extractor for skin lesion  classification: A preliminary study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00617</p>
  <p><b>作者</b>：Abel Reyes-Angulo,  Sidike Paheding</p>
  <p><b>备注</b>：This is a camera-ready version of the paper for the LXAI @ ICML'23 workshop</p>
  <p><b>关键词</b>：deadly form, form of cancer, cancer, survival rate, Skin cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin cancer, a deadly form of cancer, exhibits a 23\% survival rate in the
USA with late diagnosis. Early detection can significantly increase the
survival rate, and facilitate timely treatment. Accurate biomedical image
classification is vital in medical analysis, aiding clinicians in disease
diagnosis and treatment. Deep learning (DL) techniques, such as convolutional
neural networks and transformers, have revolutionized clinical decision-making
automation. However, computational cost and hardware constraints limit the
implementation of state-of-the-art DL architectures. In this work, we explore a
new type of neural network that does not need backpropagation (BP), namely the
Forward-Forward Algorithm (FFA), for skin lesion classification. While FFA is
claimed to use very low-power analog hardware, BP still tends to be superior in
terms of classification accuracy. In addition, our experimental results suggest
that the combination of FFA and BP can be a better alternative to achieve a
more accurate prediction.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to  Estimate the Check-Worthiness of Multi-Modal Tweets</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00610</p>
  <p><b>作者</b>：Raphael Frick,  Inna Vogel</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：social media opens, social media, videos and audio, option of sharing, audio files</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The option of sharing images, videos and audio files on social media opens up
new possibilities for distinguishing between false information and fake news on
the Internet. Due to the vast amount of data shared every second on social
media, not all data can be verified by a computer or a human expert. Here, a
check-worthiness analysis can be used as a first step in the fact-checking
pipeline and as a filtering mechanism to improve efficiency. This paper
proposes a novel way of detecting the check-worthiness in multi-modal tweets.
It takes advantage of two classifiers, each trained on a single modality. For
image data, extracting the embedded text with an OCR analysis has shown to
perform best. By combining the two classifiers, the proposed solution was able
to place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297
achieved on the private test set.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：IoT-Based Air Quality Monitoring System with Machine Learning for  Accurate and Real-time Data Analysis</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00580</p>
  <p><b>作者</b>：Hemanth Karnati</p>
  <p><b>备注</b>：18 pages, 10 figures</p>
  <p><b>关键词</b>：Air Pollution Monitoring, Air pollution, Pollution Monitoring systems, air pollution awareness, predominantly caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Air pollution in urban areas has severe consequences for both human health
and the environment, predominantly caused by exhaust emissions from vehicles.
To address the issue of air pollution awareness, Air Pollution Monitoring
systems are used to measure the concentration of gases like CO2, smoke,
alcohol, benzene, and NH3 present in the air. However, current mobile
applications are unable to provide users with real-time data specific to their
location. In this paper, we propose the development of a portable air quality
detection device that can be used anywhere. The data collected will be stored
and visualized using the cloud-based web app ThinkSpeak.
The device utilizes two sensors, MQ135 and MQ3, to detect harmful gases and
measure air quality in parts per million (PPM). Additionally, machine learning
analysis will be employed on the collected data.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Conditionally Invariant Representation Learning for Disentangling  Cellular Heterogeneity</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00558</p>
  <p><b>作者</b>：Hananeh Aliee,  Ferdinand Kapl,  Soroor Hediyeh-Zadeh,  Fabian J. Theis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leverages domain variability, unwanted variability, paper presents, learn representations, invariant latent features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach that leverages domain variability to
learn representations that are conditionally invariant to unwanted variability
or distractors. Our approach identifies both spurious and invariant latent
features necessary for achieving accurate reconstruction by placing distinct
conditional priors on latent features. The invariant signals are disentangled
from noise by enforcing independence which facilitates the construction of an
interpretable model with a causal semantic. By exploiting the interplay between
data domains and labels, our method simultaneously identifies invariant
features and builds invariant predictors. We apply our method to grand
biological challenges, such as data integration in single-cell genomics with
the aim of capturing biological variations across datasets with many samples,
obtained from different conditions or multiple laboratories. Our approach
allows for the incorporation of specific biological mechanisms, including gene
programs, disease states, or treatment conditions into the data integration
process, bridging the gap between the theoretical assumptions and real
biological applications. Specifically, the proposed approach helps to
disentangle biological signals from data biases that are unrelated to the
target task or the causal explanation of interest. Through extensive
benchmarking using large-scale human hematopoiesis and human lung cancer data,
we validate the superiority of our approach over existing methods and
demonstrate that it can empower deeper insights into cellular heterogeneity and
the identification of disease cell states.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Partial-label Learning with Mixed Closed-set and Open-set  Out-of-candidate Examples</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00553</p>
  <p><b>作者</b>：Shuo He,  Lei Feng,  Guowu Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：candidate label set, label set OOC, label set, OOC, true label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Partial-label learning (PLL) relies on a key assumption that the true label
of each training example must be in the candidate label set. This restrictive
assumption may be violated in complex real-world scenarios, and thus the true
label of some collected examples could be unexpectedly outside the assigned
candidate label set. In this paper, we term the examples whose true label is
outside the candidate label set OOC (out-of-candidate) examples, and pioneer a
new PLL study to learn with OOC examples. We consider two types of OOC examples
in reality, i.e., the closed-set/open-set OOC examples whose true label is
inside/outside the known label space. To solve this new PLL problem, we first
calculate the wooden cross-entropy loss from candidate and non-candidate labels
respectively, and dynamically differentiate the two types of OOC examples based
on specially designed criteria. Then, for closed-set OOC examples, we conduct
reversed label disambiguation in the non-candidate label set; for open-set OOC
examples, we leverage them for training by utilizing an effective
regularization strategy that dynamically assigns random candidate labels from
the candidate label set. In this way, the two types of OOC examples can be
differentiated and further leveraged for model training. Extensive experiments
demonstrate that our proposed method outperforms state-of-the-art PLL methods.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Adaptive reinforcement learning of multi-agent ethically-aligned  behaviours: the QSOM and QDSOM algorithms</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00552</p>
  <p><b>作者</b>：Rémy Chaput,  Olivier Boissier,  Mathieu Guillermin</p>
  <p><b>备注</b>：30 pages, 7 figures, 7 tables</p>
  <p><b>关键词</b>：deployed Artificial Intelligence, numerous deployed Artificial, Artificial Intelligence systems, Artificial Intelligence, deployed Artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The numerous deployed Artificial Intelligence systems need to be aligned with
our ethical considerations. However, such ethical considerations might change
as time passes: our society is not fixed, and our social mores evolve. This
makes it difficult for these AI systems; in the Machine Ethics field
especially, it has remained an under-studied challenge. In this paper, we
present two algorithms, named QSOM and QDSOM, which are able to adapt to
changes in the environment, and especially in the reward function, which
represents the ethical considerations that we want these systems to be aligned
with. They associate the well-known Q-Table to (Dynamic) Self-Organizing Maps
to handle the continuous and multi-dimensional state and action spaces. We
evaluate them on a use-case of multi-agent energy repartition within a small
Smart Grid neighborhood, and prove their ability to adapt, and their higher
performance compared to baseline Reinforcement Learning algorithms.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Is Risk-Sensitive Reinforcement Learning Properly Resolved?</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00547</p>
  <p><b>作者</b>：Ruiwen Zhou,  Minghuan Liu,  Kan Ren,  Xufang Luo,  Weinan Zhang,  Dongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important direction, learning applicable policies, risk measures, reinforcement learning, RSRL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the nature of risk management in learning applicable policies,
risk-sensitive reinforcement learning (RSRL) has been realized as an important
direction. RSRL is usually achieved by learning risk-sensitive objectives
characterized by various risk measures, under the framework of distributional
reinforcement learning. However, it remains unclear if the distributional
Bellman operator properly optimizes the RSRL objective in the sense of risk
measures. In this paper, we prove that the existing RSRL methods do not achieve
unbiased optimization and can not guarantee optimality or even improvements
regarding risk measures over accumulated return distributions. To remedy this
issue, we further propose a novel algorithm, namely Trajectory Q-Learning
(TQL), for RSRL problems with provable convergence to the optimal policy. Based
on our new learning architecture, we are free to introduce a general and
practical implementation for different risk measures to learn disparate
risk-sensitive policies. In the experiments, we verify the learnability of our
algorithm and show how our method effectively achieves better performances
toward risk-sensitive objectives.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Defending Against Malicious Behaviors in Federated Learning with  Blockchain</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00543</p>
  <p><b>作者</b>：Nanqing Dong,  Zhipeng Wang,  Jiahao Sun,  Michael Kampffmeyer,  Yizhe Wen,  Shuoying Zhang,  William Knottenbelt,  Eric Xing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-institutional data owners, compromising data privacy, train machine learning, collaboratively train machine, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of deep learning, federated learning (FL) presents a promising
approach that allows multi-institutional data owners, or clients, to
collaboratively train machine learning models without compromising data
privacy. However, most existing FL approaches rely on a centralized server for
global model aggregation, leading to a single point of failure. This makes the
system vulnerable to malicious attacks when dealing with dishonest clients. In
this work, we address this problem by proposing a secure and reliable FL system
based on blockchain and distributed ledger technology. Our system incorporates
a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are
powered by on-chain smart contracts, to detect and deter malicious behaviors.
Both theoretical and empirical analyses are presented to demonstrate the
effectiveness of the proposed approach, showing that our framework is robust
against malicious client-side behaviors.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Collaborative Policy Learning for Dynamic Scheduling Tasks in  Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00541</p>
  <p><b>作者</b>：Do-Yup Kim,  Da-Eun Lee,  Ji-Wan Kim,  Hyun-Suk Lee</p>
  <p><b>备注</b>：14 pages, 16 figures, IEEEtran.cls</p>
  <p><b>关键词</b>：IoT networks, central policy, policy, undertake a range, range of typical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we examine cloud-edge-terminal IoT networks, where edges
undertake a range of typical dynamic scheduling tasks. In these IoT networks, a
central policy for each task can be constructed at a cloud server. The central
policy can be then used by the edges conducting the task, thereby mitigating
the need for them to learn their own policy from scratch. Furthermore, this
central policy can be collaboratively learned at the cloud server by
aggregating local experiences from the edges, thanks to the hierarchical
architecture of the IoT networks. To this end, we propose a novel collaborative
policy learning framework for dynamic scheduling tasks using federated
reinforcement learning. For effective learning, our framework adaptively
selects the tasks for collaborative learning in each round, taking into account
the need for fairness among tasks. In addition, as a key enabler of the
framework, we propose an edge-agnostic policy structure that enables the
aggregation of local policies from different edges. We then provide the
convergence analysis of the framework. Through simulations, we demonstrate that
our proposed framework significantly outperforms the approaches without
collaborative policy learning. Notably, it accelerates the learning speed of
the policies and allows newly arrived edges to adapt to their tasks more
easily.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Shared Growth of Graph Neural Networks via Free-direction Knowledge  Distillation</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00534</p>
  <p><b>作者</b>：Kaituo Feng,  Yikun Miao,  Changsheng Li,  Ye Yuan,  Guoren Wang</p>
  <p><b>备注</b>：14 pages. arXiv admin note: substantial text overlap with arXiv:2206.06561</p>
  <p><b>关键词</b>：graph neural networks, Knowledge, Free-direction Knowledge Distillation, Knowledge distillation, knowledge transfer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation (KD) has shown to be effective to boost the
performance of graph neural networks (GNNs), where the typical objective is to
distill knowledge from a deeper teacher GNN into a shallower student GNN.
However, it is often quite challenging to train a satisfactory deeper GNN due
to the well-known over-parametrized and over-smoothing issues, leading to
invalid knowledge transfer in practical applications. In this paper, we propose
the first Free-direction Knowledge Distillation framework via reinforcement
learning for GNNs, called FreeKD, which is no longer required to provide a
deeper well-optimized teacher GNN. Our core idea is to collaboratively learn
two shallower GNNs in an effort to exchange knowledge between them via
reinforcement learning in a hierarchical way. As we observe that one typical
GNN model often exhibits better and worse performances at different nodes
during training, we devise a dynamic and free-direction knowledge transfer
strategy that involves two levels of actions: 1) node-level action determines
the directions of knowledge transfer between the corresponding nodes of two
networks; and then 2) structure-level action determines which of the local
structures generated by the node-level actions to be propagated. Furthermore,
considering the diverse knowledge present in different GNNs when dealing with
multi-view inputs, we introduce FreeKD++ as a solution to enable free-direction
knowledge transfer among multiple shallow GNNs operating on multi-view inputs.
Extensive experiments on five benchmark datasets demonstrate our approaches
outperform the base GNNs in a large margin, and shows their efficacy to various
GNNs. More surprisingly, our FreeKD has comparable or even better performance
than traditional KD algorithms that distill knowledge from a deeper and
stronger teacher GNN.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：New intelligent defense systems to reduce the risks of Selfish Mining  and Double-Spending attacks using Learning Automata</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00529</p>
  <p><b>作者</b>：Seyed Ardalan Ghoreishi,  Mohammad Reza Meybodi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：blockchain-based digital currencies, selfish mining attacks, selfish mining, address the critical, critical challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we address the critical challenges of double-spending and
selfish mining attacks in blockchain-based digital currencies. Double-spending
is a problem where the same tender is spent multiple times during a digital
currency transaction, while selfish mining is an intentional alteration of a
blockchain to increase rewards to one miner or a group of miners. We introduce
a new attack that combines both these attacks and propose a machine
learning-based solution to mitigate the risks associated with them.
Specifically, we use the learning automaton, a powerful online learning method,
to develop two models, namely the SDTLA and WVBM, which can effectively defend
against selfish mining attacks. Our experimental results show that the SDTLA
method increases the profitability threshold of selfish mining up to 47$\%$,
while the WVBM method performs even better and is very close to the ideal
situation where each miner's revenue is proportional to their shared hash
processing power. Additionally, we demonstrate that both methods can
effectively reduce the risks of double-spending by tuning the $Z$ Parameter.
Our findings highlight the potential of SDTLA and WVBM as promising solutions
for enhancing the security and efficiency of blockchain networks.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Graph Neural Network based Log Anomaly Detection and Explanation</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00527</p>
  <p><b>作者</b>：Zhong Li,  Jiayang Shi,  Matthijs van Leeuwen</p>
  <p><b>备注</b>：Paper submitted for possible publication</p>
  <p><b>关键词</b>：log anomaly detection, anomaly detection, anomaly detection methods, log anomaly, anomaly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event logs are widely used to record the status of high-tech systems, making
log anomaly detection important for monitoring those systems. Most existing log
anomaly detection methods take a log event count matrix or log event sequences
as input, exploiting quantitative and/or sequential relationships between log
events to detect anomalies. Unfortunately, only considering quantitative or
sequential relationships may result in many false positives and/or false
negatives. To alleviate this problem, we propose a graph-based method for
unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts
event logs into attributed, directed, and weighted graphs, and then leverages
graph neural networks to perform graph-level anomaly detection. Specifically,
we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as
OCDiGCN, a novel graph neural network model for detecting graph-level anomalies
in a collection of attributed, directed, and weighted graphs. By coupling the
graph representation and anomaly detection steps, OCDiGCN can learn a
representation that is especially suited for anomaly detection, resulting in a
high detection accuracy. Importantly, for each identified anomaly, we
additionally provide a small subset of nodes that play a crucial role in
OCDiGCN's prediction as explanations, which can offer valuable cues for
subsequent root cause diagnosis. Experiments on five benchmark datasets show
that Logs2Graphs performs at least on par state-of-the-art log anomaly
detection methods on simple datasets while largely outperforming
state-of-the-art log anomaly detection methods on complicated datasets.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on  the Tensor-Train Decomposition</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00526</p>
  <p><b>作者</b>：Mingxue Xu,  Yao Lei Xu,  Danilo P. Mandic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：underpin Large Language, Large Language Models, complex language patterns, embeddings underpin Large, capture subtle semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-dimensional token embeddings underpin Large Language Models (LLMs), as
they can capture subtle semantic information and significantly enhance the
modelling of complex language patterns. However, the associated high
dimensionality also introduces considerable model parameters, and a
prohibitively high model storage. To address this issue, this work proposes an
approach based on the Tensor-Train Decomposition (TTD), where each token
embedding is treated as a Matrix Product State (MPS) that can be efficiently
computed in a distributed manner. The experimental results on GPT-2 demonstrate
that, through our approach, the embedding layer can be compressed by a factor
of up to 38.40 times, and when the compression factor is 3.31 times, even
produced a better performance than the original GPT-2 model.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00522</p>
  <p><b>作者</b>：Linoy Tsaban (1),  Apolinário Passos (1) ((1) Hugging Face)</p>
  <p><b>备注</b>：8 pages, 5 figures, 1 table. This report builds up on the works introduced in - arXiv:2304.06140, arXiv:2301.12247</p>
  <p><b>关键词</b>：Recent large-scale text-guided, large-scale text-guided diffusion, provide powerful image-generation, text-guided diffusion models, diffusion models provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent large-scale text-guided diffusion models provide powerful
image-generation capabilities. Currently, a significant effort is given to
enable the modification of these images using text only as means to offer
intuitive and versatile editing. However, editing proves to be difficult for
these generative models due to the inherent nature of editing techniques, which
involves preserving certain content from the original image. Conversely, in
text-based models, even minor modifications to the text prompt frequently
result in an entirely distinct result, making attaining one-shot generation
that accurately corresponds to the users intent exceedingly challenging. In
addition, to edit a real image using these state-of-the-art tools, one must
first invert the image into the pre-trained models domain - adding another
factor affecting the edit quality, as well as latency. In this exploratory
report, we propose LEDITS - a combined lightweight approach for real-image
editing, incorporating the Edit Friendly DDPM inversion technique with Semantic
Guidance, thus extending Semantic Guidance to real image editing, while
harnessing the editing capabilities of DDPM inversion as well. This approach
achieves versatile edits, both subtle and extensive as well as alterations in
composition and style, while requiring no optimization nor extensions to the
architecture.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for  Traffic Forecasting</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00518</p>
  <p><b>作者</b>：Binqing Wu,  Ling Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligent transportation systems, transportation systems, temporal, essential to intelligent, intelligent transportation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traffic forecasting is essential to intelligent transportation systems, which
is challenging due to the complicated spatial and temporal dependencies within
a road network. Existing works usually learn spatial and temporal dependencies
separately, ignoring the dependencies crossing spatial and temporal dimensions.
In this paper, we propose DSTCGCN, a dynamic spatial-temporal cross graph
convolution network to learn dynamic spatial and temporal dependencies jointly
via graphs for traffic forecasting. Specifically, we introduce a fast Fourier
transform (FFT) based attentive selector to choose relevant time steps for each
time step based on time-varying traffic data. Given the selected time steps, we
introduce a dynamic cross graph construction module, consisting of the spatial
graph construction, temporal connection graph construction, and fusion modules,
to learn dynamic spatial-temporal cross dependencies without pre-defined
priors. Extensive experiments on six real-world datasets demonstrate that
DSTCGCN achieves the state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：HeGeL: A Novel Dataset for Geo-Location from Hebrew Text</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00509</p>
  <p><b>作者</b>：Tzuf Paz-Argaman,  Tal Bauman,  Itai Mondshine,  Itzhak Omer,  Sagi Dalyot,  Reut Tsarfaty</p>
  <p><b>备注</b>：Accepted for ACL findings 2023</p>
  <p><b>关键词</b>：natural language understanding, retrieving the coordinates, Wikipedia and Twitter, free-form language description, textual geolocation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of textual geolocation - retrieving the coordinates of a place based
on a free-form language description - calls for not only grounding but also
natural language understanding and geospatial reasoning. Even though there are
quite a few datasets in English used for geolocation, they are currently based
on open-source data (Wikipedia and Twitter), where the location of the
described place is mostly implicit, such that the location retrieval resolution
is limited. Furthermore, there are no datasets available for addressing the
problem of textual geolocation in morphologically rich and resource-poor
languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location
(HeGeL) corpus, designed to collect literal place descriptions and analyze
lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place
descriptions of various place types in three cities in Israel. Qualitative and
empirical analysis show that the data exhibits abundant use of geospatial
reasoning and requires a novel environmental representation.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with  Stochastic Configuration Networks</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00507</p>
  <p><b>作者</b>：Wei Dai,  Jiang Liu,  Lanhao Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diagnose faults efficiently, rolling bearings, Fault diagnosis, rotating machinery, great significance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fault diagnosis of rolling bearings is of great significance for
post-maintenance in rotating machinery, but it is a challenging work to
diagnose faults efficiently with a few samples. Additionally, faults commonly
occur with randomness and fuzziness due to the complexity of the external
environment and the structure of rolling bearings, hindering effective mining
of fault characteristics and eventually restricting accuracy of fault
diagnosis. To overcome these problems, stochastic configuration network (SCN)
based cloud ensemble learning, called SCN-CEL, is developed in this work.
Concretely, a cloud feature extraction method is first developed by using a
backward cloud generator of normal cloud model to mine the uncertainty of fault
information. Then, a cloud sampling method, which generates enough cloud
droplets using bidirectional cloud generator, is proposed to extend the cloud
feature samples. Finally, an ensemble model with SCNs is developed to
comprehensively characterize the uncertainty of fault information and advance
the generalization performance of fault diagnosis machine. Experimental results
demonstrate that the proposed method indeed performs favorably for
distinguishing fault categories of rolling bearings in the few shot scenarios.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：On efficient computation in active inference</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00504</p>
  <p><b>作者</b>：Aswin Paul,  Noor Sajid,  Lancelot Da Costa,  Adeel Razi</p>
  <p><b>备注</b>：23 pages, 7 figures. Project repo: this https URL</p>
  <p><b>关键词</b>：complex environments due, inference faces difficulties, simulate intelligent behaviour, target distribution, active inference faces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite being recognized as neurobiologically plausible, active inference
faces difficulties when employed to simulate intelligent behaviour in complex
environments due to its computational cost and the difficulty of specifying an
appropriate target distribution for the agent. This paper introduces two
solutions that work in concert to address these limitations. First, we present
a novel planning algorithm for finite temporal horizons with drastically lower
computational complexity. Second, inspired by Z-learning from control theory
literature, we simplify the process of setting an appropriate target
distribution for new and existing active inference planning schemes. Our first
approach leverages the dynamic programming algorithm, known for its
computational efficiency, to minimize the cost function used in planning
through the Bellman-optimality principle. Accordingly, our algorithm
recursively assesses the expected free energy of actions in the reverse
temporal order. This improves computational efficiency by orders of magnitude
and allows precise model learning and planning, even under uncertain
conditions. Our method simplifies the planning process and shows meaningful
behaviour even when specifying only the agent's final goal state. The proposed
solutions make defining a target distribution from a goal state straightforward
compared to the more complicated task of defining a temporally informed target
distribution. The effectiveness of these methods is tested and demonstrated
through simulations in standard grid-world tasks. These advances create new
opportunities for various applications.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Classifying World War II Era Ciphers with Machine Learning</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00501</p>
  <p><b>作者</b>：Brooke Dalton,  Mark Stamp</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：selected World War, classify selected World, World War, selected World, War II era</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We determine the accuracy with which machine learning and deep learning
techniques can classify selected World War II era ciphers when only ciphertext
is available. The specific ciphers considered are Enigma, M-209, Sigaba,
Purple, and Typex. We experiment with three classic machine learning models,
namely, Support Vector Machines (SVM), $k$-Nearest Neighbors ($k$-NN), and
Random Forest (RF). We also experiment with four deep learning neural
network-based models: Multi-Layer Perceptrons (MLP), Long Short-Term Memory
(LSTM), Extreme Learning Machines (ELM), and Convolutional Neural Networks
(CNN). Each model is trained on features consisting of histograms, digrams, and
raw ciphertext letter sequences. Furthermore, the classification problem is
considered under four distinct scenarios: Fixed plaintext with fixed keys,
random plaintext with fixed keys, fixed plaintext with random keys, and random
plaintext with random keys. Under the most realistic scenario, given 1000
characters per ciphertext, we are able to distinguish the ciphers with greater
than 97% accuracy. In addition, we consider the accuracy of a subset of the
learning techniques as a function of the length of the ciphertext messages.
Somewhat surprisingly, our classic machine learning models perform at least as
well as our deep learning models. We also find that ciphers that are more
similar in design are somewhat more challenging to distinguish, but not as
difficult as might be expected.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Data-Free Quantization via Mixed-Precision Compensation without  Fine-Tuning</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00498</p>
  <p><b>作者</b>：Jun Chen,  Shipeng Bai,  Tianxin Huang,  Mengmeng Wang,  Guanzhong Tian,  Yong Liu</p>
  <p><b>备注</b>：This paper has been accepted for publication in the Pattern Recognition</p>
  <p><b>关键词</b>：Neural network quantization, resulting accuracy highly, accuracy highly depends, Neural network, highly depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network quantization is a very promising solution in the field of
model compression, but its resulting accuracy highly depends on a
training/fine-tuning process and requires the original data. This not only
brings heavy computation and time costs but also is not conducive to privacy
and sensitive information protection. Therefore, a few recent works are
starting to focus on data-free quantization. However, data-free quantization
does not perform well while dealing with ultra-low precision quantization.
Although researchers utilize generative methods of synthetic data to address
this problem partially, data synthesis needs to take a lot of computation and
time. In this paper, we propose a data-free mixed-precision compensation
(DF-MPC) method to recover the performance of an ultra-low precision quantized
model without any data and fine-tuning process. By assuming the quantized error
caused by a low-precision quantized layer can be restored via the
reconstruction of a high-precision quantized layer, we mathematically formulate
the reconstruction loss between the pre-trained full-precision model and its
layer-wise mixed-precision quantized model. Based on our formulation, we
theoretically deduce the closed-form solution by minimizing the reconstruction
loss of the feature maps. Since DF-MPC does not require any original/synthetic
data, it is a more efficient method to approximate the full-precision model.
Experimentally, our DF-MPC is able to achieve higher accuracy for an ultra-low
precision quantized model compared to the recent methods without any data and
fine-tuning process.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Don't Memorize; Mimic The Past: Federated Class Incremental Learning  Without Episodic Memory</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00497</p>
  <p><b>作者</b>：Sara Babakniya,  Zalan Fabian,  Chaoyang He,  Mahdi Soltanolkotabi,  Salman Avestimehr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：forgetting information learned, Deep learning models, information learned, Deep learning, generative model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models are prone to forgetting information learned in the past
when trained on new data. This problem becomes even more pronounced in the
context of federated learning (FL), where data is decentralized and subject to
independent changes for each user. Continual Learning (CL) studies this
so-called \textit{catastrophic forgetting} phenomenon primarily in centralized
settings, where the learner has direct access to the complete training dataset.
However, applying CL techniques to FL is not straightforward due to privacy
concerns and resource limitations. This paper presents a framework for
federated class incremental learning that utilizes a generative model to
synthesize samples from past distributions instead of storing part of past
data. Then, clients can leverage the generative model to mitigate catastrophic
forgetting locally. The generative model is trained on the server using
data-free methods at the end of each task without requesting data from clients.
Therefore, it reduces the risk of data leakage as opposed to training it on the
client's private data. We demonstrate significant improvements for the
CIFAR-100 dataset compared to existing baselines.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural  Networks for Traffic Prediction</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00495</p>
  <p><b>作者</b>：Xunlian Luo,  Chunjiang Zhu,  Detian Zhang,  Qing Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：active research topic, spatial-temporal data mining, data mining, active research, research topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traffic prediction has been an active research topic in the domain of
spatial-temporal data mining. Accurate real-time traffic prediction is
essential to improve the safety, stability, and versatility of smart city
systems, i.e., traffic control and optimal routing. The complex and highly
dynamic spatial-temporal dependencies make effective predictions still face
many challenges. Recent studies have shown that spatial-temporal graph neural
networks exhibit great potential applied to traffic prediction, which combines
sequential models with graph convolutional networks to jointly model temporal
and spatial correlations. However, a survey study of graph learning,
spatial-temporal graph models for traffic, as well as a fair comparison of
baseline models are pending and unavoidable issues. In this paper, we first
provide a systematic review of graph learning strategies and commonly used
graph convolution algorithms. Then we conduct a comprehensive analysis of the
strengths and weaknesses of recently proposed spatial-temporal graph network
models. Furthermore, we build a study called STG4Traffic using the deep
learning framework PyTorch to establish a standardized and scalable benchmark
on two types of traffic datasets. We can evaluate their performance by
personalizing the model settings with uniform metrics. Finally, we point out
some problems in the current study and discuss future directions. Source codes
are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence  Time-Series Forecasting</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00493</p>
  <p><b>作者</b>：Nhat Thanh Tran,  Jack Xin</p>
  <p><b>备注</b>：13 pages (main), 2 pages (appendix), 2 figures</p>
  <p><b>关键词</b>：fast local-global window-based, local-global window-based attention, study a fast, fast local-global, local-global window-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a fast local-global window-based attention method to accelerate
Informer for long sequence time-series forecasting. While window attention is
local and a considerable computational saving, it lacks the ability to capture
global token information which is compensated by a subsequent Fourier transform
block. Our method, named FWin, does not rely on query sparsity hypothesis and
an empirical approximation underlying the ProbSparse attention of Informer.
Through experiments on univariate and multivariate datasets, we show that FWin
transformers improve the overall prediction accuracies of Informer while
accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear
regression model that a learned FWin type attention approaches or even
outperforms softmax full attention based on key vectors extracted from an
Informer model's full attention layer acting on time series data.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Moments, Random Walks, and Limits for Spectrum Approximation</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00474</p>
  <p><b>作者</b>：Yujia Jin,  Christopher Musco,  Aaron Sidford,  Apoorv Vikram Singh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study lower bounds, epsilon, study lower, Omega, dimensional distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study lower bounds for the problem of approximating a one dimensional
distribution given (noisy) measurements of its moments. We show that there are
distributions on $[-1,1]$ that cannot be approximated to accuracy $\epsilon$ in
Wasserstein-1 distance even if we know \emph{all} of their moments to
multiplicative accuracy $(1\pm2^{-\Omega(1/\epsilon)})$; this result matches an
upper bound of Kong and Valiant [Annals of Statistics, 2017]. To obtain our
result, we provide a hard instance involving distributions induced by the
eigenvalue spectra of carefully constructed graph adjacency matrices.
Efficiently approximating such spectra in Wasserstein-1 distance is a
well-studied algorithmic problem, and a recent result of Cohen-Steiner et al.
[KDD 2018] gives a method based on accurately approximating spectral moments
using $2^{O(1/\epsilon)}$ random walks initiated at uniformly random nodes in
the graph.
As a strengthening of our main result, we show that improving the dependence
on $1/\epsilon$ in this result would require a new algorithmic approach.
Specifically, no algorithm can compute an $\epsilon$-accurate approximation to
the spectrum of a normalized graph adjacency matrix with constant probability,
even when given the transcript of $2^{\Omega(1/\epsilon)}$ random walks of
length $2^{\Omega(1/\epsilon)}$ started at random nodes.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Equal Confusion Fairness: Measuring Group-Based Disparities in Automated  Decision Systems</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00472</p>
  <p><b>作者</b>：Furkan Gursoy,  Ioannis A. Kakadiaris</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial intelligence plays, increasingly substantial role, receiving increasing attention, decisions affecting humans, humans and society</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As artificial intelligence plays an increasingly substantial role in
decisions affecting humans and society, the accountability of automated
decision systems has been receiving increasing attention from researchers and
practitioners. Fairness, which is concerned with eliminating unjust treatment
and discrimination against individuals or sensitive groups, is a critical
aspect of accountability. Yet, for evaluating fairness, there is a plethora of
fairness metrics in the literature that employ different perspectives and
assumptions that are often incompatible. This work focuses on group fairness.
Most group fairness metrics desire a parity between selected statistics
computed from confusion matrices belonging to different sensitive groups.
Generalizing this intuition, this paper proposes a new equal confusion fairness
test to check an automated decision system for fairness and a new confusion
parity error to quantify the extent of any unfairness. To further analyze the
source of potential unfairness, an appropriate post hoc analysis methodology is
also presented. The usefulness of the test, metric, and post hoc analysis is
demonstrated via a case study on the controversial case of COMPAS, an automated
decision system employed in the US to assist judges with assessing recidivism
risks. Overall, the methods and metrics provided here may assess automated
decision systems' fairness as part of a more extensive accountability
assessment, such as those based on the system accountability benchmark.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Data-Driven Probabilistic Energy Consumption Estimation for Battery  Electric Vehicles with Model Uncertainty</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00469</p>
  <p><b>作者</b>：Ayan Maity,  Sudeshna Sarkar</p>
  <p><b>备注</b>：This paper is under review at the International Journal of Green Energy</p>
  <p><b>关键词</b>：energy consumption estimation, energy consumption, trip energy consumption, trip-level energy consumption, consumption estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel probabilistic data-driven approach to trip-level
energy consumption estimation of battery electric vehicles (BEVs). As there are
very few electric vehicle (EV) charging stations, EV trip energy consumption
estimation can make EV routing and charging planning easier for drivers. In
this research article, we propose a new driver behaviour-centric EV energy
consumption estimation model using probabilistic neural networks with model
uncertainty. By incorporating model uncertainty into neural networks, we have
created an ensemble of neural networks using Monte Carlo approximation. Our
method comprehensively considers various vehicle dynamics, driver behaviour and
environmental factors to estimate EV energy consumption for a given trip. We
propose relative positive acceleration (RPA), average acceleration and average
deceleration as driver behaviour factors in EV energy consumption estimation
and this paper shows that the use of these driver behaviour features improves
the accuracy of the EV energy consumption model significantly. Instead of
predicting a single-point estimate for EV trip energy consumption, this
proposed method predicts a probability distribution for the EV trip energy
consumption. The experimental results of our approach show that our proposed
probabilistic neural network with weight uncertainty achieves a mean absolute
percentage error of 9.3% and outperforms other existing EV energy consumption
models in terms of accuracy.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：MissDiff: Training Diffusion Models on Tabular Data with Missing Values</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00467</p>
  <p><b>作者</b>：Yidong Ouyang,  Liyan Xie,  Chongxuan Li,  Guang Cheng</p>
  <p><b>备注</b>：22 pages, short version is accepted by ICML workshop on Structured Probabilistic Inference & Generative Modeling 2023</p>
  <p><b>关键词</b>：shown remarkable performance, diffusion model, shown remarkable, remarkable performance, performance in modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The diffusion model has shown remarkable performance in modeling data
distributions and synthesizing data. However, the vanilla diffusion model
requires complete or fully observed data for training. Incomplete data is a
common issue in various real-world applications, including healthcare and
finance, particularly when dealing with tabular datasets. This work presents a
unified and principled diffusion-based framework for learning from data with
missing values under various missing mechanisms. We first observe that the
widely adopted "impute-then-generate" pipeline may lead to a biased learning
objective. Then we propose to mask the regression loss of Denoising Score
Matching in the training phase. We prove the proposed method is consistent in
learning the score of data distributions, and the proposed training objective
serves as an upper bound for the negative likelihood in certain cases. The
proposed framework is evaluated on multiple tabular datasets using realistic
and efficacious metrics and is demonstrated to outperform state-of-the-art
diffusion model on tabular data with "impute-then-generate" pipeline by a large
margin.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Towards Unbiased Exploration in Partial Label Learning</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00465</p>
  <p><b>作者</b>：Zsolt Zombori,  Agapi Rissaki,  Kristóf Szabó,  Wolfgang Gatterbauer,  Michael Benedikt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard neural architectures, partially-labelled supervision, inputs denoted, multiple possibilities, probabilistic classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider learning a probabilistic classifier from partially-labelled
supervision (inputs denoted with multiple possibilities) using standard neural
architectures with a softmax as the final layer. We identify a bias phenomenon
that can arise from the softmax layer in even simple architectures that
prevents proper exploration of alternative options, making the dynamics of
gradient descent overly sensitive to initialisation. We introduce a novel loss
function that allows for unbiased exploration within the space of alternative
outputs. We give a theoretical justification for our loss function, and provide
an extensive evaluation of its impact on synthetic data, on standard partially
labelled benchmarks and on a contributed novel benchmark related to an existing
rule learning challenge.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Conformer LLMs -- Convolution Augmented Large Language Models</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00461</p>
  <p><b>作者</b>：Prateek Verma</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：large language models, blocks of neural, work builds, language models, popular blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work builds together two popular blocks of neural architecture, namely
convolutional layers and Transformers, for large language models (LLMs).
Non-causal conformers are used ubiquitously in automatic speech recognition.
This work aims to adapt these architectures in a causal setup for training
LLMs. Transformers decoders effectively capture long-range dependencies over
several modalities and form a core backbone of modern advancements in machine
learning. Convolutional architectures have been popular in extracting features
in domains such as raw 1-D signals, speech, and images, to name a few. In this
paper, by combining local and global dependencies over latent representations
using causal convolutional filters and Transformer, we achieve significant
gains in performance. This work showcases a robust speech architecture that can
be integrated and adapted in a causal setup beyond speech applications for
large-scale language modeling.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：An Adaptive Optimization Approach to Personalized Financial Incentives  in Mobile Behavioral Weight Loss Interventions</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00444</p>
  <p><b>作者</b>：Qiaomei Li,  Yonatan Mintz,  Kara Gavin,  Corrine Voils</p>
  <p><b>备注</b>：48 pages, 5 figures</p>
  <p><b>关键词</b>：United States, critical healthcare issue, healthcare issue affecting, affecting the United, critical healthcare</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obesity is a critical healthcare issue affecting the United States. The least
risky treatments available for obesity are behavioral interventions meant to
promote diet and exercise. Often these interventions contain a mobile component
that allows interventionists to collect participants level data and provide
participants with incentives and goals to promote long term behavioral change.
Recently, there has been interest in using direct financial incentives to
promote behavior change. However, adherence is challenging in these
interventions, as each participant will react differently to different
incentive structure and amounts, leading researchers to consider personalized
interventions. The key challenge for personalization, is that the clinicians do
not know a priori how best to administer incentives to participants, and given
finite intervention budgets how to disburse costly resources efficiently. In
this paper, we consider this challenge of designing personalized weight loss
interventions that use direct financial incentives to motivate weight loss
while remaining within a budget. We create a machine learning approach that is
able to predict how individuals may react to different incentive schedules
within the context of a behavioral intervention. We use this predictive model
in an adaptive framework that over the course of the intervention computes what
incentives to disburse to participants and remain within the study budget. We
provide both theoretical guarantees for our modeling and optimization
approaches as well as demonstrate their performance in a simulated weight loss
study. Our results highlight the cost efficiency and effectiveness of our
personalized intervention design for weight loss.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：One Copy Is All You Need: Resource-Efficient Streaming of Medical  Imaging Data at Scale</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00438</p>
  <p><b>作者</b>：Pranav Kulkarni,  Adway Kanhere,  Eliot Siegel,  Paul H. Yi,  Vishwa S. Parekh</p>
  <p><b>备注</b>：13 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：clinical decision support, artificial intelligence tools, decision support, accelerated development, development of artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale medical imaging datasets have accelerated development of
artificial intelligence tools for clinical decision support. However, the large
size of these datasets is a bottleneck for users with limited storage and
bandwidth. Many users may not even require such large datasets as AI models are
often trained on lower resolution images. If users could directly download at
their desired resolution, storage and bandwidth requirements would
significantly decrease. However, it is impossible to anticipate every users'
requirements and impractical to store the data at multiple resolutions. What if
we could store images at a single resolution but send them at different ones?
We propose MIST, an open-source framework to operationalize progressive
resolution for streaming medical images at multiple resolutions from a single
high-resolution copy. We demonstrate that MIST can dramatically reduce imaging
infrastructure inefficiencies for hosting and streaming medical images by >90%,
while maintaining diagnostic quality for deep learning applications.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Sparsity aware generalization theory for deep neural networks</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00426</p>
  <p><b>作者</b>：Ramchandran Muthukumar,  Jeremias Sulam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remain poorly understood, Deep artificial neural, neural networks achieve, networks achieve surprising, artificial neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep artificial neural networks achieve surprising generalization abilities
that remain poorly understood. In this paper, we present a new approach to
analyzing generalization for deep feed-forward ReLU networks that takes
advantage of the degree of sparsity that is achieved in the hidden layer
activations. By developing a framework that accounts for this reduced effective
model size for each input sample, we are able to show fundamental trade-offs
between sparsity and generalization. Importantly, our results make no strong
assumptions about the degree of sparsity achieved by the model, and it improves
over recent norm-based approaches. We illustrate our results numerically,
demonstrating non-vacuous bounds when coupled with data-dependent priors in
specific settings, even in over-parametrized models.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：JoinBoost: Grow Trees Over Normalized Data Using Only SQL</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00422</p>
  <p><b>作者</b>：Zezhou Huang,  Rathijit Sen,  Jiaxiang Liu,  Eugene Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：single table, dominant for tabular, tabular data, train tree models, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although dominant for tabular data, ML libraries that train tree models over
normalized databases (e.g., LightGBM, XGBoost) require the data to be
denormalized as a single table, materialized, and exported. This process is not
scalable, slow, and poses security risks. In-DB ML aims to train models within
DBMSes to avoid data movement and provide data governance. Rather than modify a
DBMS to support In-DB ML, is it possible to offer competitive tree training
performance to specialized ML libraries...with only SQL?
We present JoinBoost, a Python library that rewrites tree training algorithms
over normalized databases into pure SQL. It is portable to any DBMS, offers
performance competitive with specialized ML libraries, and scales with the
underlying DBMS capabilities. JoinBoost extends prior work from both
algorithmic and systems perspectives. Algorithmically, we support factorized
gradient boosting, by updating the $Y$ variable to the residual in the
non-materialized join result. Although this view update problem is generally
ambiguous, we identify addition-to-multiplication preserving, the key property
of variance semi-ring to support rmse, the most widely used criterion.
System-wise, we identify residual updates as a performance bottleneck. Such
overhead can be natively minimized on columnar DBMSes by creating a new column
of residual values and adding it as a projection. We validate this with two
implementations on DuckDB, with no or minimal modifications to its internals
for portability. Our experiment shows that JoinBoost is 3x (1.1x) faster for
random forests (gradient boosting) compared to LightGBM, and over an order
magnitude faster than state-of-the-art In-DB ML systems. Further, JoinBoost
scales well beyond LightGBM in terms of the # features, DB size (TPC-DS
SF=1000), and join graph complexity (galaxy schemas).</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Provably Efficient UCB-type Algorithms For Learning Predictive State  Representations</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00405</p>
  <p><b>作者</b>：Ruiquan Huang,  Yingbin Liang,  Jing Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov decision processes, includes Markov decision, sequential decision-making problem, Markov decision, partially observable MDPs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The general sequential decision-making problem, which includes Markov
decision processes (MDPs) and partially observable MDPs (POMDPs) as special
cases, aims at maximizing a cumulative reward by making a sequence of decisions
based on a history of observations and actions over time. Recent studies have
shown that the sequential decision-making problem is statistically learnable if
it admits a low-rank structure modeled by predictive state representations
(PSRs). Despite these advancements, existing approaches typically involve
oracles or steps that are not computationally efficient. On the other hand, the
upper confidence bound (UCB) based approaches, which have served successfully
as computationally efficient methods in bandits and MDPs, have not been
investigated for more general PSRs, due to the difficulty of optimistic bonus
design in these more challenging settings. This paper proposes the first known
UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the
total variation distance between the estimated and true models. We further
characterize the sample complexity bounds for our designed UCB-type algorithms
for both online and offline PSRs. In contrast to existing approaches for PSRs,
our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed
near-optimal policy, and guaranteed model accuracy.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00398</p>
  <p><b>作者</b>：Uddeshya Upadhyay,  Shyamgopal Karthik,  Massimiliano Mancini,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully find correspondences, CLIP successfully find, successfully find, find correspondences, CLIP successfully</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language models (VLMs) like CLIP successfully find
correspondences between images and text. Through the standard deterministic
mapping process, an image or a text sample is mapped to a single vector in the
embedding space. This is problematic: as multiple samples (images or text) can
abstract the same concept in the physical world, deterministic embeddings do
not reflect the inherent ambiguity in the embedding space. We propose ProbVLM,
a probabilistic adapter that estimates probability distributions for the
embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc
manner without needing large-scale datasets or computing. On four challenging
datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the
multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify
the calibration of embedding uncertainties in retrieval tasks and show that
ProbVLM outperforms other methods. Furthermore, we propose active learning and
model selection as two real-world downstream tasks for VLMs and show that the
estimated uncertainty aids both tasks. Lastly, we present a novel technique for
visualizing the embedding distributions using a large-scale pre-trained latent
diffusion model.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00395</p>
  <p><b>作者</b>：Mustafa Munir,  William Avery,  Radu Marculescu</p>
  <p><b>备注</b>：Proceedings of the 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</p>
  <p><b>关键词</b>：convolutional neural networks, dominated computer vision, graph neural networks, neural networks, dominated computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, convolutional neural networks (CNN) and vision transformers
(ViT) have dominated computer vision. However, recently proposed vision graph
neural networks (ViG) provide a new avenue for exploration. Unfortunately, for
mobile applications, ViGs are computationally expensive due to the overhead of
representing images as graph structures. In this work, we propose a new
graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA),
that is designed for ViGs running on mobile devices. Additionally, we propose
the first hybrid CNN-GNN architecture for vision tasks on mobile devices,
MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats
existing ViG models and existing mobile CNN and ViT architectures in terms of
accuracy and/or speed on image classification, object detection, and instance
segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1
accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU
(compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7%
top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model,
MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is
faster and more accurate than the similarly sized EfficientFormer-L3 model
(2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN
architectures can be a new avenue of exploration for designing models that are
extremely fast and accurate on mobile devices. Our code is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular  Data Synthesis</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00384</p>
  <p><b>作者</b>：Abdallah Alshantti,  Damiano Varagnolo,  Adil Rasheed,  Aria Rahmati,  Frank Westad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：drawn considerable attention, Generative adversarial networks, generating synthetic data, synthetic data, synthetic data samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) have drawn considerable attention in
recent years for their proven capability in generating synthetic data which can
be utilized for multiple purposes. While GANs have demonstrated tremendous
successes in producing synthetic data samples that replicate the dynamics of
the original datasets, the validity of the synthetic data and the underlying
privacy concerns represent major challenges which are not sufficiently
addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN)
for generating realistic tabular data with a specific focus on the validity of
the output. In this context, validity refers to the the dependency between
features that can be found in the real data, but is typically misrepresented by
traditional generative models. Our key idea entails that employing a cascaded
architecture in which a dedicated generator samples each feature, the synthetic
output becomes more representative of the real data. Our experimental results
demonstrate that our model well captures the constraints and the correlations
between the features of the real data, especially the high dimensional
datasets. Furthermore, we evaluate the risk of white-box privacy attacks on our
model and subsequently show that applying some perturbations to the auxiliary
learners in CasTGAN increases the overall robustness of our model against
targeted attacks.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Residual-based attention and connection to information bottleneck theory  in PINNs</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00379</p>
  <p><b>作者</b>：Sokratis J. Anagnostopoulos,  Juan Diego Toscano,  Nikolaos Stergiopulos,  George Em Karniadakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：physics-informed neural networks, models and data, recent years, seamless integration, integration of physical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Driven by the need for more efficient and seamless integration of physical
models and data, physics-informed neural networks (PINNs) have seen a surge of
interest in recent years. However, ensuring the reliability of their
convergence and accuracy remains a challenge. In this work, we propose an
efficient, gradient-less weighting scheme for PINNs, that accelerates the
convergence of dynamic or static systems. This simple yet effective attention
mechanism is a function of the evolving cumulative residuals and aims to make
the optimizer aware of problematic regions at no extra computational cost or
adversarial learning. We illustrate that this general method consistently
achieves a relative $L^{2}$ error of the order of $10^{-5}$ using standard
optimizers on typical benchmark cases of the literature. Furthermore, by
investigating the evolution of weights during training, we identify two
distinct learning phases reminiscent of the fitting and diffusion phases
proposed by the information bottleneck (IB) theory. Subsequent gradient
analysis supports this hypothesis by aligning the transition from high to low
signal-to-noise ratio (SNR) with the transition from fitting to diffusion
regimes of the adopted weights. This novel correlation between PINNs and IB
theory could open future possibilities for understanding the underlying
mechanisms behind the training and stability of PINNs and, more broadly, of
neural operators.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Minimizing Energy Consumption of Deep Learning Models by Energy-Aware  Training</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00368</p>
  <p><b>作者</b>：Dario Lazzaro,  Antonio Emanuele Cinà,  Maura Pintor,  Ambra Demontis,  Battista Biggio,  Fabio Roli,  Marcello Pelillo</p>
  <p><b>备注</b>：12 pages, 3 figures. Paper accepted at the 22nd International Conference on Image Analysis and Processing (ICIAP) 2023</p>
  <p><b>关键词</b>：learning models undergo, number of parameters, larger number, number of operations, parameters they possess</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models undergo a significant increase in the number of
parameters they possess, leading to the execution of a larger number of
operations during inference. This expansion significantly contributes to higher
energy consumption and prediction latency. In this work, we propose EAT, a
gradient-based algorithm that aims to reduce energy consumption during model
training. To this end, we leverage a differentiable approximation of the
$\ell_0$ norm, and use it as a sparse penalty over the training loss. Through
our experimental analysis conducted on three datasets and two deep neural
networks, we demonstrate that our energy-aware training algorithm EAT is able
to train networks with a better trade-off between classification performance
and energy efficiency.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Understanding recent deep-learning techniques for identifying collective  variables of molecular dynamics</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00365</p>
  <p><b>作者</b>：Wei Zhang,  Christof Schütte</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：high-dimensional metastable molecular, metastable molecular system, collective variables, complex molecular systems, high-dimensional metastable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The dynamics of a high-dimensional metastable molecular system can often be
characterised by a few features of the system, i.e. collective variables (CVs).
Thanks to the rapid advance in the area of machine learning, various deep
learning-based CV identification techniques have been developed in recent
years, allowing accurate modelling and efficient simulation of complex
molecular systems. In this paper, we look at two different categories of deep
learning-based approaches for finding CVs, either by computing leading
eigenfunctions of infinitesimal generator or transfer operator associated to
the underlying dynamics, or by learning an autoencoder via minimisation of
reconstruction error. We present a concise overview of the mathematics behind
these two approaches and conduct a comparative numerical study of these two
approaches on illustrative examples.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：The future of human-centric eXplainable Artificial Intelligence (XAI) is  not post-hoc explanations</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00364</p>
  <p><b>作者</b>：Vinitra Swamy,  Jibril Frej,  Tanja Käser</p>
  <p><b>备注</b>：Viewpoint paper, under review at JAIR</p>
  <p><b>关键词</b>：Explainable Artificial Intelligence, Artificial Intelligence, enabling human understanding, Explainable Artificial, deep learning systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable Artificial Intelligence (XAI) plays a crucial role in enabling
human understanding and trust in deep learning systems, often defined as
determining which features are most important to a model's prediction. As
models get larger, more ubiquitous, and pervasive in aspects of daily life,
explainability is necessary to avoid or minimize adverse effects of model
mistakes. Unfortunately, current approaches in human-centric XAI (e.g.
predictive tasks in healthcare, education, or personalized ads) tend to rely on
a single explainer. This is a particularly concerning trend when considering
that recent work has identified systematic disagreement in explainability
methods when applied to the same points and underlying black-box models. In
this paper, we therefore present a call for action to address the limitations
of current state-of-the-art explainers. We propose to shift from post-hoc
explainability to designing interpretable neural network architectures; moving
away from approximation techniques in human-centric and high impact
applications. We identify five needs of human-centric XAI (real-time, accurate,
actionable, human-interpretable, and consistent) and propose two schemes for
interpretable-by-design neural network workflows (adaptive routing for
interpretable conditional computation and diagnostic benchmarks for iterative
model learning). We postulate that the future of human-centric XAI is neither
in explaining black-boxes nor in reverting to traditional, interpretable
models, but in neural networks that are intrinsically interpretable.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：A Comparative Study of Machine Learning Algorithms for Anomaly Detection  in Industrial Environments: Performance and Environmental Impact</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00361</p>
  <p><b>作者</b>：Álvaro Huertas-García,  Carlos Martí-González,  Rubén García Maezo,  Alejandro Echeverría Rey</p>
  <p><b>备注</b>：29 references, 8 figures, 9 tables, 18 pages</p>
  <p><b>关键词</b>：high computational requirements, context of Industry, machine learning, machine learning algorithms, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of Industry 4.0, the use of artificial intelligence (AI) and
machine learning for anomaly detection is being hampered by high computational
requirements and associated environmental effects. This study seeks to address
the demands of high-performance machine learning models with environmental
sustainability, contributing to the emerging discourse on 'Green AI.' An
extensive variety of machine learning algorithms, coupled with various
Multilayer Perceptron (MLP) configurations, were meticulously evaluated. Our
investigation encapsulated a comprehensive suite of evaluation metrics,
comprising Accuracy, Area Under the Curve (AUC), Recall, Precision, F1 Score,
Kappa Statistic, Matthews Correlation Coefficient (MCC), and F1 Macro.
Simultaneously, the environmental footprint of these models was gauged through
considerations of time duration, CO2 equivalent, and energy consumption during
the training, cross-validation, and inference phases. Traditional machine
learning algorithms, such as Decision Trees and Random Forests, demonstrate
robust efficiency and performance. However, superior outcomes were obtained
with optimised MLP configurations, albeit with a commensurate increase in
resource consumption. The study incorporated a multi-objective optimisation
approach, invoking Pareto optimality principles, to highlight the trade-offs
between a model's performance and its environmental impact. The insights
derived underscore the imperative of striking a balance between model
performance, complexity, and environmental implications, thus offering valuable
directions for future work in the development of environmentally conscious
machine learning models for industrial applications.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：When Synthetic Data Met Regulation</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00359</p>
  <p><b>作者</b>：Georgi Ganev</p>
  <p><b>备注</b>：Accepted to the 1st Workshop on Generative AI and Law (GenLaw 2023), part of ICML 2023</p>
  <p><b>关键词</b>：produced by Differentially, synthetic data produced, argue that synthetic, Differentially, synthetic data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we argue that synthetic data produced by Differentially
Private generative models can be sufficiently anonymized and, therefore,
anonymous data and regulatory compliant.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00356</p>
  <p><b>作者</b>：Zekai Chen,  Fuyi Wang,  Zhiwei Zheng,  Ximeng Liu,  Yujie Lin</p>
  <p><b>备注</b>：Accepted by IEEE ICME 2023</p>
  <p><b>关键词</b>：train deep learning, enables multiple clients, local datasets' privacy, collaboratively train deep, sensitive local datasets'</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) enables multiple clients to collaboratively train
deep learning models while considering sensitive local datasets' privacy.
However, adversaries can manipulate datasets and upload models by injecting
triggers for federated backdoor attacks (FBA). Existing defense strategies
against FBA consider specific and limited attacker models, and a sufficient
amount of noise to be injected only mitigates rather than eliminates FBA. To
address these deficiencies, we introduce a Flexible Federated Backdoor Defense
Framework (Fedward) to ensure the elimination of adversarial backdoors. We
decompose FBA into various attacks, and design amplified magnitude
sparsification (AmGrad) and adaptive OPTICS clustering (AutoOPTICS) to address
each attack. Meanwhile, Fedward uses the adaptive clipping method by regarding
the number of samples in the benign group as constraints on the boundary. This
ensures that Fedward can maintain the performance for the Non-IID scenario. We
conduct experimental evaluations over three benchmark datasets and thoroughly
compare them to state-of-the-art studies. The results demonstrate the promising
defense performance from Fedward, moderately improved by 33% $\sim$ 75 in
clustering defense methods, and 96.98%, 90.74%, and 89.8% for Non-IID to the
utmost extent for the average FBA success rate over MNIST, FMNIST, and CIFAR10,
respectively.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Recursive Algorithmic Reasoning</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00337</p>
  <p><b>作者</b>：Dulhan Jayalath,  Jonas Jürß,  Petar Veličković</p>
  <p><b>备注</b>：11 pages, 5 figures. Accepted at the workshop on Knowledge and Logical Reasoning in the Era of Data-Driven Learning at ICML 2023</p>
  <p><b>关键词</b>：Learning models, deep learning, execute recursive algorithms, key problem, problem in deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning models that execute algorithms can enable us to address a key
problem in deep learning: generalizing to out-of-distribution data. However,
neural networks are currently unable to execute recursive algorithms because
they do not have arbitrarily large memory to store and recall state. To address
this, we (1) propose a way to augment graph neural networks (GNNs) with a
stack, and (2) develop an approach for capturing intermediate algorithm
trajectories that improves algorithmic alignment with recursive algorithms over
previous methods. The stack allows the network to learn to store and recall a
portion of the state of the network at a particular time, analogous to the
action of a call stack in a recursive algorithm. This augmentation permits the
network to reason recursively. We empirically demonstrate that our proposals
significantly improve generalization to larger input graphs over prior work on
depth-first search (DFS).</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Single Sequence Prediction over Reasoning Graphs for Multi-hop QA</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00335</p>
  <p><b>作者</b>：Gowtham Ramesh,  Makesh Sreedhar,  Junjie Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent generative approaches, single sequence output, multi-hop question answering, reasoning path, Recent generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent generative approaches for multi-hop question answering (QA) utilize
the fusion-in-decoder method~\cite{izacard-grave-2021-leveraging} to generate a
single sequence output which includes both a final answer and a reasoning path
taken to arrive at that answer, such as passage titles and key facts from those
passages. While such models can lead to better interpretability and high
quantitative scores, they often have difficulty accurately identifying the
passages corresponding to key entities in the context, resulting in incorrect
passage hops and a lack of faithfulness in the reasoning path. To address this,
we propose a single-sequence prediction method over a local reasoning graph
(\model)\footnote{Code/Models will be released at
\url{this https URL}} that integrates a graph
structure connecting key entities in each context passage to relevant
subsequent passages for each question. We use a graph neural network to encode
this graph structure and fuse the resulting representations into the entity
representations of the model. Our experiments show significant improvements in
answer exact-match/F1 scores and faithfulness of grounding in the reasoning
path on the HotpotQA dataset and achieve state-of-the-art numbers on the
Musique dataset with only up to a 4\% increase in model parameters.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Variation-aware Vision Transformer Quantization</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00331</p>
  <p><b>作者</b>：Xijie Huang,  Zhiqiang Shen,  Kwang-Ting Cheng</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：Vision Transformers, performance of Vision, visual tasks, remarkable performance, increased the demand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable performance of Vision Transformers (ViTs) in various
visual tasks, the expanding computation and model size of ViTs have increased
the demand for improved efficiency during training and inference. To address
the heavy computation and parameter drawbacks, quantization is frequently
studied in the community as a representative model compression technique and
has seen extensive use on CNNs. However, due to the unique properties of CNNs
and ViTs, the quantization applications on ViTs are still limited and
underexplored. In this paper, we identify the difficulty of ViT quantization on
its unique variation behaviors, which differ from traditional CNN
architectures. The variations indicate the magnitude of the parameter
fluctuations and can also measure outlier conditions. Moreover, the variation
behaviors reflect the various sensitivities to the quantization of each module.
The quantization sensitivity analysis and comparison of ViTs with CNNs help us
locate the underlying differences in variations. We also find that the
variations in ViTs cause training oscillations, bringing instability during
quantization-aware training (QAT). Correspondingly, we solve the variation
problem with an efficient knowledge-distillation-based variation-aware
quantization method. The multi-crop knowledge distillation scheme can
accelerate and stabilize the training and alleviate the variation's influence
during QAT. We also proposed a module-dependent quantization scheme and a
variation-aware regularization term to suppress the oscillation of weights. On
ImageNet-1K, we obtain a 77.66% Top-1 accuracy on the extremely low-bit
scenario of 2-bit Swin-T, outperforming the previous state-of-the-art quantized
model by 3.35%.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis  Across the Spectrum</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00324</p>
  <p><b>作者</b>：Kishore Babu Nampalle,  Pradeep Singh,  Uppala Vivek Narayan,  Balasubramanian Raman</p>
  <p><b>备注</b>：23 pages, 3 figures, 4 tables, 1 algorithm</p>
  <p><b>关键词</b>：achieving high accuracy, rapidly evolving landscape, computational efficiency remains, achieving high, rapidly evolving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the rapidly evolving landscape of medical imaging diagnostics, achieving
high accuracy while preserving computational efficiency remains a formidable
challenge. This work presents \texttt{DeepMediX}, a groundbreaking,
resource-efficient model that significantly addresses this challenge. Built on
top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI
scans and skin cancer images, with superior performance demonstrated on both
binary and multiclass skin cancer datasets. It provides a solution to
labor-intensive manual processes, the need for large datasets, and complexities
related to image properties. DeepMediX's design also includes the concept of
Federated Learning, enabling a collaborative learning approach without
compromising data privacy. This approach allows diverse healthcare institutions
to benefit from shared learning experiences without the necessity of direct
data access, enhancing the model's predictive power while preserving the
privacy and integrity of sensitive patient data. Its low computational
footprint makes DeepMediX suitable for deployment on handheld devices, offering
potential for real-time diagnostic support. Through rigorous testing on
standard datasets, including the ISIC2018 for dermatological research,
DeepMediX demonstrates exceptional diagnostic capabilities, matching the
performance of existing models on almost all tasks and even outperforming them
in some cases. The findings of this study underline significant implications
for the development and deployment of AI-based tools in medical imaging and
their integration into point-of-care settings. The source code and models
generated would be released at this https URL.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：SHARCS: Shared Concept Space for Explainable Multimodal Learning</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00316</p>
  <p><b>作者</b>：Gabriele Dominici,  Pietro Barbiero,  Lucie Charlotte Magister,  Pietro Liò,  Nikola Simidjievski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex real-world problems, addressing complex real-world, individual data modalities, real-world problems, essential paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal learning is an essential paradigm for addressing complex
real-world problems, where individual data modalities are typically
insufficient to accurately solve a given modelling task. While various deep
learning approaches have successfully addressed these challenges, their
reasoning process is often opaque; limiting the capabilities for a principled
explainable cross-modal analysis and any domain-expert intervention. In this
paper, we introduce SHARCS (SHARed Concept Space) -- a novel concept-based
approach for explainable multimodal learning. SHARCS learns and maps
interpretable concepts from different heterogeneous modalities into a single
unified concept-manifold, which leads to an intuitive projection of
semantically similar cross-modal concepts. We demonstrate that such an approach
can lead to inherently explainable task predictions while also improving
downstream predictive performance. Moreover, we show that SHARCS can operate
and significantly outperform other approaches in practically significant
scenarios, such as retrieval of missing modalities and cross-modal
explanations. Our approach is model-agnostic and easily applicable to different
types (and number) of modalities, thus advancing the development of effective,
interpretable, and trustworthy multimodal approaches.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00310</p>
  <p><b>作者</b>：Anvith Thudi,  Hengrui Jia,  Casey Meehan,  Ilia Shumailov,  Nicolas Papernot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Differentially private stochastic, private deep learning, stochastic gradient descent, private stochastic gradient, Differentially private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentially private stochastic gradient descent (DP-SGD) is the canonical
algorithm for private deep learning. While it is known that its privacy
analysis is tight in the worst-case, several empirical results suggest that
when training on common benchmark datasets, the models obtained leak
significantly less privacy for many datapoints. In this paper, we develop a new
analysis for DP-SGD that captures the intuition that points with similar
neighbors in the dataset enjoy better privacy than outliers. Formally, this is
done by modifying the per-step privacy analysis of DP-SGD to introduce a
dependence on the distribution of model updates computed from a training
dataset. We further develop a new composition theorem to effectively use this
new per-step analysis to reason about an entire training run. Put all together,
our evaluation shows that this novel DP-SGD analysis allows us to now formally
show that DP-SGD leaks significantly less privacy for many datapoints. In
particular, we observe that correctly classified points obtain better privacy
guarantees than misclassified points.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Adversarial Attacks and Defenses on 3D Point Cloud Classification: A  Survey</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00309</p>
  <p><b>作者</b>：Hanieh Naderi,  Ivan V. Bajić</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully solved, solved a wide, wide range, Deep learning, Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has successfully solved a wide range of tasks in 2D vision as a
dominant AI technique. Recently, deep learning on 3D point clouds is becoming
increasingly popular for addressing various tasks in this field. Despite
remarkable achievements, deep learning algorithms are vulnerable to adversarial
attacks. These attacks are imperceptible to the human eye but can easily fool
deep neural networks in the testing and deployment stage. To encourage future
research, this survey summarizes the current progress on adversarial attack and
defense techniques on point cloud classification. This paper first introduces
the principles and characteristics of adversarial attacks and summarizes and
analyzes the adversarial example generation methods in recent years. Besides,
it classifies defense strategies as input transformation, data optimization,
and deep model modification. Finally, it presents several challenging issues
and future research directions in this domain.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D  Object Pose Estimation</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00306</p>
  <p><b>作者</b>：Fabian Duffhauss,  Sebastian Koch,  Hanna Ziesche,  Ngo Anh Vien,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at the IEEE Robotics and Automation Letters (RA-L) 2023</p>
  <p><b>关键词</b>：essential for automated, automated systems, systems to interact, interact safely, pose estimator called</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting objects and estimating their 6D poses is essential for automated
systems to interact safely with the environment. Most 6D pose estimators,
however, rely on a single camera frame and suffer from occlusions and
ambiguities due to object symmetries. We overcome this issue by presenting a
novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach
efficiently fuses the RGB-D frames from multiple perspectives in a deep
multi-directional fusion network and predicts predefined keypoints for all
objects in the scene simultaneously. Based on the keypoints and an instance
semantic segmentation, we efficiently compute the 6D poses by least-squares
fitting. To address the ambiguity issues for symmetric objects, we propose a
novel training procedure for symmetry-aware keypoint detection including a new
objective function. Our SyMFM6D network significantly outperforms the
state-of-the-art in both single-view and multi-view 6D pose estimation. We
furthermore show the effectiveness of our symmetry-aware training procedure and
demonstrate that our approach is robust towards inaccurate camera calibration
and dynamic camera setups.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Applied Bayesian Structural Health Monitoring: inclinometer data anomaly  detection and forecasting</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00305</p>
  <p><b>作者</b>：David K. E. Green,  Adam Jaspan</p>
  <p><b>备注</b>：6 Pages. Conference proceedings from GAMM23</p>
  <p><b>关键词</b>：earthwork slopes, probes are devices, measure deformations, deformations within earthwork, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inclinometer probes are devices that can be used to measure deformations
within earthwork slopes. This paper demonstrates a novel application of
Bayesian techniques to real-world inclinometer data, providing both anomaly
detection and forecasting. Specifically, this paper details an analysis of data
collected from inclinometer data across the entire UK rail network.
Practitioners have effectively two goals when processing monitoring data. The
first is to identify any anomalous or dangerous movements, and the second is to
predict potential future adverse scenarios by forecasting. In this paper we
apply Uncertainty Quantification (UQ) techniques by implementing a Bayesian
approach to anomaly detection and forecasting for inclinometer data.
Subsequently, both costs and risks may be minimised by quantifying and
evaluating the appropriate uncertainties. This framework may then act as an
enabler for enhanced decision making and risk analysis.
We show that inclinometer data can be described by a latent autocorrelated
Markov process derived from measurements. This can be used as the transition
model of a non-linear Bayesian filter. This allows for the prediction of system
states. This learnt latent model also allows for the detection of anomalies:
observations that are far from their expected value may be considered to have
`high surprisal', that is they have a high information content relative to the
model encoding represented by the learnt latent model.
We successfully apply the forecasting and anomaly detection techniques to a
large real-world data set in a computationally efficient manner. Although this
paper studies inclinometers in particular, the techniques are broadly
applicable to all areas of engineering UQ and Structural Health Monitoring
(SHM).</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：AutoST: Training-free Neural Architecture Search for Spiking  Transformers</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00293</p>
  <p><b>作者</b>：Ziqing Wang,  Qidong Zhao,  Jinku Cui,  Xu Liu,  Dongkuan Xu</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：Spiking Neural Networks, gained considerable attention, Spiking Transformer architectures, Neural Networks, Spiking Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Transformers have gained considerable attention because they achieve
both the energy efficiency of Spiking Neural Networks (SNNs) and the high
capacity of Transformers. However, the existing Spiking Transformer
architectures, derived from ANNs, exhibit a notable architectural gap,
resulting in suboptimal performance compared to their ANN counterparts.
Traditional approaches to discovering optimal architectures primarily rely on
either manual procedures, which are time-consuming, or Neural Architecture
Search (NAS) methods, which are usually expensive in terms of memory footprints
and computation time. To address these limitations, we introduce AutoST, a
training-free NAS method for Spiking Transformers, to rapidly identify
high-performance and energy-efficient Spiking Transformer architectures. Unlike
existing training-free NAS methods, which struggle with the
non-differentiability and high sparsity inherent in SNNs, we propose to utilize
Floating-Point Operations (FLOPs) as a performance metric, which is independent
of model computations and training dynamics, leading to a stronger correlation
with performance. Moreover, to enable the search for energy-efficient
architectures, we leverage activation patterns during initialization to
estimate the energy consumption of Spiking Transformers. Our extensive
experiments show that AutoST models outperform state-of-the-art manually or
automatically designed SNN architectures on static and neuromorphic datasets,
while significantly reducing energy consumption.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with  Prompt-based Finetuning</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00290</p>
  <p><b>作者</b>：Can Cui,  Ruining Deng,  Quan Liu,  Tianyuan Yao,  Shunxing Bao,  Lucas W. Remedios,  Yucheng Tang,  Yuankai Huo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：zero-shot segmentation approach, generic zero-shot segmentation, recently proposed prompt-based, prompt-based segmentation model, SAM segmentation model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) is a recently proposed prompt-based
segmentation model in a generic zero-shot segmentation approach. With the
zero-shot segmentation capacity, SAM achieved impressive flexibility and
precision on various segmentation tasks. However, the current pipeline requires
manual prompts during the inference stage, which is still resource intensive
for biomedical image segmentation. In this paper, instead of using prompts
during the inference stage, we introduce a pipeline that utilizes the SAM,
called all-in-SAM, through the entire AI development workflow (from annotation
generation to model finetuning) without requiring manual prompts during the
inference stage. Specifically, SAM is first employed to generate pixel-level
annotations from weak prompts (e.g., points, bounding box). Then, the
pixel-level annotations are used to finetune the SAM segmentation model rather
than training from scratch. Our experimental results reveal two key findings:
1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a
nuclei segmentation task on the public Monuseg dataset, and 2) the utilization
of weak and few annotations for SAM finetuning achieves competitive performance
compared to using strong pixel-wise annotated data.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and  Salvageable Failure</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00286</p>
  <p><b>作者</b>：Lennart Purucker,  Joeran Beel</p>
  <p><b>备注</b>：10 pages main paper, 13 pages references and appendix, 4 figures, 14 subfigures, 10 tables, to be published in: International Conference on Automated Machine Learning 2023</p>
  <p><b>关键词</b>：automated machine learning, greedy ensemble selection, ROC AUC, automated machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many state-of-the-art automated machine learning (AutoML) systems use greedy
ensemble selection (GES) by Caruana et al. (2004) to ensemble models found
during model selection post hoc. Thereby, boosting predictive performance and
likely following Auto-Sklearn 1's insight that alternatives, like stacking or
gradient-free numerical optimization, overfit. Overfitting in Auto-Sklearn 1 is
much more likely than in other AutoML systems because it uses only low-quality
validation data for post hoc ensembling. Therefore, we were motivated to
analyze whether Auto-Sklearn 1's insight holds true for systems with
higher-quality validation data. Consequently, we compared the performance of
covariance matrix adaptation evolution strategy (CMA-ES), state-of-the-art
gradient-free numerical optimization, to GES on the 71 classification datasets
from the AutoML benchmark for AutoGluon. We found that Auto-Sklearn's insight
depends on the chosen metric. For the metric ROC AUC, CMA-ES overfits
drastically and is outperformed by GES -- statistically significantly for
multi-class classification. For the metric balanced accuracy, CMA-ES does not
overfit and outperforms GES significantly. Motivated by the successful
application of CMA-ES for balanced accuracy, we explored methods to stop CMA-ES
from overfitting for ROC AUC. We propose a method to normalize the weights
produced by CMA-ES, inspired by GES, that avoids overfitting for CMA-ES and
makes CMA-ES perform better than or similar to GES for ROC AUC.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Assembled-OpenML: Creating Efficient Benchmarks for Ensembles in AutoML  with OpenML</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00285</p>
  <p><b>作者</b>：Lennart Purucker,  Joeran Beel</p>
  <p><b>备注</b>：5 pages main paper, 13 pages references and appendix, 2 figures, 1 table, poster presented at: International Conference on Automated Machine Learning 2022, Workshop Track</p>
  <p><b>关键词</b>：Automated Machine Learning, Machine Learning, Automated Machine, ensemble techniques, Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated Machine Learning (AutoML) frameworks regularly use ensembles.
Developers need to compare different ensemble techniques to select appropriate
techniques for an AutoML framework from the many potential techniques. So far,
the comparison of ensemble techniques is often computationally expensive,
because many base models must be trained and evaluated one or multiple times.
Therefore, we present Assembled-OpenML. Assembled-OpenML is a Python tool,
which builds meta-datasets for ensembles using OpenML. A meta-dataset, called
Metatask, consists of the data of an OpenML task, the task's dataset, and
prediction data from model evaluations for the task. We can make the comparison
of ensemble techniques computationally cheaper by using the predictions stored
in a metatask instead of training and evaluating base models. To introduce
Assembled-OpenML, we describe the first version of our tool. Moreover, we
present an example of using Assembled-OpenML to compare a set of ensemble
techniques. For this example comparison, we built a benchmark using
Assembled-OpenML and implemented ensemble techniques expecting predictions
instead of base models as input. In our example comparison, we gathered the
prediction data of $1523$ base models for $31$ datasets. Obtaining the
prediction data for all base models using Assembled-OpenML took ${\sim} 1$ hour
in total. In comparison, obtaining the prediction data by training and
evaluating just one base model on the most computationally expensive dataset
took ${\sim} 37$ minutes.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：SysNoise: Exploring and Benchmarking Training-Deployment System  Inconsistency</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00280</p>
  <p><b>作者</b>：Yan Wang,  Yuhang Li,  Ruihao Gong,  Aishan Liu,  Yanfei Wang,  Jian Hu,  Yongqiang Yao,  Yunchen Zhang,  Tianzi Xiao,  Fengwei Yu,  Xianglong Liu</p>
  <p><b>备注</b>：Proceedings of Machine Learning and Systems. 2023 Mar 18</p>
  <p><b>关键词</b>：deep learning, studies have shown, deep learning training-deployment, noises caused, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extensive studies have shown that deep learning models are vulnerable to
adversarial and natural noises, yet little is known about model robustness on
noises caused by different system implementations. In this paper, we for the
first time introduce SysNoise, a frequently occurred but often overlooked noise
in the deep learning training-deployment cycle. In particular, SysNoise happens
when the source training system switches to a disparate target system in
deployments, where various tiny system mismatch adds up to a non-negligible
difference. We first identify and classify SysNoise into three categories based
on the inference stage; we then build a holistic benchmark to quantitatively
measure the impact of SysNoise on 20+ models, comprehending image
classification, object detection, instance segmentation and natural language
processing tasks. Our extensive experiments revealed that SysNoise could bring
certain impacts on model robustness across different tasks and common
mitigations like data augmentation and adversarial training show limited
effects on it. Together, our findings open a new research topic and we hope
this work will raise research attention to deep learning deployment systems
accounting for model performance. We have open-sourced the benchmark and
framework at this https URL.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Common Knowledge Learning for Generating Transferable Adversarial  Examples</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00274</p>
  <p><b>作者</b>：Ruijie Yang,  Yuanfang Guo,  Junfu Wang,  Jiantao Zhou,  Yunhong Wang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：transfer-based adversarial attacks, unseen target model, black-box attacks, adversary generates adversarial, knowing its information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper focuses on an important type of black-box attacks, i.e.,
transfer-based adversarial attacks, where the adversary generates adversarial
examples by a substitute (source) model and utilize them to attack an unseen
target model, without knowing its information. Existing methods tend to give
unsatisfactory adversarial transferability when the source and target models
are from different types of DNN architectures (e.g. ResNet-18 and Swin
Transformer). In this paper, we observe that the above phenomenon is induced by
the output inconsistency problem. To alleviate this problem while effectively
utilizing the existing DNN models, we propose a common knowledge learning (CKL)
framework to learn better network weights to generate adversarial examples with
better transferability, under fixed network architectures. Specifically, to
reduce the model-specific features and obtain better output distributions, we
construct a multi-teacher framework, where the knowledge is distilled from
different teacher architectures into one student network. By considering that
the gradient of input is usually utilized to generated adversarial examples, we
impose constraints on the gradients between the student and teacher models, to
further alleviate the output inconsistency problem and enhance the adversarial
transferability. Extensive experiments demonstrate that our proposed work can
significantly improve the adversarial transferability.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Hiding in Plain Sight: Differential Privacy Noise Exploitation for  Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00268</p>
  <p><b>作者</b>：Md Tamjid Hossain,  Hung La</p>
  <p><b>备注</b>：Accepted for publication in the proceeding of ICMLC 2023, 9-11 July 2023, The University of Adelaide, Adelaide, Australia</p>
  <p><b>关键词</b>：multiagent reinforcement learning, cooperative multiagent reinforcement, differential privacy, agents' privacy, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lately, differential privacy (DP) has been introduced in cooperative
multiagent reinforcement learning (CMARL) to safeguard the agents' privacy
against adversarial inference during knowledge sharing. Nevertheless, we argue
that the noise introduced by DP mechanisms may inadvertently give rise to a
novel poisoning threat, specifically in the context of private knowledge
sharing during CMARL, which remains unexplored in the literature. To address
this shortcoming, we present an adaptive, privacy-exploiting, and
evasion-resilient localized poisoning attack (PeLPA) that capitalizes on the
inherent DP-noise to circumvent anomaly detection systems and hinder the
optimal convergence of the CMARL model. We rigorously evaluate our proposed
PeLPA attack in diverse environments, encompassing both non-adversarial and
multiple-adversarial contexts. Our findings reveal that, in a medium-scale
environment, the PeLPA attack with attacker ratios of 20% and 40% can lead to
an increase in average steps to goal by 50.69% and 64.41%, respectively.
Furthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x
computational time increase in optimal reward attainment and a 1.18x and 1.38x
slower convergence for attacker ratios of 20% and 40%, respectively.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：An ML approach to resolution of singularities</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00252</p>
  <p><b>作者</b>：Gergely Bérczi,  Honglu Fan,  Mingcong Zeng</p>
  <p><b>备注</b>：To appear in Proceedings of the 40th International Conference on Machine Learning TAG Workshop (ICML-TAG 2023)</p>
  <p><b>关键词</b>：polynomial equations typically, replace singular points, solution set unchanged, singular points, typically contains ill-behaved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The solution set of a system of polynomial equations typically contains
ill-behaved, singular points. Resolution is a fundamental process in geometry
in which we replace singular points with smooth points, while keeping the rest
of the solution set unchanged. Resolutions are not unique: the usual way to
describe them involves repeatedly performing a fundamental operation known as
"blowing-up", and the complexity of the resolution highly depends on certain
choices. The process can be translated into various versions of a 2-player
game, the so-called Hironaka game, and a winning strategy for the first player
provides a solution to the resolution problem. In this paper we introduce a new
approach to the Hironaka game that uses reinforcement learning agents to find
optimal resolutions of singularities. In certain domains, the trained model
outperforms state-of-the-art selection heuristics in total number of polynomial
additions performed, which provides a proof-of-concept that recent developments
in machine learning have the potential to improve performance of algorithms in
symbolic computation.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：On a Relation Between the Rate-Distortion Function and Optimal Transport</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00246</p>
  <p><b>作者</b>：Eric Lei,  Hamed Hassani,  Shirin Saeedi Bidokhti</p>
  <p><b>备注</b>：Published as a Tiny Paper at ICLR 2023; invited to present</p>
  <p><b>关键词</b>：discuss a relationship, theory, Monge and Kantorovich, rate-distortion, optimal transport</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We discuss a relationship between rate-distortion and optimal transport (OT)
theory, even though they seem to be unrelated at first glance. In particular,
we show that a function defined via an extremal entropic OT distance is
equivalent to the rate-distortion function. We numerically verify this result
as well as previous results that connect the Monge and Kantorovich problems to
optimal scalar quantization. Thus, we unify solving scalar quantization and
rate-distortion functions in an alternative fashion by using their respective
optimal transport solvers.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Hierarchical Federated Learning Incentivization for Gas Usage Estimation</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00233</p>
  <p><b>作者</b>：Has Sun,  Xiaoli Tang,  Chengyi Yang,  Zhenpeng Yu,  Xiuli Wang,  Qijie Ding,  Zengxiang Li,  Han Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：saving operational costs, Accurately estimating gas, Accurately estimating, operational costs, efficient functioning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately estimating gas usage is essential for the efficient functioning of
gas distribution networks and saving operational costs. Traditional methods
rely on centralized data processing, which poses privacy risks. Federated
learning (FL) offers a solution to this problem by enabling local data
processing on each participant, such as gas companies and heating stations.
However, local training and communication overhead may discourage gas companies
and heating stations from actively participating in the FL training process. To
address this challenge, we propose a Hierarchical FL Incentive Mechanism for
Gas Usage Estimation (HI-GAS), which has been testbedded in the ENN Group, one
of the leading players in the natural gas and green energy industry. It is
designed to support horizontal FL among gas companies, and vertical FL among
each gas company and heating station within a hierarchical FL ecosystem,
rewarding participants based on their contributions to FL. In addition, a
hierarchical FL model aggregation approach is also proposed to improve the gas
usage estimation performance by aggregating models at different levels of the
hierarchy. The incentive scheme employs a multi-dimensional contribution-aware
reward distribution function that combines the evaluation of data quality and
model contribution to incentivize both gas companies and heating stations
within their jurisdiction while maintaining fairness. Results of extensive
experiments validate the effectiveness of the proposed mechanism.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Forward-Forward Algorithm for Hyperspectral Image Classification: A  Preliminary Study</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00231</p>
  <p><b>作者</b>：Sidike Paheding,  Abel A. Reyes-Angulo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, cutting-edge deep learning, learning models, de-facto standard, standard in optimizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The back-propagation algorithm has long been the de-facto standard in
optimizing weights and biases in neural networks, particularly in cutting-edge
deep learning models. Its widespread adoption in fields like natural language
processing, computer vision, and remote sensing has revolutionized automation
in various tasks. The popularity of back-propagation stems from its ability to
achieve outstanding performance in tasks such as classification, detection, and
segmentation. Nevertheless, back-propagation is not without its limitations,
encompassing sensitivity to initial conditions, vanishing gradients,
overfitting, and computational complexity. The recent introduction of a
forward-forward algorithm (FFA), which computes local goodness functions to
optimize network parameters, alleviates the dependence on substantial
computational resources and the constant need for architectural scaling. This
study investigates the application of FFA for hyperspectral image
classification. Experimental results and comparative analysis are provided with
the use of the traditional back-propagation algorithm. Preliminary results show
the potential behind FFA and its promises.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph  Neural Network over Huge Graphs</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00228</p>
  <p><b>作者</b>：Dalong Zhang,  Xianzheng Song,  Zhiyang Hu,  Yang Li,  Miao Tao,  Binbin Hu,  Lin Wang,  Zhiqiang Zhang,  Jun Zhou</p>
  <p><b>备注</b>：Accepted by ICDE 2023</p>
  <p><b>关键词</b>：GNN inference, stochastic acceleration strategies, GNN, scalability tailored, inconsistency caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>GNN inference is a non-trivial task, especially in industrial scenarios with
giant graphs, given three main challenges, i.e., scalability tailored for
full-graph inference on huge graphs, inconsistency caused by stochastic
acceleration strategies (e.g., sampling), and the serious redundant computation
issue. To address the above challenges, we propose a scalable system named
InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired
by the philosophy of ``think-like-a-vertex", a GAS-like (Gather-Apply-Scatter)
schema is proposed to describe the computation paradigm and data flow of GNN
inference. The computation of GNNs is expressed in an iteration manner, in
which a vertex would gather messages via in-edges and update its state
information by forwarding an associated layer of GNNs with those messages and
then send the updated information to other vertexes via out-edges. Following
the schema, the proposed InferTurbo can be built with alternative backends
(e.g., batch processing system or graph computing system). Moreover, InferTurbo
introduces several strategies like shadow-nodes and partial-gather to handle
nodes with large degrees for better load balancing. With InferTurbo, GNN
inference can be hierarchically conducted over the full graph without sampling
and redundant computation. Experimental results demonstrate that our system is
robust and efficient for inference tasks over graphs containing some hub nodes
with many adjacent edges. Meanwhile, the system gains a remarkable performance
compared with the traditional inference pipeline, and it can finish a GNN
inference task over a graph with tens of billions of nodes and hundreds of
billions of edges within 2 hours.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：S-Omninet: Structured Data Enhanced Universal Multimodal Learning  Architecture</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00226</p>
  <p><b>作者</b>：Ye Xue,  Diego Klabjan,  Jean Utke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, attracted an increasing, increasing interest, interest in recent, Multimodal multitask learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal multitask learning has attracted an increasing interest in recent
years. Singlemodal models have been advancing rapidly and have achieved
astonishing results on various tasks across multiple domains. Multimodal
learning offers opportunities for further improvements by integrating data from
multiple modalities. Many methods are proposed to learn on a specific type of
multimodal data, such as vision and language data. A few of them are designed
to handle several modalities and tasks at a time. In this work, we extend and
improve Omninet, an architecture that is capable of handling multiple
modalities and tasks at a time, by introducing cross-cache attention,
integrating patch embeddings for vision inputs, and supporting structured data.
The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model
that is capable of learning from structured data of various dimensions
effectively with unstructured data through cross-cache attention, which enables
interactions among spatial, temporal, and structured features. We also enhance
spatial representations in a spatial cache with patch embeddings. We evaluate
the proposed model on several multimodal datasets and demonstrate a significant
improvement over the baseline, Omninet.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Re-Think and Re-Design Graph Neural Networks in Spaces of Continuous  Graph Diffusion Functionals</b></summary>
  <p><b>编号</b>：[392]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00222</p>
  <p><b>作者</b>：Tingting Dan,  Jiaqi Ding,  Ziquan Wei,  Shahar Z Kovalsky,  Minjeong Kim,  Won Hwa Kim,  Guorong Wu</p>
  <p><b>备注</b>：23 papers, 10 figures</p>
  <p><b>关键词</b>：biological systems, GNNs, GNN models, Graph, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) are widely used in domains like social networks
and biological systems. However, the locality assumption of GNNs, which limits
information exchange to neighboring nodes, hampers their ability to capture
long-range dependencies and global patterns in graphs. To address this, we
propose a new inductive bias based on variational analysis, drawing inspiration
from the Brachistochrone problem. Our framework establishes a mapping between
discrete GNN models and continuous diffusion functionals. This enables the
design of application-specific objective functions in the continuous domain and
the construction of discrete deep models with mathematical guarantees. To
tackle over-smoothing in GNNs, we analyze the existing layer-by-layer graph
embedding models and identify that they are equivalent to l2-norm integral
functionals of graph gradients, which cause over-smoothing. Similar to
edge-preserving filters in image denoising, we introduce total variation (TV)
to align the graph diffusion pattern with global community topologies.
Additionally, we devise a selective mechanism to address the trade-off between
model depth and over-smoothing, which can be easily integrated into existing
GNNs. Furthermore, we propose a novel generative adversarial network (GAN) that
predicts spreading flows in graphs through a neural transport equation. To
mitigate vanishing flows, we customize the objective function to minimize
transportation within each community while maximizing inter-community flows.
Our GNN models achieve state-of-the-art (SOTA) performance on popular graph
learning benchmarks such as Cora, Citeseer, and Pubmed.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：More for Less: Compact Convolutional Transformers Enable Robust Medical  Image Classification with Limited Data</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00213</p>
  <p><b>作者</b>：Andrew Kean Gao</p>
  <p><b>备注</b>：9 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：tasks across domains, powerful tools, variety of tasks, text generation, Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are very powerful tools for a variety of tasks across domains,
from text generation to image captioning. However, transformers require
substantial amounts of training data, which is often a challenge in biomedical
settings, where high quality labeled data can be challenging or expensive to
obtain. This study investigates the efficacy of Compact Convolutional
Transformers (CCT) for robust medical image classification with limited data,
addressing a key issue faced by conventional Vision Transformers - their
requirement for large datasets. A hybrid of transformers and convolutional
layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed
a benchmark dataset of peripheral blood cell images of eight distinct cell
types, each represented by approximately 2,000 low-resolution (28x28x3 pixel)
samples. Despite the dataset size being smaller than those typically used with
Vision Transformers, we achieved a commendable classification accuracy of
92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly,
exceeding 80% validation accuracy after five epochs. Analysis of per-class
precision, recall, F1, and ROC showed that performance was strong across cell
types. Our findings underscore the robustness of CCTs, indicating their
potential as a solution to data scarcity issues prevalent in biomedical
imaging. We substantiate the applicability of CCTs in data-constrained areas
and encourage further work on CCTs.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：An Interpretable Constructive Algorithm for Incremental Random Weight  Neural Networks and Its Application</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00185</p>
  <p><b>作者</b>：Jing Nan,  Wei Dai,  Guan Yuan,  Ping Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Incremental random weight, random weight neural, hidden parameters, weight neural networks, Incremental random</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incremental random weight neural networks (IRWNNs) have gained attention in
view of its easy implementation and fast learning. However, a significant
drawback of IRWNNs is that the elationship between the hidden parameters
(node)and the residual error (model performance) is difficult to be
interpreted. To address the above issue, this article proposes an interpretable
constructive algorithm (ICA) with geometric information constraint. First,
based on the geometric relationship between the hidden parameters and the
residual error, an interpretable geometric information constraint is proposed
to randomly assign the hidden parameters. Meanwhile, a node pool strategy is
employed to obtain hidden parameters that is more conducive to convergence from
hidden parameters satisfying the proposed constraint. Furthermore, the
universal approximation property of the ICA is proved. Finally, a lightweight
version of ICA is presented for large-scale data modeling tasks. Experimental
results on six benchmark datasets and a numerical simulation dataset
demonstrate that the ICA outperforms other constructive algorithms in terms of
modeling speed, model accuracy, and model network structure. Besides, two
practical industrial application case are used to validate the effectiveness of
ICA in practical applications.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Still No Lie Detector for Language Models: Probing Empirical and  Conceptual Roadblocks</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00175</p>
  <p><b>作者</b>：B.A. Levinstein,  Daniel A. Herrmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, language models, Azaria and Mitchell, large language, beliefs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the questions of whether or not large language models (LLMs) have
beliefs, and, if they do, how we might measure them. First, we evaluate two
existing approaches, one due to Azaria and Mitchell (2023) and the other to
Burns et al. (2022). We provide empirical results that show that these methods
fail to generalize in very basic ways. We then argue that, even if LLMs have
beliefs, these methods are unlikely to be successful for conceptual reasons.
Thus, there is still no lie-detector for LLMs. After describing our empirical
results we take a step back and consider whether or not we should expect LLMs
to have something like beliefs in the first place. We consider some recent
arguments aiming to show that LLMs cannot have beliefs. We show that these
arguments are misguided. We provide a more productive framing of questions
surrounding the status of beliefs in LLMs, and highlight the empirical nature
of the problem. We conclude by suggesting some concrete paths for future work.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：The Integer Linear Programming Inference Cookbook</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00171</p>
  <p><b>作者</b>：Vivek Srikumar,  Dan Roth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, language processing problems, integer linear programs, integer linear, employed to model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the years, integer linear programs have been employed to model inference
in many natural language processing problems. This survey is meant to guide the
reader through the process of framing a new inference problem as an instance of
an integer linear program and is structured as a collection of recipes. At the
end, we will see two worked examples to illustrate the use of these recipes.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：U-Calibration: Forecasting for an Unknown Agent</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00168</p>
  <p><b>作者</b>：Robert Kleinberg,  Renato Paes Leme,  Jon Schneider,  Yifeng Teng</p>
  <p><b>备注</b>：Accepted for presentation at the Conference on Learning Theory (COLT) 2023</p>
  <p><b>关键词</b>：single scoring rule, scoring rule, single scoring, binary events, consumed by rational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of evaluating forecasts of binary events whose
predictions are consumed by rational agents who take an action in response to a
prediction, but whose utility is unknown to the forecaster. We show that
optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot
guarantee low regret for all possible agents. In contrast, forecasts that are
well-calibrated guarantee that all agents incur sublinear regret. However,
calibration is not a necessary criterion here (it is possible for miscalibrated
forecasts to provide good regret guarantees for all possible agents), and
calibrated forecasting procedures have provably worse convergence rates than
forecasting procedures targeting a single scoring rule.
Motivated by this, we present a new metric for evaluating forecasts that we
call U-calibration, equal to the maximal regret of the sequence of forecasts
when evaluated under any bounded scoring rule. We show that sublinear
U-calibration error is a necessary and sufficient condition for all agents to
achieve sublinear regret guarantees. We additionally demonstrate how to compute
the U-calibration error efficiently and provide an online algorithm that
achieves $O(\sqrt{T})$ U-calibration error (on par with optimal rates for
optimizing for a single scoring rule, and bypassing lower bounds for the
traditionally calibrated learning procedures). Finally, we discuss
generalizations to the multiclass prediction setting.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：What do self-supervised speech models know about words?</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00162</p>
  <p><b>作者</b>：Ankita Pasad,  Chung-Ming Chien,  Shane Settle,  Karen Livescu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data efficiency improvements, self-supervised speech models, self-supervised speech, data efficiency, efficiency improvements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many self-supervised speech models (S3Ms) have been introduced over the last
few years, producing performance and data efficiency improvements for a variety
of speech tasks. Evidence is emerging that different S3Ms encode linguistic
information in different layers, and also that some S3Ms appear to learn
phone-like sub-word units. However, the extent to which these models capture
larger linguistic units, such as words, and where word-related information is
encoded, remains unclear. In this study, we conduct several analyses of word
segment representations extracted from different layers of three S3Ms:
wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a
lightweight analysis tool, to measure the similarity between these
representations and word-level linguistic properties. We find that the maximal
word-level linguistic content tends to be found in intermediate model layers,
while some lower-level information like pronunciation is also retained in
higher layers of HuBERT and WavLM. Syntactic and semantic word attributes have
similar layer-wise behavior. We also find that, for all of the models tested,
word identity information is concentrated near the center of each word segment.
We then test the layer-wise performance of the same models, when used directly
with no additional learned parameters, on several tasks: acoustic word
discrimination, word segmentation, and semantic sentence similarity. We find
similar layer-wise trends in performance, and furthermore, find that when using
the best-performing layer of HuBERT or WavLM, it is possible to achieve
performance on word segmentation and sentence similarity that rivals more
complex existing approaches.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：FFPDG: Fast, Fair and Private Data Generation</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00161</p>
  <p><b>作者</b>：Weijie Xu,  Jinjin Zhao,  Francis Iannacci,  Bo Wang</p>
  <p><b>备注</b>：12 pages, 2 figures, ICLR 2021 Workshop on Synthetic Data Generation</p>
  <p><b>关键词</b>：Generative modeling, data, synthetic data, synthetic, frequently in synthetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative modeling has been used frequently in synthetic data generation.
Fairness and privacy are two big concerns for synthetic data. Although Recent
GAN [\cite{goodfellow2014generative}] based methods show good results in
preserving privacy, the generated data may be more biased. At the same time,
these methods require high computation resources. In this work, we design a
fast, fair, flexible and private data generation method. We show the
effectiveness of our method theoretically and empirically. We show that models
trained on data generated by the proposed method can perform well (in inference
stage) on real application scenarios.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：The Effect of Balancing Methods on Model Behavior in Imbalanced  Classification Problems</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00157</p>
  <p><b>作者</b>：Adrian Stando,  Mustafa Cavus,  Przemysław Biecek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Imbalanced data poses, minority classes, challenge in classification, affected by insufficient, Balancing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imbalanced data poses a significant challenge in classification as model
performance is affected by insufficient learning from minority classes.
Balancing methods are often used to address this problem. However, such
techniques can lead to problems such as overfitting or loss of information.
This study addresses a more challenging aspect of balancing methods - their
impact on model behavior. To capture these changes, Explainable Artificial
Intelligence tools are used to compare models trained on datasets before and
after balancing. In addition to the variable importance method, this study uses
the partial dependence profile and accumulated local effects techniques. Real
and simulated datasets are tested, and an open-source Python package edgaro is
developed to facilitate this analysis. The results obtained show significant
changes in model behavior due to balancing methods, which can lead to biased
models toward a balanced distribution. These findings confirm that balancing
analysis should go beyond model performance comparisons to achieve higher
reliability of machine learning models. Therefore, we propose a new method
performance gain plot for informed data balancing strategy to make an optimal
selection of balancing method by analyzing the measure of change in model
behavior versus performance gain.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Stitched ViTs are Flexible Vision Backbones</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00154</p>
  <p><b>作者</b>：Zizheng Pan,  Jing Liu,  Haoyu He,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Tech report</p>
  <p><b>关键词</b>：plain vision Transformers, Large pretrained plain, vision Transformers, pretrained plain vision, Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained plain vision Transformers (ViTs) have been the workhorse for
many downstream tasks. However, existing works utilizing off-the-shelf ViTs are
inefficient in terms of training and deployment, because adopting ViTs with
individual sizes requires separate training and is restricted by fixed
performance-efficiency trade-offs. In this paper, we are inspired by stitchable
neural networks, which is a new framework that cheaply produces a single model
that covers rich subnetworks by stitching pretrained model families, supporting
diverse performance-efficiency trade-offs at runtime. Building upon this
foundation, we introduce SN-Netv2, a systematically improved model stitching
framework to facilitate downstream task adaptation. Specifically, we first
propose a Two-way stitching scheme to enlarge the stitching space. We then
design a resource-constrained sampling strategy that takes into account the
underlying FLOPs distributions in the space for improved sampling. Finally, we
observe that learning stitching layers is a low-rank update, which plays an
essential role on downstream tasks to stabilize training and ensure a good
Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K,
COCO-Stuff-10K, NYUv2 and COCO-2017, SN-Netv2 demonstrates strong ability to
serve as a flexible vision backbone, achieving great advantages in both
training efficiency and adaptation. Code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Hierarchical Neural Coding for Controllable CAD Model Generation</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00149</p>
  <p><b>作者</b>：Xiang Xu,  Pradeep Kumar Jayaraman,  Joseph G. Lambourne,  Karl D.D. Willis,  Yasutaka Furukawa</p>
  <p><b>备注</b>：Accepted to ICML 2023. Project website at this https URL</p>
  <p><b>关键词</b>：Computer Aided Design, Computer Aided, local curve geometry, global part arrangement, represents high-level design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel generative model for Computer Aided Design (CAD)
that 1) represents high-level design concepts of a CAD model as a three-level
hierarchical tree of neural codes, from global part arrangement down to local
curve geometry; and 2) controls the generation or completion of CAD models by
specifying the target design using a code tree. Concretely, a novel variant of
a vector quantized VAE with "masked skip connection" extracts design variations
as neural codebooks at three levels. Two-stage cascaded auto-regressive
transformers learn to generate code trees from incomplete CAD models and then
complete CAD models following the intended design. Extensive experiments
demonstrate superior performance on conventional tasks such as random
generation while enabling novel interaction capabilities on conditional
generation tasks. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Abide by the Law and Follow the Flow: Conservation Laws for Gradient  Flows</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00144</p>
  <p><b>作者</b>：Sibylle Marcotte,  Rémi Gribonval,  Gabriel Peyré</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gradient descent dynamics, descent dynamics, key ingredient, ingredient in deciphering, deciphering the recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the geometric properties of gradient descent dynamics is a key
ingredient in deciphering the recent success of very large machine learning
models. A striking observation is that trained over-parameterized models retain
some properties of the optimization initialization. This "implicit bias" is
believed to be responsible for some favorable properties of the trained models
and could explain their good generalization properties. The purpose of this
article is threefold. First, we rigorously expose the definition and basic
properties of "conservation laws", which are maximal sets of independent
quantities conserved during gradient flows of a given model (e.g. of a ReLU
network with a given architecture) with any training data and any loss. Then we
explain how to find the exact number of these quantities by performing
finite-dimensional algebraic manipulations on the Lie algebra generated by the
Jacobian of the model. Finally, we provide algorithms (implemented in SageMath)
to: a) compute a family of polynomial laws; b) compute the number of (not
necessarily polynomial) conservation laws. We provide showcase examples that we
fully work out theoretically. Besides, applying the two algorithms confirms for
a number of ReLU network architectures that all known laws are recovered by the
algorithm, and that there are no other laws. Such computational tools pave the
way to understanding desirable properties of optimization initialization in
large machine learning models.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark  for Short-Term Load Forecasting</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00142</p>
  <p><b>作者</b>：Patrick Emami,  Abhijeet Sahu,  Peter Graf</p>
  <p><b>备注</b>：32 pages. Code available at this https URL and data available at this https URL</p>
  <p><b>关键词</b>：building energy consumption, grow in importance, energy consumption, consumption is widely, power systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Short-term forecasting of residential and commercial building energy
consumption is widely used in power systems and continues to grow in
importance. Data-driven short-term load forecasting (STLF), although promising,
has suffered from a lack of open, large-scale datasets with high building
diversity. This has hindered exploring the pretrain-then-finetune paradigm for
STLF. To help address this, we present BuildingsBench, which consists of 1)
Buildings-900K, a large-scale dataset of 900K simulated buildings representing
the U.S. building stock, and 2) an evaluation platform with over 1,900 real
residential and commercial buildings from 7 open datasets. BuildingsBench
benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model
is evaluated on unseen buildings without fine-tuning, and transfer learning,
where a pretrained model is fine-tuned on a target building. The main finding
of our benchmark analysis is that synthetically pretrained models generalize
surprisingly well to real commercial buildings. An exploration of the effect of
increasing dataset size and diversity on zero-shot commercial building
performance reveals a power-law with diminishing returns. We also show that
fine-tuning pretrained models on real commercial and residential buildings
improves performance for a majority of target buildings. We hope that
BuildingsBench encourages and facilitates future research on generalizable
STLF. All datasets and code can be accessed from
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Risk-sensitive Actor-free Policy via Convex Optimization</b></summary>
  <p><b>编号</b>：[432]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00141</p>
  <p><b>作者</b>：Ruoqi Zhang,  Jens Sjölund</p>
  <p><b>备注</b>：Accepted by The IJCAI-2023 AlSafety and SafeRL Joint Workshop</p>
  <p><b>关键词</b>：Traditional reinforcement learning, reinforcement learning methods, learning methods optimize, methods optimize agents, Traditional reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional reinforcement learning methods optimize agents without
considering safety, potentially resulting in unintended consequences. In this
paper, we propose an optimal actor-free policy that optimizes a risk-sensitive
criterion based on the conditional value at risk. The risk-sensitive objective
function is modeled using an input-convex neural network ensuring convexity
with respect to the actions and enabling the identification of globally optimal
actions through simple gradient-following methods. Experimental results
demonstrate the efficacy of our approach in maintaining effective risk control.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Generalization Limits of Graph Neural Networks in Identity Effects  Learning</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00134</p>
  <p><b>作者</b>：Giuseppe Alessio D'Inverno,  Simone Brugiapaglia,  Mirco Ravanelli</p>
  <p><b>备注</b>：13 pages, 10 figures</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, Graph Neural, powerful tool, tool for data-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have emerged as a powerful tool for data-driven
learning on various graph domains. They are usually based on a message-passing
mechanism and have gained increasing popularity for their intuitive
formulation, which is closely linked to the Weisfeiler-Lehman (WL) test for
graph isomorphism to which they have been proven equivalent in terms of
expressive power. In this work, we establish new generalization properties and
fundamental limits of GNNs in the context of learning so-called identity
effects, i.e., the task of determining whether an object is composed of two
identical components or not. Our study is motivated by the need to understand
the capabilities of GNNs when performing simple cognitive tasks, with potential
applications in computational linguistics and chemistry. We analyze two case
studies: (i) two-letters words, for which we show that GNNs trained via
stochastic gradient descent are unable to generalize to unseen letters when
utilizing orthogonal encodings like one-hot representations; (ii) dicyclic
graphs, i.e., graphs composed of two cycles, for which we present positive
existence results leveraging the connection between GNNs and the WL test. Our
theoretical analysis is supported by an extensive numerical study.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：RObotic MAnipulation Network (ROMAN) -- Hybrid Hierarchical Learning for  Solving Complex Sequential Tasks</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00125</p>
  <p><b>作者</b>：Eleftherios Triantafyllidis,  Fernando Acero,  Zhaocheng Liu,  Zhibin Li</p>
  <p><b>备注</b>：To appear in Nature Machine Intelligence. Includes the main and supplementary manuscript. Total of 70 pages, with a total of 9 Figures and 17 Tables</p>
  <p><b>关键词</b>：embodied artificial intelligence, artificial intelligence, sequential tasks poses, Hybrid Hierarchical Learning, poses a significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving long sequential tasks poses a significant challenge in embodied
artificial intelligence. Enabling a robotic system to perform diverse
sequential tasks with a broad range of manipulation skills is an active area of
research. In this work, we present a Hybrid Hierarchical Learning framework,
the Robotic Manipulation Network (ROMAN), to address the challenge of solving
multiple complex tasks over long time horizons in robotic manipulation. ROMAN
achieves task versatility and robust failure recovery by integrating
behavioural cloning, imitation learning, and reinforcement learning. It
consists of a central manipulation network that coordinates an ensemble of
various neural networks, each specialising in distinct re-combinable sub-tasks
to generate their correct in-sequence actions for solving complex long-horizon
manipulation tasks. Experimental results show that by orchestrating and
activating these specialised manipulation experts, ROMAN generates correct
sequential activations for accomplishing long sequences of sophisticated
manipulation tasks and achieving adaptive behaviours beyond demonstrations,
while exhibiting robustness to various sensory noises. These results
demonstrate the significance and versatility of ROMAN's dynamic adaptability
featuring autonomous failure recovery capabilities, and highlight its potential
for various autonomous manipulation tasks that demand adaptive motor skills.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：How Do Human Users Teach a Continual Learning Robot in Repeated  Interactions?</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00123</p>
  <p><b>作者</b>：Ali Ayub,  Jainish Mehta,  Zachary De Francesco,  Patrick Holthaus,  Kerstin Dautenhahn,  Chrystopher L. Nehaniv</p>
  <p><b>备注</b>：Accepted to the IEEE International Conference on Robot and Human Interactive Communication (ROMAN), 2023</p>
  <p><b>关键词</b>：Continual learning, intersection of Machine, Machine Learning, continual learning robots, learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual learning (CL) has emerged as an important avenue of research in
recent years, at the intersection of Machine Learning (ML) and Human-Robot
Interaction (HRI), to allow robots to continually learn in their environments
over long-term interactions with humans. Most research in continual learning,
however, has been robot-centered to develop continual learning algorithms that
can quickly learn new information on static datasets. In this paper, we take a
human-centered approach to continual learning, to understand how humans teach
continual learning robots over the long term and if there are variations in
their teaching styles. We conducted an in-person study with 40 participants
that interacted with a continual learning robot in 200 sessions. In this
between-participant study, we used two different CL models deployed on a Fetch
mobile manipulator robot. An extensive qualitative and quantitative analysis of
the data collected in the study shows that there is significant variation among
the teaching styles of individual users indicating the need for personalized
adaptation to their distinct teaching styles. The results also show that
although there is a difference in the teaching styles between expert and
non-expert users, the style does not have an effect on the performance of the
continual learning robot. Finally, our analysis shows that the constrained
experimental setups that have been widely used to test most continual learning
techniques are not adequate, as real users interact with and teach continual
learning robots in a variety of ways. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Goal Representations for Instruction Following: A Semi-Supervised  Language Interface to Control</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00117</p>
  <p><b>作者</b>：Vivek Myers,  Andre He,  Kuan Fang,  Homer Walke,  Philippe Hansen-Estruch,  Ching-An Cheng,  Mihai Jalobeanu,  Andrey Kolobov,  Anca Dragan,  Sergey Levine</p>
  <p><b>备注</b>：15 pages, 5 figures</p>
  <p><b>关键词</b>：follow natural language, put the towel, natural language instructions, follow natural, labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Our goal is for robots to follow natural language instructions like "put the
towel next to the microwave." But getting large amounts of labeled data, i.e.
data that contains demonstrations of tasks labeled with the language
instruction, is prohibitive. In contrast, obtaining policies that respond to
image goals is much easier, because any autonomous trial or demonstration can
be labeled in hindsight with its final state as the goal. In this work, we
contribute a method that taps into joint image- and goal- conditioned policies
with language using only a small amount of language data. Prior work has made
progress on this using vision-language models or by jointly training
language-goal-conditioned policies, but so far neither method has scaled
effectively to real-world robot tasks without significant human annotation. Our
method achieves robust performance in the real world by learning an embedding
from the labeled data that aligns language not to the goal image, but rather to
the desired change between the start and goal images that the instruction
corresponds to. We then train a policy on this embedding: the policy benefits
from all the unlabeled data, but the aligned embedding provides an interface
for language to steer the policy. We show instruction following across a
variety of manipulation tasks in different scenes, with generalization to
language instructions outside of the labeled data. Videos and code for our
approach can be found on our website: this http URL .</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Ticket-BERT: Labeling Incident Management Tickets with Language Models</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00108</p>
  <p><b>作者</b>：Zhexiong Liu,  Cris Benge,  Siduo Jiang</p>
  <p><b>备注</b>：In the Microsoft Journal of Applied Research (MSJAR), Volume 18, January 2023</p>
  <p><b>关键词</b>：prioritizing incident tickets, efficiently labeling tickets, fine-grained categories, essential aspect, aspect of prioritizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An essential aspect of prioritizing incident tickets for resolution is
efficiently labeling tickets with fine-grained categories. However, ticket data
is often complex and poses several unique challenges for modern machine
learning methods: (1) tickets are created and updated either by machines with
pre-defined algorithms or by engineers with domain expertise that share
different protocols, (2) tickets receive frequent revisions that update ticket
status by modifying all or parts of ticket descriptions, and (3) ticket
labeling is time-sensitive and requires knowledge updates and new labels per
the rapid software and hardware improvement lifecycle. To handle these issues,
we introduce Ticket- BERT which trains a simple yet robust language model for
labeling tickets using our proposed ticket datasets. Experiments demonstrate
the superiority of Ticket-BERT over baselines and state-of-the-art text
classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT
with an active learning cycle and deploy it on the Microsoft IcM system, which
enables the model to quickly finetune on newly-collected tickets with a few
annotations.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Distance Functions and Normalization Under Stream Scenarios</b></summary>
  <p><b>编号</b>：[450]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00106</p>
  <p><b>作者</b>：Eduardo V. L. Barboza,  Paulo R. Lisboa de Almeida,  Alceu de Souza Britto Jr,  Rafael M. O. Cruz</p>
  <p><b>备注</b>：Paper accepted to the 2022 International Joint Conference on Neural Networks</p>
  <p><b>关键词</b>：classification system, essential task, task when modeling, modeling a classification, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data normalization is an essential task when modeling a classification
system. When dealing with data streams, data normalization becomes especially
challenging since we may not know in advance the properties of the features,
such as their minimum/maximum values, and these properties may change over
time. We compare the accuracies generated by eight well-known distance
functions in data streams without normalization, normalized considering the
statistics of the first batch of data received, and considering the previous
batch received. We argue that experimental protocols for streams that consider
the full stream as normalized are unrealistic and can lead to biased and poor
results. Our results indicate that using the original data stream without
applying normalization, and the Canberra distance, can be a good combination
when no information about the data stream is known beforehand.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns  Captured by Unmanned Aerial Systems</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00104</p>
  <p><b>作者</b>：Uma Meleti,  Abolfazl Razi</p>
  <p><b>备注</b>：6 pages, 6 figures</p>
  <p><b>关键词</b>：research paper addresses, covered by trees, natural barriers, detecting obscured wildfires, research paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research paper addresses the challenge of detecting obscured wildfires
(when the fire flames are covered by trees, smoke, clouds, and other natural
barriers) in real-time using drones equipped only with RGB cameras. We propose
a novel methodology that employs semantic segmentation based on the temporal
analysis of smoke patterns in video sequences. Our approach utilizes an
encoder-decoder architecture based on deep convolutional neural network
architecture with a pre-trained CNN encoder and 3D convolutions for decoding
while using sequential stacking of features to exploit temporal variations. The
predicted fire locations can assist drones in effectively combating forest
fires and pinpoint fire retardant chemical drop on exact flame locations. We
applied our method to a curated dataset derived from the FLAME2 dataset that
includes RGB video along with IR video to determine the ground truth. Our
proposed method has a unique property of detecting obscured fire and achieves a
Dice score of 85.88%, while achieving a high precision of 92.47% and
classification accuracy of 90.67% on test data showing promising results when
inspected visually. Indeed, our method outperforms other methods by a
significant margin in terms of video-level fire classification as we obtained
about 100% accuracy using MobileNet+CBAM as the encoder backbone.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Redeeming Data Science by Decision Modelling</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00088</p>
  <p><b>作者</b>：John Mark Agosta,  Robert Horton</p>
  <p><b>备注</b>：Accepted for the 16th Bayesian Modelling Applications Workshop (@UAI2022) (BMAW 2022)</p>
  <p><b>关键词</b>：Data Science, applications of Data, explosion of applications, practice of Data, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the explosion of applications of Data Science, the field is has come
loose from its foundations. This article argues for a new program of applied
research in areas familiar to researchers in Bayesian methods in AI that are
needed to ground the practice of Data Science by borrowing from AI techniques
for model formulation that we term ``Decision Modelling.'' This article briefly
reviews the formulation process as building a causal graphical model, then
discusses the process in terms of six principles that comprise \emph{Decision
Quality}, a framework from the popular business literature. We claim that any
successful applied ML modelling effort must include these six principles.
We explain how Decision Modelling combines a conventional machine learning
model with an explicit value model. To give a specific example we show how this
is done by integrating a model's ROC curve with a utility model.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Inter-case Predictive Process Monitoring: A candidate for Quantum  Machine Learning?</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00080</p>
  <p><b>作者</b>：Stefan Hill,  David Fitzek,  Patrick Delfmann,  Carl Corea</p>
  <p><b>备注</b>：17 pages, 6 figures, 5 appendixes</p>
  <p><b>关键词</b>：multiple instances interact, running process instance, instances interact, multiple instances, Predictive Process Monitoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regardless of the domain, forecasting the future behaviour of a running
process instance is a question of interest for decision makers, especially when
multiple instances interact. Fostered by the recent advances in machine
learning research, several methods have been proposed to predict the next
activity, outcome or remaining time of a process automatically. Still, building
a model with high predictive power requires both - intrinsic knowledge of how
to extract meaningful features from the event log data and a model that
captures complex patterns in data. This work builds upon the recent progress in
inter-case Predictive Process Monitoring (PPM) and comprehensively benchmarks
the impact of inter-case features on prediction accuracy. Moreover, it includes
quantum machine learning models, which are expected to provide an advantage
over classical models with a scaling amount of feature dimensions. The
evaluation on real-world training data from the BPI challenge shows that the
inter-case features provide a significant boost by more than four percent in
accuracy and quantum algorithms are indeed competitive in a handful of feature
configurations. Yet, as quantum hardware is still in its early stages of
development, this paper critically discusses these findings in the light of
runtime, noise and the risk to overfit on the training data. Finally, the
implementation of an open-source plugin demonstrates the technical feasibility
to connect a state-of-the-art workflow engine such as Camunda to an IBM quantum
computing cloud service.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Dataset balancing can hurt model performance</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00079</p>
  <p><b>作者</b>：R. Channing Moore,  Daniel P. W. Ellis,  Eduardo Fonseca,  Shawn Hershey,  Aren Jansen,  Manoj Plakal</p>
  <p><b>备注</b>：5 pages, 3 figures, ICASSP 2023</p>
  <p><b>关键词</b>：performance, Machine learning, learning from training, skewed distribution, lead to models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning from training data with a skewed distribution of examples
per class can lead to models that favor performance on common classes at the
expense of performance on rare ones. AudioSet has a very wide range of priors
over its 527 sound event classes. Classification performance on AudioSet is
usually evaluated by a simple average over per-class metrics, meaning that
performance on rare classes is equal in importance to the performance on common
ones. Several recent papers have used dataset balancing techniques to improve
performance on AudioSet. We find, however, that while balancing improves
performance on the public AudioSet evaluation data it simultaneously hurts
performance on an unpublished evaluation set collected under the same
conditions. By varying the degree of balancing, we show that its benefits are
fragile and depend on the evaluation set. We also do not find evidence
indicating that balancing improves rare class performance relative to common
classes. We therefore caution against blind application of balancing, as well
as against paying too much attention to small improvements on a public
evaluation set.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Transformers in Healthcare: A Survey</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00067</p>
  <p><b>作者</b>：Subhash Nerella,  Sabyasachi Bandyopadhyay,  Jiaqing Zhang,  Miguel Contreras,  Scott Siegel,  Aysegul Bumin,  Brandon Silva,  Jessica Sena,  Benjamin Shickel,  Azra Bihorac,  Kia Khezeli,  Parisa Rashidi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, Transformers neural network, neural network architecture, increasingly permeating, aspects of society</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With Artificial Intelligence (AI) increasingly permeating various aspects of
society, including healthcare, the adoption of the Transformers neural network
architecture is rapidly changing many applications. Transformer is a type of
deep learning architecture initially developed to solve general-purpose Natural
Language Processing (NLP) tasks and has subsequently been adapted in many
fields, including healthcare. In this survey paper, we provide an overview of
how this architecture has been adopted to analyze various forms of data,
including medical imaging, structured and unstructured Electronic Health
Records (EHR), social media, physiological signals, and biomolecular sequences.
Those models could help in clinical diagnosis, report generation, data
reconstruction, and drug/protein synthesis. We identified relevant studies
using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) guidelines. We also discuss the benefits and limitations of using
transformers in healthcare and examine issues such as computational cost, model
interpretability, fairness, alignment with human values, ethical implications,
and environmental impact.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：Improving the Transferability of Time Series Forecasting with  Decomposition Adaptation</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00066</p>
  <p><b>作者</b>：Yan Gao,  Yan Wang,  Qiang Wang</p>
  <p><b>备注</b>：15 pages, 7 figures</p>
  <p><b>关键词</b>：achieved great progress, effective pattern mining, neural forecasting models, forecasting models based, great progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to effective pattern mining and feature representation, neural
forecasting models based on deep learning have achieved great progress. The
premise of effective learning is to collect sufficient data. However, in time
series forecasting, it is difficult to obtain enough data, which limits the
performance of neural forecasting models. To alleviate the data scarcity
limitation, we design Sequence Decomposition Adaptation Network (SeDAN) which
is a novel transfer architecture to improve forecasting performance on the
target domain by aligning transferable knowledge from cross-domain datasets.
Rethinking the transferability of features in time series data, we propose
Implicit Contrastive Decomposition to decompose the original features into
components including seasonal and trend features, which are easier to transfer.
Then we design the corresponding adaptation methods for decomposed features in
different domains. Specifically, for seasonal features, we perform joint
distribution adaptation and for trend features, we design an Optimal Local
Adaptation. We conduct extensive experiments on five benchmark datasets for
multivariate time series forecasting. The results demonstrate the effectiveness
of our SeDAN. It can provide more efficient and stable knowledge transfer.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Towards Brain Inspired Design for Addressing the Shortcomings of ANNs</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00039</p>
  <p><b>作者</b>：Fahad Sarfraz,  Elahe Arani,  Bahram Zonooz</p>
  <p><b>备注</b>：11 pages, 7 figures, and 4 tables</p>
  <p><b>关键词</b>：function is enhanced, deserves further consideration, insights gained, algorithms deserves, recent neuroscience study</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As our understanding of the mechanisms of brain function is enhanced, the
value of insights gained from neuroscience to the development of AI algorithms
deserves further consideration. Here, we draw parallels with an existing
tree-based ANN architecture and a recent neuroscience study[27] arguing that
the error-based organization of neurons in the cerebellum that share a
preference for a personalized view of the entire error space, may account for
several desirable features of behavior and learning. We then analyze the
learning behavior and characteristics of the model under varying scenarios to
gauge the potential benefits of a similar mechanism in ANN. Our empirical
results suggest that having separate populations of neurons with personalized
error views can enable efficient learning under class imbalance and limited
data, and reduce the susceptibility to unintended shortcut strategies, leading
to improved generalization. This work highlights the potential of translating
the learning machinery of the brain into the design of a new generation of ANNs
and provides further credence to the argument that biologically inspired AI may
hold the key to overcoming the shortcomings of ANNs.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：Machine learning for potion development at Hogwarts</b></summary>
  <p><b>编号</b>：[471]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00036</p>
  <p><b>作者</b>：Christoph F. Kurz,  Adriana N. König</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：School of Witchcraft, Hogwarts School, recipes, Harry Potter Wiki, Hogwarts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective: To determine whether machine learning methods can generate useful
potion recipes for research and teaching at Hogwarts School of Witchcraft and
Wizardry. Design: Using deep neural networks to classify generated recipes into
a standard drug classification system. Setting: Hogwarts School of Witchcraft
and Wizardry. Data sources: 72 potion recipes from the Hogwarts curriculum,
extracted from the Harry Potter Wiki. Results: Most generated recipes fall into
the categories of psychoanaleptics and dermatologicals. The number of recipes
predicted for each category reflected the number of training recipes. Predicted
probabilities were often above 90% but some recipes were classified into 2 or
more categories with similar probabilities which complicates anticipating the
predicted effects. Conclusions: Machine learning powered methods are able to
generate potentially useful potion recipes for teaching and research at
Hogwarts. This corresponds to similar efforts in the non-magical world where
such methods have been applied to identify potentially effective drug
combinations.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Parameter Identification for Partial Differential Equations with  Spatiotemporal Varying Coefficients</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00035</p>
  <p><b>作者</b>：Guangtao Zhang,  Yiting Duan,  Guanyu Pan,  Qijing Chen,  Huiyu Yang,  Zhikun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple states, comprehend complex systems, imperative to reveal, reveal the identity, system outputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To comprehend complex systems with multiple states, it is imperative to
reveal the identity of these states by system outputs. Nevertheless, the
mathematical models describing these systems often exhibit nonlinearity so that
render the resolution of the parameter inverse problem from the observed
spatiotemporal data a challenging endeavor. Starting from the observed data
obtained from such systems, we propose a novel framework that facilitates the
investigation of parameter identification for multi-state systems governed by
spatiotemporal varying parametric partial differential equations. Our framework
consists of two integral components: a constrained self-adaptive
physics-informed neural network, encompassing a sub-network, as our methodology
for parameter identification, and a finite mixture model approach to detect
regions of probable parameter variations. Through our scheme, we can precisely
ascertain the unknown varying parameters of the complex multi-state system,
thereby accomplishing the inversion of the varying parameters. Furthermore, we
have showcased the efficacy of our framework on two numerical cases: the 1D
Burgers' equation with time-varying parameters and the 2D wave equation with a
space-varying parameter.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：Seeing in Words: Learning to Classify through Language Bottlenecks</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00028</p>
  <p><b>作者</b>：Khalid Saifullah,  Yuxin Wen,  Jonas Geiping,  Micah Goldblum,  Tom Goldstein</p>
  <p><b>备注</b>：5 pages, 2 figures, Published as a Tiny Paper at ICLR 2023</p>
  <p><b>关键词</b>：achieving high accuracy, computer vision extract, vision extract uninterpretable, extract uninterpretable features, accuracy on benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks for computer vision extract uninterpretable features despite
achieving high accuracy on benchmarks. In contrast, humans can explain their
predictions using succinct and intuitive descriptions. To incorporate
explainability into neural networks, we train a vision model whose feature
representations are text. We show that such a model can effectively classify
ImageNet images, and we discuss the challenges we encountered when training it.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Inertial Navigation Meets Deep Learning: A Survey of Current Trends and  Future Directions</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00014</p>
  <p><b>作者</b>：Nadav Cohen,  Itzik Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications and platforms, deep learning, Inertial sensing, learning, Inertial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inertial sensing is used in many applications and platforms, ranging from
day-to-day devices such as smartphones to very complex ones such as autonomous
vehicles. In recent years, the development of machine learning and deep
learning techniques has increased significantly in the field of inertial
sensing. This is due to the development of efficient computing hardware and the
accessibility of publicly available sensor data. These data-driven approaches
are used to empower model-based navigation and sensor fusion algorithms. This
paper provides an in-depth review of those deep learning methods. We examine
separately, each vehicle operation domain including land, air, and sea. Each
domain is divided into pure inertial advances and improvements based on filter
parameters learning. In addition, we review deep learning approaches for
calibrating and denoising inertial sensors. Throughout the paper, we discuss
these trends and future directions. We also provide statistics on the commonly
used approaches to illustrate their efficiency and stimulate further research
in deep learning embedded in inertial navigation and fusion.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：Black-Box Prediction of Flaky Test Fix Categories Using Language Models</b></summary>
  <p><b>编号</b>：[478]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00012</p>
  <p><b>作者</b>：Sakina Fatima,  Hadi Hemmati,  Lionel Briand</p>
  <p><b>备注</b>：12 pages, 8 Figures</p>
  <p><b>关键词</b>：wasting developer time, causing confusion, non-deterministically pass, pass or fail, software version</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Flaky tests are problematic because they non-deterministically pass or fail
for the same software version under test, causing confusion and wasting
developer time. While machine learning models have been used to predict
flakiness and its root causes, there is less work on providing support to fix
the problem. To address this gap, we propose a framework that automatically
generates labeled datasets for 13 fix categories and train models to predict
the fix category of a flaky test by analyzing the test code only. Though it is
unrealistic at this stage to accurately predict the fix itself, the categories
provide precise guidance about what part of the test code to look at. Our
approach is based on language models, namely CodeBERT and UniXcoder, whose
output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese
Network-based Few Shot Learning (FSL). Our experimental results show that
UniXcoder outperforms CodeBERT, in correctly predicting most of the categories
of fixes a developer should apply. Furthermore, FSL does not appear to have any
significant effect. Given the high accuracy obtained for most fix categories,
our proposed framework has the potential to help developers to fix flaky tests
quickly and this http URL aid future research, we make our automated labeling
tool, dataset, prediction models, and experimental infrastructure publicly
available.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Automated Assignment and Classification of Software Issues</b></summary>
  <p><b>编号</b>：[479]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00009</p>
  <p><b>作者</b>：Büşra Tabak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：team members, work to fix, improve or create, relevant team member, units of work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software issues contain units of work to fix, improve or create new threads
during the development and facilitate communication among the team members.
Assigning an issue to the most relevant team member and determining a category
of an issue is a tedious and challenging task. Wrong classifications cause
delays and rework in the project and trouble among the team members. This
thesis proposes a set of carefully curated linguistic features for shallow
machine learning methods and compares the performance of shallow and ensemble
methods with deep language models. Unlike the state-of-the-art, we assign
issues to four roles (designer, developer, tester, and leader) rather than to
specific individuals or teams to contribute to the generality of our solution.
We also consider the level of experience of the developers to reflect the
industrial practices in our solution formulation. We employ a classification
approach to categorize issues into distinct classes, namely bug, new feature,
improvement, and other. Additionally, we endeavor to further classify bugs
based on the specific type of modification required. We collect and annotate
five industrial data sets from one of the top three global television producers
to evaluate our proposal and compare it with deep language models. Our data
sets contain 5324 issues in total. We show that an ensemble classifier of
shallow techniques achieves 0.92 for issue assignment and 0.90 for issue
classification in accuracy which is statistically comparable to the
state-of-the-art deep language models. The contributions include the public
sharing of five annotated industrial issue data sets, the development of a
clear and comprehensive feature set, the introduction of a novel label set and
the validation of the efficacy of an ensemble classifier of shallow machine
learning techniques.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Fitting an ellipsoid to a quadratic number of random points</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01181</p>
  <p><b>作者</b>：Afonso S. Bandeira,  Antoine Maillard,  Shahar Mendelson,  Elliot Paquette</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：standard Gaussian random, standard Gaussian, Gaussian random vectors, mathrm, Gaussian random</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem $(\mathrm{P})$ of fitting $n$ standard Gaussian
random vectors in $\mathbb{R}^d$ to the boundary of a centered ellipsoid, as
$n, d \to \infty$. This problem is conjectured to have a sharp feasibility
transition: for any $\varepsilon > 0$, if $n \leq (1 - \varepsilon) d^2 / 4$
then $(\mathrm{P})$ has a solution with high probability, while $(\mathrm{P})$
has no solutions with high probability if $n \geq (1 + \varepsilon) d^2 /4$. So
far, only a trivial bound $n \geq d^2 / 2$ is known on the negative side, while
the best results on the positive side assume $n \leq d^2 /
\mathrm{polylog}(d)$. In this work, we improve over previous approaches using a
key result of Bartl & Mendelson on the concentration of Gram matrices of random
vectors under mild assumptions on their tail behavior. This allows us to give a
simple proof that $(\mathrm{P})$ is feasible with high probability when $n \leq
d^2 / C$, for a (possibly large) constant $C > 0$.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Quantum Neural Estimation of Entropies</b></summary>
  <p><b>编号</b>：[482]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01171</p>
  <p><b>作者</b>：Ziv Goldfeld,  Dhrumil Patel,  Sreejith Sreekumar,  Mark M. Wilde</p>
  <p><b>备注</b>：11 pages, 1 figure; see also independent work of Shin, Lee, and Jeong at arXiv:2306.14566v1</p>
  <p><b>关键词</b>：Entropy measures quantify, Entropy measures, quantify the amount, amount of information, information and correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entropy measures quantify the amount of information and correlations present
in a quantum system. In practice, when the quantum state is unknown and only
copies thereof are available, one must resort to the estimation of such entropy
measures. Here we propose a variational quantum algorithm for estimating the
von Neumann and Rényi entropies, as well as the measured relative entropy and
measured Rényi relative entropy. Our approach first parameterizes a
variational formula for the measure of interest by a quantum circuit and a
classical neural network, and then optimizes the resulting objective over
parameter space. Numerical simulations of our quantum algorithm are provided,
using a noiseless quantum simulator. The algorithm provides accurate estimates
of the various entropy measures for the examples tested, which renders it as a
promising approach for usage in downstream tasks.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：Analyzing and Improving Greedy 2-Coordinate Updates for  Equality-Constrained Optimization via Steepest Descent in the 1-Norm</b></summary>
  <p><b>编号</b>：[483]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01169</p>
  <p><b>作者</b>：Amrutha Varshini Ramesh,  Aaron Mishkin,  Mark Schmidt,  Yihan Zhou,  Jonathan Wilder Lavington,  Jennifer She</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smooth function subject, smooth function, function subject, summation constraint, steepest descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider minimizing a smooth function subject to a summation constraint
over its variables. By exploiting a connection between the greedy 2-coordinate
update for this problem and equality-constrained steepest descent in the
1-norm, we give a convergence rate for greedy selection under a proximal
Polyak-Lojasiewicz assumption that is faster than random selection and
independent of the problem dimension $n$. We then consider minimizing with both
a summation constraint and bound constraints, as arises in the support vector
machine dual problem. Existing greedy rules for this setting either guarantee
trivial progress only or require $O(n^2)$ time to compute. We show that bound-
and summation-constrained steepest descent in the L1-norm guarantees more
progress per iteration than previous rules and can be computed in only $O(n
\log n)$ time.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Sampling the lattice Nambu-Goto string using Continuous Normalizing  Flows</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01107</p>
  <p><b>作者</b>：Michele Caselle,  Elia Cellini,  Alessandro Nada</p>
  <p><b>备注</b>：1+28 pages, 11 figures</p>
  <p><b>关键词</b>：Effective String Theory, confining flux tube, thin vibrating string, powerful non-perturbative approach, Yang-Mills theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Effective String Theory (EST) represents a powerful non-perturbative approach
to describe confinement in Yang-Mills theory that models the confining flux
tube as a thin vibrating string. EST calculations are usually performed using
the zeta-function regularization: however there are situations (for instance
the study of the shape of the flux tube or of the higher order corrections
beyond the Nambu-Goto EST) which involve observables that are too complex to be
addressed in this way. In this paper we propose a numerical approach based on
recent advances in machine learning methods to circumvent this problem. Using
as a laboratory the Nambu-Goto string, we show that by using a new class of
deep generative models called Continuous Normalizing Flows it is possible to
obtain reliable numerical estimates of EST predictions.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：Streamlined Lensed Quasar Identification in Multiband Images via  Ensemble Networks</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01090</p>
  <p><b>作者</b>：Irham Taufik Andika,  Sherry H. Suyu,  Raoul Cañameras,  Alejandra Melo,  Stefan Schuldt,  Yiping Shu,  Anna-Christina Eilers,  Anton Timur Jaelani,  Minghao Yue</p>
  <p><b>备注</b>：Submitted to the Astronomy & Astrophysics journal. 25 pages, 11 figures, and 3 tables. We welcome comments from the reader</p>
  <p><b>关键词</b>：lensing offer unique, offer unique viewpoints, dark matter profile, quasar host galaxies, cosmic expansion rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quasars experiencing strong lensing offer unique viewpoints on subjects like
the cosmic expansion rate, the dark matter profile within the foreground
deflectors, and the quasar host galaxies. Unfortunately, identifying them in
astronomical images is challenging since they are overwhelmed by the abundance
of non-lenses. To address this, we have developed a novel approach by
ensembling cutting-edge convolutional networks (CNNs) -- i.e., ResNet,
Inception, NASNet, MobileNet, EfficientNet, and RegNet -- along with vision
transformers (ViTs) trained on realistic galaxy-quasar lens simulations based
on the Hyper Suprime-Cam (HSC) multiband images. While the individual model
exhibits remarkable performance when evaluated against the test dataset,
achieving an area under the receiver operating characteristic curve of $>$97.4%
and a median false positive rate of 3.1%, it struggles to generalize in real
data, indicated by numerous spurious sources picked by each classifier. A
significant improvement is achieved by averaging these CNNs and ViTs, resulting
in the impurities being downsized by factors up to 40. Subsequently, combining
the HSC images with the UKIRT, VISTA, and unWISE data, we retrieve
approximately 60 million sources as parent samples and reduce this to 892,609
after employing a photometry preselection to discover $z>1.5$ lensed quasars
with Einstein radii of $\theta_\mathrm{E}<5$ 161 3991 arcsec. afterward, the ensemble classifier indicates sources with a high probability of being lenses, for which we visually inspect, yielding prevailing candidates awaiting spectroscopic confirmation. these outcomes suggest that automated deep learning pipelines hold great potential in effectively detecting strong lenses vast datasets minimal manual visual inspection involved.< p>
  </5$></p></details>
</details>
<details>
  <summary>164. <b>标题：Supervised Manifold Learning via Random Forest Geometry-Preserving  Proximities</b></summary>
  <p><b>编号</b>：[488]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01077</p>
  <p><b>作者</b>：Jake S. Rhodes</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：seek the intrinsic, high-dimensional space, Manifold learning, Diffusion Map, learning approaches seek</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manifold learning approaches seek the intrinsic, low-dimensional data
structure within a high-dimensional space. Mainstream manifold learning
algorithms, such as Isomap, UMAP, $t$-SNE, Diffusion Map, and Laplacian
Eigenmaps do not use data labels and are thus considered unsupervised. Existing
supervised extensions of these methods are limited to classification problems
and fall short of uncovering meaningful embeddings due to their construction
using order non-preserving, class-conditional distances. In this paper, we show
the weaknesses of class-conditional manifold learning quantitatively and
visually and propose an alternate choice of kernel for supervised
dimensionality reduction using a data-geometry-preserving variant of random
forest proximities as an initialization for manifold learning methods. We show
that local structure preservation using these proximities is near universal
across manifold learning approaches and global structure is properly maintained
using diffusion-based algorithms.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：A versatile deep learning-based protein-ligand interaction prediction  model for accurate binding affinity scoring and virtual screening</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01066</p>
  <p><b>作者</b>：Seokhyun Moon,  Sang-Yeon Hwang,  Jaechang Lim,  Woo Youn Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learning-based PLI prediction, PLI prediction, deep learning-based PLI, PLI prediction models, target proteins</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Protein--ligand interaction (PLI) prediction is critical in drug discovery,
aiding the identification and enhancement of molecules that effectively bind to
target proteins. Despite recent advances in deep learning-based PLI prediction,
developing a versatile model capable of accurate binding affinity scoring and
virtual screening in PLI prediction is an ongoing challenge. This is primarily
due to the lack of structure--affinity data, resulting in low model
generalization ability. We here propose a viable solution to this challenge by
introducing a novel data augmentation strategy along with a physics-informed
neural network. The resulting model exhibits significant improvement in both
scoring and screening capabilities. Its performance was compared to
task-specific deep learning-based PLI prediction models, confirming its
versatility. Notably, it even outperformed computationally expensive molecular
dynamics simulations as well as the other deep learning models in a derivative
benchmark while maintaining sufficiently high performance in virtual screening.
This underscores the potential of this approach in drug discovery,
demonstrating its applicability to both binding affinity scoring and virtual
screening.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：Transport, Variational Inference and Diffusions: with Applications to  Annealed Flows and Schrödinger Bridges</b></summary>
  <p><b>编号</b>：[491]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01050</p>
  <p><b>作者</b>：Francisco Vargas,  Nikolas Nüsken</p>
  <p><b>备注</b>：Workshop on New Frontiers in Learning, Control, and Dynamical Systems at the International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA, 2023</p>
  <p><b>关键词</b>：Girsanov transformations.We present, reverse time stochastic, time stochastic differential, stochastic differential equations, generative modelling centred</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the connections between optimal transport and variational
inference, with a focus on forward and reverse time stochastic differential
equations and Girsanov transformations.We present a principled and systematic
framework for sampling and generative modelling centred around divergences on
path space. Our work culminates in the development of a novel score-based
annealed flow technique (with connections to Jarzynski and Crooks identities
from statistical physics) and a regularised iterative proportional fitting
(IPF)-type objective, departing from the sequential nature of standard IPF.
Through a series of generative modelling examples and a double-well-based rare
event task, we showcase the potential of the proposed methods.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Vector Quantile Regression on Manifolds</b></summary>
  <p><b>编号</b>：[493]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01037</p>
  <p><b>作者</b>：Marco Pegoraro,  Sanketh Vedula,  Aviv A. Rosenberg,  Irene Tallini,  Emanuele Rodolà,  Alex M. Bronstein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explanatory features, statistical tool, tool for distribution-free, Euclidean domain, distribution-free estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantile regression (QR) is a statistical tool for distribution-free
estimation of conditional quantiles of a target variable given explanatory
features. QR is limited by the assumption that the target distribution is
univariate and defined on an Euclidean domain. Although the notion of quantiles
was recently extended to multi-variate distributions, QR for multi-variate
distributions on manifolds remains underexplored, even though many important
applications inherently involve data distributed on, e.g., spheres (climate
measurements), tori (dihedral angles in proteins), or Lie groups (attitude in
navigation). By leveraging optimal transport theory and the notion of
$c$-concave functions, we meaningfully define conditional vector quantile
functions of high-dimensional variables on manifolds (M-CVQFs). Our approach
allows for quantile estimation, regression, and computation of conditional
confidence sets. We demonstrate the approach's efficacy and provide insights
regarding the meaning of non-Euclidean quantiles through preliminary synthetic
data experiments.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Pareto optimal proxy metrics</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01000</p>
  <p><b>作者</b>：Lee Richardson,  Alessandro Zito,  Dylan Greaves,  Jacopo Soriano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：north star metric, North star, online experimentation play, technology companies improve, star metric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>North star metrics and online experimentation play a central role in how
technology companies improve their products. In many practical settings,
however, evaluating experiments based on the north star metric directly can be
difficult. The two most significant issues are 1) low sensitivity of the north
star metric and 2) differences between the short-term and long-term impact on
the north star metric. A common solution is to rely on proxy metrics rather
than the north star in experiment evaluation and launch decisions. Existing
literature on proxy metrics concentrates mainly on the estimation of the
long-term impact from short-term experimental data. In this paper, instead, we
focus on the trade-off between the estimation of the long-term impact and the
sensitivity in the short term. In particular, we propose the Pareto optimal
proxy metrics method, which simultaneously optimizes prediction accuracy and
sensitivity. In addition, we give an efficient multi-objective optimization
algorithm that outperforms standard methods. We applied our methodology to
experiments from a large industrial recommendation system, and found proxy
metrics that are eight times more sensitive than the north star and
consistently moved in the same direction, increasing the velocity and the
quality of the decisions to launch new features.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：Environmental effects on emergent strategy in micro-scale multi-agent  reinforcement learning</b></summary>
  <p><b>编号</b>：[495]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00994</p>
  <p><b>作者</b>：Samuel Tovey,  David Zimmer,  Christoph Lohrmann,  Tobias Merkt,  Simon Koppenhoefer,  Veit-Lorenz Heuthe,  Clemens Bechinger,  Christian Holm</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：realizing efficient control, promising candidate, candidate for realizing, realizing efficient, efficient control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Agent Reinforcement Learning (MARL) is a promising candidate for
realizing efficient control of microscopic particles, of which micro-robots are
a subset. However, the microscopic particles' environment presents unique
challenges, such as Brownian motion at sufficiently small length-scales. In
this work, we explore the role of temperature in the emergence and efficacy of
strategies in MARL systems using particle-based Langevin molecular dynamics
simulations as a realistic representation of micro-scale environments. To this
end, we perform experiments on two different multi-agent tasks in microscopic
environments at different temperatures, detecting the source of a concentration
gradient and rotation of a rod. We find that at higher temperatures, the RL
agents identify new strategies for achieving these tasks, highlighting the
importance of understanding this regime and providing insight into optimal
training strategies for bridging the generalization gap between simulation and
reality. We also introduce a novel Python package for studying microscopic
agents using reinforcement learning (RL) to accompany our results.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：Over-The-Air Federated Learning: Status Quo, Open Challenges, and Future  Directions</b></summary>
  <p><b>编号</b>：[496]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00974</p>
  <p><b>作者</b>：Bingnan Xiao,  Xichen Yu,  Wei Ni,  Xin Wang,  H. Vincent Poor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：wireless networks, applications based, based on artificial, artificial intelligence, intelligence and implemented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of applications based on artificial intelligence and
implemented over wireless networks is increasingly rapidly and is expected to
grow dramatically in the future. The resulting demand for the aggregation of
large amounts of data has caused serious communication bottlenecks in wireless
networks and particularly at the network edge. Over-the-air federated learning
(OTA-FL), leveraging the superposition feature of multi-access channels (MACs),
enables users at the network edge to share spectrum resources and achieves
efficient and low-latency global model aggregation. This paper provides a
holistic review of progress in OTA-FL and points to potential future research
directions. Specifically, we classify OTA-FL from the perspective of system
settings, including single-antenna OTA-FL, multi-antenna OTA-FL, and OTA-FL
with the aid of the emerging reconfigurable intelligent surface (RIS)
technology, and the contributions of existing works in these areas are
summarized. Moreover, we discuss the trust, security and privacy aspects of
OTA-FL, and highlight concerns arising from security and privacy. Finally,
challenges and potential research directions are discussed to promote the
future development of OTA-FL in terms of improving system performance,
reliability, and trustworthiness. Specifical challenges to be addressed include
model distortion under channel fading, the ineffective OTA aggregation of local
models trained on substantially unbalanced data, and the limited accessibility
and verifiability of individual local models.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Quantum Machine Learning on Near-Term Quantum Devices: Current State of  Supervised and Unsupervised Techniques for Real-World Applications</b></summary>
  <p><b>编号</b>：[499]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00908</p>
  <p><b>作者</b>：Yaswitha Gujju,  Atsushi Matsuo,  Rudy Raymond</p>
  <p><b>备注</b>：40 pages, 8 figures</p>
  <p><b>关键词</b>：Quantum Machine Learning, quantum, past decade, considerable progress, maximum size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The past decade has seen considerable progress in quantum hardware in terms
of the speed, number of qubits and quantum volume which is defined as the
maximum size of a quantum circuit that can be effectively implemented on a
near-term quantum device. Consequently, there has also been a rise in the
number of works based on the applications of Quantum Machine Learning (QML) on
real hardware to attain quantum advantage over their classical counterparts. In
this survey, our primary focus is on selected supervised and unsupervised
learning applications implemented on quantum hardware, specifically targeting
real-world scenarios. Our survey explores and highlights the current
limitations of QML implementations on quantum hardware. We delve into various
techniques to overcome these limitations, such as encoding techniques, ansatz
structure, error mitigation, and gradient methods. Additionally, we assess the
performance of these QML implementations in comparison to their classical
counterparts. Finally, we conclude our survey with a discussion on the existing
bottlenecks associated with applying QML on real quantum devices and propose
potential solutions for overcoming these challenges in the future.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：Exploring the Multi-modal Demand Dynamics During Transport System  Disruptions</b></summary>
  <p><b>编号</b>：[504]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00877</p>
  <p><b>作者</b>：Ali Shateri Benam,  Angelo Furno,  Nour-Eddin El Faouzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transport systems perturb, systems perturb urban, perturb urban mobility, transport systems, systems perturb</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various forms of disruption in transport systems perturb urban mobility in
different ways. Passengers respond heterogeneously to such disruptive events
based on numerous factors. This study takes a data-driven approach to explore
multi-modal demand dynamics under disruptions. We first develop a methodology
to automatically detect anomalous instances through historical hourly travel
demand data. Then we apply clustering to these anomalous hours to distinguish
various forms of multi-modal demand dynamics occurring during disruptions. Our
study provides a straightforward tool for categorising various passenger
responses to disruptive events in terms of mode choice and paves the way for
predictive analyses on estimating the scope of modal shift under distinct
disruption scenarios.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：MADS: Modulated Auto-Decoding SIREN for time series imputation</b></summary>
  <p><b>编号</b>：[506]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00868</p>
  <p><b>作者</b>：Tom Bamford,  Elizabeth Fons,  Yousef El-Laham,  Svitlana Vyetrenko</p>
  <p><b>备注</b>：8 pages (inc. refs), 1 figure</p>
  <p><b>关键词</b>：potentially significant variability, Time series imputation, series imputation remains, Time series, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series imputation remains a significant challenge across many fields due
to the potentially significant variability in the type of data being modelled.
Whilst traditional imputation methods often impose strong assumptions on the
underlying data generation process, limiting their applicability, researchers
have recently begun to investigate the potential of deep learning for this
task, inspired by the strong performance shown by these models in both
classification and regression problems across a range of applications. In this
work we propose MADS, a novel auto-decoding framework for time series
imputation, built upon implicit neural representations. Our method leverages
the capabilities of SIRENs for high fidelity reconstruction of signals and
irregular data, and combines it with a hypernetwork architecture which allows
us to generalise by learning a prior over the space of time series. We evaluate
our model on two real-world datasets, and show that it outperforms
state-of-the-art methods for time series imputation. On the human activity
dataset, it improves imputation performance by at least 40%, while on the air
quality dataset it is shown to be competitive across all metrics. When
evaluated on synthetic data, our model results in the best average rank across
different dataset configurations over all baselines.</p>
  </details>
</details>
<details>
  <summary>174. <b>标题：Beyond the Snapshot: Brain Tokenized Graph Transformer for Longitudinal  Brain Functional Connectome Embedding</b></summary>
  <p><b>编号</b>：[507]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00858</p>
  <p><b>作者</b>：Zijian Dong,  Yilei Wu,  Yu Xiao,  Joanna Su Xian Chong,  Yueming Jin,  Juan Helen Zhou</p>
  <p><b>备注</b>：MICCAI 2023</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, based Graph Neural, brain functional connectome, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Under the framework of network-based neurodegeneration, brain functional
connectome (FC)-based Graph Neural Networks (GNN) have emerged as a valuable
tool for the diagnosis and prognosis of neurodegenerative diseases such as
Alzheimer's disease (AD). However, these models are tailored for brain FC at a
single time point instead of characterizing FC trajectory. Discerning how FC
evolves with disease progression, particularly at the predementia stages such
as cognitively normal individuals with amyloid deposition or individuals with
mild cognitive impairment (MCI), is crucial for delineating disease spreading
patterns and developing effective strategies to slow down or even halt disease
advancement. In this work, we proposed the first interpretable framework for
brain FC trajectory embedding with application to neurodegenerative disease
diagnosis and prognosis, namely Brain Tokenized Graph Transformer (Brain
TokenGT). It consists of two modules: 1) Graph Invariant and Variant Embedding
(GIVE) for generation of node and spatio-temporal edge embeddings, which were
tokenized for downstream processing; 2) Brain Informed Graph Transformer
Readout (BIGTR) which augments previous tokens with trainable type identifiers
and non-trainable node identifiers and feeds them into a standard transformer
encoder to readout. We conducted extensive experiments on two public
longitudinal fMRI datasets of the AD continuum for three tasks, including
differentiating MCI from controls, predicting dementia conversion in MCI, and
classification of amyloid positive or negative cognitively normal individuals.
Based on brain FC trajectory, the proposed Brain TokenGT approach outperformed
all the other benchmark models and at the same time provided excellent
interpretability. The code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：Trading-Off Payments and Accuracy in Online Classification with Paid  Stochastic Experts</b></summary>
  <p><b>编号</b>：[508]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00836</p>
  <p><b>作者</b>：Dirk van der Hoeven,  Ciara Pike-Burke,  Hao Qiu,  Nicolo Cesa-Bianchi</p>
  <p><b>备注</b>：ICML 2023</p>
  <p><b>关键词</b>：paid stochastic experts, paid stochastic, investigate online classification, stochastic experts, experts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate online classification with paid stochastic experts. Here,
before making their prediction, each expert must be paid. The amount that we
pay each expert directly influences the accuracy of their prediction through
some unknown Lipschitz "productivity" function. In each round, the learner must
decide how much to pay each expert and then make a prediction. They incur a
cost equal to a weighted sum of the prediction error and upfront payments for
all experts. We introduce an online learning algorithm whose total cost after
$T$ rounds exceeds that of a predictor which knows the productivity of all
experts in advance by at most $\mathcal{O}(K^2(\log T)\sqrt{T})$ where $K$ is
the number of experts. In order to achieve this result, we combine Lipschitz
bandits and online classification with surrogate losses. These tools allow us
to improve upon the bound of order $T^{2/3}$ one would obtain in the standard
Lipschitz bandit setting. Our algorithm is empirically evaluated on synthetic
data</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Engression: Extrapolation for Nonlinear Regression?</b></summary>
  <p><b>编号</b>：[509]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00835</p>
  <p><b>作者</b>：Xinwei Shen,  Nicolai Meinshausen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning applications, encounter test data, learning applications, statistical and machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extrapolation is crucial in many statistical and machine learning
applications, as it is common to encounter test data outside the training
support. However, extrapolation is a considerable challenge for nonlinear
models. Conventional models typically struggle in this regard: while tree
ensembles provide a constant prediction beyond the support, neural network
predictions tend to become uncontrollable. This work aims at providing a
nonlinear regression methodology whose reliability does not break down
immediately at the boundary of the training support. Our primary contribution
is a new method called `engression' which, at its core, is a distributional
regression technique for pre-additive noise models, where the noise is added to
the covariates before applying a nonlinear transformation. Our experimental
results indicate that this model is typically suitable for many real data sets.
We show that engression can successfully perform extrapolation under some
assumptions such as a strictly monotone function class, whereas traditional
regression approaches such as least-squares regression and quantile regression
fall short under the same assumptions. We establish the advantages of
engression over existing approaches in terms of extrapolation, showing that
engression consistently provides a meaningful improvement. Our empirical
results, from both simulated and real data, validate these findings,
highlighting the effectiveness of the engression method. The software
implementations of engression are available in both R and Python.</p>
  </details>
</details>
<details>
  <summary>177. <b>标题：Monte Carlo Policy Gradient Method for Binary Optimization</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00783</p>
  <p><b>作者</b>：Cheng Chen,  Ruitao Chen,  Tianyou Li,  Ruichen Ao,  Zaiwen Wen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：MIMO detection, combinatorial optimization problems, parameterized policy distribution, binary optimization problems, wide range</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary optimization has a wide range of applications in combinatorial
optimization problems such as MaxCut, MIMO detection, and MaxSAT. However,
these problems are typically NP-hard due to the binary constraints. We develop
a novel probabilistic model to sample the binary solution according to a
parameterized policy distribution. Specifically, minimizing the KL divergence
between the parameterized policy distribution and the Gibbs distributions of
the function value leads to a stochastic optimization problem whose policy
gradient can be derived explicitly similar to reinforcement learning. For
coherent exploration in discrete spaces, parallel Markov Chain Monte Carlo
(MCMC) methods are employed to sample from the policy distribution with
diversity and approximate the gradient efficiently. We further develop a filter
scheme to replace the original objective function by the one with the local
search technique to broaden the horizon of the function landscape. Convergence
to stationary points in expectation of the policy gradient method is
established based on the concentration inequality for MCMC. Numerical results
show that this framework is very promising to provide near-optimal solutions
for quite a few binary optimization problems.</p>
  </details>
</details>
<details>
  <summary>178. <b>标题：On the choice of training data for machine learning of geostrophic  mesoscale turbulence</b></summary>
  <p><b>编号</b>：[512]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00734</p>
  <p><b>作者</b>：F. E. Yan,  J. Mak,  Y. Wang</p>
  <p><b>备注</b>：23 pages, 8 figures</p>
  <p><b>关键词</b>：machine learning algorithms, Earth System Modeling, plays a central, System Modeling related, central role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>'Data' plays a central role in data-driven methods, but is not often the
subject of focus in investigations of machine learning algorithms as applied to
Earth System Modeling related problems. Here we consider the case of eddy-mean
interaction in rotating stratified turbulence in the presence of lateral
boundaries, a problem of relevance to ocean modeling, where the eddy fluxes
contain dynamically inert rotational components that are expected to
contaminate the learning process. An often utilized choice in the literature is
to learn from the divergence of the eddy fluxes. Here we provide theoretical
arguments and numerical evidence that learning from the eddy fluxes with the
rotational component appropriately filtered out results in models with
comparable or better skill, but substantially improved robustness. If we simply
want a data-driven model to have predictive skill then the choice of data
choice and/or quality may not be critical, but we argue it is highly desirable
and perhaps even necessary if we want to leverage data-driven methods to aid in
discovering unknown or hidden physical processes within the data itself.</p>
  </details>
</details>
<details>
  <summary>179. <b>标题：ENN: A Neural Network with DCT-Adaptive Activation Functions</b></summary>
  <p><b>编号</b>：[514]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00673</p>
  <p><b>作者</b>：Marc Martinez-Gost,  Ana Pérez-Neira,  Miguel Ángel Lagunas</p>
  <p><b>备注</b>：Paper submitted to IEEE Journal of Selected Topics in Signal Processing (JSTSP) Special Series on AI in Signal & Data Science - Toward Explainable, Reliable, and Sustainable Machine Learning</p>
  <p><b>关键词</b>：neural networks highly, networks highly depends, Expressive Neural Network, Discrete Cosine Transform, present Expressive Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The expressiveness of neural networks highly depends on the nature of the
activation function, although these are usually assumed predefined and fixed
during the training stage. In this paper we present Expressive Neural Network
(ENN), a novel architecture in which the non-linear activation functions are
modeled using the Discrete Cosine Transform (DCT) and adapted using
backpropagation during training. This parametrization keeps the number of
trainable parameters low, is appropriate for gradient-based schemes, and adapts
to different learning tasks. This is the first non-linear model for activation
functions that relies on a signal processing perspective, providing high
flexibility and expressiveness to the network. We contribute with insights in
the explainability of the network at convergence by recovering the concept of
bump, this is, the response of each activation function in the output space to
provide insights. Finally, through exhaustive experiments we show that the
model can adapt to classification and regression tasks. The performance of ENN
outperforms state of the art benchmarks, providing up to a 40\% gap in accuracy
in some scenarios.</p>
  </details>
</details>
<details>
  <summary>180. <b>标题：Morse Neural Networks for Uncertainty Quantification</b></summary>
  <p><b>编号</b>：[515]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00667</p>
  <p><b>作者</b>：Benoit Dherin,  Huiyi Hu,  Jie Ren,  Michael W. Dusenberry,  Balaji Lakshminarayanan</p>
  <p><b>备注</b>：Accepted to ICML workshop on Structured Probabilistic Inference & Generative Modeling 2023</p>
  <p><b>关键词</b>：Morse neural network, Morse neural, deep generative model, Morse, uncertainty quantification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new deep generative model useful for uncertainty
quantification: the Morse neural network, which generalizes the unnormalized
Gaussian densities to have modes of high-dimensional submanifolds instead of
just discrete points. Fitting the Morse neural network via a KL-divergence loss
yields 1) a (unnormalized) generative density, 2) an OOD detector, 3) a
calibration temperature, 4) a generative sampler, along with in the supervised
case 5) a distance aware-classifier. The Morse network can be used on top of a
pre-trained network to bring distance-aware calibration w.r.t the training
data. Because of its versatility, the Morse neural networks unifies many
techniques: e.g., the Entropic Out-of-Distribution Detector of (Macêdo et
al., 2021) in OOD detection, the one class Deep Support Vector Description
method of (Ruff et al., 2018) in anomaly detection, or the Contrastive One
Class classifier in continuous learning (Sun et al., 2021). The Morse neural
network has connections to support vector machines, kernel methods, and Morse
theory in topology.</p>
  </details>
</details>
<details>
  <summary>181. <b>标题：Mode-wise Principal Subspace Pursuit and Matrix Spiked Covariance Model</b></summary>
  <p><b>编号</b>：[519]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00575</p>
  <p><b>作者</b>：Runshi Tang,  Ming Yuan,  Anru R. Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Mode-wise Principal, Mode-wise Principal Subspace, framework called Mode-wise, Mode-wise Principal, called Mode-wise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a novel framework called Mode-wise Principal Subspace
Pursuit (MOP-UP) to extract hidden variations in both the row and column
dimensions for matrix data. To enhance the understanding of the framework, we
introduce a class of matrix-variate spiked covariance models that serve as
inspiration for the development of the MOP-UP algorithm. The MOP-UP algorithm
consists of two steps: Average Subspace Capture (ASC) and Alternating
Projection (AP). These steps are specifically designed to capture the row-wise
and column-wise dimension-reduced subspaces which contain the most informative
features of the data. ASC utilizes a novel average projection operator as
initialization and achieves exact recovery in the noiseless setting. We analyze
the convergence and non-asymptotic error bounds of MOP-UP, introducing a
blockwise matrix eigenvalue perturbation bound that proves the desired bound,
where classic perturbation bounds fail. The effectiveness and practical merits
of the proposed framework are demonstrated through experiments on both
simulated and real datasets. Lastly, we discuss generalizations of our approach
to higher-order data.</p>
  </details>
</details>
<details>
  <summary>182. <b>标题：SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical  Surface Registration</b></summary>
  <p><b>编号</b>：[522]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00511</p>
  <p><b>作者</b>：Jianxun Ren,  Ning An,  Youjia Zhang,  Danyang Wang,  Zhenyu Sun,  Cong Lin,  Weigang Cui,  Weiwei Wang,  Ying Zhou,  Wei Zhang,  Qingyu Hu,  Ping Zhang,  Dan Hu,  Danhong Wang,  Hesheng Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligning cortical functional, aligning cortical, cortical functional, features across individuals, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cortical surface registration plays a crucial role in aligning cortical
functional and anatomical features across individuals. However, conventional
registration algorithms are computationally inefficient. Recently,
learning-based registration algorithms have emerged as a promising solution,
significantly improving processing efficiency. Nonetheless, there remains a gap
in the development of a learning-based method that exceeds the state-of-the-art
conventional methods simultaneously in computational efficiency, registration
accuracy, and distortion control, despite the theoretically greater
representational capabilities of deep learning approaches. To address the
challenge, we present SUGAR, a unified unsupervised deep-learning framework for
both rigid and non-rigid registration. SUGAR incorporates a U-Net-based
spherical graph attention network and leverages the Euler angle representation
for deformation. In addition to the similarity loss, we introduce fold and
multiple distortion losses, to preserve topology and minimize various types of
distortions. Furthermore, we propose a data augmentation strategy specifically
tailored for spherical surface registration, enhancing the registration
performance. Through extensive evaluation involving over 10,000 scans from 7
diverse datasets, we showed that our framework exhibits comparable or superior
registration performance in accuracy, distortion, and test-retest reliability
compared to conventional and learning-based methods. Additionally, SUGAR
achieves remarkable sub-second processing times, offering a notable speed-up of
approximately 12,000 times in registering 9,000 subjects from the UK Biobank
dataset in just 32 minutes. This combination of high registration performance
and accelerated processing time may greatly benefit large-scale neuroimaging
studies.</p>
  </details>
</details>
<details>
  <summary>183. <b>标题：Optimizing protein fitness using Gibbs sampling with Graph-based  Smoothing</b></summary>
  <p><b>编号</b>：[523]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00494</p>
  <p><b>作者</b>：Andrew Kirjner,  Jason Yim,  Raman Samusevich,  Tommi Jaakkola,  Regina Barzilay,  Ila Fiete</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fields of medicine, higher fitness, proteins with higher, Graph-based Smoothing, combinatorially large space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to design novel proteins with higher fitness on a given task
would be revolutionary for many fields of medicine. However, brute-force search
through the combinatorially large space of sequences is infeasible. Prior
methods constrain search to a small mutational radius from a reference
sequence, but such heuristics drastically limit the design space. Our work
seeks to remove the restriction on mutational distance while enabling efficient
exploration. We propose Gibbs sampling with Graph-based Smoothing (GGS) which
iteratively applies Gibbs with gradients to propose advantageous mutations
using graph-based smoothing to remove noisy gradients that lead to false
positives. Our method is state-of-the-art in discovering high-fitness proteins
with up to 8 mutations from the training set. We study the GFP and AAV design
problems, ablations, and baselines to elucidate the results. Code:
this https URL</p>
  </details>
</details>
<details>
  <summary>184. <b>标题：Pricing European Options with Google AutoML, TensorFlow, and XGBoost</b></summary>
  <p><b>编号</b>：[525]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00476</p>
  <p><b>作者</b>：Juan Esteban Berger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：related machine-learning techniques, Neural Networks, Gradient Boosting Decision, Boosting Decision Trees, Cloud AutoML Regressor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Researchers have been using Neural Networks and other related
machine-learning techniques to price options since the early 1990s. After three
decades of improvements in machine learning techniques, computational
processing power, cloud computing, and data availability, this paper is able to
provide a comparison of using Google Cloud's AutoML Regressor, TensorFlow
Neural Networks, and XGBoost Gradient Boosting Decision Trees for pricing
European Options. All three types of models were able to outperform the Black
Scholes Model in terms of mean absolute error. These results showcase the
potential of using historical data from an option's underlying asset for
pricing European options, especially when using machine learning algorithms
that learn complex patterns that traditional parametric models do not take into
account.</p>
  </details>
</details>
<details>
  <summary>185. <b>标题：Adaptive Algorithms for Relaxed Pareto Set Identification</b></summary>
  <p><b>编号</b>：[528]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00424</p>
  <p><b>作者</b>：Cyrille Kone,  Emilie Kaufmann,  Laura Richert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-armed bandit model, multi-objective multi-armed bandit, Adaptive Pareto Exploration, Pareto set, Pareto Set Identification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we revisit the fixed-confidence identification of the Pareto
optimal set in a multi-objective multi-armed bandit model. As the sample
complexity to identify the exact Pareto set can be very large, a relaxation
allowing to output some additional near-optimal arms has been studied. In this
work we also tackle alternative relaxations that allow instead to identify a
relevant subset of the Pareto set. Notably, we propose a single sampling
strategy, called Adaptive Pareto Exploration, that can be used in conjunction
with different stopping rules to take into account different relaxations of the
Pareto Set Identification problem. We analyze the sample complexity of these
different combinations, quantifying in particular the reduction in sample
complexity that occurs when one seeks to identify at most $k$ Pareto optimal
arms. We showcase the good practical performance of Adaptive Pareto Exploration
on a real-world scenario, in which we adaptively explore several vaccination
strategies against Covid-19 in order to find the optimal ones when multiple
immunogenicity criteria are taken into account.</p>
  </details>
</details>
<details>
  <summary>186. <b>标题：Sparse-Input Neural Network using Group Concave Regularization</b></summary>
  <p><b>编号</b>：[531]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00344</p>
  <p><b>作者</b>：Bin Luo,  Susan Halabi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-linear function estimation, Simultaneous feature selection, feature selection, estimation are challenging, non-linear function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simultaneous feature selection and non-linear function estimation are
challenging, especially in high-dimensional settings where the number of
variables exceeds the available sample size in modeling. In this article, we
investigate the problem of feature selection in neural networks. Although the
group LASSO has been utilized to select variables for learning with neural
networks, it tends to select unimportant variables into the model to compensate
for its over-shrinkage. To overcome this limitation, we propose a framework of
sparse-input neural networks using group concave regularization for feature
selection in both low-dimensional and high-dimensional settings. The main idea
is to apply a proper concave penalty to the $l_2$ norm of weights from all
outgoing connections of each input node, and thus obtain a neural net that only
uses a small subset of the original variables. In addition, we develop an
effective algorithm based on backward path-wise optimization to yield stable
solution paths, in order to tackle the challenge of complex optimization
landscapes. Our extensive simulation studies and real data examples demonstrate
satisfactory finite sample performances of the proposed estimator, in feature
selection and prediction for modeling continuous, binary, and time-to-event
outcomes.</p>
  </details>
</details>
<details>
  <summary>187. <b>标题：Accelerated primal-dual methods with enlarged step sizes and operator  learning for nonsmooth optimal control problems</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00296</p>
  <p><b>作者</b>：Yongcun Song,  Xiaoming Yuan,  Hangrui Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nonsmooth optimal control, nonsmooth objective functionals, partial differential equation, optimal control problems, primal-dual method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a general class of nonsmooth optimal control problems with
partial differential equation (PDE) constraints, which are very challenging due
to its nonsmooth objective functionals and the resulting high-dimensional and
ill-conditioned systems after discretization. We focus on the application of a
primal-dual method, with which different types of variables can be treated
individually and thus its main computation at each iteration only requires
solving two PDEs. Our target is to accelerate the primal-dual method with
either larger step sizes or operator learning techniques. For the accelerated
primal-dual method with larger step sizes, its convergence can be still proved
rigorously while it numerically accelerates the original primal-dual method in
a simple and universal way. For the operator learning acceleration, we
construct deep neural network surrogate models for the involved PDEs. Once a
neural operator is learned, solving a PDE requires only a forward pass of the
neural network, and the computational cost is thus substantially reduced. The
accelerated primal-dual method with operator learning is mesh-free, numerically
efficient, and scalable to different types of PDEs. The acceleration
effectiveness of these two techniques is promisingly validated by some
preliminary numerical results.</p>
  </details>
</details>
<details>
  <summary>188. <b>标题：Safe Screening for Unbalanced Optimal Transport</b></summary>
  <p><b>编号</b>：[534]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00247</p>
  <p><b>作者</b>：Xun Su,  Zhongxi Fang,  Hiroyuki Kasai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unbalanced Optimal Transport, Safe Screening technique, Optimal Transport, Unbalanced Optimal, applying Safe Screening</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a framework that utilizes the Safe Screening technique
to accelerate the optimization process of the Unbalanced Optimal Transport
(UOT) problem by proactively identifying and eliminating zero elements in the
sparse solutions. We demonstrate the feasibility of applying Safe Screening to
the UOT problem with $\ell_2$-penalty and KL-penalty by conducting an analysis
of the solution's bounds and considering the local strong convexity of the dual
problem. Considering the specific structural characteristics of the UOT in
comparison to general Lasso problems on the index matrix, we specifically
propose a novel approximate projection, an elliptical safe region construction,
and a two-hyperplane relaxation method. These enhancements significantly
improve the screening efficiency for the UOT's without altering the algorithm's
complexity.</p>
  </details>
</details>
<details>
  <summary>189. <b>标题：Unified Transfer Learning Models for High-Dimensional Linear Regression</b></summary>
  <p><b>编号</b>：[536]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00238</p>
  <p><b>作者</b>：Shuo Shuo Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern data analysis, Transfer learning plays, target data, data, plays a key</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning plays a key role in modern data analysis when: (1) the
target data are scarce but the source data are sufficient; (2) the
distributions of the source and target data are heterogeneous. This paper
develops an interpretable unified transfer learning model, termed as UTrans,
which can detect both transferable variables and source data. More
specifically, we establish the estimation error bounds and prove that our
bounds are lower than those with target data only. Besides, we propose a source
detection algorithm based on hypothesis testing to exclude the nontransferable
data. We evaluate and compare UTrans to the existing algorithms in multiple
experiments. It is shown that UTrans attains much lower estimation and
prediction errors than the existing methods, while preserving interpretability.
We finally apply it to the US intergenerational mobility data and compare our
proposed algorithms to the classical machine learning algorithms.</p>
  </details>
</details>
<details>
  <summary>190. <b>标题：Causal Structure Learning by Using Intersection of Markov Blankets</b></summary>
  <p><b>编号</b>：[537]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00227</p>
  <p><b>作者</b>：Yiran Dong,  Chuanhou Gao</p>
  <p><b>备注</b>：41 pages, 13 figures</p>
  <p><b>关键词</b>：Markov Blankets Intersection, Exogenous Markov Blankets, Structural Causal Models, causal structure learning, Blankets Intersection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a novel causal structure learning algorithm
called Endogenous and Exogenous Markov Blankets Intersection (EEMBI), which
combines the properties of Bayesian networks and Structural Causal Models
(SCM). Furthermore, we propose an extended version of EEMBI, namely EEMBI-PC,
which integrates the last step of the PC algorithm into EEMBI.</p>
  </details>
</details>
<details>
  <summary>191. <b>标题：A Constructive Approach to Function Realization by Neural Stochastic  Differential Equations</b></summary>
  <p><b>编号</b>：[538]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00215</p>
  <p><b>作者</b>：Tanya Veeravalli,  Maxim Raginsky</p>
  <p><b>备注</b>：6 pages, 1 pdf figure</p>
  <p><b>关键词</b>：sufficiently complex model, top-down manner, typically been approached, arbitrary accuracy, sufficiently complex</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of function approximation by neural dynamical systems has
typically been approached in a top-down manner: Any continuous function can be
approximated to an arbitrary accuracy by a sufficiently complex model with a
given architecture. This can lead to high-complexity controls which are
impractical in applications. In this paper, we take the opposite, constructive
approach: We impose various structural restrictions on system dynamics and
consequently characterize the class of functions that can be realized by such a
system. The systems are implemented as a cascade interconnection of a neural
stochastic differential equation (Neural SDE), a deterministic dynamical
system, and a readout map. Both probabilistic and geometric (Lie-theoretic)
methods are used to characterize the classes of functions realized by such
systems.</p>
  </details>
</details>
<details>
  <summary>192. <b>标题：VoxWatch: An open-set speaker recognition benchmark on VoxCeleb</b></summary>
  <p><b>编号</b>：[540]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00169</p>
  <p><b>作者</b>：Raghuveer Peri,  Seyed Omid Sadjadi,  Daniel Garcia-Romero</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：recognition community compared, open-set speaker identification, speaker recognition community, broad practical applications, fraud prevention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite its broad practical applications such as in fraud prevention,
open-set speaker identification (OSI) has received less attention in the
speaker recognition community compared to speaker verification (SV). OSI deals
with determining if a test speech sample belongs to a speaker from a set of
pre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In
addition to the typical challenges associated with speech variability, OSI is
prone to the "false-alarm problem"; as the size of the in-set speaker
population (a.k.a watchlist) grows, the out-of-set scores become larger,
leading to increased false alarm rates. This is in particular challenging for
applications in financial institutions and border security where the watchlist
size is typically of the order of several thousand speakers. Therefore, it is
important to systematically quantify the false-alarm problem, and develop
techniques that alleviate the impact of watchlist size on detection
performance. Prior studies on this problem are sparse, and lack a common
benchmark for systematic evaluations. In this paper, we present the first
public benchmark for OSI, developed using the VoxCeleb dataset. We quantify the
effect of the watchlist size and speech duration on the watchlist-based speaker
detection task using three strong neural network based systems. In contrast to
the findings from prior research, we show that the commonly adopted adaptive
score normalization is not guaranteed to improve the performance for this task.
On the other hand, we show that score calibration and score fusion, two other
commonly used techniques in SV, result in significant improvements in OSI
performance.</p>
  </details>
</details>
<details>
  <summary>193. <b>标题：Machine learning for advancing low-temperature plasma modeling and  simulation</b></summary>
  <p><b>编号</b>：[542]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00131</p>
  <p><b>作者</b>：Jan Trieschmann,  Luca Vialetto,  Tobias Gergs</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enormous impact, low-temperature plasma modeling, plasma modeling, modeling and simulation, plasma</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning has had an enormous impact in many scientific disciplines.
Also in the field of low-temperature plasma modeling and simulation it has
attracted significant interest within the past years. Whereas its application
should be carefully assessed in general, many aspects of plasma modeling and
simulation have benefited substantially from recent developments within the
field of machine learning and data-driven modeling. In this survey, we approach
two main objectives: (a) We review the state-of-the-art focusing on approaches
to low-temperature plasma modeling and simulation. By dividing our survey into
plasma physics, plasma chemistry, plasma-surface interactions, and plasma
process control, we aim to extensively discuss relevant examples from
literature. (b) We provide a perspective of potential advances to plasma
science and technology. We specifically elaborate on advances possibly enabled
by adaptation from other scientific disciplines. We argue that not only the
known unknowns, but also unknown unknowns may be discovered due to an inherent
propensity to spotlight hidden patterns in data.</p>
  </details>
</details>
<details>
  <summary>194. <b>标题：Accelerating Inexact HyperGradient Descent for Bilevel Optimization</b></summary>
  <p><b>编号</b>：[543]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00126</p>
  <p><b>作者</b>：Haikuo Yang,  Luo Luo,  Chris Junchi Li,  Michael I. Jordan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solving general, epsilon, Restarted Accelerated, optimization problems, stationary point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a method for solving general nonconvex-strongly-convex bilevel
optimization problems. Our method -- the \emph{Restarted Accelerated
HyperGradient Descent} (\texttt{RAHGD}) method -- finds an
$\epsilon$-first-order stationary point of the objective with
$\tilde{\mathcal{O}}(\kappa^{3.25}\epsilon^{-1.75})$ oracle complexity, where
$\kappa$ is the condition number of the lower-level objective and $\epsilon$ is
the desired accuracy. We also propose a perturbed variant of \texttt{RAHGD} for
finding an
$\big(\epsilon,\mathcal{O}(\kappa^{2.5}\sqrt{\epsilon}\,)\big)$-second-order
stationary point within the same order of oracle complexity. Our results
achieve the best-known theoretical guarantees for finding stationary points in
bilevel optimization and also improve upon the existing upper complexity bound
for finding second-order stationary points in nonconvex-strongly-concave
minimax optimization problems, setting a new state-of-the-art benchmark.
Empirical studies are conducted to validate the theoretical results in this
paper.</p>
  </details>
</details>
<details>
  <summary>195. <b>标题：Application of data engineering approaches to address challenges in  microbiome data for optimal medical decision-making</b></summary>
  <p><b>编号</b>：[547]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00033</p>
  <p><b>作者</b>：Isha Thombre,  Pavan Kumar Perepu,  Shyam Kumar Sudhakar</p>
  <p><b>备注</b>：Will be submitted to Computers in Biology and Medicine</p>
  <p><b>关键词</b>：numerous physiological functions, human gut microbiota, gut microbiota, pathological conditions, contribute to numerous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human gut microbiota is known to contribute to numerous physiological
functions of the body through their interplay with multiple organs and also
implicated in a myriad of pathological conditions. Prolific research work in
the past few decades have yielded valuable information regarding the relative
taxonomic distribution of the gut microbiota that could enable personalized
medicine. Unfortunately, the microbiome data suffers from class imbalance and
high dimensionality issues that must be addressed. In this study, we have
implemented data engineering algorithms to address the above-mentioned issues
inherent to microbiome data. Four standard machine learning classifiers
(logistic regression (LR), support vector machines (SVM), random forests (RF),
and extreme gradient boosting (XGB) decision trees) were implemented on a
previously published dataset of infants with cystic fibrosis exhibiting normal
vs abnormal growth patterns. The issue of class imbalance and high
dimensionality of the data was addressed through synthetic minority
oversampling technique (SMOTE) and principal component analysis (PCA).
Classification of host phenotype was performed at multiple levels of taxonomic
hierarchy. Our results indicate that ensemble classifiers (RF and XGB decision
trees) exhibit superior classification accuracy in predicting the host
phenotype. The application of PCA significantly reduced the testing time while
maintaining high classification accuracy. The highest classification accuracy
was obtained at the levels of species for most classifiers. The prototype
employed in the study addresses the issues inherent to microbiome datasets and
could be highly beneficial for providing personalized medicine.</p>
  </details>
</details>
<details>
  <summary>196. <b>标题：Uncertainty Informed Optimal Resource Allocation with Gaussian Process  based Bayesian Inference</b></summary>
  <p><b>编号</b>：[548]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00032</p>
  <p><b>作者</b>：Samarth Gupta,  Saurabh Amin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：managing epidemic spread, epidemic spread, ODE, heterogeneous populations, populations for managing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on the problem of uncertainty informed allocation of medical
resources (vaccines) to heterogeneous populations for managing epidemic spread.
We tackle two related questions: (1) For a compartmental ordinary differential
equation (ODE) model of epidemic spread, how can we estimate and integrate
parameter uncertainty into resource allocation decisions? (2) How can we
computationally handle both nonlinear ODE constraints and parameter
uncertainties for a generic stochastic optimization problem for resource
allocation? To the best of our knowledge current literature does not fully
resolve these questions. Here, we develop a data-driven approach to represent
parameter uncertainty accurately and tractably in a novel stochastic
optimization problem formulation. We first generate a tractable scenario set by
estimating the distribution on ODE model parameters using Bayesian inference
with Gaussian processes. Next, we develop a parallelized solution algorithm
that accounts for scenario-dependent nonlinear ODE constraints. Our
scenario-set generation procedure and solution approach are flexible in that
they can handle any compartmental epidemiological ODE model. Our computational
experiments on two different non-linear ODE models (SEIR and SEPIHR) indicate
that accounting for uncertainty in key epidemiological parameters can improve
the efficacy of time-critical allocation decisions by 4-8%. This improvement
can be attributed to data-driven and optimal (strategic) nature of vaccine
allocations, especially in the early stages of the epidemic when the allocation
strategy can crucially impact the long-term trajectory of the disease.</p>
  </details>
</details>
<details>
  <summary>197. <b>标题：EmoSpeech: Guiding FastSpeech2 Towards Emotional Text to Speech</b></summary>
  <p><b>编号</b>：[550]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00024</p>
  <p><b>作者</b>：Daria Diatlova,  Vitaly Shutov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human voice, speech synthesis models, synthesis models, speech synthesis, speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art speech synthesis models try to get as close as possible to
the human voice. Hence, modelling emotions is an essential part of
Text-To-Speech (TTS) research. In our work, we selected FastSpeech2 as the
starting point and proposed a series of modifications for synthesizing
emotional speech. According to automatic and human evaluation, our model,
EmoSpeech, surpasses existing models regarding both MOS score and emotion
recognition accuracy in generated speech. We provided a detailed ablation study
for every extension to FastSpeech2 architecture that forms EmoSpeech. The
uneven distribution of emotions in the text is crucial for better, synthesized
speech and intonation perception. Our model includes a conditioning mechanism
that effectively handles this issue by allowing emotions to contribute to each
phone with varying intensity levels. The human assessment indicates that
proposed modifications generate audio with higher MOS and emotional
expressiveness.</p>
  </details>
</details>
<details>
  <summary>198. <b>标题：PV Fleet Modeling via Smooth Periodic Gaussian Copula</b></summary>
  <p><b>编号</b>：[551]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00004</p>
  <p><b>作者</b>：Mehmet G. Ogut,  Bennet Meyers,  Stephen P. Boyd</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：jointly modeling power, modeling power generation, jointly modeling, modeling power, power generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a method for jointly modeling power generation from a fleet of
photovoltaic (PV) systems. We propose a white-box method that finds a function
that invertibly maps vector time-series data to independent and identically
distributed standard normal variables. The proposed method, based on a novel
approach for fitting a smooth, periodic copula transform to data, captures many
aspects of the data such as diurnal variation in the distribution of power
output, dependencies among different PV systems, and dependencies across time.
It consists of interpretable steps and is scalable to many systems. The
resulting joint probability model of PV fleet output across systems and time
can be used to generate synthetic data, impute missing data, perform anomaly
detection, and make forecasts. In this paper, we explain the method and
demonstrate these applications.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：NeuBTF: Neural fields for BTF encoding and transfer</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01199</p>
  <p><b>作者</b>：Carlos Rodriguez-Pardo,  Konstantinos Kazatzis,  Jorge Lopez-Moreno,  Elena Garces</p>
  <p><b>备注</b>：9 pages, 7 figures. Accepted to Computers & Graphics (Special Section on CEIG 2023). Project Website: this https URL</p>
  <p><b>关键词</b>：BTF, neural BTF, Neural, material, Neural material</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural material representations are becoming a popular way to represent
materials for rendering. They are more expressive than analytic models and
occupy less memory than tabulated BTFs. However, existing neural materials are
immutable, meaning that their output for a certain query of UVs, camera, and
light vector is fixed once they are trained. While this is practical when there
is no need to edit the material, it can become very limiting when the fragment
of the material used for training is too small or not tileable, which
frequently happens when the material has been captured with a
gonioreflectometer. In this paper, we propose a novel neural material
representation which jointly tackles the problems of BTF compression, tiling,
and extrapolation. At test time, our method uses a guidance image as input to
condition the neural BTF to the structural features of this input image. Then,
the neural BTF can be queried as a regular BTF using UVs, camera, and light
vectors. Every component in our framework is purposefully designed to maximize
BTF encoding quality at minimal parameter count and computational complexity,
achieving competitive compression rates compared with previous work. We
demonstrate the results of our method on a variety of synthetic and captured
materials, showing its generality and capacity to learn to represent many
optical properties.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Squeezing Large-Scale Diffusion Models for Mobile</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01193</p>
  <p><b>作者</b>：Jiwoong Choi,  Minkyu Kim,  Daehyun Ahn,  Taesu Kim,  Yulhwa Kim,  Dongwon Jo,  Hyesung Jeon,  Jae-Joon Kim,  Hyungjun Kim</p>
  <p><b>备注</b>：7 pages, 8 figures, ICML 2023 Workshop on Challenges in Deployable Generative AI</p>
  <p><b>关键词</b>：high-fidelity image synthesis, academic research, greatly broadened, broadened the scope, scope of high-fidelity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emergence of diffusion models has greatly broadened the scope of
high-fidelity image synthesis, resulting in notable advancements in both
practical implementation and academic research. With the active adoption of the
model in various real-world applications, the need for on-device deployment has
grown considerably. However, deploying large diffusion models such as Stable
Diffusion with more than one billion parameters to mobile devices poses
distinctive challenges due to the limited computational and memory resources,
which may vary according to the device. In this paper, we present the
challenges and solutions for deploying Stable Diffusion on mobile devices with
TensorFlow Lite framework, which supports both iOS and Android devices. The
resulting Mobile Stable Diffusion achieves the inference latency of smaller
than 7 seconds for a 512x512 image generation on Android devices with mobile
GPUs.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SAMAug: Point Prompt Augmentation for Segment Anything Model</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01187</p>
  <p><b>作者</b>：Haixing Dai,  Chong Ma,  Zhengliang Liu,  Yiwei Li,  Peng Shu,  Xiaozheng Wei,  Lin Zhao,  Zihao Wu,  Dajiang Zhu,  Wei Liu,  Quanzheng Li,  Tianming Liu,  Xiang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：augmented point prompts, paper introduces SAMAug, SAM, enhances interactive image, augmented point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces SAMAug, a novel visual point augmentation method for
the Segment Anything Model (SAM) that enhances interactive image segmentation
performance. SAMAug generates augmented point prompts to provide more
information to SAM. From the initial point prompt, SAM produces the initial
mask, which is then fed into our proposed SAMAug to generate augmented point
prompts. By incorporating these extra points, SAM can generate augmented
segmentation masks based on the augmented point prompts and the initial prompt,
resulting in improved segmentation performance. We evaluate four point
augmentation techniques: random selection, maximum difference entropy, maximum
distance, and a saliency model. Experiments on the COCO, Fundus, and Chest
X-ray datasets demonstrate that SAMAug can boost SAM's segmentation results,
especially using the maximum distance and saliency model methods. SAMAug
underscores the potential of visual prompt engineering to advance interactive
computer vision models.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：PlanE: Representation Learning over Planar Graphs</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01180</p>
  <p><b>作者</b>：Radoslav Dimitrov,  Zeyang Zhao,  Ralph Abboud,  İsmail İlkan Ceylan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph neural networks, learned graph function, iteratively compute representations, Graph, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks are prominent models for representation learning over
graphs, where the idea is to iteratively compute representations of nodes of an
input graph through a series of transformations in such a way that the learned
graph function is isomorphism invariant on graphs, which makes the learned
representations graph invariants. On the other hand, it is well-known that
graph invariants learned by these class of models are incomplete: there are
pairs of non-isomorphic graphs which cannot be distinguished by standard graph
neural networks. This is unsurprising given the computational difficulty of
graph isomorphism testing on general graphs, but the situation begs to differ
for special graph classes, for which efficient graph isomorphism testing
algorithms are known, such as planar graphs. The goal of this work is to design
architectures for efficiently learning complete invariants of planar graphs.
Inspired by the classical planar graph isomorphism algorithm of Hopcroft and
Tarjan, we propose PlanE as a framework for planar representation learning.
PlanE includes architectures which can learn complete invariants over planar
graphs while remaining practically scalable. We empirically validate the strong
performance of the resulting model architectures on well-known planar graph
benchmarks, achieving multiple state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Don't freeze: Finetune encoders for better Self-Supervised HAR</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01168</p>
  <p><b>作者</b>：Vitor Fortes Rey,  Dominique Nshimyimana,  Paul Lukowicz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recently self-supervised learning, human activity recognition, data availability problem, Recently self-supervised, availability problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently self-supervised learning has been proposed in the field of human
activity recognition as a solution to the labelled data availability problem.
The idea being that by using pretext tasks such as reconstruction or
contrastive predictive coding, useful representations can be learned that then
can be used for classification. Those approaches follow the pretrain, freeze
and fine-tune procedure. In this paper we will show how a simple change - not
freezing the representation - leads to substantial performance gains across
pretext tasks. The improvement was found in all four investigated datasets and
across all four pretext tasks and is inversely proportional to amount of
labelled data. Moreover the effect is present whether the pretext task is
carried on the Capture24 dataset or directly in unlabelled data of the target
dataset.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Soft Gripping: Specifying for Trustworthiness</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01159</p>
  <p><b>作者</b>：Dhaminda B. Abeywickrama,  Nguyen Hao Le,  Greg Chance,  Peter D. Winter,  Arianna Manzini,  Alix J. Partridge,  Jonathan Ives,  John Downer,  Graham Deacon,  Jonathan Rossiter,  Kerstin Eder,  Shane Windsor</p>
  <p><b>备注</b>：9 pages, 2 figures, 1 table, 34 references</p>
  <p><b>关键词</b>：engineers create flexible, create flexible devices, variety of applications, Soft, emerging technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Soft robotics is an emerging technology in which engineers create flexible
devices for use in a variety of applications. In order to advance the wide
adoption of soft robots, ensuring their trustworthiness is essential; if soft
robots are not trusted, they will not be used to their full potential. In order
to demonstrate trustworthiness, a specification needs to be formulated to
define what is trustworthy. However, even for soft robotic grippers, which is
one of the most mature areas in soft robotics, the soft robotics community has
so far given very little attention to formulating specifications. In this work,
we discuss the importance of developing specifications during development of
soft robotic systems, and present an extensive example specification for a soft
gripper for pick-and-place tasks for grocery items. The proposed specification
covers both functional and non-functional requirements, such as reliability,
safety, adaptability, predictability, ethics, and regulations. We also
highlight the need to promote verifiability as a first-class objective in the
design of a soft gripper.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01158</p>
  <p><b>作者</b>：Ini Oguntola,  Joseph Campbell,  Simon Stepputtis,  Katia Sycara</p>
  <p><b>备注</b>：To appear at ICML 2023 Workshop on Theory of Mind</p>
  <p><b>关键词</b>：human social intelligence, social dynamics induced, offer similar benefits, social intelligence, human social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to model the mental states of others is crucial to human social
intelligence, and can offer similar benefits to artificial agents with respect
to the social dynamics induced in multi-agent settings. We present a method of
grounding semantically meaningful, human-interpretable beliefs within policies
modeled by deep networks. We then consider the task of 2nd-order belief
prediction. We propose that ability of each agent to predict the beliefs of the
other agents can be used as an intrinsic reward signal for multi-agent
reinforcement learning. Finally, we present preliminary empirical results in a
mixed cooperative-competitive environment.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：SCITUNE: Aligning Large Language Models with Scientific Multimodal  Instructions</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01139</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Sai Munikoti,  Ian Stewart,  Henry Kvinge</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：popular paradigm, paradigm to align, align large language, human intent, align existing foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction finetuning is a popular paradigm to align large language models
(LLM) with human intent. Despite its popularity, this idea is less explored in
improving the LLMs to align existing foundation models with scientific
disciplines, concepts and goals. In this work, we present SciTune as a tuning
framework to improve the ability of LLMs to follow scientific multimodal
instructions. To test our methodology, we use a human-generated scientific
instruction tuning dataset and train a large multimodal model LLaMA-SciTune
that connects a vision encoder and LLM for science-focused visual and language
understanding. In comparison to the models that are finetuned with machine
generated data only, LLaMA-SciTune surpasses human performance on average and
in many sub-categories on the ScienceQA benchmark.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Exploring the In-context Learning Ability of Large Language Model for  Biomedical Concept Linking</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01137</p>
  <p><b>作者</b>：Qinyong Wang,  Zhenxiang Gao,  Rong Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：field relies heavily, biomedical field relies, graph alignment, literature mining, knowledge integration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The biomedical field relies heavily on concept linking in various areas such
as literature mining, graph alignment, information retrieval,
question-answering, data, and knowledge integration. Although large language
models (LLMs) have made significant strides in many natural language processing
tasks, their effectiveness in biomedical concept mapping is yet to be fully
explored. This research investigates a method that exploits the in-context
learning (ICL) capabilities of large models for biomedical concept linking. The
proposed approach adopts a two-stage retrieve-and-rank framework. Initially,
biomedical concepts are embedded using language models, and then embedding
similarity is utilized to retrieve the top candidates. These candidates'
contextual information is subsequently incorporated into the prompt and
processed by a large language model to re-rank the concepts. This approach
achieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%
in chemical entity normalization, exhibiting a competitive performance relative
to supervised learning methods. Further, it showed a significant improvement,
with an over 20-point absolute increase in F1 score on an oncology matching
dataset. Extensive qualitative assessments were conducted, and the benefits and
potential shortcomings of using large language models within the biomedical
domain were discussed. were discussed.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：ChatGPT vs. Google: A Comparative Study of Search Performance and User  Experience</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01135</p>
  <p><b>作者</b>：Ruiyun Xu (Rayna),  Yue Feng (Katherine),  Hailiang Chen</p>
  <p><b>备注</b>：30 pages, 5 figures, 2 tables</p>
  <p><b>关键词</b>：large language model-powered, language model-powered chatbot, traditional search engines, large language, language model-powered</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of ChatGPT, a large language model-powered chatbot, has prompted
questions about its potential implications for traditional search engines. In
this study, we investigate the differences in user behavior when employing
search engines and chatbot tools for information-seeking tasks. We carry out a
randomized online experiment, dividing participants into two groups: one using
a ChatGPT-like tool and the other using a Google Search-like tool. Our findings
reveal that the ChatGPT group consistently spends less time on all tasks, with
no significant difference in overall task performance between the groups.
Notably, ChatGPT levels user search performance across different education
levels and excels in answering straightforward questions and providing general
solutions but falls short in fact-checking tasks. Users perceive ChatGPT's
responses as having higher information quality compared to Google Search,
despite displaying a similar level of trust in both tools. Furthermore,
participants using ChatGPT report significantly better user experiences in
terms of usefulness, enjoyment, and satisfaction, while perceived ease of use
remains comparable between the two tools. However, ChatGPT may also lead to
overreliance and generate or replicate misinformation, yielding inconsistent
results. Our study offers valuable insights for search engine management and
highlights opportunities for integrating chatbot technologies into search
engine designs.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01128</p>
  <p><b>作者</b>：Salvatore Carta,  Alessandro Giuliani,  Leonardo Piano,  Alessandro Sebastian Podda,  Livio Pompianu,  Sandro Gabriele Tiddia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：current digitalization era, effectively representing knowledge, digitalization era, capturing and effectively, real-world scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the current digitalization era, capturing and effectively representing
knowledge is crucial in most real-world scenarios. In this context, knowledge
graphs represent a potent tool for retrieving and organizing a vast amount of
information in a properly interconnected and interpretable structure. However,
their generation is still challenging and often requires considerable human
effort and domain expertise, hampering the scalability and flexibility across
different application fields. This paper proposes an innovative knowledge graph
generation approach that leverages the potential of the latest generative large
language models, such as GPT-3.5, that can address all the main critical issues
in knowledge graph building. The approach is conveyed in a pipeline that
comprises novel iterative zero-shot and external knowledge-agnostic strategies
in the main stages of the generation process. Our unique manifold approach may
encompass significant benefits to the scientific community. In particular, the
main contribution can be summarized by: (i) an innovative strategy for
iteratively prompting large language models to extract relevant components of
the final graph; (ii) a zero-shot strategy for each prompt, meaning that there
is no need for providing examples for "guiding" the prompt result; (iii) a
scalable solution, as the adoption of LLMs avoids the need for any external
resources or human expertise. To assess the effectiveness of our proposed
model, we performed experiments on a dataset that covered a specific domain. We
claim that our proposal is a suitable solution for scalable and versatile
knowledge graph construction and may be applied to different and novel
contexts.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Some challenges of calibrating differentiable agent-based models</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01085</p>
  <p><b>作者</b>：Arnau Quera-Bofarull,  Joel Dyer,  Anisoara Calinescu,  Michael Wooldridge</p>
  <p><b>备注</b>：Accepted at the ICML 2023 Differentiable Almost Everything Workshop</p>
  <p><b>关键词</b>：performing parameter inference, Agent-based models, discrete nature, complex systems, optimisation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Agent-based models (ABMs) are a promising approach to modelling and reasoning
about complex systems, yet their application in practice is impeded by their
complexity, discrete nature, and the difficulty of performing parameter
inference and optimisation tasks. This in turn has sparked interest in the
construction of differentiable ABMs as a strategy for combatting these
difficulties, yet a number of challenges remain. In this paper, we discuss and
present experiments that highlight some of these challenges, along with
potential solutions.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：ENGAGE: Explanation Guided Data Augmentation for Graph Representation  Learning</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01053</p>
  <p><b>作者</b>：Yucheng Shi,  Kaixiong Zhou,  Ninghao Liu</p>
  <p><b>备注</b>：Accepted by ECML-PKDD 2023</p>
  <p><b>关键词</b>：applied to modeling, recent contrastive learning, data, modeling graph data, widely applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent contrastive learning methods, due to their effectiveness in
representation learning, have been widely applied to modeling graph data.
Random perturbation is widely used to build contrastive views for graph data,
which however, could accidentally break graph structures and lead to suboptimal
performance. In addition, graph data is usually highly abstract, so it is hard
to extract intuitive meanings and design more informed augmentation schemes.
Effective representations should preserve key characteristics in data and
abandon superfluous information. In this paper, we propose ENGAGE (ExplaNation
Guided data AuGmEntation), where explanation guides the contrastive
augmentation process to preserve the key parts in graphs and explore removing
superfluous information. Specifically, we design an efficient unsupervised
explanation method called smoothed activation map as the indicator of node
importance in representation learning. Then, we design two data augmentation
schemes on graphs for perturbing structural and feature information,
respectively. We also provide justification for the proposed method in the
framework of information theories. Experiments of both graph-level and
node-level tasks, on various model architectures and on different real-world
graphs, are conducted to demonstrate the effectiveness and flexibility of
ENGAGE. The code of ENGAGE can be found: this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Temporal Graph Benchmark for Machine Learning on Temporal Graphs</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01026</p>
  <p><b>作者</b>：Shenyang Huang,  Farimah Poursafaei,  Jacob Danovitch,  Matthias Fey,  Weihua Hu,  Emanuele Rossi,  Jure Leskovec,  Michael Bronstein,  Guillaume Rabusseau,  Reihaneh Rabbany</p>
  <p><b>备注</b>：16 pages, 4 figures, 5 tables, preprint</p>
  <p><b>关键词</b>：TGB, collection of challenging, Temporal Graph, TGB datasets, diverse benchmark datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the Temporal Graph Benchmark (TGB), a collection of challenging
and diverse benchmark datasets for realistic, reproducible, and robust
evaluation of machine learning models on temporal graphs. TGB datasets are of
large scale, spanning years in duration, incorporate both node and edge-level
prediction tasks and cover a diverse set of domains including social, trade,
transaction, and transportation networks. For both tasks, we design evaluation
protocols based on realistic use-cases. We extensively benchmark each dataset
and find that the performance of common models can vary drastically across
datasets. In addition, on dynamic node property prediction tasks, we show that
simple methods often achieve superior performance compared to existing temporal
graph models. We believe that these findings open up opportunities for future
research on temporal graphs. Finally, TGB provides an automated machine
learning pipeline for reproducible and accessible temporal graph research,
including data loading, experiment setup and performance evaluation. TGB will
be maintained and updated on a regular basis and welcomes community feedback.
TGB datasets, data loaders, example codes, evaluation setup, and leaderboards
are publicly available at this https URL .</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：RefSAM: Efficiently Adapting Segmenting Anything Model for Referring  Video Object Segmentation</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00997</p>
  <p><b>作者</b>：Yonglin Li,  Jing Zhang,  Xiao Teng,  Long Lan</p>
  <p><b>备注</b>：The code and models will be made publicly at this https URL</p>
  <p><b>关键词</b>：gained significant attention, gained significant, significant attention, impressive performance, performance in image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) has gained significant attention for its
impressive performance in image segmentation. However, it lacks proficiency in
referring video object segmentation (RVOS) due to the need for precise
user-interactive prompts and limited understanding of different modalities,
such as language and vision. This paper presents the RefSAM model, which for
the first time explores the potential of SAM for RVOS by incorporating
multi-view information from diverse modalities and successive frames at
different timestamps. Our proposed approach adapts the original SAM model to
enhance cross-modality learning by employing a lightweight Cross-Modal MLP that
projects the text embedding of the referring expression into sparse and dense
embeddings, serving as user-interactive prompts. Subsequently, a
parameter-efficient tuning strategy is employed to effectively align and fuse
the language and vision features. Through comprehensive ablation studies, we
demonstrate the practical and effective design choices of our strategy.
Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasets
validate the superiority and effectiveness of our RefSAM model over existing
methods. The code and models will be made publicly at
\href{this https URL}{this http URL}.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：REAL: A Representative Error-Driven Approach for Active Learning</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00968</p>
  <p><b>作者</b>：Cheng Chen,  Yong Wang,  Lizi Liao,  Yueguo Chen,  Xiaoyong Du</p>
  <p><b>备注</b>：Accepted by ECML/PKDD 2023</p>
  <p><b>关键词</b>：subsequent model training, limited labeling budget, active learning, aims to sample, limited labeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given a limited labeling budget, active learning (AL) aims to sample the most
informative instances from an unlabeled pool to acquire labels for subsequent
model training. To achieve this, AL typically measures the informativeness of
unlabeled instances based on uncertainty and diversity. However, it does not
consider erroneous instances with their neighborhood error density, which have
great potential to improve the model performance. To address this limitation,
we propose $REAL$, a novel approach to select data instances with
$\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive
$\underline{L}$earning. It identifies minority predictions as \emph{pseudo
errors} within a cluster and allocates an adaptive sampling budget for the
cluster based on estimated error density. Extensive experiments on five text
classification datasets demonstrate that $REAL$ consistently outperforms all
best-performing baselines regarding accuracy and F1-macro scores across a wide
range of hyperparameter settings. Our analysis also shows that $REAL$ selects
the most representative pseudo errors that match the distribution of
ground-truth errors along the decision boundary. Our code is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：OpenClinicalAI: An Open and Dynamic Model for Alzheimer's Disease  Diagnosis</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00965</p>
  <p><b>作者</b>：Yunyou Huang,  Xiaoshuang Liang,  Xiangjiang Lu,  Xiuxia Miao,  Jiyue Xie,  Wenjing Liu,  Fan Zhang,  Guoxin Kang,  Li Ma,  Suqin Tang,  Zhifei Zhang,  Jianfeng Zhan</p>
  <p><b>备注</b>：Real-world clinical setting,Alzheimer's disease,diagnose,AI,deep learning. arXiv admin note: text overlap with arXiv:2109.04004</p>
  <p><b>关键词</b>：Alzheimer disease, reversed or cured, significantly reduce, reduce the burden, burden of treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although Alzheimer's disease (AD) cannot be reversed or cured, timely
diagnosis can significantly reduce the burden of treatment and care. Current
research on AD diagnosis models usually regards the diagnosis task as a typical
classification task with two primary assumptions: 1) All target categories are
known a priori; 2) The diagnostic strategy for each patient is consistent, that
is, the number and type of model input data for each patient are the same.
However, real-world clinical settings are open, with complexity and uncertainty
in terms of both subjects and the resources of the medical institutions. This
means that diagnostic models may encounter unseen disease categories and need
to dynamically develop diagnostic strategies based on the subject's specific
circumstances and available medical resources. Thus, the AD diagnosis task is
tangled and coupled with the diagnosis strategy formulation. To promote the
application of diagnostic systems in real-world clinical settings, we propose
OpenClinicalAI for direct AD diagnosis in complex and uncertain clinical
settings. This is the first powerful end-to-end model to dynamically formulate
diagnostic strategies and provide diagnostic results based on the subject's
conditions and available medical resources. OpenClinicalAI combines
reciprocally coupled deep multiaction reinforcement learning (DMARL) for
diagnostic strategy formulation and multicenter meta-learning (MCML) for
open-set recognition. The experimental results show that OpenClinicalAI
achieves better performance and fewer clinical examinations than the
state-of-the-art model. Our method provides an opportunity to embed the AD
diagnostic system into the current health care system to cooperate with
clinicians to improve current health care.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Challenges in Domain-Specific Abstractive Summarization and How to  Overcome them</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00963</p>
  <p><b>作者</b>：Anum Afzal,  Juraj Vladika,  Daniel Braun,  Florian Matthes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Large Language Models, Natural Language, Language Models work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models work quite well with general-purpose data and many
tasks in Natural Language Processing. However, they show several limitations
when used for a task such as domain-specific abstractive text summarization.
This paper identifies three of those limitations as research problems in the
context of abstractive text summarization: 1) Quadratic complexity of
transformer-based models with respect to the input text length; 2) Model
Hallucination, which is a model's ability to generate factually incorrect text;
and 3) Domain Shift, which happens when the distribution of the model's
training and test corpus is not the same. Along with a discussion of the open
research questions, this paper also provides an assessment of existing
state-of-the-art techniques relevant to domain-specific text summarization to
address the research gaps.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in  Multi-Objective Neural Architecture Search</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00960</p>
  <p><b>作者</b>：Simone Sarti,  Eugenio Lomurno,  Matteo Matteucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning, contemporary society, learning is increasingly, increasingly impacting, impacting various aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is increasingly impacting various aspects of contemporary
society. Artificial neural networks have emerged as the dominant models for
solving an expanding range of tasks. The introduction of Neural Architecture
Search (NAS) techniques, which enable the automatic design of task-optimal
networks, has led to remarkable advances. However, the NAS process is typically
associated with long execution times and significant computational resource
requirements. Once-For-All (OFA) and its successor, Once-For-All-2 (OFAv2),
have been developed to mitigate these challenges. While maintaining exceptional
performance and eliminating the need for retraining, they aim to build a single
super-network model capable of directly extracting sub-networks satisfying
different constraints. Neural Architecture Transfer (NAT) was developed to
maximise the effectiveness of extracting sub-networks from a super-network. In
this paper, we present NATv2, an extension of NAT that improves multi-objective
search algorithms applied to dynamic super-network architectures. NATv2
achieves qualitative improvements in the extractable sub-networks by exploiting
the improved super-networks generated by OFAv2 and incorporating new policies
for initialisation, pre-processing and updating its networks archive. In
addition, a post-processing pipeline based on fine-tuning is introduced.
Experimental results show that NATv2 successfully improves NAT and is highly
recommended for investigating high-performance architectures with a minimal
number of parameters.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Towards Explainable AI for Channel Estimation in Wireless Communications</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00952</p>
  <p><b>作者</b>：Abdul Karim Gizzini,  Yahia Medjahdi,  Ali J. Ghandour,  Laurent Clavier</p>
  <p><b>备注</b>：This paper has been submitted to the IEEE Transactions on Vehicular Technology (TVT) as a correspondence paper on 25/04/2023</p>
  <p><b>关键词</b>：critical artificial intelligence, artificial intelligence, autonomous driving, initiated to support, support a variety</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research into 6G networks has been initiated to support a variety of critical
artificial intelligence (AI) assisted applications such as autonomous driving.
In such applications, AI-based decisions should be performed in a real-time
manner. These decisions include resource allocation, localization, channel
estimation, etc. Considering the black-box nature of existing AI-based models,
it is highly challenging to understand and trust the decision-making behavior
of such models. Therefore, explaining the logic behind those models through
explainable AI (XAI) techniques is essential for their employment in critical
applications. This manuscript proposes a novel XAI-based channel estimation
(XAI-CHEST) scheme that provides detailed reasonable interpretability of the
deep learning (DL) models that are employed in doubly-selective channel
estimation. The aim of the proposed XAI-CHEST scheme is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. As a
result, the behavior of the studied DL-based channel estimators can be further
analyzed and evaluated based on the generated interpretations. Simulation
results show that the proposed XAI-CHEST scheme provides valid interpretations
of the DL-based channel estimators for different scenarios.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：OpenAPMax: Abnormal Patterns-based Model for Real-World Alzheimer's  Disease Diagnosis</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00936</p>
  <p><b>作者</b>：Yunyou Huang,  Xianglong Guan,  Xiangjiang Lu,  Xiaoshuang Liang,  Xiuxia Miao,  Jiyue Xie,  Wenjing Liu,  Li Ma,  Suqin Tang,  Zhifei Zhang,  Jianfeng Zhan</p>
  <p><b>备注</b>：Alzheimer's Disease, Abnormal Patterns, Open-set Recognition, OpenAPMax</p>
  <p><b>关键词</b>：significantly benefit patients', benefit patients' medical, patients' medical treatment, treatment and care, open-set recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's disease (AD) cannot be reversed, but early diagnosis will
significantly benefit patients' medical treatment and care. In recent works, AD
diagnosis has the primary assumption that all categories are known a prior -- a
closed-set classification problem, which contrasts with the open-set
recognition problem. This assumption hinders the application of the model in
natural clinical settings. Although many open-set recognition technologies have
been proposed in other fields, they are challenging to use for AD diagnosis
directly since 1) AD is a degenerative disease of the nervous system with
similar symptoms at each stage, and it is difficult to distinguish from its
pre-state, and 2) diversified strategies for AD diagnosis are challenging to
model uniformly. In this work, inspired by the concerns of clinicians during
diagnosis, we propose an open-set recognition model, OpenAPMax, based on the
anomaly pattern to address AD diagnosis in real-world settings. OpenAPMax first
obtains the abnormal pattern of each patient relative to each known category
through statistics or a literature search, clusters the patients' abnormal
pattern, and finally, uses extreme value theory (EVT) to model the distance
between each patient's abnormal pattern and the center of their category and
modify the classification probability. We evaluate the performance of the
proposed method with recent open-set recognition, where we obtain
state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Learning Differentiable Logic Programs for Abstract Visual Reasoning</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00928</p>
  <p><b>作者</b>：Hikaru Shindo,  Viktor Pfanschilling,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：building intelligent agents, problem-solving beyond perception, Visual reasoning, essential for building, building intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual reasoning is essential for building intelligent agents that understand
the world and perform problem-solving beyond perception. Differentiable forward
reasoning has been developed to integrate reasoning with gradient-based machine
learning paradigms. However, due to the memory intensity, most existing
approaches do not bring the best of the expressivity of first-order logic,
excluding a crucial ability to solve abstract visual reasoning, where agents
need to perform reasoning by using analogies on abstract concepts in different
scenarios. To overcome this problem, we propose NEUro-symbolic Message-pAssiNg
reasoNer (NEUMANN), which is a graph-based differentiable forward reasoner,
passing messages in a memory-efficient manner and handling structured programs
with functors. Moreover, we propose a computationally-efficient structure
learning algorithm to perform explanatory program induction on complex visual
scenes. To evaluate, in addition to conventional visual reasoning tasks, we
propose a new task, visual reasoning behind-the-scenes, where agents need to
learn abstract programs and then answer queries by imagining scenes that are
not observed. We empirically demonstrate that NEUMANN solves visual reasoning
tasks efficiently, outperforming neural, symbolic, and neuro-symbolic
baselines.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Automatic Design of Semantic Similarity Ensembles Using Grammatical  Evolution</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00925</p>
  <p><b>作者</b>：Jorge Martinez-Gil</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：natural language processing, Semantic similarity, semantic similarity tasks, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic similarity measures are widely used in natural language processing
to catalyze various computer-related tasks. However, no single semantic
similarity measure is the most appropriate for all tasks, and researchers often
use ensemble strategies to ensure performance. This research work proposes a
method for automatically designing semantic similarity ensembles. In fact, our
proposed method uses grammatical evolution, for the first time, to
automatically select and aggregate measures from a pool of candidates to create
an ensemble that maximizes correlation to human judgment. The method is
evaluated on several benchmark datasets and compared to state-of-the-art
ensembles, showing that it can significantly improve similarity assessment
accuracy and outperform existing methods in some cases. As a result, our
research demonstrates the potential of using grammatical evolution to
automatically compare text and prove the benefits of using ensembles for
semantic similarity tasks.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Achieving Stable Training of Reinforcement Learning Agents in Bimodal  Environments through Batch Learning</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00923</p>
  <p><b>作者</b>：E. Hurwitz,  N. Peace,  G. Cevora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Learning, typical Reinforcement, batch learning, stochastic environments present, Bimodal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bimodal, stochastic environments present a challenge to typical Reinforcement
Learning problems. This problem is one that is surprisingly common in real
world applications, being particularly applicable to pricing problems. In this
paper we present a novel learning approach to the tabular Q-learning algorithm,
tailored to tackling these specific challenges by using batch updates. A
simulation of pricing problem is used as a testbed to compare a typically
updated agent with a batch learning agent. The batch learning agents are shown
to be both more effective than the typically-trained agents, and to be more
resilient to the fluctuations in a large stochastic environment. This work has
a significant potential to enable practical, industrial deployment of
Reinforcement Learning in the context of pricing and others.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Node-weighted Graph Convolutional Network for Depression Detection in  Transcribed Clinical Interviews</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00920</p>
  <p><b>作者</b>：Sergio Burdisso,  Esaú Villatoro-Tello,  Srikanth Madikeri,  Petr Motlicek</p>
  <p><b>备注</b>：Paper Accepted to Interspeech 2023</p>
  <p><b>关键词</b>：weighting self-connecting edges, propose a simple, weighting self-connecting, Graph, Convolutional Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a simple approach for weighting self-connecting edges in a Graph
Convolutional Network (GCN) and show its impact on depression detection from
transcribed clinical interviews. To this end, we use a GCN for modeling
non-consecutive and long-distance semantics to classify the transcriptions into
depressed or control subjects. The proposed method aims to mitigate the
limiting assumptions of locality and the equal importance of self-connections
vs. edges to neighboring nodes in GCNs, while preserving attractive features
such as low computational cost, data agnostic, and interpretability
capabilities. We perform an exhaustive evaluation in two benchmark datasets.
Results show that our approach consistently outperforms the vanilla GCN model
as well as previously reported results, achieving an F1=0.84% on both datasets.
Finally, a qualitative analysis illustrates the interpretability capabilities
of the proposed approach and its alignment with previous findings in
psychology.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Why do CNNs excel at feature extraction? A mathematical explanation</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00919</p>
  <p><b>作者</b>：Vinoth Nandakumar,  Arush Tagade,  Tongliang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：past decade deep, decade deep learning, image classification benchmarks, image classification, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the past decade deep learning has revolutionized the field of computer
vision, with convolutional neural network models proving to be very effective
for image classification benchmarks. However, a fundamental theoretical
questions remain answered: why can they solve discrete image classification
tasks that involve feature extraction? We address this question in this paper
by introducing a novel mathematical model for image classification, based on
feature extraction, that can be used to generate images resembling real-world
datasets. We show that convolutional neural network classifiers can solve these
image classification tasks with zero error. In our proof, we construct
piecewise linear functions that detect the presence of features, and show that
they can be realized by a convolutional network.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Contextual Prompt Learning for Vision-Language Understanding</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00910</p>
  <p><b>作者</b>：Koustava Goswami,  Srikrishna Karanam,  Joseph K J,  Prateksha Udhayanan,  Balaji Vasan Srinivasan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful vision-language models, prompts, local image features, image features, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in multimodal learning has resulted in powerful
vision-language models, whose representations are generalizable across a
variety of downstream tasks. Recently, their generalizability has been further
extended by incorporating trainable prompts, borrowed from the natural language
processing literature. While such prompt learning techniques have shown
impressive results, we identify that these prompts are trained based on global
image features which limits itself in two aspects: First, by using global
features, these prompts could be focusing less on the discriminative foreground
image, resulting in poor generalization to various out-of-distribution test
cases. Second, existing work weights all prompts equally whereas our intuition
is that these prompts are more specific to the type of the image. We address
these issues with as part of our proposed Contextual Prompt Learning (CoPL)
framework, capable of aligning the prompts to the localized features of the
image. Our key innovations over earlier works include using local image
features as part of the prompt learning process, and more crucially, learning
to weight these prompts based on local features that are appropriate for the
task at hand. This gives us dynamic prompts that are both aligned to local
image features as well as aware of local contextual relationships. Our
extensive set of experiments on a variety of standard and few-shot datasets
show that our method produces substantially improved performance when compared
to the current state of the art methods. We also demonstrate both few-shot and
out-of-distribution performance to establish the utility of learning dynamic
prompts that are aligned to local image features.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Fixing confirmation bias in feature attribution methods via semantic  match</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00897</p>
  <p><b>作者</b>：Giovanni Cinà,  Daniel Fernandez-Llaneza,  Nishant Mishra,  Tabea E. Röber,  Sandro Pezzelle,  Iacer Calixto,  Rob Goedhart,  Ş. İlker Birbil</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black box models, disentangle the complex, black box, Feature attribution methods, staple method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature attribution methods have become a staple method to disentangle the
complex behavior of black box models. Despite their success, some scholars have
argued that such methods suffer from a serious flaw: they do not allow a
reliable interpretation in terms of human concepts. Simply put, visualizing an
array of feature contributions is not enough for humans to conclude something
about a model's internal representations, and confirmation bias can trick users
into false beliefs about model behavior. We argue that a structured approach is
required to test whether our hypotheses on the model are confirmed by the
feature attributions. This is what we call the "semantic match" between human
concepts and (sub-symbolic) explanations. Building on the conceptual framework
put forward in Cinà et al. [2023], we propose a structured approach to
evaluate semantic match in practice. We showcase the procedure in a suite of
experiments spanning tabular and image data, and show how the assessment of
semantic match can give insight into both desirable (e.g., focusing on an
object relevant for prediction) and undesirable model behaviors (e.g., focusing
on a spurious correlation). We couple our experimental results with an analysis
on the metrics to measure semantic match, and argue that this approach
constitutes the first step towards resolving the issue of confirmation bias in
XAI.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Augmenting Deep Learning Adaptation for Wearable Sensor Data through  Combined Temporal-Frequency Image Encoding</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00883</p>
  <p><b>作者</b>：Yidong Zhu,  Md Mahmudur Rahman,  Mohammad Arif Ul Alam</p>
  <p><b>备注</b>：Under review in IEEE-EMBS International Conference on Body Sensor Networks: Sensor and Systems for Digital Health (IEEE BSN 2023)</p>
  <p><b>关键词</b>：including computer vision, revolutionized scalable classification, Deep learning advancements, Deep learning, advancements have revolutionized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning advancements have revolutionized scalable classification in
many domains including computer vision. However, when it comes to
wearable-based classification and domain adaptation, existing computer
vision-based deep learning architectures and pretrained models trained on
thousands of labeled images for months fall short. This is primarily because
wearable sensor data necessitates sensor-specific preprocessing, architectural
modification, and extensive data collection. To overcome these challenges,
researchers have proposed encoding of wearable temporal sensor data in images
using recurrent plots. In this paper, we present a novel modified-recurrent
plot-based image representation that seamlessly integrates both temporal and
frequency domain information. Our approach incorporates an efficient Fourier
transform-based frequency domain angular difference estimation scheme in
conjunction with the existing temporal recurrent plot image. Furthermore, we
employ mixup image augmentation to enhance the representation. We evaluate the
proposed method using accelerometer-based activity recognition data and a
pretrained ResNet model, and demonstrate its superior performance compared to
existing approaches.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Mining Clues from Incomplete Utterance: A Query-enhanced Network for  Incomplete Utterance Rewriting</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00866</p>
  <p><b>作者</b>：Shuzheng Si,  Shuang Zeng,  Baobao Chang</p>
  <p><b>备注</b>：NAACL 2022</p>
  <p><b>关键词</b>：raised wide attention, recently raised wide, Incomplete utterance rewriting, wide attention, Incomplete utterance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incomplete utterance rewriting has recently raised wide attention. However,
previous works do not consider the semantic structural information between
incomplete utterance and rewritten utterance or model the semantic structure
implicitly and insufficiently. To address this problem, we propose a
QUEry-Enhanced Network (QUEEN). Firstly, our proposed query template explicitly
brings guided semantic structural knowledge between the incomplete utterance
and the rewritten utterance making model perceive where to refer back to or
recover omitted tokens. Then, we adopt a fast and effective edit operation
scoring network to model the relation between two tokens. Benefiting from
proposed query template and the well-designed edit operation scoring network,
QUEEN achieves state-of-the-art performance on several public datasets.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：OpenSiteRec: An Open Dataset for Site Recommendation</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00856</p>
  <p><b>作者</b>：Xinhang Li,  Xiangyu Zhao,  Yejing Wang,  Yu Liu,  Yong Li,  Cheng Long,  Yong Zhang,  Chunxiao Xing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：information retrieval task, representative information retrieval, site recommendation, modern business, information retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a representative information retrieval task, site recommendation, which
aims at predicting the optimal sites for a brand or an institution to open new
branches in an automatic data-driven way, is beneficial and crucial for brand
development in modern business. However, there is no publicly available dataset
so far and most existing approaches are limited to an extremely small scope of
brands, which seriously hinders the research on site recommendation. Therefore,
we collect, construct and release an open comprehensive dataset, namely
OpenSiteRec, to facilitate and promote the research on site recommendation.
Specifically, OpenSiteRec leverages a heterogeneous graph schema to represent
various types of real-world entities and relations in four international
metropolises. To evaluate the performance of the existing general methods on
the site recommendation task, we conduct benchmarking experiments of several
representative recommendation models on OpenSiteRec. Furthermore, we also
highlight the potential application directions to demonstrate the wide
applicability of OpenSiteRec. We believe that our OpenSiteRec dataset is
significant and anticipated to encourage the development of advanced methods
for site recommendation. OpenSiteRec is available online at
this https URL.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Review of Large Vision Models and Visual Prompt Engineering</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00855</p>
  <p><b>作者</b>：Jiaqi Wang,  Zhengliang Liu,  Lin Zhao,  Zihao Wu,  Chong Ma,  Sigang Yu,  Haixing Dai,  Qiushi Yang,  Yiheng Liu,  Songyao Zhang,  Enze Shi,  Yi Pan,  Tuo Zhang,  Dajiang Zhu,  Xiang Li,  Xi Jiang,  Bao Ge,  Yixuan Yuan,  Dinggang Shen,  Tianming Liu,  Shu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial General Intelligence, image Artificial General, General Intelligence, Artificial General, achieving zero-shot capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual prompt engineering is a fundamental technology in the field of visual
and image Artificial General Intelligence, serving as a key component for
achieving zero-shot capabilities. As the development of large vision models
progresses, the importance of prompt engineering becomes increasingly evident.
Designing suitable prompts for specific visual tasks has emerged as a
meaningful research direction. This review aims to summarize the methods
employed in the computer vision domain for large vision models and visual
prompt engineering, exploring the latest advancements in visual prompt
engineering. We present influential large models in the visual domain and a
range of prompt engineering methods employed on these models. It is our hope
that this review provides a comprehensive and systematic description of prompt
engineering methods based on large visual models, offering valuable insights
for future researchers in their exploration of this field.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Review helps learn better: Temporal Supervised Knowledge Distillation</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00811</p>
  <p><b>作者</b>：Dongwei Wang,  Zhi Han,  Yanmei Wang,  Xiai Chen,  Baichen Liu,  Yandong Tang</p>
  <p><b>备注</b>：Under review in NIPS 2023</p>
  <p><b>关键词</b>：Reviewing plays, plays an important, important role, knowledge, network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reviewing plays an important role when learning knowledge. The knowledge
acquisition at a certain time point may be strongly inspired with the help of
previous experience. Thus the knowledge growing procedure should show strong
relationship along the temporal dimension. In our research, we find that during
the network training, the evolution of feature map follows temporal sequence
property. A proper temporal supervision may further improve the network
training performance. Inspired by this observation, we design a novel knowledge
distillation method. Specifically, we extract the spatiotemporal features in
the different training phases of student by convolutional Long Short-term
memory network (Conv-LSTM). Then, we train the student net through a dynamic
target, rather than static teacher network features. This process realizes the
refinement of old knowledge in student network, and utilizes them to assist
current learning. Extensive experiments verify the effectiveness and advantages
of our method over existing knowledge distillation methods, including various
network architectures, different tasks (image classification and object
detection) .</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Evaluating Shutdown Avoidance of Language Models in Textual Scenarios</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00787</p>
  <p><b>作者</b>：Teun van der Weij,  Simon Lermen,  Leon lang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluating large language, dangerous capabilities, large language models, language models, increase in interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there has been an increase in interest in evaluating large language
models for emergent and dangerous capabilities. Importantly, agents could
reason that in some scenarios their goal is better achieved if they are not
turned off, which can lead to undesirable behaviors. In this paper, we
investigate the potential of using toy textual scenarios to evaluate
instrumental reasoning and shutdown avoidance in language models such as GPT-4
and Claude. Furthermore, we explore whether shutdown avoidance is merely a
result of simple pattern matching between the dataset and the prompt or if it
is a consistent behaviour across different environments and variations.
We evaluated behaviours manually and also experimented with using language
models for automatic evaluations, and these evaluations demonstrate that simple
pattern matching is likely not the sole contributing factor for shutdown
avoidance. This study provides insights into the behaviour of language models
in shutdown avoidance scenarios and inspires further research on the use of
textual scenarios for evaluations.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：ContextSpeech: Expressive and Efficient Text-to-Speech for Paragraph  Reading</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00782</p>
  <p><b>作者</b>：Yujia Xiao,  Shaofei Zhang,  Xi Wang,  Xu Tan,  Lei He,  Sheng Zhao,  Frank K. Soong,  Tan Lee</p>
  <p><b>备注</b>：5 pages, 4 figures, accepted by INTERSPEECH 2023</p>
  <p><b>关键词</b>：meet great challenges, generate natural speech, generate natural, meet great, great challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While state-of-the-art Text-to-Speech systems can generate natural speech of
very high quality at sentence level, they still meet great challenges in speech
generation for paragraph / long-form reading. Such deficiencies are due to i)
ignorance of cross-sentence contextual information, and ii) high computation
and memory cost for long-form synthesis. To address these issues, this work
develops a lightweight yet effective TTS system, ContextSpeech. Specifically,
we first design a memory-cached recurrence mechanism to incorporate global text
and speech context into sentence encoding. Then we construct
hierarchically-structured textual semantics to broaden the scope for global
context enhancement. Additionally, we integrate linearized self-attention to
improve model efficiency. Experiments show that ContextSpeech significantly
improves the voice quality and prosody expressiveness in paragraph reading with
competitive model efficiency. Audio samples are available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：GA-DRL: Graph Neural Network-Augmented Deep Reinforcement Learning for  DAG Task Scheduling over Dynamic Vehicular Clouds</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00777</p>
  <p><b>作者</b>：Zhang Liu,  Lianfen Huang,  Zhibin Gao,  Manman Luo,  Seyyedali Hosseinalipour,  Huaiyu Dai</p>
  <p><b>备注</b>：15 pages, 12 figures, regular journal</p>
  <p><b>关键词</b>：DAG task, DAG, Vehicular clouds, modern platforms, platforms for processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vehicular clouds (VCs) are modern platforms for processing of
computation-intensive tasks over vehicles. Such tasks are often represented as
directed acyclic graphs (DAGs) consisting of interdependent vertices/subtasks
and directed edges. In this paper, we propose a graph neural network-augmented
deep reinforcement learning scheme (GA-DRL) for scheduling DAG tasks over
dynamic VCs. In doing so, we first model the VC-assisted DAG task scheduling as
a Markov decision process. We then adopt a multi-head graph attention network
(GAT) to extract the features of DAG subtasks. Our developed GAT enables a
two-way aggregation of the topological information in a DAG task by
simultaneously considering predecessors and successors of each subtask. We
further introduce non-uniform DAG neighborhood sampling through codifying the
scheduling priority of different subtasks, which makes our developed GAT
generalizable to completely unseen DAG task topologies. Finally, we augment GAT
into a double deep Q-network learning module to conduct subtask-to-vehicle
assignment according to the extracted features of subtasks, while considering
the dynamics and heterogeneity of the vehicles in VCs. Through simulating
various DAG tasks under real-world movement traces of vehicles, we demonstrate
that GA-DRL outperforms existing benchmarks in terms of DAG task completion
time.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：DifFSS: Diffusion Model for Few-Shot Semantic Segmentation</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00773</p>
  <p><b>作者</b>：Weimin Tan,  Siyuan Chen,  Bo Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated excellent performance, FSS models, FSS, diffusion model, FSS task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have demonstrated excellent performance in image generation.
Although various few-shot semantic segmentation (FSS) models with different
network structures have been proposed, performance improvement has reached a
bottleneck. This paper presents the first work to leverage the diffusion model
for FSS task, called DifFSS. DifFSS, a novel FSS paradigm, can further improve
the performance of the state-of-the-art FSS models by a large margin without
modifying their network structure. Specifically, we utilize the powerful
generation ability of diffusion models to generate diverse auxiliary support
images by using the semantic mask, scribble or soft HED boundary of the support
image as control conditions. This generation process simulates the variety
within the class of the query image, such as color, texture variation,
lighting, $etc$. As a result, FSS models can refer to more diverse support
images, yielding more robust representations, thereby achieving a consistent
improvement in segmentation performance. Extensive experiments on three
publicly available datasets based on existing advanced FSS models demonstrate
the effectiveness of the diffusion model for FSS task. Furthermore, we explore
in detail the impact of different input settings of the diffusion model on
segmentation performance. Hopefully, this completely new paradigm will bring
inspiration to the study of FSS task integrated with AI-generated content.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Hierarchical Open-vocabulary Universal Image Segmentation</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00764</p>
  <p><b>作者</b>：Xudong Wang,  Shufan Li,  Konstantinos Kallidromitis,  Yusuke Kato,  Kazuki Kozuka,  Trevor Darrell</p>
  <p><b>备注</b>：Project web-page: this http URL</p>
  <p><b>关键词</b>：arbitrary text descriptions, text descriptions, aims to partition, arbitrary text, image segmentation aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-vocabulary image segmentation aims to partition an image into semantic
regions according to arbitrary text descriptions. However, complex visual
scenes can be naturally decomposed into simpler parts and abstracted at
multiple levels of granularity, introducing inherent segmentation ambiguity.
Unlike existing methods that typically sidestep this ambiguity and treat it as
an external factor, our approach actively incorporates a hierarchical
representation encompassing different semantic-levels into the learning
process. We propose a decoupled text-image fusion mechanism and representation
learning modules for both "things" and "stuff".1 Additionally, we
systematically examine the differences that exist in the textual and visual
features between these types of categories. Our resulting model, named HIPIE,
tackles HIerarchical, oPen-vocabulary, and unIvErsal segmentation tasks within
a unified framework. Benchmarked on over 40 datasets, e.g., ADE20K, COCO,
Pascal-VOC Part, RefCOCO/RefCOCOg, ODinW and SeginW, HIPIE achieves the
state-of-the-art results at various levels of image comprehension, including
semantic-level (e.g., semantic segmentation), instance-level (e.g.,
panoptic/referring segmentation and object detection), as well as part-level
(e.g., part/subpart segmentation) tasks. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Towards Real Smart Apps: Investigating Human-AI Interactions in  Smartphone On-Device AI Apps</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00756</p>
  <p><b>作者</b>：Jason Ching Yuen Siu,  Jieshan Chen,  Yujin Huang,  Zhenchang Xing,  Chunyang Chen</p>
  <p><b>备注</b>：14 pages, 6 figures</p>
  <p><b>关键词</b>：deep learning techniques, increase market competitiveness, enabling advanced tasks, learning techniques, speech translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the emergence of deep learning techniques, smartphone apps are now
embedded on-device AI features for enabling advanced tasks like speech
translation, to attract users and increase market competitiveness. A good
interaction design is important to make an AI feature usable and
understandable. However, AI features have their unique challenges like
sensitiveness to the input, dynamic behaviours and output uncertainty. Existing
guidelines and tools either do not cover AI features or consider mobile apps
which are confirmed by our informal interview with professional designers. To
address these issues, we conducted the first empirical study to explore
user-AI-interaction in mobile apps. We aim to understand the status of
on-device AI usage by investigating 176 AI apps from 62,822 apps. We identified
255 AI features and summarised 759 implementations into three primary
interaction pattern types. We further implemented our findings into a
multi-faceted search-enabled gallery. The results of the user study demonstrate
the usefulness of our findings.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：ImDiffusion: Imputed Diffusion Models for Multivariate Time Series  Anomaly Detection</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00754</p>
  <p><b>作者</b>：Yuhang Chen,  Chaoyun Zhang,  Minghua Ma,  Yudong Liu,  Ruomeng Ding,  Bowen Li,  Shilin He,  Saravan Rajmohan,  Qingwei Lin,  Dongmei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, Anomaly detection, multivariate time series, diverse domains, paramount importance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection in multivariate time series data is of paramount importance
for ensuring the efficient operation of large-scale systems across diverse
domains. However, accurately detecting anomalies in such data poses significant
challenges. Existing approaches, including forecasting and reconstruction-based
methods, struggle to address these challenges effectively. To overcome these
limitations, we propose a novel anomaly detection framework named ImDiffusion,
which combines time series imputation and diffusion models to achieve accurate
and robust anomaly detection. The imputation-based approach employed by
ImDiffusion leverages the information from neighboring values in the time
series, enabling precise modeling of temporal and inter-correlated
dependencies, reducing uncertainty in the data, thereby enhancing the
robustness of the anomaly detection process. ImDiffusion further leverages
diffusion models as time series imputers to accurately capturing complex
dependencies. We leverage the step-by-step denoised outputs generated during
the inference process to serve as valuable signals for anomaly prediction,
resulting in improved accuracy and robustness of the detection process.
We evaluate the performance of ImDiffusion via extensive experiments on
benchmark datasets. The results demonstrate that our proposed framework
significantly outperforms state-of-the-art approaches in terms of detection
accuracy and timeliness. ImDiffusion is further integrated into the real
production system in Microsoft and observe a remarkable 11.4% increase in
detection F1 score compared to the legacy approach. To the best of our
knowledge, ImDiffusion represents a pioneering approach that combines
imputation-based techniques with time series anomaly detection, while
introducing the novel use of diffusion models to the field.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Population Age Group Sensitivity for COVID-19 Infections with Deep  Learning</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00751</p>
  <p><b>作者</b>：Md Khairul Islam,  Tyler Valentine,  Royal Wang,  Levi Davis,  Matt Manner,  Judy Fox</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：healthcare systems worldwide, created unprecedented challenges, Modified Morris Method, Temporal Fusion Transformer, age groups</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The COVID-19 pandemic has created unprecedented challenges for governments
and healthcare systems worldwide, highlighting the critical importance of
understanding the factors that contribute to virus transmission. This study
aimed to identify the most influential age groups in COVID-19 infection rates
at the US county level using the Modified Morris Method and deep learning for
time series. Our approach involved training the state-of-the-art time-series
model Temporal Fusion Transformer on different age groups as a static feature
and the population vaccination status as the dynamic feature. We analyzed the
impact of those age groups on COVID-19 infection rates by perturbing individual
input features and ranked them based on their Morris sensitivity scores, which
quantify their contribution to COVID-19 transmission rates. The findings are
verified using ground truth data from the CDC and US Census, which provide the
true infection rates for each age group. The results suggest that young adults
were the most influential age group in COVID-19 transmission at the county
level between March 1, 2020, and November 27, 2021. Using these results can
inform public health policies and interventions, such as targeted vaccination
strategies, to better control the spread of the virus. Our approach
demonstrates the utility of feature sensitivity analysis in identifying
critical factors contributing to COVID-19 transmission and can be applied in
other public health domains.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Feasibility of Universal Anomaly Detection without Knowing the  Abnormality in Medical Images</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00750</p>
  <p><b>作者</b>：Can Cui,  Yaohong Wang,  Shunxing Bao,  Yucheng Tang,  Ruining Deng,  Lucas W. Remedios,  Zuhayr Asad,  Joseph T. Roland,  Ken S. Lau,  Qi Liu,  Lori A. Coburn,  Keith T. Wilson,  Bennett A. Landman,  Yuankai Huo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：anomaly detection, anomaly detection approaches, anomaly detection methods, deep learning methods, identify abnormal image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many anomaly detection approaches, especially deep learning methods, have
been recently developed to identify abnormal image morphology by only employing
normal images during training. Unfortunately, many prior anomaly detection
methods were optimized for a specific "known" abnormality (e.g., brain tumor,
bone fraction, cell types). Moreover, even though only the normal images were
used in the training process, the abnormal images were oftenly employed during
the validation process (e.g., epoch selection, hyper-parameter tuning), which
might leak the supposed ``unknown" abnormality unintentionally. In this study,
we investigated these two essential aspects regarding universal anomaly
detection in medical images by (1) comparing various anomaly detection methods
across four medical datasets, (2) investigating the inevitable but often
neglected issues on how to unbiasedly select the optimal anomaly detection
model during the validation phase using only normal images, and (3) proposing a
simple decision-level ensemble method to leverage the advantage of different
kinds of anomaly detection without knowing the abnormality. The results of our
experiments indicate that none of the evaluated methods consistently achieved
the best performance across all datasets. Our proposed method enhanced the
robustness of performance in general (average AUC 0.956).</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：UnLoc: A Universal Localization Method for Autonomous Vehicles using  LiDAR, Radar and/or Camera Input</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00741</p>
  <p><b>作者</b>：Muhammad Ibrahim,  Naveed Akhtar,  Saeed Anwar,  Ajmal Mian</p>
  <p><b>备注</b>：UnLoc: A Universal Localization Method for Autonomous Vehicles using LiDAR, Radar and/or Camera Input has been accepted for publication in the Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</p>
  <p><b>关键词</b>：autonomous navigation, fundamental task, task in robotics, robotics for autonomous, Localization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Localization is a fundamental task in robotics for autonomous navigation.
Existing localization methods rely on a single input data modality or train
several computational models to process different modalities. This leads to
stringent computational requirements and sub-optimal results that fail to
capitalize on the complementary information in other data streams. This paper
proposes UnLoc, a novel unified neural modeling approach for localization with
multi-sensor input in all weather conditions. Our multi-stream network can
handle LiDAR, Camera and RADAR inputs for localization on demand, i.e., it can
work with one or more input sensors, making it robust to sensor failure. UnLoc
uses 3D sparse convolutions and cylindrical partitioning of the space to
process LiDAR frames and implements ResNet blocks with a slot attention-based
feature filtering module for the Radar and image modalities. We introduce a
unique learnable modality encoding scheme to distinguish between the input
sensor data. Our method is extensively evaluated on Oxford Radar RobotCar,
ApolloSouthBay and Perth-WA datasets. The results ascertain the efficacy of our
technique.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Novelty and Lifted Helpful Actions in Generalized Planning</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00735</p>
  <p><b>作者</b>：Chao Lei,  Nir Lipovetzky,  Krista A. Ehinger</p>
  <p><b>备注</b>：Accepted at SoCS 2023 (extended version)</p>
  <p><b>关键词</b>：heuristics and landmarks, shown recently, recently that successful, successful techniques, techniques in classical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It has been shown recently that successful techniques in classical planning,
such as goal-oriented heuristics and landmarks, can improve the ability to
compute planning programs for generalized planning (GP) problems. In this work,
we introduce the notion of action novelty rank, which computes novelty with
respect to a planning program, and propose novelty-based generalized planning
solvers, which prune a newly generated planning program if its most frequent
action repetition is greater than a given bound $v$, implemented by
novelty-based best-first search BFS($v$) and its progressive variant PGP($v$).
Besides, we introduce lifted helpful actions in GP derived from action schemes,
and propose new evaluation functions and structural program restrictions to
scale up the search. Our experiments show that the new algorithms BFS($v$) and
PGP($v$) outperform the state-of-the-art in GP over the standard generalized
planning benchmarks. Practical findings on the above-mentioned methods in
generalized planning are briefly discussed.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Worth of knowledge in deep learning</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00712</p>
  <p><b>作者</b>：Hao Xu,  Yuntian Chen,  Dongxiao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constitutes the accumulated, experience that humans, gain insight, Knowledge, prior knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge constitutes the accumulated understanding and experience that
humans use to gain insight into the world. In deep learning, prior knowledge is
essential for mitigating shortcomings of data-driven models, such as data
dependence, generalization ability, and compliance with constraints. To enable
efficient evaluation of the worth of knowledge, we present a framework inspired
by interpretable machine learning. Through quantitative experiments, we assess
the influence of data volume and estimation range on the worth of knowledge.
Our findings elucidate the complex relationship between data and knowledge,
including dependence, synergistic, and substitution effects. Our model-agnostic
framework can be applied to a variety of common network architectures,
providing a comprehensive understanding of the role of prior knowledge in deep
learning models. It can also be used to improve the performance of informed
machine learning, as well as distinguish improper prior knowledge.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and  Privacy</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00691</p>
  <p><b>作者</b>：Maanak Gupta,  CharanKumar Akiri,  Kshitiz Aryal,  Eli Parker,  Lopamudra Praharaj</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evolution of Generative, Google Bard continue, digital transformation, GenAI, Google Bard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Undoubtedly, the evolution of Generative AI (GenAI) models has been the
highlight of digital transformation in the year 2022. As the different GenAI
models like ChatGPT and Google Bard continue to foster their complexity and
capability, it's critical to understand its consequences from a cybersecurity
perspective. Several instances recently have demonstrated the use of GenAI
tools in both the defensive and offensive side of cybersecurity, and focusing
on the social, ethical and privacy implications this technology possesses. This
research paper highlights the limitations, challenges, potential risks, and
opportunities of GenAI in the domain of cybersecurity and privacy. The work
presents the vulnerabilities of ChatGPT, which can be exploited by malicious
users to exfiltrate malicious information bypassing the ethical constraints on
the model. This paper demonstrates successful example attacks like Jailbreaks,
reverse psychology, and prompt injection attacks on the ChatGPT. The paper also
investigates how cyber offenders can use the GenAI tools in developing cyber
attacks, and explore the scenarios where ChatGPT can be used by adversaries to
create social engineering attacks, phishing attacks, automated hacking, attack
payload generation, malware creation, and polymorphic malware. This paper then
examines defense techniques and uses GenAI tools to improve security measures,
including cyber defense automation, reporting, threat intelligence, secure code
generation and detection, attack identification, developing ethical guidelines,
incidence response plans, and malware detection. We will also discuss the
social, legal, and ethical implications of ChatGPT. In conclusion, the paper
highlights open challenges and future directions to make this GenAI secure,
safe, trustworthy, and ethical as the community understands its cybersecurity
impacts.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary  Directed Differential with Normalized Density and Self-Adaption</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00677</p>
  <p><b>作者</b>：Hao Shu</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：popular clustering algorithm, low-density regions, high-density region, arbitrary shape, shape as long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Density-based clustering could be the most popular clustering algorithm since
it can identify clusters of arbitrary shape as long as different (high-density)
clusters are separated by low-density regions. However, the requirement of the
separateness of clusters by low-density regions is not trivial since a
high-density region might have different structures which should be clustered
into different groups. Such a situation demonstrates the main flaw of all
previous density-based clustering algorithms we have known--structures in a
high-density cluster could not be detected. Therefore, this paper aims to
provide a density-based clustering scheme that not only has the ability
previous ones have but could also detect structures in a high-density region
not separated by low-density ones. The algorithm employs secondary directed
differential, hierarchy, normalized density, as well as the self-adaption
coefficient, and thus is called Structure Detecting Cluster by Hierarchical
Secondary Directed Differential with Normalized Density and Self-Adaption,
dubbed by SDC-HSDD-NDSA for short. To illustrate its effectiveness, we run the
algorithm in several data sets. The results verify its validity in structure
detection, robustness over noises, as well as independence of granularities,
and demonstrate that it could outperform previous ones. The Python code of the
paper could be found on this https URL.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Solving Multi-Agent Target Assignment and Path Finding with a Single  Constraint Tree</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00663</p>
  <p><b>作者</b>：Yimin Tang,  Zhongqiang Ren,  Jiaoyang Li,  Katia Sycara</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：requires simultaneously assigning, planning collision-free paths, simultaneously assigning targets, K-best target assignments, Combined Target-Assignment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combined Target-Assignment and Path-Finding problem (TAPF) requires
simultaneously assigning targets to agents and planning collision-free paths
for agents from their start locations to their assigned targets. As a leading
approach to address TAPF, Conflict-Based Search with Target Assignment (CBS-TA)
leverages both K-best target assignments to create multiple search trees and
Conflict-Based Search (CBS) to resolve collisions in each search tree. While
being able to find an optimal solution, CBS-TA suffers from scalability due to
the duplicated collision resolution in multiple trees and the expensive
computation of K-best assignments. We therefore develop Incremental Target
Assignment CBS (ITA-CBS) to bypass these two computational bottlenecks. ITA-CBS
generates only a single search tree and avoids computing K-best assignments by
incrementally computing new 1-best assignments during the search. We show that,
in theory, ITA-CBS is guaranteed to find an optimal solution and, in practice,
is computationally efficient.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Minimum Levels of Interpretability for Artificial Moral Agents</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00660</p>
  <p><b>作者</b>：Avish Vijayaraghavan,  Cosmin Badea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：continue to scale, capable and integrated, artificial intelligence, decision-making systems, models continue</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As artificial intelligence (AI) models continue to scale up, they are
becoming more capable and integrated into various forms of decision-making
systems. For models involved in moral decision-making, also known as artificial
moral agents (AMA), interpretability provides a way to trust and understand the
agent's internal reasoning mechanisms for effective use and error correction.
In this paper, we provide an overview of this rapidly-evolving sub-field of AI
interpretability, introduce the concept of the Minimum Level of
Interpretability (MLI) and recommend an MLI for various types of agents, to aid
their safe deployment in real-world settings.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Neuro-Symbolic Sudoku Solver</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00653</p>
  <p><b>作者</b>：Ashutosh Hathidara,  Lalit Pandey</p>
  <p><b>备注</b>：Published as a conference paper at KDD KiML 2023</p>
  <p><b>关键词</b>：achieved great success, Deep Neural Networks, Neural Networks, modern Neural Networks, Neural Networks fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Neural Networks have achieved great success in some of the complex tasks
that humans can do with ease. These include image recognition/classification,
natural language processing, game playing etc. However, modern Neural Networks
fail or perform poorly when trained on tasks that can be solved easily using
backtracking and traditional algorithms. Therefore, we use the architecture of
the Neuro Logic Machine (NLM) and extend its functionality to solve a 9X9 game
of Sudoku. To expand the application of NLMs, we generate a random grid of
cells from a dataset of solved games and assign up to 10 new empty cells. The
goal of the game is then to find a target value ranging from 1 to 9 and fill in
the remaining empty cells while maintaining a valid configuration. In our
study, we showcase an NLM which is capable of obtaining 100% accuracy for
solving a Sudoku with empty cells ranging from 3 to 10. The purpose of this
study is to demonstrate that NLMs can also be used for solving complex problems
and games like Sudoku. We also analyze the behaviour of NLMs with a
backtracking algorithm by comparing the convergence time using a graph plot on
the same problem. With this study we show that Neural Logic Machines can be
trained on the tasks that traditional Deep Learning architectures fail using
Reinforcement Learning. We also aim to propose the importance of symbolic
learning in explaining the systematicity in the hybrid model of NLMs.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Intra- & Extra-Source Exemplar-Based Style Synthesis for Improved Domain  Generalization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00648</p>
  <p><b>作者</b>：Yumeng Li,  Dan Zhang,  Margret Keuper,  Anna Khoreva</p>
  <p><b>备注</b>：An extended version of the accepted WACV paper arXiv:2210.10175</p>
  <p><b>关键词</b>：remaining big challenges, deep learning models, autonomous driving, remaining big, big challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The generalization with respect to domain shifts, as they frequently appear
in applications such as autonomous driving, is one of the remaining big
challenges for deep learning models. Therefore, we propose an exemplar-based
style synthesis pipeline to improve domain generalization in semantic
segmentation. Our method is based on a novel masked noise encoder for StyleGAN2
inversion. The model learns to faithfully reconstruct the image, preserving its
semantic layout through noise prediction. Using the proposed masked noise
encoder to randomize style and content combinations in the training set, i.e.,
intra-source style augmentation (ISSA) effectively increases the diversity of
training data and reduces spurious correlation. As a result, we achieve up to
$12.4\%$ mIoU improvements on driving-scene semantic segmentation under
different types of data shifts, i.e., changing geographic locations, adverse
weather conditions, and day to night. ISSA is model-agnostic and
straightforwardly applicable with CNNs and Transformers. It is also
complementary to other domain generalization techniques, e.g., it improves the
recent state-of-the-art solution RobustNet by $3\%$ mIoU in Cityscapes to Dark
Zürich. In addition, we demonstrate the strong plug-n-play ability of the
proposed style synthesis pipeline, which is readily usable for extra-source
exemplars e.g., web-crawled images, without any retraining or fine-tuning.
Moreover, we study a new use case to indicate neural network's generalization
capability by building a stylized proxy validation set. This application has
significant practical sense for selecting models to be deployed in the
open-world environment. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Effects of Explanation Specificity on Passengers in Autonomous Driving</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00633</p>
  <p><b>作者</b>：Daniel Omeiza,  Raunak Bhattacharyya,  Nick Hawes,  Marina Jirotka,  Lars Kunze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-computer interaction community, interaction community, topic of interest, human-computer interaction, explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The nature of explanations provided by an explainable AI algorithm has been a
topic of interest in the explainable AI and human-computer interaction
community. In this paper, we investigate the effects of natural language
explanations' specificity on passengers in autonomous driving. We extended an
existing data-driven tree-based explainer algorithm by adding a rule-based
option for explanation generation. We generated auditory natural language
explanations with different levels of specificity (abstract and specific) and
tested these explanations in a within-subject user study (N=39) using an
immersive physical driving simulation setup. Our results showed that both
abstract and specific explanations had similar positive effects on passengers'
perceived safety and the feeling of anxiety. However, the specific explanations
influenced the desire of passengers to takeover driving control from the
autonomous vehicle (AV), while the abstract explanations did not. We conclude
that natural language auditory explanations are useful for passengers in
autonomous driving, and their specificity levels could influence how much
in-vehicle participants would wish to be in control of the driving activity.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Solving Linear Inverse Problems Provably via Posterior Sampling with  Latent Diffusion Models</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00619</p>
  <p><b>作者</b>：Litu Rout,  Negin Raoof,  Giannis Daras,  Constantine Caramanis,  Alexandros G. Dimakis,  Sanjay Shakkottai</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：leveraging pre-trained latent, pre-trained latent diffusion, solve linear inverse, inverse problems leveraging, problems leveraging pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the first framework to solve linear inverse problems leveraging
pre-trained latent diffusion models. Previously proposed algorithms (such as
DPS and DDRM) only apply to pixel-space diffusion models. We theoretically
analyze our algorithm showing provable sample recovery in a linear model
setting. The algorithmic insight obtained from our analysis extends to more
general settings often considered in practice. Experimentally, we outperform
previously proposed posterior sampling algorithms in a wide variety of problems
including random inpainting, block inpainting, denoising, deblurring,
destriping, and super-resolution.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：The Forward-Forward Algorithm as a feature extractor for skin lesion  classification: A preliminary study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00617</p>
  <p><b>作者</b>：Abel Reyes-Angulo,  Sidike Paheding</p>
  <p><b>备注</b>：This is a camera-ready version of the paper for the LXAI @ ICML'23 workshop</p>
  <p><b>关键词</b>：deadly form, form of cancer, cancer, survival rate, Skin cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin cancer, a deadly form of cancer, exhibits a 23\% survival rate in the
USA with late diagnosis. Early detection can significantly increase the
survival rate, and facilitate timely treatment. Accurate biomedical image
classification is vital in medical analysis, aiding clinicians in disease
diagnosis and treatment. Deep learning (DL) techniques, such as convolutional
neural networks and transformers, have revolutionized clinical decision-making
automation. However, computational cost and hardware constraints limit the
implementation of state-of-the-art DL architectures. In this work, we explore a
new type of neural network that does not need backpropagation (BP), namely the
Forward-Forward Algorithm (FFA), for skin lesion classification. While FFA is
claimed to use very low-power analog hardware, BP still tends to be superior in
terms of classification accuracy. In addition, our experimental results suggest
that the combination of FFA and BP can be a better alternative to achieve a
more accurate prediction.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：RH20T: A Robotic Dataset for Learning Diverse Skills in One-Shot</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00595</p>
  <p><b>作者</b>：Hao-Shu Fang,  Hongjie Fang,  Zhenyu Tang,  Jirong Liu,  Junbo Wang,  Haoyi Zhu,  Cewu Lu</p>
  <p><b>备注</b>：RSS 2023 workshop on LTAMP. The project page is at rh20t.github.io</p>
  <p><b>关键词</b>：key challenge, challenge in robotic, open domains, skills, generalizable skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key challenge in robotic manipulation in open domains is how to acquire
diverse and generalizable skills for robots. Recent research in one-shot
imitation learning has shown promise in transferring trained policies to new
tasks based on demonstrations. This feature is attractive for enabling robots
to acquire new skills and improving task and motion planning. However, due to
limitations in the training dataset, the current focus of the community has
mainly been on simple cases, such as push or pick-place tasks, relying solely
on visual guidance. In reality, there are many complex skills, some of which
may even require both visual and tactile perception to solve. This paper aims
to unlock the potential for an agent to generalize to hundreds of real-world
skills with multi-modal perception. To achieve this, we have collected a
dataset comprising over 110,000 \emph{contact-rich} robot manipulation
sequences across diverse skills, contexts, robots, and camera viewpoints, all
collected \emph{in the real world}. Each sequence in the dataset includes
visual, force, audio, and action information, along with a corresponding human
demonstration video. We have invested significant efforts in calibrating all
the sensors and ensuring a high-quality dataset. The dataset is made publicly
available at this http URL</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed  Search Logs for Zero-shot Biomedical Information Retrieval</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00589</p>
  <p><b>作者</b>：Qiao Jin,  Won Kim,  Qingyu Chen,  Donald C. Comeau,  Lana Yeganova,  John Wilbur,  Zhiyong Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical decision support, biomedical knowledge acquisition, decision support, Information retrieval, knowledge acquisition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information retrieval (IR) is essential in biomedical knowledge acquisition
and clinical decision support. While recent progress has shown that language
model encoders perform better semantic retrieval, training such models requires
abundant query-article annotations that are difficult to obtain in biomedicine.
As a result, most biomedical IR systems only conduct lexical matching. In
response, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained
Transformer model for zero-shot biomedical IR. To train BioCPT, we collected an
unprecedented scale of 255 million user click logs from PubMed. With such data,
we use contrastive learning to train a pair of closely-integrated retriever and
re-ranker. Experimental results show that BioCPT sets new state-of-the-art
performance on five biomedical IR tasks, outperforming various baselines
including much larger models such as GPT-3-sized cpt-text-XL. In addition,
BioCPT also generates better biomedical article and sentence representations
for semantic evaluations. As such, BioCPT can be readily applied to various
real-world biomedical IR tasks. BioCPT API and code are publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Adaptive reinforcement learning of multi-agent ethically-aligned  behaviours: the QSOM and QDSOM algorithms</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00552</p>
  <p><b>作者</b>：Rémy Chaput,  Olivier Boissier,  Mathieu Guillermin</p>
  <p><b>备注</b>：30 pages, 7 figures, 7 tables</p>
  <p><b>关键词</b>：deployed Artificial Intelligence, numerous deployed Artificial, Artificial Intelligence systems, Artificial Intelligence, deployed Artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The numerous deployed Artificial Intelligence systems need to be aligned with
our ethical considerations. However, such ethical considerations might change
as time passes: our society is not fixed, and our social mores evolve. This
makes it difficult for these AI systems; in the Machine Ethics field
especially, it has remained an under-studied challenge. In this paper, we
present two algorithms, named QSOM and QDSOM, which are able to adapt to
changes in the environment, and especially in the reward function, which
represents the ethical considerations that we want these systems to be aligned
with. They associate the well-known Q-Table to (Dynamic) Self-Organizing Maps
to handle the continuous and multi-dimensional state and action spaces. We
evaluate them on a use-case of multi-agent energy repartition within a small
Smart Grid neighborhood, and prove their ability to adapt, and their higher
performance compared to baseline Reinforcement Learning algorithms.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Defending Against Malicious Behaviors in Federated Learning with  Blockchain</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00543</p>
  <p><b>作者</b>：Nanqing Dong,  Zhipeng Wang,  Jiahao Sun,  Michael Kampffmeyer,  Yizhe Wen,  Shuoying Zhang,  William Knottenbelt,  Eric Xing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-institutional data owners, compromising data privacy, train machine learning, collaboratively train machine, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of deep learning, federated learning (FL) presents a promising
approach that allows multi-institutional data owners, or clients, to
collaboratively train machine learning models without compromising data
privacy. However, most existing FL approaches rely on a centralized server for
global model aggregation, leading to a single point of failure. This makes the
system vulnerable to malicious attacks when dealing with dishonest clients. In
this work, we address this problem by proposing a secure and reliable FL system
based on blockchain and distributed ledger technology. Our system incorporates
a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are
powered by on-chain smart contracts, to detect and deter malicious behaviors.
Both theoretical and empirical analyses are presented to demonstrate the
effectiveness of the proposed approach, showing that our framework is robust
against malicious client-side behaviors.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Collaborative Policy Learning for Dynamic Scheduling Tasks in  Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00541</p>
  <p><b>作者</b>：Do-Yup Kim,  Da-Eun Lee,  Ji-Wan Kim,  Hyun-Suk Lee</p>
  <p><b>备注</b>：14 pages, 16 figures, IEEEtran.cls</p>
  <p><b>关键词</b>：IoT networks, central policy, policy, undertake a range, range of typical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we examine cloud-edge-terminal IoT networks, where edges
undertake a range of typical dynamic scheduling tasks. In these IoT networks, a
central policy for each task can be constructed at a cloud server. The central
policy can be then used by the edges conducting the task, thereby mitigating
the need for them to learn their own policy from scratch. Furthermore, this
central policy can be collaboratively learned at the cloud server by
aggregating local experiences from the edges, thanks to the hierarchical
architecture of the IoT networks. To this end, we propose a novel collaborative
policy learning framework for dynamic scheduling tasks using federated
reinforcement learning. For effective learning, our framework adaptively
selects the tasks for collaborative learning in each round, taking into account
the need for fairness among tasks. In addition, as a key enabler of the
framework, we propose an edge-agnostic policy structure that enables the
aggregation of local policies from different edges. We then provide the
convergence analysis of the framework. Through simulations, we demonstrate that
our proposed framework significantly outperforms the approaches without
collaborative policy learning. Notably, it accelerates the learning speed of
the policies and allows newly arrived edges to adapt to their tasks more
easily.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Graph Neural Network based Log Anomaly Detection and Explanation</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00527</p>
  <p><b>作者</b>：Zhong Li,  Jiayang Shi,  Matthijs van Leeuwen</p>
  <p><b>备注</b>：Paper submitted for possible publication</p>
  <p><b>关键词</b>：log anomaly detection, anomaly detection, anomaly detection methods, log anomaly, anomaly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event logs are widely used to record the status of high-tech systems, making
log anomaly detection important for monitoring those systems. Most existing log
anomaly detection methods take a log event count matrix or log event sequences
as input, exploiting quantitative and/or sequential relationships between log
events to detect anomalies. Unfortunately, only considering quantitative or
sequential relationships may result in many false positives and/or false
negatives. To alleviate this problem, we propose a graph-based method for
unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts
event logs into attributed, directed, and weighted graphs, and then leverages
graph neural networks to perform graph-level anomaly detection. Specifically,
we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as
OCDiGCN, a novel graph neural network model for detecting graph-level anomalies
in a collection of attributed, directed, and weighted graphs. By coupling the
graph representation and anomaly detection steps, OCDiGCN can learn a
representation that is especially suited for anomaly detection, resulting in a
high detection accuracy. Importantly, for each identified anomaly, we
additionally provide a small subset of nodes that play a crucial role in
OCDiGCN's prediction as explanations, which can offer valuable cues for
subsequent root cause diagnosis. Experiments on five benchmark datasets show
that Logs2Graphs performs at least on par state-of-the-art log anomaly
detection methods on simple datasets while largely outperforming
state-of-the-art log anomaly detection methods on complicated datasets.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00522</p>
  <p><b>作者</b>：Linoy Tsaban (1),  Apolinário Passos (1) ((1) Hugging Face)</p>
  <p><b>备注</b>：8 pages, 5 figures, 1 table. This report builds up on the works introduced in - arXiv:2304.06140, arXiv:2301.12247</p>
  <p><b>关键词</b>：Recent large-scale text-guided, large-scale text-guided diffusion, provide powerful image-generation, text-guided diffusion models, diffusion models provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent large-scale text-guided diffusion models provide powerful
image-generation capabilities. Currently, a significant effort is given to
enable the modification of these images using text only as means to offer
intuitive and versatile editing. However, editing proves to be difficult for
these generative models due to the inherent nature of editing techniques, which
involves preserving certain content from the original image. Conversely, in
text-based models, even minor modifications to the text prompt frequently
result in an entirely distinct result, making attaining one-shot generation
that accurately corresponds to the users intent exceedingly challenging. In
addition, to edit a real image using these state-of-the-art tools, one must
first invert the image into the pre-trained models domain - adding another
factor affecting the edit quality, as well as latency. In this exploratory
report, we propose LEDITS - a combined lightweight approach for real-image
editing, incorporating the Edit Friendly DDPM inversion technique with Semantic
Guidance, thus extending Semantic Guidance to real image editing, while
harnessing the editing capabilities of DDPM inversion as well. This approach
achieves versatile edits, both subtle and extensive as well as alterations in
composition and style, while requiring no optimization nor extensions to the
architecture.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for  Traffic Forecasting</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00518</p>
  <p><b>作者</b>：Binqing Wu,  Ling Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligent transportation systems, transportation systems, temporal, essential to intelligent, intelligent transportation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traffic forecasting is essential to intelligent transportation systems, which
is challenging due to the complicated spatial and temporal dependencies within
a road network. Existing works usually learn spatial and temporal dependencies
separately, ignoring the dependencies crossing spatial and temporal dimensions.
In this paper, we propose DSTCGCN, a dynamic spatial-temporal cross graph
convolution network to learn dynamic spatial and temporal dependencies jointly
via graphs for traffic forecasting. Specifically, we introduce a fast Fourier
transform (FFT) based attentive selector to choose relevant time steps for each
time step based on time-varying traffic data. Given the selected time steps, we
introduce a dynamic cross graph construction module, consisting of the spatial
graph construction, temporal connection graph construction, and fusion modules,
to learn dynamic spatial-temporal cross dependencies without pre-defined
priors. Extensive experiments on six real-world datasets demonstrate that
DSTCGCN achieves the state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：HeGeL: A Novel Dataset for Geo-Location from Hebrew Text</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00509</p>
  <p><b>作者</b>：Tzuf Paz-Argaman,  Tal Bauman,  Itai Mondshine,  Itzhak Omer,  Sagi Dalyot,  Reut Tsarfaty</p>
  <p><b>备注</b>：Accepted for ACL findings 2023</p>
  <p><b>关键词</b>：natural language understanding, retrieving the coordinates, Wikipedia and Twitter, free-form language description, textual geolocation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of textual geolocation - retrieving the coordinates of a place based
on a free-form language description - calls for not only grounding but also
natural language understanding and geospatial reasoning. Even though there are
quite a few datasets in English used for geolocation, they are currently based
on open-source data (Wikipedia and Twitter), where the location of the
described place is mostly implicit, such that the location retrieval resolution
is limited. Furthermore, there are no datasets available for addressing the
problem of textual geolocation in morphologically rich and resource-poor
languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location
(HeGeL) corpus, designed to collect literal place descriptions and analyze
lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place
descriptions of various place types in three cities in Israel. Qualitative and
empirical analysis show that the data exhibits abundant use of geospatial
reasoning and requires a novel environmental representation.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with  Stochastic Configuration Networks</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00507</p>
  <p><b>作者</b>：Wei Dai,  Jiang Liu,  Lanhao Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diagnose faults efficiently, rolling bearings, Fault diagnosis, rotating machinery, great significance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fault diagnosis of rolling bearings is of great significance for
post-maintenance in rotating machinery, but it is a challenging work to
diagnose faults efficiently with a few samples. Additionally, faults commonly
occur with randomness and fuzziness due to the complexity of the external
environment and the structure of rolling bearings, hindering effective mining
of fault characteristics and eventually restricting accuracy of fault
diagnosis. To overcome these problems, stochastic configuration network (SCN)
based cloud ensemble learning, called SCN-CEL, is developed in this work.
Concretely, a cloud feature extraction method is first developed by using a
backward cloud generator of normal cloud model to mine the uncertainty of fault
information. Then, a cloud sampling method, which generates enough cloud
droplets using bidirectional cloud generator, is proposed to extend the cloud
feature samples. Finally, an ensemble model with SCNs is developed to
comprehensively characterize the uncertainty of fault information and advance
the generalization performance of fault diagnosis machine. Experimental results
demonstrate that the proposed method indeed performs favorably for
distinguishing fault categories of rolling bearings in the few shot scenarios.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：On efficient computation in active inference</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00504</p>
  <p><b>作者</b>：Aswin Paul,  Noor Sajid,  Lancelot Da Costa,  Adeel Razi</p>
  <p><b>备注</b>：23 pages, 7 figures. Project repo: this https URL</p>
  <p><b>关键词</b>：complex environments due, inference faces difficulties, simulate intelligent behaviour, target distribution, active inference faces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite being recognized as neurobiologically plausible, active inference
faces difficulties when employed to simulate intelligent behaviour in complex
environments due to its computational cost and the difficulty of specifying an
appropriate target distribution for the agent. This paper introduces two
solutions that work in concert to address these limitations. First, we present
a novel planning algorithm for finite temporal horizons with drastically lower
computational complexity. Second, inspired by Z-learning from control theory
literature, we simplify the process of setting an appropriate target
distribution for new and existing active inference planning schemes. Our first
approach leverages the dynamic programming algorithm, known for its
computational efficiency, to minimize the cost function used in planning
through the Bellman-optimality principle. Accordingly, our algorithm
recursively assesses the expected free energy of actions in the reverse
temporal order. This improves computational efficiency by orders of magnitude
and allows precise model learning and planning, even under uncertain
conditions. Our method simplifies the planning process and shows meaningful
behaviour even when specifying only the agent's final goal state. The proposed
solutions make defining a target distribution from a goal state straightforward
compared to the more complicated task of defining a temporally informed target
distribution. The effectiveness of these methods is tested and demonstrated
through simulations in standard grid-world tasks. These advances create new
opportunities for various applications.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Don't Memorize; Mimic The Past: Federated Class Incremental Learning  Without Episodic Memory</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00497</p>
  <p><b>作者</b>：Sara Babakniya,  Zalan Fabian,  Chaoyang He,  Mahdi Soltanolkotabi,  Salman Avestimehr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：forgetting information learned, Deep learning models, information learned, Deep learning, generative model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models are prone to forgetting information learned in the past
when trained on new data. This problem becomes even more pronounced in the
context of federated learning (FL), where data is decentralized and subject to
independent changes for each user. Continual Learning (CL) studies this
so-called \textit{catastrophic forgetting} phenomenon primarily in centralized
settings, where the learner has direct access to the complete training dataset.
However, applying CL techniques to FL is not straightforward due to privacy
concerns and resource limitations. This paper presents a framework for
federated class incremental learning that utilizes a generative model to
synthesize samples from past distributions instead of storing part of past
data. Then, clients can leverage the generative model to mitigate catastrophic
forgetting locally. The generative model is trained on the server using
data-free methods at the end of each task without requesting data from clients.
Therefore, it reduces the risk of data leakage as opposed to training it on the
client's private data. We demonstrate significant improvements for the
CIFAR-100 dataset compared to existing baselines.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural  Networks for Traffic Prediction</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00495</p>
  <p><b>作者</b>：Xunlian Luo,  Chunjiang Zhu,  Detian Zhang,  Qing Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：active research topic, spatial-temporal data mining, data mining, active research, research topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traffic prediction has been an active research topic in the domain of
spatial-temporal data mining. Accurate real-time traffic prediction is
essential to improve the safety, stability, and versatility of smart city
systems, i.e., traffic control and optimal routing. The complex and highly
dynamic spatial-temporal dependencies make effective predictions still face
many challenges. Recent studies have shown that spatial-temporal graph neural
networks exhibit great potential applied to traffic prediction, which combines
sequential models with graph convolutional networks to jointly model temporal
and spatial correlations. However, a survey study of graph learning,
spatial-temporal graph models for traffic, as well as a fair comparison of
baseline models are pending and unavoidable issues. In this paper, we first
provide a systematic review of graph learning strategies and commonly used
graph convolution algorithms. Then we conduct a comprehensive analysis of the
strengths and weaknesses of recently proposed spatial-temporal graph network
models. Furthermore, we build a study called STG4Traffic using the deep
learning framework PyTorch to establish a standardized and scalable benchmark
on two types of traffic datasets. We can evaluate their performance by
personalizing the model settings with uniform metrics. Finally, we point out
some problems in the current study and discuss future directions. Source codes
are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence  Time-Series Forecasting</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00493</p>
  <p><b>作者</b>：Nhat Thanh Tran,  Jack Xin</p>
  <p><b>备注</b>：13 pages (main), 2 pages (appendix), 2 figures</p>
  <p><b>关键词</b>：fast local-global window-based, local-global window-based attention, study a fast, fast local-global, local-global window-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a fast local-global window-based attention method to accelerate
Informer for long sequence time-series forecasting. While window attention is
local and a considerable computational saving, it lacks the ability to capture
global token information which is compensated by a subsequent Fourier transform
block. Our method, named FWin, does not rely on query sparsity hypothesis and
an empirical approximation underlying the ProbSparse attention of Informer.
Through experiments on univariate and multivariate datasets, we show that FWin
transformers improve the overall prediction accuracies of Informer while
accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear
regression model that a learned FWin type attention approaches or even
outperforms softmax full attention based on key vectors extracted from an
Informer model's full attention layer acting on time series data.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：PatternGPT :A Pattern-Driven Framework for Large Language Model Text  Generation</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00470</p>
  <p><b>作者</b>：Le Xiao,  Xin Shan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, Large language, language models, shown excellent text, guide large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models(LLMs) have shown excellent text generation
capabilities, but there is still much space for improvement in accuracy,
sometimes with grammatical errors, semantic inaccuracies, and contextual
incoherence, which seriously affect the reliability of the models. These
problems may originate from the difficulties and limitations encountered in the
pattern extraction stage of large language models. How to utilize the
generative power of large language models to generate as many possible patterns
that help solve problems and find the optimal patterns from them, so as to use
patterns to guide large language models to generate good content, has become a
current research hotspot. In this paper, we propose a pattern extraction and
selection framework, PatternGPT, which generates rich patterns through the
extraction ability of large language models and draws on the idea of federation
learning, where multiple agents collaborate with each other to generate diverse
patterns. High-quality patterns are selected by defining criteria and
optimization algorithms to personalize the guidance of the model generation
process. PatternGPT has the advantages of generating diverse and useful
patterns, extending relevant knowledge, facilitating efficient pattern use and
transfer, and optimizing the quality of generated results and user experience,
which provides an effective method for optimizing the text generation
capability of large language models and is expected to drive further
development in the field of intelligent dialogue and content generation. It is
expected to promote further development in the field of intelligent dialogue
and content generation.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Human-to-Human Interaction Detection</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00464</p>
  <p><b>作者</b>：Zhenhua Wang,  Kaining Ying,  Jiajun Meng,  Jifeng Ning,  Cong Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interactive groups, concurrent interactive groups, fighting and chasing, squares and parks, understanding of interested</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A comprehensive understanding of interested human-to-human interactions in
video streams, such as queuing, handshaking, fighting and chasing, is of
immense importance to the surveillance of public security in regions like
campuses, squares and parks. Different from conventional human interaction
recognition, which uses choreographed videos as inputs, neglects concurrent
interactive groups, and performs detection and recognition in separate stages,
we introduce a new task named human-to-human interaction detection (HID). HID
devotes to detecting subjects, recognizing person-wise actions, and grouping
people according to their interactive relations, in one model. First, based on
the popular AVA dataset created for action detection, we establish a new HID
benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive
relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and
86,338 interactive groups, and each image includes up to 4 concurrent
interactive groups. Second, we present a novel baseline approach SaMFormer for
HID, containing a visual feature extractor, a split stage which leverages a
Transformer-based model to decode action instances and interactive groups, and
a merging stage which reconstructs the relationship between instances and
groups. All SaMFormer components are jointly trained in an end-to-end manner.
Extensive experiments on AVA-I validate the superiority of SaMFormer over
representative methods. The dataset and code will be made public to encourage
more follow-up studies.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Conformer LLMs -- Convolution Augmented Large Language Models</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00461</p>
  <p><b>作者</b>：Prateek Verma</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：large language models, blocks of neural, work builds, language models, popular blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work builds together two popular blocks of neural architecture, namely
convolutional layers and Transformers, for large language models (LLMs).
Non-causal conformers are used ubiquitously in automatic speech recognition.
This work aims to adapt these architectures in a causal setup for training
LLMs. Transformers decoders effectively capture long-range dependencies over
several modalities and form a core backbone of modern advancements in machine
learning. Convolutional architectures have been popular in extracting features
in domains such as raw 1-D signals, speech, and images, to name a few. In this
paper, by combining local and global dependencies over latent representations
using causal convolutional filters and Transformer, we achieve significant
gains in performance. This work showcases a robust speech architecture that can
be integrated and adapted in a causal setup beyond speech applications for
large-scale language modeling.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：WaveMixSR: A Resource-efficient Neural Network for Image  Super-resolution</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00430</p>
  <p><b>作者</b>：Pranav Jeevan,  Akella Srinidhi,  Pasunuri Prathiba,  Amit Sethi</p>
  <p><b>备注</b>：10 pages, 3 figures</p>
  <p><b>关键词</b>：super-resolution research recently, complexity of self-attention, research recently, recently been dominated, dominated by transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image super-resolution research recently been dominated by transformer models
which need higher computational resources than CNNs due to the quadratic
complexity of self-attention. We propose a new neural network -- WaveMixSR --
for image super-resolution based on WaveMix architecture which uses a
2D-discrete wavelet transform for spatial token-mixing. Unlike
transformer-based models, WaveMixSR does not unroll the image as a sequence of
pixels/patches. It uses the inductive bias of convolutions along with the
lossless token-mixing property of wavelet transform to achieve higher
performance while requiring fewer resources and training data. We compare the
performance of our network with other state-of-the-art methods for image
super-resolution. Our experiments show that WaveMixSR achieves competitive
performance in all datasets and reaches state-of-the-art performance in the
BSD100 dataset on multiple super-resolution tasks. Our model is able to achieve
this performance using less training data and computational resources while
maintaining high parameter efficiency compared to current state-of-the-art
models.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Sparsity aware generalization theory for deep neural networks</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00426</p>
  <p><b>作者</b>：Ramchandran Muthukumar,  Jeremias Sulam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remain poorly understood, Deep artificial neural, neural networks achieve, networks achieve surprising, artificial neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep artificial neural networks achieve surprising generalization abilities
that remain poorly understood. In this paper, we present a new approach to
analyzing generalization for deep feed-forward ReLU networks that takes
advantage of the degree of sparsity that is achieved in the hidden layer
activations. By developing a framework that accounts for this reduced effective
model size for each input sample, we are able to show fundamental trade-offs
between sparsity and generalization. Importantly, our results make no strong
assumptions about the degree of sparsity achieved by the model, and it improves
over recent norm-based approaches. We illustrate our results numerically,
demonstrating non-vacuous bounds when coupled with data-dependent priors in
specific settings, even in over-parametrized models.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：WavePaint: Resource-efficient Token-mixer for Self-supervised Inpainting</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00407</p>
  <p><b>作者</b>：Pranav Jeevan,  Dharshan Sampath Kumar,  Amit Sethi</p>
  <p><b>备注</b>：11 pages, 7 figures</p>
  <p><b>关键词</b>：task for self-supervision, synthesis of missing, missing regions, restore occluded, occluded or degraded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image inpainting, which refers to the synthesis of missing regions in an
image, can help restore occluded or degraded areas and also serve as a
precursor task for self-supervision. The current state-of-the-art models for
image inpainting are computationally heavy as they are based on transformer or
CNN backbones that are trained in adversarial or diffusion settings. This paper
diverges from vision transformers by using a computationally-efficient
WaveMix-based fully convolutional architecture -- WavePaint. It uses a
2D-discrete wavelet transform (DWT) for spatial and multi-resolution
token-mixing along with convolutional layers. The proposed model outperforms
the current state-of-the-art models for image inpainting on reconstruction
quality while also using less than half the parameter count and considerably
lower training and evaluation times. Our model even outperforms current
GAN-based architectures in CelebA-HQ dataset without using an adversarially
trainable discriminator. Our work suggests that neural architectures that are
modeled after natural image priors require fewer parameters and computations to
achieve generalization comparable to transformers.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00398</p>
  <p><b>作者</b>：Uddeshya Upadhyay,  Shyamgopal Karthik,  Massimiliano Mancini,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully find correspondences, CLIP successfully find, successfully find, find correspondences, CLIP successfully</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language models (VLMs) like CLIP successfully find
correspondences between images and text. Through the standard deterministic
mapping process, an image or a text sample is mapped to a single vector in the
embedding space. This is problematic: as multiple samples (images or text) can
abstract the same concept in the physical world, deterministic embeddings do
not reflect the inherent ambiguity in the embedding space. We propose ProbVLM,
a probabilistic adapter that estimates probability distributions for the
embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc
manner without needing large-scale datasets or computing. On four challenging
datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the
multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify
the calibration of embedding uncertainties in retrieval tasks and show that
ProbVLM outperforms other methods. Furthermore, we propose active learning and
model selection as two real-world downstream tasks for VLMs and show that the
estimated uncertainty aids both tasks. Lastly, we present a novel technique for
visualizing the embedding distributions using a large-scale pre-trained latent
diffusion model.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular  Data Synthesis</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00384</p>
  <p><b>作者</b>：Abdallah Alshantti,  Damiano Varagnolo,  Adil Rasheed,  Aria Rahmati,  Frank Westad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：drawn considerable attention, Generative adversarial networks, generating synthetic data, synthetic data, synthetic data samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) have drawn considerable attention in
recent years for their proven capability in generating synthetic data which can
be utilized for multiple purposes. While GANs have demonstrated tremendous
successes in producing synthetic data samples that replicate the dynamics of
the original datasets, the validity of the synthetic data and the underlying
privacy concerns represent major challenges which are not sufficiently
addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN)
for generating realistic tabular data with a specific focus on the validity of
the output. In this context, validity refers to the the dependency between
features that can be found in the real data, but is typically misrepresented by
traditional generative models. Our key idea entails that employing a cascaded
architecture in which a dedicated generator samples each feature, the synthetic
output becomes more representative of the real data. Our experimental results
demonstrate that our model well captures the constraints and the correlations
between the features of the real data, especially the high dimensional
datasets. Furthermore, we evaluate the risk of white-box privacy attacks on our
model and subsequently show that applying some perturbations to the auxiliary
learners in CasTGAN increases the overall robustness of our model against
targeted attacks.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Minimizing Energy Consumption of Deep Learning Models by Energy-Aware  Training</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00368</p>
  <p><b>作者</b>：Dario Lazzaro,  Antonio Emanuele Cinà,  Maura Pintor,  Ambra Demontis,  Battista Biggio,  Fabio Roli,  Marcello Pelillo</p>
  <p><b>备注</b>：12 pages, 3 figures. Paper accepted at the 22nd International Conference on Image Analysis and Processing (ICIAP) 2023</p>
  <p><b>关键词</b>：learning models undergo, number of parameters, larger number, number of operations, parameters they possess</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models undergo a significant increase in the number of
parameters they possess, leading to the execution of a larger number of
operations during inference. This expansion significantly contributes to higher
energy consumption and prediction latency. In this work, we propose EAT, a
gradient-based algorithm that aims to reduce energy consumption during model
training. To this end, we leverage a differentiable approximation of the
$\ell_0$ norm, and use it as a sparse penalty over the training loss. Through
our experimental analysis conducted on three datasets and two deep neural
networks, we demonstrate that our energy-aware training algorithm EAT is able
to train networks with a better trade-off between classification performance
and energy efficiency.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：The future of human-centric eXplainable Artificial Intelligence (XAI) is  not post-hoc explanations</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00364</p>
  <p><b>作者</b>：Vinitra Swamy,  Jibril Frej,  Tanja Käser</p>
  <p><b>备注</b>：Viewpoint paper, under review at JAIR</p>
  <p><b>关键词</b>：Explainable Artificial Intelligence, Artificial Intelligence, enabling human understanding, Explainable Artificial, deep learning systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable Artificial Intelligence (XAI) plays a crucial role in enabling
human understanding and trust in deep learning systems, often defined as
determining which features are most important to a model's prediction. As
models get larger, more ubiquitous, and pervasive in aspects of daily life,
explainability is necessary to avoid or minimize adverse effects of model
mistakes. Unfortunately, current approaches in human-centric XAI (e.g.
predictive tasks in healthcare, education, or personalized ads) tend to rely on
a single explainer. This is a particularly concerning trend when considering
that recent work has identified systematic disagreement in explainability
methods when applied to the same points and underlying black-box models. In
this paper, we therefore present a call for action to address the limitations
of current state-of-the-art explainers. We propose to shift from post-hoc
explainability to designing interpretable neural network architectures; moving
away from approximation techniques in human-centric and high impact
applications. We identify five needs of human-centric XAI (real-time, accurate,
actionable, human-interpretable, and consistent) and propose two schemes for
interpretable-by-design neural network workflows (adaptive routing for
interpretable conditional computation and diagnostic benchmarks for iterative
model learning). We postulate that the future of human-centric XAI is neither
in explaining black-boxes nor in reverting to traditional, interpretable
models, but in neural networks that are intrinsically interpretable.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：A Comparative Study of Machine Learning Algorithms for Anomaly Detection  in Industrial Environments: Performance and Environmental Impact</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00361</p>
  <p><b>作者</b>：Álvaro Huertas-García,  Carlos Martí-González,  Rubén García Maezo,  Alejandro Echeverría Rey</p>
  <p><b>备注</b>：29 references, 8 figures, 9 tables, 18 pages</p>
  <p><b>关键词</b>：high computational requirements, context of Industry, machine learning, machine learning algorithms, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of Industry 4.0, the use of artificial intelligence (AI) and
machine learning for anomaly detection is being hampered by high computational
requirements and associated environmental effects. This study seeks to address
the demands of high-performance machine learning models with environmental
sustainability, contributing to the emerging discourse on 'Green AI.' An
extensive variety of machine learning algorithms, coupled with various
Multilayer Perceptron (MLP) configurations, were meticulously evaluated. Our
investigation encapsulated a comprehensive suite of evaluation metrics,
comprising Accuracy, Area Under the Curve (AUC), Recall, Precision, F1 Score,
Kappa Statistic, Matthews Correlation Coefficient (MCC), and F1 Macro.
Simultaneously, the environmental footprint of these models was gauged through
considerations of time duration, CO2 equivalent, and energy consumption during
the training, cross-validation, and inference phases. Traditional machine
learning algorithms, such as Decision Trees and Random Forests, demonstrate
robust efficiency and performance. However, superior outcomes were obtained
with optimised MLP configurations, albeit with a commensurate increase in
resource consumption. The study incorporated a multi-objective optimisation
approach, invoking Pareto optimality principles, to highlight the trade-offs
between a model's performance and its environmental impact. The insights
derived underscore the imperative of striking a balance between model
performance, complexity, and environmental implications, thus offering valuable
directions for future work in the development of environmentally conscious
machine learning models for industrial applications.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：When Synthetic Data Met Regulation</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00359</p>
  <p><b>作者</b>：Georgi Ganev</p>
  <p><b>备注</b>：Accepted to the 1st Workshop on Generative AI and Law (GenLaw 2023), part of ICML 2023</p>
  <p><b>关键词</b>：produced by Differentially, synthetic data produced, argue that synthetic, Differentially, synthetic data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we argue that synthetic data produced by Differentially
Private generative models can be sufficiently anonymized and, therefore,
anonymous data and regulatory compliant.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Variation-aware Vision Transformer Quantization</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00331</p>
  <p><b>作者</b>：Xijie Huang,  Zhiqiang Shen,  Kwang-Ting Cheng</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：Vision Transformers, performance of Vision, visual tasks, remarkable performance, increased the demand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable performance of Vision Transformers (ViTs) in various
visual tasks, the expanding computation and model size of ViTs have increased
the demand for improved efficiency during training and inference. To address
the heavy computation and parameter drawbacks, quantization is frequently
studied in the community as a representative model compression technique and
has seen extensive use on CNNs. However, due to the unique properties of CNNs
and ViTs, the quantization applications on ViTs are still limited and
underexplored. In this paper, we identify the difficulty of ViT quantization on
its unique variation behaviors, which differ from traditional CNN
architectures. The variations indicate the magnitude of the parameter
fluctuations and can also measure outlier conditions. Moreover, the variation
behaviors reflect the various sensitivities to the quantization of each module.
The quantization sensitivity analysis and comparison of ViTs with CNNs help us
locate the underlying differences in variations. We also find that the
variations in ViTs cause training oscillations, bringing instability during
quantization-aware training (QAT). Correspondingly, we solve the variation
problem with an efficient knowledge-distillation-based variation-aware
quantization method. The multi-crop knowledge distillation scheme can
accelerate and stabilize the training and alleviate the variation's influence
during QAT. We also proposed a module-dependent quantization scheme and a
variation-aware regularization term to suppress the oscillation of weights. On
ImageNet-1K, we obtain a 77.66% Top-1 accuracy on the extremely low-bit
scenario of 2-bit Swin-T, outperforming the previous state-of-the-art quantized
model by 3.35%.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：DoReMi: Grounding Language Model by Detecting and Recovering from  Plan-Execution Misalignment</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00329</p>
  <p><b>作者</b>：Yanjiang Guo,  Yen-Jen Wang,  Lihan Zha,  Zheyuan Jiang,  Jianyu Chen</p>
  <p><b>备注</b>：22 pages, 12 figures</p>
  <p><b>关键词</b>：possess remarkable understanding, Large language models, language models encode, reasoning capabilities, encode a vast</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models encode a vast amount of semantic knowledge and possess
remarkable understanding and reasoning capabilities. Previous research has
explored how to ground language models in robotic tasks to ensure that the
sequences generated by the language model are both logically correct and
practically executable. However, low-level execution may deviate from the
high-level plan due to environmental perturbations or imperfect controller
design. In this paper, we propose DoReMi, a novel language model grounding
framework that enables immediate Detection and Recovery from Misalignments
between plan and execution. Specifically, during low-level skill execution, we
use a vision question answering (VQA) model to regularly detect plan-execution
misalignments. If certain misalignment occurs, our method will call the
language model to re-plan in order to recover from misalignments. Experiments
on various complex tasks including robot arms and humanoid robots demonstrate
that our method can lead to higher task success rates and shorter task
completion times. Videos of DoReMi are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：SHARCS: Shared Concept Space for Explainable Multimodal Learning</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00316</p>
  <p><b>作者</b>：Gabriele Dominici,  Pietro Barbiero,  Lucie Charlotte Magister,  Pietro Liò,  Nikola Simidjievski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex real-world problems, addressing complex real-world, individual data modalities, real-world problems, essential paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal learning is an essential paradigm for addressing complex
real-world problems, where individual data modalities are typically
insufficient to accurately solve a given modelling task. While various deep
learning approaches have successfully addressed these challenges, their
reasoning process is often opaque; limiting the capabilities for a principled
explainable cross-modal analysis and any domain-expert intervention. In this
paper, we introduce SHARCS (SHARed Concept Space) -- a novel concept-based
approach for explainable multimodal learning. SHARCS learns and maps
interpretable concepts from different heterogeneous modalities into a single
unified concept-manifold, which leads to an intuitive projection of
semantically similar cross-modal concepts. We demonstrate that such an approach
can lead to inherently explainable task predictions while also improving
downstream predictive performance. Moreover, we show that SHARCS can operate
and significantly outperform other approaches in practically significant
scenarios, such as retrieval of missing modalities and cross-modal
explanations. Our approach is model-agnostic and easily applicable to different
types (and number) of modalities, thus advancing the development of effective,
interpretable, and trustworthy multimodal approaches.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00310</p>
  <p><b>作者</b>：Anvith Thudi,  Hengrui Jia,  Casey Meehan,  Ilia Shumailov,  Nicolas Papernot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Differentially private stochastic, private deep learning, stochastic gradient descent, private stochastic gradient, Differentially private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentially private stochastic gradient descent (DP-SGD) is the canonical
algorithm for private deep learning. While it is known that its privacy
analysis is tight in the worst-case, several empirical results suggest that
when training on common benchmark datasets, the models obtained leak
significantly less privacy for many datapoints. In this paper, we develop a new
analysis for DP-SGD that captures the intuition that points with similar
neighbors in the dataset enjoy better privacy than outliers. Formally, this is
done by modifying the per-step privacy analysis of DP-SGD to introduce a
dependence on the distribution of model updates computed from a training
dataset. We further develop a new composition theorem to effectively use this
new per-step analysis to reason about an entire training run. Put all together,
our evaluation shows that this novel DP-SGD analysis allows us to now formally
show that DP-SGD leaks significantly less privacy for many datapoints. In
particular, we observe that correctly classified points obtain better privacy
guarantees than misclassified points.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D  Object Pose Estimation</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00306</p>
  <p><b>作者</b>：Fabian Duffhauss,  Sebastian Koch,  Hanna Ziesche,  Ngo Anh Vien,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at the IEEE Robotics and Automation Letters (RA-L) 2023</p>
  <p><b>关键词</b>：essential for automated, automated systems, systems to interact, interact safely, pose estimator called</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting objects and estimating their 6D poses is essential for automated
systems to interact safely with the environment. Most 6D pose estimators,
however, rely on a single camera frame and suffer from occlusions and
ambiguities due to object symmetries. We overcome this issue by presenting a
novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach
efficiently fuses the RGB-D frames from multiple perspectives in a deep
multi-directional fusion network and predicts predefined keypoints for all
objects in the scene simultaneously. Based on the keypoints and an instance
semantic segmentation, we efficiently compute the 6D poses by least-squares
fitting. To address the ambiguity issues for symmetric objects, we propose a
novel training procedure for symmetry-aware keypoint detection including a new
objective function. Our SyMFM6D network significantly outperforms the
state-of-the-art in both single-view and multi-view 6D pose estimation. We
furthermore show the effectiveness of our symmetry-aware training procedure and
demonstrate that our approach is robust towards inaccurate camera calibration
and dynamic camera setups.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：SysNoise: Exploring and Benchmarking Training-Deployment System  Inconsistency</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00280</p>
  <p><b>作者</b>：Yan Wang,  Yuhang Li,  Ruihao Gong,  Aishan Liu,  Yanfei Wang,  Jian Hu,  Yongqiang Yao,  Yunchen Zhang,  Tianzi Xiao,  Fengwei Yu,  Xianglong Liu</p>
  <p><b>备注</b>：Proceedings of Machine Learning and Systems. 2023 Mar 18</p>
  <p><b>关键词</b>：deep learning, studies have shown, deep learning training-deployment, noises caused, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extensive studies have shown that deep learning models are vulnerable to
adversarial and natural noises, yet little is known about model robustness on
noises caused by different system implementations. In this paper, we for the
first time introduce SysNoise, a frequently occurred but often overlooked noise
in the deep learning training-deployment cycle. In particular, SysNoise happens
when the source training system switches to a disparate target system in
deployments, where various tiny system mismatch adds up to a non-negligible
difference. We first identify and classify SysNoise into three categories based
on the inference stage; we then build a holistic benchmark to quantitatively
measure the impact of SysNoise on 20+ models, comprehending image
classification, object detection, instance segmentation and natural language
processing tasks. Our extensive experiments revealed that SysNoise could bring
certain impacts on model robustness across different tasks and common
mitigations like data augmentation and adversarial training show limited
effects on it. Together, our findings open a new research topic and we hope
this work will raise research attention to deep learning deployment systems
accounting for model performance. We have open-sourced the benchmark and
framework at this https URL.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Hierarchical Pretraining for Biomedical Term Embeddings</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00266</p>
  <p><b>作者</b>：Bryan Cai,  Sihang Zeng,  Yucong Lin,  Zheng Yuan,  Doudou Zhou,  Lu Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Electronic health records, provide extensive details, Electronic health, health records, provide extensive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electronic health records (EHR) contain narrative notes that provide
extensive details on the medical condition and management of patients. Natural
language processing (NLP) of clinical notes can use observed frequencies of
clinical terms as predictive features for downstream applications such as
clinical decision making and patient trajectory prediction. However, due to the
vast number of highly similar and related clinical concepts, a more effective
modeling strategy is to represent clinical terms as semantic embeddings via
representation learning and use the low dimensional embeddings as feature
vectors for predictive modeling. To achieve efficient representation,
fine-tuning pretrained language models with biomedical knowledge graphs may
generate better embeddings for biomedical terms than those from standard
language models alone. These embeddings can effectively discriminate synonymous
pairs of from those that are unrelated. However, they often fail to capture
different degrees of similarity or relatedness for concepts that are
hierarchical in nature. To overcome this limitation, we propose HiPrBERT, a
novel biomedical term representation model trained on additionally complied
data that contains hierarchical structures for various biomedical terms. We
modify an existing contrastive loss function to extract information from these
hierarchies. Our numerical experiments demonstrate that HiPrBERT effectively
learns the pair-wise distance from hierarchical information, resulting in a
substantially more informative embeddings for further biomedical applications</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：InstructEval: Systematic Evaluation of Instruction Selection Methods</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00259</p>
  <p><b>作者</b>：Anirudh Ajith,  Chris Pan,  Mengzhou Xia,  Ameet Deshpande,  Karthik Narasimhan</p>
  <p><b>备注</b>：10 content pages, 3 figures, 8 tables</p>
  <p><b>关键词</b>：large language model, In-context learning, called demonstrations, prompting a large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In-context learning (ICL) performs tasks by prompting a large language model
(LLM) using an instruction and a small set of annotated examples called
demonstrations. Recent work has shown that the precise details of the inputs
used in the prompt significantly impacts ICL, which has incentivized
instruction selection algorithms. The effect of instruction-choice however is
severely underexplored, with existing analyses being restricted to shallow
subsets of models and tasks, which limits the generalizability of their
insights. We develop an ICL evaluation suite to conduct a thorough assessment
of these techniques. The suite includes 13 open-sourced LLMs of varying scales
from 4 distinct model families and covers 9 different tasks, representing a
range of task types across 3 categories. In this work, we evaluate the relative
performance of 7 popular instruction selection methods using our benchmark over
five desiderata relevant to ICL. We discover that using curated
manually-written instructions and simple instructions without any task-specific
descriptions often elicits superior ICL performance than that of automatic
instruction-induction methods, pointing to a lack of generalizability among the
latter. We release our evaluation suite for benchmarking instruction selection
approaches, and call for more rigorous and generalizable methods in this space.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Efficient Subclass Segmentation in Medical Images</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00257</p>
  <p><b>作者</b>：Linrui Dai,  Wenhui Lei,  Xiaofan Zhang</p>
  <p><b>备注</b>：MICCAI 2023 early accept</p>
  <p><b>关键词</b>：analysis become increasingly, annotations, fine-grained, subclass, extensive annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As research interests in medical image analysis become increasingly
fine-grained, the cost for extensive annotation also rises. One feasible way to
reduce the cost is to annotate with coarse-grained superclass labels while
using limited fine-grained annotations as a complement. In this way,
fine-grained data learning is assisted by ample coarse annotations. Recent
studies in classification tasks have adopted this method to achieve
satisfactory results. However, there is a lack of research on efficient
learning of fine-grained subclasses in semantic segmentation tasks. In this
paper, we propose a novel approach that leverages the hierarchical structure of
categories to design network architecture. Meanwhile, a task-driven data
generation method is presented to make it easier for the network to recognize
different subclass categories. Specifically, we introduce a Prior Concatenation
module that enhances confidence in subclass segmentation by concatenating
predicted logits from the superclass classifier, a Separate Normalization
module that stretches the intra-class distance within the same superclass to
facilitate subclass segmentation, and a HierarchicalMix model that generates
high-quality pseudo labels for unlabeled samples by fusing only similar
superclass regions from labeled and unlabeled images. Our experiments on the
BraTS2021 and ACDC datasets demonstrate that our approach achieves comparable
accuracy to a model trained with full subclass annotations, with limited
subclass annotations and sufficient superclass annotations. Our approach offers
a promising solution for efficient fine-grained subclass segmentation in
medical images. Our code is publicly available here.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：An ML approach to resolution of singularities</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00252</p>
  <p><b>作者</b>：Gergely Bérczi,  Honglu Fan,  Mingcong Zeng</p>
  <p><b>备注</b>：To appear in Proceedings of the 40th International Conference on Machine Learning TAG Workshop (ICML-TAG 2023)</p>
  <p><b>关键词</b>：polynomial equations typically, replace singular points, solution set unchanged, singular points, typically contains ill-behaved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The solution set of a system of polynomial equations typically contains
ill-behaved, singular points. Resolution is a fundamental process in geometry
in which we replace singular points with smooth points, while keeping the rest
of the solution set unchanged. Resolutions are not unique: the usual way to
describe them involves repeatedly performing a fundamental operation known as
"blowing-up", and the complexity of the resolution highly depends on certain
choices. The process can be translated into various versions of a 2-player
game, the so-called Hironaka game, and a winning strategy for the first player
provides a solution to the resolution problem. In this paper we introduce a new
approach to the Hironaka game that uses reinforcement learning agents to find
optimal resolutions of singularities. In certain domains, the trained model
outperforms state-of-the-art selection heuristics in total number of polynomial
additions performed, which provides a proof-of-concept that recent developments
in machine learning have the potential to improve performance of algorithms in
symbolic computation.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：THUIR2 at NTCIR-16 Session Search (SS) Task</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00250</p>
  <p><b>作者</b>：Weihang Su,  Xiangsheng Li,  Yiqun Liu,  Min Zhang,  Shaoping Ma</p>
  <p><b>备注</b>：The technical report of our team at the NTCIR 16 competition. We achieved second place</p>
  <p><b>关键词</b>：Session Search, FOSS, FOSS subtask, POSS, POSS subtasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Our team(THUIR2) participated in both FOSS and POSS subtasks of the NTCIR-161
Session Search (SS) Task. This paper describes our approaches and results. In
the FOSS subtask, we submit five runs using learning-to-rank and fine-tuned
pre-trained language models. We fine-tuned the pre-trained language model with
ad-hoc data and session information and assembled them by a learning-to-rank
method. The assembled model achieves the best performance among all
participants in the preliminary evaluation. In the POSS subtask, we used an
assembled model which also achieves the best performance in the preliminary
evaluation.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：VesselMorph: Domain-Generalized Retinal Vessel Segmentation via  Shape-Aware Representation</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00240</p>
  <p><b>作者</b>：Dewei Hu,  Hao Li,  Han Liu,  Xing Yao,  Jiacheng Wang,  Ipek Oguz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standardized imaging protocol, single standardized imaging, domain shift, learning-based algorithms, single standardized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the absence of a single standardized imaging protocol, domain shift
between data acquired from different sites is an inherent property of medical
images and has become a major obstacle for large-scale deployment of
learning-based algorithms. For retinal vessel images, domain shift usually
presents as the variation of intensity, contrast and resolution, while the
basic tubular shape of vessels remains unaffected. Thus, taking advantage of
such domain-invariant morphological features can greatly improve the
generalizability of deep models. In this study, we propose a method named
VesselMorph which generalizes the 2D retinal vessel segmentation task by
synthesizing a shape-aware representation. Inspired by the traditional Frangi
filter and the diffusion tensor imaging literature, we introduce a
Hessian-based bipolar tensor field to depict the morphology of the vessels so
that the shape information is taken into account. We map the intensity image
and the tensor field to a latent space for feature extraction. Then we fuse the
two latent representations via a weight-balancing trick and feed the result to
a segmentation network. We evaluate on six public datasets of fundus and OCT
angiography images from diverse patient populations. VesselMorph achieves
superior generalization performance compared with competing methods in
different domain shift scenarios.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Forward-Forward Algorithm for Hyperspectral Image Classification: A  Preliminary Study</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00231</p>
  <p><b>作者</b>：Sidike Paheding,  Abel A. Reyes-Angulo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, cutting-edge deep learning, learning models, de-facto standard, standard in optimizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The back-propagation algorithm has long been the de-facto standard in
optimizing weights and biases in neural networks, particularly in cutting-edge
deep learning models. Its widespread adoption in fields like natural language
processing, computer vision, and remote sensing has revolutionized automation
in various tasks. The popularity of back-propagation stems from its ability to
achieve outstanding performance in tasks such as classification, detection, and
segmentation. Nevertheless, back-propagation is not without its limitations,
encompassing sensitivity to initial conditions, vanishing gradients,
overfitting, and computational complexity. The recent introduction of a
forward-forward algorithm (FFA), which computes local goodness functions to
optimize network parameters, alleviates the dependence on substantial
computational resources and the constant need for architectural scaling. This
study investigates the application of FFA for hyperspectral image
classification. Experimental results and comparative analysis are provided with
the use of the traditional back-propagation algorithm. Preliminary results show
the potential behind FFA and its promises.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Image Matters: A New Dataset and Empirical Study for Multimodal  Hyperbole Detection</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00209</p>
  <p><b>作者</b>：Huixuan Zhang,  Xiaojun Wan</p>
  <p><b>备注</b>：11 pages, 6 figures. 6 tables</p>
  <p><b>关键词</b>：common linguistic phenomenon, linguistic phenomenon, common linguistic, Hyperbole, hyperbole detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection
of hyperbole is an important part of understanding human expression. There have
been several studies on hyperbole detection, but most of which focus on text
modality only. However, with the development of social media, people can create
hyperbolic expressions with various modalities, including text, images, videos,
etc. In this paper, we focus on multimodal hyperbole detection. We create a
multimodal detection dataset\footnote{The dataset will be released to the
community.} from Weibo (a Chinese social media) and carry out some studies on
it. We treat the text and image from a piece of weibo as two modalities and
explore the role of text and image for hyperbole detection. Different
pre-trained multimodal encoders are also evaluated on this downstream task to
show their performance. Besides, since this dataset is constructed from five
different topics, we also evaluate the cross-domain performance of different
models. These studies can serve as a benchmark and point out the direction of
further study on multimodal hyperbole detection.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：General Part Assembly Planning</b></summary>
  <p><b>编号</b>：[399]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00206</p>
  <p><b>作者</b>：Yulong Li,  Andy Zeng,  Shuran Song</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：general part assembly, autonomous robotic assembly, part assembly, general part, successes in autonomous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most successes in autonomous robotic assembly have been restricted to single
target or category. We propose to investigate general part assembly, the task
of creating novel target assemblies with unseen part shapes. To tackle the
planning of general part assembly, we present General Part Assembly Transformer
(GPAT), a transformer based model architecture that accurately predicts part
poses by inferring how each part shape corresponds to the target shape. Our
experiments on both 3D CAD models and real-world scans demonstrate GPAT's
generalization abilities to novel and diverse target and part shapes. Project
website: this https URL</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：An Interpretable Constructive Algorithm for Incremental Random Weight  Neural Networks and Its Application</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00185</p>
  <p><b>作者</b>：Jing Nan,  Wei Dai,  Guan Yuan,  Ping Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Incremental random weight, random weight neural, hidden parameters, weight neural networks, Incremental random</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incremental random weight neural networks (IRWNNs) have gained attention in
view of its easy implementation and fast learning. However, a significant
drawback of IRWNNs is that the elationship between the hidden parameters
(node)and the residual error (model performance) is difficult to be
interpreted. To address the above issue, this article proposes an interpretable
constructive algorithm (ICA) with geometric information constraint. First,
based on the geometric relationship between the hidden parameters and the
residual error, an interpretable geometric information constraint is proposed
to randomly assign the hidden parameters. Meanwhile, a node pool strategy is
employed to obtain hidden parameters that is more conducive to convergence from
hidden parameters satisfying the proposed constraint. Furthermore, the
universal approximation property of the ICA is proved. Finally, a lightweight
version of ICA is presented for large-scale data modeling tasks. Experimental
results on six benchmark datasets and a numerical simulation dataset
demonstrate that the ICA outperforms other constructive algorithms in terms of
modeling speed, model accuracy, and model network structure. Besides, two
practical industrial application case are used to validate the effectiveness of
ICA in practical applications.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Personality Traits in Large Language Models</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00184</p>
  <p><b>作者</b>：Mustafa Safdari,  Greg Serapio-García,  Clément Crepy,  Stephen Fitz,  Peter Romero,  Luning Sun,  Marwa Abdulhai,  Aleksandra Faust,  Maja Matarić</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, revolutionized natural language, contextually relevant text, large language models, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of large language models (LLMs) has revolutionized natural
language processing, enabling the generation of coherent and contextually
relevant text. As LLMs increasingly power conversational agents, the
synthesized personality embedded in these models by virtue of their training on
large amounts of human-generated data draws attention. Since personality is an
important factor determining the effectiveness of communication, we present a
comprehensive method for administering validated psychometric tests and
quantifying, analyzing, and shaping personality traits exhibited in text
generated from widely-used LLMs. We find that: 1) personality simulated in the
outputs of some LLMs (under specific prompting configurations) is reliable and
valid; 2) evidence of reliability and validity of LLM-simulated personality is
stronger for larger and instruction fine-tuned models; and 3) personality in
LLM outputs can be shaped along desired dimensions to mimic specific
personality profiles. We also discuss potential applications and ethical
implications of our measurement and shaping framework, especially regarding
responsible use of LLMs.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：The Integer Linear Programming Inference Cookbook</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00171</p>
  <p><b>作者</b>：Vivek Srikumar,  Dan Roth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, language processing problems, integer linear programs, integer linear, employed to model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the years, integer linear programs have been employed to model inference
in many natural language processing problems. This survey is meant to guide the
reader through the process of framing a new inference problem as an instance of
an integer linear program and is structured as a collection of recipes. At the
end, we will see two worked examples to illustrate the use of these recipes.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：FFPDG: Fast, Fair and Private Data Generation</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00161</p>
  <p><b>作者</b>：Weijie Xu,  Jinjin Zhao,  Francis Iannacci,  Bo Wang</p>
  <p><b>备注</b>：12 pages, 2 figures, ICLR 2021 Workshop on Synthetic Data Generation</p>
  <p><b>关键词</b>：Generative modeling, data, synthetic data, synthetic, frequently in synthetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative modeling has been used frequently in synthetic data generation.
Fairness and privacy are two big concerns for synthetic data. Although Recent
GAN [\cite{goodfellow2014generative}] based methods show good results in
preserving privacy, the generated data may be more biased. At the same time,
these methods require high computation resources. In this work, we design a
fast, fair, flexible and private data generation method. We show the
effectiveness of our method theoretically and empirically. We show that models
trained on data generated by the proposed method can perform well (in inference
stage) on real application scenarios.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Stitched ViTs are Flexible Vision Backbones</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00154</p>
  <p><b>作者</b>：Zizheng Pan,  Jing Liu,  Haoyu He,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Tech report</p>
  <p><b>关键词</b>：plain vision Transformers, Large pretrained plain, vision Transformers, pretrained plain vision, Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained plain vision Transformers (ViTs) have been the workhorse for
many downstream tasks. However, existing works utilizing off-the-shelf ViTs are
inefficient in terms of training and deployment, because adopting ViTs with
individual sizes requires separate training and is restricted by fixed
performance-efficiency trade-offs. In this paper, we are inspired by stitchable
neural networks, which is a new framework that cheaply produces a single model
that covers rich subnetworks by stitching pretrained model families, supporting
diverse performance-efficiency trade-offs at runtime. Building upon this
foundation, we introduce SN-Netv2, a systematically improved model stitching
framework to facilitate downstream task adaptation. Specifically, we first
propose a Two-way stitching scheme to enlarge the stitching space. We then
design a resource-constrained sampling strategy that takes into account the
underlying FLOPs distributions in the space for improved sampling. Finally, we
observe that learning stitching layers is a low-rank update, which plays an
essential role on downstream tasks to stabilize training and ensure a good
Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K,
COCO-Stuff-10K, NYUv2 and COCO-2017, SN-Netv2 demonstrates strong ability to
serve as a flexible vision backbone, achieving great advantages in both
training efficiency and adaptation. Code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Large Language Models (GPT) for automating feedback on programming  assignments</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00150</p>
  <p><b>作者</b>：Maciej Pankiewicz,  Ryan S. Baker</p>
  <p><b>备注</b>：Submitted to the ICCE 2023 (31st International Conference on Computers in Education)</p>
  <p><b>关键词</b>：GPT hints, generating personalized feedback, Addressing the challenge, challenge of generating, demanding due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Addressing the challenge of generating personalized feedback for programming
assignments is demanding due to several factors, like the complexity of code
syntax or different ways to correctly solve a task. In this experimental study,
we automated the process of feedback generation by employing OpenAI's GPT-3.5
model to generate personalized hints for students solving programming
assignments on an automated assessment platform. Students rated the usefulness
of GPT-generated hints positively. The experimental group (with GPT hints
enabled) relied less on the platform's regular feedback but performed better in
terms of percentage of successful submissions across consecutive attempts for
tasks, where GPT hints were enabled. For tasks where the GPT feedback was made
unavailable, the experimental group needed significantly less time to solve
assignments. Furthermore, when GPT hints were unavailable, students in the
experimental condition were initially less likely to solve the assignment
correctly. This suggests potential over-reliance on GPT-generated feedback.
However, students in the experimental condition were able to correct reasonably
rapidly, reaching the same percentage correct after seven submission attempts.
The availability of GPT hints did not significantly impact students' affective
state.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：A Personalized Household Assistive Robot that Learns and Creates New  Breakfast Options through Human-Robot Interaction</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00114</p>
  <p><b>作者</b>：Ali Ayub,  Chrystopher L. Nehaniv,  Kerstin Dautenhahn</p>
  <p><b>备注</b>：Accepted at IEEE International Conference on Robot and Human Interactive Communication (ROMAN), 2023</p>
  <p><b>关键词</b>：breakfast options, personalized breakfast options, learn personalized breakfast, learned knowledge, household assistive robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For robots to assist users with household tasks, they must first learn about
the tasks from the users. Further, performing the same task every day, in the
same way, can become boring for the robot's user(s), therefore, assistive
robots must find creative ways to perform tasks in the household. In this
paper, we present a cognitive architecture for a household assistive robot that
can learn personalized breakfast options from its users and then use the
learned knowledge to set up a table for breakfast. The architecture can also
use the learned knowledge to create new breakfast options over a longer period
of time. The proposed cognitive architecture combines state-of-the-art
perceptual learning algorithms, computational implementation of cognitive
models of memory encoding and learning, a task planner for picking and placing
objects in the household, a graphical user interface (GUI) to interact with the
user and a novel approach for creating new breakfast options using the learned
knowledge. The architecture is integrated with the Fetch mobile manipulator
robot and validated, as a proof-of-concept system evaluation in a large indoor
environment with multiple kitchen objects. Experimental results demonstrate the
effectiveness of our architecture to learn personalized breakfast options from
the user and generate new breakfast options never learned by the robot.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Performance of ChatGPT on USMLE: Unlocking the Potential of Large  Language Models for AI-Assisted Medical Education</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00112</p>
  <p><b>作者</b>：Prabin Sharma,  Kisan Thapa,  Prastab Dhakal,  Mala Deep Upadhaya,  Santosh Adhikari,  Salik Ram Khanal</p>
  <p><b>备注</b>：12 pages, 4 Figues, 4 tables</p>
  <p><b>关键词</b>：Artificial intelligence, intelligence is gaining, gaining traction, ChatGPT, questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence is gaining traction in more ways than ever before.
The popularity of language models and AI-based businesses has soared since
ChatGPT was made available to the general public via OpenAI. It is becoming
increasingly common for people to use ChatGPT both professionally and
personally. Considering the widespread use of ChatGPT and the reliance people
place on it, this study determined how reliable ChatGPT can be for answering
complex medical and clinical questions. Harvard University gross anatomy along
with the United States Medical Licensing Examination (USMLE) questionnaire were
used to accomplish the objective. The paper evaluated the obtained results
using a 2-way ANOVA and posthoc analysis. Both showed systematic covariation
between format and prompt. Furthermore, the physician adjudicators
independently rated the outcome's accuracy, concordance, and insight. As a
result of the analysis, ChatGPT-generated answers were found to be more
context-oriented and represented a better model for deductive reasoning than
regular Google search results. Furthermore, ChatGPT obtained 58.8% on logical
questions and 60% on ethical questions. This means that the ChatGPT is
approaching the passing range for logical questions and has crossed the
threshold for ethical questions. The paper believes ChatGPT and other language
learning models can be invaluable tools for e-learners; however, the study
suggests that there is still room to improve their accuracy. In order to
improve ChatGPT's performance in the future, further research is needed to
better understand how it can answer different types of questions.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Ticket-BERT: Labeling Incident Management Tickets with Language Models</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00108</p>
  <p><b>作者</b>：Zhexiong Liu,  Cris Benge,  Siduo Jiang</p>
  <p><b>备注</b>：In the Microsoft Journal of Applied Research (MSJAR), Volume 18, January 2023</p>
  <p><b>关键词</b>：prioritizing incident tickets, efficiently labeling tickets, fine-grained categories, essential aspect, aspect of prioritizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An essential aspect of prioritizing incident tickets for resolution is
efficiently labeling tickets with fine-grained categories. However, ticket data
is often complex and poses several unique challenges for modern machine
learning methods: (1) tickets are created and updated either by machines with
pre-defined algorithms or by engineers with domain expertise that share
different protocols, (2) tickets receive frequent revisions that update ticket
status by modifying all or parts of ticket descriptions, and (3) ticket
labeling is time-sensitive and requires knowledge updates and new labels per
the rapid software and hardware improvement lifecycle. To handle these issues,
we introduce Ticket- BERT which trains a simple yet robust language model for
labeling tickets using our proposed ticket datasets. Experiments demonstrate
the superiority of Ticket-BERT over baselines and state-of-the-art text
classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT
with an active learning cycle and deploy it on the Microsoft IcM system, which
enables the model to quickly finetune on newly-collected tickets with a few
annotations.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns  Captured by Unmanned Aerial Systems</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00104</p>
  <p><b>作者</b>：Uma Meleti,  Abolfazl Razi</p>
  <p><b>备注</b>：6 pages, 6 figures</p>
  <p><b>关键词</b>：research paper addresses, covered by trees, natural barriers, detecting obscured wildfires, research paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research paper addresses the challenge of detecting obscured wildfires
(when the fire flames are covered by trees, smoke, clouds, and other natural
barriers) in real-time using drones equipped only with RGB cameras. We propose
a novel methodology that employs semantic segmentation based on the temporal
analysis of smoke patterns in video sequences. Our approach utilizes an
encoder-decoder architecture based on deep convolutional neural network
architecture with a pre-trained CNN encoder and 3D convolutions for decoding
while using sequential stacking of features to exploit temporal variations. The
predicted fire locations can assist drones in effectively combating forest
fires and pinpoint fire retardant chemical drop on exact flame locations. We
applied our method to a curated dataset derived from the FLAME2 dataset that
includes RGB video along with IR video to determine the ground truth. Our
proposed method has a unique property of detecting obscured fire and achieves a
Dice score of 85.88%, while achieving a high precision of 92.47% and
classification accuracy of 90.67% on test data showing promising results when
inspected visually. Indeed, our method outperforms other methods by a
significant margin in terms of video-level fire classification as we obtained
about 100% accuracy using MobileNet+CBAM as the encoder backbone.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Queer People are People First: Deconstructing Sexual Identity  Stereotypes in Large Language Models</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00101</p>
  <p><b>作者</b>：Harnoor Dhingra,  Preetiha Jayashanker,  Sayali Moghe,  Emma Strubell</p>
  <p><b>备注</b>：Accepted to Queer in AI Workshop at ACL 2023</p>
  <p><b>关键词</b>：Large Language Models, Language Models, minimally processed web, social biases held, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are trained primarily on minimally processed web
text, which exhibits the same wide range of social biases held by the humans
who created that content. Consequently, text generated by LLMs can
inadvertently perpetuate stereotypes towards marginalized groups, like the
LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs
generate text describing people with different sexual identities. Analyzing
bias in the text generated by an LLM using regard score shows measurable bias
against queer people. We then show that a post-hoc method based on
chain-of-thought prompting using SHAP analysis can increase the regard of the
sentence, representing a promising approach towards debiasing the output of
LLMs in this setting.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Transformers in Healthcare: A Survey</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00067</p>
  <p><b>作者</b>：Subhash Nerella,  Sabyasachi Bandyopadhyay,  Jiaqing Zhang,  Miguel Contreras,  Scott Siegel,  Aysegul Bumin,  Brandon Silva,  Jessica Sena,  Benjamin Shickel,  Azra Bihorac,  Kia Khezeli,  Parisa Rashidi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, Transformers neural network, neural network architecture, increasingly permeating, aspects of society</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With Artificial Intelligence (AI) increasingly permeating various aspects of
society, including healthcare, the adoption of the Transformers neural network
architecture is rapidly changing many applications. Transformer is a type of
deep learning architecture initially developed to solve general-purpose Natural
Language Processing (NLP) tasks and has subsequently been adapted in many
fields, including healthcare. In this survey paper, we provide an overview of
how this architecture has been adopted to analyze various forms of data,
including medical imaging, structured and unstructured Electronic Health
Records (EHR), social media, physiological signals, and biomolecular sequences.
Those models could help in clinical diagnosis, report generation, data
reconstruction, and drug/protein synthesis. We identified relevant studies
using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) guidelines. We also discuss the benefits and limitations of using
transformers in healthcare and examine issues such as computational cost, model
interpretability, fairness, alignment with human values, ethical implications,
and environmental impact.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Qualitative Prediction of Multi-Agent Spatial Interactions</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00065</p>
  <p><b>作者</b>：Sariah Mghames,  Luca Castri,  Marc Hanheide,  Nicola Bellotto</p>
  <p><b>备注</b>：This work will be published in the proceedings of IEEE RO-MAN 2023 (this https URL). arXiv admin note: text overlap with arXiv:2304.11740</p>
  <p><b>关键词</b>：Deploying service robots, warehouses or hospitals, Deploying service, daily life, happening in dense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying service robots in our daily life, whether in restaurants,
warehouses or hospitals, calls for the need to reason on the interactions
happening in dense and dynamic scenes. In this paper, we present and benchmark
three new approaches to model and predict multi-agent interactions in dense
scenes, including the use of an intuitive qualitative representation. The
proposed solutions take into account static and dynamic context to predict
individual interactions. They exploit an input- and a temporal-attention
mechanism, and are tested on medium and long-term time horizons. The first two
approaches integrate different relations from the so-called Qualitative
Trajectory Calculus (QTC) within a state-of-the-art deep neural network to
create a symbol-driven neural architecture for predicting spatial interactions.
The third approach implements a purely data-driven network for motion
prediction, the output of which is post-processed to predict QTC spatial
interactions. Experimental results on a popular robot dataset of challenging
crowded scenarios show that the purely data-driven prediction approach
generally outperforms the other two. The three approaches were further
evaluated on a different but related human scenarios to assess their
generalisation capability.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：DisCo: Disentangled Control for Referring Human Dance Generation in Real  World</b></summary>
  <p><b>编号</b>：[467]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00040</p>
  <p><b>作者</b>：Tan Wang,  Linjie Li,  Kevin Lin,  Chung-Ching Lin,  Zhengyuan Yang,  Hanwang Zhang,  Zicheng Liu,  Lijuan Wang</p>
  <p><b>备注</b>：Project Page: this https URL; Github Page: this https URL</p>
  <p><b>关键词</b>：made significant strides, computer vision, text descriptions, made significant, significant strides</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative AI has made significant strides in computer vision, particularly
in image/video synthesis conditioned on text descriptions. Despite the
advancements, it remains challenging especially in the generation of
human-centric content such as dance synthesis. Existing dance synthesis methods
struggle with the gap between synthesized content and real-world dance
scenarios. In this paper, we define a new problem setting: Referring Human
Dance Generation, which focuses on real-world dance scenarios with three
important properties: (i) Faithfulness: the synthesis should retain the
appearance of both human subject foreground and background from the reference
image, and precisely follow the target pose; (ii) Generalizability: the model
should generalize to unseen human subjects, backgrounds, and poses; (iii)
Compositionality: it should allow for composition of seen/unseen subjects,
backgrounds, and poses from different sources. To address these challenges, we
introduce a novel approach, DISCO, which includes a novel model architecture
with disentangled control to improve the faithfulness and compositionality of
dance synthesis, and an effective human attribute pre-training for better
generalizability to unseen humans. Extensive qualitative and quantitative
results demonstrate that DISCO can generate high-quality human dance images and
videos with diverse appearances and flexible motions. Code, demo, video and
visualization are available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Towards Brain Inspired Design for Addressing the Shortcomings of ANNs</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00039</p>
  <p><b>作者</b>：Fahad Sarfraz,  Elahe Arani,  Bahram Zonooz</p>
  <p><b>备注</b>：11 pages, 7 figures, and 4 tables</p>
  <p><b>关键词</b>：function is enhanced, deserves further consideration, insights gained, algorithms deserves, recent neuroscience study</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As our understanding of the mechanisms of brain function is enhanced, the
value of insights gained from neuroscience to the development of AI algorithms
deserves further consideration. Here, we draw parallels with an existing
tree-based ANN architecture and a recent neuroscience study[27] arguing that
the error-based organization of neurons in the cerebellum that share a
preference for a personalized view of the entire error space, may account for
several desirable features of behavior and learning. We then analyze the
learning behavior and characteristics of the model under varying scenarios to
gauge the potential benefits of a similar mechanism in ANN. Our empirical
results suggest that having separate populations of neurons with personalized
error views can enable efficient learning under class imbalance and limited
data, and reduce the susceptibility to unintended shortcut strategies, leading
to improved generalization. This work highlights the potential of translating
the learning machinery of the brain into the design of a new generation of ANNs
and provides further credence to the argument that biologically inspired AI may
hold the key to overcoming the shortcomings of ANNs.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Seeing in Words: Learning to Classify through Language Bottlenecks</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00028</p>
  <p><b>作者</b>：Khalid Saifullah,  Yuxin Wen,  Jonas Geiping,  Micah Goldblum,  Tom Goldstein</p>
  <p><b>备注</b>：5 pages, 2 figures, Published as a Tiny Paper at ICLR 2023</p>
  <p><b>关键词</b>：achieving high accuracy, computer vision extract, vision extract uninterpretable, extract uninterpretable features, accuracy on benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks for computer vision extract uninterpretable features despite
achieving high accuracy on benchmarks. In contrast, humans can explain their
predictions using succinct and intuitive descriptions. To incorporate
explainability into neural networks, we train a vision model whose feature
representations are text. We show that such a model can effectively classify
ImageNet images, and we discuss the challenges we encountered when training it.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：CASEIN: Cascading Explicit and Implicit Control for Fine-grained Emotion  Intensity Regulation</b></summary>
  <p><b>编号</b>：[475]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00020</p>
  <p><b>作者</b>：Yuhao Cui,  Xiongwei Wang,  Zhongzhou Zhao,  Wei Zhou,  Haiqing Chen</p>
  <p><b>备注</b>：Accepted at Interspeech 2023</p>
  <p><b>关键词</b>：regulation methods rely, predicted emotion probabilities, intensity regulation methods, fine-grained intensity regulation, predicted emotion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing fine-grained intensity regulation methods rely on explicit control
through predicted emotion probabilities. However, these high-level semantic
probabilities are often inaccurate and unsmooth at the phoneme level, leading
to bias in learning. Especially when we attempt to mix multiple emotion
intensities for specific phonemes, resulting in markedly reduced
controllability and naturalness of the synthesis. To address this issue, we
propose the CAScaded Explicit and Implicit coNtrol framework (CASEIN), which
leverages accurate disentanglement of emotion manifolds from the reference
speech to learn the implicit representation at a lower semantic level. This
representation bridges the semantical gap between explicit probabilities and
the synthesis model, reducing bias in learning. In experiments, our CASEIN
surpasses existing methods in both controllability and naturalness. Notably, we
are the first to achieve fine-grained control over the mixed intensity of
multiple emotions.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Inertial Navigation Meets Deep Learning: A Survey of Current Trends and  Future Directions</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00014</p>
  <p><b>作者</b>：Nadav Cohen,  Itzik Klein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications and platforms, deep learning, Inertial sensing, learning, Inertial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inertial sensing is used in many applications and platforms, ranging from
day-to-day devices such as smartphones to very complex ones such as autonomous
vehicles. In recent years, the development of machine learning and deep
learning techniques has increased significantly in the field of inertial
sensing. This is due to the development of efficient computing hardware and the
accessibility of publicly available sensor data. These data-driven approaches
are used to empower model-based navigation and sensor fusion algorithms. This
paper provides an in-depth review of those deep learning methods. We examine
separately, each vehicle operation domain including land, air, and sea. Each
domain is divided into pure inertial advances and improvements based on filter
parameters learning. In addition, we review deep learning approaches for
calibrating and denoising inertial sensors. Throughout the paper, we discuss
these trends and future directions. We also provide statistics on the commonly
used approaches to illustrate their efficiency and stimulate further research
in deep learning embedded in inertial navigation and fusion.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Black-Box Prediction of Flaky Test Fix Categories Using Language Models</b></summary>
  <p><b>编号</b>：[478]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00012</p>
  <p><b>作者</b>：Sakina Fatima,  Hadi Hemmati,  Lionel Briand</p>
  <p><b>备注</b>：12 pages, 8 Figures</p>
  <p><b>关键词</b>：wasting developer time, causing confusion, non-deterministically pass, pass or fail, software version</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Flaky tests are problematic because they non-deterministically pass or fail
for the same software version under test, causing confusion and wasting
developer time. While machine learning models have been used to predict
flakiness and its root causes, there is less work on providing support to fix
the problem. To address this gap, we propose a framework that automatically
generates labeled datasets for 13 fix categories and train models to predict
the fix category of a flaky test by analyzing the test code only. Though it is
unrealistic at this stage to accurately predict the fix itself, the categories
provide precise guidance about what part of the test code to look at. Our
approach is based on language models, namely CodeBERT and UniXcoder, whose
output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese
Network-based Few Shot Learning (FSL). Our experimental results show that
UniXcoder outperforms CodeBERT, in correctly predicting most of the categories
of fixes a developer should apply. Furthermore, FSL does not appear to have any
significant effect. Given the high accuracy obtained for most fix categories,
our proposed framework has the potential to help developers to fix flaky tests
quickly and this http URL aid future research, we make our automated labeling
tool, dataset, prediction models, and experimental infrastructure publicly
available.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Investigating Masking-based Data Generation in Language Models</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00008</p>
  <p><b>作者</b>：Ed S. Ma</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：natural language processing, pre-trained language models, language, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current era of natural language processing (NLP) has been defined by the
prominence of pre-trained language models since the advent of BERT. A feature
of BERT and models with similar architecture is the objective of masked
language modeling, in which part of the input is intentionally masked and the
model is trained to predict this piece of masked information. Data augmentation
is a data-driven technique widely used in machine learning, including research
areas like computer vision and natural language processing, to improve model
performance by artificially augmenting the training data set by designated
techniques. Masked language models (MLM), an essential training feature of
BERT, have introduced a novel approach to perform effective pre-training on
Transformer based models in natural language processing tasks. Recent studies
have utilized masked language model to generate artificially augmented data for
NLP downstream tasks. The experimental results show that Mask based data
augmentation method provides a simple but efficient approach to improve the
model performance. In this paper, we explore and discuss the broader
utilization of these data augmentation methods based on MLM.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：The ROAD to discovery: machine learning-driven anomaly detection in  radio astronomy spectrograms</b></summary>
  <p><b>编号</b>：[490]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.01054</p>
  <p><b>作者</b>：Michael Mesarcik,  Albert-Jan Boonstra,  Marco Iacobelli,  Elena Ranguelova,  Cees de Laat,  Rob van Nieuwpoort</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sensitivity and flexibility, complexity and data-rates, radio telescopes increase, Low Frequency Array, increase in sensitivity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As radio telescopes increase in sensitivity and flexibility, so do their
complexity and data-rates. For this reason automated system health management
approaches are becoming increasingly critical to ensure nominal telescope
operations. We propose a new machine learning anomaly detection framework for
classifying both commonly occurring anomalies in radio telescopes as well as
detecting unknown rare anomalies that the system has potentially not yet seen.
To evaluate our method, we present a dataset consisting of 7050
autocorrelation-based spectrograms from the Low Frequency Array (LOFAR)
telescope and assign 10 different labels relating to the system-wide anomalies
from the perspective of telescope operators. This includes electronic failures,
miscalibration, solar storms, network and compute hardware errors among many
more. We demonstrate how a novel Self Supervised Learning (SSL) paradigm, that
utilises both context prediction and reconstruction losses, is effective in
learning normal behaviour of the LOFAR telescope. We present the Radio
Observatory Anomaly Detector (ROAD), a framework that combines both SSL-based
anomaly detection and a supervised classification, thereby enabling both
classification of both commonly occurring anomalies and detection of unseen
anomalies. We demonstrate that our system is real-time in the context of the
LOFAR data processing pipeline, requiring <1ms to process a single spectrogram. furthermore, road obtains an anomaly detection f-2 score of 0.92 while maintaining false positive rate ~2\%, as well mean per-class classification 0.89, outperforming other related works.< p>
  </1ms></p></details>
</details>
<details>
  <summary>117. <b>标题：Efficient and fully-automatic retinal choroid segmentation in OCT  through DL-based distillation of a hand-crafted pipeline</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00904</p>
  <p><b>作者</b>：Jamie Burke,  Justin Engelmann,  Charlene Hamid,  Megan Reid-Schachter,  Tom Pearson,  Dan Pugh,  Neeraj Dhaun,  Stuart King,  Tom MacGillivray,  Miguel O. Bernabeu,  Amos Storkey,  Ian J.C. MacCormick</p>
  <p><b>备注</b>：11 pages, 2 figures, 3 tables. Currently in submission to the OMIA-X workshop as part of the 2023 MICCAI annual conference. GitHub link to codebase provided upon publication</p>
  <p><b>关键词</b>：non-invasive retinal imaging, derived from low-cost, Retinal vascular phenotypes, reno-vascular disease, vascular phenotypes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retinal vascular phenotypes, derived from low-cost, non-invasive retinal
imaging, have been linked to systemic conditions such as cardio-, neuro- and
reno-vascular disease. Recent high-resolution optical coherence tomography
(OCT) allows imaging of the choroidal microvasculature which could provide more
information about vascular health that complements the superficial retinal
vessels, which current vascular phenotypes are based on. Segmentation of the
choroid in OCT is a key step in quantifying choroidal parameters like thickness
and area. Gaussian Process Edge Tracing (GPET) is a promising, clinically
validated method for this. However, GPET is semi-automatic and thus requires
time-consuming manual interventions by specifically trained personnel which
introduces subjectivity and limits the potential for analysing larger datasets
or deploying GPET into clinical practice. We introduce DeepGPET, which distils
GPET into a neural network to yield a fully-automatic and efficient choroidal
segmentation method. DeepGPET achieves excellent agreement with GPET on data
from 3 clinical studies (AUC=0.9994, Dice=0.9664; Pearson correlation of 0.8908
for choroidal thickness and 0.9082 for choroidal area), while reducing the mean
processing time per image from 34.49s ($\pm$15.09) to 1.25s ($\pm$0.10) on a
standard laptop CPU and removing all manual interventions. DeepGPET will be
made available for researchers upon publication.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Monte Carlo Policy Gradient Method for Binary Optimization</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00783</p>
  <p><b>作者</b>：Cheng Chen,  Ruitao Chen,  Tianyou Li,  Ruichen Ao,  Zaiwen Wen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：MIMO detection, combinatorial optimization problems, parameterized policy distribution, binary optimization problems, wide range</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary optimization has a wide range of applications in combinatorial
optimization problems such as MaxCut, MIMO detection, and MaxSAT. However,
these problems are typically NP-hard due to the binary constraints. We develop
a novel probabilistic model to sample the binary solution according to a
parameterized policy distribution. Specifically, minimizing the KL divergence
between the parameterized policy distribution and the Gibbs distributions of
the function value leads to a stochastic optimization problem whose policy
gradient can be derived explicitly similar to reinforcement learning. For
coherent exploration in discrete spaces, parallel Markov Chain Monte Carlo
(MCMC) methods are employed to sample from the policy distribution with
diversity and approximate the gradient efficiently. We further develop a filter
scheme to replace the original objective function by the one with the local
search technique to broaden the horizon of the function landscape. Convergence
to stationary points in expectation of the policy gradient method is
established based on the concentration inequality for MCMC. Numerical results
show that this framework is very promising to provide near-optimal solutions
for quite a few binary optimization problems.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Morse Neural Networks for Uncertainty Quantification</b></summary>
  <p><b>编号</b>：[515]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00667</p>
  <p><b>作者</b>：Benoit Dherin,  Huiyi Hu,  Jie Ren,  Michael W. Dusenberry,  Balaji Lakshminarayanan</p>
  <p><b>备注</b>：Accepted to ICML workshop on Structured Probabilistic Inference & Generative Modeling 2023</p>
  <p><b>关键词</b>：Morse neural network, Morse neural, deep generative model, Morse, uncertainty quantification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new deep generative model useful for uncertainty
quantification: the Morse neural network, which generalizes the unnormalized
Gaussian densities to have modes of high-dimensional submanifolds instead of
just discrete points. Fitting the Morse neural network via a KL-divergence loss
yields 1) a (unnormalized) generative density, 2) an OOD detector, 3) a
calibration temperature, 4) a generative sampler, along with in the supervised
case 5) a distance aware-classifier. The Morse network can be used on top of a
pre-trained network to bring distance-aware calibration w.r.t the training
data. Because of its versatility, the Morse neural networks unifies many
techniques: e.g., the Entropic Out-of-Distribution Detector of (Macêdo et
al., 2021) in OOD detection, the one class Deep Support Vector Description
method of (Ruff et al., 2018) in anomaly detection, or the Contrastive One
Class classifier in continuous learning (Sun et al., 2021). The Morse neural
network has connections to support vector machines, kernel methods, and Morse
theory in topology.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：VoxWatch: An open-set speaker recognition benchmark on VoxCeleb</b></summary>
  <p><b>编号</b>：[540]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00169</p>
  <p><b>作者</b>：Raghuveer Peri,  Seyed Omid Sadjadi,  Daniel Garcia-Romero</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：recognition community compared, open-set speaker identification, speaker recognition community, broad practical applications, fraud prevention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite its broad practical applications such as in fraud prevention,
open-set speaker identification (OSI) has received less attention in the
speaker recognition community compared to speaker verification (SV). OSI deals
with determining if a test speech sample belongs to a speaker from a set of
pre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In
addition to the typical challenges associated with speech variability, OSI is
prone to the "false-alarm problem"; as the size of the in-set speaker
population (a.k.a watchlist) grows, the out-of-set scores become larger,
leading to increased false alarm rates. This is in particular challenging for
applications in financial institutions and border security where the watchlist
size is typically of the order of several thousand speakers. Therefore, it is
important to systematically quantify the false-alarm problem, and develop
techniques that alleviate the impact of watchlist size on detection
performance. Prior studies on this problem are sparse, and lack a common
benchmark for systematic evaluations. In this paper, we present the first
public benchmark for OSI, developed using the VoxCeleb dataset. We quantify the
effect of the watchlist size and speech duration on the watchlist-based speaker
detection task using three strong neural network based systems. In contrast to
the findings from prior research, we show that the commonly adopted adaptive
score normalization is not guaranteed to improve the performance for this task.
On the other hand, we show that score calibration and score fusion, two other
commonly used techniques in SV, result in significant improvements in OSI
performance.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Uncertainty Informed Optimal Resource Allocation with Gaussian Process  based Bayesian Inference</b></summary>
  <p><b>编号</b>：[548]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00032</p>
  <p><b>作者</b>：Samarth Gupta,  Saurabh Amin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：managing epidemic spread, epidemic spread, ODE, heterogeneous populations, populations for managing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on the problem of uncertainty informed allocation of medical
resources (vaccines) to heterogeneous populations for managing epidemic spread.
We tackle two related questions: (1) For a compartmental ordinary differential
equation (ODE) model of epidemic spread, how can we estimate and integrate
parameter uncertainty into resource allocation decisions? (2) How can we
computationally handle both nonlinear ODE constraints and parameter
uncertainties for a generic stochastic optimization problem for resource
allocation? To the best of our knowledge current literature does not fully
resolve these questions. Here, we develop a data-driven approach to represent
parameter uncertainty accurately and tractably in a novel stochastic
optimization problem formulation. We first generate a tractable scenario set by
estimating the distribution on ODE model parameters using Bayesian inference
with Gaussian processes. Next, we develop a parallelized solution algorithm
that accounts for scenario-dependent nonlinear ODE constraints. Our
scenario-set generation procedure and solution approach are flexible in that
they can handle any compartmental epidemiological ODE model. Our computational
experiments on two different non-linear ODE models (SEIR and SEPIHR) indicate
that accounting for uncertainty in key epidemiological parameters can improve
the efficacy of time-critical allocation decisions by 4-8%. This improvement
can be attributed to data-driven and optimal (strategic) nature of vaccine
allocations, especially in the early stages of the epidemic when the allocation
strategy can crucially impact the long-term trajectory of the disease.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：PV Fleet Modeling via Smooth Periodic Gaussian Copula</b></summary>
  <p><b>编号</b>：[551]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.00004</p>
  <p><b>作者</b>：Mehmet G. Ogut,  Bennet Meyers,  Stephen P. Boyd</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：jointly modeling power, modeling power generation, jointly modeling, modeling power, power generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a method for jointly modeling power generation from a fleet of
photovoltaic (PV) systems. We propose a white-box method that finds a function
that invertibly maps vector time-series data to independent and identically
distributed standard normal variables. The proposed method, based on a novel
approach for fitting a smooth, periodic copula transform to data, captures many
aspects of the data such as diurnal variation in the distribution of power
output, dependencies among different PV systems, and dependencies across time.
It consists of interpretable steps and is scalable to many systems. The
resulting joint probability model of PV fleet output across systems and time
can be used to generate synthetic data, impute missing data, perform anomaly
detection, and make forecasts. In this paper, we explain the method and
demonstrate these applications.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【梳理】陆奇最新演讲实录：我的大模型世界观</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-05)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-07-05)"/></a><div class="content"><a class="title" href="/2023/07/05/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-05)">Arxiv每日速递(2023-07-05)</a><time datetime="2023-07-05T00:51:54.567Z" title="发表于 2023-07-05 08:51:54">2023-07-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【梳理】陆奇最新演讲实录：我的大模型世界观"/></a><div class="content"><a class="title" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观">【梳理】陆奇最新演讲实录：我的大模型世界观</a><time datetime="2023-05-07T11:07:45.000Z" title="发表于 2023-05-07 19:07:45">2023-05-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)"><img src="https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="变分自编码器(Variational AutoEncoder)"/></a><div class="content"><a class="title" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)">变分自编码器(Variational AutoEncoder)</a><time datetime="2023-05-05T11:28:37.000Z" title="发表于 2023-05-05 19:28:37">2023-05-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformers.generation.GenerationMixin"/></a><div class="content"><a class="title" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin">transformers.generation.GenerationMixin</a><time datetime="2023-04-08T13:42:45.000Z" title="发表于 2023-04-08 21:42:45">2023-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范"><img src="https://openaicom.imgix.net/8d14e8f0-e267-4b8b-a9f2-a79120808f5a/chatgpt.jpg?auto=compress%2Cformat&amp;fit=min&amp;fm=jpg&amp;q=80&amp;rect=0%2C0%2C2048%2C2048&amp;w=3200" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【转载】ChatGPT 标注指南：任务、数据与规范"/></a><div class="content"><a class="title" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范">【转载】ChatGPT 标注指南：任务、数据与规范</a><time datetime="2023-03-27T14:35:45.000Z" title="发表于 2023-03-27 22:35:45">2023-03-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>