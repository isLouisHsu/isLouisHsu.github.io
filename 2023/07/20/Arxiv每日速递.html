<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-07-20) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新367篇论文，其中：  100篇计算机视觉（cs.CV） 35篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 68篇人工智能（cs.AI）  计算机视觉    1. 标题：AnyDoor: Zero-shot Object-level Imag">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-07-20)">
<meta property="og:url" content="http://louishsu.xyz/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新367篇论文，其中：  100篇计算机视觉（cs.CV） 35篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 68篇人工智能（cs.AI）  计算机视觉    1. 标题：AnyDoor: Zero-shot Object-level Imag">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-07-20T00:43:34.036Z">
<meta property="article:modified_time" content="2023-07-20T00:45:42.382Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-20 08:45:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-07-20)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-20T00:43:34.036Z" title="发表于 2023-07-20 08:43:34">2023-07-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-20T00:45:42.382Z" title="更新于 2023-07-20 08:45:42">2023-07-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">51.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>310分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新367篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">100篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">35篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">102篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">68篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：AnyDoor: Zero-shot Object-level Image Customization</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09481</p>
  <p><b>作者</b>：Xi Chen,  Lianghua Huang,  Yu Liu,  Yujun Shen,  Deli Zhao,  Hengshuang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work presents AnyDoor, diffusion-based image generator, teleport target objects, presents AnyDoor, work presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents AnyDoor, a diffusion-based image generator with the power
to teleport target objects to new scenes at user-specified locations in a
harmonious way. Instead of tuning parameters for each object, our model is
trained only once and effortlessly generalizes to diverse object-scene
combinations at the inference stage. Such a challenging zero-shot setting
requires an adequate characterization of a certain object. To this end, we
complement the commonly used identity feature with detail features, which are
carefully designed to maintain texture details yet allow versatile local
variations (e.g., lighting, orientation, posture, etc.), supporting the object
in favorably blending with different surroundings. We further propose to borrow
knowledge from video datasets, where we can observe various forms (i.e., along
the time axis) of a single object, leading to stronger model generalizability
and robustness. Extensive experiments demonstrate the superiority of our
approach over existing alternatives as well as its great potential in
real-world applications, such as virtual try-on and object moving. Project page
is this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：FACTS: Facial Animation Creation using the Transfer of Styles</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09480</p>
  <p><b>作者</b>：Jack Saunders,  Steven Caulkin,  Vinay Namboodiri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：creating believable characters, forms of entertainment, ability to accurately, critical aspect, aspect of creating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to accurately capture and express emotions is a critical aspect
of creating believable characters in video games and other forms of
entertainment. Traditionally, this animation has been achieved with artistic
effort or performance capture, both requiring costs in time and labor. More
recently, audio-driven models have seen success, however, these often lack
expressiveness in areas not correlated to the audio signal. In this paper, we
present a novel approach to facial animation by taking existing animations and
allowing for the modification of style characteristics. Specifically, we
explore the use of a StarGAN to enable the conversion of 3D facial animations
into different emotions and person-specific styles. We are able to maintain the
lip-sync of the animations with this method thanks to the use of a novel
viseme-preserving loss.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring  Instruction Tuning</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09474</p>
  <p><b>作者</b>：Liang Zhao,  En Yu,  Zheng Ge,  Jinrong Yang,  Haoran Wei,  Hongyu Zhou,  Jianjian Sun,  Yuang Peng,  Runpei Dong,  Chunrui Han,  Xiangyu Zhang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：multimodal large language, critical aspect, aspect that reflects, reflects the usability, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-AI interactivity is a critical aspect that reflects the usability of
multimodal large language models (MLLMs). However, existing end-to-end MLLMs
only allow users to interact with them through language instructions, leading
to the limitation of the interactive accuracy and efficiency. In this study, we
present precise referring instructions that utilize diverse reference
representations such as points and boxes as referring prompts to refer to the
special region. This enables MLLMs to focus on the region of interest and
achieve finer-grained interaction. Based on precise referring instruction, we
propose ChatSpot, a unified end-to-end multimodal large language model that
supports diverse forms of interactivity including mouse clicks, drag-and-drop,
and drawing boxes, which provides a more flexible and seamless interactive
experience. We also construct a multi-grained vision-language
instruction-following dataset based on existing datasets and GPT-4 generating.
Furthermore, we design a series of evaluation tasks to assess the effectiveness
of region recognition and interaction. Experimental results showcase ChatSpot's
promising performance.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：GroupLane: End-to-End 3D Lane Detection with Channel-wise Grouping</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09472</p>
  <p><b>作者</b>：Zhuoling Li,  Chunrui Han,  Zheng Ge,  Jinrong Yang,  En Yu,  Haoqian Wang,  Hengshuang Zhao,  Xiangyu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：practical deployment demand, deployment demand, due to practical, practical deployment, lane detection due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficiency is quite important for 3D lane detection due to practical
deployment demand. In this work, we propose a simple, fast, and end-to-end
detector that still maintains high detection precision. Specifically, we devise
a set of fully convolutional heads based on row-wise classification. In
contrast to previous counterparts, ours supports recognizing both vertical and
horizontal lanes. Besides, our method is the first one to perform row-wise
classification in bird-eye-view. In the heads, we split feature into multiple
groups and every group of feature corresponds to a lane instance. During
training, the predictions are associated with lane labels using the proposed
single-win one-to-one matching to compute loss, and no post-processing
operation is demanded for inference. In this way, our proposed fully
convolutional detector, GroupLane, realizes end-to-end detection like DETR.
Evaluated on 3 real world 3D lane benchmarks, OpenLane, Once-3DLanes, and
OpenLane-Huawei, GroupLane adopting ConvNext-Base as the backbone outperforms
the published state-of-the-art PersFormer by 13.6% F1 score in the OpenLane
validation set. Besides, GroupLane with ResNet18 still surpasses PersFormer by
4.9% F1 score, while the inference speed is nearly 7x faster and the FLOPs is
only 13.3% of it.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Occlusion Aware Student Emotion Recognition based on Facial Action Unit  Detection</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09465</p>
  <p><b>作者</b>：Shrouk Wally,  Ahmed Elsayed,  Islam Alkabbany,  Asem Ali,  Aly Farag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：half of science, undergraduate students, colleges and universities, approximately half, universities leave</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given that approximately half of science, technology, engineering, and
mathematics (STEM) undergraduate students in U.S. colleges and universities
leave by the end of the first year [15], it is crucial to improve the quality
of classroom environments. This study focuses on monitoring students' emotions
in the classroom as an indicator of their engagement and proposes an approach
to address this issue. The impact of different facial parts on the performance
of an emotional recognition model is evaluated through experimentation. To test
the proposed model under partial occlusion, an artificially occluded dataset is
introduced. The novelty of this work lies in the proposal of an occlusion-aware
architecture for facial action units (AUs) extraction, which employs attention
mechanism and adaptive feature learning. The AUs can be used later to classify
facial expressions in classroom settings.
This research paper's findings provide valuable insights into handling
occlusion in analyzing facial images for emotional engagement analysis. The
proposed experiments demonstrate the significance of considering occlusion and
enhancing the reliability of facial analysis models in classroom environments.
These findings can also be extended to other settings where occlusions are
prevalent.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：A comparative analysis of SRGAN models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09456</p>
  <p><b>作者</b>：Fatemeh Rezapoor Nikroo,  Ajinkya Deshmukh,  Anantha Sharma,  Adrian Tam,  Kaarthik Kumar,  Cleo Norris,  Aditya Dangi</p>
  <p><b>备注</b>：9 pages, 6 tables, 2 figures</p>
  <p><b>关键词</b>：Generative Adversarial Network, Super Resolution Generative, Resolution Generative Adversarial, Adversarial Network, Generative Adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we evaluate the performance of multiple state-of-the-art SRGAN
(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN
and EDSR, on a benchmark dataset of real-world images which undergo degradation
using a pipeline. Our results show that some models seem to significantly
increase the resolution of the input images while preserving their visual
quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE
model from huggingface outperforms the remaining candidate models in terms of
both quantitative metrics and subjective visual quality assessments with least
compute overhead. Specifically, EDSR generates images with higher peak
signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and
are seen to return high quality OCR results with Tesseract OCR engine. These
findings suggest that EDSR is a robust and effective approach for single-image
super-resolution and may be particularly well-suited for applications where
high-quality visual fidelity is critical and optimized compute.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Measuring Student Behavioral Engagement using Histogram of Actions</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09420</p>
  <p><b>作者</b>：Ahmed Abdelkawy,  Islam Alkabbany,  Asem Ali,  Aly Farag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：students' actions recognition, measuring behavioral engagement, actions, student, technique for measuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel technique for measuring behavioral
engagement through students' actions recognition. The proposed approach
recognizes student actions then predicts the student behavioral engagement
level. For student action recognition, we use human skeletons to model student
postures and upper body movements. To learn the dynamics of student upper body,
a 3D-CNN model is used. The trained 3D-CNN model is used to recognize actions
within every 2minute video segment then these actions are used to build a
histogram of actions which encodes the student actions and their frequencies.
This histogram is utilized as an input to SVM classifier to classify whether
the student is engaged or disengaged. To evaluate the proposed framework, we
build a dataset consisting of 1414 2-minute video segments annotated with 13
actions and 112 video segments annotated with two engagement levels.
Experimental results indicate that student actions can be recognized with top 1
accuracy 83.63% and the proposed framework can capture the average engagement
of the class.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation  Evaluation</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09416</p>
  <p><b>作者</b>：Federico Betti,  Jacopo Staiano,  Lorenzo Baraldi,  Lorenzo Baraldi,  Rita Cucchiara,  Nicu Sebe</p>
  <p><b>备注</b>：Accepted as oral at ACM MultiMedia 2023 (Brave New Ideas track)</p>
  <p><b>关键词</b>：produce high-quality visual, high-quality visual content, visual content based, made significant progress, recently made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in Image Generation has recently made significant progress,
particularly boosted by the introduction of Vision-Language models which are
able to produce high-quality visual content based on textual inputs. Despite
ongoing advancements in terms of generation quality and realism, no methodical
frameworks have been defined yet to quantitatively measure the quality of the
generated content and the adherence with the prompted requests: so far, only
human-based evaluations have been adopted for quality satisfaction and for
comparing different generative methods. We introduce a novel automated method
for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a
generated/edited image and the corresponding prompt/instructions, with a
process inspired by the human cognitive behaviour. ViCE combines the strengths
of Large Language Models (LLMs) and Visual Question Answering (VQA) into a
unified pipeline, aiming to replicate the human cognitive process in quality
assessment. This method outlines visual concepts, formulates image-specific
verification questions, utilizes the Q&A system to investigate the image, and
scores the combined outcome. Although this brave new hypothesis of mimicking
humans in the image evaluation process is in its preliminary assessment stage,
results are promising and open the door to a new form of automatic evaluation
which could have significant impact as the image generation or the image target
editing tasks become more and more sophisticated.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Plug the Leaks: Advancing Audio-driven Talking Face Generation by  Preventing Unintended Information Flow</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09368</p>
  <p><b>作者</b>：Dogucan Yaman,  Fevziye Irem Eyiokur,  Leonard Bärmann,  Hazim Kemal Ekenel,  Alexander Waibel</p>
  <p><b>备注</b>：Submitted to ICCV 2023</p>
  <p><b>关键词</b>：realistic face video, Audio-driven talking face, talking face generation, creating a lip-synchronized, task of creating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Audio-driven talking face generation is the task of creating a
lip-synchronized, realistic face video from given audio and reference frames.
This involves two major challenges: overall visual quality of generated images
on the one hand, and audio-visual synchronization of the mouth part on the
other hand. In this paper, we start by identifying several problematic aspects
of synchronization methods in recent audio-driven talking face generation
approaches. Specifically, this involves unintended flow of lip and pose
information from the reference to the generated image, as well as instabilities
during model training. Subsequently, we propose various techniques for
obviating these issues: First, a silent-lip reference image generator prevents
leaking of lips from the reference to the generated image. Second, an adaptive
triplet loss handles the pose leaking problem. Finally, we propose a stabilized
formulation of synchronization loss, circumventing aforementioned training
instabilities while additionally further alleviating the lip leaking issue.
Combining the individual improvements, we present state-of-the art performance
on LRS2 and LRW in both synchronization and visual quality. We further validate
our design in various ablation experiments, confirming the individual
contributions as well as their complementary effects.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：LEST: Large-scale LiDAR Semantic Segmentation with Transformer</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09367</p>
  <p><b>作者</b>：Chuanyu Luo,  Nuo Cheng,  Sikun Ma,  Han Li,  Xiaohan Li,  Shengguang Lei,  Pu Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autonomous driving perception, semantic segmentation, driving perception, cloud semantic segmentation, critical task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale LiDAR-based point cloud semantic segmentation is a critical task
in autonomous driving perception. Almost all of the previous state-of-the-art
LiDAR semantic segmentation methods are variants of sparse 3D convolution.
Although the Transformer architecture is becoming popular in the field of
natural language processing and 2D computer vision, its application to
large-scale point cloud semantic segmentation is still limited. In this paper,
we propose a LiDAR sEmantic Segmentation architecture with pure Transformer,
LEST. LEST comprises two novel components: a Space Filling Curve (SFC) Grouping
strategy and a Distance-based Cosine Linear Transformer, DISCO. On the public
nuScenes semantic segmentation validation set and SemanticKITTI test set, our
model outperforms all the other state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：An Evaluation of Zero-Cost Proxies -- from Neural Architecture  Performance to Model Robustness</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09365</p>
  <p><b>作者</b>：Jovita Lukasik,  Michael Moeller,  Margret Keuper</p>
  <p><b>备注</b>：Accepted at DAGM GCPR 2023</p>
  <p><b>关键词</b>：nowadays frequently studied, nowadays frequently, frequently studied, Zero-cost proxies, proxies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Zero-cost proxies are nowadays frequently studied and used to search for
neural architectures. They show an impressive ability to predict the
performance of architectures by making use of their untrained weights. These
techniques allow for immense search speed-ups. So far the joint search for
well-performing and robust architectures has received much less attention in
the field of NAS. Therefore, the main focus of zero-cost proxies is the clean
accuracy of architectures, whereas the model robustness should play an evenly
important part. In this paper, we analyze the ability of common zero-cost
proxies to serve as performance predictors for robustness in the popular
NAS-Bench-201 search space. We are interested in the single prediction task for
robustness and the joint multi-objective of clean and robust accuracy. We
further analyze the feature importance of the proxies and show that predicting
the robustness makes the prediction task from existing zero-cost proxies more
challenging. As a result, the joint consideration of several proxies becomes
necessary to predict a model's robustness while the clean accuracy can be
regressed from a single such feature.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Disentangle then Parse:Night-time Semantic Segmentation with  Illumination Disentanglement</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09362</p>
  <p><b>作者</b>：Zhixiang Wei,  Lin Chen,  Tao Tu,  Huaian Chen,  Pengyang Ling,  Yi Jin</p>
  <p><b>备注</b>：Accepted by ICCV2023</p>
  <p><b>关键词</b>：night-time scenes due, scenes due, typically underperforming, due to insufficient, complicated lighting conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most prior semantic segmentation methods have been developed for day-time
scenes, while typically underperforming in night-time scenes due to
insufficient and complicated lighting conditions. In this work, we tackle this
challenge by proposing a novel night-time semantic segmentation paradigm, i.e.,
disentangle then parse (DTP). DTP explicitly disentangles night-time images
into light-invariant reflectance and light-specific illumination components and
then recognizes semantics based on their adaptive fusion. Concretely, the
proposed DTP comprises two key components: 1) Instead of processing
lighting-entangled features as in prior works, our Semantic-Oriented
Disentanglement (SOD) framework enables the extraction of reflectance component
without being impeded by lighting, allowing the network to consistently
recognize the semantics under cover of varying and complicated lighting
conditions. 2) Based on the observation that the illumination component can
serve as a cue for some semantically confused regions, we further introduce an
Illumination-Aware Parser (IAParser) to explicitly learn the correlation
between semantics and lighting, and aggregate the illumination features to
yield more precise predictions. Extensive experiments on the night-time
segmentation task with various settings demonstrate that DTP significantly
outperforms state-of-the-art methods. Furthermore, with negligible additional
parameters, DTP can be directly used to benefit existing day-time methods for
night-time segmentation.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：MOCA: Self-supervised Representation Learning by Predicting Masked  Online Codebook Assignments</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09361</p>
  <p><b>作者</b>：Spyros Gidaris,  Andrei Bursuc,  Oriane Simeoni,  Antonin Vobecky,  Nikos Komodakis,  Matthieu Cord,  Patrick Pérez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mitigating the greedy, Vision Transformer networks, Vision Transformer, Self-supervised learning, Transformer networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning can be used for mitigating the greedy needs of
Vision Transformer networks for very large fully-annotated datasets. Different
classes of self-supervised learning offer representations with either good
contextual reasoning properties, e.g., using masked image modeling strategies,
or invariance to image perturbations, e.g., with contrastive methods. In this
work, we propose a single-stage and standalone method, MOCA, which unifies both
desired properties using novel mask-and-predict objectives defined with
high-level features (instead of pixel-level details). Moreover, we show how to
effectively employ both learning paradigms in a synergistic and
computation-efficient way. Doing so, we achieve new state-of-the-art results on
low-shot settings and strong experimental results in various evaluation
protocols with a training that is at least 3 times faster than prior methods.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：OnlineRefer: A Simple Online Baseline for Referring Video Object  Segmentation</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09356</p>
  <p><b>作者</b>：Dongming Wu,  Tiancai Wang,  Yuang Zhang,  Xiangyu Zhang,  Jianbing Shen</p>
  <p><b>备注</b>：Accepted by ICCV2023. The code is at this https URL</p>
  <p><b>关键词</b>：video object segmentation, Referring video object, object segmentation, video object, aims at segmenting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Referring video object segmentation (RVOS) aims at segmenting an object in a
video following human instruction. Current state-of-the-art methods fall into
an offline pattern, in which each clip independently interacts with text
embedding for cross-modal understanding. They usually present that the offline
pattern is necessary for RVOS, yet model limited temporal association within
each clip. In this work, we break up the previous offline belief and propose a
simple yet effective online model using explicit query propagation, named
OnlineRefer. Specifically, our approach leverages target cues that gather
semantic information and position prior to improve the accuracy and ease of
referring predictions for the current frame. Furthermore, we generalize our
online model into a semi-online framework to be compatible with video-based
backbones. To show the effectiveness of our method, we evaluate it on four
benchmarks, \ie, Refer-Youtube-VOS, Refer-DAVIS17, A2D-Sentences, and
JHMDB-Sentences. Without bells and whistles, our OnlineRefer with a Swin-L
backbone achieves 63.5 J&F and 64.8 J&F on Refer-Youtube-VOS and Refer-DAVIS17,
outperforming all other offline methods.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：SphereNet: Learning a Noise-Robust and General Descriptor for Point  Cloud Registration</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09351</p>
  <p><b>作者</b>：Guiyu Zhao,  Zhentao Guo,  Xin Wang,  Hongbin Ma</p>
  <p><b>备注</b>：15 pages, under review for IEEE Transactions on Circuits and Systems for Video Technology</p>
  <p><b>关键词</b>：Point cloud registration, align point clouds, point clouds collected, Point cloud, cloud registration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point cloud registration is to estimate a transformation to align point
clouds collected in different perspectives. In learning-based point cloud
registration, a robust descriptor is vital for high-accuracy registration.
However, most methods are susceptible to noise and have poor generalization
ability on unseen datasets. Motivated by this, we introduce SphereNet to learn
a noise-robust and unseen-general descriptor for point cloud registration. In
our method, first, the spheroid generator builds a geometric domain based on
spherical voxelization to encode initial features. Then, the spherical
interpolation of the sphere is introduced to realize robustness against noise.
Finally, a new spherical convolutional neural network with spherical integrity
padding completes the extraction of descriptors, which reduces the loss of
features and fully captures the geometric features. To evaluate our methods, a
new benchmark 3DMatch-noise with strong noise is introduced. Extensive
experiments are carried out on both indoor and outdoor datasets. Under
high-intensity noise, SphereNet increases the feature matching recall by more
than 25 percentage points on 3DMatch-noise. In addition, it sets a new
state-of-the-art performance for the 3DMatch and 3DLoMatch benchmarks with
93.5\% and 75.6\% registration recall and also has the best generalization
ability on unseen datasets.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Visual Validation versus Visual Estimation: A Study on the Average Value  in Scatterplots</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09330</p>
  <p><b>作者</b>：Daniel Braun,  Ashley Suh,  Remco Chang,  Michael Gleicher,  Tatiana von Landesberger</p>
  <p><b>备注</b>：Preprint and Author Version of a Short Paper, accepted to the 2023 IEEE Visualization Conference (VIS)</p>
  <p><b>关键词</b>：investigate the ability, ability of individuals, visually validate, visual model, visual model validation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the ability of individuals to visually validate statistical
models in terms of their fit to the data. While visual model estimation has
been studied extensively, visual model validation remains under-investigated.
It is unknown how well people are able to visually validate models, and how
their performance compares to visual and computational estimation. As a
starting point, we conducted a study across two populations (crowdsourced and
volunteers). Participants had to both visually estimate (i.e, draw) and
visually validate (i.e., accept or reject) the frequently studied model of
averages. Across both populations, the level of accuracy of the models that
were considered valid was lower than the accuracy of the estimated models. We
find that participants' validation and estimation were unbiased. Moreover,
their natural critical point between accepting and rejecting a given mean value
is close to the boundary of its 95% confidence interval, indicating that the
visually perceived confidence interval corresponds to a common statistical
standard. Our work contributes to the understanding of visual model validation
and opens new research opportunities.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Towards a performance analysis on pre-trained Visual Question Answering  models for autonomous driving</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09329</p>
  <p><b>作者</b>：Kaavya Rekanar,  Ciarán Eising,  Ganesh Sistu,  Martin Hayes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：short paper presents, popular Visual, short paper, paper presents, presents a preliminary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This short paper presents a preliminary analysis of three popular Visual
Question Answering (VQA) models, namely ViLBERT, ViLT, and LXMERT, in the
context of answering questions relating to driving scenarios. The performance
of these models is evaluated by comparing the similarity of responses to
reference answers provided by computer vision experts. Model selection is
predicated on the analysis of transformer utilization in multimodal
architectures. The results indicate that models incorporating cross-modal
attention and late fusion techniques exhibit promising potential for generating
improved answers within a driving perspective. This initial analysis serves as
a launchpad for a forthcoming comprehensive comparative study involving nine
VQA models and sets the scene for further investigations into the effectiveness
of VQA model queries in self-driving scenarios. Supplementary material is
available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking  Portrait Synthesis</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09323</p>
  <p><b>作者</b>：Jiahe Li,  Jiawei Zhang,  Xiao Bai,  Jun Zhou,  Lin Gu</p>
  <p><b>备注</b>：Accepted by ICCV 2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, conditional Neural Radiance, Radiance Fields, paper presents ER-NeRF, small model size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents ER-NeRF, a novel conditional Neural Radiance Fields
(NeRF) based architecture for talking portrait synthesis that can concurrently
achieve fast convergence, real-time rendering, and state-of-the-art performance
with small model size. Our idea is to explicitly exploit the unequal
contribution of spatial regions to guide talking portrait modeling.
Specifically, to improve the accuracy of dynamic head reconstruction, a compact
and expressive NeRF-based Tri-Plane Hash Representation is introduced by
pruning empty spatial regions with three planar hash encoders. For speech
audio, we propose a Region Attention Module to generate region-aware condition
feature via an attention mechanism. Different from existing methods that
utilize an MLP-based encoder to learn the cross-modal relation implicitly, the
attention mechanism builds an explicit connection between audio features and
spatial regions to capture the priors of local motions. Moreover, a direct and
fast Adaptive Pose Encoding is introduced to optimize the head-torso separation
problem by mapping the complex transformation of the head pose into spatial
coordinates. Extensive experiments demonstrate that our method renders better
high-fidelity and audio-lips synchronized talking portrait videos, with
realistic details and high efficiency compared to previous methods.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on  Multi-Scan 3D Point Clouds</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09316</p>
  <p><b>作者</b>：Jiahui Liu,  Chirui Chang,  Jianhui Liu,  Xiaoyang Wu,  Lan Ma,  Xiaojuan Qi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic segmentation, large-scale point clouds, point clouds plays, multi-scan large-scale point, semantic segmentation task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D semantic segmentation on multi-scan large-scale point clouds plays an
important role in autonomous systems. Unlike the single-scan-based semantic
segmentation task, this task requires distinguishing the motion states of
points in addition to their semantic categories. However, methods designed for
single-scan-based segmentation tasks perform poorly on the multi-scan task due
to the lacking of an effective way to integrate temporal information. We
propose MarS3D, a plug-and-play motion-aware module for semantic segmentation
on multi-scan 3D point clouds. This module can be flexibly combined with
single-scan models to allow them to have multi-scan perception abilities. The
model encompasses two key designs: the Cross-Frame Feature Embedding module for
enriching representation learning and the Motion-Aware Feature Learning module
for enhancing motion awareness. Extensive experiments show that MarS3D can
improve the performance of the baseline model by a large margin. The code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory  Forecasting</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09306</p>
  <p><b>作者</b>：Inhwan Bae,  Jean Oh,  Hae-Gon Jeon</p>
  <p><b>备注</b>：Accepted at ICCV 2023</p>
  <p><b>关键词</b>：Capturing high-dimensional social, Capturing high-dimensional, predicting trajectories, essential for predicting, mathbb</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Capturing high-dimensional social interactions and feasible futures is
essential for predicting trajectories. To address this complex nature, several
attempts have been devoted to reducing the dimensionality of the output
variables via parametric curve fitting such as the Bézier curve and B-spline
function. However, these functions, which originate in computer graphics
fields, are not suitable to account for socially acceptable human dynamics. In
this paper, we present EigenTrajectory ($\mathbb{ET}$), a trajectory prediction
approach that uses a novel trajectory descriptor to form a compact space, known
here as $\mathbb{ET}$ space, in place of Euclidean space, for representing
pedestrian movements. We first reduce the complexity of the trajectory
descriptor via a low-rank approximation. We transform the pedestrians' history
paths into our $\mathbb{ET}$ space represented by spatio-temporal principle
components, and feed them into off-the-shelf trajectory forecasting models. The
inputs and outputs of the models as well as social interactions are all
gathered and aggregated in the corresponding $\mathbb{ET}$ space. Lastly, we
propose a trajectory anchor-based refinement method to cover all possible
futures in the proposed $\mathbb{ET}$ space. Extensive experiments demonstrate
that our EigenTrajectory predictor can significantly improve both the
prediction accuracy and reliability of existing trajectory forecasting models
on public benchmarks, indicating that the proposed descriptor is suited to
represent pedestrian behaviors. Code is publicly available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Conformal prediction under ambiguous ground truth</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09302</p>
  <p><b>作者</b>：David Stutz,  Abhijit Guha Roy,  Tatiana Matejovicova,  Patricia Strachan,  Ali Taylan Cemgil,  Arnaud Doucet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：providing confidence sets, safety-critical classification tasks, user-specified probability, rigorous uncertainty quantification, perform rigorous uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In safety-critical classification tasks, conformal prediction allows to
perform rigorous uncertainty quantification by providing confidence sets
including the true class with a user-specified probability. This generally
assumes the availability of a held-out calibration set with access to ground
truth labels. Unfortunately, in many domains, such labels are difficult to
obtain and usually approximated by aggregating expert opinions. In fact, this
holds true for almost all datasets, including well-known ones such as CIFAR and
ImageNet. Applying conformal prediction using such labels underestimates
uncertainty. Indeed, when expert opinions are not resolvable, there is inherent
ambiguity present in the labels. That is, we do not have ``crisp'', definitive
ground truth labels and this uncertainty should be taken into account during
calibration. In this paper, we develop a conformal prediction framework for
such ambiguous ground truth settings which relies on an approximation of the
underlying posterior distribution of labels given inputs. We demonstrate our
methodology on synthetic and real datasets, including a case study of skin
condition classification in dermatology.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：RepViT: Revisiting Mobile CNN From ViT Perspective</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09283</p>
  <p><b>作者</b>：Ao Wang,  Hui Chen,  Zijia Lin,  Hengjun Pu,  Guiguang Ding</p>
  <p><b>备注</b>：9 pages, 7 figures</p>
  <p><b>关键词</b>：lightweight Convolutional Neural, Convolutional Neural, demonstrate superior performance, lightweight Vision Transformers, Vision Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, lightweight Vision Transformers (ViTs) demonstrate superior
performance and lower latency compared with lightweight Convolutional Neural
Networks (CNNs) on resource-constrained mobile devices. This improvement is
usually attributed to the multi-head self-attention module, which enables the
model to learn global representations. However, the architectural disparities
between lightweight ViTs and lightweight CNNs have not been adequately
examined. In this study, we revisit the efficient design of lightweight CNNs
and emphasize their potential for mobile devices. We incrementally enhance the
mobile-friendliness of a standard lightweight CNN, specifically MobileNetV3, by
integrating the efficient architectural choices of lightweight ViTs. This ends
up with a new family of pure lightweight CNNs, namely RepViT. Extensive
experiments show that RepViT outperforms existing state-of-the-art lightweight
ViTs and exhibits favorable latency in various vision tasks. On ImageNet,
RepViT achieves over 80\% top-1 accuracy with nearly 1ms latency on an iPhone
12, which is the first time for a lightweight model, to the best of our
knowledge. Our largest model, RepViT-M3, obtains 81.4\% accuracy with only
1.3ms latency. The code and trained models are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Regression-free Blind Image Quality Assessment</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09279</p>
  <p><b>作者</b>：Xiaoqi Wang,  Jian Xiong,  Hao Gao,  Weisi Lin</p>
  <p><b>备注</b>：11 pages, 7 figures, 50 conferences</p>
  <p><b>关键词</b>：biased training samples, image quality assessment, blind image quality, biased training, biased estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regression-based blind image quality assessment (IQA) models are susceptible
to biased training samples, leading to a biased estimation of model parameters.
To mitigate this issue, we propose a regression-free framework for image
quality evaluation, which is founded upon retrieving similar instances by
incorporating semantic and distortion features. The motivation behind this
approach is rooted in the observation that the human visual system (HVS) has
analogous visual responses to semantically similar image contents degraded by
the same distortion. The proposed framework comprises two classification-based
modules: semantic-based classification (SC) module and distortion-based
classification (DC) module. Given a test image and an IQA database, the SC
module retrieves multiple pristine images based on semantic similarity. The DC
module then retrieves instances based on distortion similarity from the
distorted images that correspond to each retrieved pristine image. Finally, the
predicted quality score is derived by aggregating the subjective quality scores
of multiple retrieved instances. Experimental results on four benchmark
databases validate that the proposed model can remarkably outperform the
state-of-the-art regression-based models.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly  Supervised 3D Visual Grounding</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09267</p>
  <p><b>作者</b>：Zehan Wang,  Haifeng Huang,  Yang Zhao,  Linjun Li,  Xize Cheng,  Yichen Zhu,  Aoxiong Yin,  Zhou Zhao</p>
  <p><b>备注</b>：ICCV2023</p>
  <p><b>关键词</b>：grounding involves finding, visual grounding involves, visual grounding model, visual grounding, scene that corresponds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D visual grounding involves finding a target object in a 3D scene that
corresponds to a given sentence query. Although many approaches have been
proposed and achieved impressive performance, they all require dense
object-sentence pair annotations in 3D point clouds, which are both
time-consuming and expensive. To address the problem that fine-grained
annotated data is difficult to obtain, we propose to leverage weakly supervised
annotations to learn the 3D visual grounding model, i.e., only coarse
scene-sentence correspondences are used to learn object-sentence links. To
accomplish this, we design a novel semantic matching model that analyzes the
semantic similarity between object proposals and sentences in a coarse-to-fine
manner. Specifically, we first extract object proposals and coarsely select the
top-K candidates based on feature and class similarity matrices. Next, we
reconstruct the masked keywords of the sentence using each candidate one by
one, and the reconstructed accuracy finely reflects the semantic similarity of
each candidate to the query. Additionally, we distill the coarse-to-fine
semantic matching knowledge into a typical two-stage 3D visual grounding model,
which reduces inference costs and improves performance by taking full advantage
of the well-studied structure of the existing architectures. We conduct
extensive experiments on ScanRefer, Nr3D, and Sr3D, which demonstrate the
effectiveness of our proposed method.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Knowledge Distillation for Object Detection: from generic to remote  sensing datasets</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09264</p>
  <p><b>作者</b>：Hoàng-Ân Lê,  Minh-Tan Pham</p>
  <p><b>备注</b>：Accepted for publishing at IGARSS 2023</p>
  <p><b>关键词</b>：model compression technique, active research area, remote sensing communities, well-known model compression, compression technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation, a well-known model compression technique, is an
active research area in both computer vision and remote sensing communities. In
this paper, we evaluate in a remote sensing context various off-the-shelf
object detection knowledge distillation methods which have been originally
developed on generic computer vision datasets such as Pascal VOC. In
particular, methods covering both logit mimicking and feature imitation
approaches are applied for vehicle detection using the well-known benchmarks
such as xView and VEDAI datasets. Extensive experiments are performed to
compare the relative performance and interrelationships of the methods.
Experimental results show high variations and confirm the importance of result
aggregation and cross validation on remote sensing datasets.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Neuromorphic spintronics simulated using an unconventional data-driven  Thiele equation approach</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09262</p>
  <p><b>作者</b>：Anatole Moureaux,  Simon de Wergifosse,  Chloé Chopin,  Flavio Abreu Araujo</p>
  <p><b>备注</b>：Presented in ISCS2023</p>
  <p><b>关键词</b>：spin-torque vortex nano-oscillators, Thiele equation approach, unconventional model based, Thiele equation, vortex nano-oscillators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we developed a quantitative description of the dynamics of
spin-torque vortex nano-oscillators (STVOs) through an unconventional model
based on the combination of the Thiele equation approach (TEA) and data from
micromagnetic simulations (MMS). Solving the STVO dynamics with our analytical
model allows to accelerate the simulations by 9 orders of magnitude compared to
MMS while reaching the same level of accuracy. Here, we showcase our model by
simulating a STVO-based neural network for solving a classification task. We
assess its performance with respect to the input signal current intensity and
the level of noise that might affect such a system. Our approach is promising
for accelerating the design of STVO-based neuromorphic computing devices while
decreasing drastically its computational cost.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Adaptive Topological Feature via Persistent Homology: Filtration  Learning for Point Clouds</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09259</p>
  <p><b>作者</b>：Naoki Nishikawa,  Yuichi Ike,  Kenji Yamanishi</p>
  <p><b>备注</b>：17 pages with 4 figures</p>
  <p><b>关键词</b>：machine learning methods, Machine learning, attracting much attention, material science, persistent homology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning for point clouds has been attracting much attention, with
many applications in various fields, such as shape recognition and material
science. To enhance the accuracy of such machine learning methods, it is known
to be effective to incorporate global topological features, which are typically
extracted by persistent homology. In the calculation of persistent homology for
a point cloud, we need to choose a filtration for the point clouds, an
increasing sequence of spaces. Because the performance of machine learning
methods combined with persistent homology is highly affected by the choice of a
filtration, we need to tune it depending on data and tasks. In this paper, we
propose a framework that learns a filtration adaptively with the use of neural
networks. In order to make the resulting persistent homology
isometry-invariant, we develop a neural network architecture with such
invariance. Additionally, we theoretically show a finite-dimensional
approximation result that justifies our architecture. Experimental results
demonstrated the efficacy of our framework in several classification tasks.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Generation of High Spatial Resolution Terrestrial Surface from Low  Spatial Resolution Elevation Contour Maps via Hierarchical Computation of  Median Elevation Regions</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09239</p>
  <p><b>作者</b>：Geetika Barman,  B.S. Daya Sagar</p>
  <p><b>备注</b>：11 pages, 6 figures,1 table, 1 algorithm</p>
  <p><b>关键词</b>：Digital Elevation Model, Elevation Model, effective morphological approach, Elevation, Digital Elevation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We proposed a simple yet effective morphological approach to convert a sparse
Digital Elevation Model (DEM) to a dense Digital Elevation Model. The
conversion is similar to that of the generation of high-resolution DEM from its
low-resolution DEM. The approach involves the generation of median contours to
achieve the purpose. It is a sequential step of the I) decomposition of the
existing sparse Contour map into the maximum possible Threshold Elevation
Region (TERs). II) Computing all possible non-negative and non-weighted Median
Elevation Region (MER) hierarchically between the successive TER decomposed
from a sparse contour map. III) Computing the gradient of all TER, and MER
computed from previous steps would yield the predicted intermediate elevation
contour at a higher spatial resolution. We presented this approach initially
with some self-made synthetic data to show how the contour prediction works and
then experimented with the available contour map of Washington, NH to justify
its usefulness. This approach considers the geometric information of existing
contours and interpolates the elevation contour at a new spatial region of a
topographic surface until no elevation contours are necessary to generate. This
novel approach is also very low-cost and robust as it uses elevation contours.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Fusing Hand and Body Skeletons for Human Action Recognition in Assembly</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09238</p>
  <p><b>作者</b>：Dustin Aganian,  Mona Köhler,  Benedict Stephan,  Markus Eisenbach,  Horst-Michael Gross</p>
  <p><b>备注</b>：International Conference on Artificial Neural Networks (ICANN) 2023</p>
  <p><b>关键词</b>：effective human-robot collaboration, collaborative robots, continue to gain, industrial manufacturing, effective human-robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As collaborative robots (cobots) continue to gain popularity in industrial
manufacturing, effective human-robot collaboration becomes crucial. Cobots
should be able to recognize human actions to assist with assembly tasks and act
autonomously. To achieve this, skeleton-based approaches are often used due to
their ability to generalize across various people and environments. Although
body skeleton approaches are widely used for action recognition, they may not
be accurate enough for assembly actions where the worker's fingers and hands
play a significant role. To address this limitation, we propose a method in
which less detailed body skeletons are combined with highly detailed hand
skeletons. We investigate CNNs and transformers, the latter of which are
particularly adept at extracting and combining important information from both
skeleton types using attention. This paper demonstrates the effectiveness of
our proposed approach in enhancing action recognition in assembly scenarios.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Augmenting CLIP with Improved Visio-Linguistic Reasoning</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09233</p>
  <p><b>作者</b>：Samyadeep Basu,  Maziar Sanjabi,  Daniela Massiceti,  Shell Xu Hu,  Soheil Feizi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including zero-shot classification, downstream applications including, transfer learning, applications including zero-shot, applications including</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-text contrastive models such as CLIP are useful for a variety of
downstream applications including zero-shot classification, image-text
retrieval and transfer learning. However, these contrastively trained
vision-language models often fail on compositional visio-linguistic tasks such
as Winoground with performance equivalent to random chance. In our paper, we
address this issue and propose a sample-efficient light-weight method called
SDS-CLIP to improve the compositional visio-linguistic reasoning capabilities
of CLIP. The core idea of our method is to use differentiable image
parameterizations to fine-tune CLIP with a distillation objective from large
text-to-image generative models such as Stable-Diffusion which are relatively
good at visio-linguistic reasoning tasks. On the challenging Winoground
compositional reasoning benchmark, our method improves the absolute
visio-linguistic performance of different CLIP models by up to 7%, while on the
ARO dataset, our method improves the visio-linguistic performance by upto 3%.
As a byproduct of inducing visio-linguistic reasoning into CLIP, we also find
that the zero-shot performance improves marginally on a variety of downstream
datasets. Our method reinforces that carefully designed distillation objectives
from generative models can be leveraged to extend existing contrastive
image-text models with improved visio-linguistic reasoning capabilities.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Survey on Open-Vocabulary Detection and Segmentation: Past, Present,  and Future</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09220</p>
  <p><b>作者</b>：Chaoyang Zhu,  Long Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning era, made tremendous progress, computer vision, learning era, made tremendous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the most fundamental tasks of computer vision, object detection and
segmentation have made tremendous progress in the deep learning era. Due to the
expensive manual labeling, the annotated categories in existing datasets are
often small-scale and pre-defined, i.e., state-of-the-art detectors and
segmentors fail to generalize beyond the closed-vocabulary. To resolve this
limitation, the last few years have witnessed increasing attention toward
Open-Vocabulary Detection (OVD) and Segmentation (OVS). In this survey, we
provide a comprehensive review on the past and recent development of OVD and
OVS. To this end, we develop a taxonomy according to the type of task and
methodology. We find that the permission and usage of weak supervision signals
can well discriminate different methodologies, including: visual-semantic space
mapping, novel visual feature synthesis, region-aware training,
pseudo-labeling, knowledge distillation-based, and transfer learning-based. The
proposed taxonomy is universal across different tasks, covering object
detection, semantic/instance/panoptic segmentation, 3D scene and video
understanding. In each category, its main principles, key challenges,
development routes, strengths, and weaknesses are thoroughly discussed. In
addition, we benchmark each task along with the vital components of each
method. Finally, several promising directions are provided to stimulate future
research.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual  Learning</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09218</p>
  <p><b>作者</b>：Zhenyi Wang,  Enneng Yang,  Li Shen,  Heng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previously acquired information, Forgetting, loss or deterioration, deterioration of previously, previously acquired</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forgetting refers to the loss or deterioration of previously acquired
information or knowledge. While the existing surveys on forgetting have
primarily focused on continual learning, forgetting is a prevalent phenomenon
observed in various other research domains within deep learning. Forgetting
manifests in research fields such as generative models due to generator shifts,
and federated learning due to heterogeneous data distributions across clients.
Addressing forgetting encompasses several challenges, including balancing the
retention of old task knowledge with fast learning of new tasks, managing task
interference with conflicting goals, and preventing privacy leakage, etc.
Moreover, most existing surveys on continual learning implicitly assume that
forgetting is always harmful. In contrast, our survey argues that forgetting is
a double-edged sword and can be beneficial and desirable in certain cases, such
as privacy-preserving scenarios. By exploring forgetting in a broader context,
we aim to present a more nuanced understanding of this phenomenon and highlight
its potential advantages. Through this comprehensive survey, we aspire to
uncover potential solutions by drawing upon ideas and approaches from various
fields that have dealt with forgetting. By examining forgetting beyond its
conventional boundaries, in future work, we hope to encourage the development
of novel strategies for mitigating, harnessing, or even embracing forgetting in
real applications. A comprehensive list of papers about forgetting in various
research fields is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：You've Got Two Teachers: Co-evolutionary Image and Report Distillation  for Semi-supervised Anatomical Abnormality Detection in Chest X-ray</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09184</p>
  <p><b>作者</b>：Jinghan Sun,  Dong Wei,  Zhe Xu,  Donghuan Lu,  Hong Liu,  Liansheng Wang,  Yefeng Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reduce observational oversights, characterising cardiopulmonary radiological, cardiopulmonary radiological findings, expedite clinical workflow, Chest X-ray</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chest X-ray (CXR) anatomical abnormality detection aims at localizing and
characterising cardiopulmonary radiological findings in the radiographs, which
can expedite clinical workflow and reduce observational oversights. Most
existing methods attempted this task in either fully supervised settings which
demanded costly mass per-abnormality annotations, or weakly supervised settings
which still lagged badly behind fully supervised methods in performance. In
this work, we propose a co-evolutionary image and report distillation (CEIRD)
framework, which approaches semi-supervised abnormality detection in CXR by
grounding the visual detection results with text-classified abnormalities from
paired radiology reports, and vice versa. Concretely, based on the classical
teacher-student pseudo label distillation (TSD) paradigm, we additionally
introduce an auxiliary report classification model, whose prediction is used
for report-guided pseudo detection label refinement (RPDLR) in the primary
vision detection task. Inversely, we also use the prediction of the vision
detection model for abnormality-guided pseudo classification label refinement
(APCLR) in the auxiliary report classification task, and propose a co-evolution
strategy where the vision and report models mutually promote each other with
RPDLR and APCLR performed alternatively. To this end, we effectively
incorporate the weak supervision by reports into the semi-supervised TSD
pipeline. Besides the cross-modal pseudo label refinement, we further propose
an intra-image-modal self-adaptive non-maximum suppression, where the pseudo
detection labels generated by the teacher vision model are dynamically
rectified by high-confidence predictions by the student. Experimental results
on the public MIMIC-CXR benchmark demonstrate CEIRD's superior performance to
several up-to-date weakly and semi-supervised methods.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Pixel-wise Graph Attention Networks for Person Re-identification</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09183</p>
  <p><b>作者</b>：Wenyu Zhang,  Qing Ding,  Jian Hu,  Yi Ma,  Mingzhe Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：handle irregular data, Graph, Graph convolutional networks, handle irregular, GCN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph convolutional networks (GCN) is widely used to handle irregular data
since it updates node features by using the structure information of graph.
With the help of iterated GCN, high-order information can be obtained to
further enhance the representation of nodes. However, how to apply GCN to
structured data (such as pictures) has not been deeply studied. In this paper,
we explore the application of graph attention networks (GAT) in image feature
extraction. First of all, we propose a novel graph generation algorithm to
convert images into graphs through matrix transformation. It is one magnitude
faster than the algorithm based on K Nearest Neighbors (KNN). Then, GAT is used
on the generated graph to update the node features. Thus, a more robust
representation is obtained. These two steps are combined into a module called
pixel-wise graph attention module (PGA). Since the graph obtained by our graph
generation algorithm can still be transformed into a picture after processing,
PGA can be well combined with CNN. Based on these two modules, we consulted the
ResNet and design a pixel-wise graph attention network (PGANet). The PGANet is
applied to the task of person re-identification in the datasets Market1501,
DukeMTMC-reID and Occluded-DukeMTMC (outperforms state-of-the-art by 0.8\%,
1.1\% and 11\% respectively, in mAP scores). Experiment results show that it
achieves the state-of-the-art performance.
\href{this https URL}{The code is available here}.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Jean-Luc Picard at Touché 2023: Comparing Image Generation, Stance  Detection and Feature Matching for Image Retrieval for Arguments</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09172</p>
  <p><b>作者</b>：Max Moebius,  Maximilian Enderling,  Sarah T. Bachinger</p>
  <p><b>备注</b>：7 pages, 1 figure, 1 table, conference: CLEF</p>
  <p><b>关键词</b>：Image Retrieval, Image Generation, Image, shared task, Stance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Participating in the shared task "Image Retrieval for arguments", we used
different pipelines for image retrieval containing Image Generation, Stance
Detection, Preselection and Feature Matching. We submitted four different runs
with different pipeline layout and compare them to given baseline. Our
pipelines perform similarly to the baseline.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Towards Trustworthy Dataset Distillation</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09165</p>
  <p><b>作者</b>：Shijie Ma,  Fei Zhu,  Zhen Cheng,  Xu-Yao Zhang</p>
  <p><b>备注</b>：20 pages, 20 figures</p>
  <p><b>关键词</b>：applying deep learning, real-world applications, eternal pursuits, pursuits when applying, applying deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficiency and trustworthiness are two eternal pursuits when applying deep
learning in real-world applications. With regard to efficiency, dataset
distillation (DD) endeavors to reduce training costs by distilling the large
dataset into a tiny synthetic dataset. However, existing methods merely
concentrate on in-distribution (InD) classification in a closed-world setting,
disregarding out-of-distribution (OOD) samples. On the other hand, OOD
detection aims to enhance models' trustworthiness, which is always
inefficiently achieved in full-data settings. For the first time, we
simultaneously consider both issues and propose a novel paradigm called
Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and
outliers, the condensed datasets are capable to train models competent in both
InD classification and OOD detection. To alleviate the requirement of real
outlier data and make OOD detection more practical, we further propose to
corrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier
Exposure (POE). Comprehensive experiments on various settings demonstrate the
effectiveness of TrustDD, and the proposed POE surpasses state-of-the-art
method Outlier Exposure (OE). Compared with the preceding DD, TrustDD is more
trustworthy and applicable to real open-world scenarios. Our code will be
publicly available.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：CG-fusion CAM: Online segmentation of laser-induced damage on  large-aperture optics</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09161</p>
  <p><b>作者</b>：Yueyue Han,  Yingyan Huang,  Hangcheng Dong,  Fengdong Chen,  Fa Zeng,  Zhitao Peng,  Qihua Zhu,  Guodong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stray light interference, high-power laser facilities, supervised semantic segmentation, complicated damage morphology, uneven illumination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online segmentation of laser-induced damage on large-aperture optics in
high-power laser facilities is challenged by complicated damage morphology,
uneven illumination and stray light interference. Fully supervised semantic
segmentation algorithms have achieved state-of-the-art performance, but rely on
plenty of pixel-level labels, which are time-consuming and labor-consuming to
produce. LayerCAM, an advanced weakly supervised semantic segmentation
algorithm, can generate pixel-accurate results using only image-level labels,
but its scattered and partially under-activated class activation regions
degrade segmentation performance. In this paper, we propose a weakly supervised
semantic segmentation method with Continuous Gradient CAM and its nonlinear
multi-scale fusion (CG-fusion CAM). The method redesigns the way of
back-propagating gradients and non-linearly activates the multi-scale fused
heatmaps to generate more fine-grained class activation maps with appropriate
activation degree for different sizes of damage sites. Experiments on our
dataset show that the proposed method can achieve segmentation performance
comparable to that of fully supervised algorithms.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth  Approach with Saddle-shaped Depth Cells</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09160</p>
  <p><b>作者</b>：Xinyi Ye,  Weiyue Zhao,  Tianqi Liu,  Zihao Huang,  Zhiguo Cao,  Xin Li</p>
  <p><b>备注</b>：Accepted by ICCV 2023</p>
  <p><b>关键词</b>：Learning-based multi-view stereo, predicting accurate depth, predicting accurate, depth, MVS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning-based multi-view stereo (MVS) methods deal with predicting accurate
depth maps to achieve an accurate and complete 3D representation. Despite the
excellent performance, existing methods ignore the fact that a suitable depth
geometry is also critical in MVS. In this paper, we demonstrate that different
depth geometries have significant performance gaps, even using the same depth
prediction error. Therefore, we introduce an ideal depth geometry composed of
Saddle-Shaped Cells, whose predicted depth map oscillates upward and downward
around the ground-truth surface, rather than maintaining a continuous and
smooth depth plane. To achieve it, we develop a coarse-to-fine framework called
Dual-MVSNet (DMVSNet), which can produce an oscillating depth plane.
Technically, we predict two depth values for each pixel (Dual-Depth), and
propose a novel loss function and a checkerboard-shaped selecting strategy to
constrain the predicted depth geometry. Compared to existing methods,DMVSNet
achieves a high rank on the DTU benchmark and obtains the top performance on
challenging scenes of Tanks and Temples, demonstrating its strong performance
and generalization ability. Our method also points to a new research direction
for considering depth geometry in MVS.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Class-relation Knowledge Distillation for Novel Class Discovery</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09158</p>
  <p><b>作者</b>：Peiyan Gu,  Chuyu Zhang,  Ruijie Xu,  Xuming He</p>
  <p><b>备注</b>：ICCV2023</p>
  <p><b>关键词</b>：classes, tackle the problem, aims to learn, labeled data, class</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We tackle the problem of novel class discovery, which aims to learn novel
classes without supervision based on labeled data from known classes. A key
challenge lies in transferring the knowledge in the known-class data to the
learning of novel classes. Previous methods mainly focus on building a shared
representation space for knowledge transfer and often ignore modeling class
relations. To address this, we introduce a class relation representation for
the novel classes based on the predicted class distribution of a model trained
on known classes. Empirically, we find that such class relation becomes less
informative during typical discovery training. To prevent such information
loss, we propose a novel knowledge distillation framework, which utilizes our
class-relation representation to regularize the learning of novel classes. In
addition, to enable a flexible knowledge distillation scheme for each data
point in novel classes, we develop a learnable weighting function for the
regularization, which adaptively promotes knowledge transfer based on the
semantic similarity between the novel and known classes. To validate the
effectiveness and generalization of our method, we conduct extensive
experiments on multiple benchmarks, including CIFAR100, Stanford Cars, CUB, and
FGVC-Aircraft datasets. Our results demonstrate that the proposed method
outperforms the previous state-of-the-art methods by a significant margin on
almost all benchmarks. Code is available at
\href{this https URL}{here}.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：MLF-DET: Multi-Level Fusion for Cross-Modal 3D Object Detection</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09155</p>
  <p><b>作者</b>：Zewei Lin,  Yanqing Shen,  Sanping Zhou,  Shitao Chen,  Nanning Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-Level Fusion network, Multi-scale Voxel Image, Voxel Image fusion, effective Multi-Level Fusion, multi-scale voxel features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel and effective Multi-Level Fusion network,
named as MLF-DET, for high-performance cross-modal 3D object DETection, which
integrates both the feature-level fusion and decision-level fusion to fully
utilize the information in the image. For the feature-level fusion, we present
the Multi-scale Voxel Image fusion (MVI) module, which densely aligns
multi-scale voxel features with image features. For the decision-level fusion,
we propose the lightweight Feature-cued Confidence Rectification (FCR) module
which further exploits image semantics to rectify the confidence of detection
candidates. Besides, we design an effective data augmentation strategy termed
Occlusion-aware GT Sampling (OGS) to reserve more sampled objects in the
training scenes, so as to reduce overfitting. Extensive experiments on the
KITTI dataset demonstrate the effectiveness of our method. Notably, on the
extremely competitive KITTI car 3D object detection benchmark, our method
reaches 82.89% moderate AP and achieves state-of-the-art performance without
bells and whistles.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：OPHAvatars: One-shot Photo-realistic Head Avatars</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09153</p>
  <p><b>作者</b>：Shaoxu Li</p>
  <p><b>备注</b>：code: this https URL</p>
  <p><b>关键词</b>：synthesizing photo-realistic digital, method, coarse talking head, method synthesizes, coarse talking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for synthesizing photo-realistic digital avatars from
only one portrait as the reference. Given a portrait, our method synthesizes a
coarse talking head video using driving keypoints features. And with the coarse
video, our method synthesizes a coarse talking head avatar with a deforming
neural radiance field. With rendered images of the coarse avatar, our method
updates the low-quality images with a blind face restoration model. With
updated images, we retrain the avatar for higher quality. After several
iterations, our method can synthesize a photo-realistic animatable 3D neural
head avatar. The motivation of our method is deformable neural radiance field
can eliminate the unnatural distortion caused by the image2video method. Our
method outperforms state-of-the-art methods in quantitative and qualitative
studies on various subjects.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：PRO-Face S: Privacy-preserving Reversible Obfuscation of Face Images via  Secure Flow</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09146</p>
  <p><b>作者</b>：Lin Yuan,  Kai Liang,  Xiao Pu,  Yan Zhang,  Jiaxu Leng,  Tao Wu,  Nannan Wang,  Xinbo Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：characteristics including anonymity, Privacy-preserving Reversible Obfuscation, single lightweight framework, unifies multiple characteristics, multiple characteristics including</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a novel paradigm for facial privacy protection that
unifies multiple characteristics including anonymity, diversity, reversibility
and security within a single lightweight framework. We name it PRO-Face S,
short for Privacy-preserving Reversible Obfuscation of Face images via Secure
flow-based model. In the framework, an Invertible Neural Network (INN) is
utilized to process the input image along with its pre-obfuscated form, and
generate the privacy protected image that visually approximates to the
pre-obfuscated one, thus ensuring privacy. The pre-obfuscation applied can be
in diversified form with different strengths and styles specified by users.
Along protection, a secret key is injected into the network such that the
original image can only be recovered from the protection image via the same
model given the correct key provided. Two modes of image recovery are devised
to deal with malicious recovery attempts in different scenarios. Finally,
extensive experiments conducted on three public image datasets demonstrate the
superiority of the proposed framework over multiple state-of-the-art
approaches.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset,  Methods, and Results</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09143</p>
  <p><b>作者</b>：Yuki Kondo,  Norimichi Ukita,  Takayuki Yamaguchi,  Hao-Yu Hou,  Mu-Yi Shen,  Chia-Chi Hsu,  En-Ming Huang,  Yu-Chen Huang,  Yu-Cheng Xia,  Chien-Yao Wang,  Chun-Yi Lee,  Da Huo,  Marc A. Kastner,  Tingwei Liu,  Yasutomo Kawanishi,  Takatsugu Hirayama,  Takahiro Komamizu,  Ichiro Ide,  Yosuke Shinya,  Xinyao Liu,  Guang Liang,  Syusuke Yasui</p>
  <p><b>备注</b>：This paper is included in the proceedings of the 18th International Conference on Machine Vision Applications (MVA2023). It will be officially published at a later date. Project page : this https URL</p>
  <p><b>关键词</b>：Small Object Detection, require object detection, applications require object, important machine vision, machine vision topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Small Object Detection (SOD) is an important machine vision topic because (i)
a variety of real-world applications require object detection for distant
objects and (ii) SOD is a challenging task due to the noisy, blurred, and
less-informative image appearances of small objects. This paper proposes a new
SOD dataset consisting of 39,070 images including 137,121 bird instances, which
is called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The
detail of the challenge with the SOD4SB dataset is introduced in this paper. In
total, 223 participants joined this challenge. This paper briefly introduces
the award-winning methods. The dataset, the baseline code, and the website for
evaluation on the public testset are publicly available.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DropMix: Reducing Class Dependency in Mixed Sample Data Augmentation</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09136</p>
  <p><b>作者</b>：Haeil Lee,  Hansang Lee,  Junmo Kim</p>
  <p><b>备注</b>：17 pages, 10 figures</p>
  <p><b>关键词</b>：Mixed sample data, sample data augmentation, Mixed sample, variety of tasks, widely used technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixed sample data augmentation (MSDA) is a widely used technique that has
been found to improve performance in a variety of tasks. However, in this
paper, we show that the effects of MSDA are class-dependent, with some classes
seeing an improvement in performance while others experience a decline. To
reduce class dependency, we propose the DropMix method, which excludes a
specific percentage of data from the MSDA computation. By training on a
combination of MSDA and non-MSDA data, the proposed method not only improves
the performance of classes that were previously degraded by MSDA, but also
increases overall average accuracy, as shown in experiments on two datasets
(CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and
PuzzleMix).</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Light-Weight Vision Transformer with Parallel Local and Global  Self-Attention</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09120</p>
  <p><b>作者</b>：Nikolas Ebert,  Laurenz Reichardt,  Didier Stricker,  Oliver Wasenmüller</p>
  <p><b>备注</b>：This paper has been accepted at IEEE Intelligent Transportation Systems Conference (ITSC), 2023</p>
  <p><b>关键词</b>：dominated computer vision, recent years, dominated computer, models cannot easily, easily be deployed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While transformer architectures have dominated computer vision in recent
years, these models cannot easily be deployed on hardware with limited
resources for autonomous driving tasks that require real-time-performance.
Their computational complexity and memory requirements limits their use,
especially for applications with high-resolution inputs. In our work, we
redesign the powerful state-of-the-art Vision Transformer PLG-ViT to a much
more compact and efficient architecture that is suitable for such tasks. We
identify computationally expensive blocks in the original PLG-ViT architecture
and propose several redesigns aimed at reducing the number of parameters and
floating-point operations. As a result of our redesign, we are able to reduce
PLG-ViT in size by a factor of 5, with a moderate drop in performance. We
propose two variants, optimized for the best trade-off between parameter count
to runtime as well as parameter count to accuracy. With only 5 million
parameters, we achieve 79.5$\%$ top-1 accuracy on the ImageNet-1K
classification benchmark. Our networks demonstrate great performance on general
vision benchmarks like COCO instance segmentation. In addition, we conduct a
series of experiments, demonstrating the potential of our approach in solving
various tasks specifically tailored to the challenges of autonomous driving and
transportation.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and  Repulsive UDF</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09112</p>
  <p><b>作者</b>：Stefan Lionar,  Xiangyu Xu,  Min Lin,  Gim Hee Lee</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：Remarkable progress, Repulsive UDF, MCC, Repulsive, Repulsive Unsigned Distance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remarkable progress has been made in 3D reconstruction from single-view RGB-D
inputs. MCC is the current state-of-the-art method in this field, which
achieves unprecedented success by combining vision Transformers with
large-scale training. However, we identified two key limitations of MCC: 1) The
Transformer decoder is inefficient in handling large number of query points; 2)
The 3D representation struggles to recover high-fidelity details. In this
paper, we propose a new approach called NU-MCC that addresses these
limitations. NU-MCC includes two key innovations: a Neighborhood decoder and a
Repulsive Unsigned Distance Function (Repulsive UDF). First, our Neighborhood
decoder introduces center points as an efficient proxy of input visual
features, allowing each query point to only attend to a small neighborhood.
This design not only results in much faster inference speed but also enables
the exploitation of finer-scale visual features for improved recovery of 3D
textures. Second, our Repulsive UDF is a novel alternative to the occupancy
field used in MCC, significantly improving the quality of 3D object
reconstruction. Compared to standard UDFs that suffer from holes in results,
our proposed Repulsive UDF can achieve more complete surface reconstruction.
Experimental results demonstrate that NU-MCC is able to learn a strong 3D
representation, significantly advancing the state of the art in single-view 3D
reconstruction. Particularly, it outperforms MCC by 9.7% in terms of the
F1-score on the CO3D-v2 dataset with more than 5x faster running speed.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Mining of Single-Class by Active Learning for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09109</p>
  <p><b>作者</b>：Hugues Lambert,  Emma Slade</p>
  <p><b>备注</b>：29 pages, 14 figures, 2 tables</p>
  <p><b>关键词</b>：Active Learning, policies require retraining, informative samples, retraining a target, times in order</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several Active Learning (AL) policies require retraining a target model
several times in order to identify the most informative samples and rarely
offer the option to focus on the acquisition of samples from underrepresented
classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm
is introduced where an AL policy is constructed through deep reinforcement
learning and exploits quantity-accuracy correlations to build datasets on which
high-performance models can be trained with regards to specific classes.
MiSiCAL is especially helpful in the case of very large batch sizes since it
does not require repeated model training sessions as is common in other AL
methods. This is thanks to its ability to exploit fixed representations of the
candidate data points. We find that MiSiCAL is able to outperform a random
policy on 150 out of 171 COCO10k classes, while the strongest baseline only
outperforms random on 101 classes.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Division Gets Better: Learning Brightness-Aware and Detail-Sensitive  Representations for Low-Light Image Enhancement</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09104</p>
  <p><b>作者</b>：Huake Wang,  Xiaoyang Yan,  Xingsong Hou,  Junhui Li,  Yujie Dun,  Kaibing Zhang</p>
  <p><b>备注</b>：14 pages, 16 figures</p>
  <p><b>关键词</b>：Low-light image enhancement, image enhancement strives, Low-light image, image enhancement, color and texture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-light image enhancement strives to improve the contrast, adjust the
visibility, and restore the distortion in color and texture. Existing methods
usually pay more attention to improving the visibility and contrast via
increasing the lightness of low-light images, while disregarding the
significance of color and texture restoration for high-quality images. Against
above issue, we propose a novel luminance and chrominance dual branch network,
termed LCDBNet, for low-light image enhancement, which divides low-light image
enhancement into two sub-tasks, e.g., luminance adjustment and chrominance
restoration. Specifically, LCDBNet is composed of two branches, namely
luminance adjustment network (LAN) and chrominance restoration network (CRN).
LAN takes responsibility for learning brightness-aware features leveraging
long-range dependency and local attention correlation. While CRN concentrates
on learning detail-sensitive features via multi-level wavelet decomposition.
Finally, a fusion network is designed to blend their learned features to
produce visually impressive images. Extensive experiments conducted on seven
benchmark datasets validate the effectiveness of our proposed LCDBNet, and the
results manifest that LCDBNet achieves superior performance in terms of
multiple reference/non-reference quality evaluators compared to other
state-of-the-art competitors. Our code and pretrained model will be available.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Survey on Multi-Objective Neural Architecture Search</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09099</p>
  <p><b>作者</b>：Seyed Mahdi Shariatzadeh,  Mahmood Fathy,  Reza Berangi,  Mohammad Shahverdy</p>
  <p><b>备注</b>：22 pages, 10 figures, 9 tables</p>
  <p><b>关键词</b>：Auto Machine Learning, neural architecture search, expert-crafted neural architectures, automatic generation, architecture search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the expert-crafted neural architectures is increasing overtaken by
the utilization of neural architecture search (NAS) and automatic generation
(and tuning) of network structures which has a close relation to the
Hyperparameter Optimization and Auto Machine Learning (AutoML). After the
earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective
Neural architecture Search (MONAS) has been attracting attentions which
considers more goals such as computational complexity, power consumption, and
size of the network for optimization, reaching a trade-off between the accuracy
and other features like the computational cost. In this paper, we present an
overview of principal and state-of-the-art works in the field of MONAS.
Starting from a well-categorized taxonomy and formulation for the NAS, we
address and correct some miscategorizations in previous surveys of the NAS
field. We also provide a list of all known objectives used and add a number of
new ones and elaborate their specifications. We have provides analyses about
the most important objectives and shown that the stochastic properties of some
the them should be differed from deterministic ones in the multi-objective
optimization procedure of NAS. We finalize this paper with a number of future
directions and topics in the field of MONAS.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：PixelHuman: Animatable Neural Radiance Fields from Few Images</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09070</p>
  <p><b>作者</b>：Gyumin Shim,  Jaeseong Lee,  Junha Hyung,  Jaegul Choo</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：human rendering model, generates animatable human, propose PixelHuman, rendering model, model that generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose PixelHuman, a novel human rendering model that
generates animatable human scenes from a few images of a person with unseen
identity, views, and poses. Previous work have demonstrated reasonable
performance in novel view and pose synthesis, but they rely on a large number
of images to train and are trained per scene from videos, which requires
significant amount of time to produce animatable scenes from unseen human
images. Our method differs from existing methods in that it can generalize to
any input image for animatable human synthesis. Given a random pose sequence,
our method synthesizes each target scene using a neural radiance field that is
conditioned on a canonical representation and pose-aware pixel-aligned
features, both of which can be obtained through deformation fields learned in a
data-driven manner. Our experiments show that our method achieves
state-of-the-art performance in multiview and novel pose synthesis from
few-shot images.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：PatchCT: Aligning Patch Set and Label Set with Conditional Transport for  Multi-Label Image Classification</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09066</p>
  <p><b>作者</b>：Miaoge Li,  Dongsheng Wang,  Xinyang Liu,  Zequn Zeng,  Ruiying Lu,  Bo Chen,  Mingyuan Zhou</p>
  <p><b>备注</b>：accepted by ICCV23</p>
  <p><b>关键词</b>：prediction task, task that aims, aims to identify, Multi-label image classification, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-label image classification is a prediction task that aims to identify
more than one label from a given image. This paper considers the semantic
consistency of the latent space between the visual patch and linguistic label
domains and introduces the conditional transport (CT) theory to bridge the
acknowledged gap. While recent cross-modal attention-based studies have
attempted to align such two representations and achieved impressive
performance, they required carefully-designed alignment modules and extra
complex operations in the attention computation. We find that by formulating
the multi-label classification as a CT problem, we can exploit the interactions
between the image and label efficiently by minimizing the bidirectional CT
cost. Specifically, after feeding the images and textual labels into the
modality-specific encoders, we view each image as a mixture of patch embeddings
and a mixture of label embeddings, which capture the local region features and
the class prototypes, respectively. CT is then employed to learn and align
those two semantic sets by defining the forward and backward navigators.
Importantly, the defined navigators in CT distance model the similarities
between patches and labels, which provides an interpretable tool to visualize
the learned prototypes. Extensive experiments on three public image benchmarks
show that the proposed model consistently outperforms the previous methods. Our
code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Learning Adaptive Neighborhoods for Graph Neural Networks</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09065</p>
  <p><b>作者</b>：Avishkar Saha,  Oscar Mendez,  Chris Russell,  Richard Bowden</p>
  <p><b>备注</b>：ICCV 2023</p>
  <p><b>关键词</b>：Graph convolutional networks, graph structured data, convolutional networks, structured data, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph convolutional networks (GCNs) enable end-to-end learning on graph
structured data. However, many works assume a given graph structure. When the
input graph is noisy or unavailable, one approach is to construct or learn a
latent graph structure. These methods typically fix the choice of node degree
for the entire graph, which is suboptimal. Instead, we propose a novel
end-to-end differentiable graph generator which builds graph topologies where
each node selects both its neighborhood and its size. Our module can be readily
integrated into existing pipelines involving graph convolution operations,
replacing the predetermined or existing adjacency matrix with one that is
learned, and optimized, as part of the general objective. As such it is
applicable to any GCN. We integrate our module into trajectory prediction,
point cloud classification and node classification pipelines resulting in
improved accuracy over other structure-learning methods across a wide range of
datasets and GCN backbones.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Unleashing the Imagination of Text: A Novel Framework for Text-to-image  Person Retrieval via Exploring the Power of Words</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09059</p>
  <p><b>作者</b>：Delong Liu,  Haiwen Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve person images, large gallery, gallery that match, textual, abstract textual descriptions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of Text-to-image person retrieval is to retrieve person images from
a large gallery that match the given textual descriptions. The main challenge
of this task lies in the significant differences in information representation
between the visual and textual modalities. The textual modality conveys
abstract and precise information through vocabulary and grammatical structures,
while the visual modality conveys concrete and intuitive information through
images. To fully leverage the expressive power of textual representations, it
is essential to accurately map abstract textual descriptions to specific
images.
To address this issue, we propose a novel framework to Unleash the
Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully
explore the power of words in sentences. Specifically, the framework employs
the pre-trained full CLIP model as a dual encoder for the images and texts ,
taking advantage of prior cross-modal alignment knowledge. The Text-guided
Image Restoration auxiliary task is proposed with the aim of implicitly mapping
abstract textual entities to specific image regions, facilitating alignment
between textual and visual embeddings. Additionally, we introduce a cross-modal
triplet loss tailored for handling hard samples, enhancing the model's ability
to distinguish minor differences.
To focus the model on the key components within sentences, we propose a novel
text data augmentation technique. Our proposed methods achieve state-of-the-art
results on three popular benchmark datasets, and the source code will be made
publicly available shortly.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Longitudinal Data and a Semantic Similarity Reward for Chest X-Ray  Report Generation</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09758</p>
  <p><b>作者</b>：Aaron Nicolson,  Jason Dowling,  Bevan Koopman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Chest X-Ray, approach to improving, improving the efficiency, CXR report generation, CXR interpretation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chest X-Ray (CXR) report generation is a promising approach to improving the
efficiency of CXR interpretation. However, a significant increase in diagnostic
accuracy is required before that can be realised. Motivated by this, we propose
a framework that is more inline with a radiologist's workflow by considering
longitudinal data. Here, the decoder is additionally conditioned on the report
from the subject's previous imaging study via a prompt. We also propose a new
reward for reinforcement learning based on CXR-BERT, which computes the
similarity between reports. We conduct experiments on the MIMIC-CXR dataset.
The results indicate that longitudinal data improves CXR report generation.
CXR-BERT is also shown to be a promising alternative to the current
state-of-the-art reward based on RadGraph. This investigation indicates that
longitudinal CXR report generation can offer a substantial increase in
diagnostic accuracy. Our Hugging Face model is available at:
this https URL and code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Generative Prompt Model for Weakly Supervised Object Localization</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09756</p>
  <p><b>作者</b>：Yuzhong Zhao,  Qixiang Ye,  Weijia Wu,  Chunhua Shen,  Fang Wan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised object localization, learning object localization, Weakly supervised object, object localization, Weakly supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Weakly supervised object localization (WSOL) remains challenging when
learning object localization models from image category labels. Conventional
methods that discriminatively train activation models ignore representative yet
less discriminative object parts. In this study, we propose a generative prompt
model (GenPromp), defining the first generative pipeline to localize less
discriminative object parts by formulating WSOL as a conditional image
denoising procedure. During training, GenPromp converts image category labels
to learnable prompt embeddings which are fed to a generative model to
conditionally recover the input image with noise and learn representative
embeddings. During inference, enPromp combines the representative embeddings
with discriminative embeddings (queried from an off-the-shelf vision-language
model) for both representative and discriminative capacity. The combined
embeddings are finally used to generate multi-scale high-quality attention
maps, which facilitate localizing full object extent. Experiments on
CUB-200-2011 and ILSVRC show that GenPromp respectively outperforms the best
discriminative models by 5.2% and 5.6% (Top-1 Loc), setting a solid baseline
for WSOL with the generative model. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Space Engage: Collaborative Space Supervision for Contrastive-based  Semi-Supervised Semantic Segmentation</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09755</p>
  <p><b>作者</b>：Changqi Wang,  Haoyu Xie,  Yuhui Yuan,  Chong Fu,  Xiangyu Yue</p>
  <p><b>备注</b>：Accepted to ICCV 2023</p>
  <p><b>关键词</b>：Semi-Supervised Semantic Segmentation, limited labeled images, Semantic Segmentation, labeled images, segmentation model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model
with limited labeled images and a substantial volume of unlabeled images. To
improve the robustness of representations, powerful methods introduce a
pixel-wise contrastive learning approach in latent space (i.e., representation
space) that aggregates the representations to their prototypes in a fully
supervised manner. However, previous contrastive-based S4 methods merely rely
on the supervision from the model's output (logits) in logit space during
unlabeled training. In contrast, we utilize the outputs in both logit space and
representation space to obtain supervision in a collaborative way. The
supervision from two spaces plays two roles: 1) reduces the risk of
over-fitting to incorrect semantic information in logits with the help of
representations; 2) enhances the knowledge exchange between the two spaces.
Furthermore, unlike previous approaches, we use the similarity between
representations and prototypes as a new indicator to tilt training those
under-performing representations and achieve a more efficient contrastive
learning process. Results on two public benchmarks demonstrate the competitive
performance of our method compared with state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Towards Robust Scene Text Image Super-resolution via Explicit Location  Enhancement</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09749</p>
  <p><b>作者</b>：Hang Guo,  Tao Dai,  Guanghao Meng,  Shu-Tao Xia</p>
  <p><b>备注</b>：Accepted as IJCAI2023 paper</p>
  <p><b>关键词</b>：improve image quality, achieved great success, recently achieved great, boosting downstream scene, Scene text image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scene text image super-resolution (STISR), aiming to improve image quality
while boosting downstream scene text recognition accuracy, has recently
achieved great success. However, most existing methods treat the foreground
(character regions) and background (non-character regions) equally in the
forward process, and neglect the disturbance from the complex background, thus
limiting the performance. To address these issues, in this paper, we propose a
novel method LEMMA that explicitly models character regions to produce
high-level text-specific guidance for super-resolution. To model the location
of characters effectively, we propose the location enhancement module to
extract character region features based on the attention map sequence. Besides,
we propose the multi-modal alignment module to perform bidirectional
visual-semantic alignment to generate high-quality prior guidance, which is
then incorporated into the super-resolution branch in an adaptive manner using
the proposed adaptive fusion module. Experiments on TextZoom and four scene
text recognition benchmarks demonstrate the superiority of our method over
other state-of-the-art methods. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Watch out Venomous Snake Species: A Solution to SnakeCLEF2023</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09748</p>
  <p><b>作者</b>：Feiran Hu,  Peng Wang,  Yangyang Li,  Chenlong Duan,  Zijian Zhu,  Fei Wang,  Faen Zhang,  Yong Li,  Xiu-Shen Wei</p>
  <p><b>备注</b>：This work was the winner solution of the SnakeCLEF2023 challenge</p>
  <p><b>关键词</b>：snake species identification, competition aims, development of advanced, advanced algorithms, algorithms for snake</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The SnakeCLEF2023 competition aims to the development of advanced algorithms
for snake species identification through the analysis of images and
accompanying metadata. This paper presents a method leveraging utilization of
both images and metadata. Modern CNN models and strong data augmentation are
utilized to learn better representation of images. To relieve the challenge of
long-tailed distribution, seesaw loss is utilized in our method. We also design
a light model to calculate prior probabilities using metadata features
extracted from CLIP in post processing stage. Besides, we attach more
importance to venomous species by assigning venomous species labels to some
examples that model is uncertain about. Our method achieves 91.31% score of the
final metric combined of F1 and other metrics on private leaderboard, which is
the 1st place among the participators. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Improved Distribution Matching for Dataset Condensation</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09742</p>
  <p><b>作者</b>：Ganlong Zhao,  Guanbin Li,  Yipeng Qin,  Yizhou Yu</p>
  <p><b>备注</b>：CVPR2023</p>
  <p><b>关键词</b>：deep learning applications, Dataset Condensation aims, Dataset Condensation, learning applications, maintaining its ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dataset Condensation aims to condense a large dataset into a smaller one
while maintaining its ability to train a well-performing model, thus reducing
the storage cost and training effort in deep learning applications. However,
conventional dataset condensation methods are optimization-oriented and
condense the dataset by performing gradient or parameter matching during model
optimization, which is computationally intensive even on small datasets and
models. In this paper, we propose a novel dataset condensation method based on
distribution matching, which is more efficient and promising. Specifically, we
identify two important shortcomings of naive distribution matching (i.e.,
imbalanced feature numbers and unvalidated embeddings for distance computation)
and address them with three novel techniques (i.e., partitioning and expansion
augmentation, efficient and enriched model sampling, and class-aware
distribution regularization). Our simple yet effective method outperforms most
previous optimization-oriented methods with much fewer computational resources,
thereby scaling data condensation to larger datasets and models. Extensive
experiments demonstrate the effectiveness of our method. Codes are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ClickSeg: 3D Instance Segmentation with Click-Level Weak Annotations</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09732</p>
  <p><b>作者</b>：Leyao Liu,  Tao Kong,  Minzhao Zhu,  Jiashuo Fan,  Lu Fang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require fully-annotated dense, fully-annotated dense labels, costly to obtain, instance segmentation, fully-annotated dense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D instance segmentation methods often require fully-annotated dense labels
for training, which are costly to obtain. In this paper, we present ClickSeg, a
novel click-level weakly supervised 3D instance segmentation method that
requires one point per instance annotation merely. Such a problem is very
challenging due to the extremely limited labels, which has rarely been solved
before. We first develop a baseline weakly-supervised training method, which
generates pseudo labels for unlabeled data by the model itself. To utilize the
property of click-level annotation setting, we further propose a new training
framework. Instead of directly using the model inference way, i.e., mean-shift
clustering, to generate the pseudo labels, we propose to use k-means with fixed
initial seeds: the annotated points. New similarity metrics are further
designed for clustering. Experiments on ScanNetV2 and S3DIS datasets show that
the proposed ClickSeg surpasses the previous best weakly supervised instance
segmentation result by a large margin (e.g., +9.4% mAP on ScanNetV2). Using
0.02% supervision signals merely, ClickSeg achieves $\sim$90% of the accuracy
of the fully-supervised counterpart. Meanwhile, it also achieves
state-of-the-art semantic segmentation results among weakly supervised methods
that use the same annotation settings.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：NTIRE 2023 Quality Assessment of Video Enhancement Challenge</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09729</p>
  <p><b>作者</b>：Xiaohong Liu,  Xiongkuo Min,  Wei Sun,  Yulun Zhang,  Kai Zhang,  Radu Timofte,  Guangtao Zhai,  Yixuan Gao,  Yuqin Cao,  Tengchuan Kou,  Yunlong Dong,  Ziheng Jia,  Yilin Li,  Wei Wu,  Shuming Hu,  Sibin Deng,  Pengxiang Xiao,  Ying Chen,  Kai Li,  Kai Zhao,  Kun Yuan,  Ming Sun,  Heng Cong,  Hao Wang,  Lingzhi Fu,  Yusheng Zhang,  Rongyu Zhang,  Hang Shi,  Qihang Xu,  Longan Xiao,  Zhiliang Ma,  Mirko Agarla,  Luigi Celona,  Claudio Rota,  Raimondo Schettini,  Zhiwei Huang,  Yanan Li,  Xiaotao Wang,  Lei Lei,  Hongye Liu,  Wei Hong,  Ironhead Chuang,  Allen Lin,  Drake Guan,  Iris Chen,  Kae Lou,  Willy Huang,  Yachun Tasi,  Yvonne Kao,  Haotian Fan,  Fangyuan Kong,  Shiqi Zhou,  Hao Liu,  Yu Lai,  Shanshan Chen,  Wenqi Wang,  Haoning Wu,  Chaofeng Chen,  Chunzheng Zhu,  Zekun Guo,  Shiling Zhao,  Haibing Yin,  Hongkui Wang,  Hanene Brachemi Meftah,  et al. (8 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video quality assessment, Trends in Image, Quality Assessment, Perceptual Video Enhancement, Video Enhancement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reports on the NTIRE 2023 Quality Assessment of Video Enhancement
Challenge, which will be held in conjunction with the New Trends in Image
Restoration and Enhancement Workshop (NTIRE) at CVPR 2023. This challenge is to
address a major challenge in the field of video processing, namely, video
quality assessment (VQA) for enhanced videos. The challenge uses the VQA
Dataset for Perceptual Video Enhancement (VDPVE), which has a total of 1211
enhanced videos, including 600 videos with color, brightness, and contrast
enhancements, 310 videos with deblurring, and 301 deshaked videos. The
challenge has a total of 167 registered participants. 61 participating teams
submitted their prediction results during the development phase, with a total
of 3168 submissions. A total of 176 submissions were submitted by 37
participating teams during the final testing phase. Finally, 19 participating
teams submitted their models and fact sheets, and detailed the methods they
used. Some methods have achieved better results than baseline methods, and the
winning methods have demonstrated superior prediction performance.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Uncertainty-Driven Multi-Scale Feature Fusion Network for Real-time  Image Deraining</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09728</p>
  <p><b>作者</b>：Ming Tong,  Xuefeng Yan,  Yongzhen Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rainy weather due, Visual-based measurement systems, existing imaging devices, imaging devices struggle, issue in real-time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual-based measurement systems are frequently affected by rainy weather due
to the degradation caused by rain streaks in captured images, and existing
imaging devices struggle to address this issue in real-time. While most efforts
leverage deep networks for image deraining and have made progress, their large
parameter sizes hinder deployment on resource-constrained devices.
Additionally, these data-driven models often produce deterministic results,
without considering their inherent epistemic uncertainty, which can lead to
undesired reconstruction errors. Well-calibrated uncertainty can help alleviate
prediction errors and assist measurement devices in mitigating risks and
improving usability. Therefore, we propose an Uncertainty-Driven Multi-Scale
Feature Fusion Network (UMFFNet) that learns the probability mapping
distribution between paired images to estimate uncertainty. Specifically, we
introduce an uncertainty feature fusion block (UFFB) that utilizes uncertainty
information to dynamically enhance acquired features and focus on blurry
regions obscured by rain streaks, reducing prediction errors. In addition, to
further boost the performance of UMFFNet, we fused feature information from
multiple scales to guide the network for efficient collaborative rain removal.
Extensive experiments demonstrate that UMFFNet achieves significant performance
improvements with few parameters, surpassing state-of-the-art image deraining
methods.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：SAMConvex: Fast Discrete Optimization for CT Registration using  Self-supervised Anatomical Embedding and Correlation Pyramid</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09727</p>
  <p><b>作者</b>：Zi Li,  Lin Tian,  Tony C. W. Mok,  Xiaoyu Bai,  Puyang Wang,  Jia Ge,  Jingren Zhou,  Le Lu,  Xianghua Ye,  Ke Yan,  Dakai Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Estimating displacement vector, excessive computation burdens, shown great success, suffers excessive computation, cost volume computed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating displacement vector field via a cost volume computed in the
feature space has shown great success in image registration, but it suffers
excessive computation burdens. Moreover, existing feature descriptors only
extract local features incapable of representing the global semantic
information, which is especially important for solving large transformations.
To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine
discrete optimization method for CT registration that includes a decoupled
convex optimization procedure to obtain deformation fields based on a
self-supervised anatomical embedding (SAM) feature extractor that captures both
local and global information. To be specific, SAMConvex extracts per-voxel
features and builds 6D correlation volumes based on SAM features, and
iteratively updates a flow field by performing lookups on the correlation
volumes with a coarse-to-fine scheme. SAMConvex outperforms the
state-of-the-art learning-based methods and optimization-based methods over two
inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one
intra-patient registration dataset (Lung CT). Moreover, as an
optimization-based method, SAMConvex only takes $\sim2$s ($\sim5s$ with
instance optimization) for one paired images.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09724</p>
  <p><b>作者</b>：Kibeom Hong,  Seogkyu Jeon,  Junsoo Lee,  Namhyuk Ahn,  Kunhee Kim,  Pilhyeon Lee,  Daesik Kim,  Youngjung Uh,  Hyeran Byun</p>
  <p><b>备注</b>：Accepted by ICCV 2023. Code is available at this this https URL</p>
  <p><b>关键词</b>：recent studies exploit, attention mechanism owing, style image, attention mechanism, style</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To deliver the artistic expression of the target style, recent studies
exploit the attention mechanism owing to its ability to map the local patches
of the style image to the corresponding patches of the content image. However,
because of the low semantic correspondence between arbitrary content and
artworks, the attention module repeatedly abuses specific local patches from
the style image, resulting in disharmonious and evident repetitive artifacts.
To overcome this limitation and accomplish impeccable artistic style transfer,
we focus on enhancing the attention mechanism and capturing the rhythm of
patterns that organize the style. In this paper, we introduce a novel metric,
namely pattern repeatability, that quantifies the repetition of patterns in the
style image. Based on the pattern repeatability, we propose Aesthetic
Pattern-Aware style transfer Networks (AesPA-Net) that discover the sweet spot
of local and global style expressions. In addition, we propose a novel
self-supervisory task to encourage the attention mechanism to learn precise and
meaningful semantic correspondence. Lastly, we introduce the patch-wise style
loss to transfer the elaborate rhythm of local patterns. Through qualitative
and quantitative evaluations, we verify the reliability of the proposed pattern
repeatability that aligns with human perception, and demonstrate the
superiority of the proposed framework.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Multi-Grained Multimodal Interaction Network for Entity Linking</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09721</p>
  <p><b>作者</b>：Pengfei Luo,  Tong Xu,  Shiwei Wu,  Chen Zhu,  Linli Xu,  Enhong Chen</p>
  <p><b>备注</b>：Accepted by KDD 2023</p>
  <p><b>关键词</b>：attracted wide attention, Multimodal entity linking, multimodal knowledge graph, resolving ambiguous mentions, entity linking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal entity linking (MEL) task, which aims at resolving ambiguous
mentions to a multimodal knowledge graph, has attracted wide attention in
recent years. Though large efforts have been made to explore the complementary
effect among multiple modalities, however, they may fail to fully absorb the
comprehensive expression of abbreviated textual context and implicit visual
indication. Even worse, the inevitable noisy data may cause inconsistency of
different modalities during the learning process, which severely degenerates
the performance. To address the above issues, in this paper, we propose a novel
Multi-GraIned Multimodal InteraCtion Network $\textbf{(MIMIC)}$ framework for
solving the MEL task. Specifically, the unified inputs of mentions and entities
are first encoded by textual/visual encoders separately, to extract global
descriptive features and local detailed features. Then, to derive the
similarity matching score for each mention-entity pair, we device three
interaction units to comprehensively explore the intra-modal interaction and
inter-modal fusion among features of entities and mentions. In particular,
three modules, namely the Text-based Global-Local interaction Unit (TGLU),
Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based
interaction Unit (CMFU) are designed to capture and integrate the fine-grained
representation lying in abbreviated text and implicit visual cues. Afterwards,
we introduce a unit-consistency objective function via contrastive learning to
avoid inconsistency and model degradation. Experimental results on three public
benchmark datasets demonstrate that our solution outperforms various
state-of-the-art baselines, and ablation studies verify the effectiveness of
designed modules.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Semantic-Aware Dual Contrastive Learning for Multi-label Image  Classification</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09715</p>
  <p><b>作者</b>：Leilei Ma,  Dengdi Sun,  Lei Wang,  Haifang Zhao,  Bin Luo</p>
  <p><b>备注</b>：8 pages, 6 figures, accepted by ECAI 23</p>
  <p><b>关键词</b>：confusing label dependencies, Extracting image semantics, effectively and assigning, attributes for natural, complex scene contents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting image semantics effectively and assigning corresponding labels to
multiple objects or attributes for natural images is challenging due to the
complex scene contents and confusing label dependencies. Recent works have
focused on modeling label relationships with graph and understanding object
regions using class activation maps (CAM). However, these methods ignore the
complex intra- and inter-category relationships among specific semantic
features, and CAM is prone to generate noisy information. To this end, we
propose a novel semantic-aware dual contrastive learning framework that
incorporates sample-to-sample contrastive learning (SSCL) as well as
prototype-to-sample contrastive learning (PSCL). Specifically, we leverage
semantic-aware representation learning to extract category-related local
discriminative features and construct category prototypes. Then based on SSCL,
label-level visual representations of the same category are aggregated
together, and features belonging to distinct categories are separated.
Meanwhile, we construct a novel PSCL module to narrow the distance between
positive samples and category prototypes and push negative samples away from
the corresponding category prototypes. Finally, the discriminative label-level
features related to the image content are accurately captured by the joint
training of the above three parts. Experiments on five challenging large-scale
public datasets demonstrate that our proposed method is effective and
outperforms the state-of-the-art methods. Code and supplementary materials are
released on this https URL.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Towards Saner Deep Image Registration</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09696</p>
  <p><b>作者</b>：Bin Duan,  Ming Zhong,  Yan Yan</p>
  <p><b>备注</b>：ICCV 2023</p>
  <p><b>关键词</b>：deep-learning architectures, traditional counterparts, inference time, recent advances, advances in computing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With recent advances in computing hardware and surges of deep-learning
architectures, learning-based deep image registration methods have surpassed
their traditional counterparts, in terms of metric performance and inference
time. However, these methods focus on improving performance measurements such
as Dice, resulting in less attention given to model behaviors that are equally
desirable for registrations, especially for medical imaging. This paper
investigates these behaviors for popular learning-based deep registrations
under a sanity-checking microscope. We find that most existing registrations
suffer from low inverse consistency and nondiscrimination of identical pairs
due to overly optimized image similarities. To rectify these behaviors, we
propose a novel regularization-based sanity-enforcer method that imposes two
sanity checks on the deep model to reduce its inverse consistency errors and
increase its discriminative power simultaneously. Moreover, we derive a set of
theoretical guarantees for our sanity-checked image registration method, with
experimental results supporting our theoretical findings and their
effectiveness in increasing the sanity of models without sacrificing any
performance. Our code and models are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：GlobalMapper: Arbitrary-Shaped Urban Layout Generation</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09693</p>
  <p><b>作者</b>：Liu He,  Daniel Aliaga</p>
  <p><b>备注</b>：Accepted by ICCV 2023</p>
  <p><b>关键词</b>：computer vision, computer graphics, Modeling and designing, significant interest, arbitrary city block</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling and designing urban building layouts is of significant interest in
computer vision, computer graphics, and urban applications. A building layout
consists of a set of buildings in city blocks defined by a network of roads. We
observe that building layouts are discrete structures, consisting of multiple
rows of buildings of various shapes, and are amenable to skeletonization for
mapping arbitrary city block shapes to a canonical form. Hence, we propose a
fully automatic approach to building layout generation using graph attention
networks. Our method generates realistic urban layouts given arbitrary road
networks, and enables conditional generation based on learned priors. Our
results, including user study, demonstrate superior performance as compared to
prior layout generation networks, support arbitrary city block and varying
building shapes as demonstrated by generating layouts for 28 large cities.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Domain Adaptation for Enhanced Object Detection in Foggy and Rainy  Weather for Autonomous Driving</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09676</p>
  <p><b>作者</b>：Jinlong Li,  Runsheng Xu,  Jin Ma,  Qin Zou,  Jiaqi Ma,  Hongkai Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autonomous driving, object detection, autonomous, detection, domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most object detection models for autonomous driving may experience a
significant drop in performance when deployed in real-world applications, due
to the well-known domain shift issue. Supervised object detection methods for
autonomous driving usually assume a consistent feature distribution between
training and testing data, however, such assumptions may not always be the case
when weather conditions differ significantly. For example, an object detection
model trained under clear weather may not perform well in foggy or rainy
weather, due to the domain gap. Overcoming detection bottlenecks in foggy or
rainy weather scenarios is a significant challenge for autonomous vehicles
deployed in the wild. To address the domain gap in different weather
conditions, This paper proposes a novel domain adaptive object detection
framework for autonomous driving in foggy and rainy weather. Our method
leverages both image-level and object-level adaptation to reduce the domain
discrepancy in image style and object appearance. Additionally, to enhance the
model's performance under challenging samples, we introduce a new adversarial
gradient reversal layer that performs adversarial mining on hard examples
alongside domain adaptation. Moreover, we propose to generate an auxiliary
domain by data augmentation to enforce a new domain-level metric
regularization. Experimental results on public benchmarks demonstrate that
object detection performance is significantly improved when using our proposed
method in domain shift scenarios for autonomous driving applications.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Object-aware Gaze Target Detection</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09662</p>
  <p><b>作者</b>：Francesco Tonini,  Nicola Dall'Asen,  Cigdem Beyan,  Elisa Ricci</p>
  <p><b>备注</b>：Accepted to ICCV 2023</p>
  <p><b>关键词</b>：Gaze target detection, target detection aims, Gaze target, Gaze, aims to predict</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gaze target detection aims to predict the image location where the person is
looking and the probability that a gaze is out of the scene. Several works have
tackled this task by regressing a gaze heatmap centered on the gaze location,
however, they overlooked decoding the relationship between the people and the
gazed objects. This paper proposes a Transformer-based architecture that
automatically detects objects (including heads) in the scene to build
associations between every head and the gazed-head/object, resulting in a
comprehensive, explainable gaze analysis composed of: gaze target area, gaze
pixel point, the class and the image location of the gazed-object. Upon
evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art
results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze
distance, and 9% gain in out-of-frame average precision) for gaze target
detection and 11-13% improvement in average precision for the classification
and the localization of the gazed-objects. The code of the proposed method is
available this https URL</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Skin Lesion Correspondence Localization in Total Body Photography</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09642</p>
  <p><b>作者</b>：Wei-Lun Huang,  Davood Tashayyod,  Jun Kang,  Amir Gandjbakhche,  Michael Kazhdan,  Mehran Armand</p>
  <p><b>备注</b>：MICCAI-2023</p>
  <p><b>关键词</b>：detection of melanoma, early detection, skin lesion correspondence, skin lesions, finding correspondence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Longitudinal tracking of skin lesions - finding correspondence, changes in
morphology, and texture - is beneficial to the early detection of melanoma.
However, it has not been well investigated in the context of full-body imaging.
We propose a novel framework combining geometric and texture information to
localize skin lesion correspondence from a source scan to a target scan in
total body photography (TBP). Body landmarks or sparse correspondence are first
created on the source and target 3D textured meshes. Every vertex on each of
the meshes is then mapped to a feature vector characterizing the geodesic
distances to the landmarks on that mesh. Then, for each lesion of interest
(LOI) on the source, its corresponding location on the target is first coarsely
estimated using the geometric information encoded in the feature vectors and
then refined using the texture information. We evaluated the framework
quantitatively on both a public and a private dataset, for which our success
rates (at 10 mm criterion) are comparable to the only reported longitudinal
study. As full-body 3D capture becomes more prevalent and has higher quality,
we expect the proposed method to constitute a valuable step in the longitudinal
tracking of skin lesions.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Traffic-Domain Video Question Answering with Automatic Captioning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09636</p>
  <p><b>作者</b>：Ehsan Qasemi,  Jonathan M. Francis,  Alessandro Oltramari</p>
  <p><b>备注</b>：Accepted in ITSC2023</p>
  <p><b>关键词</b>：facilitating advanced machine, advanced machine reasoning, machine reasoning capabilities, Intelligent Traffic Monitoring, Intelligent Transportation Systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video Question Answering (VidQA) exhibits remarkable potential in
facilitating advanced machine reasoning capabilities within the domains of
Intelligent Traffic Monitoring and Intelligent Transportation Systems.
Nevertheless, the integration of urban traffic scene knowledge into VidQA
systems has received limited attention in previous research endeavors. In this
work, we present a novel approach termed Traffic-domain Video Question
Answering with Automatic Captioning (TRIVIA), which serves as a
weak-supervision technique for infusing traffic-domain knowledge into large
video-language models. Empirical findings obtained from the SUTD-TrafficQA task
highlight the substantial enhancements achieved by TRIVIA, elevating the
accuracy of representative video-language models by a remarkable 6.5 points
(19.88%) compared to baseline settings. This pioneering methodology holds great
promise for driving advancements in the field, inspiring researchers and
practitioners alike to unlock the full potential of emerging video-language
models in traffic-related applications.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Conditional 360-degree Image Synthesis for Immersive Indoor Scene  Decoration</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09621</p>
  <p><b>作者</b>：Ka Chun Shum,  Hong-Wing Pang,  Binh-Son Hua,  Duc Thanh Nguyen,  Sai-Kit Yeung</p>
  <p><b>备注</b>：ICCV2023</p>
  <p><b>关键词</b>：address the problem, problem of conditional, scene, conditional scene decoration, object layout</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we address the problem of conditional scene decoration for
360-degree images. Our method takes a 360-degree background photograph of an
indoor scene and generates decorated images of the same scene in the panorama
view. To do this, we develop a 360-aware object layout generator that learns
latent object vectors in the 360-degree view to enable a variety of furniture
arrangements for an input 360-degree background image. We use this object
layout to condition a generative adversarial network to synthesize images of an
input scene. To further reinforce the generation capability of our model, we
develop a simple yet effective scene emptier that removes the generated
furniture and produces an emptied scene for our model to learn a cyclic
constraint. We train the model on the Structure3D dataset and show that our
model can generate diverse decorations with controllable object layout. Our
method achieves state-of-the-art performance on the Structure3D dataset and
generalizes well to the Zillow indoor scene dataset. Our user study confirms
the immersive experiences provided by the realistic image quality and furniture
layout in our generation results. Our implementation will be made available.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Looking deeper into interpretable deep learning in neuroimaging: a  comprehensive survey</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09615</p>
  <p><b>作者</b>：Md. Mahfuzur Rahman,  Vince D. Calhoun,  Sergey M. Plis</p>
  <p><b>备注</b>：109 pages, 21 figures</p>
  <p><b>关键词</b>：feature extraction phase, separate error-prone feature, error-prone feature extraction, deep learning models, alleviating the concern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) models have been popular due to their ability to learn
directly from the raw data in an end-to-end paradigm, alleviating the concern
of a separate error-prone feature extraction phase. Recent DL-based
neuroimaging studies have also witnessed a noticeable performance advancement
over traditional machine learning algorithms. But the challenges of deep
learning models still exist because of the lack of transparency in these models
for their successful deployment in real-world applications. In recent years,
Explainable AI (XAI) has undergone a surge of developments mainly to get
intuitions of how the models reached the decisions, which is essential for
safety-critical domains such as healthcare, finance, and law enforcement
agencies. While the interpretability domain is advancing noticeably,
researchers are still unclear about what aspect of model learning a post hoc
method reveals and how to validate its reliability. This paper comprehensively
reviews interpretable deep learning models in the neuroimaging domain. Firstly,
we summarize the current status of interpretability resources in general,
focusing on the progression of methods, associated challenges, and opinions.
Secondly, we discuss how multiple recent neuroimaging studies leveraged model
interpretability to capture anatomical and functional brain alterations most
relevant to model predictions. Finally, we discuss the limitations of the
current practices and offer some valuable insights and guidance on how we can
steer our future research directions to make deep learning models substantially
interpretable and thus advance scientific understanding of brain disorders.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：DenseMP: Unsupervised Dense Pre-training for Few-shot Medical Image  Segmentation</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09604</p>
  <p><b>作者</b>：Zhaoxin Fan,  Puquan Pan,  Zeren Zhang,  Ce Chen,  Tianyang Wang,  Siyang Zheng,  Min Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image analysis, Few-shot medical image, medical image semantic, medical image, Medical Image Segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot medical image semantic segmentation is of paramount importance in
the domain of medical image analysis. However, existing methodologies grapple
with the challenge of data scarcity during the training phase, leading to
over-fitting. To mitigate this issue, we introduce a novel Unsupervised Dense
Few-shot Medical Image Segmentation Model Training Pipeline (DenseMP) that
capitalizes on unsupervised dense pre-training. DenseMP is composed of two
distinct stages: (1) segmentation-aware dense contrastive pre-training, and (2)
few-shot-aware superpixel guided dense pre-training. These stages
collaboratively yield a pre-trained initial model specifically designed for
few-shot medical image segmentation, which can subsequently be fine-tuned on
the target dataset. Our proposed pipeline significantly enhances the
performance of the widely recognized few-shot segmentation model, PA-Net,
achieving state-of-the-art results on the Abd-CT and Abd-MRI datasets. Code
will be released after acceptance.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Gradient strikes back: How filtering out high frequencies improves  explanations</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09591</p>
  <p><b>作者</b>：Sabine Muzellec,  Leo Andeol,  Thomas Fel,  Rufin VanRullen,  Thomas Serre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supplanting older gradient-based, deep neural networks, methods, gradient-based methods, Recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed an explosion in the development of novel
prediction-based attribution methods, which have slowly been supplanting older
gradient-based methods to explain the decisions of deep neural networks.
However, it is still not clear why prediction-based methods outperform
gradient-based ones. Here, we start with an empirical observation: these two
approaches yield attribution maps with very different power spectra, with
gradient-based methods revealing more high-frequency content than
prediction-based methods. This observation raises multiple questions: What is
the source of this high-frequency information, and does it truly reflect
decisions made by the system? Lastly, why would the absence of high-frequency
information in prediction-based methods yield better explainability scores
along multiple metrics? We analyze the gradient of three representative visual
classification models and observe that it contains noisy information emanating
from high-frequencies. Furthermore, our analysis reveals that the operations
used in Convolutional Neural Networks (CNNs) for downsampling appear to be a
significant source of this high-frequency content -- suggesting aliasing as a
possible underlying basis. We then apply an optimal low-pass filter for
attribution maps and demonstrate that it improves gradient-based attribution
methods. We show that (i) removing high-frequency noise yields significant
improvements in the explainability scores obtained with gradient-based methods
across multiple models -- leading to (ii) a novel ranking of state-of-the-art
methods with gradient-based methods at the top. We believe that our results
will spur renewed interest in simpler and computationally more efficient
gradient-based methods for explainability.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Automating Wood Species Detection and Classification in Microscopic  Images of Fibrous Materials with Deep Learning</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09588</p>
  <p><b>作者</b>：Lars Nieradzik,  Jördis Sieburg-Rockel,  Stephanie Helmling,  Janis Keuper,  Thomas Weibel,  Andrea Olbrich,  Henrike Stephani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large image dataset, generate image data, macerated wood references, systematic generation, dataset of macerated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We have developed a methodology for the systematic generation of a large
image dataset of macerated wood references, which we used to generate image
data for nine hardwood genera. This is the basis for a substantial approach to
automate, for the first time, the identification of hardwood species in
microscopic images of fibrous materials by deep learning. Our methodology
includes a flexible pipeline for easy annotation of vessel elements. We compare
the performance of different neural network architectures and hyperparameters.
Our proposed method performs similarly well to human experts. In the future,
this will improve controls on global wood fiber product flows to protect
forests.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Guided Linear Upsampling</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09582</p>
  <p><b>作者</b>：Shuangbing Song,  Fan Zhong,  Tianju Wang,  Xueying Qin,  Changhe Tu</p>
  <p><b>备注</b>：ACM SIGGRAPH</p>
  <p><b>关键词</b>：effective guided upsampling, approach for accelerating, Guided upsampling, effective approach, guided upsampling method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Guided upsampling is an effective approach for accelerating high-resolution
image processing. In this paper, we propose a simple yet effective guided
upsampling method. Each pixel in the high-resolution image is represented as a
linear interpolation of two low-resolution pixels, whose indices and weights
are optimized to minimize the upsampling error. The downsampling can be jointly
optimized in order to prevent missing small isolated regions. Our method can be
derived from the color line model and local color transformations. Compared to
previous methods, our method can better preserve detail effects while
suppressing artifacts such as bleeding and blurring. It is efficient, easy to
implement, and free of sensitive parameters. We evaluate the proposed method
with a wide range of image operators, and show its advantages through
quantitative and qualitative analysis. We demonstrate the advantages of our
method for both interactive image editing and real-time high-resolution video
processing. In particular, for interactive editing, the joint optimization can
be precomputed, thus allowing for instant feedback without hardware
acceleration.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Rethinking Intersection Over Union for Small Object Detection in  Few-Shot Regime</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09562</p>
  <p><b>作者</b>：Pierre Le Jeune,  Anissa Mokraoui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extremely difficult, small objects, SIoU, detecting small objects, small</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Few-Shot Object Detection (FSOD), detecting small objects is extremely
difficult. The limited supervision cripples the localization capabilities of
the models and a few pixels shift can dramatically reduce the Intersection over
Union (IoU) between the ground truth and predicted boxes for small objects. To
this end, we propose Scale-adaptive Intersection over Union (SIoU), a novel box
similarity measure. SIoU changes with the objects' size, it is more lenient
with small object shifts. We conducted a user study and SIoU better aligns than
IoU with human judgment. Employing SIoU as an evaluation criterion helps to
build more user-oriented models. SIoU can also be used as a loss function to
prioritize small objects during training, outperforming existing loss
functions. SIoU improves small object detection in the non-few-shot regime, but
this setting is unrealistic in the industry as annotated detection datasets are
often too expensive to acquire. Hence, our experiments mainly focus on the
few-shot regime to demonstrate the superiority and versatility of SIoU loss.
SIoU improves significantly FSOD performance on small objects in both natural
(Pascal VOC and COCO datasets) and aerial images (DOTA and DIOR). In aerial
imagery, small objects are critical and SIoU loss achieves new state-of-the-art
FSOD on DOTA and DIOR.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Transient Neural Radiance Fields for Lidar View Synthesis and 3D  Reconstruction</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09555</p>
  <p><b>作者</b>：Anagh Malik,  Parsa Mirdehghan,  Sotiris Nousias,  Kiriakos N. Kutulakos,  David B. Lindell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural radiance fields, modeling scene appearance, Neural radiance, radiance fields, ubiquitous tool</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural radiance fields (NeRFs) have become a ubiquitous tool for modeling
scene appearance and geometry from multiview imagery. Recent work has also
begun to explore how to use additional supervision from lidar or depth sensor
measurements in the NeRF framework. However, previous lidar-supervised NeRFs
focus on rendering conventional camera imagery and use lidar-derived point
cloud data as auxiliary supervision; thus, they fail to incorporate the
underlying image formation model of the lidar. Here, we propose a novel method
for rendering transient NeRFs that take as input the raw, time-resolved photon
count histograms measured by a single-photon lidar system, and we seek to
render such histograms from novel views. Different from conventional NeRFs, the
approach relies on a time-resolved version of the volume rendering equation to
render the lidar measurements and capture transient light transport phenomena
at picosecond timescales. We evaluate our method on a first-of-its-kind dataset
of simulated and captured transient multiview scans from a prototype
single-photon lidar. Overall, our work brings NeRFs to a new dimension of
imaging at transient timescales, newly enabling rendering of transient imagery
from novel views. Additionally, we show that our approach recovers improved
geometry and conventional appearance compared to point cloud-based supervision
when training on few input viewpoints. Transient NeRFs may be especially useful
for applications which seek to simulate raw lidar measurements for downstream
tasks in autonomous driving, robotics, and remote sensing.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Surgical Action Triplet Detection by Mixed Supervised Learning of  Instrument-Tissue Interactions</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09548</p>
  <p><b>作者</b>：Saurav Sharma,  Chinedu Innocent Nwoye,  Didier Mutter,  Nicolas Padoy</p>
  <p><b>备注</b>：Accepted at MICCAI, 2023. Project Page: this https URL</p>
  <p><b>关键词</b>：surgical action triplet, surgical scene activities, Surgical action, action triplets describe, triplets describe instrument-tissue</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surgical action triplets describe instrument-tissue interactions as
(instrument, verb, target) combinations, thereby supporting a detailed analysis
of surgical scene activities and workflow. This work focuses on surgical action
triplet detection, which is challenging but more precise than the traditional
triplet recognition task as it consists of joint (1) localization of surgical
instruments and (2) recognition of the surgical action triplet associated with
every localized instrument. Triplet detection is highly complex due to the lack
of spatial triplet annotation. We analyze how the amount of instrument spatial
annotations affects triplet detection and observe that accurate instrument
localization does not guarantee better triplet detection due to the risk of
erroneous associations with the verbs and targets. To solve the two tasks, we
propose MCIT-IG, a two-stage network, that stands for Multi-Class
Instrument-aware Transformer-Interaction Graph. The MCIT stage of our network
models per class embedding of the targets as additional features to reduce the
risk of misassociating triplets. Furthermore, the IG stage constructs a
bipartite dynamic graph to model the interaction between the instruments and
targets, cast as the verbs. We utilize a mixed-supervised learning strategy
that combines weak target presence labels for MCIT and pseudo triplet labels
for IG to train our network. We observed that complementing minimal instrument
spatial annotations with target embeddings results in better triplet detection.
We evaluate our model on the CholecT50 dataset and show improved performance on
both instrument localization and triplet detection, topping the leaderboard of
the CholecTriplet challenge in MICCAI 2022.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Can Neural Network Memorization Be Localized?</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09542</p>
  <p><b>作者</b>：Pratyush Maini,  Michael C. Mozer,  Hanie Sedghi,  Zachary C. Lipton,  J. Zico Kolter,  Chiyuan Zhang</p>
  <p><b>备注</b>：Accepted at ICML 2023</p>
  <p><b>关键词</b>：deep overparametrized networks, textit, overparametrized networks, neural networks, Recent efforts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent efforts at explaining the interplay of memorization and generalization
in deep overparametrized networks have posited that neural networks
$\textit{memorize}$ "hard" examples in the final few layers of the model.
Memorization refers to the ability to correctly predict on $\textit{atypical}$
examples of the training set. In this work, we show that rather than being
confined to individual layers, memorization is a phenomenon confined to a small
set of neurons in various layers of the model. First, via three experimental
sources of converging evidence, we find that most layers are redundant for the
memorization of examples and the layers that contribute to example memorization
are, in general, not the final layers. The three sources are $\textit{gradient
accounting}$ (measuring the contribution to the gradient norms from memorized
and clean examples), $\textit{layer rewinding}$ (replacing specific model
weights of a converged model with previous training checkpoints), and
$\textit{retraining}$ (training rewound layers only on clean examples). Second,
we ask a more generic question: can memorization be localized
$\textit{anywhere}$ in a model? We discover that memorization is often confined
to a small number of neurons or channels (around 5) of the model. Based on
these insights we propose a new form of dropout -- $\textit{example-tied
dropout}$ that enables us to direct the memorization of examples to an apriori
determined set of neurons. By dropping out these neurons, we are able to reduce
the accuracy on memorized examples from $100\%\to3\%$, while also reducing the
generalization gap.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Adversarial Bayesian Augmentation for Single-Source Domain  Generalization</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09520</p>
  <p><b>作者</b>：Sheng Cheng,  Tejas Gokhale,  Yezhou Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inaccessible target data, problem primarily due, challenging problem primarily, inaccessible target, diverse training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalizing to unseen image domains is a challenging problem primarily due
to the lack of diverse training data, inaccessible target data, and the large
domain shift that may exist in many real-world settings. As such data
augmentation is a critical component of domain generalization methods that seek
to address this problem. We present Adversarial Bayesian Augmentation (ABA), a
novel algorithm that learns to generate image augmentations in the challenging
single-source domain generalization setting. ABA draws on the strengths of
adversarial learning and Bayesian neural networks to guide the generation of
diverse data augmentations -- these synthesized image domains aid the
classifier in generalizing to unseen domains. We demonstrate the strength of
ABA on several types of domain shift including style shift, subpopulation
shift, and shift in the medical imaging setting. ABA outperforms all previous
state-of-the-art methods, including pre-specified augmentations, pixel-based
and convolutional-based augmentations.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Make-A-Volume: Leveraging Latent Diffusion Models for Cross-Modality 3D  Brain MRI Synthesis</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10094</p>
  <p><b>作者</b>：Lingting Zhu,  Zeyue Xue,  Zhenchao Jin,  Xian Liu,  Jingzhen He,  Ziwei Liu,  Lequan Yu</p>
  <p><b>备注</b>：Accepted by International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023). 10 pages, 4 figures</p>
  <p><b>关键词</b>：facilitate numerous applications, medical image synthesis, medical imaging field, image synthesis, medical image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-modality medical image synthesis is a critical topic and has the
potential to facilitate numerous applications in the medical imaging field.
Despite recent successes in deep-learning-based generative models, most current
medical image synthesis methods rely on generative adversarial networks and
suffer from notorious mode collapse and unstable training. Moreover, the 2D
backbone-driven approaches would easily result in volumetric inconsistency,
while 3D backbones are challenging and impractical due to the tremendous memory
cost and training difficulty. In this paper, we introduce a new paradigm for
volumetric medical data synthesis by leveraging 2D backbones and present a
diffusion-based framework, Make-A-Volume, for cross-modality 3D medical image
synthesis. To learn the cross-modality slice-wise mapping, we employ a latent
diffusion model and learn a low-dimensional latent space, resulting in high
computational efficiency. To enable the 3D image synthesis and mitigate
volumetric inconsistency, we further insert a series of volumetric layers in
the 2D slice-mapping model and fine-tune them with paired 3D data. This
paradigm extends the 2D image diffusion model to a volumetric version with a
slightly increasing number of parameters and computation, offering a principled
solution for generic cross-modality 3D medical image synthesis. We showcase the
effectiveness of our Make-A-Volume framework on an in-house SWI-MRA brain MRI
dataset and a public T1-T2 brain MRI dataset. Experimental results demonstrate
that our framework achieves superior synthesis results with volumetric
consistency.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Cryo-forum: A framework for orientation recovery with uncertainty  measure with the application in cryo-EM image analysis</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09847</p>
  <p><b>作者</b>：Szu-Chi Chung</p>
  <p><b>备注</b>：27 pages, 9 figures</p>
  <p><b>关键词</b>：single-particle cryo-electron microscopy, projection images poses, cryo-electron microscopy, crucial for reconstructing, single-particle cryo-electron</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In single-particle cryo-electron microscopy (cryo-EM), the efficient
determination of orientation parameters for 2D projection images poses a
significant challenge yet is crucial for reconstructing 3D structures. This
task is complicated by the high noise levels present in the cryo-EM datasets,
which often include outliers, necessitating several time-consuming 2D clean-up
processes. Recently, solutions based on deep learning have emerged, offering a
more streamlined approach to the traditionally laborious task of orientation
estimation. These solutions often employ amortized inference, eliminating the
need to estimate parameters individually for each image. However, these methods
frequently overlook the presence of outliers and may not adequately concentrate
on the components used within the network. This paper introduces a novel
approach that uses a 10-dimensional feature vector to represent the orientation
and applies a Quadratically-Constrained Quadratic Program to derive the
predicted orientation as a unit quaternion, supplemented by an uncertainty
metric. Furthermore, we propose a unique loss function that considers the
pairwise distances between orientations, thereby enhancing the accuracy of our
method. Finally, we also comprehensively evaluate the design choices involved
in constructing the encoder network, a topic that has not received sufficient
attention in the literature. Our numerical analysis demonstrates that our
methodology effectively recovers orientations from 2D cryo-EM images in an
end-to-end manner. Importantly, the inclusion of uncertainty quantification
allows for direct clean-up of the dataset at the 3D level. Lastly, we package
our proposed methods into a user-friendly software suite named cryo-forum,
designed for easy accessibility by the developers.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Compressive Image Scanning Microscope</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09841</p>
  <p><b>作者</b>：Ajay Gunalan,  Marco Castello,  Simonluca Piazza,  Shunlei Li,  Alberto Diaspro,  Leonardo S. Mattos,  Paolo Bianchini</p>
  <p><b>备注</b>：Presented in ISCS23</p>
  <p><b>关键词</b>：laser scanning microscopes, single-photon avalanche diode, image scanning microscopy, implement compressive sensing, scanning microscopes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel approach to implement compressive sensing in laser
scanning microscopes (LSM), specifically in image scanning microscopy (ISM),
using a single-photon avalanche diode (SPAD) array detector. Our method
addresses two significant limitations in applying compressive sensing to LSM:
the time to compute the sampling matrix and the quality of reconstructed
images. We employ a fixed sampling strategy, skipping alternate rows and
columns during data acquisition, which reduces the number of points scanned by
a factor of four and eliminates the need to compute different sampling
matrices. By exploiting the parallel images generated by the SPAD array, we
improve the quality of the reconstructed compressive-ISM images compared to
standard compressive confocal LSM images. Our results demonstrate the
effectiveness of our approach in producing higher-quality images with reduced
data acquisition time and potential benefits in reducing photobleaching.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Multi-modal Learning based Prediction for Disease</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09823</p>
  <p><b>作者</b>：Yaran Chen,  Xueyu Chen,  Yu Han,  Haoran Li,  Dongbin Zhao,  Jingzhong Li,  Xu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fatty liver disease, chronic liver disease, prevent advanced fibrosis, alcoholic fatty liver, liver disease</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non alcoholic fatty liver disease (NAFLD) is the most common cause of chronic
liver disease, which can be predicted accurately to prevent advanced fibrosis
and cirrhosis. While, a liver biopsy, the gold standard for NAFLD diagnosis, is
invasive, expensive, and prone to sampling errors. Therefore, non-invasive
studies are extremely promising, yet they are still in their infancy due to the
lack of comprehensive research data and intelligent methods for multi-modal
data. This paper proposes a NAFLD diagnosis system (DeepFLDDiag) combining a
comprehensive clinical dataset (FLDData) and a multi-modal learning based NAFLD
prediction method (DeepFLD). The dataset includes over 6000 participants
physical examinations, laboratory and imaging studies, extensive
questionnaires, and facial images of partial participants, which is
comprehensive and valuable for clinical studies. From the dataset, we
quantitatively analyze and select clinical metadata that most contribute to
NAFLD prediction. Furthermore, the proposed DeepFLD, a deep neural network
model designed to predict NAFLD using multi-modal input, including metadata and
facial images, outperforms the approach that only uses metadata. Satisfactory
performance is also verified on other unseen datasets. Inspiringly, DeepFLD can
achieve competitive results using only facial images as input rather than
metadata, paving the way for a more robust and simpler non-invasive NAFLD
diagnosis.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Deep unrolling Shrinkage Network for Dynamic MR imaging</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09818</p>
  <p><b>作者</b>：Yinghao Zhang,  Xiaodi Li,  Weihang Li,  Yue Hu</p>
  <p><b>备注</b>：5 pages,3 figures,2 tables</p>
  <p><b>关键词</b>：achieved great success, utilize sparsity priors, dynamic magnetic resonance, sparsity priors, magnetic resonance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep unrolling networks that utilize sparsity priors have achieved great
success in dynamic magnetic resonance (MR) imaging. The convolutional neural
network (CNN) is usually utilized to extract the transformed domain, and then
the soft thresholding (ST) operator is applied to the CNN-transformed data to
enforce the sparsity priors. However, the ST operator is usually constrained to
be the same across all channels of the CNN-transformed data. In this paper, we
propose a novel operator, called soft thresholding with channel attention
(AST), that learns the threshold for each channel. In particular, we put
forward a novel deep unrolling shrinkage network (DUS-Net) by unrolling the
alternating direction method of multipliers (ADMM) for optimizing the
transformed $l_1$ norm dynamic MR reconstruction model. Experimental results on
an open-access dynamic cine MR dataset demonstrate that the proposed DUS-Net
outperforms the state-of-the-art methods. The source code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：DiffDP: Radiotherapy Dose Prediction via a Diffusion Model</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09794</p>
  <p><b>作者</b>：Zhenghao Feng,  Lu Wen,  Peng Wang,  Binyu Yan,  Xi Wu,  Jiliu Zhou,  Yan Wang</p>
  <p><b>备注</b>：to be published in MICCAI 2023</p>
  <p><b>关键词</b>：dose distribution, deep learning, enhancing its efficiency, efficiency and quality, achieved the automatic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Currently, deep learning (DL) has achieved the automatic prediction of dose
distribution in radiotherapy planning, enhancing its efficiency and quality.
However, existing methods suffer from the over-smoothing problem for their
commonly used L_1 or L_2 loss with posterior average calculations. To alleviate
this limitation, we innovatively introduce a diffusion-based dose prediction
(DiffDP) model for predicting the radiotherapy dose distribution of cancer
patients. Specifically, the DiffDP model contains a forward process and a
reverse process. In the forward process, DiffDP gradually transforms dose
distribution maps into Gaussian noise by adding small noise and trains a noise
predictor to predict the noise added in each timestep. In the reverse process,
it removes the noise from the original Gaussian noise in multiple steps with
the well-trained noise predictor and finally outputs the predicted dose
distribution map. To ensure the accuracy of the prediction, we further design a
structure encoder to extract anatomical information from patient anatomy images
and enable the noise predictor to be aware of the dose constraints within
several essential organs, i.e., the planning target volume and organs at risk.
Extensive experiments on an in-house dataset with 130 rectum cancer patients
demonstrate the s</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital  Pathology</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09570</p>
  <p><b>作者</b>：Jingwei Zhang,  Ke Ma,  Saarthak Kapse,  Joel Saltz,  Maria Vakalopoulou,  Prateek Prasanna,  Dimitris Samaras</p>
  <p><b>备注</b>：Submitted to MedAGI 2023</p>
  <p><b>关键词</b>：SAM, pathological entities, entities have crucial, crucial clinical, pathology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic segmentations of pathological entities have crucial clinical value
in computational pathology workflows. Foundation models, such as the Segment
Anything Model (SAM), have been recently proposed for universal use in
segmentation tasks. SAM shows remarkable promise in instance segmentation on
natural images. However, the applicability of SAM to computational pathology
tasks is limited due to the following factors: (1) lack of comprehensive
pathology datasets used in SAM training and (2) the design of SAM is not
inherently optimized for semantic segmentation tasks. In this work, we adapt
SAM for semantic segmentation by introducing trainable class prompts, followed
by further enhancements through the incorporation of a pathology encoder,
specifically a pathology foundation model. Our framework, SAM-Path enhances
SAM's ability to conduct semantic segmentation in digital pathology without
human input prompts. Through experiments on two public pathology datasets, the
BCSS and the CRAG datasets, we demonstrate that the fine-tuning with trainable
class prompts outperforms vanilla SAM with manual prompts and post-processing
by 27.52% in Dice score and 71.63% in IOU. On these two datasets, the proposed
additional pathology foundation model further achieves a relative improvement
of 5.07% to 5.12% in Dice score and 4.50% to 8.48% in IOU.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：AnyDoor: Zero-shot Object-level Image Customization</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09481</p>
  <p><b>作者</b>：Xi Chen,  Lianghua Huang,  Yu Liu,  Yujun Shen,  Deli Zhao,  Hengshuang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work presents AnyDoor, diffusion-based image generator, teleport target objects, presents AnyDoor, work presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents AnyDoor, a diffusion-based image generator with the power
to teleport target objects to new scenes at user-specified locations in a
harmonious way. Instead of tuning parameters for each object, our model is
trained only once and effortlessly generalizes to diverse object-scene
combinations at the inference stage. Such a challenging zero-shot setting
requires an adequate characterization of a certain object. To this end, we
complement the commonly used identity feature with detail features, which are
carefully designed to maintain texture details yet allow versatile local
variations (e.g., lighting, orientation, posture, etc.), supporting the object
in favorably blending with different surroundings. We further propose to borrow
knowledge from video datasets, where we can observe various forms (i.e., along
the time axis) of a single object, leading to stronger model generalizability
and robustness. Extensive experiments demonstrate the superiority of our
approach over existing alternatives as well as its great potential in
real-world applications, such as virtual try-on and object moving. Project page
is this https URL.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：FACTS: Facial Animation Creation using the Transfer of Styles</b></summary>
  <p><b>编号</b>：[323]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09480</p>
  <p><b>作者</b>：Jack Saunders,  Steven Caulkin,  Vinay Namboodiri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：creating believable characters, forms of entertainment, ability to accurately, critical aspect, aspect of creating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to accurately capture and express emotions is a critical aspect
of creating believable characters in video games and other forms of
entertainment. Traditionally, this animation has been achieved with artistic
effort or performance capture, both requiring costs in time and labor. More
recently, audio-driven models have seen success, however, these often lack
expressiveness in areas not correlated to the audio signal. In this paper, we
present a novel approach to facial animation by taking existing animations and
allowing for the modification of style characteristics. Specifically, we
explore the use of a StarGAN to enable the conversion of 3D facial animations
into different emotions and person-specific styles. We are able to maintain the
lip-sync of the animations with this method thanks to the use of a novel
viseme-preserving loss.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring  Instruction Tuning</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09474</p>
  <p><b>作者</b>：Liang Zhao,  En Yu,  Zheng Ge,  Jinrong Yang,  Haoran Wei,  Hongyu Zhou,  Jianjian Sun,  Yuang Peng,  Runpei Dong,  Chunrui Han,  Xiangyu Zhang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：multimodal large language, critical aspect, aspect that reflects, reflects the usability, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-AI interactivity is a critical aspect that reflects the usability of
multimodal large language models (MLLMs). However, existing end-to-end MLLMs
only allow users to interact with them through language instructions, leading
to the limitation of the interactive accuracy and efficiency. In this study, we
present precise referring instructions that utilize diverse reference
representations such as points and boxes as referring prompts to refer to the
special region. This enables MLLMs to focus on the region of interest and
achieve finer-grained interaction. Based on precise referring instruction, we
propose ChatSpot, a unified end-to-end multimodal large language model that
supports diverse forms of interactivity including mouse clicks, drag-and-drop,
and drawing boxes, which provides a more flexible and seamless interactive
experience. We also construct a multi-grained vision-language
instruction-following dataset based on existing datasets and GPT-4 generating.
Furthermore, we design a series of evaluation tasks to assess the effectiveness
of region recognition and interaction. Experimental results showcase ChatSpot's
promising performance.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：GroupLane: End-to-End 3D Lane Detection with Channel-wise Grouping</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09472</p>
  <p><b>作者</b>：Zhuoling Li,  Chunrui Han,  Zheng Ge,  Jinrong Yang,  En Yu,  Haoqian Wang,  Hengshuang Zhao,  Xiangyu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：practical deployment demand, deployment demand, due to practical, practical deployment, lane detection due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficiency is quite important for 3D lane detection due to practical
deployment demand. In this work, we propose a simple, fast, and end-to-end
detector that still maintains high detection precision. Specifically, we devise
a set of fully convolutional heads based on row-wise classification. In
contrast to previous counterparts, ours supports recognizing both vertical and
horizontal lanes. Besides, our method is the first one to perform row-wise
classification in bird-eye-view. In the heads, we split feature into multiple
groups and every group of feature corresponds to a lane instance. During
training, the predictions are associated with lane labels using the proposed
single-win one-to-one matching to compute loss, and no post-processing
operation is demanded for inference. In this way, our proposed fully
convolutional detector, GroupLane, realizes end-to-end detection like DETR.
Evaluated on 3 real world 3D lane benchmarks, OpenLane, Once-3DLanes, and
OpenLane-Huawei, GroupLane adopting ConvNext-Base as the backbone outperforms
the published state-of-the-art PersFormer by 13.6% F1 score in the OpenLane
validation set. Besides, GroupLane with ResNet18 still surpasses PersFormer by
4.9% F1 score, while the inference speed is nearly 7x faster and the FLOPs is
only 13.3% of it.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Occlusion Aware Student Emotion Recognition based on Facial Action Unit  Detection</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09465</p>
  <p><b>作者</b>：Shrouk Wally,  Ahmed Elsayed,  Islam Alkabbany,  Asem Ali,  Aly Farag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：half of science, undergraduate students, colleges and universities, approximately half, universities leave</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given that approximately half of science, technology, engineering, and
mathematics (STEM) undergraduate students in U.S. colleges and universities
leave by the end of the first year [15], it is crucial to improve the quality
of classroom environments. This study focuses on monitoring students' emotions
in the classroom as an indicator of their engagement and proposes an approach
to address this issue. The impact of different facial parts on the performance
of an emotional recognition model is evaluated through experimentation. To test
the proposed model under partial occlusion, an artificially occluded dataset is
introduced. The novelty of this work lies in the proposal of an occlusion-aware
architecture for facial action units (AUs) extraction, which employs attention
mechanism and adaptive feature learning. The AUs can be used later to classify
facial expressions in classroom settings.
This research paper's findings provide valuable insights into handling
occlusion in analyzing facial images for emotional engagement analysis. The
proposed experiments demonstrate the significance of considering occlusion and
enhancing the reliability of facial analysis models in classroom environments.
These findings can also be extended to other settings where occlusions are
prevalent.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A comparative analysis of SRGAN models</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09456</p>
  <p><b>作者</b>：Fatemeh Rezapoor Nikroo,  Ajinkya Deshmukh,  Anantha Sharma,  Adrian Tam,  Kaarthik Kumar,  Cleo Norris,  Aditya Dangi</p>
  <p><b>备注</b>：9 pages, 6 tables, 2 figures</p>
  <p><b>关键词</b>：Generative Adversarial Network, Super Resolution Generative, Resolution Generative Adversarial, Adversarial Network, Generative Adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we evaluate the performance of multiple state-of-the-art SRGAN
(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN
and EDSR, on a benchmark dataset of real-world images which undergo degradation
using a pipeline. Our results show that some models seem to significantly
increase the resolution of the input images while preserving their visual
quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE
model from huggingface outperforms the remaining candidate models in terms of
both quantitative metrics and subjective visual quality assessments with least
compute overhead. Specifically, EDSR generates images with higher peak
signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and
are seen to return high quality OCR results with Tesseract OCR engine. These
findings suggest that EDSR is a robust and effective approach for single-image
super-resolution and may be particularly well-suited for applications where
high-quality visual fidelity is critical and optimized compute.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Measuring Student Behavioral Engagement using Histogram of Actions</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09420</p>
  <p><b>作者</b>：Ahmed Abdelkawy,  Islam Alkabbany,  Asem Ali,  Aly Farag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：students' actions recognition, measuring behavioral engagement, actions, student, technique for measuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel technique for measuring behavioral
engagement through students' actions recognition. The proposed approach
recognizes student actions then predicts the student behavioral engagement
level. For student action recognition, we use human skeletons to model student
postures and upper body movements. To learn the dynamics of student upper body,
a 3D-CNN model is used. The trained 3D-CNN model is used to recognize actions
within every 2minute video segment then these actions are used to build a
histogram of actions which encodes the student actions and their frequencies.
This histogram is utilized as an input to SVM classifier to classify whether
the student is engaged or disengaged. To evaluate the proposed framework, we
build a dataset consisting of 1414 2-minute video segments annotated with 13
actions and 112 video segments annotated with two engagement levels.
Experimental results indicate that student actions can be recognized with top 1
accuracy 83.63% and the proposed framework can capture the average engagement
of the class.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation  Evaluation</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09416</p>
  <p><b>作者</b>：Federico Betti,  Jacopo Staiano,  Lorenzo Baraldi,  Lorenzo Baraldi,  Rita Cucchiara,  Nicu Sebe</p>
  <p><b>备注</b>：Accepted as oral at ACM MultiMedia 2023 (Brave New Ideas track)</p>
  <p><b>关键词</b>：produce high-quality visual, high-quality visual content, visual content based, made significant progress, recently made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in Image Generation has recently made significant progress,
particularly boosted by the introduction of Vision-Language models which are
able to produce high-quality visual content based on textual inputs. Despite
ongoing advancements in terms of generation quality and realism, no methodical
frameworks have been defined yet to quantitatively measure the quality of the
generated content and the adherence with the prompted requests: so far, only
human-based evaluations have been adopted for quality satisfaction and for
comparing different generative methods. We introduce a novel automated method
for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a
generated/edited image and the corresponding prompt/instructions, with a
process inspired by the human cognitive behaviour. ViCE combines the strengths
of Large Language Models (LLMs) and Visual Question Answering (VQA) into a
unified pipeline, aiming to replicate the human cognitive process in quality
assessment. This method outlines visual concepts, formulates image-specific
verification questions, utilizes the Q&A system to investigate the image, and
scores the combined outcome. Although this brave new hypothesis of mimicking
humans in the image evaluation process is in its preliminary assessment stage,
results are promising and open the door to a new form of automatic evaluation
which could have significant impact as the image generation or the image target
editing tasks become more and more sophisticated.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring  Instruction Tuning</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09474</p>
  <p><b>作者</b>：Liang Zhao,  En Yu,  Zheng Ge,  Jinrong Yang,  Haoran Wei,  Hongyu Zhou,  Jianjian Sun,  Yuang Peng,  Runpei Dong,  Chunrui Han,  Xiangyu Zhang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：multimodal large language, critical aspect, aspect that reflects, reflects the usability, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-AI interactivity is a critical aspect that reflects the usability of
multimodal large language models (MLLMs). However, existing end-to-end MLLMs
only allow users to interact with them through language instructions, leading
to the limitation of the interactive accuracy and efficiency. In this study, we
present precise referring instructions that utilize diverse reference
representations such as points and boxes as referring prompts to refer to the
special region. This enables MLLMs to focus on the region of interest and
achieve finer-grained interaction. Based on precise referring instruction, we
propose ChatSpot, a unified end-to-end multimodal large language model that
supports diverse forms of interactivity including mouse clicks, drag-and-drop,
and drawing boxes, which provides a more flexible and seamless interactive
experience. We also construct a multi-grained vision-language
instruction-following dataset based on existing datasets and GPT-4 generating.
Furthermore, we design a series of evaluation tasks to assess the effectiveness
of region recognition and interaction. Experimental results showcase ChatSpot's
promising performance.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：A comparative analysis of SRGAN models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09456</p>
  <p><b>作者</b>：Fatemeh Rezapoor Nikroo,  Ajinkya Deshmukh,  Anantha Sharma,  Adrian Tam,  Kaarthik Kumar,  Cleo Norris,  Aditya Dangi</p>
  <p><b>备注</b>：9 pages, 6 tables, 2 figures</p>
  <p><b>关键词</b>：Generative Adversarial Network, Super Resolution Generative, Resolution Generative Adversarial, Adversarial Network, Generative Adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we evaluate the performance of multiple state-of-the-art SRGAN
(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN
and EDSR, on a benchmark dataset of real-world images which undergo degradation
using a pipeline. Our results show that some models seem to significantly
increase the resolution of the input images while preserving their visual
quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE
model from huggingface outperforms the remaining candidate models in terms of
both quantitative metrics and subjective visual quality assessments with least
compute overhead. Specifically, EDSR generates images with higher peak
signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and
are seen to return high quality OCR results with Tesseract OCR engine. These
findings suggest that EDSR is a robust and effective approach for single-image
super-resolution and may be particularly well-suited for applications where
high-quality visual fidelity is critical and optimized compute.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Pseudo Outlier Exposure for Out-of-Distribution Detection using  Pretrained Transformers</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09455</p>
  <p><b>作者</b>：Jaeyoung Kim,  Kyuheon Jung,  Dongbin Na,  Sion Jang,  Eunbin Park,  Sungchul Choi</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：real-world language applications, OOD, OOD samples, helpful to alert, alert users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For real-world language applications, detecting an out-of-distribution (OOD)
sample is helpful to alert users or reject such unreliable samples. However,
modern over-parameterized language models often produce overconfident
predictions for both in-distribution (ID) and OOD samples. In particular,
language models suffer from OOD samples with a similar semantic representation
to ID samples since these OOD samples lie near the ID manifold. A rejection
network can be trained with ID and diverse outlier samples to detect test OOD
samples, but explicitly collecting auxiliary OOD datasets brings an additional
burden for data collection. In this paper, we propose a simple but effective
method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD
dataset by sequentially masking tokens related to ID classes. The surrogate OOD
sample introduced by POE shows a similar representation to ID data, which is
most effective in training a rejection network. Our method does not require any
external OOD data and can be easily implemented within off-the-shelf
Transformers. A comprehensive comparison with state-of-the-art algorithms
demonstrates POE's competitiveness on several text classification benchmarks.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation  Evaluation</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09416</p>
  <p><b>作者</b>：Federico Betti,  Jacopo Staiano,  Lorenzo Baraldi,  Lorenzo Baraldi,  Rita Cucchiara,  Nicu Sebe</p>
  <p><b>备注</b>：Accepted as oral at ACM MultiMedia 2023 (Brave New Ideas track)</p>
  <p><b>关键词</b>：produce high-quality visual, high-quality visual content, visual content based, made significant progress, recently made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in Image Generation has recently made significant progress,
particularly boosted by the introduction of Vision-Language models which are
able to produce high-quality visual content based on textual inputs. Despite
ongoing advancements in terms of generation quality and realism, no methodical
frameworks have been defined yet to quantitatively measure the quality of the
generated content and the adherence with the prompted requests: so far, only
human-based evaluations have been adopted for quality satisfaction and for
comparing different generative methods. We introduce a novel automated method
for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a
generated/edited image and the corresponding prompt/instructions, with a
process inspired by the human cognitive behaviour. ViCE combines the strengths
of Large Language Models (LLMs) and Visual Question Answering (VQA) into a
unified pipeline, aiming to replicate the human cognitive process in quality
assessment. This method outlines visual concepts, formulates image-specific
verification questions, utilizes the Q&A system to investigate the image, and
scores the combined outcome. Although this brave new hypothesis of mimicking
humans in the image evaluation process is in its preliminary assessment stage,
results are promising and open the door to a new form of automatic evaluation
which could have significant impact as the image generation or the image target
editing tasks become more and more sophisticated.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：How do software citation formats evolve over time? A longitudinal  analysis of R programming language packages</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09390</p>
  <p><b>作者</b>：Yuzhuo Wang,  Kai Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：play crucial roles, data-driven research paradigm, scientific inquiry, software, play crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Under the data-driven research paradigm, research software has come to play
crucial roles in nearly every stage of scientific inquiry. Scholars are
advocating for the formal citation of software in academic publications,
treating it on par with traditional research outputs. However, software is
hardly consistently cited: one software entity can be cited as different
objects, and the citations can change over time. These issues, however, are
largely overlooked in existing empirical research on software citation. To fill
the above gaps, the present study compares and analyzes a longitudinal dataset
of citation formats of all R packages collected in 2021 and 2022, in order to
understand the citation formats of R-language packages, important members in
the open-source software family, and how the citations evolve over time. In
particular, we investigate the different document types underlying the
citations and what metadata elements in the citation formats changed over time.
Furthermore, we offer an in-depth analysis of the disciplinarity of journal
articles cited as software (software papers). By undertaking this research, we
aim to contribute to a better understanding of the complexities associated with
software citation, shedding light on future software citation policies and
infrastructure.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Zero-shot Query Reformulation for Conversational Search</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09384</p>
  <p><b>作者</b>：Dayu Yang,  Yue Zhang,  Hui Fang</p>
  <p><b>备注</b>：Accepted by ICTIR 2023</p>
  <p><b>关键词</b>：Information Retrieval, voice assistants continues, gained increased attention, attention in Information, conversational search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the popularity of voice assistants continues to surge, conversational
search has gained increased attention in Information Retrieval. However, data
sparsity issues in conversational search significantly hinder the progress of
supervised conversational search methods. Consequently, researchers are
focusing more on zero-shot conversational search approaches. Nevertheless,
existing zero-shot methods face three primary limitations: they are not
universally applicable to all retrievers, their effectiveness lacks sufficient
explainability, and they struggle to resolve common conversational ambiguities
caused by omission. To address these limitations, we introduce a novel
Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based
on previous dialogue contexts without requiring supervision from conversational
search data. Specifically, our framework utilizes language models designed for
machine reading comprehension tasks to explicitly resolve two common
ambiguities: coreference and omission, in raw queries. In comparison to
existing zero-shot methods, our approach is universally applicable to any
retriever without additional adaptation or indexing. It also provides greater
explainability and effectively enhances query intent understanding because
ambiguities are explicitly and proactively resolved. Through extensive
experiments on four TREC conversational datasets, we demonstrate the
effectiveness of our method, which consistently outperforms state-of-the-art
baselines.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Adapting an ASR Foundation Model for Spoken Language Assessment</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09378</p>
  <p><b>作者</b>：Rao Ma,  Mengjie Qian,  Mark J. F. Gales,  Kate M. Knill</p>
  <p><b>备注</b>：Submitted to SLaTE 2023</p>
  <p><b>关键词</b>：language assessment system, underlying ASR model, reliable spoken language, spoken language assessment, underlying ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A crucial part of an accurate and reliable spoken language assessment system
is the underlying ASR model. Recently, large-scale pre-trained ASR foundation
models such as Whisper have been made available. As the output of these models
is designed to be human readable, punctuation is added, numbers are presented
in Arabic numeric form and abbreviations are included. Additionally, these
models have a tendency to skip disfluencies and hesitations in the output.
Though useful for readability, these attributes are not helpful for assessing
the ability of a candidate and providing feedback. Here a precise transcription
of what a candidate said is needed. In this paper, we give a detailed analysis
of Whisper outputs and propose two solutions: fine-tuning and soft prompt
tuning. Experiments are conducted on both public speech corpora and an English
learner dataset. Results show that we can effectively alter the decoding
behaviour of Whisper to generate the exact words spoken in the response.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Multi-Modal Discussion Transformer: Integrating Text, Images and Graph  Transformers to Detect Hate Speech on Social Media</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09312</p>
  <p><b>作者</b>：Liam Hebert,  Gaurav Sahu,  Nanda Kishore Sreenivas,  Lukasz Golab,  Robin Cohen</p>
  <p><b>备注</b>：Under Submission</p>
  <p><b>关键词</b>：multi-modal graph-based transformer, detecting hate speech, Multi-Modal Discussion Transformer, graph-based transformer model, multi-modal graph-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal
graph-based transformer model for detecting hate speech in online social
networks. In contrast to traditional text-only methods, our approach to
labelling a comment as hate speech centers around the holistic analysis of text
and images. This is done by leveraging graph transformers to capture the
contextual relationships in the entire discussion that surrounds a comment,
with interwoven fusion layers to combine text and image embeddings instead of
processing different modalities separately. We compare the performance of our
model to baselines that only process text; we also conduct extensive ablation
studies. We conclude with future work for multimodal solutions to deliver
social value in online contexts, arguing that capturing a holistic view of a
conversation greatly advances the effort to detect anti-social behavior.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Llama 2: Open Foundation and Fine-Tuned Chat Models</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09288</p>
  <p><b>作者</b>：Hugo Touvron,  Louis Martin,  Kevin Stone,  Peter Albert,  Amjad Almahairi,  Yasmine Babaei,  Nikolay Bashlykov,  Soumya Batra,  Prajjwal Bhargava,  Shruti Bhosale,  Dan Bikel,  Lukas Blecher,  Cristian Canton Ferrer,  Moya Chen,  Guillem Cucurull,  David Esiobu,  Jude Fernandes,  Jeremy Fu,  Wenyin Fu,  Brian Fuller,  Cynthia Gao,  Vedanuj Goswami,  Naman Goyal,  Anthony Hartshorn,  Saghar Hosseini,  Rui Hou,  Hakan Inan,  Marcin Kardas,  Viktor Kerkez,  Madian Khabsa,  Isabel Kloumann,  Artem Korenev,  Punit Singh Koura,  Marie-Anne Lachaux,  Thibaut Lavril,  Jenya Lee,  Diana Liskovich,  Yinghai Lu,  Yuning Mao,  Xavier Martinet,  Todor Mihaylov,  Pushkar Mishra,  Igor Molybog,  Yixin Nie,  Andrew Poulton,  Jeremy Reizenstein,  Rashi Rungta,  Kalyan Saladi,  Alan Schelten,  Ruan Silva,  Eric Michael Smith,  Ranjan Subramanian,  Xiaoqing Ellen Tan,  et al. (15 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fine-tuned large language, large language models, billion parameters, ranging in scale, release Llama</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we develop and release Llama 2, a collection of pretrained and
fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70
billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for
dialogue use cases. Our models outperform open-source chat models on most
benchmarks we tested, and based on our human evaluations for helpfulness and
safety, may be a suitable substitute for closed-source models. We provide a
detailed description of our approach to fine-tuning and safety improvements of
Llama 2-Chat in order to enable the community to build on our work and
contribute to the responsible development of LLMs.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Improving Text Semantic Similarity Modeling through a 3D Siamese Network</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09274</p>
  <p><b>作者</b>：Jianxiang Zang,  Hui Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Transformer blocks, Siamese network, text semantic similarity, semantic, gained popularity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Siamese networks have gained popularity as a method for modeling text
semantic similarity. Traditional methods rely on pooling operation to compress
the semantic representations from Transformer blocks in encoding, resulting in
two-dimensional semantic vectors and the loss of hierarchical semantic
information from Transformer blocks. Moreover, this limited structure of
semantic vectors is akin to a flattened landscape, which restricts the methods
that can be applied in downstream modeling, as they can only navigate this flat
terrain. To address this issue, we propose a novel 3D Siamese network for text
semantic similarity modeling, which maps semantic information to a
higher-dimensional space. The three-dimensional semantic tensors not only
retains more precise spatial and feature domain information but also provides
the necessary structural condition for comprehensive downstream modeling
strategies to capture them. Leveraging this structural advantage, we introduce
several modules to reinforce this 3D framework, focusing on three aspects:
feature extraction, attention, and feature fusion. Our extensive experiments on
four text semantic similarity benchmarks demonstrate the effectiveness and
efficiency of our 3D Siamese Network.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Linearized Relative Positional Encoding</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09270</p>
  <p><b>作者</b>：Zhen Qin,  Weixuan Sun,  Kaiyue Lu,  Hui Deng,  Dongxu Li,  Xiaodong Han,  Yuchao Dai,  Lingpeng Kong,  Yiran Zhong</p>
  <p><b>备注</b>：Reviewed by TMLR, decision pending. Yiran Zhong is the corresponding author. Code is available at this https URL</p>
  <p><b>关键词</b>：Relative positional encoding, represent positional information, positional encoding, Relative positional, encoding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relative positional encoding is widely used in vanilla and linear
transformers to represent positional information. However, existing encoding
methods of a vanilla transformer are not always directly applicable to a linear
transformer, because the latter requires a decomposition of the query and key
representations into separate kernel functions. Nevertheless, principles for
designing encoding methods suitable for linear transformers remain
understudied. In this work, we put together a variety of existing linear
relative positional encoding approaches under a canonical form and further
propose a family of linear relative positional encoding algorithms via unitary
transformation. Our formulation leads to a principled framework that can be
used to develop new relative positional encoding methods that preserve linear
space-time complexity. Equipped with different models, the proposed linearized
relative positional encoding (LRPE) family derives effective encoding for
various applications. Experiments show that compared with existing methods,
LRPE achieves state-of-the-art performance in language modeling, text
classification, and image classification. Meanwhile, it emphasizes a general
paradigm for designing broadly more relative positional encoding methods that
are applicable to linear transformers. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Text vectorization via transformer-based language models and n-gram  perplexities</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09255</p>
  <p><b>作者</b>：Mihailo Škorić</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：highly probable input, token significantly reduces, simple typographical error, typographical error, probabilities of individual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the probability (and thus perplexity) of a text is calculated based on the
product of the probabilities of individual tokens, it may happen that one
unlikely token significantly reduces the probability (i.e., increase the
perplexity) of some otherwise highly probable input, while potentially
representing a simple typographical error. Also, given that perplexity is a
scalar value that refers to the entire input, information about the probability
distribution within it is lost in the calculation (a relatively good text that
has one unlikely token and another text in which each token is equally likely
they can have the same perplexity value), especially for longer texts. As an
alternative to scalar perplexity this research proposes a simple algorithm used
to calculate vector values based on n-gram perplexities within the input. Such
representations consider the previously mentioned aspects, and instead of a
unique value, the relative perplexity of each text token is calculated, and
these values are combined into a single vector representing the input.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：PAC Neural Prediction Set Learning to Quantify the Uncertainty of  Generative Language Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09254</p>
  <p><b>作者</b>：Sangdon Park,  Taesoo Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial tasks, tasks to enhance, enhance the trustworthiness, prediction set models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty learning and quantification of models are crucial tasks to
enhance the trustworthiness of the models. Importantly, the recent surge of
generative language models (GLMs) emphasizes the need for reliable uncertainty
quantification due to the concerns on generating hallucinated facts. In this
paper, we propose to learn neural prediction set models that comes with the
probably approximately correct (PAC) guarantee for quantifying the uncertainty
of GLMs. Unlike existing prediction set models, which are parameterized by a
scalar value, we propose to parameterize prediction sets via neural networks,
which achieves more precise uncertainty quantification but still satisfies the
PAC guarantee. We demonstrate the efficacy of our method on four types of
language datasets and six types of models by showing that our method improves
the quantified uncertainty by $63\%$ on average, compared to a standard
baseline method.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular  Data</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09249</p>
  <p><b>作者</b>：Yazheng Yang,  Yuqi Wang,  Guang Liu,  Ledell Wu,  Qi Liu</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, yielding impressive outcomes, advancements in Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Natural Language Processing (NLP) have witnessed the
groundbreaking impact of pretrained models, yielding impressive outcomes across
various tasks. This study seeks to extend the power of pretraining
methodologies to tabular data, a domain traditionally overlooked, yet
inherently challenging due to the plethora of table schemas intrinsic to
different tasks. The primary research questions underpinning this work revolve
around the adaptation to heterogeneous table structures, the establishment of a
universal pretraining protocol for tabular data, the generalizability and
transferability of learned knowledge across tasks, the adaptation to diverse
downstream applications, and the incorporation of incremental columns over
time. In response to these challenges, we introduce UniTabE, a pioneering
method designed to process tables in a uniform manner, devoid of constraints
imposed by specific table structures. UniTabE's core concept relies on
representing each basic table element with a module, termed TabUnit. This is
subsequently followed by a Transformer encoder to refine the representation.
Moreover, our model is designed to facilitate pretraining and finetuning
through the utilization of free-form prompts. In order to implement the
pretraining phase, we curated an expansive tabular dataset comprising
approximately 13 billion samples, meticulously gathered from the Kaggle
platform. Rigorous experimental testing and analyses were performed under a
myriad of scenarios to validate the effectiveness of our methodology. The
experimental results demonstrate UniTabE's superior performance against several
baseline models across a multitude of benchmark datasets. This, therefore,
underscores UniTabE's potential to significantly enhance the semantic
representation of tabular data, thereby marking a significant stride in the
field of tabular data analysis.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Automated Ableism: An Exploration of Explicit Disability Biases in  Sentiment and Toxicity Analysis Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09209</p>
  <p><b>作者</b>：Pranav Narayanan Venkit,  Mukund Srinath,  Shomir Wilson</p>
  <p><b>备注</b>：TrustNLP at ACL 2023</p>
  <p><b>关键词</b>：Perturbation Sensitivity Analysis, analyze sentiment analysis, Twitter and Reddit, Perturbation Sensitivity, sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze sentiment analysis and toxicity detection models to detect the
presence of explicit bias against people with disability (PWD). We employ the
bias identification framework of Perturbation Sensitivity Analysis to examine
conversations related to PWD on social media platforms, specifically Twitter
and Reddit, in order to gain insight into how disability bias is disseminated
in real-world social settings. We then create the \textit{Bias Identification
Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any
sentiment analysis and toxicity detection models. Our study utilizes BITS to
uncover significant biases in four open AIaaS (AI as a Service) sentiment
analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,
DistilBERT and two toxicity detection models, namely two versions of
Toxic-BERT. Our findings indicate that all of these models exhibit
statistically significant explicit bias against PWD.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and  Addressing Sociological Implications</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09162</p>
  <p><b>作者</b>：Vishesh Thakur</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：garnered significant attention, significant attention due, Gender bias, natural language processing, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gender bias in artificial intelligence (AI) and natural language processing
has garnered significant attention due to its potential impact on societal
perceptions and biases. This research paper aims to analyze gender bias in
Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2
and GPT-3.5, some prominent language models, to better understand its
implications. Through a comprehensive literature review, the study examines
existing research on gender bias in AI language models and identifies gaps in
the current knowledge. The methodology involves collecting and preprocessing
data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis
techniques to evaluate gender bias in the generated text. The findings shed
light on gendered word associations, language usage, and biased narratives
present in the outputs of these Large Language Models. The discussion explores
the ethical implications of gender bias and its potential consequences on
social perceptions and marginalized communities. Additionally, the paper
presents strategies for reducing gender bias in LLMs, including algorithmic
approaches and data augmentation techniques. The research highlights the
importance of interdisciplinary collaborations and the role of sociological
studies in mitigating gender bias in AI models. By addressing these issues, we
can pave the way for more inclusive and unbiased AI systems that have a
positive impact on society.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Attention over pre-trained Sentence Embeddings for Long Document  Classification</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09084</p>
  <p><b>作者</b>：Amine Abdaoui,  Sourav Dutta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：short sequences due, quadratic attention complexity, NLP tasks, current de-facto models, number of tokens</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite being the current de-facto models in most NLP tasks, transformers are
often limited to short sequences due to their quadratic attention complexity on
the number of tokens. Several attempts to address this issue were studied,
either by reducing the cost of the self-attention computation or by modeling
smaller sequences and combining them through a recurrence mechanism or using a
new transformer model. In this paper, we suggest to take advantage of
pre-trained sentence transformers to start from semantically meaningful
embeddings of the individual sentences, and then combine them through a small
attention layer that scales linearly with the document length. We report the
results obtained by this simple architecture on three standard document
classification datasets. When compared with the current state-of-the-art models
using standard fine-tuning, the studied method obtains competitive results
(even if there is no clear best model in this configuration). We also showcase
that the studied architecture obtains better results when freezing the
underlying transformers. A configuration that is useful when we need to avoid
complete fine-tuning (e.g. when the same frozen transformer is shared by
different applications). Finally, two additional experiments are provided to
further evaluate the relevancy of the studied architecture over simpler
baselines.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Unleashing the Imagination of Text: A Novel Framework for Text-to-image  Person Retrieval via Exploring the Power of Words</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09059</p>
  <p><b>作者</b>：Delong Liu,  Haiwen Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve person images, large gallery, gallery that match, textual, abstract textual descriptions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of Text-to-image person retrieval is to retrieve person images from
a large gallery that match the given textual descriptions. The main challenge
of this task lies in the significant differences in information representation
between the visual and textual modalities. The textual modality conveys
abstract and precise information through vocabulary and grammatical structures,
while the visual modality conveys concrete and intuitive information through
images. To fully leverage the expressive power of textual representations, it
is essential to accurately map abstract textual descriptions to specific
images.
To address this issue, we propose a novel framework to Unleash the
Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully
explore the power of words in sentences. Specifically, the framework employs
the pre-trained full CLIP model as a dual encoder for the images and texts ,
taking advantage of prior cross-modal alignment knowledge. The Text-guided
Image Restoration auxiliary task is proposed with the aim of implicitly mapping
abstract textual entities to specific image regions, facilitating alignment
between textual and visual embeddings. Additionally, we introduce a cross-modal
triplet loss tailored for handling hard samples, enhancing the model's ability
to distinguish minor differences.
To focus the model on the key components within sentences, we propose a novel
text data augmentation technique. Our proposed methods achieve state-of-the-art
results on three popular benchmark datasets, and the source code will be made
publicly available shortly.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Enhancing conversational quality in language learning chatbots: An  evaluation of GPT4 for ASR error correction</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09744</p>
  <p><b>作者</b>：Long Mai,  Julie Carson-Berndsen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown promising results, natural language processing, language learning domain, technologies into educational, promising results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of natural language processing (NLP) technologies into
educational applications has shown promising results, particularly in the
language learning domain. Recently, many spoken open-domain chatbots have been
used as speaking partners, helping language learners improve their language
skills. However, one of the significant challenges is the high word-error-rate
(WER) when recognizing non-native/non-fluent speech, which interrupts
conversation flow and leads to disappointment for learners. This paper explores
the use of GPT4 for ASR error correction in conversational settings. In
addition to WER, we propose to use semantic textual similarity (STS) and next
response sensibility (NRS) metrics to evaluate the impact of error correction
models on the quality of the conversation. We find that transcriptions
corrected by GPT4 lead to higher conversation quality, despite an increase in
WER. GPT4 also outperforms standard error correction methods without the need
for in-domain training data.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09706</p>
  <p><b>作者</b>：Tianjian Gao,  Phillipe Langlais</p>
  <p><b>备注</b>：15th International Conference on Computational Semantics (IWCS), Association for Computational Linguistics (ACL)</p>
  <p><b>关键词</b>：essential knowledge representation, knowledge representation, resort to manual, automatic taxonomy construction, essential knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taxonomies are an essential knowledge representation, yet most studies on
automatic taxonomy construction (ATC) resort to manual evaluation to score
proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just
as important as taxonomy construction. We propose RaTE, an automatic label-free
taxonomy scoring procedure, which relies on a large pre-trained language model.
We apply our evaluation procedure to three state-of-the-art ATC algorithms with
which we built seven taxonomies from the Yelp domain, and show that 1) RaTE
correlates well with human judgments and 2) artificially degrading a taxonomy
leads to decreasing RaTE score.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：CValues: Measuring the Values of Chinese Large Language Models from  Safety to Responsibility</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09705</p>
  <p><b>作者</b>：Guohai Xu,  Jiayi Liu,  Ming Yan,  Haotian Xu,  Jinghui Si,  Zhuoran Zhou,  Peng Yi,  Xing Gao,  Jitao Sang,  Rong Zhang,  Ji Zhang,  Chao Peng,  Fei Huang,  Jingren Zhou</p>
  <p><b>备注</b>：Working in Process</p>
  <p><b>关键词</b>：large language models, negative social impacts, language models, social impacts, rapid evolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid evolution of large language models (LLMs), there is a growing
concern that they may pose risks or have negative social impacts. Therefore,
evaluation of human values alignment is becoming increasingly important.
Previous work mainly focuses on assessing the performance of LLMs on certain
knowledge and reasoning abilities, while neglecting the alignment to human
values, especially in a Chinese context. In this paper, we present CValues, the
first Chinese human values evaluation benchmark to measure the alignment
ability of LLMs in terms of both safety and responsibility criteria. As a
result, we have manually collected adversarial safety prompts across 10
scenarios and induced responsibility prompts from 8 domains by professional
experts. To provide a comprehensive values evaluation of Chinese LLMs, we not
only conduct human evaluation for reliable comparison, but also construct
multi-choice prompts for automatic evaluation. Our findings suggest that while
most Chinese LLMs perform well in terms of safety, there is considerable room
for improvement in terms of responsibility. Moreover, both the automatic and
human evaluation are important for assessing the human values alignment in
different aspects. The benchmark and code is available on ModelScope and
Github.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Efficient Guided Generation for LLMs</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09702</p>
  <p><b>作者</b>：Brandon T. Willard,  Rémi Louf</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：guiding language model, language model text, model text generation, context-free grammars, article we describe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article we describe an efficient approach to guiding language model
text generation with regular expressions and context-free grammars. Our
approach adds little to no overhead to the token sequence generation process,
and makes guided generation feasible in practice. An implementation is provided
in the open source Python library Outlines.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09701</p>
  <p><b>作者</b>：Hao Peng,  Qingqing Cao,  Jesse Dodge,  Matthew E. Peters,  Jared Fernandez,  Tom Sherborne,  Kyle Lo,  Sam Skjonsberg,  Emma Strubell,  Darrell Plessas,  Iz Beltagy,  Evan Pete Walsh,  Noah A. Smith,  Hannaneh Hajishirzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Rising computational demands, Rising computational, computational demands, demands of modern, barrier to entry</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rising computational demands of modern natural language processing (NLP)
systems have increased the barrier to entry for cutting-edge research while
posing serious environmental concerns. Yet, progress on model efficiency has
been impeded by practical challenges in model evaluation and comparison. For
example, hardware is challenging to control due to disparate levels of
accessibility across different institutions. Moreover, improvements in metrics
such as FLOPs often fail to translate to progress in real-world applications.
In response, we introduce Pentathlon, a benchmark for holistic and realistic
evaluation of model efficiency. Pentathlon focuses on inference, which accounts
for a majority of the compute in a model's lifecycle. It offers a
strictly-controlled hardware platform, and is designed to mirror real-world
applications scenarios. It incorporates a suite of metrics that target
different aspects of efficiency, including latency, throughput, memory
overhead, and energy consumption. Pentathlon also comes with a software library
that can be seamlessly integrated into any codebase and enable evaluation. As a
standardized and centralized evaluation platform, Pentathlon can drastically
reduce the workload to make fair and reproducible efficiency comparisons. While
initially focused on natural language processing (NLP) models, Pentathlon is
designed to allow flexible extension to other fields. We envision Pentathlon
will stimulate algorithmic innovations in building efficient models, and foster
an increased awareness of the social and environmental implications in the
development of future-generation NLP models.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Noor-Ghateh: A Benchmark Dataset for Evaluating Arabic Word Segmenters  in Hadith Domain</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09630</p>
  <p><b>作者</b>：Huda AlShuhayeb,  Behrouz Minaei-Bidgoli,  Mohammad E. Shenassa,  Sayyed-Ali Hossayni</p>
  <p><b>备注</b>：15 pages, 2 figures</p>
  <p><b>关键词</b>：analyzing traditional Arabic, rich morphological subtleties, traditional Arabic texts, religious contexts, complex and rich</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are many complex and rich morphological subtleties in the Arabic
language, which are very useful when analyzing traditional Arabic texts,
especially in the historical and religious contexts, and help in understanding
the meaning of the texts. Vocabulary separation means separating the word into
different parts such as root and affix. In the morphological datasets, the
variety of labels and the number of data samples helps to evaluate the
morphological methods. In this paper, we present a benchmark data set for
evaluating the methods of separating Arabic words which include about 223,690
words from the book of Sharia alIslam, which have been labeled by experts. In
terms of the volume and variety of words, this dataset is superior to other
existing data sets, and as far as we know, there are no Arabic Hadith Domain
texts. To evaluate the dataset, we applied different methods such as Farasa,
Camel, Madamira, and ALP to the dataset and we reported the annotation quality
through four evaluation methods.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09579</p>
  <p><b>作者</b>：Bocheng Chen,  Guangjing Wang,  Hanqing Guo,  Yuanda Wang,  Qiben Yan</p>
  <p><b>备注</b>：RAID 2023</p>
  <p><b>关键词</b>：natural language processing, Recent advances, advances in natural, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in natural language processing and machine learning have led
to the development of chatbot models, such as ChatGPT, that can engage in
conversational dialogue with human users. However, the ability of these models
to generate toxic or harmful responses during a non-toxic multi-turn
conversation remains an open research question. Existing research focuses on
single-turn sentence testing, while we find that 82\% of the individual
non-toxic sentences that elicit toxic behaviors in a conversation are
considered safe by existing tools. In this paper, we design a new attack,
\toxicbot, by fine-tuning a chatbot to engage in conversation with a target
open-domain chatbot. The chatbot is fine-tuned with a collection of crafted
conversation sequences. Particularly, each conversation begins with a sentence
from a crafted prompt sentences dataset. Our extensive evaluation shows that
open-domain chatbot models can be triggered to generate toxic responses in a
multi-turn conversation. In the best scenario, \toxicbot achieves a 67\%
activation rate. The conversation sequences in the fine-tuning stage help
trigger the toxicity in a conversation, which allows the attack to bypass two
defense methods. Our findings suggest that further research is needed to
address chatbot toxicity in a dynamic interactive environment. The proposed
\toxicbot can be used by both industry and researchers to develop methods for
detecting and mitigating toxic responses in conversational dialogue and improve
the robustness of chatbots for end users.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Can Model Fusing Help Transformers in Long Document Classification? An  Empirical Study</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09532</p>
  <p><b>作者</b>：Damith Premasiri,  Tharindu Ranasinghe,  Ruslan Mitkov</p>
  <p><b>备注</b>：Accepted in RANLP 2023</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, years in Natural, long document classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text classification is an area of research which has been studied over the
years in Natural Language Processing (NLP). Adapting NLP to multiple domains
has introduced many new challenges for text classification and one of them is
long document classification. While state-of-the-art transformer models provide
excellent results in text classification, most of them have limitations in the
maximum sequence length of the input sequence. The majority of the transformer
models are limited to 512 tokens, and therefore, they struggle with long
document classification problems. In this research, we explore on employing
Model Fusing for long document classification while comparing the results with
well-known BERT and Longformer architectures.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring  Instruction Tuning</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09474</p>
  <p><b>作者</b>：Liang Zhao,  En Yu,  Zheng Ge,  Jinrong Yang,  Haoran Wei,  Hongyu Zhou,  Jianjian Sun,  Yuang Peng,  Runpei Dong,  Chunrui Han,  Xiangyu Zhang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：multimodal large language, critical aspect, aspect that reflects, reflects the usability, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-AI interactivity is a critical aspect that reflects the usability of
multimodal large language models (MLLMs). However, existing end-to-end MLLMs
only allow users to interact with them through language instructions, leading
to the limitation of the interactive accuracy and efficiency. In this study, we
present precise referring instructions that utilize diverse reference
representations such as points and boxes as referring prompts to refer to the
special region. This enables MLLMs to focus on the region of interest and
achieve finer-grained interaction. Based on precise referring instruction, we
propose ChatSpot, a unified end-to-end multimodal large language model that
supports diverse forms of interactivity including mouse clicks, drag-and-drop,
and drawing boxes, which provides a more flexible and seamless interactive
experience. We also construct a multi-grained vision-language
instruction-following dataset based on existing datasets and GPT-4 generating.
Furthermore, we design a series of evaluation tasks to assess the effectiveness
of region recognition and interaction. Experimental results showcase ChatSpot's
promising performance.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A comparative analysis of SRGAN models</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09456</p>
  <p><b>作者</b>：Fatemeh Rezapoor Nikroo,  Ajinkya Deshmukh,  Anantha Sharma,  Adrian Tam,  Kaarthik Kumar,  Cleo Norris,  Aditya Dangi</p>
  <p><b>备注</b>：9 pages, 6 tables, 2 figures</p>
  <p><b>关键词</b>：Generative Adversarial Network, Super Resolution Generative, Resolution Generative Adversarial, Adversarial Network, Generative Adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we evaluate the performance of multiple state-of-the-art SRGAN
(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN
and EDSR, on a benchmark dataset of real-world images which undergo degradation
using a pipeline. Our results show that some models seem to significantly
increase the resolution of the input images while preserving their visual
quality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE
model from huggingface outperforms the remaining candidate models in terms of
both quantitative metrics and subjective visual quality assessments with least
compute overhead. Specifically, EDSR generates images with higher peak
signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and
are seen to return high quality OCR results with Tesseract OCR engine. These
findings suggest that EDSR is a robust and effective approach for single-image
super-resolution and may be particularly well-suited for applications where
high-quality visual fidelity is critical and optimized compute.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Pseudo Outlier Exposure for Out-of-Distribution Detection using  Pretrained Transformers</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09455</p>
  <p><b>作者</b>：Jaeyoung Kim,  Kyuheon Jung,  Dongbin Na,  Sion Jang,  Eunbin Park,  Sungchul Choi</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：real-world language applications, OOD, OOD samples, helpful to alert, alert users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For real-world language applications, detecting an out-of-distribution (OOD)
sample is helpful to alert users or reject such unreliable samples. However,
modern over-parameterized language models often produce overconfident
predictions for both in-distribution (ID) and OOD samples. In particular,
language models suffer from OOD samples with a similar semantic representation
to ID samples since these OOD samples lie near the ID manifold. A rejection
network can be trained with ID and diverse outlier samples to detect test OOD
samples, but explicitly collecting auxiliary OOD datasets brings an additional
burden for data collection. In this paper, we propose a simple but effective
method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD
dataset by sequentially masking tokens related to ID classes. The surrogate OOD
sample introduced by POE shows a similar representation to ID data, which is
most effective in training a rejection network. Our method does not require any
external OOD data and can be easily implemented within off-the-shelf
Transformers. A comprehensive comparison with state-of-the-art algorithms
demonstrates POE's competitiveness on several text classification benchmarks.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation  Evaluation</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09416</p>
  <p><b>作者</b>：Federico Betti,  Jacopo Staiano,  Lorenzo Baraldi,  Lorenzo Baraldi,  Rita Cucchiara,  Nicu Sebe</p>
  <p><b>备注</b>：Accepted as oral at ACM MultiMedia 2023 (Brave New Ideas track)</p>
  <p><b>关键词</b>：produce high-quality visual, high-quality visual content, visual content based, made significant progress, recently made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in Image Generation has recently made significant progress,
particularly boosted by the introduction of Vision-Language models which are
able to produce high-quality visual content based on textual inputs. Despite
ongoing advancements in terms of generation quality and realism, no methodical
frameworks have been defined yet to quantitatively measure the quality of the
generated content and the adherence with the prompted requests: so far, only
human-based evaluations have been adopted for quality satisfaction and for
comparing different generative methods. We introduce a novel automated method
for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a
generated/edited image and the corresponding prompt/instructions, with a
process inspired by the human cognitive behaviour. ViCE combines the strengths
of Large Language Models (LLMs) and Visual Question Answering (VQA) into a
unified pipeline, aiming to replicate the human cognitive process in quality
assessment. This method outlines visual concepts, formulates image-specific
verification questions, utilizes the Q&A system to investigate the image, and
scores the combined outcome. Although this brave new hypothesis of mimicking
humans in the image evaluation process is in its preliminary assessment stage,
results are promising and open the door to a new form of automatic evaluation
which could have significant impact as the image generation or the image target
editing tasks become more and more sophisticated.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：How do software citation formats evolve over time? A longitudinal  analysis of R programming language packages</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09390</p>
  <p><b>作者</b>：Yuzhuo Wang,  Kai Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：play crucial roles, data-driven research paradigm, scientific inquiry, software, play crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Under the data-driven research paradigm, research software has come to play
crucial roles in nearly every stage of scientific inquiry. Scholars are
advocating for the formal citation of software in academic publications,
treating it on par with traditional research outputs. However, software is
hardly consistently cited: one software entity can be cited as different
objects, and the citations can change over time. These issues, however, are
largely overlooked in existing empirical research on software citation. To fill
the above gaps, the present study compares and analyzes a longitudinal dataset
of citation formats of all R packages collected in 2021 and 2022, in order to
understand the citation formats of R-language packages, important members in
the open-source software family, and how the citations evolve over time. In
particular, we investigate the different document types underlying the
citations and what metadata elements in the citation formats changed over time.
Furthermore, we offer an in-depth analysis of the disciplinarity of journal
articles cited as software (software papers). By undertaking this research, we
aim to contribute to a better understanding of the complexities associated with
software citation, shedding light on future software citation policies and
infrastructure.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Zero-shot Query Reformulation for Conversational Search</b></summary>
  <p><b>编号</b>：[356]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09384</p>
  <p><b>作者</b>：Dayu Yang,  Yue Zhang,  Hui Fang</p>
  <p><b>备注</b>：Accepted by ICTIR 2023</p>
  <p><b>关键词</b>：Information Retrieval, voice assistants continues, gained increased attention, attention in Information, conversational search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the popularity of voice assistants continues to surge, conversational
search has gained increased attention in Information Retrieval. However, data
sparsity issues in conversational search significantly hinder the progress of
supervised conversational search methods. Consequently, researchers are
focusing more on zero-shot conversational search approaches. Nevertheless,
existing zero-shot methods face three primary limitations: they are not
universally applicable to all retrievers, their effectiveness lacks sufficient
explainability, and they struggle to resolve common conversational ambiguities
caused by omission. To address these limitations, we introduce a novel
Zero-shot Query Reformulation (ZeQR) framework that reformulates queries based
on previous dialogue contexts without requiring supervision from conversational
search data. Specifically, our framework utilizes language models designed for
machine reading comprehension tasks to explicitly resolve two common
ambiguities: coreference and omission, in raw queries. In comparison to
existing zero-shot methods, our approach is universally applicable to any
retriever without additional adaptation or indexing. It also provides greater
explainability and effectively enhances query intent understanding because
ambiguities are explicitly and proactively resolved. Through extensive
experiments on four TREC conversational datasets, we demonstrate the
effectiveness of our method, which consistently outperforms state-of-the-art
baselines.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Adapting an ASR Foundation Model for Spoken Language Assessment</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09378</p>
  <p><b>作者</b>：Rao Ma,  Mengjie Qian,  Mark J. F. Gales,  Kate M. Knill</p>
  <p><b>备注</b>：Submitted to SLaTE 2023</p>
  <p><b>关键词</b>：language assessment system, underlying ASR model, reliable spoken language, spoken language assessment, underlying ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A crucial part of an accurate and reliable spoken language assessment system
is the underlying ASR model. Recently, large-scale pre-trained ASR foundation
models such as Whisper have been made available. As the output of these models
is designed to be human readable, punctuation is added, numbers are presented
in Arabic numeric form and abbreviations are included. Additionally, these
models have a tendency to skip disfluencies and hesitations in the output.
Though useful for readability, these attributes are not helpful for assessing
the ability of a candidate and providing feedback. Here a precise transcription
of what a candidate said is needed. In this paper, we give a detailed analysis
of Whisper outputs and propose two solutions: fine-tuning and soft prompt
tuning. Experiments are conducted on both public speech corpora and an English
learner dataset. Results show that we can effectively alter the decoding
behaviour of Whisper to generate the exact words spoken in the response.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Forecasting the steam mass flow in a powerplant using the parallel  hybrid network</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09483</p>
  <p><b>作者</b>：Andrii Kurkin,  Jonas Hegemann,  Mo Kordzanganeh,  Alexey Melnikov</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：sustainable power generation, steam mass flow, Efficient and sustainable, crucial concern, mass flow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient and sustainable power generation is a crucial concern in the energy
sector. In particular, thermal power plants grapple with accurately predicting
steam mass flow, which is crucial for operational efficiency and cost
reduction. In this study, we use a parallel hybrid neural network architecture
that combines a parametrized quantum circuit and a conventional feed-forward
neural network specifically designed for time-series prediction in industrial
settings to enhance predictions of steam mass flow 15 minutes into the future.
Our results show that the parallel hybrid model outperforms standalone
classical and quantum models, achieving more than 5.7 and 4.9 times lower mean
squared error (MSE) loss on the test set after training compared to pure
classical and pure quantum networks, respectively. Furthermore, the hybrid
model demonstrates smaller relative errors between the ground truth and the
model predictions on the test set, up to 2 times better than the pure classical
model. These findings contribute to the broader scientific understanding of how
integrating quantum and classical machine learning techniques can be applied to
real-world challenges faced by the energy sector, ultimately leading to
optimized power plant operations.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：The Role of Transparency in Repeated First-Price Auctions with Unknown  Valuations</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09478</p>
  <p><b>作者</b>：Nicolò Cesa-Bianchi,  Tommaso Cesari,  Roberto Colomboni,  Federico Fusco,  Stefano Leonardi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study the problem, regret minimization, first-price auctions, single bidder, competing bids disclosed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of regret minimization for a single bidder in a sequence
of first-price auctions where the bidder knows the item's value only if the
auction is won. Our main contribution is a complete characterization, up to
logarithmic factors, of the minimax regret in terms of the auction's
transparency, which regulates the amount of information on competing bids
disclosed by the auctioneer at the end of each auction. Our results hold under
different assumptions (stochastic, adversarial, and their smoothed variants) on
the environment generating the bidder's valuations and competing bids. These
minimax rates reveal how the interplay between transparency and the nature of
the environment affects how fast one can learn to bid optimally in first-price
auctions.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Towards Ordinal Data Science</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09477</p>
  <p><b>作者</b>：Gerd Stumme,  Dominik Dürrschnabel,  Tom Hanika</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：main instruments, instruments to measure, measure the relationship, ordinal, empirical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Order is one of the main instruments to measure the relationship between
objects in (empirical) data. However, compared to methods that use numerical
properties of objects, the amount of ordinal methods developed is rather small.
One reason for this is the limited availability of computational resources in
the last century that would have been required for ordinal computations.
Another reason -- particularly important for this line of research -- is that
order-based methods are often seen as too mathematically rigorous for applying
them to real-world data. In this paper, we will therefore discuss different
means for measuring and 'calculating' with ordinal structures -- a specific
class of directed graphs -- and show how to infer knowledge from them. Our aim
is to establish Ordinal Data Science as a fundamentally new research agenda.
Besides cross-fertilization with other cornerstone machine learning and
knowledge representation methods, a broad range of disciplines will benefit
from this endeavor, including, psychology, sociology, economics, web science,
knowledge engineering, scientometrics.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Multi-Player Zero-Sum Markov Games with Networked Separable Interactions</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09470</p>
  <p><b>作者</b>：Chanwoo Park,  Kaiqing Zhang,  Asuman Ozdaglar</p>
  <p><b>备注</b>：61 pages</p>
  <p><b>关键词</b>：Multi-player Zero-sum, Markov, Markov games, Networked separable interactions, Markov Nash equilibrium</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a new class of Markov games (MGs), \textit{Multi-player Zero-sum
Markov Games} with {\it Networked separable interactions} (MZNMGs), to model
the local interaction structure in non-cooperative multi-agent sequential
decision-making. We define an MZNMG as a model where {the payoffs of the
auxiliary games associated with each state are zero-sum and} have some
separable (i.e., polymatrix) structure across the neighbors over some
interaction network. We first identify the necessary and sufficient conditions
under which an MG can be presented as an MZNMG, and show that the set of Markov
coarse correlated equilibrium (CCE) collapses to the set of Markov Nash
equilibrium (NE) in these games, in that the {product of} per-state
marginalization of the former for all players yields the latter. Furthermore,
we show that finding approximate Markov \emph{stationary} CCE in
infinite-horizon discounted MZNMGs is \texttt{PPAD}-hard, unless the underlying
network has a ``star topology''. Then, we propose fictitious-play-type
dynamics, the classical learning dynamics in normal-form games, for MZNMGs, and
establish convergence guarantees to Markov stationary NE under a star-shaped
network structure. Finally, in light of the hardness result, we focus on
computing a Markov \emph{non-stationary} NE and provide finite-iteration
guarantees for a series of value-iteration-based algorithms. We also provide
numerical experiments to corroborate our theoretical results.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Does Circuit Analysis Interpretability Scale? Evidence from Multiple  Choice Capabilities in Chinchilla</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09458</p>
  <p><b>作者</b>：Tom Lieberum,  Matthew Rahtz,  János Kramár,  Neel Nanda,  Geoffrey Irving,  Rohin Shah,  Vladimir Mikulik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Circuit analysis, understanding the internal, internal mechanisms, mechanisms of language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>\emph{Circuit analysis} is a promising technique for understanding the
internal mechanisms of language models. However, existing analyses are done in
small models far from the state of the art. To address this, we present a case
study of circuit analysis in the 70B Chinchilla model, aiming to test the
scalability of circuit analysis. In particular, we study multiple-choice
question answering, and investigate Chinchilla's capability to identify the
correct answer \emph{label} given knowledge of the correct answer \emph{text}.
We find that the existing techniques of logit attribution, attention pattern
visualization, and activation patching naturally scale to Chinchilla, allowing
us to identify and categorize a small set of `output nodes' (attention heads
and MLPs).
We further study the `correct letter' category of attention heads aiming to
understand the semantics of their features, with mixed results. For normal
multiple-choice question answers, we significantly compress the query, key and
value subspaces of the head without loss of performance when operating on the
answer labels for multiple-choice questions, and we show that the query and key
subspaces represent an `Nth item in an enumeration' feature to at least some
extent. However, when we attempt to use this explanation to understand the
heads' behaviour on a more general distribution including randomized answer
labels, we find that it is only a partial explanation, suggesting there is more
to learn about the operation of `correct letter' heads on multiple choice
question answering.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Convergent regularization in inverse problems and linear plug-and-play  denoisers</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09441</p>
  <p><b>作者</b>：Andreas Hauptmann,  Subhadip Mukherjee,  Carola-Bibiane Schönlieb,  Ferdia Sherry</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular iterative framework, solving imaging inverse, convergent regularization schemes, imaging inverse problems, provably convergent regularization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Plug-and-play (PnP) denoising is a popular iterative framework for solving
imaging inverse problems using off-the-shelf image denoisers. Their empirical
success has motivated a line of research that seeks to understand the
convergence of PnP iterates under various assumptions on the denoiser. While a
significant amount of research has gone into establishing the convergence of
the PnP iteration for different regularity conditions on the denoisers, not
much is known about the asymptotic properties of the converged solution as the
noise level in the measurement tends to zero, i.e., whether PnP methods are
provably convergent regularization schemes under reasonable assumptions on the
denoiser. This paper serves two purposes: first, we provide an overview of the
classical regularization theory in inverse problems and survey a few notable
recent data-driven methods that are provably convergent regularization schemes.
We then continue to discuss PnP algorithms and their established convergence
guarantees. Subsequently, we consider PnP algorithms with linear denoisers and
propose a novel spectral filtering technique to control the strength of
regularization arising from the denoiser. Further, by relating the implicit
regularization of the denoiser to an explicit regularization functional, we
rigorously show that PnP with linear denoisers leads to a convergent
regularization scheme. More specifically, we prove that in the limit as the
noise vanishes, the PnP reconstruction converges to the minimizer of a
regularization potential subject to the solution satisfying the noiseless
operator equation. The theoretical analysis is corroborated by numerical
experiments for the classical inverse problem of tomographic image
reconstruction.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Scaling Laws for Imitation Learning in NetHack</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09423</p>
  <p><b>作者</b>：Jens Tuyls,  Dhruv Madeka,  Kari Torkkola,  Dean Foster,  Karthik Narasimhan,  Sham Kakade</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely used methods, methods in machine, Natural Language Processing, Imitation Learning, scaling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation Learning (IL) is one of the most widely used methods in machine
learning. Yet, while powerful, many works find it is often not able to fully
recover the underlying expert behavior. However, none of these works deeply
investigate the role of scaling up the model and data size. Inspired by recent
work in Natural Language Processing (NLP) where "scaling up" has resulted in
increasingly more capable LLMs, we investigate whether carefully scaling up
model and data size can bring similar improvements in the imitation learning
setting. To demonstrate our findings, we focus on the game of NetHack, a
challenging environment featuring procedural generation, stochasticity,
long-term dependencies, and partial observability. We find IL loss and mean
return scale smoothly with the compute budget and are strongly correlated,
resulting in power laws for training compute-optimal IL agents with respect to
model size and number of samples. We forecast and train several NetHack agents
with IL and find they outperform prior state-of-the-art by at least 2x in all
settings. Our work both demonstrates the scaling behavior of imitation learning
in a challenging domain, as well as the viability of scaling up current
approaches for increasingly capable agents in NetHack, a game that remains
elusively hard for current AI systems.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Online Learning with Costly Features in Non-stationary Environments</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09388</p>
  <p><b>作者</b>：Saeed Ghoorchian,  Evgenii Kortukov,  Setareh Maghsudi</p>
  <p><b>备注</b>：31 pages, 6 figures</p>
  <p><b>关键词</b>：sequential decision-making problems, Maximizing long-term rewards, primary goal, goal in sequential, features' states</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Maximizing long-term rewards is the primary goal in sequential
decision-making problems. The majority of existing methods assume that side
information is freely available, enabling the learning agent to observe all
features' states before making a decision. In real-world problems, however,
collecting beneficial information is often costly. That implies that, besides
individual arms' reward, learning the observations of the features' states is
essential to improve the decision-making strategy. The problem is aggravated in
a non-stationary environment where reward and cost distributions undergo abrupt
changes over time. To address the aforementioned dual learning problem, we
extend the contextual bandit setting and allow the agent to observe subsets of
features' states. The objective is to maximize the long-term average gain,
which is the difference between the accumulated rewards and the paid costs on
average. Therefore, the agent faces a trade-off between minimizing the cost of
information acquisition and possibly improving the decision-making process
using the obtained information. To this end, we develop an algorithm that
guarantees a sublinear regret in time. Numerical results demonstrate the
superiority of our proposed policy in a real-world scenario.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Data Cross-Segmentation for Improved Generalization in Reinforcement  Learning Based Algorithmic Trading</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09377</p>
  <p><b>作者</b>：Vikram Duvvur,  Aashay Mehta,  Edward Sun,  Bo Wu,  Ken Yew Chan,  Jeff Schneider</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithmic trading systems, increasingly common, systems is increasingly, machine learning, algorithmic trading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of machine learning in algorithmic trading systems is increasingly
common. In a typical set-up, supervised learning is used to predict the future
prices of assets, and those predictions drive a simple trading and execution
strategy. This is quite effective when the predictions have sufficient signal,
markets are liquid, and transaction costs are low. However, those conditions
often do not hold in thinly traded financial markets and markets for
differentiated assets such as real estate or vehicles. In these markets, the
trading strategy must consider the long-term effects of taking positions that
are relatively more difficult to change. In this work, we propose a
Reinforcement Learning (RL) algorithm that trades based on signals from a
learned predictive model and addresses these challenges. We test our algorithm
on 20+ years of equity data from Bursa Malaysia.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Enhancing Pattern Classification in Support Vector Machines through  Matrix Formulation</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09372</p>
  <p><b>作者</b>：Sambhav Jain Reshma Rastogi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Support Vector Machines, Vector Machines, gathered significant acclaim, Support Vector, implementation of Statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Support Vector Machines (SVM) have gathered significant acclaim as
classifiers due to their successful implementation of Statistical Learning
Theory. However, in the context of multiclass and multilabel settings, the
reliance on vector-based formulations in existing SVM-based models poses
limitations regarding flexibility and ease of incorporating additional terms to
handle specific challenges. To overcome these limitations, our research paper
focuses on introducing a matrix formulation for SVM that effectively addresses
these constraints. By employing the Accelerated Gradient Descent method in the
dual, we notably enhance the efficiency of solving the Matrix-SVM problem.
Experimental evaluations on multilabel and multiclass datasets demonstrate that
Matrix SVM achieves superior time efficacy while delivering similar results to
Binary Relevance SVM.
Moreover, our matrix formulation unveils crucial insights and advantages that
may not be readily apparent in traditional vector-based notations. We emphasize
that numerous multilabel models can be viewed as extensions of SVM, with
customised modifications to meet specific requirements. The matrix formulation
presented in this paper establishes a solid foundation for developing more
sophisticated models capable of effectively addressing the distinctive
challenges encountered in multilabel learning.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Sparse Gaussian Graphical Models with Discrete Optimization:  Computational and Statistical Perspectives</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09366</p>
  <p><b>作者</b>：Kayhan Behdin,  Wenyu Chen,  Rahul Mazumder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sparse graph underlying, underlying an undirected, graph underlying, sparse graph, Gaussian graphical model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of learning a sparse graph underlying an undirected
Gaussian graphical model, a key problem in statistical machine learning. Given
$n$ samples from a multivariate Gaussian distribution with $p$ variables, the
goal is to estimate the $p \times p$ inverse covariance matrix (aka precision
matrix), assuming it is sparse (i.e., has a few nonzero entries). We propose
GraphL0BnB, a new estimator based on an $\ell_0$-penalized version of the
pseudolikelihood function, while most earlier approaches are based on the
$\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer
program (MIP) which can be difficult to compute at scale using off-the-shelf
commercial solvers. To solve the MIP, we propose a custom nonlinear
branch-and-bound (BnB) framework that solves node relaxations with tailored
first-order methods. As a by-product of our BnB framework, we propose
large-scale solvers for obtaining good primal solutions that are of independent
interest. We derive novel statistical guarantees (estimation and variable
selection) for our estimator and discuss how our approach improves upon
existing estimators. Our numerical experiments on real/synthetic datasets
suggest that our method can solve, to near-optimality, problem instances with
$p = 10^4$ -- corresponding to a symmetric matrix of size $p \times p$ with
$p^2/2$ binary variables. We demonstrate the usefulness of GraphL0BnB versus
various state-of-the-art approaches on a range of datasets.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：An Evaluation of Zero-Cost Proxies -- from Neural Architecture  Performance to Model Robustness</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09365</p>
  <p><b>作者</b>：Jovita Lukasik,  Michael Moeller,  Margret Keuper</p>
  <p><b>备注</b>：Accepted at DAGM GCPR 2023</p>
  <p><b>关键词</b>：nowadays frequently studied, nowadays frequently, frequently studied, Zero-cost proxies, proxies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Zero-cost proxies are nowadays frequently studied and used to search for
neural architectures. They show an impressive ability to predict the
performance of architectures by making use of their untrained weights. These
techniques allow for immense search speed-ups. So far the joint search for
well-performing and robust architectures has received much less attention in
the field of NAS. Therefore, the main focus of zero-cost proxies is the clean
accuracy of architectures, whereas the model robustness should play an evenly
important part. In this paper, we analyze the ability of common zero-cost
proxies to serve as performance predictors for robustness in the popular
NAS-Bench-201 search space. We are interested in the single prediction task for
robustness and the joint multi-objective of clean and robust accuracy. We
further analyze the feature importance of the proxies and show that predicting
the robustness makes the prediction task from existing zero-cost proxies more
challenging. As a result, the joint consideration of several proxies becomes
necessary to predict a model's robustness while the clean accuracy can be
regressed from a single such feature.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：MOCA: Self-supervised Representation Learning by Predicting Masked  Online Codebook Assignments</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09361</p>
  <p><b>作者</b>：Spyros Gidaris,  Andrei Bursuc,  Oriane Simeoni,  Antonin Vobecky,  Nikos Komodakis,  Matthieu Cord,  Patrick Pérez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mitigating the greedy, Vision Transformer networks, Vision Transformer, Self-supervised learning, Transformer networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning can be used for mitigating the greedy needs of
Vision Transformer networks for very large fully-annotated datasets. Different
classes of self-supervised learning offer representations with either good
contextual reasoning properties, e.g., using masked image modeling strategies,
or invariance to image perturbations, e.g., with contrastive methods. In this
work, we propose a single-stage and standalone method, MOCA, which unifies both
desired properties using novel mask-and-predict objectives defined with
high-level features (instead of pixel-level details). Moreover, we show how to
effectively employ both learning paradigms in a synergistic and
computation-efficient way. Doing so, we achieve new state-of-the-art results on
low-shot settings and strong experimental results in various evaluation
protocols with a training that is at least 3 times faster than prior methods.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural  Network Training and Inference</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09357</p>
  <p><b>作者</b>：Manuel Le Gallo,  Corey Lammie,  Julian Buechel,  Fabio Carta,  Omobayode Fagbohungbe,  Charles Mackin,  Hsinyu Tsai,  Vijay Narayanan,  Abu Sebastian,  Kaoutar El Maghraoui,  Malte J. Rasch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Neural Network, Neural Network, Analog In-Memory Computing, Deep Neural, IBM Analog Hardware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analog In-Memory Computing (AIMC) is a promising approach to reduce the
latency and energy consumption of Deep Neural Network (DNN) inference and
training. However, the noisy and non-linear device characteristics, and the
non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be
deployed on such hardware to achieve equivalent accuracy to digital computing.
In this tutorial, we provide a deep dive into how such adaptations can be
achieved and evaluated using the recently released IBM Analog Hardware
Acceleration Kit (AIHWKit), freely available at this https URL.
The AIHWKit is a Python library that simulates inference and training of DNNs
using AIMC. We present an in-depth description of the AIHWKit design,
functionality, and best practices to properly perform inference and training.
We also present an overview of the Analog AI Cloud Composer, that provides the
benefits of using the AIHWKit simulation platform in a fully managed cloud
setting. Finally, we show examples on how users can expand and customize
AIHWKit for their own needs. This tutorial is accompanied by comprehensive
Jupyter Notebook code examples that can be run using AIHWKit, which can be
downloaded from this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer  Constraints</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09342</p>
  <p><b>作者</b>：Felix Ulrich-Oltean,  Peter Nightingale,  James Alfred Walker</p>
  <p><b>备注</b>：24 pages, 10 figures, submitted to Constraints Journal (Springer)</p>
  <p><b>关键词</b>：Boolean Satisfiability problem, Boolean Satisfiability, Satisfiability problem, satisfaction and optimisation, SAT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many constraint satisfaction and optimisation problems can be solved
effectively by encoding them as instances of the Boolean Satisfiability problem
(SAT). However, even the simplest types of constraints have many encodings in
the literature with widely varying performance, and the problem of selecting
suitable encodings for a given problem instance is not trivial. We explore the
problem of selecting encodings for pseudo-Boolean and linear constraints using
a supervised machine learning approach. We show that it is possible to select
encodings effectively using a standard set of features for constraint problems;
however we obtain better performance with a new set of features specifically
designed for the pseudo-Boolean and linear constraints. In fact, we achieve
good results when selecting encodings for unseen problem classes. Our results
compare favourably to AutoFolio when using the same feature set. We discuss the
relative importance of instance features to the task of selecting the best
encodings, and compare several variations of the machine learning method.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Exploiting Field Dependencies for Learning on Categorical Data</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09321</p>
  <p><b>作者</b>：Zhibin Li,  Piotr Koniusz,  Lu Zhang,  Daniel Edward Pagendam,  Peyman Moghadam</p>
  <p><b>备注</b>：IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted June 2022, accepted July 2023)</p>
  <p><b>关键词</b>：data points driven, categorical data underexploit, field dependency matrix, global field dependency, categorical data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional approaches for learning on categorical data underexploit the
dependencies between columns (\aka fields) in a dataset because they rely on
the embedding of data points driven alone by the classification/regression
loss. In contrast, we propose a novel method for learning on categorical data
with the goal of exploiting dependencies between fields. Instead of modelling
statistics of features globally (i.e., by the covariance matrix of features),
we learn a global field dependency matrix that captures dependencies between
fields and then we refine the global field dependency matrix at the
instance-wise level with different weights (so-called local dependency
modelling) w.r.t. each field to improve the modelling of the field
dependencies. Our algorithm exploits the meta-learning paradigm, i.e., the
dependency matrices are refined in the inner loop of the meta-learning
algorithm without the use of labels, whereas the outer loop intertwines the
updates of the embedding matrix (the matrix performing projection) and global
dependency matrix in a supervised fashion (with the use of labels). Our method
is simple yet it outperforms several state-of-the-art methods on six popular
dataset benchmarks. Detailed ablation studies provide additional insights into
our method.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Biomaker CA: a Biome Maker project using Cellular Automata</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09320</p>
  <p><b>作者</b>：Ettore Randazzo,  Alexander Mordvintsev</p>
  <p><b>备注</b>：20 pages, 23 figures. For code base, see this https URL</p>
  <p><b>关键词</b>：Cellular Automata, Biome Maker project, Biome Maker, Maker project, introduce Biomaker</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA).
In Biomaker CA, morphogenesis is a first class citizen and small seeds need to
grow into plant-like organisms to survive in a nutrient starved environment and
eventually reproduce with variation so that a biome survives for long
timelines. We simulate complex biomes by means of CA rules in 2D grids and
parallelize all of its computation on GPUs through the Python JAX framework. We
show how this project allows for several different kinds of environments and
laws of 'physics', alongside different model architectures and mutation
strategies. We further analyze some configurations to show how plant agents can
grow, survive, reproduce, and evolve, forming stable and unstable biomes. We
then demonstrate how one can meta-evolve models to survive in a harsh
environment either through end-to-end meta-evolution or by a more surgical and
efficient approach, called Petri dish meta-evolution. Finally, we show how to
perform interactive evolution, where the user decides how to evolve a plant
model interactively and then deploys it in a larger environment. We open source
Biomaker CA at: this https URL .</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multi-Modal Discussion Transformer: Integrating Text, Images and Graph  Transformers to Detect Hate Speech on Social Media</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09312</p>
  <p><b>作者</b>：Liam Hebert,  Gaurav Sahu,  Nanda Kishore Sreenivas,  Lukasz Golab,  Robin Cohen</p>
  <p><b>备注</b>：Under Submission</p>
  <p><b>关键词</b>：multi-modal graph-based transformer, detecting hate speech, Multi-Modal Discussion Transformer, graph-based transformer model, multi-modal graph-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal
graph-based transformer model for detecting hate speech in online social
networks. In contrast to traditional text-only methods, our approach to
labelling a comment as hate speech centers around the holistic analysis of text
and images. This is done by leveraging graph transformers to capture the
contextual relationships in the entire discussion that surrounds a comment,
with interwoven fusion layers to combine text and image embeddings instead of
processing different modalities separately. We compare the performance of our
model to baselines that only process text; we also conduct extensive ablation
studies. We conclude with future work for multimodal solutions to deliver
social value in online contexts, arguing that capturing a holistic view of a
conversation greatly advances the effort to detect anti-social behavior.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Automatic Differentiation for Inverse Problems with Applications in  Quantum Transport</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09311</p>
  <p><b>作者</b>：Ivan Williams,  Eric Polizzi</p>
  <p><b>备注</b>：7 pages, 5 figures</p>
  <p><b>关键词</b>：quantum transport problem, transmitting boundary model, quantum transmitting boundary, inverse quantum transport, transport problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A neural solver and differentiable simulation of the quantum transmitting
boundary model is presented for the inverse quantum transport problem. The
neural solver is used to engineer continuous transmission properties and the
differentiable simulation is used to engineer current-voltage characteristics.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory  Forecasting</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09306</p>
  <p><b>作者</b>：Inhwan Bae,  Jean Oh,  Hae-Gon Jeon</p>
  <p><b>备注</b>：Accepted at ICCV 2023</p>
  <p><b>关键词</b>：Capturing high-dimensional social, Capturing high-dimensional, predicting trajectories, essential for predicting, mathbb</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Capturing high-dimensional social interactions and feasible futures is
essential for predicting trajectories. To address this complex nature, several
attempts have been devoted to reducing the dimensionality of the output
variables via parametric curve fitting such as the Bézier curve and B-spline
function. However, these functions, which originate in computer graphics
fields, are not suitable to account for socially acceptable human dynamics. In
this paper, we present EigenTrajectory ($\mathbb{ET}$), a trajectory prediction
approach that uses a novel trajectory descriptor to form a compact space, known
here as $\mathbb{ET}$ space, in place of Euclidean space, for representing
pedestrian movements. We first reduce the complexity of the trajectory
descriptor via a low-rank approximation. We transform the pedestrians' history
paths into our $\mathbb{ET}$ space represented by spatio-temporal principle
components, and feed them into off-the-shelf trajectory forecasting models. The
inputs and outputs of the models as well as social interactions are all
gathered and aggregated in the corresponding $\mathbb{ET}$ space. Lastly, we
propose a trajectory anchor-based refinement method to cover all possible
futures in the proposed $\mathbb{ET}$ space. Extensive experiments demonstrate
that our EigenTrajectory predictor can significantly improve both the
prediction accuracy and reliability of existing trajectory forecasting models
on public benchmarks, indicating that the proposed descriptor is suited to
represent pedestrian behaviors. Code is publicly available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Conformal prediction under ambiguous ground truth</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09302</p>
  <p><b>作者</b>：David Stutz,  Abhijit Guha Roy,  Tatiana Matejovicova,  Patricia Strachan,  Ali Taylan Cemgil,  Arnaud Doucet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：providing confidence sets, safety-critical classification tasks, user-specified probability, rigorous uncertainty quantification, perform rigorous uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In safety-critical classification tasks, conformal prediction allows to
perform rigorous uncertainty quantification by providing confidence sets
including the true class with a user-specified probability. This generally
assumes the availability of a held-out calibration set with access to ground
truth labels. Unfortunately, in many domains, such labels are difficult to
obtain and usually approximated by aggregating expert opinions. In fact, this
holds true for almost all datasets, including well-known ones such as CIFAR and
ImageNet. Applying conformal prediction using such labels underestimates
uncertainty. Indeed, when expert opinions are not resolvable, there is inherent
ambiguity present in the labels. That is, we do not have ``crisp'', definitive
ground truth labels and this uncertainty should be taken into account during
calibration. In this paper, we develop a conformal prediction framework for
such ambiguous ground truth settings which relies on an approximation of the
underlying posterior distribution of labels given inputs. We demonstrate our
methodology on synthetic and real datasets, including a case study of skin
condition classification in dermatology.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Nested Elimination: A Simple Algorithm for Best-Item Identification from  Choice-Based Feedback</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09295</p>
  <p><b>作者</b>：Junwen Yang,  Yifan Feng</p>
  <p><b>备注</b>：Accepted to ICML 2023</p>
  <p><b>关键词</b>：choice-based feedback, best-item identification, identification from choice-based, problem, feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of best-item identification from choice-based feedback.
In this problem, a company sequentially and adaptively shows display sets to a
population of customers and collects their choices. The objective is to
identify the most preferred item with the least number of samples and at a high
confidence level. We propose an elimination-based algorithm, namely Nested
Elimination (NE), which is inspired by the nested structure implied by the
information-theoretic lower bound. NE is simple in structure, easy to
implement, and has a strong theoretical guarantee for sample complexity.
Specifically, NE utilizes an innovative elimination criterion and circumvents
the need to solve any complex combinatorial optimization problem. We provide an
instance-specific and non-asymptotic bound on the expected sample complexity of
NE. We also show NE achieves high-order worst-case asymptotic optimality.
Finally, numerical experiments from both synthetic and real data corroborate
our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：FlexiAST: Flexibility is What AST Needs</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09286</p>
  <p><b>作者</b>：Jiu Feng,  Mehmet Hamza Erol,  Joon Son Chung,  Arda Senocak</p>
  <p><b>备注</b>：Interspeech 2023</p>
  <p><b>关键词</b>：AST models, AST, patch sizes, standard AST models, patch</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The objective of this work is to give patch-size flexibility to Audio
Spectrogram Transformers (AST). Recent advancements in ASTs have shown superior
performance in various audio-based tasks. However, the performance of standard
ASTs degrades drastically when evaluated using different patch sizes from that
used during training. As a result, AST models are typically re-trained to
accommodate changes in patch sizes. To overcome this limitation, this paper
proposes a training procedure to provide flexibility to standard AST models
without architectural changes, allowing them to work with various patch sizes
at the inference stage - FlexiAST. This proposed training approach simply
utilizes random patch size selection and resizing of patch and positional
embedding weights. Our experiments show that FlexiAST gives similar performance
to standard AST models while maintaining its evaluation ability at various
patch sizes on different datasets for audio classification tasks.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：End-to-End Neural Network Training for Hyperbox-Based Classification</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09269</p>
  <p><b>作者</b>：Denis Mayr Lima Martins,  Christian Lülf,  Fabian Gieseke</p>
  <p><b>备注</b>：6 pages, accepted for poster presentation at ESANN 2023</p>
  <p><b>关键词</b>：multidimensional boxes, series of orthogonal, interpretable and human-readable, promising technique, hyperboxes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperbox-based classification has been seen as a promising technique in which
decisions on the data are represented as a series of orthogonal,
multidimensional boxes (i.e., hyperboxes) that are often interpretable and
human-readable. However, existing methods are no longer capable of efficiently
handling the increasing volume of data many application domains face nowadays.
We address this gap by proposing a novel, fully differentiable framework for
hyperbox-based classification via neural networks. In contrast to previous
work, our hyperbox models can be efficiently trained in an end-to-end fashion,
which leads to significantly reduced training times and superior classification
results.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Mobility-Aware Joint User Scheduling and Resource Allocation for Low  Latency Federated Learning</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09263</p>
  <p><b>作者</b>：Kecheng Fan,  Wen Chen,  Jun Li,  Xiumei Deng,  Xuefeng Han,  Ming Ding</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning approach, distributed machine learning, central server side, efficient distributed machine, Federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an efficient distributed machine learning approach, Federated learning
(FL) can obtain a shared model by iterative local model training at the user
side and global model aggregating at the central server side, thereby
protecting privacy of users. Mobile users in FL systems typically communicate
with base stations (BSs) via wireless channels, where training performance
could be degraded due to unreliable access caused by user mobility. However,
existing work only investigates a static scenario or random initialization of
user locations, which fail to capture mobility in real-world networks. To
tackle this issue, we propose a practical model for user mobility in FL across
multiple BSs, and develop a user scheduling and resource allocation method to
minimize the training delay with constrained communication resources.
Specifically, we first formulate an optimization problem with user mobility
that jointly considers user selection, BS assignment to users, and bandwidth
allocation to minimize the latency in each communication round. This
optimization problem turned out to be NP-hard and we proposed a delay-aware
greedy search algorithm (DAGSA) to solve it. Simulation results show that the
proposed algorithm achieves better performance than the state-of-the-art
baselines and a certain level of user mobility could improve training
performance.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Adaptive Topological Feature via Persistent Homology: Filtration  Learning for Point Clouds</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09259</p>
  <p><b>作者</b>：Naoki Nishikawa,  Yuichi Ike,  Kenji Yamanishi</p>
  <p><b>备注</b>：17 pages with 4 figures</p>
  <p><b>关键词</b>：machine learning methods, Machine learning, attracting much attention, material science, persistent homology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning for point clouds has been attracting much attention, with
many applications in various fields, such as shape recognition and material
science. To enhance the accuracy of such machine learning methods, it is known
to be effective to incorporate global topological features, which are typically
extracted by persistent homology. In the calculation of persistent homology for
a point cloud, we need to choose a filtration for the point clouds, an
increasing sequence of spaces. Because the performance of machine learning
methods combined with persistent homology is highly affected by the choice of a
filtration, we need to tune it depending on data and tasks. In this paper, we
propose a framework that learns a filtration adaptively with the use of neural
networks. In order to make the resulting persistent homology
isometry-invariant, we develop a neural network architecture with such
invariance. Additionally, we theoretically show a finite-dimensional
approximation result that justifies our architecture. Experimental results
demonstrated the efficacy of our framework in several classification tasks.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：PAC Neural Prediction Set Learning to Quantify the Uncertainty of  Generative Language Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09254</p>
  <p><b>作者</b>：Sangdon Park,  Taesoo Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crucial tasks, tasks to enhance, enhance the trustworthiness, prediction set models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty learning and quantification of models are crucial tasks to
enhance the trustworthiness of the models. Importantly, the recent surge of
generative language models (GLMs) emphasizes the need for reliable uncertainty
quantification due to the concerns on generating hallucinated facts. In this
paper, we propose to learn neural prediction set models that comes with the
probably approximately correct (PAC) guarantee for quantifying the uncertainty
of GLMs. Unlike existing prediction set models, which are parameterized by a
scalar value, we propose to parameterize prediction sets via neural networks,
which achieves more precise uncertainty quantification but still satisfies the
PAC guarantee. We demonstrate the efficacy of our method on four types of
language datasets and six types of models by showing that our method improves
the quantified uncertainty by $63\%$ on average, compared to a standard
baseline method.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular  Data</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09249</p>
  <p><b>作者</b>：Yazheng Yang,  Yuqi Wang,  Guang Liu,  Ledell Wu,  Qi Liu</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, yielding impressive outcomes, advancements in Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Natural Language Processing (NLP) have witnessed the
groundbreaking impact of pretrained models, yielding impressive outcomes across
various tasks. This study seeks to extend the power of pretraining
methodologies to tabular data, a domain traditionally overlooked, yet
inherently challenging due to the plethora of table schemas intrinsic to
different tasks. The primary research questions underpinning this work revolve
around the adaptation to heterogeneous table structures, the establishment of a
universal pretraining protocol for tabular data, the generalizability and
transferability of learned knowledge across tasks, the adaptation to diverse
downstream applications, and the incorporation of incremental columns over
time. In response to these challenges, we introduce UniTabE, a pioneering
method designed to process tables in a uniform manner, devoid of constraints
imposed by specific table structures. UniTabE's core concept relies on
representing each basic table element with a module, termed TabUnit. This is
subsequently followed by a Transformer encoder to refine the representation.
Moreover, our model is designed to facilitate pretraining and finetuning
through the utilization of free-form prompts. In order to implement the
pretraining phase, we curated an expansive tabular dataset comprising
approximately 13 billion samples, meticulously gathered from the Kaggle
platform. Rigorous experimental testing and analyses were performed under a
myriad of scenarios to validate the effectiveness of our methodology. The
experimental results demonstrate UniTabE's superior performance against several
baseline models across a multitude of benchmark datasets. This, therefore,
underscores UniTabE's potential to significantly enhance the semantic
representation of tabular data, thereby marking a significant stride in the
field of tabular data analysis.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Application of BERT in Wind Power Forecasting-Teletraan's Solution in  Baidu KDD Cup 2022</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09248</p>
  <p><b>作者</b>：Longxing Tan,  Hongying Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：drawn increasing attention, sustainable development, energy has drawn, drawn increasing, increasing attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, wind energy has drawn increasing attention as its important role in
carbon neutrality and sustainable development. When wind power is integrated
into the power grid, precise forecasting is necessary for the sustainability
and security of the system. However, the unpredictable nature and long sequence
prediction make it especially challenging. In this technical report, we
introduce the BERT model applied for Baidu KDD Cup 2022, and the daily
fluctuation is added by post-processing to make the predicted results in line
with daily periodicity. Our solution achieves 3rd place of 2490 teams. The code
is released athttps://github.com/LongxingTan/KDD2022-Baidu</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Towards Sustainable Deep Learning for Multi-Label Classification on NILM</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09244</p>
  <p><b>作者</b>：Anže Pirnat,  Blaž Bertalanič,  Gregor Cerar,  Mihael Mohorčič,  Carolina Fortuna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Non-intrusive load monitoring, measuring total electricity, total electricity consumption, single metering point, obtaining appliance-level data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-intrusive load monitoring (NILM) is the process of obtaining
appliance-level data from a single metering point, measuring total electricity
consumption of a household or a business. Appliance-level data can be directly
used for demand response applications and energy management systems as well as
for awareness raising and motivation for improvements in energy efficiency and
reduction in the carbon footprint. Recently, classical machine learning and
deep learning (DL) techniques became very popular and proved as highly
effective for NILM classification, but with the growing complexity these
methods are faced with significant computational and energy demands during both
their training and operation. In this paper, we introduce a novel DL model
aimed at enhanced multi-label classification of NILM with improved computation
and energy efficiency. We also propose a testing methodology for comparison of
different models using data synthesized from the measurement datasets so as to
better represent real-world scenarios. Compared to the state-of-the-art, the
proposed model has its carbon footprint reduced by more than 23% while
providing on average approximately 8 percentage points in performance
improvement when testing on data derived from REFIT and UK-DALE datasets.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Fusing Hand and Body Skeletons for Human Action Recognition in Assembly</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09238</p>
  <p><b>作者</b>：Dustin Aganian,  Mona Köhler,  Benedict Stephan,  Markus Eisenbach,  Horst-Michael Gross</p>
  <p><b>备注</b>：International Conference on Artificial Neural Networks (ICANN) 2023</p>
  <p><b>关键词</b>：effective human-robot collaboration, collaborative robots, continue to gain, industrial manufacturing, effective human-robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As collaborative robots (cobots) continue to gain popularity in industrial
manufacturing, effective human-robot collaboration becomes crucial. Cobots
should be able to recognize human actions to assist with assembly tasks and act
autonomously. To achieve this, skeleton-based approaches are often used due to
their ability to generalize across various people and environments. Although
body skeleton approaches are widely used for action recognition, they may not
be accurate enough for assembly actions where the worker's fingers and hands
play a significant role. To address this limitation, we propose a method in
which less detailed body skeletons are combined with highly detailed hand
skeletons. We investigate CNNs and transformers, the latter of which are
particularly adept at extracting and combining important information from both
skeleton types using attention. This paper demonstrates the effectiveness of
our proposed approach in enhancing action recognition in assembly scenarios.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Detecting Throat Cancer from Speech Signals Using Machine Learning: A  Reproducible Literature Review</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09230</p>
  <p><b>作者</b>：Mary Paterson,  James Moor,  Luisa Cutillo</p>
  <p><b>备注</b>：19 pages, 10 figures</p>
  <p><b>关键词</b>：artificial intelligence, work we perform, perform a scoping, scoping review, current literature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we perform a scoping review of the current literature on the
detection of throat cancer from speech recordings using machine learning and
artificial intelligence. We find 22 papers within this area and discuss their
methods and results. We split these papers into two groups - nine performing
binary classification, and 13 performing multi-class classification. The papers
present a range of methods with neural networks being most commonly
implemented. Many features are also extracted from the audio before
classification, with the most common bring mel-frequency cepstral coefficients.
None of the papers found in this search have associated code repositories and
as such are not reproducible. Therefore, we create a publicly available code
repository of our own classifiers. We use transfer learning on a multi-class
problem, classifying three pathologies and healthy controls. Using this
technique we achieve an unweighted average recall of 53.54%, sensitivity of
83.14%, and specificity of 64.00%. We compare our classifiers with the results
obtained on the same dataset and find similar results.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual  Learning</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09218</p>
  <p><b>作者</b>：Zhenyi Wang,  Enneng Yang,  Li Shen,  Heng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previously acquired information, Forgetting, loss or deterioration, deterioration of previously, previously acquired</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forgetting refers to the loss or deterioration of previously acquired
information or knowledge. While the existing surveys on forgetting have
primarily focused on continual learning, forgetting is a prevalent phenomenon
observed in various other research domains within deep learning. Forgetting
manifests in research fields such as generative models due to generator shifts,
and federated learning due to heterogeneous data distributions across clients.
Addressing forgetting encompasses several challenges, including balancing the
retention of old task knowledge with fast learning of new tasks, managing task
interference with conflicting goals, and preventing privacy leakage, etc.
Moreover, most existing surveys on continual learning implicitly assume that
forgetting is always harmful. In contrast, our survey argues that forgetting is
a double-edged sword and can be beneficial and desirable in certain cases, such
as privacy-preserving scenarios. By exploring forgetting in a broader context,
we aim to present a more nuanced understanding of this phenomenon and highlight
its potential advantages. Through this comprehensive survey, we aspire to
uncover potential solutions by drawing upon ideas and approaches from various
fields that have dealt with forgetting. By examining forgetting beyond its
conventional boundaries, in future work, we hope to encourage the development
of novel strategies for mitigating, harnessing, or even embracing forgetting in
real applications. A comprehensive list of papers about forgetting in various
research fields is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：How Many Neurons Does it Take to Approximate the Maximum?</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09212</p>
  <p><b>作者</b>：Itay Safran,  Daniel Reichman,  Paul Valiant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maximum function, ReLU activations, depth, basic setting, neural network needed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the size of a neural network needed to approximate the maximum
function over $d$ inputs, in the most basic setting of approximating with
respect to the $L_2$ norm, for continuous distributions, for a network that
uses ReLU activations. We provide new lower and upper bounds on the width
required for approximation across various depths. Our results establish new
depth separations between depth 2 and 3, and depth 3 and 5 networks, as well as
providing a depth $\mathcal{O}(\log(\log(d)))$ and width $\mathcal{O}(d)$
construction which approximates the maximum function, significantly improving
upon the depth requirements of the best previously known bounds for networks
with linearly-bounded width. Our depth separation results are facilitated by a
new lower bound for depth 2 networks approximating the maximum function over
the uniform distribution, assuming an exponential upper bound on the size of
the weights. Furthermore, we are able to use this depth 2 lower bound to
provide tight bounds on the number of neurons needed to approximate the maximum
by a depth 3 network. Our lower bounds are of potentially broad interest as
they apply to the widely studied and used \emph{max} function, in contrast to
many previous results that base their bounds on specially constructed or
pathological functions and distributions.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Automated Ableism: An Exploration of Explicit Disability Biases in  Sentiment and Toxicity Analysis Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09209</p>
  <p><b>作者</b>：Pranav Narayanan Venkit,  Mukund Srinath,  Shomir Wilson</p>
  <p><b>备注</b>：TrustNLP at ACL 2023</p>
  <p><b>关键词</b>：Perturbation Sensitivity Analysis, analyze sentiment analysis, Twitter and Reddit, Perturbation Sensitivity, sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze sentiment analysis and toxicity detection models to detect the
presence of explicit bias against people with disability (PWD). We employ the
bias identification framework of Perturbation Sensitivity Analysis to examine
conversations related to PWD on social media platforms, specifically Twitter
and Reddit, in order to gain insight into how disability bias is disseminated
in real-world social settings. We then create the \textit{Bias Identification
Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any
sentiment analysis and toxicity detection models. Our study utilizes BITS to
uncover significant biases in four open AIaaS (AI as a Service) sentiment
analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,
DistilBERT and two toxicity detection models, namely two versions of
Toxic-BERT. Our findings indicate that all of these models exhibit
statistically significant explicit bias against PWD.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Context-Conditional Navigation with a Learning-Based Terrain- and  Robot-Aware Dynamics Model</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09206</p>
  <p><b>作者</b>：Suresh Guttikonda,  Jan Achterhold,  Haolong Li,  Joschka Boedecker,  Joerg Stueckler</p>
  <p><b>备注</b>：\copyright 2023 IEEE. To be presented at the 2023 European Conference on Mobile Robots (ECMR)</p>
  <p><b>关键词</b>：robot, friction coefficients, Terrain, variations, friction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In autonomous navigation settings, several quantities can be subject to
variations. Terrain properties such as friction coefficients may vary over time
depending on the location of the robot. Also, the dynamics of the robot may
change due to, e.g., different payloads, changing the system's mass, or wear
and tear, changing actuator gains or joint friction. An autonomous agent should
thus be able to adapt to such variations. In this paper, we develop a novel
probabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN,
which is able to adapt to the above-mentioned variations. It builds on recent
advances in meta-learning forward dynamics models based on Neural Processes. We
evaluate our method in a simulated 2D navigation setting with a unicycle-like
robot and different terrain layouts with spatially varying friction
coefficients. In our experiments, the proposed model exhibits lower prediction
error for the task of long-horizon trajectory prediction, compared to
non-adaptive ablation models. We also evaluate our model on the downstream task
of navigation planning, which demonstrates improved performance in planning
control-efficient paths by taking robot and terrain properties into account.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Learning Dynamic Attribute-factored World Models for Efficient  Multi-object Reinforcement Learning</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09205</p>
  <p><b>作者</b>：Fan Feng,  Sara Magliacane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：types and generalize, combinations and numbers, reinforcement learning tasks, objects, tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many reinforcement learning tasks, the agent has to learn to interact with
many objects of different types and generalize to unseen combinations and
numbers of objects. Often a task is a composition of previously learned tasks
(e.g. block stacking). These are examples of compositional generalization, in
which we compose object-centric representations to solve complex tasks. Recent
works have shown the benefits of object-factored representations and
hierarchical abstractions for improving sample efficiency in these settings. On
the other hand, these methods do not fully exploit the benefits of
factorization in terms of object attributes. In this paper, we address this
opportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL)
framework. In DAFT-RL, we leverage object-centric representation learning to
extract objects from visual inputs. We learn to classify them in classes and
infer their latent parameters. For each class of object, we learn a class
template graph that describes how the dynamics and reward of an object of this
class factorize according to its attributes. We also learn an interaction
pattern graph that describes how objects of different classes interact with
each other at the attribute level. Through these graphs and a dynamic
interaction graph that models the interactions between objects, we can learn a
policy that can then be directly applied in a new environment by just
estimating the interactions and latent parameters. We evaluate DAFT-RL in three
benchmark datasets and show our framework outperforms the state-of-the-art in
generalizing across unseen objects with varying attributes and latent
parameters, as well as in the composition of previously learned tasks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：A benchmark of categorical encoders for binary classification</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09191</p>
  <p><b>作者</b>：Federico Matteucci,  Vadim Arzamasov,  Klemens Boehm</p>
  <p><b>备注</b>：Submitted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：machine learning models, transform categorical features, learning models, Categorical encoders transform, encoders transform categorical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Categorical encoders transform categorical features into numerical
representations that are indispensable for a wide range of machine learning
models. Existing encoder benchmark studies lack generalizability because of
their limited choice of (1) encoders, (2) experimental factors, and (3)
datasets. Additionally, inconsistencies arise from the adoption of varying
aggregation strategies. This paper is the most comprehensive benchmark of
categorical encoders to date, including an extensive evaluation of 32
configurations of encoders from diverse families, with 36 combinations of
experimental factors, and on 50 datasets. The study shows the profound
influence of dataset selection, experimental factors, and aggregation
strategies on the benchmark's conclusions -- aspects disregarded in previous
encoder benchmarks.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Federated Learning for Computationally-Constrained Heterogeneous  Devices: A Survey</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09182</p>
  <p><b>作者</b>：Kilian Pfeiffer,  Martin Rapp,  Ramin Khalili,  Jörg Henkel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：internet of things, offloadingtraining of neural, neural networks, increasing number, number of smart</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With an increasing number of smart devices like internet of things (IoT)
devices deployed in the field, offloadingtraining of neural networks (NNs) to a
central server becomes more and more infeasible. Recent efforts toimprove
users' privacy have led to on-device learning emerging as an alternative.
However, a model trainedonly on a single device, using only local data, is
unlikely to reach a high accuracy. Federated learning (FL)has been introduced
as a solution, offering a privacy-preserving trade-off between communication
overheadand model accuracy by sharing knowledge between devices but disclosing
the devices' private data. Theapplicability and the benefit of applying
baseline FL are, however, limited in many relevant use cases dueto the
heterogeneity present in such environments. In this survey, we outline the
heterogeneity challengesFL has to overcome to be widely applicable in
real-world applications. We especially focus on the aspect ofcomputation
heterogeneity among the participating devices and provide a comprehensive
overview of recentworks on heterogeneity-aware FL. We discuss two groups: works
that adapt the NN architecture and worksthat approach heterogeneity on a system
level, covering Federated Averaging (FedAvg), distillation, and
splitlearning-based approaches, as well as synchronous and asynchronous
aggregation schemes.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Towards Trustworthy Dataset Distillation</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09165</p>
  <p><b>作者</b>：Shijie Ma,  Fei Zhu,  Zhen Cheng,  Xu-Yao Zhang</p>
  <p><b>备注</b>：20 pages, 20 figures</p>
  <p><b>关键词</b>：applying deep learning, real-world applications, eternal pursuits, pursuits when applying, applying deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficiency and trustworthiness are two eternal pursuits when applying deep
learning in real-world applications. With regard to efficiency, dataset
distillation (DD) endeavors to reduce training costs by distilling the large
dataset into a tiny synthetic dataset. However, existing methods merely
concentrate on in-distribution (InD) classification in a closed-world setting,
disregarding out-of-distribution (OOD) samples. On the other hand, OOD
detection aims to enhance models' trustworthiness, which is always
inefficiently achieved in full-data settings. For the first time, we
simultaneously consider both issues and propose a novel paradigm called
Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and
outliers, the condensed datasets are capable to train models competent in both
InD classification and OOD detection. To alleviate the requirement of real
outlier data and make OOD detection more practical, we further propose to
corrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier
Exposure (POE). Comprehensive experiments on various settings demonstrate the
effectiveness of TrustDD, and the proposed POE surpasses state-of-the-art
method Outlier Exposure (OE). Compared with the preceding DD, TrustDD is more
trustworthy and applicable to real open-world scenarios. Our code will be
publicly available.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset,  Methods, and Results</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09143</p>
  <p><b>作者</b>：Yuki Kondo,  Norimichi Ukita,  Takayuki Yamaguchi,  Hao-Yu Hou,  Mu-Yi Shen,  Chia-Chi Hsu,  En-Ming Huang,  Yu-Chen Huang,  Yu-Cheng Xia,  Chien-Yao Wang,  Chun-Yi Lee,  Da Huo,  Marc A. Kastner,  Tingwei Liu,  Yasutomo Kawanishi,  Takatsugu Hirayama,  Takahiro Komamizu,  Ichiro Ide,  Yosuke Shinya,  Xinyao Liu,  Guang Liang,  Syusuke Yasui</p>
  <p><b>备注</b>：This paper is included in the proceedings of the 18th International Conference on Machine Vision Applications (MVA2023). It will be officially published at a later date. Project page : this https URL</p>
  <p><b>关键词</b>：Small Object Detection, require object detection, applications require object, important machine vision, machine vision topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Small Object Detection (SOD) is an important machine vision topic because (i)
a variety of real-world applications require object detection for distant
objects and (ii) SOD is a challenging task due to the noisy, blurred, and
less-informative image appearances of small objects. This paper proposes a new
SOD dataset consisting of 39,070 images including 137,121 bird instances, which
is called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The
detail of the challenge with the SOD4SB dataset is introduced in this paper. In
total, 223 participants joined this challenge. This paper briefly introduces
the award-winning methods. The dataset, the baseline code, and the website for
evaluation on the public testset are publicly available.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Mining of Single-Class by Active Learning for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09109</p>
  <p><b>作者</b>：Hugues Lambert,  Emma Slade</p>
  <p><b>备注</b>：29 pages, 14 figures, 2 tables</p>
  <p><b>关键词</b>：Active Learning, policies require retraining, informative samples, retraining a target, times in order</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several Active Learning (AL) policies require retraining a target model
several times in order to identify the most informative samples and rarely
offer the option to focus on the acquisition of samples from underrepresented
classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm
is introduced where an AL policy is constructed through deep reinforcement
learning and exploits quantity-accuracy correlations to build datasets on which
high-performance models can be trained with regards to specific classes.
MiSiCAL is especially helpful in the case of very large batch sizes since it
does not require repeated model training sessions as is common in other AL
methods. This is thanks to its ability to exploit fixed representations of the
candidate data points. We find that MiSiCAL is able to outperform a random
policy on 150 out of 171 COCO10k classes, while the strongest baseline only
outperforms random on 101 classes.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related  Rewards</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09093</p>
  <p><b>作者</b>：Saeed Ghoorchian,  Setareh Maghsudi</p>
  <p><b>备注</b>：33 pages, 9 figures. arXiv admin note: text overlap with arXiv:2212.12923</p>
  <p><b>关键词</b>：long feedback delays, Sequential decision-making, delays, optimal collective reward, feedback delays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sequential decision-making under uncertainty is often associated with long
feedback delays. Such delays degrade the performance of the learning agent in
identifying a subset of arms with the optimal collective reward in the long
run. This problem becomes significantly challenging in a non-stationary
environment with structural dependencies amongst the reward distributions
associated with the arms. Therefore, besides adapting to delays and
environmental changes, learning the causal relations alleviates the adverse
effects of feedback delay on the decision-making process. We formalize the
described setting as a non-stationary and delayed combinatorial semi-bandit
problem with causally related rewards. We model the causal relations by a
directed graph in a stationary structural equation model. The agent maximizes
the long-term average payoff, defined as a linear function of the base arms'
rewards. We develop a policy that learns the structural dependencies from
delayed feedback and utilizes that to optimize the decision-making while
adapting to drifts. We prove a regret bound for the performance of the proposed
algorithm. Besides, we evaluate our method via numerical analysis using
synthetic and real-world datasets to detect the regions that contribute the
most to the spread of Covid-19 in Italy.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：A Federated learning model for Electric Energy management using  Blockchain Technology</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09080</p>
  <p><b>作者</b>：Muhammad Shoaib Farooq,  Azeen Ahmed Hayat</p>
  <p><b>备注</b>：14 figures, 7 tables, 15 pages</p>
  <p><b>关键词</b>：electricity load shedding, Energy, developing countries, shortfall and electricity, electricity load</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Energy shortfall and electricity load shedding are the main problems for
developing countries. The main causes are lack of management in the energy
sector and the use of non-renewable energy sources. The improved energy
management and use of renewable sources can be significant to resolve energy
crisis. It is necessary to increase the use of renewable energy sources (RESs)
to meet the increasing energy demand due to high prices of fossil-fuel based
energy. Federated learning (FL) is the most emerging technique in the field of
artificial intelligence. Federated learning helps to generate global model at
server side by ensemble locally trained models at remote edges sites while
preserving data privacy. The global model used to predict energy demand to
satisfy the needs of consumers. In this article, we have proposed Blockchain
based safe distributed ledger technology for transaction of data between
prosumer and consumer to ensure their transparency, traceability and security.
Furthermore, we have also proposed a Federated learning model to forecast the
energy requirements of consumer and prosumer. Moreover, Blockchain has been
used to store excess energy data from prosumer for better management of energy
between prosumer and grid. Lastly, the experiment results revealed that
renewable energy sources have produced better and comparable results to other
non-renewable energy resources.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：DiTTO: Diffusion-inspired Temporal Transformer Operator</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09072</p>
  <p><b>作者</b>：Oded Ovadia,  Eli Turkel,  Adar Kahana,  George Em Karniadakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Solving partial differential, partial differential equations, Solving partial, increasingly common, partial differential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving partial differential equations (PDEs) using a data-driven approach
has become increasingly common. The recent development of the operator learning
paradigm has enabled the solution of a broader range of PDE-related problems.
We propose an operator learning method to solve time-dependent PDEs
continuously in time without needing any temporal discretization. The proposed
approach, named DiTTO, is inspired by latent diffusion models. While diffusion
models are usually used in generative artificial intelligence tasks, their
time-conditioning mechanism is extremely useful for PDEs. The
diffusion-inspired framework is combined with elements from the Transformer
architecture to improve its capabilities.
We demonstrate the effectiveness of the new approach on a wide variety of
PDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D
Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO
achieves state-of-the-art results in terms of accuracy for these problems. We
also present a method to improve the performance of DiTTO by using fast
sampling concepts from diffusion models. Finally, we show that DiTTO can
accurately perform zero-shot super-resolution in time.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning Adaptive Neighborhoods for Graph Neural Networks</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09065</p>
  <p><b>作者</b>：Avishkar Saha,  Oscar Mendez,  Chris Russell,  Richard Bowden</p>
  <p><b>备注</b>：ICCV 2023</p>
  <p><b>关键词</b>：Graph convolutional networks, graph structured data, convolutional networks, structured data, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph convolutional networks (GCNs) enable end-to-end learning on graph
structured data. However, many works assume a given graph structure. When the
input graph is noisy or unavailable, one approach is to construct or learn a
latent graph structure. These methods typically fix the choice of node degree
for the entire graph, which is suboptimal. Instead, we propose a novel
end-to-end differentiable graph generator which builds graph topologies where
each node selects both its neighborhood and its size. Our module can be readily
integrated into existing pipelines involving graph convolution operations,
replacing the predetermined or existing adjacency matrix with one that is
learned, and optimized, as part of the general objective. As such it is
applicable to any GCN. We integrate our module into trajectory prediction,
point cloud classification and node classification pipelines resulting in
improved accuracy over other structure-learning methods across a wide range of
datasets and GCN backbones.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Constructing Extreme Learning Machines with zero Spectral Bias</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09759</p>
  <p><b>作者</b>：Kaumudi Joshi,  Vukka Snigdha,  Arya Kumar Bhattacharya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Neural Network, feedforward Artificial Neural, Informed Neural Networks, Physics Informed Neural, higher frequency components</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The phenomena of Spectral Bias, where the higher frequency components of a
function being learnt in a feedforward Artificial Neural Network (ANN) are seen
to converge more slowly than the lower frequencies, is observed ubiquitously
across ANNs. This has created technology challenges in fields where resolution
of higher frequencies is crucial, like in Physics Informed Neural Networks
(PINNs). Extreme Learning Machines (ELMs) that obviate an iterative solution
process which provides the theoretical basis of Spectral Bias (SB), should in
principle be free of the same. This work verifies the reliability of this
assumption, and shows that it is incorrect. However, the structure of ELMs
makes them naturally amenable to implementation of variants of Fourier Feature
Embeddings, which have been shown to mitigate SB in ANNs. This approach is
implemented and verified to completely eliminate SB, thus bringing into
feasibility the application of ELMs for practical problems like PINNs where
resolution of higher frequencies is essential.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Improved Distribution Matching for Dataset Condensation</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09742</p>
  <p><b>作者</b>：Ganlong Zhao,  Guanbin Li,  Yipeng Qin,  Yizhou Yu</p>
  <p><b>备注</b>：CVPR2023</p>
  <p><b>关键词</b>：deep learning applications, Dataset Condensation aims, Dataset Condensation, learning applications, maintaining its ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dataset Condensation aims to condense a large dataset into a smaller one
while maintaining its ability to train a well-performing model, thus reducing
the storage cost and training effort in deep learning applications. However,
conventional dataset condensation methods are optimization-oriented and
condense the dataset by performing gradient or parameter matching during model
optimization, which is computationally intensive even on small datasets and
models. In this paper, we propose a novel dataset condensation method based on
distribution matching, which is more efficient and promising. Specifically, we
identify two important shortcomings of naive distribution matching (i.e.,
imbalanced feature numbers and unvalidated embeddings for distance computation)
and address them with three novel techniques (i.e., partitioning and expansion
augmentation, efficient and enriched model sampling, and class-aware
distribution regularization). Our simple yet effective method outperforms most
previous optimization-oriented methods with much fewer computational resources,
thereby scaling data condensation to larger datasets and models. Extensive
experiments demonstrate the effectiveness of our method. Codes are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09706</p>
  <p><b>作者</b>：Tianjian Gao,  Phillipe Langlais</p>
  <p><b>备注</b>：15th International Conference on Computational Semantics (IWCS), Association for Computational Linguistics (ACL)</p>
  <p><b>关键词</b>：essential knowledge representation, knowledge representation, resort to manual, automatic taxonomy construction, essential knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taxonomies are an essential knowledge representation, yet most studies on
automatic taxonomy construction (ATC) resort to manual evaluation to score
proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just
as important as taxonomy construction. We propose RaTE, an automatic label-free
taxonomy scoring procedure, which relies on a large pre-trained language model.
We apply our evaluation procedure to three state-of-the-art ATC algorithms with
which we built seven taxonomies from the Yelp domain, and show that 1) RaTE
correlates well with human judgments and 2) artificially degrading a taxonomy
leads to decreasing RaTE score.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Efficient Guided Generation for LLMs</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09702</p>
  <p><b>作者</b>：Brandon T. Willard,  Rémi Louf</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：guiding language model, language model text, model text generation, context-free grammars, article we describe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article we describe an efficient approach to guiding language model
text generation with regular expressions and context-free grammars. Our
approach adds little to no overhead to the token sequence generation process,
and makes guided generation feasible in practice. An implementation is provided
in the open source Python library Outlines.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：STRAPPER: Preference-based Reinforcement Learning via Self-training  Augmentation and Peer Regularization</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09692</p>
  <p><b>作者</b>：Yachen Kang,  Li He,  Jinxin Liu,  Zifeng Zhuang,  Donglin Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Preference-based reinforcement learning, binary human preference, complex reward function, Preference-based reinforcement, promises to learn</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Preference-based reinforcement learning (PbRL) promises to learn a complex
reward function with binary human preference. However, such human-in-the-loop
formulation requires considerable human effort to assign preference labels to
segment pairs, hindering its large-scale applications. Recent approache has
tried to reuse unlabeled segments, which implicitly elucidates the distribution
of segments and thereby alleviates the human effort. And consistency
regularization is further considered to improve the performance of
semi-supervised learning. However, we notice that, unlike general
classification tasks, in PbRL there exits a unique phenomenon that we defined
as similarity trap in this paper. Intuitively, human can have diametrically
opposite preferredness for similar segment pairs, but such similarity may trap
consistency regularization fail in PbRL. Due to the existence of similarity
trap, such consistency regularization improperly enhances the consistency
possiblity of the model's predictions between segment pairs, and thus reduces
the confidence in reward learning, since the augmented distribution does not
match with the original one in PbRL. To overcome such issue, we present a
self-training method along with our proposed peer regularization, which
penalizes the reward model memorizing uninformative labels and acquires
confident predictions. Empirically, we demonstrate that our approach is capable
of learning well a variety of locomotion and robotic manipulation behaviors
using different semi-supervised alternatives and peer regularization.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Joint Service Caching, Communication and Computing Resource Allocation  in Collaborative MEC Systems: A DRL-based Two-timescale Approach</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09691</p>
  <p><b>作者</b>：Qianqian Liu,  Haixia Zhang,  Xin Zhang,  Dongfeng Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multiaccess Edge Computing, limited multidimensional resources, Edge Computing, Multiaccess Edge, strict Quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meeting the strict Quality of Service (QoS) requirements of terminals has
imposed a signiffcant challenge on Multiaccess Edge Computing (MEC) systems,
due to the limited multidimensional resources. To address this challenge, we
propose a collaborative MEC framework that facilitates resource sharing between
the edge servers, and with the aim to maximize the long-term QoS and reduce the
cache switching cost through joint optimization of service caching,
collaborative offfoading, and computation and communication resource
allocation. The dual timescale feature and temporal recurrence relationship
between service caching and other resource allocation make solving the problem
even more challenging. To solve it, we propose a deep reinforcement learning
(DRL)-based dual timescale scheme, called DGL-DDPG, which is composed of a
short-term genetic algorithm (GA) and a long short-term memory network-based
deep deterministic policy gradient (LSTM-DDPG). In doing so, we reformulate the
optimization problem as a Markov decision process (MDP) where the
small-timescale resource allocation decisions generated by an improved GA are
taken as the states and input into a centralized LSTM-DDPG agent to generate
the service caching decision for the large-timescale. Simulation results
demonstrate that our proposed algorithm outperforms the baseline algorithms in
terms of the average QoS and cache switching cost.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for  Recommendation and Text Generation</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09688</p>
  <p><b>作者</b>：Wei Jin,  Haitao Mao,  Zheng Li,  Haoming Jiang,  Chen Luo,  Hongzhi Wen,  Haoyu Han,  Hanqing Lu,  Zhengyang Wang,  Ruirui Li,  Zhen Li,  Monica Xiao Cheng,  Rahul Goutam,  Haiyang Zhang,  Karthik Subbian,  Suhang Wang,  Yizhou Sun,  Jiliang Tang,  Bing Yin,  Xianfeng Tang</p>
  <p><b>备注</b>：Dataset for KDD Cup 2023, this https URL</p>
  <p><b>关键词</b>：impacts user experience, directly impacts user, Modeling customer shopping, customer shopping intentions, experience and engagement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling customer shopping intentions is a crucial task for e-commerce, as it
directly impacts user experience and engagement. Thus, accurately understanding
customer preferences is essential for providing personalized recommendations.
Session-based recommendation, which utilizes customer session data to predict
their next interaction, has become increasingly popular. However, existing
session datasets have limitations in terms of item attributes, user diversity,
and dataset scale. As a result, they cannot comprehensively capture the
spectrum of user behaviors and preferences. To bridge this gap, we present the
Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It
is the first multilingual dataset consisting of millions of user sessions from
six different locales, where the major languages of products are English,
German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can
help us enhance personalization and understanding of user preferences, which
can benefit various existing tasks as well as enable new tasks. To test the
potential of the dataset, we introduce three tasks in this work: (1)
next-product recommendation, (2) next-product recommendation with domain
shifts, and (3) next-product title generation. With the above tasks, we
benchmark a range of algorithms on our proposed dataset, drawing new insights
for further research and practice. In addition, based on the proposed dataset
and tasks, we hosted a competition in the KDD CUP 2023 and have attracted
thousands of users and submissions. The winning solutions and the associated
workshop can be accessed at our website this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Convex Geometry of ReLU-layers, Injectivity on the Ball and Local  Reconstruction</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09672</p>
  <p><b>作者</b>：Daniel Haider,  Martin Ehler,  Peter Balazs</p>
  <p><b>备注</b>：10 pages main paper + 2 pages appendix, 4 figures, 2 algorithms, conference</p>
  <p><b>关键词</b>：frame-theoretic setting, setting to study, study the injectivity, bias vector, ball</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The paper uses a frame-theoretic setting to study the injectivity of a
ReLU-layer on the closed ball of $\mathbb{R}^n$ and its non-negative part. In
particular, the interplay between the radius of the ball and the bias vector is
emphasized. Together with a perspective from convex geometry, this leads to a
computationally feasible method of verifying the injectivity of a ReLU-layer
under reasonable restrictions in terms of an upper bound of the bias vector.
Explicit reconstruction formulas are provided, inspired by the duality concept
from frame theory. All this gives rise to the possibility of quantifying the
invertibility of a ReLU-layer and a concrete reconstruction algorithm for any
input vector on the ball.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：JAZZVAR: A Dataset of Variations found within Solo Piano Performances of  Jazz Standards for Music Overpainting</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09670</p>
  <p><b>作者</b>：Eleanor Row,  Jingjing Tang,  George Fazekas</p>
  <p><b>备注</b>：Pre-print accepted for publication at CMMR2023, 12 pages, 4 figures</p>
  <p><b>关键词</b>：uniquely interpret jazz, pianists often uniquely, uniquely interpret, interpret jazz standards, variation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jazz pianists often uniquely interpret jazz standards. Passages from these
interpretations can be viewed as sections of variation. We manually extracted
such variations from solo jazz piano performances. The JAZZVAR dataset is a
collection of 502 pairs of Variation and Original MIDI segments. Each Variation
in the dataset is accompanied by a corresponding Original segment containing
the melody and chords from the original jazz standard. Our approach differs
from many existing jazz datasets in the music information retrieval (MIR)
community, which often focus on improvisation sections within jazz
performances. In this paper, we outline the curation process for obtaining and
sorting the repertoire, the pipeline for creating the Original and Variation
pairs, and our analysis of the dataset. We also introduce a new generative
music task, Music Overpainting, and present a baseline Transformer model
trained on the JAZZVAR dataset for this task. Other potential applications of
our dataset include expressive performance analysis and performer
identification.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Towards A Unified Agent with Foundation Models</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09668</p>
  <p><b>作者</b>：Norman Di Palo,  Arunkumar Byravan,  Leonard Hasenclever,  Markus Wulfmeier,  Nicolas Heess,  Martin Riedmiller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vision Language Models, recently demonstrated unprecedented, demonstrated unprecedented capabilities, Language Models, understanding human intentions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models and Vision Language Models have recently demonstrated
unprecedented capabilities in terms of understanding human intentions,
reasoning, scene understanding, and planning-like behaviour, in text form,
among many others. In this work, we investigate how to embed and leverage such
abilities in Reinforcement Learning (RL) agents. We design a framework that
uses language as the core reasoning tool, exploring how this enables an agent
to tackle a series of fundamental RL challenges, such as efficient exploration,
reusing experience data, scheduling skills, and learning from observations,
which traditionally require separate, vertically designed algorithms. We test
our method on a sparse-reward simulated robotic manipulation environment, where
a robot needs to stack a set of objects. We demonstrate substantial performance
improvements over baselines in exploration efficiency and ability to reuse data
from offline datasets, and illustrate how to reuse learned skills to solve
novel tasks or imitate videos of human experts.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Anticipating Technical Expertise and Capability Evolution in Research  Communities using Dynamic Graph Transformers</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09665</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Ellyn Ayton,  Anastasiya Usenko,  Robin Cosbey,  Svitlana Volkova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evolution trends globally, capability evolution trends, anticipate technical expertise, technical capability evolution, capability evolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to anticipate technical expertise and capability evolution trends
globally is essential for national and global security, especially in
safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging
fields like artificial intelligence (AI). In this work, we extend traditional
statistical relational learning approaches (e.g., link prediction in
collaboration networks) and formulate a problem of anticipating technical
expertise and capability evolution using dynamic heterogeneous graph
representations. We develop novel capabilities to forecast collaboration
patterns, authorship behavior, and technical capability evolution at different
granularities (e.g., scientist and institution levels) in two distinct research
fields. We implement a dynamic graph transformer (DGT) neural architecture,
which pushes the state-of-the-art graph neural network models by (a)
forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b)
relying on both discrete -- and continuous -- time inputs. We demonstrate that
our DGT models predict collaboration, partnership, and expertise patterns with
0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and
0.22 for NN domains. DGT model performance exceeds the best-performing static
graph baseline models by 30-80% across AI and NN domains. Our findings
demonstrate that DGT models boost inductive task performance, when previously
unseen nodes appear in the test data, for the domains with emerging
collaboration patterns (e.g., AI). Specifically, models accurately predict
which established scientists will collaborate with early career scientists and
vice-versa in the AI domain.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Physics-based Reduced Order Modeling for Uncertainty Quantification of  Guided Wave Propagation using Bayesian Optimization</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09661</p>
  <p><b>作者</b>：G. I. Drakoulas,  T. V. Gortsas,  D. Polyzos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：structural health monitoring, digital twins, structural health, health monitoring, constitutes the backbone</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of digital twins, structural health monitoring (SHM)
constitutes the backbone of condition-based maintenance, facilitating the
interconnection between virtual and physical assets. Guided wave propagation
(GWP) is commonly employed for the inspection of structures in SHM. However,
GWP is sensitive to variations in the material properties of the structure,
leading to false alarms. In this direction, uncertainty quantification (UQ) is
regularly applied to improve the reliability of predictions. Computational
mechanics is a useful tool for the simulation of GWP, and is often applied for
UQ. Even so, the application of UQ methods requires numerous simulations, while
large-scale, transient numerical GWP solutions increase the computational cost.
Reduced order models (ROMs) are commonly employed to provide numerical results
in a limited amount of time. In this paper, we propose a machine learning
(ML)-based ROM, mentioned as BO-ML-ROM, to decrease the computational time
related to the simulation of the GWP. The ROM is integrated with a Bayesian
optimization (BO) framework, to adaptively sample the parameters for the ROM
training. The finite element method is used for the simulation of the
high-fidelity models. The formulated ROM is used for forward UQ of the GWP in
an aluminum plate with varying material properties. To determine the influence
of each parameter perturbation, a global, variance-based sensitivity analysis
is implemented based on Sobol' indices. It is shown that Bayesian optimization
outperforms one-shot sampling methods, both in terms of accuracy and speed-up.
The predicted results reveal the efficiency of BO-ML-ROM for GWP and
demonstrate its value for UQ.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Neural Priority Queues for Graph Neural Networks</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09660</p>
  <p><b>作者</b>：Rishabh Jain,  Petar Veličković,  Pietro Liò</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, shown considerable success, considerable success, Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have shown considerable success in neural
algorithmic reasoning. Many traditional algorithms make use of an explicit
memory in the form of a data structure. However, there has been limited
exploration on augmenting GNNs with external memory. In this paper, we present
Neural Priority Queues, a differentiable analogue to algorithmic priority
queues, for GNNs. We propose and motivate a desiderata for memory modules, and
show that Neural PQs exhibit the desiderata, and reason about their use with
algorithmic reasoning. This is further demonstrated by empirical results on the
CLRS-30 dataset. Furthermore, we find the Neural PQs useful in capturing
long-range interactions, as empirically shown on a dataset from the Long-Range
Graph Benchmark.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual  Learning</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09653</p>
  <p><b>作者</b>：Xiaotian Duan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：loses previously obtained, previously obtained knowledge, neural network loses, network loses previously, Catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Catastrophic forgetting, the phenomenon in which a neural network loses
previously obtained knowledge during the learning of new tasks, poses a
significant challenge in continual learning. The Hard-Attention-to-the-Task
(HAT) mechanism has shown potential in mitigating this problem, but its
practical implementation has been complicated by issues of usability and
compatibility, and a lack of support for existing network reuse. In this paper,
we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT
mechanism. HAT-CL not only automates gradient manipulation but also streamlines
the transformation of PyTorch modules into HAT modules. It achieves this by
providing a comprehensive suite of modules that can be seamlessly integrated
into existing architectures. Additionally, HAT-CL offers ready-to-use HAT
networks that are smoothly integrated with the TIMM library. Beyond the
redesign and reimplementation of HAT, we also introduce novel mask manipulation
techniques for HAT, which have consistently shown improvements across various
experiments. Our work paves the way for a broader application of the HAT
mechanism, opening up new possibilities in continual learning across diverse
models and applications.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Application of BadNets in Spam Filters</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09649</p>
  <p><b>作者</b>：Swagnik Roychoudhury,  Akshaj Kumar Veldanda</p>
  <p><b>备注</b>：5 pages, 4 figures, submitted to ICDE23 ASTRIDE, this https URL</p>
  <p><b>关键词</b>：modern email systems, potentially harmful emails, email systems, modern email, harmful emails</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spam filters are a crucial component of modern email systems, as they help to
protect users from unwanted and potentially harmful emails. However, the
effectiveness of these filters is dependent on the quality of the machine
learning models that power them. In this paper, we design backdoor attacks in
the domain of spam filtering. By demonstrating the potential vulnerabilities in
the machine learning model supply chain, we highlight the need for careful
consideration and evaluation of the models used in spam filters. Our results
show that the backdoor attacks can be effectively used to identify
vulnerabilities in spam filters and suggest the need for ongoing monitoring and
improvement in this area.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Promoting Exploration in Memory-Augmented Adam using Critical Momenta</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09638</p>
  <p><b>作者</b>：Pranshu Malviya,  Gonçalo Mordido,  Aristide Baratin,  Reza Babanezhad Harikandeh,  Jerry Huang,  Simon Lacoste-Julien,  Razvan Pascanu,  Sarath Chandar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, large-scale deep learning, training large-scale deep, Adaptive gradient-based optimizers, learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive gradient-based optimizers, particularly Adam, have left their mark
in training large-scale deep learning models. The strength of such optimizers
is that they exhibit fast convergence while being more robust to hyperparameter
choice. However, they often generalize worse than non-adaptive methods. Recent
studies have tied this performance gap to flat minima selection: adaptive
methods tend to find solutions in sharper basins of the loss landscape, which
in turn hurts generalization. To overcome this issue, we propose a new
memory-augmented version of Adam that promotes exploration towards flatter
minima by using a buffer of critical momentum terms during training.
Intuitively, the use of the buffer makes the optimizer overshoot outside the
basin of attraction if it is not wide enough. We empirically show that our
method improves the performance of several variants of Adam on standard
supervised language modelling and image classification tasks.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Towards Federated Foundation Models: Scalable Dataset Pipelines for  Group-Structured Learning</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09619</p>
  <p><b>作者</b>：Zachary Charles,  Nicole Mitchell,  Krishna Pillutla,  Michael Reneer,  Zachary Garrett</p>
  <p><b>备注</b>：Dataset Grouper is available at this https URL</p>
  <p><b>关键词</b>：enabling federated learning, foundation models, create large-scale group-structured, Dataset Grouper, Dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a library, Dataset Grouper, to create large-scale
group-structured (e.g., federated) datasets, enabling federated learning
simulation at the scale of foundation models. This library allows the creation
of group-structured versions of existing datasets based on user-specified
partitions, and directly leads to a variety of useful heterogeneous datasets
that can be plugged into existing software frameworks. Dataset Grouper offers
three key advantages. First, it scales to settings where even a single group's
dataset is too large to fit in memory. Second, it provides flexibility, both in
choosing the base (non-partitioned) dataset and in defining partitions.
Finally, it is framework-agnostic. We empirically demonstrate that Dataset
Grouper allows for large-scale federated language modeling simulations on
datasets that are orders of magnitude larger than in previous work. Our
experimental results show that algorithms like FedAvg operate more as
meta-learning methods than as empirical risk minimization methods at this
scale, suggesting their utility in downstream personalization and task-specific
adaptation.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Looking deeper into interpretable deep learning in neuroimaging: a  comprehensive survey</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09615</p>
  <p><b>作者</b>：Md. Mahfuzur Rahman,  Vince D. Calhoun,  Sergey M. Plis</p>
  <p><b>备注</b>：109 pages, 21 figures</p>
  <p><b>关键词</b>：feature extraction phase, separate error-prone feature, error-prone feature extraction, deep learning models, alleviating the concern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) models have been popular due to their ability to learn
directly from the raw data in an end-to-end paradigm, alleviating the concern
of a separate error-prone feature extraction phase. Recent DL-based
neuroimaging studies have also witnessed a noticeable performance advancement
over traditional machine learning algorithms. But the challenges of deep
learning models still exist because of the lack of transparency in these models
for their successful deployment in real-world applications. In recent years,
Explainable AI (XAI) has undergone a surge of developments mainly to get
intuitions of how the models reached the decisions, which is essential for
safety-critical domains such as healthcare, finance, and law enforcement
agencies. While the interpretability domain is advancing noticeably,
researchers are still unclear about what aspect of model learning a post hoc
method reveals and how to validate its reliability. This paper comprehensively
reviews interpretable deep learning models in the neuroimaging domain. Firstly,
we summarize the current status of interpretability resources in general,
focusing on the progression of methods, associated challenges, and opinions.
Secondly, we discuss how multiple recent neuroimaging studies leveraged model
interpretability to capture anatomical and functional brain alterations most
relevant to model predictions. Finally, we discuss the limitations of the
current practices and offer some valuable insights and guidance on how we can
steer our future research directions to make deep learning models substantially
interpretable and thus advance scientific understanding of brain disorders.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Retrieving Continuous Time Event Sequences using Neural Temporal Point  Processes with Learnable Hashing</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09613</p>
  <p><b>作者</b>：Vinayak Gupta,  Srikanta Bedathur,  Abir De</p>
  <p><b>备注</b>：Extended version of Gupta et al. [arXiv:2202.11485] (AAAI 2022). Under review in a journal</p>
  <p><b>关键词</b>：CTES, sequence, CTES retrieval, CTES datasets, query sequence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporal sequences have become pervasive in various real-world applications.
Consequently, the volume of data generated in the form of continuous time-event
sequence(s) or CTES(s) has increased exponentially in the past few years. Thus,
a significant fraction of the ongoing research on CTES datasets involves
designing models to address downstream tasks such as next-event prediction,
long-term forecasting, sequence classification etc. The recent developments in
predictive modeling using marked temporal point processes (MTPP) have enabled
an accurate characterization of several real-world applications involving the
CTESs. However, due to the complex nature of these CTES datasets, the task of
large-scale retrieval of temporal sequences has been overlooked by the past
literature. In detail, by CTES retrieval we mean that for an input query
sequence, a retrieval system must return a ranked list of relevant sequences
from a large corpus. To tackle this, we propose NeuroSeqRet, a
first-of-its-kind framework designed specifically for end-to-end CTES
retrieval. Specifically, NeuroSeqRet introduces multiple enhancements over
standard retrieval frameworks and first applies a trainable unwarping function
on the query sequence which makes it comparable with corpus sequences,
especially when a relevant query-corpus pair has individually different
attributes. Next, it feeds the unwarped query sequence and the corpus sequence
into MTPP-guided neural relevance models. We develop four variants of the
relevance model for different kinds of applications based on the trade-off
between accuracy and efficiency. We also propose an optimization framework to
learn binary sequence embeddings from the relevance scores, suitable for the
locality-sensitive hashing. Our experiments show the significant accuracy boost
of NeuroSeqRet as well as the efficacy of our hashing mechanism.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Sequential Monte Carlo Learning for Time Series Structure Discovery</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09607</p>
  <p><b>作者</b>：Feras A. Saad,  Brian J. Patton,  Matthew D. Hoffman,  Rif A. Saurous,  Vikash K. Mansinghka</p>
  <p><b>备注</b>：17 pages, 8 figures, 2 tables. Appearing in ICML 2023</p>
  <p><b>关键词</b>：sequential Monte Carlo, Gaussian process time, automatically discovering accurate, Monte Carlo, time series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new approach to automatically discovering accurate
models of complex time series data. Working within a Bayesian nonparametric
prior over a symbolic space of Gaussian process time series models, we present
a novel structure learning algorithm that integrates sequential Monte Carlo
(SMC) and involutive MCMC for highly effective posterior inference. Our method
can be used both in "online" settings, where new data is incorporated
sequentially in time, and in "offline" settings, by using nested subsets of
historical data to anneal the posterior. Empirical measurements on real-world
time series show that our method can deliver 10x--100x runtime speedups over
previous MCMC and greedy-search structure learning algorithms targeting the
same model family. We use our method to perform the first large-scale
evaluation of Gaussian process time series structure learning on a prominent
benchmark of 1,428 econometric datasets. The results show that our method
discovers sensible models that deliver more accurate point forecasts and
interval forecasts over multiple horizons as compared to widely used
statistical and neural baselines that struggle on this challenging data.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A max-affine spline approximation of neural networks using the Legendre  transform of a convex-concave representation</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09602</p>
  <p><b>作者</b>：Adam Perrett,  Danny Wood,  Gavin Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm for transforming, spline representation, work presents, work, previous work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a novel algorithm for transforming a neural network into a
spline representation. Unlike previous work that required convex and
piecewise-affine network operators to create a max-affine spline alternate
form, this work relaxes this constraint. The only constraint is that the
function be bounded and possess a well-define second derivative, although this
was shown experimentally to not be strictly necessary. It can also be performed
over the whole network rather than on each layer independently. As in previous
work, this bridges the gap between neural networks and approximation theory but
also enables the visualisation of network feature maps. Mathematical proof and
experimental investigation of the technique is performed with approximation
error and feature maps being extracted from a range of architectures, including
convolutional neural networks.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Gradient strikes back: How filtering out high frequencies improves  explanations</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09591</p>
  <p><b>作者</b>：Sabine Muzellec,  Leo Andeol,  Thomas Fel,  Rufin VanRullen,  Thomas Serre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supplanting older gradient-based, deep neural networks, methods, gradient-based methods, Recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed an explosion in the development of novel
prediction-based attribution methods, which have slowly been supplanting older
gradient-based methods to explain the decisions of deep neural networks.
However, it is still not clear why prediction-based methods outperform
gradient-based ones. Here, we start with an empirical observation: these two
approaches yield attribution maps with very different power spectra, with
gradient-based methods revealing more high-frequency content than
prediction-based methods. This observation raises multiple questions: What is
the source of this high-frequency information, and does it truly reflect
decisions made by the system? Lastly, why would the absence of high-frequency
information in prediction-based methods yield better explainability scores
along multiple metrics? We analyze the gradient of three representative visual
classification models and observe that it contains noisy information emanating
from high-frequencies. Furthermore, our analysis reveals that the operations
used in Convolutional Neural Networks (CNNs) for downsampling appear to be a
significant source of this high-frequency content -- suggesting aliasing as a
possible underlying basis. We then apply an optimal low-pass filter for
attribution maps and demonstrate that it improves gradient-based attribution
methods. We show that (i) removing high-frequency noise yields significant
improvements in the explainability scores obtained with gradient-based methods
across multiple models -- leading to (ii) a novel ranking of state-of-the-art
methods with gradient-based methods at the top. We believe that our results
will spur renewed interest in simpler and computationally more efficient
gradient-based methods for explainability.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Causal Influences over Social Learning Networks</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09575</p>
  <p><b>作者</b>：Mert Kayaalp,  Ali H. Sayed</p>
  <p><b>备注</b>：Submitted for publication</p>
  <p><b>关键词</b>：investigates causal influences, paper investigates causal, interacting over time, investigates causal, agents linked</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates causal influences between agents linked by a social
graph and interacting over time. In particular, the work examines the dynamics
of social learning models and distributed decision-making protocols, and
derives expressions that reveal the causal relations between pairs of agents
and explain the flow of influence over the network. The results turn out to be
dependent on the graph topology and the level of information that each agent
has about the inference problem they are trying to solve. Using these
conclusions, the paper proposes an algorithm to rank the overall influence
between agents to discover highly influential agents. It also provides a method
to learn the necessary model parameters from raw observational data. The
results and the proposed algorithm are illustrated by considering both
synthetic data and real Twitter data.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Self-Compatibility: Evaluating Causal Discovery without Ground Truth</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09552</p>
  <p><b>作者</b>：Philipp M. Faller (1),  Leena Chennuru Vankadara (2),  Atalanti A. Mastakouri (2),  Francesco Locatello (2),  Dominik Janzing (2) ((1) Karlsruhe Institute of Technology, (2) Amazon Research Tuebingen)</p>
  <p><b>备注</b>：28 pages, 10 figures</p>
  <p><b>关键词</b>：incredibly rare, commonly only evaluated, evaluated on simulated, causal, ground truth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As causal ground truth is incredibly rare, causal discovery algorithms are
commonly only evaluated on simulated data. This is concerning, given that
simulations reflect common preconceptions about generating processes regarding
noise distributions, model classes, and more. In this work, we propose a novel
method for falsifying the output of a causal discovery algorithm in the absence
of ground truth. Our key insight is that while statistical learning seeks
stability across subsets of data points, causal learning should seek stability
across subsets of variables. Motivated by this insight, our method relies on a
notion of compatibility between causal graphs learned on different subsets of
variables. We prove that detecting incompatibilities can falsify wrongly
inferred causal relations due to violation of assumptions or errors from finite
sample effects. Although passing such compatibility tests is only a necessary
criterion for good performance, we argue that it provides strong evidence for
the causal models whenever compatibility entails strong implications for the
joint distribution. We also demonstrate experimentally that detection of
incompatibilities can aid in causal model selection.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：The semantic landscape paradigm for neural networks</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09550</p>
  <p><b>作者</b>：Shreyas Gokhale</p>
  <p><b>备注</b>：14 pages, 4 figures</p>
  <p><b>关键词</b>：neural networks exhibit, neural networks, dataset size, Deep neural networks, exhibit a fascinating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks exhibit a fascinating spectrum of phenomena ranging from
predictable scaling laws to the unpredictable emergence of new capabilities as
a function of training time, dataset size and network size. Analysis of these
phenomena has revealed the existence of concepts and algorithms encoded within
the learned representations of these networks. While significant strides have
been made in explaining observed phenomena separately, a unified framework for
understanding, dissecting, and predicting the performance of neural networks is
lacking. Here, we introduce the semantic landscape paradigm, a conceptual and
mathematical framework that describes the training dynamics of neural networks
as trajectories on a graph whose nodes correspond to emergent algorithms that
are instrinsic to the learned representations of the networks. This abstraction
enables us to describe a wide range of neural network phenomena in terms of
well studied problems in statistical physics. Specifically, we show that
grokking and emergence with scale are associated with percolation phenomena,
and neural scaling laws are explainable in terms of the statistics of random
walks on graphs. Finally, we discuss how the semantic landscape paradigm
complements existing theoretical and practical approaches aimed at
understanding and interpreting deep neural networks.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Can Neural Network Memorization Be Localized?</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09542</p>
  <p><b>作者</b>：Pratyush Maini,  Michael C. Mozer,  Hanie Sedghi,  Zachary C. Lipton,  J. Zico Kolter,  Chiyuan Zhang</p>
  <p><b>备注</b>：Accepted at ICML 2023</p>
  <p><b>关键词</b>：deep overparametrized networks, textit, overparametrized networks, neural networks, Recent efforts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent efforts at explaining the interplay of memorization and generalization
in deep overparametrized networks have posited that neural networks
$\textit{memorize}$ "hard" examples in the final few layers of the model.
Memorization refers to the ability to correctly predict on $\textit{atypical}$
examples of the training set. In this work, we show that rather than being
confined to individual layers, memorization is a phenomenon confined to a small
set of neurons in various layers of the model. First, via three experimental
sources of converging evidence, we find that most layers are redundant for the
memorization of examples and the layers that contribute to example memorization
are, in general, not the final layers. The three sources are $\textit{gradient
accounting}$ (measuring the contribution to the gradient norms from memorized
and clean examples), $\textit{layer rewinding}$ (replacing specific model
weights of a converged model with previous training checkpoints), and
$\textit{retraining}$ (training rewound layers only on clean examples). Second,
we ask a more generic question: can memorization be localized
$\textit{anywhere}$ in a model? We discover that memorization is often confined
to a small number of neurons or channels (around 5) of the model. Based on
these insights we propose a new form of dropout -- $\textit{example-tied
dropout}$ that enables us to direct the memorization of examples to an apriori
determined set of neurons. By dropping out these neurons, we are able to reduce
the accuracy on memorized examples from $100\%\to3\%$, while also reducing the
generalization gap.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Explanation-Guided Fair Federated Learning for Transparent 6G RAN  Slicing</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09494</p>
  <p><b>作者</b>：Swastika Roy,  Hatim Chergui,  Christos Verikoukis</p>
  <p><b>备注</b>：Submitted for possible publication in IEEE</p>
  <p><b>关键词</b>：zero-touch artificial intelligence, explainable artificial intelligence, Future zero-touch artificial, quantifiable service-level agreement, key performance indicators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Future zero-touch artificial intelligence (AI)-driven 6G network automation
requires building trust in the AI black boxes via explainable artificial
intelligence (XAI), where it is expected that AI faithfulness would be a
quantifiable service-level agreement (SLA) metric along with telecommunications
key performance indicators (KPIs). This entails exploiting the XAI outputs to
generate transparent and unbiased deep neural networks (DNNs). Motivated by
closed-loop (CL) automation and explanation-guided learning (EGL), we design an
explanation-guided federated learning (EGFL) scheme to ensure trustworthy
predictions by exploiting the model explanation emanating from XAI strategies
during the training run time via Jensen-Shannon (JS) divergence. Specifically,
we predict per-slice RAN dropped traffic probability to exemplify the proposed
concept while respecting fairness goals formulated in terms of the recall
metric which is included as a constraint in the optimization task. Finally, the
comprehensiveness score is adopted to measure and validate the faithfulness of
the explanations quantitatively. Simulation results show that the proposed
EGFL-JS scheme has achieved more than $50\%$ increase in terms of
comprehensiveness compared to different baselines from the literature,
especially the variant EGFL-KL that is based on the Kullback-Leibler
Divergence. It has also improved the recall score with more than $25\%$
relatively to unconstrained-EGFL.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：PLiNIO: A User-Friendly Library of Gradient-based Methods for  Complexity-aware DNN Optimization</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09488</p>
  <p><b>作者</b>：Daniele Jahier Pagliari,  Matteo Risso,  Beatrice Alessandra Motetti,  Alessio Burrello</p>
  <p><b>备注</b>：Accepted at the 2023 Forum on Specification & Design Languages (FDL)</p>
  <p><b>关键词</b>：Deep Neural Networks, efficient Deep Neural, Neural Networks, constrained edge devices, Deep Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate yet efficient Deep Neural Networks (DNNs) are in high demand,
especially for applications that require their execution on constrained edge
devices. Finding such DNNs in a reasonable time for new applications requires
automated optimization pipelines since the huge space of hyper-parameter
combinations is impossible to explore extensively by hand. In this work, we
propose PLiNIO, an open-source library implementing a comprehensive set of
state-of-the-art DNN design automation techniques, all based on lightweight
gradient-based optimization, under a unified and user-friendly interface. With
experiments on several edge-relevant tasks, we show that combining the various
optimizations available in PLiNIO leads to rich sets of solutions that
Pareto-dominate the considered baselines in terms of accuracy vs model size.
Noteworthy, PLiNIO achieves up to 94.34% memory reduction for a <1% accuracy drop compared to a baseline architecture.< p>
  </1%></p></details>
</details>
<details>
  <summary>77. <b>标题：Submodular Maximization under the Intersection of Matroid and Knapsack  Constraints</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09487</p>
  <p><b>作者</b>：Yu-Ran Gu,  Chao Bian,  Chao Qian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Submodular maximization arises, artificial intelligence, finance and operations, research attentions, operations research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Submodular maximization arises in many applications, and has attracted a lot
of research attentions from various areas such as artificial intelligence,
finance and operations research. Previous studies mainly consider only one kind
of constraint, while many real-world problems often involve several
constraints. In this paper, we consider the problem of submodular maximization
under the intersection of two commonly used constraints, i.e., $k$-matroid
constraint and $m$-knapsack constraint, and propose a new algorithm SPROUT by
incorporating partial enumeration into the simultaneous greedy framework. We
prove that SPROUT can achieve a polynomial-time approximation guarantee better
than the state-of-the-art algorithms. Then, we introduce the random enumeration
and smooth techniques into SPROUT to improve its efficiency, resulting in the
SPROUT++ algorithm, which can keep a similar approximation guarantee.
Experiments on the applications of movie recommendation and weighted max-cut
demonstrate the superiority of SPROUT++ in practice.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：VITS : Variational Inference Thomson Sampling for contextual bandits</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10167</p>
  <p><b>作者</b>：Pierre Clavier,  Tom Huix,  Alain Durmus</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：introduce and analyze, analyze a variant, Varational Inference Thompson, Thompson sampling, Inference Thompson sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce and analyze a variant of the Thompson sampling
(TS) algorithm for contextual bandits. At each round, traditional TS requires
samples from the current posterior distribution, which is usually intractable.
To circumvent this issue, approximate inference techniques can be used and
provide samples with distribution close to the posteriors. However, current
approximate techniques yield to either poor estimation (Laplace approximation)
or can be computationally expensive (MCMC methods, Ensemble sampling...). In
this paper, we propose a new algorithm, Varational Inference Thompson sampling
VITS, based on Gaussian Variational Inference. This scheme provides powerful
posterior approximations which are easy to sample from, and is computationally
efficient, making it an ideal choice for TS. In addition, we show that VITS
achieves a sub-linear regret bound of the same order in the dimension and
number of round as traditional TS for linear contextual bandit. Finally, we
demonstrate experimentally the effectiveness of VITS on both synthetic and real
world datasets.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Quarl: A Learning-Based Quantum Circuit Optimizer</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10120</p>
  <p><b>作者</b>：Zikun Li,  Jinjun Peng,  Yixuan Mei,  Sina Lin,  Yi Wu,  Oded Padon,  Zhihao Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：final performance improvement, temporarily decrease performance, functionally equivalent circuits, Optimizing quantum circuits, performance improvement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimizing quantum circuits is challenging due to the very large search space
of functionally equivalent circuits and the necessity of applying
transformations that temporarily decrease performance to achieve a final
performance improvement. This paper presents Quarl, a learning-based quantum
circuit optimizer. Applying reinforcement learning (RL) to quantum circuit
optimization raises two main challenges: the large and varying action space and
the non-uniform state representation. Quarl addresses these issues with a novel
neural architecture and RL-training procedure. Our neural architecture
decomposes the action space into two parts and leverages graph neural networks
in its state representation, both of which are guided by the intuition that
optimization decisions can be mostly guided by local reasoning while allowing
global circuit-wide reasoning. Our evaluation shows that Quarl significantly
outperforms existing circuit optimizers on almost all benchmark circuits.
Surprisingly, Quarl can learn to perform rotation merging, a complex, non-local
circuit optimization implemented as a separate pass in existing optimizers.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Accurate deep learning sub-grid scale models for large eddy simulations</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10060</p>
  <p><b>作者</b>：Rikhi Bose,  Arunabha M. Roy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：turbulence models developed, sub-grid scale, present two families, families of sub-grid, developed for large-eddy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present two families of sub-grid scale (SGS) turbulence models developed
for large-eddy simulation (LES) purposes. Their development required the
formulation of physics-informed robust and efficient Deep Learning (DL)
algorithms which, unlike state-of-the-art analytical modeling techniques can
produce high-order complex non-linear relations between inputs and outputs.
Explicit filtering of data from direct simulations of the canonical channel
flow at two friction Reynolds numbers $Re_\tau\approx 395$ and 590 provided
accurate data for training and testing. The two sets of models use different
network architectures. One of the architectures uses tensor basis neural
networks (TBNN) and embeds the simplified analytical model form of the general
effective-viscosity hypothesis, thus incorporating the Galilean, rotational and
reflectional invariances. The other architecture is that of a relatively simple
network, that is able to incorporate the Galilean invariance only. However,
this simpler architecture has better feature extraction capacity owing to its
ability to establish relations between and extract information from
cross-components of the integrity basis tensors and the SGS stresses. Both sets
of models are used to predict the SGS stresses for feature datasets generated
with different filter widths, and at different Reynolds numbers. It is shown
that due to the simpler model's better feature learning capabilities, it
outperforms the invariance embedded model in statistical performance metrics.
In a priori tests, both sets of models provide similar levels of dissipation
and backscatter. Based on the test results, both sets of models should be
usable in a posteriori actual LESs.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth  Nonconvex Optimization</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10053</p>
  <p><b>作者</b>：Nachuan Xiao,  Xiaoyin Hu,  Kim-Chuan Toh</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：stochastic gradient descent, training neural networks, neural networks built, nonsmooth activation functions, gradient descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the convergence properties of the stochastic
gradient descent (SGD) method and its variants, especially in training neural
networks built from nonsmooth activation functions. We develop a novel
framework that assigns different timescales to stepsizes for updating the
momentum terms and variables, respectively. Under mild conditions, we prove the
global convergence of our proposed framework in both single-timescale and
two-timescale cases. We show that our proposed framework encompasses a wide
range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion,
normalized SGD and clipped SGD. Furthermore, when the objective function adopts
a finite-sum formulation, we prove the convergence properties for these
SGD-type methods based on our proposed framework. In particular, we prove that
these SGD-type methods find the Clarke stationary points of the objective
function with randomly chosen stepsizes and initial points under mild
assumptions. Preliminary numerical experiments demonstrate the high efficiency
of our analyzed SGD-type methods.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Reinforcement Learning for Credit Index Option Hedging</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09844</p>
  <p><b>作者</b>：Francesco Mandelli,  Marco Pinciroli,  Michele Trapletti,  Edoardo Vittori</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：credit index option, reinforcement learning, optimal hedging strategy, finding the optimal, credit index</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we focus on finding the optimal hedging strategy of a credit
index option using reinforcement learning. We take a practical approach, where
the focus is on realism i.e. discrete time, transaction costs; even testing our
policy on real market data. We apply a state of the art algorithm, the Trust
Region Volatility Optimization (TRVO) algorithm and show that the derived
hedging strategy outperforms the practitioner's Black & Scholes delta hedge.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Multi-modal Learning based Prediction for Disease</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09823</p>
  <p><b>作者</b>：Yaran Chen,  Xueyu Chen,  Yu Han,  Haoran Li,  Dongbin Zhao,  Jingzhong Li,  Xu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fatty liver disease, chronic liver disease, prevent advanced fibrosis, alcoholic fatty liver, liver disease</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non alcoholic fatty liver disease (NAFLD) is the most common cause of chronic
liver disease, which can be predicted accurately to prevent advanced fibrosis
and cirrhosis. While, a liver biopsy, the gold standard for NAFLD diagnosis, is
invasive, expensive, and prone to sampling errors. Therefore, non-invasive
studies are extremely promising, yet they are still in their infancy due to the
lack of comprehensive research data and intelligent methods for multi-modal
data. This paper proposes a NAFLD diagnosis system (DeepFLDDiag) combining a
comprehensive clinical dataset (FLDData) and a multi-modal learning based NAFLD
prediction method (DeepFLD). The dataset includes over 6000 participants
physical examinations, laboratory and imaging studies, extensive
questionnaires, and facial images of partial participants, which is
comprehensive and valuable for clinical studies. From the dataset, we
quantitatively analyze and select clinical metadata that most contribute to
NAFLD prediction. Furthermore, the proposed DeepFLD, a deep neural network
model designed to predict NAFLD using multi-modal input, including metadata and
facial images, outperforms the approach that only uses metadata. Satisfactory
performance is also verified on other unseen datasets. Inspiringly, DeepFLD can
achieve competitive results using only facial images as input rather than
metadata, paving the way for a more robust and simpler non-invasive NAFLD
diagnosis.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Deep unrolling Shrinkage Network for Dynamic MR imaging</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09818</p>
  <p><b>作者</b>：Yinghao Zhang,  Xiaodi Li,  Weihang Li,  Yue Hu</p>
  <p><b>备注</b>：5 pages,3 figures,2 tables</p>
  <p><b>关键词</b>：achieved great success, utilize sparsity priors, dynamic magnetic resonance, sparsity priors, magnetic resonance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep unrolling networks that utilize sparsity priors have achieved great
success in dynamic magnetic resonance (MR) imaging. The convolutional neural
network (CNN) is usually utilized to extract the transformed domain, and then
the soft thresholding (ST) operator is applied to the CNN-transformed data to
enforce the sparsity priors. However, the ST operator is usually constrained to
be the same across all channels of the CNN-transformed data. In this paper, we
propose a novel operator, called soft thresholding with channel attention
(AST), that learns the threshold for each channel. In particular, we put
forward a novel deep unrolling shrinkage network (DUS-Net) by unrolling the
alternating direction method of multipliers (ADMM) for optimizing the
transformed $l_1$ norm dynamic MR reconstruction model. Experimental results on
an open-access dynamic cine MR dataset demonstrate that the proposed DUS-Net
outperforms the state-of-the-art methods. The source code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Manifold Learning with Sparse Regularised Optimal Transport</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09816</p>
  <p><b>作者</b>：Stephen Zhang,  Gilles Mordant,  Tetsuya Matsumoto,  Geoffrey Schiebinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern statistics, data science, central task, dimensional ambient space, Manifold learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manifold learning is a central task in modern statistics and data science.
Many datasets (cells, documents, images, molecules) can be represented as point
clouds embedded in a high dimensional ambient space, however the degrees of
freedom intrinsic to the data are usually far fewer than the number of ambient
dimensions. The task of detecting a latent manifold along which the data are
embedded is a prerequisite for a wide family of downstream analyses. Real-world
datasets are subject to noisy observations and sampling, so that distilling
information about the underlying manifold is a major challenge. We propose a
method for manifold learning that utilises a symmetric version of optimal
transport with a quadratic regularisation that constructs a sparse and adaptive
affinity matrix, that can be interpreted as a generalisation of the
bistochastic kernel normalisation. We prove that the resulting kernel is
consistent with a Laplace-type operator in the continuous limit, establish
robustness to heteroskedastic noise and exhibit these results in simulations.
We identify a highly efficient computational scheme for computing this optimal
transport for discrete data and demonstrate that it outperforms competing
methods in a set of examples.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：A Novel Spatial-Temporal Variational Quantum Circuit to Enable Deep  Learning on NISQ Devices</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09771</p>
  <p><b>作者</b>：Jinyang Li,  Zhepeng Wang,  Zhirui Hu,  Prasanna Date,  Ang Li,  Weiwen Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extremely parallel computation, Quantum, Variational Quantum Circuits, superposition and entanglement, presents a promising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantum computing presents a promising approach for machine learning with its
capability for extremely parallel computation in high-dimension through
superposition and entanglement. Despite its potential, existing quantum
learning algorithms, such as Variational Quantum Circuits(VQCs), face
challenges in handling more complex datasets, particularly those that are not
linearly separable. What's more, it encounters the deployability issue, making
the learning models suffer a drastic accuracy drop after deploying them to the
actual quantum devices. To overcome these limitations, this paper proposes a
novel spatial-temporal design, namely ST-VQC, to integrate non-linearity in
quantum learning and improve the robustness of the learning model to noise.
Specifically, ST-VQC can extract spatial features via a novel block-based
encoding quantum sub-circuit coupled with a layer-wise computation quantum
sub-circuit to enable temporal-wise deep learning. Additionally, a SWAP-Free
physical circuit design is devised to improve robustness. These designs bring a
number of hyperparameters. After a systematic analysis of the design space for
each design component, an automated optimization framework is proposed to
generate the ST-VQC quantum circuit. The proposed ST-VQC has been evaluated on
two IBM quantum processors, ibm_cairo with 27 qubits and ibmq_lima with 7
qubits to assess its effectiveness. The results of the evaluation on the
standard dataset for binary classification show that ST-VQC can achieve over
30% accuracy improvement compared with existing VQCs on actual quantum
computers. Moreover, on a non-linear synthetic dataset, the ST-VQC outperforms
a linear classifier by 27.9%, while the linear classifier using classical
computing outperforms the existing VQC by 15.58%.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Deep Reinforcement Learning for ESG financial portfolio management</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09631</p>
  <p><b>作者</b>：Eduardo C. Garrido-Merchán,  Sol Mora-Figueroa-Cruz-Guzmán,  María Coronado-Vaca</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, Deep Reinforcement, ESG score-based market, application of Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates the application of Deep Reinforcement Learning (DRL)
for Environment, Social, and Governance (ESG) financial portfolio management,
with a specific focus on the potential benefits of ESG score-based market
regulation. We leveraged an Advantage Actor-Critic (A2C) agent and conducted
our experiments using environments encoded within the OpenAI Gym, adapted from
the FinRL platform. The study includes a comparative analysis of DRL agent
performance under standard Dow Jones Industrial Average (DJIA) market
conditions and a scenario where returns are regulated in line with company ESG
scores. In the ESG-regulated market, grants were proportionally allotted to
portfolios based on their returns and ESG scores, while taxes were assigned to
portfolios below the mean ESG score of the index. The results intriguingly
reveal that the DRL agent within the ESG-regulated market outperforms the
standard DJIA market setup. Furthermore, we considered the inclusion of ESG
variables in the agent state space, and compared this with scenarios where such
data were excluded. This comparison adds to the understanding of the role of
ESG factors in portfolio management decision-making. We also analyze the
behaviour of the DRL agent in IBEX 35 and NASDAQ-100 indexes. Both the A2C and
Proximal Policy Optimization (PPO) algorithms were applied to these additional
markets, providing a broader perspective on the generalization of our findings.
This work contributes to the evolving field of ESG investing, suggesting that
market regulation based on ESG scoring can potentially improve DRL-based
portfolio management, with significant implications for sustainable investing
strategies.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Multi-view self-supervised learning for multivariate variable-channel  time series</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09614</p>
  <p><b>作者</b>：Thea Brüsch,  Mikkel N. Schmidt,  Tommy S. Alstrøm</p>
  <p><b>备注</b>：To appear in proceedings of 2023 IEEE International workshop on Machine Learning for Signal Processing</p>
  <p><b>关键词</b>：time series data, expensive process, biomedical time series, laborious and expensive, multivariate biomedical time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Labeling of multivariate biomedical time series data is a laborious and
expensive process. Self-supervised contrastive learning alleviates the need for
large, labeled datasets through pretraining on unlabeled data. However, for
multivariate time series data the set of input channels often varies between
applications, and most existing work does not allow for transfer between
datasets with different sets of input channels. We propose learning one encoder
to operate on all input channels individually. We then use a message passing
neural network to extract a single representation across channels. We
demonstrate the potential of this method by pretraining our network on a
dataset with six EEG channels and finetuning on a dataset with two different
EEG channels. We compare networks with and without the message passing neural
network across different contrastive loss functions. We show that our method
combined with the TS2Vec loss outperforms all other methods in most settings.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：DreaMR: Diffusion-driven Counterfactual Explanation for Functional MRI</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09547</p>
  <p><b>作者</b>：Hasan Atakan Bedel,  Tolga Çukur</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offered sensitivity leaps, functional MRI, Deep learning analyses, cognitive states, learning analyses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning analyses have offered sensitivity leaps in detection of
cognitive states from functional MRI (fMRI) measurements across the brain. Yet,
as deep models perform hierarchical nonlinear transformations on their input,
interpreting the association between brain responses and cognitive states is
challenging. Among common explanation approaches for deep fMRI classifiers,
attribution methods show poor specificity and perturbation methods show limited
plausibility. While counterfactual generation promises to address these
limitations, previous methods use variational or adversarial priors that yield
suboptimal sample fidelity. Here, we introduce the first diffusion-driven
counterfactual method, DreaMR, to enable fMRI interpretation with high
specificity, plausibility and fidelity. DreaMR performs diffusion-based
resampling of an input fMRI sample to alter the decision of a downstream
classifier, and then computes the minimal difference between the original and
counterfactual samples for explanation. Unlike conventional diffusion methods,
DreaMR leverages a novel fractional multi-phase-distilled diffusion prior to
improve sampling efficiency without compromising fidelity, and it employs a
transformer architecture to account for long-range spatiotemporal context in
fMRI scans. Comprehensive experiments on neuroimaging datasets demonstrate the
superior specificity, fidelity and efficiency of DreaMR in sample generation
over state-of-the-art counterfactual methods for fMRI interpretation.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：MolFM: A Multimodal Molecular Foundation Model</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09484</p>
  <p><b>作者</b>：Yizhen Luo,  Kai Yang,  Massimo Hong,  Xingyi Liu,  Zaiqing Nie</p>
  <p><b>备注</b>：31 pages, 15 figures, and 15 tables</p>
  <p><b>关键词</b>：Molecular, Molecular knowledge resides, molecular structures, knowledge graphs, Molecular knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Molecular knowledge resides within three different modalities of information
sources: molecular structures, biomedical documents, and knowledge bases.
Effective incorporation of molecular knowledge from these modalities holds
paramount significance in facilitating biomedical research. However, existing
multimodal molecular foundation models exhibit limitations in capturing
intricate connections between molecular structures and texts, and more
importantly, none of them attempt to leverage a wealth of molecular expertise
derived from knowledge graphs. In this study, we introduce MolFM, a multimodal
molecular foundation model designed to facilitate joint representation learning
from molecular structures, biomedical texts, and knowledge graphs. We propose
cross-modal attention between atoms of molecular structures, neighbors of
molecule entities and semantically related texts to facilitate cross-modal
comprehension. We provide theoretical analysis that our cross-modal
pre-training captures local and global molecular knowledge by minimizing the
distance in the feature space between different modalities of the same
molecule, as well as molecules sharing similar structures or functions. MolFM
achieves state-of-the-art performance on various downstream tasks. On
cross-modal retrieval, MolFM outperforms existing models with 12.13% and 5.04%
absolute gains under the zero-shot and fine-tuning settings, respectively.
Furthermore, qualitative analysis showcases MolFM's implicit ability to provide
grounding from molecular substructures and knowledge graphs. Code and models
are available on this https URL.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Forecasting the steam mass flow in a powerplant using the parallel  hybrid network</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09483</p>
  <p><b>作者</b>：Andrii Kurkin,  Jonas Hegemann,  Mo Kordzanganeh,  Alexey Melnikov</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：sustainable power generation, steam mass flow, Efficient and sustainable, crucial concern, mass flow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient and sustainable power generation is a crucial concern in the energy
sector. In particular, thermal power plants grapple with accurately predicting
steam mass flow, which is crucial for operational efficiency and cost
reduction. In this study, we use a parallel hybrid neural network architecture
that combines a parametrized quantum circuit and a conventional feed-forward
neural network specifically designed for time-series prediction in industrial
settings to enhance predictions of steam mass flow 15 minutes into the future.
Our results show that the parallel hybrid model outperforms standalone
classical and quantum models, achieving more than 5.7 and 4.9 times lower mean
squared error (MSE) loss on the test set after training compared to pure
classical and pure quantum networks, respectively. Furthermore, the hybrid
model demonstrates smaller relative errors between the ground truth and the
model predictions on the test set, up to 2 times better than the pure classical
model. These findings contribute to the broader scientific understanding of how
integrating quantum and classical machine learning techniques can be applied to
real-world challenges faced by the energy sector, ultimately leading to
optimized power plant operations.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：The Role of Transparency in Repeated First-Price Auctions with Unknown  Valuations</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09478</p>
  <p><b>作者</b>：Nicolò Cesa-Bianchi,  Tommaso Cesari,  Roberto Colomboni,  Federico Fusco,  Stefano Leonardi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study the problem, regret minimization, first-price auctions, single bidder, competing bids disclosed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of regret minimization for a single bidder in a sequence
of first-price auctions where the bidder knows the item's value only if the
auction is won. Our main contribution is a complete characterization, up to
logarithmic factors, of the minimax regret in terms of the auction's
transparency, which regulates the amount of information on competing bids
disclosed by the auctioneer at the end of each auction. Our results hold under
different assumptions (stochastic, adversarial, and their smoothed variants) on
the environment generating the bidder's valuations and competing bids. These
minimax rates reveal how the interplay between transparency and the nature of
the environment affects how fast one can learn to bid optimally in first-price
auctions.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Towards Ordinal Data Science</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09477</p>
  <p><b>作者</b>：Gerd Stumme,  Dominik Dürrschnabel,  Tom Hanika</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：main instruments, instruments to measure, measure the relationship, ordinal, empirical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Order is one of the main instruments to measure the relationship between
objects in (empirical) data. However, compared to methods that use numerical
properties of objects, the amount of ordinal methods developed is rather small.
One reason for this is the limited availability of computational resources in
the last century that would have been required for ordinal computations.
Another reason -- particularly important for this line of research -- is that
order-based methods are often seen as too mathematically rigorous for applying
them to real-world data. In this paper, we will therefore discuss different
means for measuring and 'calculating' with ordinal structures -- a specific
class of directed graphs -- and show how to infer knowledge from them. Our aim
is to establish Ordinal Data Science as a fundamentally new research agenda.
Besides cross-fertilization with other cornerstone machine learning and
knowledge representation methods, a broad range of disciplines will benefit
from this endeavor, including, psychology, sociology, economics, web science,
knowledge engineering, scientometrics.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Multi-Player Zero-Sum Markov Games with Networked Separable Interactions</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09470</p>
  <p><b>作者</b>：Chanwoo Park,  Kaiqing Zhang,  Asuman Ozdaglar</p>
  <p><b>备注</b>：61 pages</p>
  <p><b>关键词</b>：Multi-player Zero-sum, Markov, Markov games, Networked separable interactions, Markov Nash equilibrium</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a new class of Markov games (MGs), \textit{Multi-player Zero-sum
Markov Games} with {\it Networked separable interactions} (MZNMGs), to model
the local interaction structure in non-cooperative multi-agent sequential
decision-making. We define an MZNMG as a model where {the payoffs of the
auxiliary games associated with each state are zero-sum and} have some
separable (i.e., polymatrix) structure across the neighbors over some
interaction network. We first identify the necessary and sufficient conditions
under which an MG can be presented as an MZNMG, and show that the set of Markov
coarse correlated equilibrium (CCE) collapses to the set of Markov Nash
equilibrium (NE) in these games, in that the {product of} per-state
marginalization of the former for all players yields the latter. Furthermore,
we show that finding approximate Markov \emph{stationary} CCE in
infinite-horizon discounted MZNMGs is \texttt{PPAD}-hard, unless the underlying
network has a ``star topology''. Then, we propose fictitious-play-type
dynamics, the classical learning dynamics in normal-form games, for MZNMGs, and
establish convergence guarantees to Markov stationary NE under a star-shaped
network structure. Finally, in light of the hardness result, we focus on
computing a Markov \emph{non-stationary} NE and provide finite-iteration
guarantees for a series of value-iteration-based algorithms. We also provide
numerical experiments to corroborate our theoretical results.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Does Circuit Analysis Interpretability Scale? Evidence from Multiple  Choice Capabilities in Chinchilla</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09458</p>
  <p><b>作者</b>：Tom Lieberum,  Matthew Rahtz,  János Kramár,  Neel Nanda,  Geoffrey Irving,  Rohin Shah,  Vladimir Mikulik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Circuit analysis, understanding the internal, internal mechanisms, mechanisms of language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>\emph{Circuit analysis} is a promising technique for understanding the
internal mechanisms of language models. However, existing analyses are done in
small models far from the state of the art. To address this, we present a case
study of circuit analysis in the 70B Chinchilla model, aiming to test the
scalability of circuit analysis. In particular, we study multiple-choice
question answering, and investigate Chinchilla's capability to identify the
correct answer \emph{label} given knowledge of the correct answer \emph{text}.
We find that the existing techniques of logit attribution, attention pattern
visualization, and activation patching naturally scale to Chinchilla, allowing
us to identify and categorize a small set of `output nodes' (attention heads
and MLPs).
We further study the `correct letter' category of attention heads aiming to
understand the semantics of their features, with mixed results. For normal
multiple-choice question answers, we significantly compress the query, key and
value subspaces of the head without loss of performance when operating on the
answer labels for multiple-choice questions, and we show that the query and key
subspaces represent an `Nth item in an enumeration' feature to at least some
extent. However, when we attempt to use this explanation to understand the
heads' behaviour on a more general distribution including randomized answer
labels, we find that it is only a partial explanation, suggesting there is more
to learn about the operation of `correct letter' heads on multiple choice
question answering.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Convergent regularization in inverse problems and linear plug-and-play  denoisers</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09441</p>
  <p><b>作者</b>：Andreas Hauptmann,  Subhadip Mukherjee,  Carola-Bibiane Schönlieb,  Ferdia Sherry</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular iterative framework, solving imaging inverse, convergent regularization schemes, imaging inverse problems, provably convergent regularization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Plug-and-play (PnP) denoising is a popular iterative framework for solving
imaging inverse problems using off-the-shelf image denoisers. Their empirical
success has motivated a line of research that seeks to understand the
convergence of PnP iterates under various assumptions on the denoiser. While a
significant amount of research has gone into establishing the convergence of
the PnP iteration for different regularity conditions on the denoisers, not
much is known about the asymptotic properties of the converged solution as the
noise level in the measurement tends to zero, i.e., whether PnP methods are
provably convergent regularization schemes under reasonable assumptions on the
denoiser. This paper serves two purposes: first, we provide an overview of the
classical regularization theory in inverse problems and survey a few notable
recent data-driven methods that are provably convergent regularization schemes.
We then continue to discuss PnP algorithms and their established convergence
guarantees. Subsequently, we consider PnP algorithms with linear denoisers and
propose a novel spectral filtering technique to control the strength of
regularization arising from the denoiser. Further, by relating the implicit
regularization of the denoiser to an explicit regularization functional, we
rigorously show that PnP with linear denoisers leads to a convergent
regularization scheme. More specifically, we prove that in the limit as the
noise vanishes, the PnP reconstruction converges to the minimizer of a
regularization potential subject to the solution satisfying the noiseless
operator equation. The theoretical analysis is corroborated by numerical
experiments for the classical inverse problem of tomographic image
reconstruction.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Scaling Laws for Imitation Learning in NetHack</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09423</p>
  <p><b>作者</b>：Jens Tuyls,  Dhruv Madeka,  Kari Torkkola,  Dean Foster,  Karthik Narasimhan,  Sham Kakade</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely used methods, methods in machine, Natural Language Processing, Imitation Learning, scaling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation Learning (IL) is one of the most widely used methods in machine
learning. Yet, while powerful, many works find it is often not able to fully
recover the underlying expert behavior. However, none of these works deeply
investigate the role of scaling up the model and data size. Inspired by recent
work in Natural Language Processing (NLP) where "scaling up" has resulted in
increasingly more capable LLMs, we investigate whether carefully scaling up
model and data size can bring similar improvements in the imitation learning
setting. To demonstrate our findings, we focus on the game of NetHack, a
challenging environment featuring procedural generation, stochasticity,
long-term dependencies, and partial observability. We find IL loss and mean
return scale smoothly with the compute budget and are strongly correlated,
resulting in power laws for training compute-optimal IL agents with respect to
model size and number of samples. We forecast and train several NetHack agents
with IL and find they outperform prior state-of-the-art by at least 2x in all
settings. Our work both demonstrates the scaling behavior of imitation learning
in a challenging domain, as well as the viability of scaling up current
approaches for increasingly capable agents in NetHack, a game that remains
elusively hard for current AI systems.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Online Learning with Costly Features in Non-stationary Environments</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09388</p>
  <p><b>作者</b>：Saeed Ghoorchian,  Evgenii Kortukov,  Setareh Maghsudi</p>
  <p><b>备注</b>：31 pages, 6 figures</p>
  <p><b>关键词</b>：sequential decision-making problems, Maximizing long-term rewards, primary goal, goal in sequential, features' states</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Maximizing long-term rewards is the primary goal in sequential
decision-making problems. The majority of existing methods assume that side
information is freely available, enabling the learning agent to observe all
features' states before making a decision. In real-world problems, however,
collecting beneficial information is often costly. That implies that, besides
individual arms' reward, learning the observations of the features' states is
essential to improve the decision-making strategy. The problem is aggravated in
a non-stationary environment where reward and cost distributions undergo abrupt
changes over time. To address the aforementioned dual learning problem, we
extend the contextual bandit setting and allow the agent to observe subsets of
features' states. The objective is to maximize the long-term average gain,
which is the difference between the accumulated rewards and the paid costs on
average. Therefore, the agent faces a trade-off between minimizing the cost of
information acquisition and possibly improving the decision-making process
using the obtained information. To this end, we develop an algorithm that
guarantees a sublinear regret in time. Numerical results demonstrate the
superiority of our proposed policy in a real-world scenario.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Data Cross-Segmentation for Improved Generalization in Reinforcement  Learning Based Algorithmic Trading</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09377</p>
  <p><b>作者</b>：Vikram Duvvur,  Aashay Mehta,  Edward Sun,  Bo Wu,  Ken Yew Chan,  Jeff Schneider</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithmic trading systems, increasingly common, systems is increasingly, machine learning, algorithmic trading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of machine learning in algorithmic trading systems is increasingly
common. In a typical set-up, supervised learning is used to predict the future
prices of assets, and those predictions drive a simple trading and execution
strategy. This is quite effective when the predictions have sufficient signal,
markets are liquid, and transaction costs are low. However, those conditions
often do not hold in thinly traded financial markets and markets for
differentiated assets such as real estate or vehicles. In these markets, the
trading strategy must consider the long-term effects of taking positions that
are relatively more difficult to change. In this work, we propose a
Reinforcement Learning (RL) algorithm that trades based on signals from a
learned predictive model and addresses these challenges. We test our algorithm
on 20+ years of equity data from Bursa Malaysia.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Enhancing Pattern Classification in Support Vector Machines through  Matrix Formulation</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09372</p>
  <p><b>作者</b>：Sambhav Jain Reshma Rastogi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Support Vector Machines, Vector Machines, gathered significant acclaim, Support Vector, implementation of Statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Support Vector Machines (SVM) have gathered significant acclaim as
classifiers due to their successful implementation of Statistical Learning
Theory. However, in the context of multiclass and multilabel settings, the
reliance on vector-based formulations in existing SVM-based models poses
limitations regarding flexibility and ease of incorporating additional terms to
handle specific challenges. To overcome these limitations, our research paper
focuses on introducing a matrix formulation for SVM that effectively addresses
these constraints. By employing the Accelerated Gradient Descent method in the
dual, we notably enhance the efficiency of solving the Matrix-SVM problem.
Experimental evaluations on multilabel and multiclass datasets demonstrate that
Matrix SVM achieves superior time efficacy while delivering similar results to
Binary Relevance SVM.
Moreover, our matrix formulation unveils crucial insights and advantages that
may not be readily apparent in traditional vector-based notations. We emphasize
that numerous multilabel models can be viewed as extensions of SVM, with
customised modifications to meet specific requirements. The matrix formulation
presented in this paper establishes a solid foundation for developing more
sophisticated models capable of effectively addressing the distinctive
challenges encountered in multilabel learning.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Towards Ordinal Data Science</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09477</p>
  <p><b>作者</b>：Gerd Stumme,  Dominik Dürrschnabel,  Tom Hanika</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：main instruments, instruments to measure, measure the relationship, ordinal, empirical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Order is one of the main instruments to measure the relationship between
objects in (empirical) data. However, compared to methods that use numerical
properties of objects, the amount of ordinal methods developed is rather small.
One reason for this is the limited availability of computational resources in
the last century that would have been required for ordinal computations.
Another reason -- particularly important for this line of research -- is that
order-based methods are often seen as too mathematically rigorous for applying
them to real-world data. In this paper, we will therefore discuss different
means for measuring and 'calculating' with ordinal structures -- a specific
class of directed graphs -- and show how to infer knowledge from them. Our aim
is to establish Ordinal Data Science as a fundamentally new research agenda.
Besides cross-fertilization with other cornerstone machine learning and
knowledge representation methods, a broad range of disciplines will benefit
from this endeavor, including, psychology, sociology, economics, web science,
knowledge engineering, scientometrics.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Balancing Privacy and Progress in Artificial Intelligence: Anonymization  in Histopathology for Biomedical Research and Education</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09426</p>
  <p><b>作者</b>：Neel Kanwal,  Emiel A.M. Janssen,  Kjersti Engan</p>
  <p><b>备注</b>：Submitted to FAIEMA 2023</p>
  <p><b>关键词</b>：biomedical research heavily, research heavily relies, advancement of biomedical, heavily relies, relies on access</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data "as open as possible" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data "as closed as
necessary" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Scaling Laws for Imitation Learning in NetHack</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09423</p>
  <p><b>作者</b>：Jens Tuyls,  Dhruv Madeka,  Kari Torkkola,  Dean Foster,  Karthik Narasimhan,  Sham Kakade</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely used methods, methods in machine, Natural Language Processing, Imitation Learning, scaling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation Learning (IL) is one of the most widely used methods in machine
learning. Yet, while powerful, many works find it is often not able to fully
recover the underlying expert behavior. However, none of these works deeply
investigate the role of scaling up the model and data size. Inspired by recent
work in Natural Language Processing (NLP) where "scaling up" has resulted in
increasingly more capable LLMs, we investigate whether carefully scaling up
model and data size can bring similar improvements in the imitation learning
setting. To demonstrate our findings, we focus on the game of NetHack, a
challenging environment featuring procedural generation, stochasticity,
long-term dependencies, and partial observability. We find IL loss and mean
return scale smoothly with the compute budget and are strongly correlated,
resulting in power laws for training compute-optimal IL agents with respect to
model size and number of samples. We forecast and train several NetHack agents
with IL and find they outperform prior state-of-the-art by at least 2x in all
settings. Our work both demonstrates the scaling behavior of imitation learning
in a challenging domain, as well as the viability of scaling up current
approaches for increasingly capable agents in NetHack, a game that remains
elusively hard for current AI systems.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：CertPri: Certifiable Prioritization for Deep Neural Networks via  Movement Cost in Feature Space</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09375</p>
  <p><b>作者</b>：Haibin Zheng,  Jinyin Chen,  Haibo Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, Deep neural, neural networks, irreversible disasters, demonstrated their outperformance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have demonstrated their outperformance in various
software systems, but also exhibit misbehavior and even result in irreversible
disasters. Therefore, it is crucial to identify the misbehavior of DNN-based
software and improve DNNs' quality. Test input prioritization is one of the
most appealing ways to guarantee DNNs' quality, which prioritizes test inputs
so that more bug-revealing inputs can be identified earlier with limited time
and manual labeling efforts. However, the existing prioritization methods are
still limited from three aspects: certifiability, effectiveness, and
generalizability. To overcome the challenges, we propose CertPri, a test input
prioritization technique designed based on a movement cost perspective of test
inputs in DNNs' feature space. CertPri differs from previous works in three key
aspects: (1) certifiable: it provides a formal robustness guarantee for the
movement cost; (2) effective: it leverages formally guaranteed movement costs
to identify malicious bug-revealing inputs; and (3) generic: it can be applied
to various tasks, data, models, and scenarios. Extensive evaluations across 2
tasks (i.e., classification and regression), 6 data forms, 4 model structures,
and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri's superior
performance. For instance, it significantly improves 53.97% prioritization
effectiveness on average compared with baselines. Its robustness and
generalizability are 1.41~2.00 times and 1.33~3.39 times that of baselines on
average, respectively.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Local Minima Drive Communications in Cooperative Interaction</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09364</p>
  <p><b>作者</b>：Roger K. Moore</p>
  <p><b>备注</b>：6 page conference paper</p>
  <p><b>关键词</b>：important open question, Perceptual Control Theory, human-robot interaction, decide to communicate, important open</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An important open question in human-robot interaction (HRI) is precisely when
an agent should decide to communicate, particularly in a cooperative task.
Perceptual Control Theory (PCT) tells us that agents are able to cooperate on a
joint task simply by sharing the same 'intention', thereby distributing the
effort required to complete the task among the agents. This is even true for
agents that do not possess the same abilities, so long as the goal is
observable, the combined actions are sufficient to complete the task, and there
is no local minimum in the search space. If these conditions hold, then a
cooperative task can be accomplished without any communication between the
contributing agents. However, for tasks that do contain local minima, the
global solution can only be reached if at least one of the agents adapts its
intention at the appropriate moments, and this can only be achieved by
appropriately timed communication. In other words, it is hypothesised that in
cooperative tasks, the function of communication is to coordinate actions in a
complex search space that contains local minima. These principles have been
verified in a computer-based simulation environment in which two independent
one-dimensional agents are obliged to cooperate in order to solve a
two-dimensional path-finding task.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：MOCA: Self-supervised Representation Learning by Predicting Masked  Online Codebook Assignments</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09361</p>
  <p><b>作者</b>：Spyros Gidaris,  Andrei Bursuc,  Oriane Simeoni,  Antonin Vobecky,  Nikos Komodakis,  Matthieu Cord,  Patrick Pérez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mitigating the greedy, Vision Transformer networks, Vision Transformer, Self-supervised learning, Transformer networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning can be used for mitigating the greedy needs of
Vision Transformer networks for very large fully-annotated datasets. Different
classes of self-supervised learning offer representations with either good
contextual reasoning properties, e.g., using masked image modeling strategies,
or invariance to image perturbations, e.g., with contrastive methods. In this
work, we propose a single-stage and standalone method, MOCA, which unifies both
desired properties using novel mask-and-predict objectives defined with
high-level features (instead of pixel-level details). Moreover, we show how to
effectively employ both learning paradigms in a synergistic and
computation-efficient way. Doing so, we achieve new state-of-the-art results on
low-shot settings and strong experimental results in various evaluation
protocols with a training that is at least 3 times faster than prior methods.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer  Constraints</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09342</p>
  <p><b>作者</b>：Felix Ulrich-Oltean,  Peter Nightingale,  James Alfred Walker</p>
  <p><b>备注</b>：24 pages, 10 figures, submitted to Constraints Journal (Springer)</p>
  <p><b>关键词</b>：Boolean Satisfiability problem, Boolean Satisfiability, Satisfiability problem, satisfaction and optimisation, SAT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many constraint satisfaction and optimisation problems can be solved
effectively by encoding them as instances of the Boolean Satisfiability problem
(SAT). However, even the simplest types of constraints have many encodings in
the literature with widely varying performance, and the problem of selecting
suitable encodings for a given problem instance is not trivial. We explore the
problem of selecting encodings for pseudo-Boolean and linear constraints using
a supervised machine learning approach. We show that it is possible to select
encodings effectively using a standard set of features for constraint problems;
however we obtain better performance with a new set of features specifically
designed for the pseudo-Boolean and linear constraints. In fact, we achieve
good results when selecting encodings for unseen problem classes. Our results
compare favourably to AutoFolio when using the same feature set. We discuss the
relative importance of instance features to the task of selecting the best
encodings, and compare several variations of the machine learning method.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Company2Vec -- German Company Embeddings based on Corporate Websites</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09332</p>
  <p><b>作者</b>：Christopher Gerling</p>
  <p><b>备注</b>：Accepted for Publication in: International Journal of Information Technology & Decision Making (2023)</p>
  <p><b>关键词</b>：company, embeddings, representation learning, semantic, company embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With Company2Vec, the paper proposes a novel application in representation
learning. The model analyzes business activities from unstructured company
website data using Word2Vec and dimensionality reduction. Company2Vec maintains
semantic language structures and thus creates efficient company embeddings in
fine-granular industries. These semantic embeddings can be used for various
applications in banking. Direct relations between companies and words allow
semantic business analytics (e.g. top-n words for a company). Furthermore,
industry prediction is presented as a supervised learning application and
evaluation method. The vectorized structure of the embeddings allows measuring
companies similarities with the cosine distance. Company2Vec hence offers a
more fine-grained comparison of companies than the standard industry labels
(NACE). This property is relevant for unsupervised learning tasks, such as
clustering. An alternative industry segmentation is shown with k-means
clustering on the company embeddings. Finally, this paper proposes three
algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric
peer-firm identification.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Exploiting Field Dependencies for Learning on Categorical Data</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09321</p>
  <p><b>作者</b>：Zhibin Li,  Piotr Koniusz,  Lu Zhang,  Daniel Edward Pagendam,  Peyman Moghadam</p>
  <p><b>备注</b>：IEEE Transactions on Pattern Analysis and Machine Intelligence (submitted June 2022, accepted July 2023)</p>
  <p><b>关键词</b>：data points driven, categorical data underexploit, field dependency matrix, global field dependency, categorical data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional approaches for learning on categorical data underexploit the
dependencies between columns (\aka fields) in a dataset because they rely on
the embedding of data points driven alone by the classification/regression
loss. In contrast, we propose a novel method for learning on categorical data
with the goal of exploiting dependencies between fields. Instead of modelling
statistics of features globally (i.e., by the covariance matrix of features),
we learn a global field dependency matrix that captures dependencies between
fields and then we refine the global field dependency matrix at the
instance-wise level with different weights (so-called local dependency
modelling) w.r.t. each field to improve the modelling of the field
dependencies. Our algorithm exploits the meta-learning paradigm, i.e., the
dependency matrices are refined in the inner loop of the meta-learning
algorithm without the use of labels, whereas the outer loop intertwines the
updates of the embedding matrix (the matrix performing projection) and global
dependency matrix in a supervised fashion (with the use of labels). Our method
is simple yet it outperforms several state-of-the-art methods on six popular
dataset benchmarks. Detailed ablation studies provide additional insights into
our method.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Biomaker CA: a Biome Maker project using Cellular Automata</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09320</p>
  <p><b>作者</b>：Ettore Randazzo,  Alexander Mordvintsev</p>
  <p><b>备注</b>：20 pages, 23 figures. For code base, see this https URL</p>
  <p><b>关键词</b>：Cellular Automata, Biome Maker project, Biome Maker, Maker project, introduce Biomaker</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA).
In Biomaker CA, morphogenesis is a first class citizen and small seeds need to
grow into plant-like organisms to survive in a nutrient starved environment and
eventually reproduce with variation so that a biome survives for long
timelines. We simulate complex biomes by means of CA rules in 2D grids and
parallelize all of its computation on GPUs through the Python JAX framework. We
show how this project allows for several different kinds of environments and
laws of 'physics', alongside different model architectures and mutation
strategies. We further analyze some configurations to show how plant agents can
grow, survive, reproduce, and evolve, forming stable and unstable biomes. We
then demonstrate how one can meta-evolve models to survive in a harsh
environment either through end-to-end meta-evolution or by a more surgical and
efficient approach, called Petri dish meta-evolution. Finally, we show how to
perform interactive evolution, where the user decides how to evolve a plant
model interactively and then deploys it in a larger environment. We open source
Biomaker CA at: this https URL .</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Rumor Detection with Diverse Counterfactual Evidence</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09296</p>
  <p><b>作者</b>：Kaiwei Zhang,  Junchi Yu,  Haichao Shi,  Jian Liang,  Xiao-Yu Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rumor detection, rumor detection results, rumor, detection, robust rumor detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The growth in social media has exacerbated the threat of fake news to
individuals and communities. This draws increasing attention to developing
efficient and timely rumor detection methods. The prevailing approaches resort
to graph neural networks (GNNs) to exploit the post-propagation patterns of the
rumor-spreading process. However, these methods lack inherent interpretation of
rumor detection due to the black-box nature of GNNs. Moreover, these methods
suffer from less robust results as they employ all the propagation patterns for
rumor detection. In this paper, we address the above issues with the proposed
Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). Our
intuition is to exploit the diverse counterfactual evidence of an event graph
to serve as multi-view interpretations, which are further aggregated for robust
rumor detection results. Specifically, our method first designs a subgraph
generation strategy to efficiently generate different subgraphs of the event
graph. We constrain the removal of these subgraphs to cause the change in rumor
detection results. Thus, these subgraphs naturally serve as counterfactual
evidence for rumor detection. To achieve multi-view interpretation, we design a
diversity loss inspired by Determinantal Point Processes (DPP) to encourage
diversity among the counterfactual evidence. A GNN-based rumor detection model
further aggregates the diverse counterfactual evidence discovered by the
proposed DCE-RD to achieve interpretable and robust rumor detection results.
Extensive experiments on two real-world datasets show the superior performance
of our method. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Llama 2: Open Foundation and Fine-Tuned Chat Models</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09288</p>
  <p><b>作者</b>：Hugo Touvron,  Louis Martin,  Kevin Stone,  Peter Albert,  Amjad Almahairi,  Yasmine Babaei,  Nikolay Bashlykov,  Soumya Batra,  Prajjwal Bhargava,  Shruti Bhosale,  Dan Bikel,  Lukas Blecher,  Cristian Canton Ferrer,  Moya Chen,  Guillem Cucurull,  David Esiobu,  Jude Fernandes,  Jeremy Fu,  Wenyin Fu,  Brian Fuller,  Cynthia Gao,  Vedanuj Goswami,  Naman Goyal,  Anthony Hartshorn,  Saghar Hosseini,  Rui Hou,  Hakan Inan,  Marcin Kardas,  Viktor Kerkez,  Madian Khabsa,  Isabel Kloumann,  Artem Korenev,  Punit Singh Koura,  Marie-Anne Lachaux,  Thibaut Lavril,  Jenya Lee,  Diana Liskovich,  Yinghai Lu,  Yuning Mao,  Xavier Martinet,  Todor Mihaylov,  Pushkar Mishra,  Igor Molybog,  Yixin Nie,  Andrew Poulton,  Jeremy Reizenstein,  Rashi Rungta,  Kalyan Saladi,  Alan Schelten,  Ruan Silva,  Eric Michael Smith,  Ranjan Subramanian,  Xiaoqing Ellen Tan,  et al. (15 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fine-tuned large language, large language models, billion parameters, ranging in scale, release Llama</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we develop and release Llama 2, a collection of pretrained and
fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70
billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for
dialogue use cases. Our models outperform open-source chat models on most
benchmarks we tested, and based on our human evaluations for helpfulness and
safety, may be a suitable substitute for closed-source models. We provide a
detailed description of our approach to fine-tuning and safety improvements of
Llama 2-Chat in order to enable the community to build on our work and
contribute to the responsible development of LLMs.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Improving Text Semantic Similarity Modeling through a 3D Siamese Network</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09274</p>
  <p><b>作者</b>：Jianxiang Zang,  Hui Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Transformer blocks, Siamese network, text semantic similarity, semantic, gained popularity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Siamese networks have gained popularity as a method for modeling text
semantic similarity. Traditional methods rely on pooling operation to compress
the semantic representations from Transformer blocks in encoding, resulting in
two-dimensional semantic vectors and the loss of hierarchical semantic
information from Transformer blocks. Moreover, this limited structure of
semantic vectors is akin to a flattened landscape, which restricts the methods
that can be applied in downstream modeling, as they can only navigate this flat
terrain. To address this issue, we propose a novel 3D Siamese network for text
semantic similarity modeling, which maps semantic information to a
higher-dimensional space. The three-dimensional semantic tensors not only
retains more precise spatial and feature domain information but also provides
the necessary structural condition for comprehensive downstream modeling
strategies to capture them. Leveraging this structural advantage, we introduce
several modules to reinforce this 3D framework, focusing on three aspects:
feature extraction, attention, and feature fusion. Our extensive experiments on
four text semantic similarity benchmarks demonstrate the effectiveness and
efficiency of our 3D Siamese Network.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular  Data</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09249</p>
  <p><b>作者</b>：Yazheng Yang,  Yuqi Wang,  Guang Liu,  Ledell Wu,  Qi Liu</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, yielding impressive outcomes, advancements in Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Natural Language Processing (NLP) have witnessed the
groundbreaking impact of pretrained models, yielding impressive outcomes across
various tasks. This study seeks to extend the power of pretraining
methodologies to tabular data, a domain traditionally overlooked, yet
inherently challenging due to the plethora of table schemas intrinsic to
different tasks. The primary research questions underpinning this work revolve
around the adaptation to heterogeneous table structures, the establishment of a
universal pretraining protocol for tabular data, the generalizability and
transferability of learned knowledge across tasks, the adaptation to diverse
downstream applications, and the incorporation of incremental columns over
time. In response to these challenges, we introduce UniTabE, a pioneering
method designed to process tables in a uniform manner, devoid of constraints
imposed by specific table structures. UniTabE's core concept relies on
representing each basic table element with a module, termed TabUnit. This is
subsequently followed by a Transformer encoder to refine the representation.
Moreover, our model is designed to facilitate pretraining and finetuning
through the utilization of free-form prompts. In order to implement the
pretraining phase, we curated an expansive tabular dataset comprising
approximately 13 billion samples, meticulously gathered from the Kaggle
platform. Rigorous experimental testing and analyses were performed under a
myriad of scenarios to validate the effectiveness of our methodology. The
experimental results demonstrate UniTabE's superior performance against several
baseline models across a multitude of benchmark datasets. This, therefore,
underscores UniTabE's potential to significantly enhance the semantic
representation of tabular data, thereby marking a significant stride in the
field of tabular data analysis.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Towards Sustainable Deep Learning for Multi-Label Classification on NILM</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09244</p>
  <p><b>作者</b>：Anže Pirnat,  Blaž Bertalanič,  Gregor Cerar,  Mihael Mohorčič,  Carolina Fortuna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Non-intrusive load monitoring, measuring total electricity, total electricity consumption, single metering point, obtaining appliance-level data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-intrusive load monitoring (NILM) is the process of obtaining
appliance-level data from a single metering point, measuring total electricity
consumption of a household or a business. Appliance-level data can be directly
used for demand response applications and energy management systems as well as
for awareness raising and motivation for improvements in energy efficiency and
reduction in the carbon footprint. Recently, classical machine learning and
deep learning (DL) techniques became very popular and proved as highly
effective for NILM classification, but with the growing complexity these
methods are faced with significant computational and energy demands during both
their training and operation. In this paper, we introduce a novel DL model
aimed at enhanced multi-label classification of NILM with improved computation
and energy efficiency. We also propose a testing methodology for comparison of
different models using data synthesized from the measurement datasets so as to
better represent real-world scenarios. Compared to the state-of-the-art, the
proposed model has its carbon footprint reduced by more than 23% while
providing on average approximately 8 percentage points in performance
improvement when testing on data derived from REFIT and UK-DALE datasets.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Human Body Digital Twin: A Master Plan</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09225</p>
  <p><b>作者</b>：Chenyu Tang,  Shuo Gao,  Luigi G. Occhipinti</p>
  <p><b>备注</b>：3 figures</p>
  <p><b>关键词</b>：human body, effective implementation requires, implementation requires consideration, healthcare and wellness, potential to revolutionize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human body DT has the potential to revolutionize healthcare and wellness,
but its responsible and effective implementation requires consideration of
various factors. This article presents a comprehensive overview of the current
status and future prospects of the human body DT and proposes a five-level
roadmap for its development. The roadmap covers the development of various
components, such as wearable devices, data collection, data analysis, and
decision-making systems. The article also highlights the necessary support,
security, cost, and ethical considerations that must be addressed in order to
ensure responsible and effective implementation of the human body DT. The
proposed roadmap provides a framework for guiding future development and offers
a unique perspective on the future of the human body DT, facilitating new
interdisciplinary research and innovative solutions in this rapidly evolving
field.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual  Learning</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09218</p>
  <p><b>作者</b>：Zhenyi Wang,  Enneng Yang,  Li Shen,  Heng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previously acquired information, Forgetting, loss or deterioration, deterioration of previously, previously acquired</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forgetting refers to the loss or deterioration of previously acquired
information or knowledge. While the existing surveys on forgetting have
primarily focused on continual learning, forgetting is a prevalent phenomenon
observed in various other research domains within deep learning. Forgetting
manifests in research fields such as generative models due to generator shifts,
and federated learning due to heterogeneous data distributions across clients.
Addressing forgetting encompasses several challenges, including balancing the
retention of old task knowledge with fast learning of new tasks, managing task
interference with conflicting goals, and preventing privacy leakage, etc.
Moreover, most existing surveys on continual learning implicitly assume that
forgetting is always harmful. In contrast, our survey argues that forgetting is
a double-edged sword and can be beneficial and desirable in certain cases, such
as privacy-preserving scenarios. By exploring forgetting in a broader context,
we aim to present a more nuanced understanding of this phenomenon and highlight
its potential advantages. Through this comprehensive survey, we aspire to
uncover potential solutions by drawing upon ideas and approaches from various
fields that have dealt with forgetting. By examining forgetting beyond its
conventional boundaries, in future work, we hope to encourage the development
of novel strategies for mitigating, harnessing, or even embracing forgetting in
real applications. A comprehensive list of papers about forgetting in various
research fields is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Automated Ableism: An Exploration of Explicit Disability Biases in  Sentiment and Toxicity Analysis Models</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09209</p>
  <p><b>作者</b>：Pranav Narayanan Venkit,  Mukund Srinath,  Shomir Wilson</p>
  <p><b>备注</b>：TrustNLP at ACL 2023</p>
  <p><b>关键词</b>：Perturbation Sensitivity Analysis, analyze sentiment analysis, Twitter and Reddit, Perturbation Sensitivity, sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze sentiment analysis and toxicity detection models to detect the
presence of explicit bias against people with disability (PWD). We employ the
bias identification framework of Perturbation Sensitivity Analysis to examine
conversations related to PWD on social media platforms, specifically Twitter
and Reddit, in order to gain insight into how disability bias is disseminated
in real-world social settings. We then create the \textit{Bias Identification
Test in Sentiment} (BITS) corpus to quantify explicit disability bias in any
sentiment analysis and toxicity detection models. Our study utilizes BITS to
uncover significant biases in four open AIaaS (AI as a Service) sentiment
analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,
DistilBERT and two toxicity detection models, namely two versions of
Toxic-BERT. Our findings indicate that all of these models exhibit
statistically significant explicit bias against PWD.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via  Parameter Constraint</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09193</p>
  <p><b>作者</b>：Zhenhao Jiang,  Biao Zeng,  Hao Feng,  Jin Liu,  Jicong Fan,  Jie Zhang,  Jia Jia,  Ning Hu,  Xingyu Chen,  Xuguang Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Space Multi-Task Model, Entire Space Multi-Task, Sample Selection Bias, Entire space, recommender system spreads</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale online recommender system spreads all over the Internet being in
charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion
Rate (CVR) estimations. However, traditional CVR estimators suffer from
well-known Sample Selection Bias and Data Sparsity issues. Entire space models
were proposed to address the two issues via tracing the decision-making path of
"exposure_click_purchase". Further, some researchers observed that there are
purchase-related behaviors between click and purchase, which can better draw
the user's decision-making intention and improve the recommendation
performance. Thus, the decision-making path has been extended to
"exposure_click_in-shop action_purchase" and can be modeled with conditional
probability approach. Nevertheless, we observe that the chain rule of
conditional probability does not always hold. We report Probability Space
Confusion (PSC) issue and give a derivation of difference between ground-truth
and estimation mathematically. We propose a novel Entire Space Multi-Task Model
for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two
alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and
Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.
Specifically, we handle "exposure_click_in-shop action" and "in-shop
action_purchase" separately in the light of characteristics of in-shop action.
The first path is still treated with conditional probability while the second
one is treated with parameter constraint strategy. Experiments on both offline
and online environments in a large-scale recommendation system illustrate the
superiority of our proposed methods over state-of-the-art models. The
real-world datasets will be released.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Intuitive Access to Smartphone Settings Using Relevance Model Trained by  Contrastive Learning</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09177</p>
  <p><b>作者</b>：Joonyoung Kim,  Kangwook Lee,  Haebin Shin,  Hurnjoo Lee,  Sechun Kang,  Byunguk Choi,  Dong Shin,  Joohyung Lee</p>
  <p><b>备注</b>：7 pages, IAAI 2023</p>
  <p><b>关键词</b>：added to smartphones, features, mobile features, queries, contextual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The more new features that are being added to smartphones, the harder it
becomes for users to find them. This is because the feature names are usually
short, and there are just too many to remember. In such a case, the users may
want to ask contextual queries that describe the features they are looking for,
but the standard term frequency-based search cannot process them. This paper
presents a novel retrieval system for mobile features that accepts intuitive
and contextual search queries. We trained a relevance model via contrastive
learning from a pre-trained language model to perceive the contextual relevance
between query embeddings and indexed mobile features. Also, to make it run
efficiently on-device using minimal resources, we applied knowledge
distillation to compress the model without degrading much performance. To
verify the feasibility of our method, we collected test queries and conducted
comparative experiments with the currently deployed search baselines. The
results show that our system outperforms the others on contextual sentence
queries and even on usual keyword-based queries.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Elementary Sets for Logic Programs</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09168</p>
  <p><b>作者</b>：Martin Gebser,  Joohyung Lee,  Yuliya Lierler</p>
  <p><b>备注</b>：6 pages. AAAI 2006, 244-249. arXiv admin note: substantial text overlap with arXiv:1012.5847</p>
  <p><b>关键词</b>：Lin and Zhao, Clark completion, Zhao showed, loop formulas, nondisjunctive logic program</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>By introducing the concepts of a loop and a loop formula, Lin and Zhao showed
that the answer sets of a nondisjunctive logic program are exactly the models
of its Clark's completion that satisfy the loop formulas of all loops.
Recently, Gebser and Schaub showed that the Lin-Zhao theorem remains correct
even if we restrict loop formulas to a special class of loops called
``elementary loops.'' In this paper, we simplify and generalize the notion of
an elementary loop, and clarify its role. We propose the notion of an
elementary set, which is almost equivalent to the notion of an elementary loop
for nondisjunctive programs, but is simpler, and, unlike elementary loops, can
be extended to disjunctive programs without producing unintuitive results. We
show that the maximal unfounded elementary sets for the ``relevant'' part of a
program are exactly the minimal sets among the nonempty unfounded sets. We also
present a graph-theoretic characterization of elementary sets for
nondisjunctive programs, which is simpler than the one proposed in (Gebser &
Schaub 2005). Unlike the case of nondisjunctive programs, we show that the
problem of deciding an elementary set is coNP-complete for disjunctive
programs.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Safe Formulas in the General Theory of Stable Models</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09166</p>
  <p><b>作者</b>：Joohyung Lee,  Vladimir Lifschitz,  Ravi Palla</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：answer set solvers, first-order formulas generalize, Safe first-order formulas, set solvers, generalize the concept</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Safe first-order formulas generalize the concept of a safe rule, which plays
an important role in the design of answer set solvers. We show that any safe
sentence is equivalent, in a certain sense, to the result of its grounding --
to the variable-free sentence obtained from it by replacing all quantifiers
with multiple conjunctions and disjunctions. It follows that a safe sentence
and the result of its grounding have the same stable models, and that the
stable models of a safe sentence can be characterized by a formula of a simple
syntactic form.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Enhancing Network Slicing Architectures with Machine Learning, Security,  Sustainability and Experimental Networks Integration</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09151</p>
  <p><b>作者</b>：Joberto S. B. Martins,  Tereza C. Carvalho,  Rodrigo Moreira,  Cristiano Both,  Adnei Donatti,  João H. Corrêa,  José A. Suruagy,  Sand L. Corrêa,  Antonio J. G. Abelem,  Moisés R. N. Ribeiro,  Jose-Marcos Nogueira,  Luiz C. S. Magalhães,  Juliano Wickboldt,  Tiago Ferreto,  Ricardo Mello,  Rafael Pasquini,  Marcos Schwarz,  Leobino N. Sampaio,  Daniel F. Macedo,  José F. de Rezende,  Kleber V. Cardoso,  Flávio O. Silva</p>
  <p><b>备注</b>：10 pages, 11 figures</p>
  <p><b>关键词</b>：mobile edge computing, mobile cloud computing, essential technique extensively, networks computing strategies, Vehicles and industrial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network Slicing (NS) is an essential technique extensively used in 5G
networks computing strategies, mobile edge computing, mobile cloud computing,
and verticals like the Internet of Vehicles and industrial IoT, among others.
NS is foreseen as one of the leading enablers for 6G futuristic and highly
demanding applications since it allows the optimization and customization of
scarce and disputed resources among dynamic, demanding clients with highly
distinct application requirements. Various standardization organizations, like
3GPP's proposal for new generation networks and state-of-the-art 5G/6G research
projects, are proposing new NS architectures. However, new NS architectures
have to deal with an extensive range of requirements that inherently result in
having NS architecture proposals typically fulfilling the needs of specific
sets of domains with commonalities. The Slicing Future Internet Infrastructures
(SFI2) architecture proposal explores the gap resulting from the diversity of
NS architectures target domains by proposing a new NS reference architecture
with a defined focus on integrating experimental networks and enhancing the NS
architecture with Machine Learning (ML) native optimizations, energy-efficient
slicing, and slicing-tailored security functionalities. The SFI2 architectural
main contribution includes the utilization of the slice-as-a-service paradigm
for end-to-end orchestration of resources across multi-domains and
multi-technology experimental networks. In addition, the SFI2 reference
architecture instantiations will enhance the multi-domain and multi-technology
integrated experimental network deployment with native ML optimization,
energy-efficient aware slicing, and slicing-tailored security functionalities
for the practical domain.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Machine Learning for SAT: Restricted Heuristics and New Graph  Representations</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09141</p>
  <p><b>作者</b>：Mikhail Shirokikh,  Ilya Shenbin,  Anton Alekseev,  Sergey Nikolenko</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including automated planning, Boolean satisfiability, fundamental NP-complete problem, including automated, fundamental NP-complete</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Boolean satisfiability (SAT) is a fundamental NP-complete problem with many
applications, including automated planning and scheduling. To solve large
instances, SAT solvers have to rely on heuristics, e.g., choosing a branching
variable in DPLL and CDCL solvers. Such heuristics can be improved with machine
learning (ML) models; they can reduce the number of steps but usually hinder
the running time because useful models are relatively large and slow. We
suggest the strategy of making a few initial steps with a trained ML model and
then releasing control to classical heuristics; this simplifies cold start for
SAT solving and can decrease both the number of steps and overall runtime, but
requires a separate decision of when to release control to the solver.
Moreover, we introduce a modification of Graph-Q-SAT tailored to SAT problems
converted from other domains, e.g., open shop scheduling problems. We validate
the feasibility of our approach with random and industrial SAT problems.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：DropMix: Reducing Class Dependency in Mixed Sample Data Augmentation</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09136</p>
  <p><b>作者</b>：Haeil Lee,  Hansang Lee,  Junmo Kim</p>
  <p><b>备注</b>：17 pages, 10 figures</p>
  <p><b>关键词</b>：Mixed sample data, sample data augmentation, Mixed sample, variety of tasks, widely used technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixed sample data augmentation (MSDA) is a widely used technique that has
been found to improve performance in a variety of tasks. However, in this
paper, we show that the effects of MSDA are class-dependent, with some classes
seeing an improvement in performance while others experience a decline. To
reduce class dependency, we propose the DropMix method, which excludes a
specific percentage of data from the MSDA computation. By training on a
combination of MSDA and non-MSDA data, the proposed method not only improves
the performance of classes that were previously degraded by MSDA, but also
increases overall average accuracy, as shown in experiments on two datasets
(CIFAR-100 and ImageNet) using three MSDA methods (Mixup, CutMix and
PuzzleMix).</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Cloud-native RStudio on Kubernetes for Hopsworks</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09132</p>
  <p><b>作者</b>：Gibson Chikafa,  Sina Sheikholeslami,  Salman Niazi,  Jim Dowling,  Vladimir Vlassov</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：Integrated Development Environment, order to fully, fully benefit, aimed at maximizing, RStudio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In order to fully benefit from cloud computing, services are designed
following the "multi-tenant" architectural model, which is aimed at maximizing
resource sharing among users. However, multi-tenancy introduces challenges of
security, performance isolation, scaling, and customization. RStudio server is
an open-source Integrated Development Environment (IDE) accessible over a web
browser for the R programming language. We present the design and
implementation of a multi-user distributed system on Hopsworks, a
data-intensive AI platform, following the multi-tenant model that provides
RStudio as Software as a Service (SaaS). We use the most popular cloud-native
technologies: Docker and Kubernetes, to solve the problems of performance
isolation, security, and scaling that are present in a multi-tenant
environment. We further enable secure data sharing in RStudio server instances
to provide data privacy and allow collaboration among RStudio users. We
integrate our system with Apache Spark, which can scale and handle Big Data
processing workloads. Also, we provide a UI where users can provide custom
configurations and have full control of their own RStudio server instances. Our
system was tested on a Google Cloud Platform cluster with four worker nodes,
each with 30GB of RAM allocated to them. The tests on this cluster showed that
44 RStudio servers, each with 2GB of RAM, can be run concurrently. Our system
can scale out to potentially support hundreds of concurrently running RStudio
servers by adding more resources (CPUs and RAM) to the cluster or system.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：BOLD: A Benchmark for Linked Data User Agents and a Simulation Framework  for Dynamic Linked Data Environments</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09114</p>
  <p><b>作者</b>：Tobias Käfer,  Victor Charpenay,  Andreas Harth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Linked Data, dynamic Linked Data, Linked Data agents, Linked Data environments, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The paper presents the BOLD (Buildings on Linked Data) benchmark for Linked
Data agents, next to the framework to simulate dynamic Linked Data
environments, using which we built BOLD. The BOLD benchmark instantiates the
BOLD framework by providing a read-write Linked Data interface to a smart
building with simulated time, occupancy movement and sensors and actuators
around lighting. On the Linked Data representation of this environment, agents
carry out several specified tasks, such as controlling illumination. The
simulation environment provides means to check for the correct execution of the
tasks and to measure the performance of agents. We conduct measurements on
Linked Data agents based on condition-action rules.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A Survey on Multi-Objective Neural Architecture Search</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09099</p>
  <p><b>作者</b>：Seyed Mahdi Shariatzadeh,  Mahmood Fathy,  Reza Berangi,  Mohammad Shahverdy</p>
  <p><b>备注</b>：22 pages, 10 figures, 9 tables</p>
  <p><b>关键词</b>：Auto Machine Learning, neural architecture search, expert-crafted neural architectures, automatic generation, architecture search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the expert-crafted neural architectures is increasing overtaken by
the utilization of neural architecture search (NAS) and automatic generation
(and tuning) of network structures which has a close relation to the
Hyperparameter Optimization and Auto Machine Learning (AutoML). After the
earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective
Neural architecture Search (MONAS) has been attracting attentions which
considers more goals such as computational complexity, power consumption, and
size of the network for optimization, reaching a trade-off between the accuracy
and other features like the computational cost. In this paper, we present an
overview of principal and state-of-the-art works in the field of MONAS.
Starting from a well-categorized taxonomy and formulation for the NAS, we
address and correct some miscategorizations in previous surveys of the NAS
field. We also provide a list of all known objectives used and add a number of
new ones and elaborate their specifications. We have provides analyses about
the most important objectives and shown that the stochastic properties of some
the them should be differed from deterministic ones in the multi-objective
optimization procedure of NAS. We finalize this paper with a number of future
directions and topics in the field of MONAS.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：DiTTO: Diffusion-inspired Temporal Transformer Operator</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09072</p>
  <p><b>作者</b>：Oded Ovadia,  Eli Turkel,  Adar Kahana,  George Em Karniadakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Solving partial differential, partial differential equations, Solving partial, increasingly common, partial differential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving partial differential equations (PDEs) using a data-driven approach
has become increasingly common. The recent development of the operator learning
paradigm has enabled the solution of a broader range of PDE-related problems.
We propose an operator learning method to solve time-dependent PDEs
continuously in time without needing any temporal discretization. The proposed
approach, named DiTTO, is inspired by latent diffusion models. While diffusion
models are usually used in generative artificial intelligence tasks, their
time-conditioning mechanism is extremely useful for PDEs. The
diffusion-inspired framework is combined with elements from the Transformer
architecture to improve its capabilities.
We demonstrate the effectiveness of the new approach on a wide variety of
PDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D
Navier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO
achieves state-of-the-art results in terms of accuracy for these problems. We
also present a method to improve the performance of DiTTO by using fast
sampling concepts from diffusion models. Finally, we show that DiTTO can
accurately perform zero-shot super-resolution in time.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Unleashing the Imagination of Text: A Novel Framework for Text-to-image  Person Retrieval via Exploring the Power of Words</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09059</p>
  <p><b>作者</b>：Delong Liu,  Haiwen Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve person images, large gallery, gallery that match, textual, abstract textual descriptions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of Text-to-image person retrieval is to retrieve person images from
a large gallery that match the given textual descriptions. The main challenge
of this task lies in the significant differences in information representation
between the visual and textual modalities. The textual modality conveys
abstract and precise information through vocabulary and grammatical structures,
while the visual modality conveys concrete and intuitive information through
images. To fully leverage the expressive power of textual representations, it
is essential to accurately map abstract textual descriptions to specific
images.
To address this issue, we propose a novel framework to Unleash the
Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully
explore the power of words in sentences. Specifically, the framework employs
the pre-trained full CLIP model as a dual encoder for the images and texts ,
taking advantage of prior cross-modal alignment knowledge. The Text-guided
Image Restoration auxiliary task is proposed with the aim of implicitly mapping
abstract textual entities to specific image regions, facilitating alignment
between textual and visual embeddings. Additionally, we introduce a cross-modal
triplet loss tailored for handling hard samples, enhancing the model's ability
to distinguish minor differences.
To focus the model on the key components within sentences, we propose a novel
text data augmentation technique. Our proposed methods achieve state-of-the-art
results on three popular benchmark datasets, and the source code will be made
publicly available shortly.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Space Engage: Collaborative Space Supervision for Contrastive-based  Semi-Supervised Semantic Segmentation</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09755</p>
  <p><b>作者</b>：Changqi Wang,  Haoyu Xie,  Yuhui Yuan,  Chong Fu,  Xiangyu Yue</p>
  <p><b>备注</b>：Accepted to ICCV 2023</p>
  <p><b>关键词</b>：Semi-Supervised Semantic Segmentation, limited labeled images, Semantic Segmentation, labeled images, segmentation model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model
with limited labeled images and a substantial volume of unlabeled images. To
improve the robustness of representations, powerful methods introduce a
pixel-wise contrastive learning approach in latent space (i.e., representation
space) that aggregates the representations to their prototypes in a fully
supervised manner. However, previous contrastive-based S4 methods merely rely
on the supervision from the model's output (logits) in logit space during
unlabeled training. In contrast, we utilize the outputs in both logit space and
representation space to obtain supervision in a collaborative way. The
supervision from two spaces plays two roles: 1) reduces the risk of
over-fitting to incorrect semantic information in logits with the help of
representations; 2) enhances the knowledge exchange between the two spaces.
Furthermore, unlike previous approaches, we use the similarity between
representations and prototypes as a new indicator to tilt training those
under-performing representations and achieve a more efficient contrastive
learning process. Results on two public benchmarks demonstrate the competitive
performance of our method compared with state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Information Retrieval Meets Large Language Models: A Strategic Report  from Chinese IR Community</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09751</p>
  <p><b>作者</b>：Qingyao Ai,  Ting Bai,  Zhao Cao,  Yi Chang,  Jiawei Chen,  Zhumin Chen,  Zhiyong Cheng,  Shoubin Dong,  Zhicheng Dou,  Fuli Feng,  Shen Gao,  Jiafeng Guo,  Xiangnan He,  Yanyan Lan,  Chenliang Li,  Yiqun Liu,  Ziyu Lyu,  Weizhi Ma,  Jun Ma,  Zhaochun Ren,  Pengjie Ren,  Zhiqiang Wang,  Mingwen Wang,  Jirong Wen,  Le Wu,  Xin Xin,  Jun Xu,  Dawei Yin,  Peng Zhang,  Fan Zhang,  Weinan Zhang,  Min Zhang,  Xiaofei Zhu</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：meet diverse user, Large Language Models, evolved significantly, expanding beyond traditional, diverse user information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The research field of Information Retrieval (IR) has evolved significantly,
expanding beyond traditional search to meet diverse user information needs.
Recently, Large Language Models (LLMs) have demonstrated exceptional
capabilities in text understanding, generation, and knowledge inference,
opening up exciting avenues for IR research. LLMs not only facilitate
generative retrieval but also offer improved solutions for user understanding,
model evaluation, and user-system interactions. More importantly, the
synergistic relationship among IR models, LLMs, and humans forms a new
technical paradigm that is more powerful for information seeking. IR models
provide real-time and relevant information, LLMs contribute internal knowledge,
and humans play a central role of demanders and evaluators to the reliability
of information services. Nevertheless, significant challenges exist, including
computational costs, credibility concerns, domain-specific limitations, and
ethical considerations. To thoroughly discuss the transformative impact of LLMs
on IR research, the Chinese IR community conducted a strategic workshop in
April 2023, yielding valuable insights. This paper provides a summary of the
workshop's outcomes, including the rethinking of IR's core values, the mutual
enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and
open challenges.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Enhancing conversational quality in language learning chatbots: An  evaluation of GPT4 for ASR error correction</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09744</p>
  <p><b>作者</b>：Long Mai,  Julie Carson-Berndsen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown promising results, natural language processing, language learning domain, technologies into educational, promising results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of natural language processing (NLP) technologies into
educational applications has shown promising results, particularly in the
language learning domain. Recently, many spoken open-domain chatbots have been
used as speaking partners, helping language learners improve their language
skills. However, one of the significant challenges is the high word-error-rate
(WER) when recognizing non-native/non-fluent speech, which interrupts
conversation flow and leads to disappointment for learners. This paper explores
the use of GPT4 for ASR error correction in conversational settings. In
addition to WER, we propose to use semantic textual similarity (STS) and next
response sensibility (NRS) metrics to evaluate the impact of error correction
models on the quality of the conversation. We find that transcriptions
corrected by GPT4 lead to higher conversation quality, despite an increase in
WER. GPT4 also outperforms standard error correction methods without the need
for in-domain training data.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Multi-Grained Multimodal Interaction Network for Entity Linking</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09721</p>
  <p><b>作者</b>：Pengfei Luo,  Tong Xu,  Shiwei Wu,  Chen Zhu,  Linli Xu,  Enhong Chen</p>
  <p><b>备注</b>：Accepted by KDD 2023</p>
  <p><b>关键词</b>：attracted wide attention, Multimodal entity linking, multimodal knowledge graph, resolving ambiguous mentions, entity linking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal entity linking (MEL) task, which aims at resolving ambiguous
mentions to a multimodal knowledge graph, has attracted wide attention in
recent years. Though large efforts have been made to explore the complementary
effect among multiple modalities, however, they may fail to fully absorb the
comprehensive expression of abbreviated textual context and implicit visual
indication. Even worse, the inevitable noisy data may cause inconsistency of
different modalities during the learning process, which severely degenerates
the performance. To address the above issues, in this paper, we propose a novel
Multi-GraIned Multimodal InteraCtion Network $\textbf{(MIMIC)}$ framework for
solving the MEL task. Specifically, the unified inputs of mentions and entities
are first encoded by textual/visual encoders separately, to extract global
descriptive features and local detailed features. Then, to derive the
similarity matching score for each mention-entity pair, we device three
interaction units to comprehensively explore the intra-modal interaction and
inter-modal fusion among features of entities and mentions. In particular,
three modules, namely the Text-based Global-Local interaction Unit (TGLU),
Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based
interaction Unit (CMFU) are designed to capture and integrate the fine-grained
representation lying in abbreviated text and implicit visual cues. Afterwards,
we introduce a unit-consistency objective function via contrastive learning to
avoid inconsistency and model degradation. Experimental results on three public
benchmark datasets demonstrate that our solution outperforms various
state-of-the-art baselines, and ablation studies verify the effectiveness of
designed modules.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Two Tales of Platoon Intelligence for Autonomous Mobility Control:  Enabling Deep Learning Recipes</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09711</p>
  <p><b>作者</b>：Soohyun Park,  Haemin Lee,  Chanyoung Park,  Soyi Jung,  Minseok Choi,  Joongheon Kim</p>
  <p><b>备注</b>：8 pages, 3 figures</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, neural Myerson auction, neural Myerson, Myerson auction, deep learning-based recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the deep learning-based recent achievements to resolve
the problem of autonomous mobility control and efficient resource management of
autonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning
(MARL), and (ii) neural Myerson auction. Representatively, communication
network (CommNet), which is one of the most popular MARL algorithms, is
introduced to enable multiple agents to take actions in a distributed manner
for their shared goals by training all agents' states and actions in a single
neural network. Moreover, the neural Myerson auction guarantees trustfulness
among multiple agents as well as achieves the optimal revenue of highly dynamic
systems. Therefore, we survey the recent studies on autonomous mobility control
based on MARL and neural Myerson auction. Furthermore, we emphasize that
integration of MARL and neural Myerson auction is expected to be critical for
efficient and trustful autonomous mobility services.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09706</p>
  <p><b>作者</b>：Tianjian Gao,  Phillipe Langlais</p>
  <p><b>备注</b>：15th International Conference on Computational Semantics (IWCS), Association for Computational Linguistics (ACL)</p>
  <p><b>关键词</b>：essential knowledge representation, knowledge representation, resort to manual, automatic taxonomy construction, essential knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taxonomies are an essential knowledge representation, yet most studies on
automatic taxonomy construction (ATC) resort to manual evaluation to score
proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just
as important as taxonomy construction. We propose RaTE, an automatic label-free
taxonomy scoring procedure, which relies on a large pre-trained language model.
We apply our evaluation procedure to three state-of-the-art ATC algorithms with
which we built seven taxonomies from the Yelp domain, and show that 1) RaTE
correlates well with human judgments and 2) artificially degrading a taxonomy
leads to decreasing RaTE score.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：STRAPPER: Preference-based Reinforcement Learning via Self-training  Augmentation and Peer Regularization</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09692</p>
  <p><b>作者</b>：Yachen Kang,  Li He,  Jinxin Liu,  Zifeng Zhuang,  Donglin Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Preference-based reinforcement learning, binary human preference, complex reward function, Preference-based reinforcement, promises to learn</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Preference-based reinforcement learning (PbRL) promises to learn a complex
reward function with binary human preference. However, such human-in-the-loop
formulation requires considerable human effort to assign preference labels to
segment pairs, hindering its large-scale applications. Recent approache has
tried to reuse unlabeled segments, which implicitly elucidates the distribution
of segments and thereby alleviates the human effort. And consistency
regularization is further considered to improve the performance of
semi-supervised learning. However, we notice that, unlike general
classification tasks, in PbRL there exits a unique phenomenon that we defined
as similarity trap in this paper. Intuitively, human can have diametrically
opposite preferredness for similar segment pairs, but such similarity may trap
consistency regularization fail in PbRL. Due to the existence of similarity
trap, such consistency regularization improperly enhances the consistency
possiblity of the model's predictions between segment pairs, and thus reduces
the confidence in reward learning, since the augmented distribution does not
match with the original one in PbRL. To overcome such issue, we present a
self-training method along with our proposed peer regularization, which
penalizes the reward model memorizing uninformative labels and acquires
confident predictions. Empirically, we demonstrate that our approach is capable
of learning well a variety of locomotion and robotic manipulation behaviors
using different semi-supervised alternatives and peer regularization.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for  Recommendation and Text Generation</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09688</p>
  <p><b>作者</b>：Wei Jin,  Haitao Mao,  Zheng Li,  Haoming Jiang,  Chen Luo,  Hongzhi Wen,  Haoyu Han,  Hanqing Lu,  Zhengyang Wang,  Ruirui Li,  Zhen Li,  Monica Xiao Cheng,  Rahul Goutam,  Haiyang Zhang,  Karthik Subbian,  Suhang Wang,  Yizhou Sun,  Jiliang Tang,  Bing Yin,  Xianfeng Tang</p>
  <p><b>备注</b>：Dataset for KDD Cup 2023, this https URL</p>
  <p><b>关键词</b>：impacts user experience, directly impacts user, Modeling customer shopping, customer shopping intentions, experience and engagement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling customer shopping intentions is a crucial task for e-commerce, as it
directly impacts user experience and engagement. Thus, accurately understanding
customer preferences is essential for providing personalized recommendations.
Session-based recommendation, which utilizes customer session data to predict
their next interaction, has become increasingly popular. However, existing
session datasets have limitations in terms of item attributes, user diversity,
and dataset scale. As a result, they cannot comprehensively capture the
spectrum of user behaviors and preferences. To bridge this gap, we present the
Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It
is the first multilingual dataset consisting of millions of user sessions from
six different locales, where the major languages of products are English,
German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can
help us enhance personalization and understanding of user preferences, which
can benefit various existing tasks as well as enable new tasks. To test the
potential of the dataset, we introduce three tasks in this work: (1)
next-product recommendation, (2) next-product recommendation with domain
shifts, and (3) next-product title generation. With the above tasks, we
benchmark a range of algorithms on our proposed dataset, drawing new insights
for further research and practice. In addition, based on the proposed dataset
and tasks, we hosted a competition in the KDD CUP 2023 and have attracted
thousands of users and submissions. The winning solutions and the associated
workshop can be accessed at our website this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：PubMed and Beyond: Recent Advances and Best Practices in Biomedical  Literature Search</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09683</p>
  <p><b>作者</b>：Qiao Jin,  Robert Leaman,  Zhiyong Lu</p>
  <p><b>备注</b>：27 pages, 6 figures, 36 tools</p>
  <p><b>关键词</b>：Biomedical research yields, yields a wealth, literature search, search, literature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biomedical research yields a wealth of information, much of which is only
accessible through the literature. Consequently, literature search is an
essential tool for building on prior knowledge in clinical and biomedical
research. Although recent improvements in artificial intelligence have expanded
functionality beyond keyword-based search, these advances may be unfamiliar to
clinicians and researchers. In response, we present a survey of literature
search tools tailored to both general and specific information needs in
biomedicine, with the objective of helping readers efficiently fulfill their
information needs. We first examine the widely used PubMed search engine,
discussing recent improvements and continued challenges. We then describe
literature search tools catering to five specific information needs: 1.
Identifying high-quality clinical research for evidence-based medicine. 2.
Retrieving gene-related information for precision medicine and genomics. 3.
Searching by meaning, including natural language questions. 4. Locating related
articles with literature recommendation. 5. Mining literature to discover
associations between concepts such as diseases and genetic variants.
Additionally, we cover practical considerations and best practices for choosing
and using these tools. Finally, we provide a perspective on the future of
literature search engines, considering recent breakthroughs in large language
models such as ChatGPT. In summary, our survey provides a comprehensive view of
biomedical literature search functionalities with 36 publicly available tools.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：What's meant by explainable model: A Scoping Review</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09673</p>
  <p><b>作者</b>：Mallika Mainali,  Rosina O Weber</p>
  <p><b>备注</b>：8 pages, 2 figures. This paper was accepted at IJCAI 2023 workshop on Explainable Artificial Intelligence (XAI)</p>
  <p><b>关键词</b>：describe applications based, artificial intelligence, explainable artificial intelligence, XAI, XAI method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We often see the term explainable in the titles of papers that describe
applications based on artificial intelligence (AI). However, the literature in
explainable artificial intelligence (XAI) indicates that explanations in XAI
are application- and domain-specific, hence requiring evaluation whenever they
are employed to explain a model that makes decisions for a specific application
problem. Additionally, the literature reveals that the performance of post-hoc
methods, particularly feature attribution methods, varies substantially hinting
that they do not represent a solution to AI explainability. Therefore, when
using XAI methods, the quality and suitability of their information outputs
should be evaluated within the specific application. For these reasons, we used
a scoping review methodology to investigate papers that apply AI models and
adopt methods to generate post-hoc explanations while referring to said models
as explainable. This paper investigates whether the term explainable model is
adopted by authors under the assumption that incorporating a post-hoc XAI
method suffices to characterize a model as explainable. To inspect this
problem, our review analyzes whether these papers conducted evaluations. We
found that 81% of the application papers that refer to their approaches as an
explainable model do not conduct any form of evaluation on the XAI method they
used.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Towards A Unified Agent with Foundation Models</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09668</p>
  <p><b>作者</b>：Norman Di Palo,  Arunkumar Byravan,  Leonard Hasenclever,  Markus Wulfmeier,  Nicolas Heess,  Martin Riedmiller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vision Language Models, recently demonstrated unprecedented, demonstrated unprecedented capabilities, Language Models, understanding human intentions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models and Vision Language Models have recently demonstrated
unprecedented capabilities in terms of understanding human intentions,
reasoning, scene understanding, and planning-like behaviour, in text form,
among many others. In this work, we investigate how to embed and leverage such
abilities in Reinforcement Learning (RL) agents. We design a framework that
uses language as the core reasoning tool, exploring how this enables an agent
to tackle a series of fundamental RL challenges, such as efficient exploration,
reusing experience data, scheduling skills, and learning from observations,
which traditionally require separate, vertically designed algorithms. We test
our method on a sparse-reward simulated robotic manipulation environment, where
a robot needs to stack a set of objects. We demonstrate substantial performance
improvements over baselines in exploration efficiency and ability to reuse data
from offline datasets, and illustrate how to reuse learned skills to solve
novel tasks or imitate videos of human experts.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Anticipating Technical Expertise and Capability Evolution in Research  Communities using Dynamic Graph Transformers</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09665</p>
  <p><b>作者</b>：Sameera Horawalavithana,  Ellyn Ayton,  Anastasiya Usenko,  Robin Cosbey,  Svitlana Volkova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evolution trends globally, capability evolution trends, anticipate technical expertise, technical capability evolution, capability evolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to anticipate technical expertise and capability evolution trends
globally is essential for national and global security, especially in
safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging
fields like artificial intelligence (AI). In this work, we extend traditional
statistical relational learning approaches (e.g., link prediction in
collaboration networks) and formulate a problem of anticipating technical
expertise and capability evolution using dynamic heterogeneous graph
representations. We develop novel capabilities to forecast collaboration
patterns, authorship behavior, and technical capability evolution at different
granularities (e.g., scientist and institution levels) in two distinct research
fields. We implement a dynamic graph transformer (DGT) neural architecture,
which pushes the state-of-the-art graph neural network models by (a)
forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b)
relying on both discrete -- and continuous -- time inputs. We demonstrate that
our DGT models predict collaboration, partnership, and expertise patterns with
0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and
0.22 for NN domains. DGT model performance exceeds the best-performing static
graph baseline models by 30-80% across AI and NN domains. Our findings
demonstrate that DGT models boost inductive task performance, when previously
unseen nodes appear in the test data, for the domains with emerging
collaboration patterns (e.g., AI). Specifically, models accurately predict
which established scientists will collaborate with early career scientists and
vice-versa in the AI domain.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual  Learning</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09653</p>
  <p><b>作者</b>：Xiaotian Duan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：loses previously obtained, previously obtained knowledge, neural network loses, network loses previously, Catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Catastrophic forgetting, the phenomenon in which a neural network loses
previously obtained knowledge during the learning of new tasks, poses a
significant challenge in continual learning. The Hard-Attention-to-the-Task
(HAT) mechanism has shown potential in mitigating this problem, but its
practical implementation has been complicated by issues of usability and
compatibility, and a lack of support for existing network reuse. In this paper,
we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT
mechanism. HAT-CL not only automates gradient manipulation but also streamlines
the transformation of PyTorch modules into HAT modules. It achieves this by
providing a comprehensive suite of modules that can be seamlessly integrated
into existing architectures. Additionally, HAT-CL offers ready-to-use HAT
networks that are smoothly integrated with the TIMM library. Beyond the
redesign and reimplementation of HAT, we also introduce novel mask manipulation
techniques for HAT, which have consistently shown improvements across various
experiments. Our work paves the way for a broader application of the HAT
mechanism, opening up new possibilities in continual learning across diverse
models and applications.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：VISER: A Tractable Solution Concept for Games with Information Asymmetry</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09652</p>
  <p><b>作者</b>：Jeremy McMahan,  Young Wu,  Yudong Chen,  Xiaojin Zhu,  Qiaomin Xie</p>
  <p><b>备注</b>：17 pages, 6 figures</p>
  <p><b>关键词</b>：Strong Stackelberg Equilibrium, real-world games suffer, full game information, information asymmetry, VISER</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many real-world games suffer from information asymmetry: one player is only
aware of their own payoffs while the other player has the full game
information. Examples include the critical domain of security games and
adversarial multi-agent reinforcement learning. Information asymmetry renders
traditional solution concepts such as Strong Stackelberg Equilibrium (SSE) and
Robust-Optimization Equilibrium (ROE) inoperative. We propose a novel solution
concept called VISER (Victim Is Secure, Exploiter best-Responds). VISER enables
an external observer to predict the outcome of such games. In particular, for
security applications, VISER allows the victim to better defend itself while
characterizing the most damaging attacks available to the attacker. We show
that each player's VISER strategy can be computed independently in polynomial
time using linear programming (LP). We also extend VISER to its Markov-perfect
counterpart for Markov games, which can be solved efficiently using a series of
LPs.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：With Flying Colors: Predicting Community Success in Large-scale  Collaborative Campaigns</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09650</p>
  <p><b>作者</b>：Abraham Israeli,  Oren Tsur</p>
  <p><b>备注</b>：Accepted for publication at ICWSM 2024</p>
  <p><b>关键词</b>：develop unique characteristics, communities develop unique, exhibit distinct dynamics, Online communities develop, Online communities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online communities develop unique characteristics, establish social norms,
and exhibit distinct dynamics among their members. Activity in online
communities often results in concrete ``off-line'' actions with a broad
societal impact (e.g., political street protests and norms related to sexual
misconduct). While community dynamics, information diffusion, and online
collaborations have been widely studied in the past two decades, quantitative
studies that measure the effectiveness of online communities in promoting their
agenda are scarce. In this work, we study the correspondence between the
effectiveness of a community, measured by its success level in a competitive
online campaign, and the underlying dynamics between its members. To this end,
we define a novel task: predicting the success level of online communities in
Reddit's r/place - a large-scale distributed experiment that required
collaboration between community members. We consider an array of definitions
for success level; each is geared toward different aspects of collaborative
achievement. We experiment with several hybrid models, combining various types
of features. Our models significantly outperform all baseline models over all
definitions of `success level'. Analysis of the results and the factors that
contribute to the success of coordinated campaigns can provide a better
understanding of the resilience or the vulnerability of communities to online
social threats such as election interference or anti-science trends. We make
all data used for this study publicly available for further research.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Promoting Exploration in Memory-Augmented Adam using Critical Momenta</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09638</p>
  <p><b>作者</b>：Pranshu Malviya,  Gonçalo Mordido,  Aristide Baratin,  Reza Babanezhad Harikandeh,  Jerry Huang,  Simon Lacoste-Julien,  Razvan Pascanu,  Sarath Chandar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, large-scale deep learning, training large-scale deep, Adaptive gradient-based optimizers, learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive gradient-based optimizers, particularly Adam, have left their mark
in training large-scale deep learning models. The strength of such optimizers
is that they exhibit fast convergence while being more robust to hyperparameter
choice. However, they often generalize worse than non-adaptive methods. Recent
studies have tied this performance gap to flat minima selection: adaptive
methods tend to find solutions in sharper basins of the loss landscape, which
in turn hurts generalization. To overcome this issue, we propose a new
memory-augmented version of Adam that promotes exploration towards flatter
minima by using a buffer of critical momentum terms during training.
Intuitively, the use of the buffer makes the optimizer overshoot outside the
basin of attraction if it is not wide enough. We empirically show that our
method improves the performance of several variants of Adam on standard
supervised language modelling and image classification tasks.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Traffic-Domain Video Question Answering with Automatic Captioning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09636</p>
  <p><b>作者</b>：Ehsan Qasemi,  Jonathan M. Francis,  Alessandro Oltramari</p>
  <p><b>备注</b>：Accepted in ITSC2023</p>
  <p><b>关键词</b>：facilitating advanced machine, advanced machine reasoning, machine reasoning capabilities, Intelligent Traffic Monitoring, Intelligent Transportation Systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video Question Answering (VidQA) exhibits remarkable potential in
facilitating advanced machine reasoning capabilities within the domains of
Intelligent Traffic Monitoring and Intelligent Transportation Systems.
Nevertheless, the integration of urban traffic scene knowledge into VidQA
systems has received limited attention in previous research endeavors. In this
work, we present a novel approach termed Traffic-domain Video Question
Answering with Automatic Captioning (TRIVIA), which serves as a
weak-supervision technique for infusing traffic-domain knowledge into large
video-language models. Empirical findings obtained from the SUTD-TrafficQA task
highlight the substantial enhancements achieved by TRIVIA, elevating the
accuracy of representative video-language models by a remarkable 6.5 points
(19.88%) compared to baseline settings. This pioneering methodology holds great
promise for driving advancements in the field, inspiring researchers and
practitioners alike to unlock the full potential of emerging video-language
models in traffic-related applications.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Looking deeper into interpretable deep learning in neuroimaging: a  comprehensive survey</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09615</p>
  <p><b>作者</b>：Md. Mahfuzur Rahman,  Vince D. Calhoun,  Sergey M. Plis</p>
  <p><b>备注</b>：109 pages, 21 figures</p>
  <p><b>关键词</b>：feature extraction phase, separate error-prone feature, error-prone feature extraction, deep learning models, alleviating the concern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) models have been popular due to their ability to learn
directly from the raw data in an end-to-end paradigm, alleviating the concern
of a separate error-prone feature extraction phase. Recent DL-based
neuroimaging studies have also witnessed a noticeable performance advancement
over traditional machine learning algorithms. But the challenges of deep
learning models still exist because of the lack of transparency in these models
for their successful deployment in real-world applications. In recent years,
Explainable AI (XAI) has undergone a surge of developments mainly to get
intuitions of how the models reached the decisions, which is essential for
safety-critical domains such as healthcare, finance, and law enforcement
agencies. While the interpretability domain is advancing noticeably,
researchers are still unclear about what aspect of model learning a post hoc
method reveals and how to validate its reliability. This paper comprehensively
reviews interpretable deep learning models in the neuroimaging domain. Firstly,
we summarize the current status of interpretability resources in general,
focusing on the progression of methods, associated challenges, and opinions.
Secondly, we discuss how multiple recent neuroimaging studies leveraged model
interpretability to capture anatomical and functional brain alterations most
relevant to model predictions. Finally, we discuss the limitations of the
current practices and offer some valuable insights and guidance on how we can
steer our future research directions to make deep learning models substantially
interpretable and thus advance scientific understanding of brain disorders.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Sequential Monte Carlo Learning for Time Series Structure Discovery</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09607</p>
  <p><b>作者</b>：Feras A. Saad,  Brian J. Patton,  Matthew D. Hoffman,  Rif A. Saurous,  Vikash K. Mansinghka</p>
  <p><b>备注</b>：17 pages, 8 figures, 2 tables. Appearing in ICML 2023</p>
  <p><b>关键词</b>：sequential Monte Carlo, Gaussian process time, automatically discovering accurate, Monte Carlo, time series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new approach to automatically discovering accurate
models of complex time series data. Working within a Bayesian nonparametric
prior over a symbolic space of Gaussian process time series models, we present
a novel structure learning algorithm that integrates sequential Monte Carlo
(SMC) and involutive MCMC for highly effective posterior inference. Our method
can be used both in "online" settings, where new data is incorporated
sequentially in time, and in "offline" settings, by using nested subsets of
historical data to anneal the posterior. Empirical measurements on real-world
time series show that our method can deliver 10x--100x runtime speedups over
previous MCMC and greedy-search structure learning algorithms targeting the
same model family. We use our method to perform the first large-scale
evaluation of Gaussian process time series structure learning on a prominent
benchmark of 1,428 econometric datasets. The results show that our method
discovers sensible models that deliver more accurate point forecasts and
interval forecasts over multiple horizons as compared to widely used
statistical and neural baselines that struggle on this challenging data.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：A max-affine spline approximation of neural networks using the Legendre  transform of a convex-concave representation</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09602</p>
  <p><b>作者</b>：Adam Perrett,  Danny Wood,  Gavin Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm for transforming, spline representation, work presents, work, previous work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a novel algorithm for transforming a neural network into a
spline representation. Unlike previous work that required convex and
piecewise-affine network operators to create a max-affine spline alternate
form, this work relaxes this constraint. The only constraint is that the
function be bounded and possess a well-define second derivative, although this
was shown experimentally to not be strictly necessary. It can also be performed
over the whole network rather than on each layer independently. As in previous
work, this bridges the gap between neural networks and approximation theory but
also enables the visualisation of network feature maps. Mathematical proof and
experimental investigation of the technique is performed with approximation
error and feature maps being extracted from a range of architectures, including
convolutional neural networks.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Gradient strikes back: How filtering out high frequencies improves  explanations</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09591</p>
  <p><b>作者</b>：Sabine Muzellec,  Leo Andeol,  Thomas Fel,  Rufin VanRullen,  Thomas Serre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supplanting older gradient-based, deep neural networks, methods, gradient-based methods, Recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed an explosion in the development of novel
prediction-based attribution methods, which have slowly been supplanting older
gradient-based methods to explain the decisions of deep neural networks.
However, it is still not clear why prediction-based methods outperform
gradient-based ones. Here, we start with an empirical observation: these two
approaches yield attribution maps with very different power spectra, with
gradient-based methods revealing more high-frequency content than
prediction-based methods. This observation raises multiple questions: What is
the source of this high-frequency information, and does it truly reflect
decisions made by the system? Lastly, why would the absence of high-frequency
information in prediction-based methods yield better explainability scores
along multiple metrics? We analyze the gradient of three representative visual
classification models and observe that it contains noisy information emanating
from high-frequencies. Furthermore, our analysis reveals that the operations
used in Convolutional Neural Networks (CNNs) for downsampling appear to be a
significant source of this high-frequency content -- suggesting aliasing as a
possible underlying basis. We then apply an optimal low-pass filter for
attribution maps and demonstrate that it improves gradient-based attribution
methods. We show that (i) removing high-frequency noise yields significant
improvements in the explainability scores obtained with gradient-based methods
across multiple models -- leading to (ii) a novel ranking of state-of-the-art
methods with gradient-based methods at the top. We believe that our results
will spur renewed interest in simpler and computationally more efficient
gradient-based methods for explainability.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Automating Wood Species Detection and Classification in Microscopic  Images of Fibrous Materials with Deep Learning</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09588</p>
  <p><b>作者</b>：Lars Nieradzik,  Jördis Sieburg-Rockel,  Stephanie Helmling,  Janis Keuper,  Thomas Weibel,  Andrea Olbrich,  Henrike Stephani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large image dataset, generate image data, macerated wood references, systematic generation, dataset of macerated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We have developed a methodology for the systematic generation of a large
image dataset of macerated wood references, which we used to generate image
data for nine hardwood genera. This is the basis for a substantial approach to
automate, for the first time, the identification of hardwood species in
microscopic images of fibrous materials by deep learning. Our methodology
includes a flexible pipeline for easy annotation of vessel elements. We compare
the performance of different neural network architectures and hyperparameters.
Our proposed method performs similarly well to human experts. In the future,
this will improve controls on global wood fiber product flows to protect
forests.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09579</p>
  <p><b>作者</b>：Bocheng Chen,  Guangjing Wang,  Hanqing Guo,  Yuanda Wang,  Qiben Yan</p>
  <p><b>备注</b>：RAID 2023</p>
  <p><b>关键词</b>：natural language processing, Recent advances, advances in natural, natural language, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in natural language processing and machine learning have led
to the development of chatbot models, such as ChatGPT, that can engage in
conversational dialogue with human users. However, the ability of these models
to generate toxic or harmful responses during a non-toxic multi-turn
conversation remains an open research question. Existing research focuses on
single-turn sentence testing, while we find that 82\% of the individual
non-toxic sentences that elicit toxic behaviors in a conversation are
considered safe by existing tools. In this paper, we design a new attack,
\toxicbot, by fine-tuning a chatbot to engage in conversation with a target
open-domain chatbot. The chatbot is fine-tuned with a collection of crafted
conversation sequences. Particularly, each conversation begins with a sentence
from a crafted prompt sentences dataset. Our extensive evaluation shows that
open-domain chatbot models can be triggered to generate toxic responses in a
multi-turn conversation. In the best scenario, \toxicbot achieves a 67\%
activation rate. The conversation sequences in the fine-tuning stage help
trigger the toxicity in a conversation, which allows the attack to bypass two
defense methods. Our findings suggest that further research is needed to
address chatbot toxicity in a dynamic interactive environment. The proposed
\toxicbot can be used by both industry and researchers to develop methods for
detecting and mitigating toxic responses in conversational dialogue and improve
the robustness of chatbots for end users.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Reinforcement Learning for Syntax-Guided Synthesis</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09564</p>
  <p><b>作者</b>：Julian Parsert,  Elizabeth Polgreen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：SyGuS, synthesis, Program synthesis, SyGuS based, based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Program synthesis is the task of automatically generating code based on a
specification. In Syntax-Guided Synthesis(SyGuS) this specification is a
combination of a syntactic template and a logical formula, and any generated
code is proven to satisfy both. Techniques like SyGuS are critical to
guaranteeing correct synthesis results. Despite the proliferation of machine
learning in other types of program synthesis, state-of-the-art techniques in
SyGuS are still driven by automated reasoning tools and simple enumeration. We
hypothesize this is for two reasons: first the complexity of the search
problem, and second the relatively small data sets available. In this work, we
tackle these challenges by framing general SyGuS problems as a tree-search, and
present a reinforcement learning guided synthesis algorithm for SyGuS based on
Monte-Carlo Tree Search (MCTS). Our algorithm incorporates learned policy and
value functions combined with the upper confidence bound for trees to balance
exploration and exploitation. We incorporate this search procedure in a
reinforcement learning setup in order to iteratively improve our policy and
value estimators which are based on boosted tree models. To address the
scarcity of training data, we present a method for automatically generating
training data for SyGuS based on \emph{anti-unification} of existing
first-order satisfiability problems, which we use to train our MCTS policy. We
implement and evaluate this setup and demonstrate that learned policy and value
improve the synthesis performance over a baseline enumerator by over $26$
percentage points in the training and testing sets. With these results our tool
outperforms state-of-the-art-tools such as CVC5 on the training set and
performs comparably on the testing set. We make our data set publicly
available, enabling further application of machine learning methods to the
SyGuS problem.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Enhancing Evacuation Planning through Multi-Agent Simulation and  Artificial Intelligence: Understanding Human Behavior in Hazardous  Environments</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09485</p>
  <p><b>作者</b>：Afnan Alazbah,  Khalid Fakeeh,  Osama Rabie</p>
  <p><b>备注</b>：21 pages,15 figures</p>
  <p><b>关键词</b>：holds great importance, employs Artificial Intelligence, event hosts, importance for coordinators, crucial task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper focuses on the crucial task of addressing the evacuation of
hazardous places, which holds great importance for coordinators, event hosts,
and authorities. To facilitate the development of effective solutions, the
paper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent
Systems (MAS), to construct a simulation model for evacuation. NetLogo is
selected as the simulation tool of choice due to its ability to provide a
comprehensive understanding of human behaviour in distressing situations within
hazardous environments. The primary objective of this paper is to enhance our
comprehension of how individuals react and respond during such distressing
situations. By leveraging AI and MAS, the simulation model aims to capture the
complex dynamics of evacuation scenarios, enabling policymakers and emergency
planners to make informed decisions and implement more efficient and effective
evacuation strategies. This paper endeavours to contribute to the advancement
of evacuation planning and ultimately improve the safety and well-being of
individuals in hazardous places</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Accurate deep learning sub-grid scale models for large eddy simulations</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10060</p>
  <p><b>作者</b>：Rikhi Bose,  Arunabha M. Roy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：turbulence models developed, sub-grid scale, present two families, families of sub-grid, developed for large-eddy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present two families of sub-grid scale (SGS) turbulence models developed
for large-eddy simulation (LES) purposes. Their development required the
formulation of physics-informed robust and efficient Deep Learning (DL)
algorithms which, unlike state-of-the-art analytical modeling techniques can
produce high-order complex non-linear relations between inputs and outputs.
Explicit filtering of data from direct simulations of the canonical channel
flow at two friction Reynolds numbers $Re_\tau\approx 395$ and 590 provided
accurate data for training and testing. The two sets of models use different
network architectures. One of the architectures uses tensor basis neural
networks (TBNN) and embeds the simplified analytical model form of the general
effective-viscosity hypothesis, thus incorporating the Galilean, rotational and
reflectional invariances. The other architecture is that of a relatively simple
network, that is able to incorporate the Galilean invariance only. However,
this simpler architecture has better feature extraction capacity owing to its
ability to establish relations between and extract information from
cross-components of the integrity basis tensors and the SGS stresses. Both sets
of models are used to predict the SGS stresses for feature datasets generated
with different filter widths, and at different Reynolds numbers. It is shown
that due to the simpler model's better feature learning capabilities, it
outperforms the invariance embedded model in statistical performance metrics.
In a priori tests, both sets of models provide similar levels of dissipation
and backscatter. Based on the test results, both sets of models should be
usable in a posteriori actual LESs.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth  Nonconvex Optimization</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.10053</p>
  <p><b>作者</b>：Nachuan Xiao,  Xiaoyin Hu,  Kim-Chuan Toh</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：stochastic gradient descent, training neural networks, neural networks built, nonsmooth activation functions, gradient descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the convergence properties of the stochastic
gradient descent (SGD) method and its variants, especially in training neural
networks built from nonsmooth activation functions. We develop a novel
framework that assigns different timescales to stepsizes for updating the
momentum terms and variables, respectively. Under mild conditions, we prove the
global convergence of our proposed framework in both single-timescale and
two-timescale cases. We show that our proposed framework encompasses a wide
range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion,
normalized SGD and clipped SGD. Furthermore, when the objective function adopts
a finite-sum formulation, we prove the convergence properties for these
SGD-type methods based on our proposed framework. In particular, we prove that
these SGD-type methods find the Clarke stationary points of the objective
function with randomly chosen stepsizes and initial points under mild
assumptions. Preliminary numerical experiments demonstrate the high efficiency
of our analyzed SGD-type methods.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：An analysis on the effects of speaker embedding choice in non  auto-regressive TTS</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09898</p>
  <p><b>作者</b>：Adriana Stan,  Johannah O'Mahony</p>
  <p><b>备注</b>：Accepted for publication at ISCA Speech Synthesis Workshop 2023</p>
  <p><b>关键词</b>：non-autoregressive factorised multi-speaker, synthesis architecture exploits, factorised multi-speaker speech, paper we introduce, attempt on understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we introduce a first attempt on understanding how a
non-autoregressive factorised multi-speaker speech synthesis architecture
exploits the information present in different speaker embedding sets. We
analyse if jointly learning the representations, and initialising them from
pretrained models determine any quality improvements for target speaker
identities. In a separate analysis, we investigate how the different sets of
embeddings impact the network's core speech abstraction (i.e. zero conditioned)
in terms of speaker identity and representation learning. We show that,
regardless of the used set of embeddings and learning strategy, the network can
handle various speaker identities equally well, with barely noticeable
variations in speech output quality, and that speaker leakage within the core
structure of the synthesis system is inevitable in the standard training
procedures adopted thus far.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Perturbing a Neural Network to Infer Effective Connectivity: Evidence  from Synthetic EEG Data</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09770</p>
  <p><b>作者</b>：Peizhen Yang,  Xinke Shen,  Zongsheng Li,  Zixiang Luo,  Kexin Lou,  Quanying Liu</p>
  <p><b>备注</b>：7 pages, 3 figures, 1 table</p>
  <p><b>关键词</b>：holds key insights, distinct brain areas, brain information processing, Identifying causal relationships, holds key</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying causal relationships among distinct brain areas, known as
effective connectivity, holds key insights into the brain's information
processing and cognitive functions. Electroencephalogram (EEG) signals exhibit
intricate dynamics and inter-areal interactions within the brain. However,
methods for characterizing nonlinear causal interactions among multiple brain
regions remain relatively underdeveloped. In this study, we proposed a
data-driven framework to infer effective connectivity by perturbing the trained
neural networks. Specifically, we trained neural networks (i.e., CNN, vanilla
RNN, GRU, LSTM, and Transformer) to predict future EEG signals according to
historical data and perturbed the networks' input to obtain effective
connectivity (EC) between the perturbed EEG channel and the rest of the
channels. The EC reflects the causal impact of perturbing one node on others.
The performance was tested on the synthetic EEG generated by a
biological-plausible Jansen-Rit model. CNN and Transformer obtained the best
performance on both 3-channel and 90-channel synthetic EEG data, outperforming
the classical Granger causality method. Our work demonstrated the potential of
perturbing an artificial neural network, learned to predict future system
dynamics, to uncover the underlying causal structure.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Transformer-based Dual-domain Network for Few-view Dedicated Cardiac  SPECT Image Reconstructions</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09624</p>
  <p><b>作者</b>：Huidong Xie,  Bo Zhou,  Xiongchao Chen,  Xueqi Guo,  Stephanie Thorn,  Yi-Hwa Liu,  Ge Wang,  Albert Sinusas,  Chi Liu</p>
  <p><b>备注</b>：Early accepted by MICCAI 2023 in Vancouver, Canada</p>
  <p><b>关键词</b>：myocardial perfusion imaging, Cardiovascular disease, cardiac SPECT, death worldwide, diagnosis of CVDs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cardiovascular disease (CVD) is the leading cause of death worldwide, and
myocardial perfusion imaging using SPECT has been widely used in the diagnosis
of CVDs. The GE 530/570c dedicated cardiac SPECT scanners adopt a stationary
geometry to simultaneously acquire 19 projections to increase sensitivity and
achieve dynamic imaging. However, the limited amount of angular sampling
negatively affects image quality. Deep learning methods can be implemented to
produce higher-quality images from stationary data. This is essentially a
few-view imaging problem. In this work, we propose a novel 3D transformer-based
dual-domain network, called TIP-Net, for high-quality 3D cardiac SPECT image
reconstructions. Our method aims to first reconstruct 3D cardiac SPECT images
directly from projection data without the iterative reconstruction process by
proposing a customized projection-to-image domain transformer. Then, given its
reconstruction output and the original few-view reconstruction, we further
refine the reconstruction using an image-domain reconstruction network.
Validated by cardiac catheterization images, diagnostic interpretations from
nuclear cardiologists, and defect size quantified by an FDA 510(k)-cleared
clinical software, our method produced images with higher cardiac defect
contrast on human studies compared with previous baseline methods, potentially
enabling high-quality defect visualization using stationary few-view dedicated
cardiac SPECT scanners.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Towards Ordinal Data Science</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09477</p>
  <p><b>作者</b>：Gerd Stumme,  Dominik Dürrschnabel,  Tom Hanika</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：main instruments, instruments to measure, measure the relationship, ordinal, empirical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Order is one of the main instruments to measure the relationship between
objects in (empirical) data. However, compared to methods that use numerical
properties of objects, the amount of ordinal methods developed is rather small.
One reason for this is the limited availability of computational resources in
the last century that would have been required for ordinal computations.
Another reason -- particularly important for this line of research -- is that
order-based methods are often seen as too mathematically rigorous for applying
them to real-world data. In this paper, we will therefore discuss different
means for measuring and 'calculating' with ordinal structures -- a specific
class of directed graphs -- and show how to infer knowledge from them. Our aim
is to establish Ordinal Data Science as a fundamentally new research agenda.
Besides cross-fertilization with other cornerstone machine learning and
knowledge representation methods, a broad range of disciplines will benefit
from this endeavor, including, psychology, sociology, economics, web science,
knowledge engineering, scientometrics.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Overthinking the Truth: Understanding how Language Models Process False  Demonstrations</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09476</p>
  <p><b>作者</b>：Danny Halawi,  Jean-Stanislas Denain,  Jacob Steinhardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitate complex patterns, complete challenging tasks, Modern language models, Modern language, tasks without fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern language models can imitate complex patterns through few-shot
learning, enabling them to complete challenging tasks without fine-tuning.
However, imitation can also lead models to reproduce inaccuracies or harmful
content if present in the context. We study harmful imitation through the lens
of a model's internal representations, and identify two related phenomena:
overthinking and false induction heads. The first phenomenon, overthinking,
appears when we decode predictions from intermediate layers, given correct vs.
incorrect few-shot demonstrations. At early layers, both demonstrations induce
similar model behavior, but the behavior diverges sharply at some "critical
layer", after which the accuracy given incorrect demonstrations progressively
decreases. The second phenomenon, false induction heads, are a possible
mechanistic cause of overthinking: these are heads in late layers that attend
to and copy false information from previous demonstrations, and whose ablation
reduces overthinking. Beyond scientific understanding, our results suggest that
studying intermediate model computations could be a promising avenue for
understanding and guarding against harmful model behaviors.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Unsupervised Conditional Slot Attention for Object Centric Learning</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09437</p>
  <p><b>作者</b>：Avinash Kori,  Francesco Locatello,  Francesca Toni,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging area, Slot Attention, slot, Extracting object-level representations, Conditional Slot Attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting object-level representations for downstream reasoning tasks is an
emerging area in AI. Learning object-centric representations in an unsupervised
setting presents multiple challenges, a key one being binding an arbitrary
number of object instances to a specialized object slot. Recent object-centric
representation methods like Slot Attention utilize iterative attention to learn
composable representations with dynamic inference level binding but fail to
achieve specialized slot level binding. To address this, in this paper we
propose Unsupervised Conditional Slot Attention using a novel Probabilistic
Slot Dictionary (PSD). We define PSD with (i) abstract object-level property
vectors as key and (ii) parametric Gaussian distribution as its corresponding
value. We demonstrate the benefits of the learnt specific object-level
conditioning distributions in multiple downstream tasks, namely object
discovery, compositional scene generation, and compositional visual reasoning.
We show that our method provides scene composition capabilities and a
significant boost in a few shot adaptability tasks of compositional visual
reasoning, while performing similarly or better than slot attention in object
discovery tasks</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Balancing Privacy and Progress in Artificial Intelligence: Anonymization  in Histopathology for Biomedical Research and Education</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09426</p>
  <p><b>作者</b>：Neel Kanwal,  Emiel A.M. Janssen,  Kjersti Engan</p>
  <p><b>备注</b>：Submitted to FAIEMA 2023</p>
  <p><b>关键词</b>：biomedical research heavily, research heavily relies, advancement of biomedical, heavily relies, relies on access</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advancement of biomedical research heavily relies on access to large
amounts of medical data. In the case of histopathology, Whole Slide Images
(WSI) and clinicopathological information are valuable for developing
Artificial Intelligence (AI) algorithms for Digital Pathology (DP).
Transferring medical data "as open as possible" enhances the usability of the
data for secondary purposes but poses a risk to patient privacy. At the same
time, existing regulations push towards keeping medical data "as closed as
necessary" to avoid re-identification risks. Generally, these legal regulations
require the removal of sensitive data but do not consider the possibility of
data linkage attacks due to modern image-matching algorithms. In addition, the
lack of standardization in DP makes it harder to establish a single solution
for all formats of WSIs. These challenges raise problems for bio-informatics
researchers in balancing privacy and progress while developing AI algorithms.
This paper explores the legal regulations and terminologies for medical
data-sharing. We review existing approaches and highlight challenges from the
histopathological perspective. We also present a data-sharing guideline for
histological data to foster multidisciplinary research and education.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Scaling Laws for Imitation Learning in NetHack</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09423</p>
  <p><b>作者</b>：Jens Tuyls,  Dhruv Madeka,  Kari Torkkola,  Dean Foster,  Karthik Narasimhan,  Sham Kakade</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely used methods, methods in machine, Natural Language Processing, Imitation Learning, scaling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation Learning (IL) is one of the most widely used methods in machine
learning. Yet, while powerful, many works find it is often not able to fully
recover the underlying expert behavior. However, none of these works deeply
investigate the role of scaling up the model and data size. Inspired by recent
work in Natural Language Processing (NLP) where "scaling up" has resulted in
increasingly more capable LLMs, we investigate whether carefully scaling up
model and data size can bring similar improvements in the imitation learning
setting. To demonstrate our findings, we focus on the game of NetHack, a
challenging environment featuring procedural generation, stochasticity,
long-term dependencies, and partial observability. We find IL loss and mean
return scale smoothly with the compute budget and are strongly correlated,
resulting in power laws for training compute-optimal IL agents with respect to
model size and number of samples. We forecast and train several NetHack agents
with IL and find they outperform prior state-of-the-art by at least 2x in all
settings. Our work both demonstrates the scaling behavior of imitation learning
in a challenging domain, as well as the viability of scaling up current
approaches for increasingly capable agents in NetHack, a game that remains
elusively hard for current AI systems.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：CertPri: Certifiable Prioritization for Deep Neural Networks via  Movement Cost in Feature Space</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.09375</p>
  <p><b>作者</b>：Haibin Zheng,  Jinyin Chen,  Haibo Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, Deep neural, neural networks, irreversible disasters, demonstrated their outperformance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have demonstrated their outperformance in various
software systems, but also exhibit misbehavior and even result in irreversible
disasters. Therefore, it is crucial to identify the misbehavior of DNN-based
software and improve DNNs' quality. Test input prioritization is one of the
most appealing ways to guarantee DNNs' quality, which prioritizes test inputs
so that more bug-revealing inputs can be identified earlier with limited time
and manual labeling efforts. However, the existing prioritization methods are
still limited from three aspects: certifiability, effectiveness, and
generalizability. To overcome the challenges, we propose CertPri, a test input
prioritization technique designed based on a movement cost perspective of test
inputs in DNNs' feature space. CertPri differs from previous works in three key
aspects: (1) certifiable: it provides a formal robustness guarantee for the
movement cost; (2) effective: it leverages formally guaranteed movement costs
to identify malicious bug-revealing inputs; and (3) generic: it can be applied
to various tasks, data, models, and scenarios. Extensive evaluations across 2
tasks (i.e., classification and regression), 6 data forms, 4 model structures,
and 2 scenarios (i.e., white-box and black-box) demonstrate CertPri's superior
performance. For instance, it significantly improves 53.97% prioritization
effectiveness on average compared with baselines. Its robustness and
generalizability are 1.41~2.00 times and 1.33~3.39 times that of baselines on
average, respectively.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【梳理】陆奇最新演讲实录：我的大模型世界观</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-20)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-07-20)"/></a><div class="content"><a class="title" href="/2023/07/20/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-20)">Arxiv每日速递(2023-07-20)</a><time datetime="2023-07-20T00:43:34.036Z" title="发表于 2023-07-20 08:43:34">2023-07-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【梳理】陆奇最新演讲实录：我的大模型世界观"/></a><div class="content"><a class="title" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观">【梳理】陆奇最新演讲实录：我的大模型世界观</a><time datetime="2023-05-07T11:07:45.000Z" title="发表于 2023-05-07 19:07:45">2023-05-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)"><img src="https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="变分自编码器(Variational AutoEncoder)"/></a><div class="content"><a class="title" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)">变分自编码器(Variational AutoEncoder)</a><time datetime="2023-05-05T11:28:37.000Z" title="发表于 2023-05-05 19:28:37">2023-05-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformers.generation.GenerationMixin"/></a><div class="content"><a class="title" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin">transformers.generation.GenerationMixin</a><time datetime="2023-04-08T13:42:45.000Z" title="发表于 2023-04-08 21:42:45">2023-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范"><img src="https://openaicom.imgix.net/8d14e8f0-e267-4b8b-a9f2-a79120808f5a/chatgpt.jpg?auto=compress%2Cformat&amp;fit=min&amp;fm=jpg&amp;q=80&amp;rect=0%2C0%2C2048%2C2048&amp;w=3200" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【转载】ChatGPT 标注指南：任务、数据与规范"/></a><div class="content"><a class="title" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范">【转载】ChatGPT 标注指南：任务、数据与规范</a><time datetime="2023-03-27T14:35:45.000Z" title="发表于 2023-03-27 22:35:45">2023-03-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>