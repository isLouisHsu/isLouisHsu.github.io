<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-07-25) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新265篇论文，其中：  64篇计算机视觉（cs.CV） 21篇自然语言处理（cs.CL） 81篇机器学习（cs.LG） 56篇人工智能（cs.AI）  计算机视觉    1. 标题：BandRe: Rethinking Band-Pass Filters f">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-07-25)">
<meta property="og:url" content="http://louishsu.xyz/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新265篇论文，其中：  64篇计算机视觉（cs.CV） 21篇自然语言处理（cs.CL） 81篇机器学习（cs.LG） 56篇人工智能（cs.AI）  计算机视觉    1. 标题：BandRe: Rethinking Band-Pass Filters f">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-07-25T00:45:04.399Z">
<meta property="article:modified_time" content="2023-07-25T00:46:50.601Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-25 08:46:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-07-25)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-25T00:45:04.399Z" title="发表于 2023-07-25 08:45:04">2023-07-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-25T00:46:50.601Z" title="更新于 2023-07-25 08:46:50">2023-07-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新265篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">64篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">21篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">81篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">56篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：BandRe: Rethinking Band-Pass Filters for Scale-Wise Object Detection  Evaluation</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11748</p>
  <p><b>作者</b>：Yosuke Shinya</p>
  <p><b>备注</b>：Honorable Mention Solution Award in Small Object Detection Challenge for Spotting Birds, International Conference on Machine Vision Applications (MVA) 2023</p>
  <p><b>关键词</b>：real-world applications, evaluation of object, object detectors, detectors is important, important for real-world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scale-wise evaluation of object detectors is important for real-world
applications. However, existing metrics are either coarse or not sufficiently
reliable. In this paper, we propose novel scale-wise metrics that strike a
balance between fineness and reliability, using a filter bank consisting of
triangular and trapezoidal band-pass filters. We conduct experiments with two
methods on two datasets and show that the proposed metrics can highlight the
differences between the methods and between the datasets. Code is available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：3D Skeletonization of Complex Grapevines for Robotic Pruning</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11706</p>
  <p><b>作者</b>：Eric Schneider,  Sushanth Jayanth,  Abhisesh Silwal,  George Kantor</p>
  <p><b>备注</b>：6 pages, IROS 2023 Computer Vision for Automation</p>
  <p><b>关键词</b>：promote vine balance, grape quality, focused on planar, commercial vineyards, area of active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic pruning of dormant grapevines is an area of active research in order
to promote vine balance and grape quality, but so far robotic efforts have
largely focused on planar, simplified vines not representative of commercial
vineyards. This paper aims to advance the robotic perception capabilities
necessary for pruning in denser and more complex vine structures by extending
plant skeletonization techniques. The proposed pipeline generates skeletal
grapevine models that have lower reprojection error and higher connectivity
than baseline algorithms. We also show how 3D and skeletal information enables
prediction accuracy of pruning weight for dense vines surpassing prior work,
where pruning weight is an important vine metric influencing pruning site
selection.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SACReg: Scene-Agnostic Coordinate Regression for Visual Localization</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11702</p>
  <p><b>作者</b>：Jerome Revaud,  Yohann Cabon,  Romain Brégier,  JongMin Lee,  Philippe Weinzaepfel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown promising potential, recently shown promising, promising potential, recently shown, shown promising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scene coordinates regression (SCR), i.e., predicting 3D coordinates for every
pixel of a given image, has recently shown promising potential. However,
existing methods remain mostly scene-specific or limited to small scenes and
thus hardly scale to realistic datasets. In this paper, we propose a new
paradigm where a single generic SCR model is trained once to be then deployed
to new test scenes, regardless of their scale and without further finetuning.
For a given query image, it collects inputs from off-the-shelf image retrieval
techniques and Structure-from-Motion databases: a list of relevant database
images with sparse pointwise 2D-3D annotations. The model is based on the
transformer architecture and can take a variable number of images and sparse
2D-3D annotations as input. It is trained on a few diverse datasets and
significantly outperforms other scene regression approaches on several
benchmarks, including scene-specific models, for visual localization. In
particular, we set a new state of the art on the Cambridge localization
benchmark, even outperforming feature-matching-based approaches.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11661</p>
  <p><b>作者</b>：Mayug Maniparambil,  Chris Vorster,  Derek Molloy,  Noel Murphy,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：10 pages, Pre-print</p>
  <p><b>关键词</b>：providing good performance, large Vision-Language Models, Contrastive pretrained large, pretrained large Vision-Language, revolutionized visual representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have
revolutionized visual representation learning by providing good performance on
downstream datasets. VLMs are 0-shot adapted to a downstream dataset by
designing prompts that are relevant to the dataset. Such prompt engineering
makes use of domain expertise and a validation dataset. Meanwhile, recent
developments in generative pretrained models like GPT-4 mean they can be used
as advanced internet search tools. They can also be manipulated to provide
visual information in any structure. In this work, we show that GPT-4 can be
used to generate text that is visually descriptive and how this can be used to
adapt CLIP to downstream tasks. We show considerable improvements in 0-shot
transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD
(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.
We also design a simple few-shot adapter that learns to choose the best
possible sentences to construct generalizable classifiers that outperform the
recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized
fine-grained datasets. We will release the code, prompts, and auxiliary text
dataset upon acceptance.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：FEDD -- Fair, Efficient, and Diverse Diffusion-based Lesion Segmentation  and Malignancy Classification</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11654</p>
  <p><b>作者</b>：Héctor Carrión,  Narges Norouzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diseases affect millions, Diverse Dermatology Images, Skin diseases affect, people worldwide, affect millions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin diseases affect millions of people worldwide, across all ethnicities.
Increasing diagnosis accessibility requires fair and accurate segmentation and
classification of dermatology images. However, the scarcity of annotated
medical images, especially for rare diseases and underrepresented skin tones,
poses a challenge to the development of fair and accurate models. In this
study, we introduce a Fair, Efficient, and Diverse Diffusion-based framework
for skin lesion segmentation and malignancy classification. FEDD leverages
semantically meaningful feature embeddings learned through a denoising
diffusion probabilistic backbone and processes them via linear probes to
achieve state-of-the-art performance on Diverse Dermatology Images (DDI). We
achieve an improvement in intersection over union of 0.18, 0.13, 0.06, and 0.07
while using only 5%, 10%, 15%, and 20% labeled samples, respectively.
Additionally, FEDD trained on 10% of DDI demonstrates malignancy classification
accuracy of 81%, 14% higher compared to the state-of-the-art. We showcase high
efficiency in data-constrained scenarios while providing fair performance for
diverse skin tones and rare malignancy conditions. Our newly annotated DDI
segmentation masks and training code can be found on
this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Morphological Image Analysis and Feature Extraction for Reasoning with  AI-based Defect Detection and Classification Models</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11643</p>
  <p><b>作者</b>：Jiajun Zhang,  Georgina Cosma,  Sarah Bugby,  Axel Finke,  Jason Watkins</p>
  <p><b>备注</b>：8 pages, 3 figures, 5 tables; submitted to 2023 IEEE symposium series on computational intelligence (SSCI)</p>
  <p><b>关键词</b>：provide transparent reasoning, artificial intelligent, engineering and manufacturing, prevalent in industries, transparent reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of artificial intelligent (AI) models becomes more prevalent in
industries such as engineering and manufacturing, it is essential that these
models provide transparent reasoning behind their predictions. This paper
proposes the AI-Reasoner, which extracts the morphological characteristics of
defects (DefChars) from images and utilises decision trees to reason with the
DefChar values. Thereafter, the AI-Reasoner exports visualisations (i.e.
charts) and textual explanations to provide insights into outputs made by
masked-based defect detection and classification models. It also provides
effective mitigation strategies to enhance data pre-processing and overall
model performance. The AI-Reasoner was tested on explaining the outputs of an
IE Mask R-CNN model using a set of 366 images containing defects. The results
demonstrated its effectiveness in explaining the IE Mask R-CNN model's
predictions. Overall, the proposed AI-Reasoner provides a solution for
improving the performance of AI models in industrial applications that require
defect analysis.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Deep Reinforcement Learning Based System for Intraoperative  Hyperspectral Video Autofocusing</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11638</p>
  <p><b>作者</b>：Charlie Budd,  Jianrong Qiu,  Oscar MacCormac,  Martin Huber,  Christopher Mower,  Mirek Janatka,  Théo Trotouin,  Jonathan Shapey,  Mads S. Bergholt,  Tom Vercauteren</p>
  <p><b>备注</b>：To be presented at MICCAI 2023</p>
  <p><b>关键词</b>：precise tissue differentiation, traditional optical imaging, potentially valuable intraoperative, valuable intraoperative tool, Hyperspectral imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral imaging (HSI) captures a greater level of spectral detail than
traditional optical imaging, making it a potentially valuable intraoperative
tool when precise tissue differentiation is essential. Hardware limitations of
current optical systems used for handheld real-time video HSI result in a
limited focal depth, thereby posing usability issues for integration of the
technology into the operating room. This work integrates a focus-tunable liquid
lens into a video HSI exoscope, and proposes novel video autofocusing methods
based on deep reinforcement learning. A first-of-its-kind robotic focal-time
scan was performed to create a realistic and reproducible testing dataset. We
benchmarked our proposed autofocus algorithm against traditional policies, and
found our novel approach to perform significantly ($p<0.05$) better than traditional techniques ($0.070\pm.098$ mean absolute focal error compared to $0.146\pm.148$). in addition, we performed a blinded usability trial by having two neurosurgeons compare the system with different autofocus policies, and found our novel approach be most favourable, making desirable addition for intraoperative hsi.< p>
  </0.05$)></p></details>
</details>
<details>
  <summary>8. <b>标题：OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11636</p>
  <p><b>作者</b>：Runjia Li,  Shuyang Sun,  Mohamed Elhoseiny,  Philip Torr</p>
  <p><b>备注</b>：Accepted by ICCV 2023</p>
  <p><b>关键词</b>：Humorous Image Captions, Humorous Image, Image Captions, paper presents OxfordTVG-HIC, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale
dataset for humour generation and understanding. Humour is an abstract,
subjective, and context-dependent cognitive construct involving several
cognitive factors, making it a challenging task to generate and interpret.
Hence, humour generation and understanding can serve as a new task for
evaluating the ability of deep-learning methods to process abstract and
subjective information. Due to the scarcity of data, humour-related generation
tasks such as captioning remain under-explored. To address this gap,
OxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to
train a generalizable humour captioning model. Contrary to existing captioning
datasets, OxfordTVG-HIC features a wide range of emotional and semantic
diversity resulting in out-of-context examples that are particularly conducive
to generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive
content. We also show how OxfordTVG-HIC can be leveraged for evaluating the
humour of a generated text. Through explainability analysis of the trained
models, we identify the visual and linguistic cues influential for evoking
humour prediction (and generation). We observe qualitatively that these cues
are aligned with the benign violation theory of humour in cognitive psychology.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Divide and Adapt: Active Domain Adaptation via Customized Learning</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11618</p>
  <p><b>作者</b>：Duojun Huang,  Jichang Li,  Weikai Chen,  Junshi Huang,  Zhenhua Chai,  Guanbin Li</p>
  <p><b>备注</b>：CVPR2023, Highlight paper</p>
  <p><b>关键词</b>：domain adaptation, Active domain adaptation, incorporating active learning, domain, model adaptation performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active domain adaptation (ADA) aims to improve the model adaptation
performance by incorporating active learning (AL) techniques to label a
maximally-informative subset of target samples. Conventional AL methods do not
consider the existence of domain shift, and hence, fail to identify the truly
valuable samples in the context of domain adaptation. To accommodate active
learning and domain adaption, the two naturally different tasks, in a
collaborative framework, we advocate that a customized learning strategy for
the target data is the key to the success of ADA solutions. We present
Divide-and-Adapt (DiaNA), a new ADA framework that partitions the target
instances into four categories with stratified transferable properties. With a
novel data subdivision protocol based on uncertainty and domainness, DiaNA can
accurately recognize the most gainful samples. While sending the informative
instances for annotation, DiaNA employs tailored learning strategies for the
remaining categories. Furthermore, we propose an informativeness score that
unifies the data partitioning criteria. This enables the use of a Gaussian
mixture model (GMM) to automatically sample unlabeled data into the proposed
four categories. Thanks to the "divideand-adapt" spirit, DiaNA can handle data
with large variations of domain gap. In addition, we show that DiaNA can
generalize to different domain adaptation settings, such as unsupervised domain
adaptation (UDA), semi-supervised domain adaptation (SSDA), source-free domain
adaptation (SFDA), etc.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Consistency-guided Meta-Learning for Bootstrapping Semi-Supervised  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11604</p>
  <p><b>作者</b>：Qingyue Wei,  Lequan Yu,  Xianhang Li,  Wei Shao,  Cihang Xie,  Lei Xing,  Yuyin Zhou</p>
  <p><b>备注</b>：Accepted to MICCAI 2023. Code is publicly available at this https URL</p>
  <p><b>关键词</b>：witnessed remarkable progress, Medical Image Segmentation, costly to obtain, imaging has witnessed, witnessed remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical imaging has witnessed remarkable progress but usually requires a
large amount of high-quality annotated data which is time-consuming and costly
to obtain. To alleviate this burden, semi-supervised learning has garnered
attention as a potential solution. In this paper, we present Meta-Learning for
Bootstrapping Medical Image Segmentation (MLB-Seg), a novel method for tackling
the challenge of semi-supervised medical image segmentation. Specifically, our
approach first involves training a segmentation model on a small set of clean
labeled images to generate initial labels for unlabeled data. To further
optimize this bootstrapping process, we introduce a per-pixel weight mapping
system that dynamically assigns weights to both the initialized labels and the
model's own predictions. These weights are determined using a meta-process that
prioritizes pixels with loss gradient directions closer to those of clean data,
which is based on a small set of precisely annotated images. To facilitate the
meta-learning process, we additionally introduce a consistency-based Pseudo
Label Enhancement (PLE) scheme that improves the quality of the model's own
predictions by ensembling predictions from various augmented versions of the
same input. In order to improve the quality of the weight maps obtained through
multiple augmentations of a single input, we introduce a mean teacher into the
PLE scheme. This method helps to reduce noise in the weight maps and stabilize
its generation process. Our extensive experimental results on public atrial and
prostate segmentation datasets demonstrate that our proposed method achieves
state-of-the-art results under semi-supervision. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Advancing Visual Grounding with Scene Knowledge: Benchmark and Method</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11558</p>
  <p><b>作者</b>：Zhihong Chen,  Ruifei Zhang,  Yibing Song,  Xiang Wan,  Guanbin Li</p>
  <p><b>备注</b>：Computer Vision and Natural Language Processing. 21 pages, 14 figures. CVPR-2023</p>
  <p><b>关键词</b>：establish fine-grained alignment, Visual grounding, aims to establish, vision and language, establish fine-grained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual grounding (VG) aims to establish fine-grained alignment between vision
and language. Ideally, it can be a testbed for vision-and-language models to
evaluate their understanding of the images and texts and their reasoning
abilities over their joint space. However, most existing VG datasets are
constructed using simple description texts, which do not require sufficient
reasoning over the images and texts. This has been demonstrated in a recent
study~\cite{luo2022goes}, where a simple LSTM-based text encoder without
pretraining can achieve state-of-the-art performance on mainstream VG datasets.
Therefore, in this paper, we propose a novel benchmark of \underline{S}cene
\underline{K}nowledge-guided \underline{V}isual \underline{G}rounding (SK-VG),
where the image content and referring expressions are not sufficient to ground
the target objects, forcing the models to have a reasoning ability on the
long-form scene knowledge. To perform this task, we propose two approaches to
accept the triple-type input, where the former embeds knowledge into the image
features before the image-query interaction; the latter leverages linguistic
structure to assist in computing the image-text matching. We conduct extensive
experiments to analyze the above methods and show that the proposed approaches
achieve promising results but still leave room for improvement, including
performance and interpretability. The dataset and code are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：YOLOPose V2: Understanding and Improving Transformer-based 6D Pose  Estimation</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11550</p>
  <p><b>作者</b>：Arul Selvam Periyasamy,  Arash Amini,  Vladimir Tsaturyan,  Sven Behnke</p>
  <p><b>备注</b>：Robotics and Autonomous Systems Journal, Elsevier, to appear 2023. arXiv admin note: substantial text overlap with arXiv:2205.02536</p>
  <p><b>关键词</b>：autonomous robot manipulation, pose estimation, robot manipulation applications, object pose estimation, crucial prerequisite</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>6D object pose estimation is a crucial prerequisite for autonomous robot
manipulation applications. The state-of-the-art models for pose estimation are
convolutional neural network (CNN)-based. Lately, Transformers, an architecture
originally proposed for natural language processing, is achieving
state-of-the-art results in many computer vision tasks as well. Equipped with
the multi-head self-attention mechanism, Transformers enable simple
single-stage end-to-end architectures for learning object detection and 6D
object pose estimation jointly. In this work, we propose YOLOPose (short form
for You Only Look Once Pose estimation), a Transformer-based multi-object 6D
pose estimation method based on keypoint regression and an improved variant of
the YOLOPose model. In contrast to the standard heatmaps for predicting
keypoints in an image, we directly regress the keypoints. Additionally, we
employ a learnable orientation estimation module to predict the orientation
from the keypoints. Along with a separate translation estimation module, our
model is end-to-end differentiable. Our method is suitable for real-time
applications and achieves results comparable to state-of-the-art methods. We
analyze the role of object queries in our architecture and reveal that the
object queries specialize in detecting objects in specific image regions.
Furthermore, we quantify the accuracy trade-off of using datasets of smaller
sizes to train our model.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Bridging Vision and Language Encoders: Parameter-Efficient Tuning for  Referring Image Segmentation</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11545</p>
  <p><b>作者</b>：Zunnan Xu,  Zhihong Chen,  Yong Zhang,  Yibing Song,  Xiang Wan,  Guanbin Li</p>
  <p><b>备注</b>：Computer Vision and Natural Language Processing. 14 pages, 8 figures. ICCV-2023</p>
  <p><b>关键词</b>：hardware resource savings, studies investigate dense, investigate dense prediction, dense prediction tasks, Efficient Tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Parameter Efficient Tuning (PET) has gained attention for reducing the number
of parameters while maintaining performance and providing better hardware
resource savings, but few studies investigate dense prediction tasks and
interaction between modalities. In this paper, we do an investigation of
efficient tuning problems on referring image segmentation. We propose a novel
adapter called Bridger to facilitate cross-modal information exchange and
inject task-specific information into the pre-trained model. We also design a
lightweight decoder for image segmentation. Our approach achieves comparable or
superior performance with only 1.61\% to 3.38\% backbone parameter updates,
evaluated on challenging benchmarks. The code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose  Estimation</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11543</p>
  <p><b>作者</b>：Ivano Donadi,  Alberto Pretto</p>
  <p><b>备注</b>：Submitted to IEEE Robotics and Automation Letters</p>
  <p><b>关键词</b>：augmented reality applications, fundamental computer vision, computer vision task, vision task exploited, Object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object pose estimation is a fundamental computer vision task exploited in
several robotics and augmented reality applications. Many established
approaches rely on predicting 2D-3D keypoint correspondences using RANSAC
(Random sample consensus) and estimating the object pose using the PnP
(Perspective-n-Point) algorithm. Being RANSAC non-differentiable,
correspondences cannot be directly learned in an end-to-end fashion. In this
paper, we address the stereo image-based object pose estimation problem by (i)
introducing a differentiable RANSAC layer into a well-known monocular pose
estimation network; (ii) exploiting an uncertainty-driven multi-view PnP solver
which can fuse information from multiple views. We evaluate our approach on a
challenging public stereo object pose estimation dataset, yielding
state-of-the-art results against other recent approaches. Furthermore, in our
ablation study, we show that the differentiable RANSAC layer plays a
significant role in the accuracy of the proposed method. We release with this
paper the open-source implementation of our method.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Improving Viewpoint Robustness for Visual Recognition via Adversarial  Training</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11528</p>
  <p><b>作者</b>：Shouwei Ruan,  Yinpeng Dong,  Hang Su,  Jianteng Peng,  Ning Chen,  Xingxing Wei</p>
  <p><b>备注</b>：14 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2307.10235</p>
  <p><b>关键词</b>：invariance remains challenging, Viewpoint invariance remains, significantly impact predictions, viewpoint robustness, remains challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Viewpoint invariance remains challenging for visual recognition in the 3D
world, as altering the viewing directions can significantly impact predictions
for the same object. While substantial efforts have been dedicated to making
neural networks invariant to 2D image translations and rotations, viewpoint
invariance is rarely investigated. Motivated by the success of adversarial
training in enhancing model robustness, we propose Viewpoint-Invariant
Adversarial Training (VIAT) to improve the viewpoint robustness of image
classifiers. Regarding viewpoint transformation as an attack, we formulate VIAT
as a minimax optimization problem, where the inner maximization characterizes
diverse adversarial viewpoints by learning a Gaussian mixture distribution
based on the proposed attack method GMVFool. The outer minimization obtains a
viewpoint-invariant classifier by minimizing the expected loss over the
worst-case viewpoint distributions that can share the same one for different
objects within the same category. Based on GMVFool, we contribute a large-scale
dataset called ImageNet-V+ to benchmark viewpoint robustness. Experimental
results show that VIAT significantly improves the viewpoint robustness of
various image classifiers based on the diversity of adversarial viewpoints
generated by GMVFool. Furthermore, we propose ViewRS, a certified viewpoint
robustness method that provides a certified radius and accuracy to demonstrate
the effectiveness of VIAT from the theoretical perspective.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11526</p>
  <p><b>作者</b>：Ziyuan Luo,  Qing Guo,  Ka Chun Cheung,  Simon See,  Renjie Wan</p>
  <p><b>备注</b>：11 pages, 6 figures, accepted by iccv 2023 non-camera-ready version</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, Fields, NeRF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) have the potential to be a major representation
of media. Since training a NeRF has never been an easy task, the protection of
its model copyright should be a priority. In this paper, by analyzing the pros
and cons of possible copyright protection solutions, we propose to protect the
copyright of NeRF models by replacing the original color representation in NeRF
with a watermarked color representation. Then, a distortion-resistant rendering
scheme is designed to guarantee robust message extraction in 2D renderings of
NeRF. Our proposed method can directly protect the copyright of NeRF models
while maintaining high rendering quality and bit accuracy when compared among
optional solutions.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Multi-modal Hate Speech Detection using Machine Learning</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11519</p>
  <p><b>作者</b>：Fariha Tahosin Boishakhi,  Ponkoj Chandra Shill,  Md. Golam Rabiul Alam</p>
  <p><b>备注</b>：5 pages, 2 figures, conference</p>
  <p><b>关键词</b>：continuous growth, growth of internet, internet users, users and media, hard to track</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous growth of internet users and media content, it is very
hard to track down hateful speech in audio and video. Converting video or audio
into text does not detect hate speech accurately as human sometimes uses
hateful words as humorous or pleasant in sense and also uses different voice
tones or show different action in the video. The state-ofthe-art hate speech
detection models were mostly developed on a single modality. In this research,
a combined approach of multimodal system has been proposed to detect hate
speech from video contents by extracting feature images, feature values
extracted from the audio, text and used machine learning and Natural language
processing.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：BatMobility: Towards Flying Without Seeing for Autonomous Drones</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11518</p>
  <p><b>作者</b>：Emerson Sie,  Zikun Liu,  Deepak Vasisht</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unmanned aerial vehicles, optical sensors, Unmanned aerial, aerial vehicles, autonomous operation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unmanned aerial vehicles (UAVs) rely on optical sensors such as cameras and
lidar for autonomous operation. However, such optical sensors are error-prone
in bad lighting, inclement weather conditions including fog and smoke, and
around textureless or transparent surfaces. In this paper, we ask: is it
possible to fly UAVs without relying on optical sensors, i.e., can UAVs fly
without seeing? We present BatMobility, a lightweight mmWave radar-only
perception system for UAVs that eliminates the need for optical sensors.
BatMobility enables two core functionalities for UAVs -- radio flow estimation
(a novel FMCW radar-based alternative for optical flow based on
surface-parallel doppler shift) and radar-based collision avoidance. We build
BatMobility using commodity sensors and deploy it as a real-time system on a
small off-the-shelf quadcopter running an unmodified flight controller. Our
evaluation shows that BatMobility achieves comparable or better performance
than commercial-grade optical sensors across a wide range of scenarios.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：CORE: Cooperative Reconstruction for Multi-Agent Perception</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11514</p>
  <p><b>作者</b>：Binglu Wang,  Lei Zhang,  Zhaozhong Wang,  Yongqiang Zhao,  Tianfei Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper presents CORE, conceptually simple, paper presents, presents CORE, observation based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents CORE, a conceptually simple, effective and
communication-efficient model for multi-agent cooperative perception. It
addresses the task from a novel perspective of cooperative reconstruction,
based on two key insights: 1) cooperating agents together provide a more
holistic observation of the environment, and 2) the holistic observation can
serve as valuable supervision to explicitly guide the model learning how to
reconstruct the ideal observation based on collaboration. CORE instantiates the
idea with three major components: a compressor for each agent to create more
compact feature representation for efficient broadcasting, a lightweight
attentive collaboration component for cross-agent message aggregation, and a
reconstruction module to reconstruct the observation based on aggregated
feature representations. This learning-to-reconstruct idea is task-agnostic,
and offers clear and reasonable supervision to inspire more effective
collaboration, eventually promoting perception tasks. We validate CORE on
OPV2V, a large-scale multi-agent percetion dataset, in two tasks, i.e., 3D
object detection and semantic segmentation. Results demonstrate that the model
achieves state-of-the-art performance on both tasks, and is more
communication-efficient.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Redemption from Range-view for Accurate 3D Object Detection</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11482</p>
  <p><b>作者</b>：Yihan Wang,  Qiao Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detection predominantly rely, object detection predominantly, object detection, surface texture, recent approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most recent approaches for 3D object detection predominantly rely on
point-view or bird's-eye view representations, with limited exploration of
range-view-based methods. The range-view representation suffers from scale
variation and surface texture deficiency, both of which pose significant
limitations for developing corresponding methods. Notably, the surface texture
loss problem has been largely ignored by all existing methods, despite its
significant impact on the accuracy of range-view-based 3D object detection. In
this study, we propose Redemption from Range-view R-CNN (R2 R-CNN), a novel and
accurate approach that comprehensively explores the range-view representation.
Our proposed method addresses scale variation through the HD Meta Kernel, which
captures range-view geometry information in multiple scales. Additionally, we
introduce Feature Points Redemption (FPR) to recover the lost 3D surface
texture information from the range view, and Synchronous-Grid RoI Pooling
(S-Grid RoI Pooling), a multi-scaled approach with multiple receptive fields
for accurate box refinement. Our R2 R-CNN outperforms existing range-view-based
methods, achieving state-of-the-art performance on both the KITTI benchmark and
the Waymo Open Dataset. Our study highlights the critical importance of
addressing the surface texture loss problem for accurate 3D object detection in
range-view-based methods. Codes will be made publicly available.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view  3D Object Detection</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11477</p>
  <p><b>作者</b>：Jinqing Zhang,  Yanan Zhang,  Qingjie Liu,  Yunhong Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：economical autonomous driving, Semantic-Aware BEV, semantic-aware BEV feature, BEV, BEV features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the pure camera-based Bird's-Eye-View (BEV) perception provides a
feasible solution for economical autonomous driving. However, the existing
BEV-based multi-view 3D detectors generally transform all image features into
BEV features, without considering the problem that the large proportion of
background information may submerge the object information. In this paper, we
propose Semantic-Aware BEV Pooling (SA-BEVPool), which can filter out
background information according to the semantic segmentation of image features
and transform image features into semantic-aware BEV features. Accordingly, we
propose BEV-Paste, an effective data augmentation strategy that closely matches
with semantic-aware BEV feature. In addition, we design a Multi-Scale
Cross-Task (MSCT) head, which combines task-specific and cross-task information
to predict depth distribution and semantic segmentation more accurately,
further improving the quality of semantic-aware BEV feature. Finally, we
integrate the above modules into a novel multi-view 3D object detection
framework, namely SA-BEV. Experiments on nuScenes show that SA-BEV achieves
state-of-the-art performance. Code has been available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Robust Visual Question Answering: Datasets, Methods, and Future  Challenges</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11471</p>
  <p><b>作者</b>：Jie Ma,  Pinghui Wang,  Dechen Kong,  Zewei Wang,  Jun Liu,  Hongbin Pei,  Junzhou Zhao</p>
  <p><b>备注</b>：IEEE TPAMI (Under Review)</p>
  <p><b>关键词</b>：natural language question, accurate natural language, Visual question answering, natural language answer, question answering requires</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual question answering requires a system to provide an accurate natural
language answer given an image and a natural language question. However, it is
widely recognized that previous generic VQA methods often exhibit a tendency to
memorize biases present in the training data rather than learning proper
behaviors, such as grounding images before predicting answers. Therefore, these
methods usually achieve high in-distribution but poor out-of-distribution
performance. In recent years, various datasets and debiasing methods have been
proposed to evaluate and enhance the VQA robustness, respectively. This paper
provides the first comprehensive survey focused on this emerging fashion.
Specifically, we first provide an overview of the development process of
datasets from in-distribution and out-of-distribution perspectives. Then, we
examine the evaluation metrics employed by these datasets. Thirdly, we propose
a typology that presents the development process, similarities and differences,
robustness comparison, and technical features of existing debiasing methods.
Furthermore, we analyze and discuss the robustness of representative
vision-and-language pre-training models on VQA. Finally, through a thorough
review of the available literature and experimental analysis, we discuss the
key areas for future research from various viewpoints.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Physics-Aware Semi-Supervised Underwater Image Enhancement</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11470</p>
  <p><b>作者</b>：Hao Qi,  Xinghui Dong</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：Underwater Image Enhancement, underwater Image, underwater Image Formation, Image Enhancement Network, Image Enhancement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Underwater images normally suffer from degradation due to the transmission
medium of water bodies. Both traditional prior-based approaches and deep
learning-based methods have been used to address this problem. However, the
inflexible assumption of the former often impairs their effectiveness in
handling diverse underwater scenes, while the generalization of the latter to
unseen images is usually weakened by insufficient data. In this study, we
leverage both the physics-based underwater Image Formation Model (IFM) and deep
learning techniques for Underwater Image Enhancement (UIE). To this end, we
propose a novel Physics-Aware Dual-Stream Underwater Image Enhancement Network,
i.e., PA-UIENet, which comprises a Transmission Estimation Steam (T-Stream) and
an Ambient Light Estimation Stream (A-Stream). This network fulfills the UIE
task by explicitly estimating the degradation parameters of the IFM. We also
adopt an IFM-inspired semi-supervised learning framework, which exploits both
the labeled and unlabeled images, to address the issue of insufficient data.
Our method performs better than, or at least comparably to, eight baselines
across five testing sets in the degradation estimation and UIE tasks. This
should be due to the fact that it not only can model the degradation but also
can learn the characteristics of diverse underwater scenes.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Distribution Shift Matters for Knowledge Distillation with Webly  Collected Images</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11469</p>
  <p><b>作者</b>：Jialiang Tang,  Shuo Chen,  Gang Niu,  Masashi Sugiyama,  Chen Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge distillation, Knowledge distillation aims, data-free knowledge distillation, knowledge distillation approaches, existing knowledge distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation aims to learn a lightweight student network from a
pre-trained teacher network. In practice, existing knowledge distillation
methods are usually infeasible when the original training data is unavailable
due to some privacy issues and data management considerations. Therefore,
data-free knowledge distillation approaches proposed to collect training
instances from the Internet. However, most of them have ignored the common
distribution shift between the instances from original training data and webly
collected data, affecting the reliability of the trained student network. To
solve this problem, we propose a novel method dubbed ``Knowledge Distillation
between Different Distributions" (KD$^{3}$), which consists of three
components. Specifically, we first dynamically select useful training instances
from the webly collected data according to the combined predictions of teacher
network and student network. Subsequently, we align both the weighted features
and classifier parameters of the two networks for knowledge memorization.
Meanwhile, we also build a new contrastive learning block called
MixDistribution to generate perturbed data with a new distribution for instance
alignment, so that the student network can further learn a
distribution-invariant representation. Intensive experiments on various
benchmark datasets demonstrate that our proposed KD$^{3}$ can outperform the
state-of-the-art data-free knowledge distillation approaches.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：MatSpectNet: Material Segmentation Network with Domain-Aware and  Physically-Constrained Hyperspectral Reconstruction</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11466</p>
  <p><b>作者</b>：Yuwen Heng,  Yihong Wu,  Jiawen Chen,  Srinandan Dasmahapatra,  Hansung Kim</p>
  <p><b>备注</b>：7 pages main paper</p>
  <p><b>关键词</b>：Achieving accurate material, Hyperspectral images, accurate material segmentation, RGB images, images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Achieving accurate material segmentation for 3-channel RGB images is
challenging due to the considerable variation in a material's appearance.
Hyperspectral images, which are sets of spectral measurements sampled at
multiple wavelengths, theoretically offer distinct information for material
identification, as variations in intensity of electromagnetic radiation
reflected by a surface depend on the material composition of a scene. However,
existing hyperspectral datasets are impoverished regarding the number of images
and material categories for the dense material segmentation task, and
collecting and annotating hyperspectral images with a spectral camera is
prohibitively expensive. To address this, we propose a new model, the
MatSpectNet to segment materials with recovered hyperspectral images from RGB
images. The network leverages the principles of colour perception in modern
cameras to constrain the reconstructed hyperspectral images and employs the
domain adaptation method to generalise the hyperspectral reconstruction
capability from a spectral recovery dataset to material segmentation datasets.
The reconstructed hyperspectral images are further filtered using learned
response curves and enhanced with human perception. The performance of
MatSpectNet is evaluated on the LMD dataset as well as the OpenSurfaces
dataset. Our experiments demonstrate that MatSpectNet attains a 1.60% increase
in average pixel accuracy and a 3.42% improvement in mean class accuracy
compared with the most recent publication. The project code is attached to the
supplementary material and will be published on GitHub.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Strip-MLP: Efficient Token Interaction for Vision MLP</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11458</p>
  <p><b>作者</b>：Guiping Cao,  Shengda Luo,  Wenjian Huang,  Xiangyuan Lan,  Dongmei Jiang,  Yaowei Wang,  Jianguo Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：token interaction power, textbf, Token interaction operation, Token interaction, Strip MLP layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Token interaction operation is one of the core modules in MLP-based models to
exchange and aggregate information between different spatial locations.
However, the power of token interaction on the spatial dimension is highly
dependent on the spatial resolution of the feature maps, which limits the
model's expressive ability, especially in deep layers where the feature are
down-sampled to a small spatial size. To address this issue, we present a novel
method called \textbf{Strip-MLP} to enrich the token interaction power in three
ways. Firstly, we introduce a new MLP paradigm called Strip MLP layer that
allows the token to interact with other tokens in a cross-strip manner,
enabling the tokens in a row (or column) to contribute to the information
aggregations in adjacent but different strips of rows (or columns). Secondly, a
\textbf{C}ascade \textbf{G}roup \textbf{S}trip \textbf{M}ixing \textbf{M}odule
(CGSMM) is proposed to overcome the performance degradation caused by small
spatial feature size. The module allows tokens to interact more effectively in
the manners of within-patch and cross-patch, which is independent to the
feature spatial size. Finally, based on the Strip MLP layer, we propose a novel
\textbf{L}ocal \textbf{S}trip \textbf{M}ixing \textbf{M}odule (LSMM) to boost
the token interaction power in the local region. Extensive experiments
demonstrate that Strip-MLP significantly improves the performance of MLP-based
models on small datasets and obtains comparable or even better results on
ImageNet. In particular, Strip-MLP models achieve higher average Top-1 accuracy
than existing MLP-based models by +2.44\% on Caltech-101 and +2.16\% on
CIFAR-100. The source codes will be available
at~\href{this https URL{this https URL\_MLP}.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Attention Consistency Refined Masked Frequency Forgery Representation  for Generalizing Face Forgery Detection</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11438</p>
  <p><b>作者</b>：Decheng Liu,  Tao Chen,  Chunlei Peng,  Nannan Wang,  Ruimin Hu,  Xinbo Gao</p>
  <p><b>备注</b>：The source code and models are publicly available at this https URL</p>
  <p><b>关键词</b>：image generation technology, deep image generation, visual data forgery, data forgery detection, generation technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the successful development of deep image generation technology, visual
data forgery detection would play a more important role in social and economic
security. Existing forgery detection methods suffer from unsatisfactory
generalization ability to determine the authenticity in the unseen domain. In
this paper, we propose a novel Attention Consistency Refined masked frequency
forgery representation model toward generalizing face forgery detection
algorithm (ACMF). Most forgery technologies always bring in high-frequency
aware cues, which make it easy to distinguish source authenticity but difficult
to generalize to unseen artifact types. The masked frequency forgery
representation module is designed to explore robust forgery cues by randomly
discarding high-frequency information. In addition, we find that the forgery
attention map inconsistency through the detection network could affect the
generalizability. Thus, the forgery attention consistency is introduced to
force detectors to focus on similar attention regions for better generalization
ability. Experiment results on several public face forgery datasets
(FaceForensic++, DFD, Celeb-DF, and WDF datasets) demonstrate the superior
performance of the proposed method compared with the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Batching for Green AI -- An Exploratory Study on Inference</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11434</p>
  <p><b>作者</b>：Tim Yarally,  Luís Cruz,  Daniel Feitosa,  June Sallou,  Arie van Deursen</p>
  <p><b>备注</b>：8 pages, 4 figures, 1 table. Accepted at Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2023</p>
  <p><b>关键词</b>：essential parameter, parameter to tune, neural networks, batch size, energy consumption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The batch size is an essential parameter to tune during the development of
new neural networks. Amongst other quality indicators, it has a large degree of
influence on the model's accuracy, generalisability, training times and
parallelisability. This fact is generally known and commonly studied. However,
during the application phase of a deep learning model, when the model is
utilised by an end-user for inference, we find that there is a disregard for
the potential benefits of introducing a batch size. In this study, we examine
the effect of input batching on the energy consumption and response times of
five fully-trained neural networks for computer vision that were considered
state-of-the-art at the time of their publication. The results suggest that
batching has a significant effect on both of these metrics. Furthermore, we
present a timeline of the energy efficiency and accuracy of neural networks
over the past decade. We find that in general, energy consumption rises at a
much steeper pace than accuracy and question the necessity of this evolution.
Additionally, we highlight one particular network, ShuffleNetV2(2018), that
achieved a competitive performance for its time while maintaining a much lower
energy consumption. Nevertheless, we highlight that the results are model
dependent.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural  Radiance Fields</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11418</p>
  <p><b>作者</b>：Sungwon Hwang,  Junha Hyung,  Daejin Kim,  Min-Jung Kim,  Jaegul Choo</p>
  <p><b>备注</b>：ICCV 2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, advances in Neural, enabled high-fidelity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As recent advances in Neural Radiance Fields (NeRF) have enabled
high-fidelity 3D face reconstruction and novel view synthesis, its manipulation
also became an essential task in 3D vision. However, existing manipulation
methods require extensive human labor, such as a user-provided semantic mask
and manual attribute search unsuitable for non-expert users. Instead, our
approach is designed to require a single text to manipulate a face
reconstructed with NeRF. To do so, we first train a scene manipulator, a latent
code-conditional deformable NeRF, over a dynamic scene to control a face
deformation using the latent code. However, representing a scene deformation
with a single latent code is unfavorable for compositing local deformations
observed in different instances. As so, our proposed Position-conditional
Anchor Compositor (PAC) learns to represent a manipulated scene with spatially
varying latent codes. Their renderings with the scene manipulator are then
optimized to yield high cosine similarity to a target text in CLIP embedding
space for text-driven manipulation. To the best of our knowledge, our approach
is the first to address the text-driven manipulation of a face reconstructed
with NeRF. Extensive results, comparisons, and ablation studies demonstrate the
effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A Video-based Detector for Suspicious Activity in Examination with  OpenPose</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11413</p>
  <p><b>作者</b>：Reuben Moyo,  Stanley Ndebvu,  Michael Zimba,  Jimmy Mbelwa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：invest significant resources, learning process, crucial part, resources into maintaining, institutions invest significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Examinations are a crucial part of the learning process, and academic
institutions invest significant resources into maintaining their integrity by
preventing cheating from students or facilitators. However, cheating has become
rampant in examination setups, compromising their integrity. The traditional
method of relying on invigilators to monitor every student is impractical and
ineffective. To address this issue, there is a need to continuously record exam
sessions to monitor students for suspicious activities. However, these
recordings are often too lengthy for invigilators to analyze effectively, and
fatigue may cause them to miss significant details. To widen the coverage,
invigilators could use fixed overhead or wearable cameras. This paper
introduces a framework that uses automation to analyze videos and detect
suspicious activities during examinations efficiently and effectively. We
utilized the OpenPose framework and Convolutional Neural Network (CNN) to
identify students exchanging objects during exams. This detection system is
vital in preventing cheating and promoting academic integrity, fairness, and
quality education for institutions.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Deep Directly-Trained Spiking Neural Networks for Object Detection</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11411</p>
  <p><b>作者</b>：Qiaoyi Su,  Yuhong Chou,  Yifan Hu,  Jianing Li,  Shijie Mei,  Ziyang Zhang,  Guoqi Li</p>
  <p><b>备注</b>：Accepted by ICCV2023</p>
  <p><b>关键词</b>：Spiking neural networks, brain-inspired energy-efficient models, directly-trained SNN, Spiking neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking neural networks (SNNs) are brain-inspired energy-efficient models
that encode information in spatiotemporal dynamics. Recently, deep SNNs trained
directly have shown great success in achieving high performance on
classification tasks with very few time steps. However, how to design a
directly-trained SNN for the regression task of object detection still remains
a challenging problem. To address this problem, we propose EMS-YOLO, a novel
directly-trained SNN framework for object detection, which is the first trial
to train a deep SNN with surrogate gradients for object detection rather than
ANN-SNN conversion strategies. Specifically, we design a full-spike residual
block, EMS-ResNet, which can effectively extend the depth of the
directly-trained SNN with low power consumption. Furthermore, we theoretically
analyze and prove the EMS-ResNet could avoid gradient vanishing or exploding.
The results demonstrate that our approach outperforms the state-of-the-art
ANN-SNN conversion methods (at least 500 time steps) in extremely fewer time
steps (only 4 time steps). It is shown that our model could achieve comparable
performance to the ANN with the same architecture while consuming 5.83 times
less energy on the frame-based COCO Dataset and the event-based Gen1 Dataset.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Subject-Diffusion:Open Domain Personalized Text-to-Image Generation  without Test-time Fine-tuning</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11410</p>
  <p><b>作者</b>：Jian Ma,  Junhao Liang,  Chen Chen,  Haonan Lu</p>
  <p><b>备注</b>：14 pages, 10 figures</p>
  <p><b>关键词</b>：personalized image generation, Recent progress, image generation, personalized image, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent progress in personalized image generation using diffusion models has
been significant. However, development in the area of open-domain and
non-fine-tuning personalized image generation is proceeding rather slowly. In
this paper, we propose Subject-Diffusion, a novel open-domain personalized
image generation model that, in addition to not requiring test-time
fine-tuning, also only requires a single reference image to support
personalized generation of single- or multi-subject in any domain. Firstly, we
construct an automatic data labeling tool and use the LAION-Aesthetics dataset
to construct a large-scale dataset consisting of 76M images and their
corresponding subject detection bounding boxes, segmentation masks and text
descriptions. Secondly, we design a new unified framework that combines text
and image semantics by incorporating coarse location and fine-grained reference
image control to maximize subject fidelity and generalization. Furthermore, we
also adopt an attention control mechanism to support multi-subject generation.
Extensive qualitative and quantitative results demonstrate that our method
outperforms other SOTA frameworks in single, multiple, and human customized
image generation. Please refer to our
\href{this https URL}{project page}</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Latent-OFER: Detect, Mask, and Reconstruct with Latent Vectors for  Occluded Facial Expression Recognition</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11404</p>
  <p><b>作者</b>：Isack Lee,  Eungi Lee,  Seok Bong Yoo</p>
  <p><b>备注</b>：11 pages, 8 figures</p>
  <p><b>关键词</b>：highly controlled environments, facial expression recognition, controlled environments, real-world situations, conducted in highly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most research on facial expression recognition (FER) is conducted in highly
controlled environments, but its performance is often unacceptable when applied
to real-world situations. This is because when unexpected objects occlude the
face, the FER network faces difficulties extracting facial features and
accurately predicting facial expressions. Therefore, occluded FER (OFER) is a
challenging problem. Previous studies on occlusion-aware FER have typically
required fully annotated facial images for training. However, collecting facial
images with various occlusions and expression annotations is time-consuming and
expensive. Latent-OFER, the proposed method, can detect occlusions, restore
occluded parts of the face as if they were unoccluded, and recognize them,
improving FER accuracy. This approach involves three steps: First, the vision
transformer (ViT)-based occlusion patch detector masks the occluded position by
training only latent vectors from the unoccluded patches using the support
vector data description algorithm. Second, the hybrid reconstruction network
generates the masking position as a complete image using the ViT and
convolutional neural network (CNN). Last, the expression-relevant latent vector
extractor retrieves and uses expression-related information from all latent
vectors by applying a CNN-based class activation map. This mechanism has a
significant advantage in preventing performance degradation from occlusion by
unseen objects. The experimental results on several databases demonstrate the
superiority of the proposed method over state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：CLR: Channel-wise Lightweight Reprogramming for Continual Learning</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11386</p>
  <p><b>作者</b>：Yunhao Ge,  Yuecheng Li,  Shuo Ni,  Jiaping Zhao,  Ming-Hsuan Yang,  Laurent Itti</p>
  <p><b>备注</b>：ICCV 2023</p>
  <p><b>关键词</b>：continually accumulate knowledge, Continual learning, Reprogramming, aims to emulate, emulate the human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual learning aims to emulate the human ability to continually
accumulate knowledge over sequential tasks. The main challenge is to maintain
performance on previously learned tasks after learning new tasks, i.e., to
avoid catastrophic forgetting. We propose a Channel-wise Lightweight
Reprogramming (CLR) approach that helps convolutional neural networks (CNNs)
overcome catastrophic forgetting during continual learning. We show that a CNN
model trained on an old task (or self-supervised proxy task) could be
``reprogrammed" to solve a new task by using our proposed lightweight (very
cheap) reprogramming parameter. With the help of CLR, we have a better
stability-plasticity trade-off to solve continual learning problems: To
maintain stability and retain previous task ability, we use a common
task-agnostic immutable part as the shared ``anchor" parameter set. We then add
task-specific lightweight reprogramming parameters to reinterpret the outputs
of the immutable parts, to enable plasticity and integrate new knowledge. To
learn sequential tasks, we only train the lightweight reprogramming parameters
to learn each new task. Reprogramming parameters are task-specific and
exclusive to each task, which makes our method immune to catastrophic
forgetting. To minimize the parameter requirement of reprogramming to learn new
tasks, we make reprogramming lightweight by only adjusting essential kernels
and learning channel-wise linear mappings from anchor parameters to
task-specific domain knowledge. We show that, for general CNNs, the CLR
parameter increase is less than 0.6\% for any new task. Our method outperforms
13 state-of-the-art continual learning baselines on a new challenging sequence
of 53 image classification datasets. Code and data are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：LatentAugment: Data Augmentation via Guided Manipulation of GAN's Latent  Space</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11375</p>
  <p><b>作者</b>：Lorenzo Tronchin,  Minh H. Vu,  Paolo Soda,  Tommy Löfstedt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：technique to increase, increase the quantity, alleviate overfitting, Generative Adversarial Networks, Data Augmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data Augmentation (DA) is a technique to increase the quantity and diversity
of the training data, and by that alleviate overfitting and improve
generalisation. However, standard DA produces synthetic data for augmentation
with limited diversity. Generative Adversarial Networks (GANs) may unlock
additional information in a dataset by generating synthetic samples having the
appearance of real images. However, these models struggle to simultaneously
address three key requirements: fidelity and high-quality samples; diversity
and mode coverage; and fast sampling. Indeed, GANs generate high-quality
samples rapidly, but have poor mode coverage, limiting their adoption in DA
applications. We propose LatentAugment, a DA strategy that overcomes the low
diversity of GANs, opening up for use in DA applications. Without external
supervision, LatentAugment modifies latent vectors and moves them into latent
space regions to maximise the synthetic images' diversity and fidelity. It is
also agnostic to the dataset and the downstream task. A wide set of experiments
shows that LatentAugment improves the generalisation of a deep model
translating from MRI-to-CT beating both standard DA as well GAN-based sampling.
Moreover, still in comparison with GAN-based sampling, LatentAugment synthetic
samples show superior mode coverage and diversity. Code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Photo2Relief: Let Human in the Photograph Stand Out</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11364</p>
  <p><b>作者</b>：Zhongping Ji,  Feifei Che,  Hanshuo Liu,  Ziyi Zhao,  Yu-Wei Zhang,  Wenping Wang</p>
  <p><b>备注</b>：10 pages, 11 figures</p>
  <p><b>关键词</b>：making humans, photographs protrude, Unlike previous methods, generate art works, paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a technique for making humans in photographs
protrude like reliefs. Unlike previous methods which mostly focus on the face
and head, our method aims to generate art works that describe the whole body
activity of the character. One challenge is that there is no ground-truth for
supervised deep learning. We introduce a sigmoid variant function to manipulate
gradients tactfully and train our neural networks by equipping with a loss
function defined in gradient domain. The second challenge is that actual
photographs often across different light conditions. We used image-based
rendering technique to address this challenge and acquire rendering images and
depth data under different lighting conditions. To make a clear division of
labor in network modules, a two-scale architecture is proposed to create
high-quality relief from a single photograph. Extensive experimental results on
a variety of scenes show that our method is a highly effective solution for
generating digital 2.5D artwork from photographs.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：ParGANDA: Making Synthetic Pedestrians A Reality For Object Detection</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11360</p>
  <p><b>作者</b>：Daria Reshetova,  Guanhang Wu,  Marcel Puyat,  Chunhui Gu,  Huizhong Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Computer Vision applications, Computer Vision, number of Computer, achieve decent results, Vision applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection is the key technique to a number of Computer Vision
applications, but it often requires large amounts of annotated data to achieve
decent results. Moreover, for pedestrian detection specifically, the collected
data might contain some personally identifiable information (PII), which is
highly restricted in many countries. This label intensive and privacy
concerning task has recently led to an increasing interest in training the
detection models using synthetically generated pedestrian datasets collected
with a photo-realistic video game engine. The engine is able to generate
unlimited amounts of data with precise and consistent annotations, which gives
potential for significant gains in the real-world applications. However, the
use of synthetic data for training introduces a synthetic-to-real domain shift
aggravating the final performance. To close the gap between the real and
synthetic data, we propose to use a Generative Adversarial Network (GAN), which
performsparameterized unpaired image-to-image translation to generate more
realistic images. The key benefit of using the GAN is its intrinsic preference
of low-level changes to geometric ones, which means annotations of a given
synthetic image remain accurate even after domain translation is performed thus
eliminating the need for labeling real data. We extensively experimented with
the proposed method using MOTSynth dataset to train and MOT17 and MOT20
detection datasets to test, with experimental results demonstrating the
effectiveness of this method. Our approach not only produces visually plausible
samples but also does not require any labels of the real domain thus making it
applicable to the variety of downstream tasks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Tuning Pre-trained Model via Moment Probing</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11342</p>
  <p><b>作者</b>：Mingze Gao,  Qilong Wang,  Zhenyi Lin,  Pengfei Zhu,  Qinghua Hu,  Jingbo Zhou</p>
  <p><b>备注</b>：Accepted to ICCV 2023; Project Page: this https URL</p>
  <p><b>关键词</b>：increasing research interests, attracted increasing research, large-scale pre-trained models, research interests, fine-tuning of large-scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, efficient fine-tuning of large-scale pre-trained models has
attracted increasing research interests, where linear probing (LP) as a
fundamental module is involved in exploiting the final representations for
task-dependent classification. However, most of the existing methods focus on
how to effectively introduce a few of learnable parameters, and little work
pays attention to the commonly used LP module. In this paper, we propose a
novel Moment Probing (MP) method to further explore the potential of LP.
Distinguished from LP which builds a linear classification head based on the
mean of final features (e.g., word tokens for ViT) or classification tokens,
our MP performs a linear classifier on feature distribution, which provides the
stronger representation ability by exploiting richer statistical information
inherent in features. Specifically, we represent feature distribution by its
characteristic function, which is efficiently approximated by using first- and
second-order moments of features. Furthermore, we propose a multi-head
convolutional cross-covariance (MHC$^3$) to compute second-order moments in an
efficient and effective manner. By considering that MP could affect feature
learning, we introduce a partially shared module to learn two recalibrating
parameters (PSRP) for backbones based on MP, namely MP$_{+}$. Extensive
experiments on ten benchmarks using various models show that our MP
significantly outperforms LP and is competitive with counterparts at less
training cost, while our MP$_{+}$ achieves state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Character Time-series Matching For Robust License Plate Recognition</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11336</p>
  <p><b>作者</b>：Quang Huy Che,  Tung Do Thanh,  Cuong Truong Van</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：License Plate, popular study area, Automatic License Plate, License Plate Recognition, Plate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic License Plate Recognition (ALPR) is becoming a popular study area
and is applied in many fields such as transportation or smart city. However,
there are still several limitations when applying many current methods to
practical problems due to the variation in real-world situations such as light
changes, unclear License Plate (LP) characters, and image quality. Almost
recent ALPR algorithms process on a single frame, which reduces accuracy in
case of worse image quality. This paper presents methods to improve license
plate recognition accuracy by tracking the license plate in multiple frames.
First, the Adaptive License Plate Rotation algorithm is applied to correctly
align the detected license plate. Second, we propose a method called Character
Time-series Matching to recognize license plate characters from many
consequence frames. The proposed method archives high performance in the
UFPR-ALPR dataset which is \boldmath$96.7\%$ accuracy in real-time on RTX A5000
GPU card. We also deploy the algorithm for the Vietnamese ALPR system. The
accuracy for license plate detection and character recognition are 0.881 and
0.979 $mAP^{test}$@.5 respectively. The source code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural  Radiance Fields</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11335</p>
  <p><b>作者</b>：Wenbo Hu,  Yuling Wang,  Lin Ma,  Bangbang Yang,  Lin Gao,  Xiao Liu,  Yuewen Ma</p>
  <p><b>备注</b>：Accepted to ICCV 2023 Project page: this https URL</p>
  <p><b>关键词</b>：MipNeRF presents fine-detailed, neural radiance fields, MipNeRF presents, days for training, tremendous progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the tremendous progress in neural radiance fields (NeRF), we still
face a dilemma of the trade-off between quality and efficiency, e.g., MipNeRF
presents fine-detailed and anti-aliased renderings but takes days for training,
while Instant-ngp can accomplish the reconstruction in a few minutes but
suffers from blurring or aliasing when rendering at various distances or
resolutions due to ignoring the sampling area. To this end, we propose a novel
Tri-Mip encoding that enables both instant reconstruction and anti-aliased
high-fidelity rendering for neural radiance fields. The key is to factorize the
pre-filtered 3D feature spaces in three orthogonal mipmaps. In this way, we can
efficiently perform 3D area sampling by taking advantage of 2D pre-filtered
feature maps, which significantly elevates the rendering quality without
sacrificing efficiency. To cope with the novel Tri-Mip representation, we
propose a cone-casting rendering technique to efficiently sample anti-aliased
3D features with the Tri-Mip encoding considering both pixel imaging and
observing distance. Extensive experiments on both synthetic and real-world
datasets demonstrate our method achieves state-of-the-art rendering quality and
reconstruction speed while maintaining a compact representation that reduces
25% model size compared against Instant-ngp.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Improving Transferability of Adversarial Examples via Bayesian Attacks</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11334</p>
  <p><b>作者</b>：Qizhang Li,  Yiwen Guo,  Xiaochen Yang,  Wangmeng Zuo,  Hao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian formulation, ICLR work advocated, model input, model parameters, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a substantial extension of our work published at ICLR.
Our ICLR work advocated for enhancing transferability in adversarial examples
by incorporating a Bayesian formulation into model parameters, which
effectively emulates the ensemble of infinitely many deep neural networks,
while, in this paper, we introduce a novel extension by incorporating the
Bayesian formulation into the model input as well, enabling the joint
diversification of both the model input and model parameters. Our empirical
findings demonstrate that: 1) the combination of Bayesian formulations for both
the model input and model parameters yields significant improvements in
transferability; 2) by introducing advanced approximations of the posterior
distribution over the model input, adversarial transferability achieves further
enhancement, surpassing all state-of-the-arts when attacking without model
fine-tuning. Moreover, we propose a principled approach to fine-tune model
parameters in such an extended Bayesian formulation. The derived optimization
objective inherently encourages flat minima in the parameter space and input
space. Extensive experiments demonstrate that our method achieves a new
state-of-the-art on transfer-based attacks, improving the average success rate
on ImageNet and CIFAR-10 by 19.14% and 2.08%, respectively, when comparing with
our ICLR basic Bayesian method. We will make our code publicly available.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：HVDetFusion: A Simple and Robust Camera-Radar Fusion Framework</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11323</p>
  <p><b>作者</b>：Kai Lei,  Zhan Chen,  Shuman Jia,  Xiaoteng Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important perception module, radar data, camera data, Camera, pure Camera</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the field of autonomous driving, 3D object detection is a very important
perception module. Although the current SOTA algorithm combines Camera and
Lidar sensors, limited by the high price of Lidar, the current mainstream
landing schemes are pure Camera sensors or Camera+Radar sensors. In this study,
we propose a new detection algorithm called HVDetFusion, which is a multi-modal
detection algorithm that not only supports pure camera data as input for
detection, but also can perform fusion input of radar data and camera data. The
camera stream does not depend on the input of Radar data, thus addressing the
downside of previous methods. In the pure camera stream, we modify the
framework of Bevdet4D for better perception and more efficient inference, and
this stream has the whole 3D detection output. Further, to incorporate the
benefits of Radar signals, we use the prior information of different object
positions to filter the false positive information of the original radar data,
according to the positioning information and radial velocity information
recorded by the radar sensors to supplement and fuse the BEV features generated
by the original camera data, and the effect is further improved in the process
of fusion training. Finally, HVDetFusion achieves the new state-of-the-art
67.4\% NDS on the challenging nuScenes test set among all camera-radar 3D
object detectors. The code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：XLDA: Linear Discriminant Analysis for Scaling Continual Learning to  Extreme Classification at the Edge</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11317</p>
  <p><b>作者</b>：Karan Shah,  Vishruth Veerendranath,  Anushka Hebbar,  Raghavendra Bhat</p>
  <p><b>备注</b>：Submitted at ICML 2023: PAC-Bayes Interactive Learning Workshop</p>
  <p><b>关键词</b>：Linear Discriminant Analysis, Streaming Linear Discriminant, Discriminant Analysis, Linear Discriminant, Streaming Linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Streaming Linear Discriminant Analysis (LDA) while proven in
Class-incremental Learning deployments at the edge with limited classes (upto
1000), has not been proven for deployment in extreme classification scenarios.
In this paper, we present: (a) XLDA, a framework for Class-IL in edge
deployment where LDA classifier is proven to be equivalent to FC layer
including in extreme classification scenarios, and (b) optimizations to enable
XLDA-based training and inference for edge deployment where there is a
constraint on available compute resources. We show up to 42x speed up using a
batched training approach and up to 5x inference speedup with nearest neighbor
search on extreme datasets like AliProducts (50k classes) and Google Landmarks
V2 (81k classes)</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Generating Image-Specific Text Improves Fine-grained Image  Classification</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11315</p>
  <p><b>作者</b>：Emily Mu,  Kathleen M. Lewis,  Adrian V. Dalca,  John Guttag</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：models outperform vision-only, outperform vision-only models, outperform vision-only, text descriptions, text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent vision-language models outperform vision-only models on many image
classification tasks. However, because of the absence of paired text/image
descriptions, it remains difficult to fine-tune these models for fine-grained
image classification. In this work, we propose a method, GIST, for generating
image-specific fine-grained text descriptions from image-only datasets, and
show that these text descriptions can be used to improve classification. Key
parts of our method include 1. prompting a pretrained large language model with
domain-specific prompts to generate diverse fine-grained text descriptions for
each class and 2. using a pretrained vision-language model to match each image
to label-preserving text descriptions that capture relevant visual features in
the image. We demonstrate the utility of GIST by fine-tuning vision-language
models on the image-and-generated-text pairs to learn an aligned
vision-language representation space for improved classification. We evaluate
our learned representation space in full-shot and few-shot scenarios across
four diverse fine-grained classification datasets, each from a different
domain. Our method achieves an average improvement of $4.1\%$ in accuracy over
CLIP linear probes and an average of $1.1\%$ improvement in accuracy over the
previous state-of-the-art image-text classification method on the full-shot
datasets. Our method achieves similar improvements across few-shot regimes.
Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DPM-OT: A New Diffusion Probabilistic Model Based on Optimal Transport</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11308</p>
  <p><b>作者</b>：Zezeng Li,  ShengHao Li,  Zhanpeng Wang,  Na Lei,  Zhongxuan Luo,  Xianfeng Gu</p>
  <p><b>备注</b>：iccv2023 accepted</p>
  <p><b>关键词</b>：generally requires hundreds, diffusion probabilistic models, piecewise distribution transformation, inverse diffusion trajectory, probabilistic models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sampling from diffusion probabilistic models (DPMs) can be viewed as a
piecewise distribution transformation, which generally requires hundreds or
thousands of steps of the inverse diffusion trajectory to get a high-quality
image. Recent progress in designing fast samplers for DPMs achieves a trade-off
between sampling speed and sample quality by knowledge distillation or
adjusting the variance schedule or the denoising equation. However, it can't be
optimal in both aspects and often suffer from mode mixture in short steps. To
tackle this problem, we innovatively regard inverse diffusion as an optimal
transport (OT) problem between latents at different stages and propose the
DPM-OT, a unified learning framework for fast DPMs with a direct expressway
represented by OT map, which can generate high-quality samples within around 10
function evaluations. By calculating the semi-discrete optimal transport map
between the data latents and the white noise, we obtain an expressway from the
prior distribution to the data distribution, while significantly alleviating
the problem of mode mixture. In addition, we give the error bound of the
proposed method, which theoretically guarantees the stability of the algorithm.
Extensive experiments validate the effectiveness and advantages of DPM-OT in
terms of speed and quality (FID and mode mixture), thus representing an
efficient solution for generative modeling. Source codes are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：EndoSurf: Neural Surface Reconstruction of Deformable Tissues with  Stereo Endoscope Videos</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11307</p>
  <p><b>作者</b>：Ruyi Zha,  Xuelian Cheng,  Hongdong Li,  Mehrtash Harandi,  Zongyuan Ge</p>
  <p><b>备注</b>：MICCAI 2023 (Early Accept); Ruyi Zha and Xuelian Cheng made equal contributions. Corresponding author: Ruyi Zha (ruyi.zha@gmail.com)</p>
  <p><b>关键词</b>：Reconstructing soft tissues, stereo endoscope videos, medical applications, soft tissues, tissues from stereo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing soft tissues from stereo endoscope videos is an essential
prerequisite for many medical applications. Previous methods struggle to
produce high-quality geometry and appearance due to their inadequate
representations of 3D scenes. To address this issue, we propose a novel
neural-field-based method, called EndoSurf, which effectively learns to
represent a deforming surface from an RGBD sequence. In EndoSurf, we model
surface dynamics, shape, and texture with three neural fields. First, 3D points
are transformed from the observed space to the canonical space using the
deformation field. The signed distance function (SDF) field and radiance field
then predict their SDFs and colors, respectively, with which RGBD images can be
synthesized via differentiable volume rendering. We constrain the learned shape
by tailoring multiple regularization strategies and disentangling geometry and
appearance. Experiments on public endoscope datasets demonstrate that EndoSurf
significantly outperforms existing solutions, particularly in reconstructing
high-fidelity shapes. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：MAS: Towards Resource-Efficient Federated Multiple-Task Learning</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11285</p>
  <p><b>作者</b>：Weiming Zhuang,  Yonggang Wen,  Lingjuan Lyu,  Shuai Zhang</p>
  <p><b>备注</b>：ICCV'23. arXiv admin note: substantial text overlap with arXiv:2207.04202</p>
  <p><b>关键词</b>：distributed machine learning, emerging distributed machine, decentralized edge devices, machine learning method, tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging distributed machine learning method
that empowers in-situ model training on decentralized edge devices. However,
multiple simultaneous FL tasks could overload resource-constrained devices. In
this work, we propose the first FL system to effectively coordinate and train
multiple simultaneous FL tasks. We first formalize the problem of training
simultaneous FL tasks. Then, we present our new approach, MAS (Merge and
Split), to optimize the performance of training multiple simultaneous FL tasks.
MAS starts by merging FL tasks into an all-in-one FL task with a multi-task
architecture. After training for a few rounds, MAS splits the all-in-one FL
task into two or more FL tasks by using the affinities among tasks measured
during the all-in-one training. It then continues training each split of FL
tasks based on model parameters from the all-in-one training. Extensive
experiments demonstrate that MAS outperforms other methods while reducing
training time by 2x and reducing energy consumption by 40%. We hope this work
will inspire the community to further study and optimize training simultaneous
FL tasks.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：SimCol3D -- 3D Reconstruction during Colonoscopy Challenge</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11261</p>
  <p><b>作者</b>：Anita Rau,  Sophia Bano,  Yueming Jin,  Pablo Azagra,  Javier Morlana,  Edward Sanderson,  Bogdan J. Matuszewski,  Jae Young Lee,  Dong-Jae Lee,  Erez Posner,  Netanel Frank,  Varshini Elangovan,  Sista Raviteja,  Zhengwen Li,  Jiquan Liu,  Seenivasan Lalithkumar,  Mobarakol Islam,  Hongliang Ren,  José M.M. Montiel,  Danail Stoyanov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Colorectal cancer, common cancers, pose prediction, prediction, effective screening technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Colorectal cancer is one of the most common cancers in the world. While
colonoscopy is an effective screening technique, navigating an endoscope
through the colon to detect polyps is challenging. A 3D map of the observed
surfaces could enhance the identification of unscreened colon tissue and serve
as a training platform. However, reconstructing the colon from video footage
remains unsolved due to numerous factors such as self-occlusion, reflective
surfaces, lack of texture, and tissue deformation that limit feature-based
methods. Learning-based approaches hold promise as robust alternatives, but
necessitate extensive datasets. By establishing a benchmark, the 2022 EndoVis
sub-challenge SimCol3D aimed to facilitate data-driven depth and pose
prediction during colonoscopy. The challenge was hosted as part of MICCAI 2022
in Singapore. Six teams from around the world and representatives from academia
and industry participated in the three sub-challenges: synthetic depth
prediction, synthetic pose prediction, and real pose prediction. This paper
describes the challenge, the submitted methods, and their results. We show that
depth prediction in virtual colonoscopy is robustly solvable, while pose
estimation remains an open research question.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Towards Non-Parametric Models for Confidence Aware Image Prediction from  Low Data using Gaussian Processes</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11259</p>
  <p><b>作者</b>：Nikhil U. Shinde,  Florian Richter,  Michael C. Yip</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：informed decision making, envision future states, crucial to informed, informed decision, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to envision future states is crucial to informed decision making
while interacting with dynamic environments. With cameras providing a prevalent
and information rich sensing modality, the problem of predicting future states
from image sequences has garnered a lot of attention. Current state of the art
methods typically train large parametric models for their predictions. Though
often able to predict with accuracy, these models rely on the availability of
large training datasets to converge to useful solutions. In this paper we focus
on the problem of predicting future images of an image sequence from very
little training data. To approach this problem, we use non-parametric models to
take a probabilistic approach to image prediction. We generate probability
distributions over sequentially predicted images and propagate uncertainty
through time to generate a confidence metric for our predictions. Gaussian
Processes are used for their data efficiency and ability to readily incorporate
new training data online. We showcase our method by successfully predicting
future frames of a smooth fluid simulation environment.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Joint one-sided synthetic unpaired image translation and segmentation  for colorectal cancer prevention</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11253</p>
  <p><b>作者</b>：Enric Moreu,  Eric Arazo,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2202.08680</p>
  <p><b>关键词</b>：shown excellent performance, analysing medical images, shown excellent, excellent performance, performance in analysing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has shown excellent performance in analysing medical images.
However, datasets are difficult to obtain due privacy issues, standardization
problems, and lack of annotations. We address these problems by producing
realistic synthetic images using a combination of 3D technologies and
generative adversarial networks. We propose CUT-seg, a joint training where a
segmentation model and a generative model are jointly trained to produce
realistic images while learning to segment polyps. We take advantage of recent
one-sided translation models because they use significantly less memory,
allowing us to add a segmentation model in the training loop. CUT-seg performs
better, is computationally less expensive, and requires less real images than
other memory-intensive image translation approaches that require two stage
training. Promising results are achieved on five real polyp segmentation
datasets using only one real image and zero real annotations. As a part of this
study we release Synth-Colon, an entirely synthetic dataset that includes 20000
realistic colon images and additional details about depth and 3D geometry:
this https URL</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with  Vision-Language Models</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11227</p>
  <p><b>作者</b>：Xin Li,  Sima Behpour,  Thang Doan,  Wenbin He,  Liang Gou,  Liu Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：undefined downstream tasks, limited annotation budget, data pre-selection, downstream tasks, single pass</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we investigate the task of data pre-selection, which aims to
select instances for labeling from an unlabeled dataset through a single pass,
thereby optimizing performance for undefined downstream tasks with a limited
annotation budget. Previous approaches to data pre-selection relied solely on
visual features extracted from foundation models, such as CLIP and BLIP-2, but
largely ignored the powerfulness of text features. In this work, we argue that,
with proper design, the joint feature space of both vision and text can yield a
better representation for data pre-selection. To this end, we introduce UP-DP,
a simple yet effective unsupervised prompt learning approach that adapts
vision-language models, like BLIP-2, for data pre-selection. Specifically, with
the BLIP-2 parameters frozen, we train text prompts to extract the joint
features with improved representation, ensuring a diverse cluster structure
that covers the entire dataset. We extensively compare our method with the
state-of-the-art using seven benchmark datasets in different settings,
achieving up to a performance gain of 20%. Interestingly, the prompts learned
from one dataset demonstrate significant generalizability and can be applied
directly to enhance the feature extraction of BLIP-2 from other datasets. To
the best of our knowledge, UP-DP is the first work to incorporate unsupervised
prompt learning in a vision-language model for data pre-selection.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Heuristic Hyperparameter Choice for Image Anomaly Detection</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11197</p>
  <p><b>作者</b>：Zeyu Jiang,  João P. C. Bertoldo,  Etienne Decencière</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify images deviating, images deviating significantly, fundamental computer vision, computer vision problem, learning neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD) in images is a fundamental computer vision problem by
deep learning neural network to identify images deviating significantly from
normality. The deep features extracted from pretrained models have been proved
to be essential for AD based on multivariate Gaussian distribution analysis.
However, since models are usually pretrained on a large dataset for
classification tasks such as ImageNet, they might produce lots of redundant
features for AD, which increases computational cost and degrades the
performance. We aim to do the dimension reduction of Negated Principal
Component Analysis (NPCA) for these features. So we proposed some heuristic to
choose hyperparameter of NPCA algorithm for getting as fewer components of
features as possible while ensuring a good performance.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Towards General Game Representations: Decomposing Games Pixels into  Content and Style</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11141</p>
  <p><b>作者</b>：Chintan Trivedi,  Konstantinos Makantasis,  Antonios Liapis,  Georgios N. Yannakakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rich contextual information, On-screen game footage, footage contains rich, rich contextual, contextual information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>On-screen game footage contains rich contextual information that players
process when playing and experiencing a game. Learning pixel representations of
games can benefit artificial intelligence across several downstream tasks
including game-playing agents, procedural content generation, and player
modelling. The generalizability of these methods, however, remains a challenge,
as learned representations should ideally be shared across games with similar
game mechanics. This could allow, for instance, game-playing agents trained on
one game to perform well in similar games with no re-training. This paper
explores how generalizable pre-trained computer vision encoders can be for such
tasks, by decomposing the latent space into content embeddings and style
embeddings. The goal is to minimize the domain gap between games of the same
genre when it comes to game content critical for downstream tasks, and ignore
differences in graphical style. We employ a pre-trained Vision Transformer
encoder and a decomposition technique based on game genres to obtain separate
content and style embeddings. Our findings show that the decomposed embeddings
achieve style invariance across multiple games while still maintaining strong
content extraction capabilities. We argue that the proposed decomposition of
content and style offers better generalization capacities across game
environments independently of the downstream task.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Diffusion Sampling with Momentum for Mitigating Divergence Artifacts</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11118</p>
  <p><b>作者</b>：Suttisak Wizadwongsa,  Worameth Chinchuthakun,  Pramook Khungurn,  Amit Raj,  Supasorn Suwajanakorn</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：slow sampling remains, remarkable success, remains a persistent, Heavy Ball, Generalized Heavy Ball</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable success of diffusion models in image generation, slow
sampling remains a persistent issue. To accelerate the sampling process, prior
studies have reformulated diffusion sampling as an ODE/SDE and introduced
higher-order numerical methods. However, these methods often produce divergence
artifacts, especially with a low number of sampling steps, which limits the
achievable acceleration. In this paper, we investigate the potential causes of
these artifacts and suggest that the small stability regions of these methods
could be the principal cause. To address this issue, we propose two novel
techniques. The first technique involves the incorporation of Heavy Ball (HB)
momentum, a well-known technique for improving optimization, into existing
diffusion numerical methods to expand their stability regions. We also prove
that the resulting methods have first-order convergence. The second technique,
called Generalized Heavy Ball (GHVB), constructs a new high-order method that
offers a variable trade-off between accuracy and artifact suppression.
Experimental results show that our techniques are highly effective in reducing
artifacts and improving image quality, surpassing state-of-the-art diffusion
solvers on both pixel-based and latent-based diffusion models for low-step
sampling. Our research provides novel insights into the design of numerical
methods for future diffusion work.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Comparison between transformers and convolutional models for  fine-grained classification of insects</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11112</p>
  <p><b>作者</b>：Rita Pucci,  Vincent J. Kalkman,  Dan Stowell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：finding discriminatory features, discriminatory features, classification is challenging, challenging due, difficulty of finding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-grained classification is challenging due to the difficulty of finding
discriminatory features. This problem is exacerbated when applied to
identifying species within the same taxonomical class. This is because species
are often sharing morphological characteristics that make them difficult to
differentiate. We consider the taxonomical class of Insecta. The identification
of insects is essential in biodiversity monitoring as they are one of the
inhabitants at the base of many ecosystems. Citizen science is doing brilliant
work of collecting images of insects in the wild giving the possibility to
experts to create improved distribution maps in all countries. We have billions
of images that need to be automatically classified and deep neural network
algorithms are one of the main techniques explored for fine-grained tasks. At
the SOTA, the field of deep learning algorithms is extremely fruitful, so how
to identify the algorithm to use? We focus on Odonata and Coleoptera orders,
and we propose an initial comparative study to analyse the two best-known layer
structures for computer vision: transformer and convolutional layers. We
compare the performance of T2TViT, a fully transformer-base, EfficientNet, a
fully convolutional-base, and ViTAE, a hybrid. We analyse the performance of
the three models in identical conditions evaluating the performance per
species, per morph together with sex, the inference time, and the overall
performance with unbalanced datasets of images from smartphones. Although we
observe high performances with all three families of models, our analysis shows
that the hybrid model outperforms the fully convolutional-base and fully
transformer-base models on accuracy performance and the fully transformer-base
model outperforms the others on inference speed and, these prove the
transformer to be robust to the shortage of samples and to be faster at
inference time.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Flatness-Aware Minimization for Domain Generalization</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11108</p>
  <p><b>作者</b>：Xingxuan Zhang,  Renzhe Xu,  Han Yu,  Yancheng Dong,  Pengfei Tian,  Peng Cu</p>
  <p><b>备注</b>：Accepted by ICCV2023</p>
  <p><b>关键词</b>：unknown distribution shifts, learn robust models, seeks to learn, distribution shifts, learn robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain generalization (DG) seeks to learn robust models that generalize well
under unknown distribution shifts. As a critical aspect of DG, optimizer
selection has not been explored in depth. Currently, most DG methods follow the
widely used benchmark, DomainBed, and utilize Adam as the default optimizer for
all datasets. However, we reveal that Adam is not necessarily the optimal
choice for the majority of current DG methods and datasets. Based on the
perspective of loss landscape flatness, we propose a novel approach,
Flatness-Aware Minimization for Domain Generalization (FAD), which can
efficiently optimize both zeroth-order and first-order flatness simultaneously
for DG. We provide theoretical analyses of the FAD's out-of-distribution (OOD)
generalization error and convergence. Our experimental results demonstrate the
superiority of FAD on various DG datasets. Additionally, we confirm that FAD is
capable of discovering flatter optima in comparison to other zeroth-order and
first-order flatness-aware optimization methods.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：CSSL-RHA: Contrastive Self-Supervised Learning for Robust Handwriting  Authentication</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11100</p>
  <p><b>作者</b>：Jingyao Wang,  Luntian Mou,  Changwen Zheng,  Wen Gao</p>
  <p><b>备注</b>：10 pages, 4 figures, 3 tables, submitted to ACM MM 2023</p>
  <p><b>关键词</b>：cultural heritage protection, heritage protection, valuable tool, fraud prevention, prevention and cultural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Handwriting authentication is a valuable tool used in various fields, such as
fraud prevention and cultural heritage protection. However, it remains a
challenging task due to the complex features, severe damage, and lack of
supervision. In this paper, we propose a novel Contrastive Self-Supervised
Learning framework for Robust Handwriting Authentication (CSSL-RHA) to address
these issues. It can dynamically learn complex yet important features and
accurately predict writer identities. Specifically, to remove the negative
effects of imperfections and redundancy, we design an information-theoretic
filter for pre-processing and propose a novel adaptive matching scheme to
represent images as patches of local regions dominated by more important
features. Through online optimization at inference time, the most informative
patch embeddings are identified as the "most important" elements. Furthermore,
we employ contrastive self-supervised training with a momentum-based paradigm
to learn more general statistical structures of handwritten data without
supervision. We conduct extensive experiments on five benchmark datasets and
our manually annotated dataset EN-HA, which demonstrate the superiority of our
CSSL-RHA compared to baselines. Additionally, we show that our proposed model
can still effectively achieve authentication even under abnormal circumstances,
such as data falsification and corruption.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Cascaded multitask U-Net using topological loss for vessel segmentation  and centerline extraction</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11603</p>
  <p><b>作者</b>：Pierre Rougé,  Nicolas Passat,  Odyssée Merveille</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：computer-aided diagnosis tools, diagnosis tools dealing, crucial preliminary tasks, crucial preliminary, computer-aided diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vessel segmentation and centerline extraction are two crucial preliminary
tasks for many computer-aided diagnosis tools dealing with vascular diseases.
Recently, deep-learning based methods have been widely applied to these tasks.
However, classic deep-learning approaches struggle to capture the complex
geometry and specific topology of vascular networks, which is of the utmost
importance in most applications. To overcome these limitations, the clDice
loss, a topological loss that focuses on the vessel centerlines, has been
recently proposed. This loss requires computing, with a proposed soft-skeleton
algorithm, the skeletons of both the ground truth and the predicted
segmentation. However, the soft-skeleton algorithm provides suboptimal results
on 3D images, which makes the clDice hardly suitable on 3D images. In this
paper, we propose to replace the soft-skeleton algorithm by a U-Net which
computes the vascular skeleton directly from the segmentation. We show that our
method provides more accurate skeletons than the soft-skeleton algorithm. We
then build upon this network a cascaded U-Net trained with the clDice loss to
embed topological constraints during the segmentation. The resulting model is
able to predict both the vessel segmentation and centerlines with a more
accurate topology.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：CortexMorph: fast cortical thickness estimation via diffeomorphic  registration using VoxelMorph</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11567</p>
  <p><b>作者</b>：Richard McKinley,  Christian Rummel</p>
  <p><b>备注</b>：Accepted (early acceptance) at MICCAI 2023</p>
  <p><b>关键词</b>：MRI studies, Freesurfer in MRI, psychiatric conditions, cortical thickness, band is linked</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The thickness of the cortical band is linked to various neurological and
psychiatric conditions, and is often estimated through surface-based methods
such as Freesurfer in MRI studies. The DiReCT method, which calculates cortical
thickness using a diffeomorphic deformation of the gray-white matter interface
towards the pial surface, offers an alternative to surface-based methods.
Recent studies using a synthetic cortical thickness phantom have demonstrated
that the combination of DiReCT and deep-learning-based segmentation is more
sensitive to subvoxel cortical thinning than Freesurfer.
While anatomical segmentation of a T1-weighted image now takes seconds,
existing implementations of DiReCT rely on iterative image registration methods
which can take up to an hour per volume. On the other hand, learning-based
deformable image registration methods like VoxelMorph have been shown to be
faster than classical methods while improving registration accuracy. This paper
proposes CortexMorph, a new method that employs unsupervised deep learning to
directly regress the deformation field needed for DiReCT. By combining
CortexMorph with a deep-learning-based segmentation model, it is possible to
estimate region-wise thickness in seconds from a T1-weighted image, while
maintaining the ability to detect cortical atrophy. We validate this claim on
the OASIS-3 dataset and the synthetic cortical thickness phantom of Rusak et
al.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：UWAT-GAN: Fundus Fluorescein Angiography Synthesis via Ultra-wide-angle  Transformation Multi-scale GAN</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11530</p>
  <p><b>作者</b>：Zhaojie Fang,  Zhanghao Chen,  Pengxue Wei,  Wangting Li,  Shaochong Zhang,  Ahmed Elazab,  Gangyong Jia,  Ruiquan Ge,  Changmiao Wang</p>
  <p><b>备注</b>：26th International Conference on Medical Image Computing and Computer Assisted Intervention</p>
  <p><b>关键词</b>：UWF Scanning Laser, Scanning Laser, essential examination, examination for clinical, clinical and differential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fundus photography is an essential examination for clinical and differential
diagnosis of fundus diseases. Recently, Ultra-Wide-angle Fundus (UWF)
techniques, UWF Fluorescein Angiography (UWF-FA) and UWF Scanning Laser
Ophthalmoscopy (UWF-SLO) have been gradually put into use. However, Fluorescein
Angiography (FA) and UWF-FA require injecting sodium fluorescein which may have
detrimental influences. To avoid negative impacts, cross-modality medical image
generation algorithms have been proposed. Nevertheless, current methods in
fundus imaging could not produce high-resolution images and are unable to
capture tiny vascular lesion areas. This paper proposes a novel conditional
generative adversarial network (UWAT-GAN) to synthesize UWF-FA from UWF-SLO.
Using multi-scale generators and a fusion module patch to better extract global
and local information, our model can generate high-resolution images. Moreover,
an attention transmit module is proposed to help the decoder learn effectively.
Besides, a supervised approach is used to train the network using multiple new
weighted losses on different scales of data. Experiments on an in-house UWF
image dataset demonstrate the superiority of the UWAT-GAN over the
state-of-the-art methods. The source code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Bone mineral density estimation from a plain X-ray image by learning  decomposition into projections of bone-segmented computed tomography</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11513</p>
  <p><b>作者</b>：Yi Gu,  Yoshito Otake,  Keisuke Uemura,  Mazen Soufi,  Masaki Takao,  Hugues Talbot,  Seiji Okada,  Nobuhiko Sugano,  Yoshinobu Sato</p>
  <p><b>备注</b>：20 pages and 22 figures</p>
  <p><b>关键词</b>：daily living activities, prevalent bone disease, living activities, fractures in fragile, decline in daily</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Osteoporosis is a prevalent bone disease that causes fractures in fragile
bones, leading to a decline in daily living activities. Dual-energy X-ray
absorptiometry (DXA) and quantitative computed tomography (QCT) are highly
accurate for diagnosing osteoporosis; however, these modalities require special
equipment and scan protocols. To frequently monitor bone health, low-cost,
low-dose, and ubiquitously available diagnostic methods are highly anticipated.
In this study, we aim to perform bone mineral density (BMD) estimation from a
plain X-ray image for opportunistic screening, which is potentially useful for
early diagnosis. Existing methods have used multi-stage approaches consisting
of extraction of the region of interest and simple regression to estimate BMD,
which require a large amount of training data. Therefore, we propose an
efficient method that learns decomposition into projections of bone-segmented
QCT for BMD estimation under limited datasets. The proposed method achieved
high accuracy in BMD estimation, where Pearson correlation coefficients of
0.880 and 0.920 were observed for DXA-measured BMD and QCT-measured BMD
estimation tasks, respectively, and the root mean square of the coefficient of
variation values were 3.27 to 3.79% for four measurements with different poses.
Furthermore, we conducted extensive validation experiments, including
multi-pose, uncalibrated-CT, and compression experiments toward actual
application in routine clinical practice.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Probabilistic Modeling of Inter- and Intra-observer Variability in  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11397</p>
  <p><b>作者</b>：Arne Schmidt,  Pablo Morales-Álvarez,  Rafael Molina</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：challenging task, due to inter, intra-observer variability, iNtra-Observer variation NetwOrk, called Probabilistic Inter-Observer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image segmentation is a challenging task, particularly due to inter-
and intra-observer variability, even between medical experts. In this paper, we
propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer
variation NetwOrk (Pionono). It captures the labeling behavior of each rater
with a multidimensional probability distribution and integrates this
information with the feature maps of the image to produce probabilistic
segmentation predictions. The model is optimized by variational inference and
can be trained end-to-end. It outperforms state-of-the-art models such as
STAPLE, Probabilistic U-Net, and models based on confusion matrices.
Additionally, Pionono predicts multiple coherent segmentation maps that mimic
the rater's expert opinion, which provides additional valuable information for
the diagnostic process. Experiments on real-world cancer segmentation datasets
demonstrate the high accuracy and efficiency of Pionono, making it a powerful
tool for medical image analysis.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Screening Mammography Breast Cancer Detection</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11274</p>
  <p><b>作者</b>：Debajyoti Chakraborty</p>
  <p><b>备注</b>：Released @ Apr 2023. For associated project files, see this https URL</p>
  <p><b>关键词</b>：cancer-related deaths, false positives, expensive and prone, prone to false, unnecessary follow-up</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer is a leading cause of cancer-related deaths, but current
programs are expensive and prone to false positives, leading to unnecessary
follow-up and patient anxiety. This paper proposes a solution to automated
breast cancer detection, to improve the efficiency and accuracy of screening
programs. Different methodologies were tested against the RSNA dataset of
radiographic breast images of roughly 20,000 female patients and yielded an
average validation case pF1 score of 0.56 across methods.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Frequency-aware optical coherence tomography image super-resolution via  conditional generative adversarial neural network</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11130</p>
  <p><b>作者</b>：Xueshen Li,  Zhenxing Dong,  Hongshan Liu,  Jennifer J. Kang-Mieler,  Yuye Ling,  Yu Gan</p>
  <p><b>备注</b>：13 pages, 7 figures, submitted to Biomedical Optics Express special issue</p>
  <p><b>关键词</b>：Optical coherence tomography, medical image-based diagnosis, Optical coherence, coherence tomography, cardiology and ophthalmology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optical coherence tomography (OCT) has stimulated a wide range of medical
image-based diagnosis and treatment in fields such as cardiology and
ophthalmology. Such applications can be further facilitated by deep
learning-based super-resolution technology, which improves the capability of
resolving morphological structures. However, existing deep learning-based
method only focuses on spatial distribution and disregard frequency fidelity in
image reconstruction, leading to a frequency bias. To overcome this limitation,
we propose a frequency-aware super-resolution framework that integrates three
critical frequency-based modules (i.e., frequency transformation, frequency
skip connection, and frequency alignment) and frequency-based loss function
into a conditional generative adversarial network (cGAN). We conducted a
large-scale quantitative study from an existing coronary OCT dataset to
demonstrate the superiority of our proposed framework over existing deep
learning frameworks. In addition, we confirmed the generalizability of our
framework by applying it to fish corneal images and rat retinal images,
demonstrating its capability to super-resolve morphological details in eye
imaging.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：OUTFOX: LLM-generated Essay Detection through In-context Learning with  Adversarially Generated Examples</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11729</p>
  <p><b>作者</b>：Ryuto Koike,  Masahiro Kaneko,  Naoaki Okazaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, achieved human-level fluency, Large Language, LLM-generated texts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have achieved human-level fluency in text
generation, making it difficult to distinguish between human-written and
LLM-generated texts. This poses a growing risk of misuse of LLMs and demands
the development of detectors to identify LLM-generated texts. However, existing
detectors degrade detection accuracy by simply paraphrasing LLM-generated
texts. Furthermore, the effectiveness of these detectors in real-life
situations, such as when students use LLMs for writing homework assignments
(e.g., essays) and quickly learn how to evade these detectors, has not been
explored. In this paper, we propose OUTFOX, a novel framework that improves the
robustness of LLM-generated-text detectors by allowing both the detector and
the attacker to consider each other's output and apply this to the domain of
student essays. In our framework, the attacker uses the detector's prediction
labels as examples for in-context learning and adversarially generates essays
that are harder to detect. While the detector uses the adversarially generated
essays as examples for in-context learning to learn to detect essays from a
strong attacker. Our experiments show that our proposed detector learned
in-context from the attacker improves the detection performance on the attacked
dataset by up to +41.3 point F1-score. While our proposed attacker can
drastically degrade the performance of the detector by up to -57.0 point
F1-score compared to the paraphrasing method.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11661</p>
  <p><b>作者</b>：Mayug Maniparambil,  Chris Vorster,  Derek Molloy,  Noel Murphy,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：10 pages, Pre-print</p>
  <p><b>关键词</b>：providing good performance, large Vision-Language Models, Contrastive pretrained large, pretrained large Vision-Language, revolutionized visual representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have
revolutionized visual representation learning by providing good performance on
downstream datasets. VLMs are 0-shot adapted to a downstream dataset by
designing prompts that are relevant to the dataset. Such prompt engineering
makes use of domain expertise and a validation dataset. Meanwhile, recent
developments in generative pretrained models like GPT-4 mean they can be used
as advanced internet search tools. They can also be manipulated to provide
visual information in any structure. In this work, we show that GPT-4 can be
used to generate text that is visually descriptive and how this can be used to
adapt CLIP to downstream tasks. We show considerable improvements in 0-shot
transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD
(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.
We also design a simple few-shot adapter that learns to choose the best
possible sentences to construct generalizable classifiers that outperform the
recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized
fine-grained datasets. We will release the code, prompts, and auxiliary text
dataset upon acceptance.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11636</p>
  <p><b>作者</b>：Runjia Li,  Shuyang Sun,  Mohamed Elhoseiny,  Philip Torr</p>
  <p><b>备注</b>：Accepted by ICCV 2023</p>
  <p><b>关键词</b>：Humorous Image Captions, Humorous Image, Image Captions, paper presents OxfordTVG-HIC, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale
dataset for humour generation and understanding. Humour is an abstract,
subjective, and context-dependent cognitive construct involving several
cognitive factors, making it a challenging task to generate and interpret.
Hence, humour generation and understanding can serve as a new task for
evaluating the ability of deep-learning methods to process abstract and
subjective information. Due to the scarcity of data, humour-related generation
tasks such as captioning remain under-explored. To address this gap,
OxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to
train a generalizable humour captioning model. Contrary to existing captioning
datasets, OxfordTVG-HIC features a wide range of emotional and semantic
diversity resulting in out-of-context examples that are particularly conducive
to generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive
content. We also show how OxfordTVG-HIC can be leveraged for evaluating the
humour of a generated text. Through explainability analysis of the trained
models, we identify the visual and linguistic cues influential for evoking
humour prediction (and generation). We observe qualitatively that these cues
are aligned with the benign violation theory of humour in cognitive psychology.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：CausE: Towards Causal Knowledge Graph Embedding</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11610</p>
  <p><b>作者</b>：Yichi Zhang,  Wen Zhang</p>
  <p><b>备注</b>：Accepted by CCKS 2023 as a research paper</p>
  <p><b>关键词</b>：continuous vector spaces, knowledge graph completion, Knowledge graph embedding, Knowledge graph, focuses on representing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph embedding (KGE) focuses on representing the entities and
relations of a knowledge graph (KG) into the continuous vector spaces, which
can be employed to predict the missing triples to achieve knowledge graph
completion (KGC). However, KGE models often only briefly learn structural
correlations of triple data and embeddings would be misled by the trivial
patterns and noisy links in real-world KGs. To address this issue, we build the
new paradigm of KGE in the context of causality and embedding disentanglement.
We further propose a Causality-enhanced knowledge graph Embedding (CausE)
framework. CausE employs causal intervention to estimate the causal effect of
the confounder embeddings and design new training objectives to make stable
predictions. Experimental results demonstrate that CausE could outperform the
baseline models and achieve state-of-the-art KGC performance. We release our
code in this https URL.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Change of Heart: Improving Speech Emotion Recognition through  Speech-to-Text Modality Conversion</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11584</p>
  <p><b>作者</b>：Zeinab Sadat Taghavi,  Ali Satvaty,  Hossein Sameti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Speech Emotion Recognition, Emotion Recognition, emotion recognition performance, enhancing emotion recognition, MELD dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) is a challenging task. In this paper, we
introduce a modality conversion concept aimed at enhancing emotion recognition
performance on the MELD dataset. We assess our approach through two
experiments: first, a method named Modality-Conversion that employs automatic
speech recognition (ASR) systems, followed by a text classifier; second, we
assume perfect ASR output and investigate the impact of modality conversion on
SER, this method is called Modality-Conversion++. Our findings indicate that
the first method yields substantial results, while the second method
outperforms state-of-the-art (SOTA) speech-based approaches in terms of SER
weighted-F1 (WF1) score on the MELD dataset. This research highlights the
potential of modality conversion for tasks that can be conducted in alternative
modalities.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Advancing Visual Grounding with Scene Knowledge: Benchmark and Method</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11558</p>
  <p><b>作者</b>：Zhihong Chen,  Ruifei Zhang,  Yibing Song,  Xiang Wan,  Guanbin Li</p>
  <p><b>备注</b>：Computer Vision and Natural Language Processing. 21 pages, 14 figures. CVPR-2023</p>
  <p><b>关键词</b>：establish fine-grained alignment, Visual grounding, aims to establish, vision and language, establish fine-grained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual grounding (VG) aims to establish fine-grained alignment between vision
and language. Ideally, it can be a testbed for vision-and-language models to
evaluate their understanding of the images and texts and their reasoning
abilities over their joint space. However, most existing VG datasets are
constructed using simple description texts, which do not require sufficient
reasoning over the images and texts. This has been demonstrated in a recent
study~\cite{luo2022goes}, where a simple LSTM-based text encoder without
pretraining can achieve state-of-the-art performance on mainstream VG datasets.
Therefore, in this paper, we propose a novel benchmark of \underline{S}cene
\underline{K}nowledge-guided \underline{V}isual \underline{G}rounding (SK-VG),
where the image content and referring expressions are not sufficient to ground
the target objects, forcing the models to have a reasoning ability on the
long-form scene knowledge. To perform this task, we propose two approaches to
accept the triple-type input, where the former embeds knowledge into the image
features before the image-query interaction; the latter leverages linguistic
structure to assist in computing the image-text matching. We conduct extensive
experiments to analyze the above methods and show that the proposed approaches
achieve promising results but still leave room for improvement, including
performance and interpretability. The dataset and code are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Bridging Vision and Language Encoders: Parameter-Efficient Tuning for  Referring Image Segmentation</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11545</p>
  <p><b>作者</b>：Zunnan Xu,  Zhihong Chen,  Yong Zhang,  Yibing Song,  Xiang Wan,  Guanbin Li</p>
  <p><b>备注</b>：Computer Vision and Natural Language Processing. 14 pages, 8 figures. ICCV-2023</p>
  <p><b>关键词</b>：hardware resource savings, studies investigate dense, investigate dense prediction, dense prediction tasks, Efficient Tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Parameter Efficient Tuning (PET) has gained attention for reducing the number
of parameters while maintaining performance and providing better hardware
resource savings, but few studies investigate dense prediction tasks and
interaction between modalities. In this paper, we do an investigation of
efficient tuning problems on referring image segmentation. We propose a novel
adapter called Bridger to facilitate cross-modal information exchange and
inject task-specific information into the pre-trained model. We also design a
lightweight decoder for image segmentation. Our approach achieves comparable or
superior performance with only 1.61\% to 3.38\% backbone parameter updates,
evaluated on challenging benchmarks. The code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Multi-modal Hate Speech Detection using Machine Learning</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11519</p>
  <p><b>作者</b>：Fariha Tahosin Boishakhi,  Ponkoj Chandra Shill,  Md. Golam Rabiul Alam</p>
  <p><b>备注</b>：5 pages, 2 figures, conference</p>
  <p><b>关键词</b>：continuous growth, growth of internet, internet users, users and media, hard to track</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous growth of internet users and media content, it is very
hard to track down hateful speech in audio and video. Converting video or audio
into text does not detect hate speech accurately as human sometimes uses
hateful words as humorous or pleasant in sense and also uses different voice
tones or show different action in the video. The state-ofthe-art hate speech
detection models were mostly developed on a single modality. In this research,
a combined approach of multimodal system has been proposed to detect hate
speech from video contents by extracting feature images, feature values
extracted from the audio, text and used machine learning and Natural language
processing.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11516</p>
  <p><b>作者</b>：Kais Dukes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：augmenting human intelligence, paper defines, approach for augmenting, optimal goal solving, goal solving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper defines a new approach for augmenting human intelligence with AI
for optimal goal solving. Our proposed AI, Indigo, is an acronym for Informed
Numerical Decision-making through Iterative Goal-Oriented optimization. When
combined with a human collaborator, we term the joint system IndigoVX, for
Virtual eXpert. The system is conceptually simple. We envisage this method
being applied to games or business strategies, with the human providing
strategic context and the AI offering optimal, data-driven moves. Indigo
operates through an iterative feedback loop, harnessing the human expert's
contextual knowledge and the AI's data-driven insights to craft and refine
strategies towards a well-defined goal. Using a quantified three-score schema,
this hybridization allows the combined team to evaluate strategies and refine
their plan, while adapting to challenges and changes in real-time.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Incorporating Human Translator Style into English-Turkish Literary  Machine Translation</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11457</p>
  <p><b>作者</b>：Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine translation systems, general domain, machine translation, designed to serve, growing tendency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although machine translation systems are mostly designed to serve in the
general domain, there is a growing tendency to adapt these systems to other
domains like literary translation. In this paper, we focus on English-Turkish
literary translation and develop machine translation models that take into
account the stylistic features of translators. We fine-tune a pre-trained
machine translation model by the manually-aligned works of a particular
translator. We make a detailed analysis of the effects of manual and automatic
alignments, data augmentation methods, and corpus size on the translations. We
propose an approach based on stylistic features to evaluate the style of a
translator in the output translations. We show that the human translator style
can be highly recreated in the target machine translations by adapting the
models to the style of the translator.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：MeetEval: A Toolkit for Computation of Word Error Rates for Meeting  Transcription Systems</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11394</p>
  <p><b>作者</b>：Thilo von Neumann,  Christoph Boeddeker,  Marc Delcroix,  Reinhold Haeb-Umbach</p>
  <p><b>备注</b>：Accepted for presentation at the Chime7 workshop 2023</p>
  <p><b>关键词</b>：Word Error Rates, meeting transcription systems, open-source toolkit, toolkit to evaluate, evaluate all kinds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>MeetEval is an open-source toolkit to evaluate all kinds of meeting
transcription systems. It provides a unified interface for the computation of
commonly used Word Error Rates (WERs), specifically cpWER, ORC WER and MIMO WER
along other WER definitions. We extend the cpWER computation by a temporal
constraint to ensure that only words are identified as correct when the
temporal alignment is plausible. This leads to a better quality of the matching
of the hypothesis string to the reference string that more closely resembles
the actual transcription quality, and a system is penalized if it provides poor
time annotations. Since word-level timing information is often not available,
we present a way to approximate exact word-level timings from segment-level
timings (e.g., a sentence) and show that the approximation leads to a similar
WER as a matching with exact word-level annotations. At the same time, the time
constraint leads to a speedup of the matching algorithm, which outweighs the
additional overhead caused by processing the time stamps.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect  ChatGPT-Generated Text</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11380</p>
  <p><b>作者</b>：Lingyi Yang,  Feng Jiang,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mitigate potential risks, large-scale language models, potential risks, including misinformation, remarkable capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The remarkable capabilities of large-scale language models, such as ChatGPT,
in text generation have incited awe and spurred researchers to devise detectors
to mitigate potential risks, including misinformation, phishing, and academic
dishonesty. Despite this, most previous studies, including HC3, have been
predominantly geared towards creating detectors that differentiate between
purely ChatGPT-generated texts and human-authored texts. This approach,
however, fails to work on discerning texts generated through human-machine
collaboration, such as ChatGPT-polished texts. Addressing this gap, we
introduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts),
facilitating the construction of more robust detectors. It diverges from extant
corpora by comprising pairs of human-written and ChatGPT-polished abstracts
instead of purely ChatGPT-generated texts. Additionally, we propose the "Polish
Ratio" method, an innovative measure of ChatGPT's involvement in text
generation based on editing distance. It provides a mechanism to measure the
degree of human originality in the resulting text. Our experimental results
show our proposed model has better robustness on the HPPT dataset and two
existing datasets (HC3 and CDB). Furthermore, the "Polish Ratio" we proposed
offers a more comprehensive explanation by quantifying the degree of ChatGPT
involvement, which indicates that a Polish Ratio value greater than 0.2
signifies ChatGPT involvement and a value exceeding 0.6 implies that ChatGPT
generates most of the text.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11346</p>
  <p><b>作者</b>：Zihan Guan,  Zihao Wu,  Zhengliang Liu,  Dufan Wu,  Hui Ren,  Quanzheng Li,  Xiang Li,  Ninghao Liu</p>
  <p><b>备注</b>：16 pages, 10 figures</p>
  <p><b>关键词</b>：Participant recruitment based, unstructured medical texts, clinical research, clinical notes, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Participant recruitment based on unstructured medical texts such as clinical
notes and radiology reports has been a challenging yet important task for the
cohort establishment in clinical research. Recently, Large Language Models
(LLMs) such as ChatGPT have achieved tremendous success in various downstream
tasks thanks to their promising performance in language understanding,
inference, and generation. It is then natural to test their feasibility in
solving the cohort recruitment task, which involves the classification of a
given paragraph of medical text into disease label(s). However, when applied to
knowledge-intensive problem settings such as medical text classification, where
the LLMs are expected to understand the decision made by human experts and
accurately identify the implied disease labels, the LLMs show a mediocre
performance. A possible explanation is that, by only using the medical text,
the LLMs neglect to use the rich context of additional information that
languages afford. To this end, we propose to use a knowledge graph as auxiliary
information to guide the LLMs in making predictions. Moreover, to further boost
the LLMs adapt to the problem setting, we apply a chain-of-thought (CoT) sample
selection strategy enhanced by reinforcement learning, which selects a set of
CoT samples given each individual medical report. Experimental results and
various ablation studies show that our few-shot learning method achieves
satisfactory performance compared with fine-tuning strategies and gains superb
advantages when the available data is limited. The code and sample dataset of
the proposed CohortGPT model is available at:
https://anonymous.4open.science/r/CohortGPT-4872/</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：DEFTri: A Few-Shot Label Fused Contextual Representation Learning For  Product Defect Triage in e-Commerce</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11344</p>
  <p><b>作者</b>：Ipsita Mohanty</p>
  <p><b>备注</b>：In Proceedings of the Fifth Workshop on e-Commerce and NLP ECNLP 5 2022 Pages 1-7</p>
  <p><b>关键词</b>：large-scale agile software, agile software development, software development lifecycle, lifecycle for e-commerce, time-sensitive and critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Defect Triage is a time-sensitive and critical process in a large-scale agile
software development lifecycle for e-commerce. Inefficiencies arising from
human and process dependencies in this domain have motivated research in
automated approaches using machine learning to accurately assign defects to
qualified teams. This work proposes a novel framework for automated defect
triage (DEFTri) using fine-tuned state-of-the-art pre-trained BERT on labels
fused text embeddings to improve contextual representations from
human-generated product defects. For our multi-label text classification defect
triage task, we also introduce a Walmart proprietary dataset of product defects
using weak supervision and adversarial learning, in a few-shot setting.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Making Pre-trained Language Models both Task-solvers and  Self-calibrators</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11316</p>
  <p><b>作者</b>：Yangyi Chen,  Xingyao Wang,  Heng Ji</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：Pre-trained language models, Pre-trained language, serve as backbones, real-world systems, PLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models (PLMs) serve as backbones for various real-world
systems. For high-stake applications, it's equally essential to have reasonable
confidence estimations in predictions. While the vanilla confidence scores of
PLMs can already be effectively utilized, PLMs consistently become
overconfident in their wrong predictions, which is not desirable in practice.
Previous work shows that introducing an extra calibration task can mitigate
this issue. The basic idea involves acquiring additional data to train models
in predicting the confidence of their initial predictions. However, it only
demonstrates the feasibility of this kind of method, assuming that there are
abundant extra available samples for the introduced calibration task. In this
work, we consider the practical scenario that we need to effectively utilize
training samples to make PLMs both task-solvers and self-calibrators. Three
challenges are presented, including limited training samples, data imbalance,
and distribution shifts. We first conduct pilot experiments to quantify various
decisive factors in the calibration task. Based on the empirical analysis
results, we propose a training algorithm LM-TOAST to tackle the challenges.
Experimental results show that LM-TOAST can effectively utilize the training
data to make PLMs have reasonable confidence estimations while maintaining the
original task performance. Further, we consider three downstream applications,
namely selective classification, adversarial defense, and model cascading, to
show the practical usefulness of LM-TOAST. The code will be made public at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Generating Image-Specific Text Improves Fine-grained Image  Classification</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11315</p>
  <p><b>作者</b>：Emily Mu,  Kathleen M. Lewis,  Adrian V. Dalca,  John Guttag</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：models outperform vision-only, outperform vision-only models, outperform vision-only, text descriptions, text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent vision-language models outperform vision-only models on many image
classification tasks. However, because of the absence of paired text/image
descriptions, it remains difficult to fine-tune these models for fine-grained
image classification. In this work, we propose a method, GIST, for generating
image-specific fine-grained text descriptions from image-only datasets, and
show that these text descriptions can be used to improve classification. Key
parts of our method include 1. prompting a pretrained large language model with
domain-specific prompts to generate diverse fine-grained text descriptions for
each class and 2. using a pretrained vision-language model to match each image
to label-preserving text descriptions that capture relevant visual features in
the image. We demonstrate the utility of GIST by fine-tuning vision-language
models on the image-and-generated-text pairs to learn an aligned
vision-language representation space for improved classification. We evaluate
our learned representation space in full-shot and few-shot scenarios across
four diverse fine-grained classification datasets, each from a different
domain. Our method achieves an average improvement of $4.1\%$ in accuracy over
CLIP linear probes and an average of $1.1\%$ improvement in accuracy over the
previous state-of-the-art image-text classification method on the full-shot
datasets. Our method achieves similar improvements across few-shot regimes.
Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Generator-Retriever-Generator: A Novel Approach to Open-domain Question  Answering</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11278</p>
  <p><b>作者</b>：Abdelrahman Abdallah,  Adam Jatowt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate accurate answers, tasks usually require, Open-domain question answering, question answering, generate accurate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-domain question answering (QA) tasks usually require the retrieval of
relevant information from a large corpus to generate accurate answers. We
propose a novel approach called Generator-Retriever-Generator (GRG) that
combines document retrieval techniques with a large language model (LLM), by
first prompting the model to generate contextual documents based on a given
question. In parallel, a dual-encoder network retrieves documents that are
relevant to the question from an external corpus. The generated and retrieved
documents are then passed to the second LLM, which generates the final answer.
By combining document retrieval and LLM generation, our approach addresses the
challenges of open-domain QA, such as generating informative and contextually
relevant answers. GRG outperforms the state-of-the-art generate-then-read and
retrieve-then-read pipelines (GENREAD and RFiD) improving their performance at
least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.
We provide code, datasets, and checkpoints
\footnote{\url{this https URL}}</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：A Systematic Evaluation of Federated Learning on Biomedical Natural  Language Processing</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11254</p>
  <p><b>作者</b>：Le Peng,  sicheng zhou,  jiandong chen,  Rui Zhang,  Ziyue Xu,  Ju Sun</p>
  <p><b>备注</b>：Accepted by KDD 2023 Workshop FL4Data-Mining</p>
  <p><b>关键词</b>：BERT and GPT, natural language processing, revolutionized natural language, Health Insurance Portability, GPT have revolutionized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models (LMs) like BERT and GPT have revolutionized natural language
processing (NLP). However, privacy-sensitive domains, particularly the medical
field, face challenges to train LMs due to limited data access and privacy
constraints imposed by regulations like the Health Insurance Portability and
Accountability Act (HIPPA) and the General Data Protection Regulation (GDPR).
Federated learning (FL) offers a decentralized solution that enables
collaborative learning while ensuring the preservation of data privacy. In this
study, we systematically evaluate FL in medicine across $2$ biomedical NLP
tasks using $6$ LMs encompassing $8$ corpora. Our results showed that: 1) FL
models consistently outperform LMs trained on individual client's data and
sometimes match the model trained with polled data; 2) With the fixed number of
total data, LMs trained using FL with more clients exhibit inferior
performance, but pre-trained transformer-based models exhibited greater
resilience. 3) LMs trained using FL perform nearly on par with the model
trained with pooled data when clients' data are IID distributed while
exhibiting visible gaps with non-IID data. Our code is available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Jina Embeddings: A Novel Set of High-Performance Sentence Embedding  Models</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11224</p>
  <p><b>作者</b>：Michael Günther,  Louis Milliken,  Jonathan Geuter,  Georgios Mastrapas,  Bo Wang,  Han Xiao</p>
  <p><b>备注</b>：9 pages, 2 page appendix, EMNLP 2023 Industrial Track</p>
  <p><b>关键词</b>：high-performance sentence embedding, Jina Embeddings constitutes, sentence embedding models, embedding models adept, numerical representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jina Embeddings constitutes a set of high-performance sentence embedding
models adept at translating various textual inputs into numerical
representations, thereby capturing the semantic essence of the text. While
these models are not exclusively designed for text generation, they excel in
applications such as dense retrieval and semantic textual similarity. This
paper details the development of Jina Embeddings, starting with the creation of
a high-quality pairwise and triplet dataset. It underlines the crucial role of
data cleaning in dataset preparation, gives in-depth insights into the model
training process, and concludes with a comprehensive performance evaluation
using the Massive Textual Embedding Benchmark (MTEB).</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：UMLS-KGI-BERT: Data-Centric Knowledge Integration in Transformers for  Biomedical Entity Recognition</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11170</p>
  <p><b>作者</b>：Aidan Mannion,  Thierry Chevalier,  Didier Schwab,  Lorraine Geouriot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transformer language models, recent years, applied NLP, Pre-trained transformer language, transformer language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained transformer language models (LMs) have in recent years become the
dominant paradigm in applied NLP. These models have achieved state-of-the-art
performance on tasks such as information extraction, question answering,
sentiment analysis, document classification and many others. In the biomedical
domain, significant progress has been made in adapting this paradigm to NLP
tasks that require the integration of domain-specific knowledge as well as
statistical modelling of language. In particular, research in this area has
focused on the question of how best to construct LMs that take into account not
only the patterns of token distribution in medical text, but also the wealth of
structured information contained in terminology resources such as the UMLS.
This work contributes a data-centric paradigm for enriching the language
representations of biomedical transformer-encoder LMs by extracting text
sequences from the UMLS. This allows for graph-based learning objectives to be
combined with masked-language pre-training. Preliminary results from
experiments in the extension of pre-trained LMs as well as training from
scratch show that this framework improves downstream performance on multiple
biomedical and clinical Named Entity Recognition (NER) tasks.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Topic Identification For Spontaneous Speech: Enriching Audio Features  With Embedded Linguistic Information</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11450</p>
  <p><b>作者</b>：Dejan Porjazovski,  Tamás Grósz,  Mikko Kurimo</p>
  <p><b>备注</b>：Accepted to EUSIPCO 2023</p>
  <p><b>关键词</b>：Traditional topic identification, automatic speech recognition, topic identification solutions, Traditional topic, speech recognition system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional topic identification solutions from audio rely on an automatic
speech recognition system (ASR) to produce transcripts used as input to a
text-based model. These approaches work well in high-resource scenarios, where
there are sufficient data to train both components of the pipeline. However, in
low-resource situations, the ASR system, even if available, produces
low-quality transcripts, leading to a bad text-based classifier. Moreover,
spontaneous speech containing hesitations can further degrade the performance
of the ASR model. In this paper, we investigate alternatives to the standard
text-only solutions by comparing audio-only and hybrid techniques of jointly
utilising text and audio features. The models evaluated on spontaneous Finnish
speech demonstrate that purely audio-based solutions are a viable option when
ASR components are not available, while the hybrid multi-modal solutions
achieve the best results.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Differentially Private Heavy Hitter Detection using Federated Analytics</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11749</p>
  <p><b>作者</b>：Karan Chadha,  Junye Chen,  John Duchi,  Vitaly Feldman,  Hanieh Hashemi,  Omid Javidbakht,  Audra McMillan,  Kunal Talwar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：heavy hitter detection, study practical heuristics, differentially private heavy, private heavy hitter, prefix-tree based algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we study practical heuristics to improve the performance of
prefix-tree based algorithms for differentially private heavy hitter detection.
Our model assumes each user has multiple data points and the goal is to learn
as many of the most frequent data points as possible across all users' data
with aggregate and local differential privacy. We propose an adaptive
hyperparameter tuning algorithm that improves the performance of the algorithm
while satisfying computational, communication and privacy constraints. We
explore the impact of different data-selection schemes as well as the impact of
introducing deny lists during multiple runs of the algorithm. We test these
improvements using extensive experimentation on the Reddit
dataset~\cite{caldas2018leaf} on the task of learning the most frequent words.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Advancing Ad Auction Realism: Practical Insights & Modeling Implications</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11732</p>
  <p><b>作者</b>：Ming Chen,  Sareh Nabi,  Marciano Siniscalchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：users' search queries, click-through rates depending, contemporary online auctions, aggregated feedback, search queries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a learning model of online ad auctions that allows for
the following four key realistic characteristics of contemporary online
auctions: (1) ad slots can have different values and click-through rates
depending on users' search queries, (2) the number and identity of competing
advertisers are unobserved and change with each auction, (3) advertisers only
receive partial, aggregated feedback, and (4) payment rules are only partially
specified. We model advertisers as agents governed by an adversarial bandit
algorithm, independent of auction mechanism intricacies. Our objective is to
simulate the behavior of advertisers for counterfactual analysis, prediction,
and inference purposes. Our findings reveal that, in such richer environments,
"soft floors" can enhance key performance metrics even when bidders are drawn
from the same population. We further demonstrate how to infer advertiser value
distributions from observed bids, thereby affirming the practical efficacy of
our approach even in a more realistic auction setting.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Mitigating Communications Threats in Decentralized Federated Learning  through Moving Target Defense</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11730</p>
  <p><b>作者</b>：Enrique Tomás Martínez Beltrán,  Pedro Miguel Sánchez Sánchez,  Sergio López Bernal,  Gérôme Bovet,  Manuel Gil Pérez,  Gregorio Martínez Pérez,  Alberto Huertas Celdrán</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Decentralized Federated Learning, machine learning models, Federated Learning, fostering decentralized model, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of Decentralized Federated Learning (DFL) has enabled the training
of machine learning models across federated participants, fostering
decentralized model aggregation and reducing dependence on a server. However,
this approach introduces unique communication security challenges that have yet
to be thoroughly addressed in the literature. These challenges primarily
originate from the decentralized nature of the aggregation process, the varied
roles and responsibilities of the participants, and the absence of a central
authority to oversee and mitigate threats. Addressing these challenges, this
paper first delineates a comprehensive threat model, highlighting the potential
risks of DFL communications. In response to these identified risks, this work
introduces a security module designed for DFL platforms to counter
communication-based attacks. The module combines security techniques such as
symmetric and asymmetric encryption with Moving Target Defense (MTD)
techniques, including random neighbor selection and IP/port switching. The
security module is implemented in a DFL platform called Fedstellar, allowing
the deployment and monitoring of the federation. A DFL scenario has been
deployed, involving eight physical devices implementing three security
configurations: (i) a baseline with no security, (ii) an encrypted
configuration, and (iii) a configuration integrating both encryption and MTD
techniques. The effectiveness of the security module is validated through
experiments with the MNIST dataset and eclipse attacks. The results indicated
an average F1 score of 95%, with moderate increases in CPU usage (up to 63.2%
+-3.5%) and network traffic (230 MB +-15 MB) under the most secure
configuration, mitigating the risks posed by eavesdropping or eclipse attacks.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Convergence of SGD for Training Neural Networks with Sliced Wasserstein  Losses</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11714</p>
  <p><b>作者</b>：Eloi Tanguy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：comparing probability measures, sparked vivid interest, Optimal Transport, Transport has sparked, probability measures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimal Transport has sparked vivid interest in recent years, in particular
thanks to the Wasserstein distance, which provides a geometrically sensible and
intuitive way of comparing probability measures. For computational reasons, the
Sliced Wasserstein (SW) distance was introduced as an alternative to the
Wasserstein distance, and has seen uses for training generative Neural Networks
(NNs). While convergence of Stochastic Gradient Descent (SGD) has been observed
practically in such a setting, there is to our knowledge no theoretical
guarantee for this observation. Leveraging recent works on convergence of SGD
on non-smooth and non-convex functions by Bianchi et al. (2022), we aim to
bridge that knowledge gap, and provide a realistic context under which
fixed-step SGD trajectories for the SW loss on NN parameters converge. More
precisely, we show that the trajectories approach the set of (sub)-gradient
flow equations as the step decreases. Under stricter assumptions, we show a
much stronger convergence result for noised and projected SGD schemes, namely
that the long-run limits of the trajectories approach a set of generalised
critical points of the loss function.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：JoinGym: An Efficient Query Optimization Environment for Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11704</p>
  <p><b>作者</b>：Kaiwen Wang,  Junxiong Wang,  Yueying Li,  Nathan Kallus,  Immanuel Trummer,  Wen Sun</p>
  <p><b>备注</b>：We will make all the queries available soon</p>
  <p><b>关键词</b>：query optimization environment, lightweight query optimization, reinforcement learning, efficient and lightweight, environment for reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present \textsc{JoinGym}, an efficient and lightweight
query optimization environment for reinforcement learning (RL). Join order
selection (JOS) is a classic NP-hard combinatorial optimization problem from
database query optimization and can serve as a practical testbed for the
generalization capabilities of RL algorithms. We describe how to formulate each
of the left-deep and bushy variants of the JOS problem as a Markov Decision
Process (MDP), and we provide an implementation adhering to the standard
Gymnasium API. We highlight that our implementation \textsc{JoinGym} is
completely based on offline traces of all possible joins, which enables RL
practitioners to easily and quickly test their methods on a realistic data
management problem without needing to setup any systems. Moreover, we also
provide all possible join traces on $3300$ novel SQL queries generated from the
IMDB dataset. Upon benchmarking popular RL algorithms, we find that at least
one method can obtain near-optimal performance on train-set queries but their
performance degrades by several orders of magnitude on test-set queries. This
gap motivates further research for RL algorithms that generalize well in
multi-task combinatorial optimization problems.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Using simulation to calibrate real data acquisition in veterinary  medicine</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11695</p>
  <p><b>作者</b>：Krystian Strzałka,  Szymon Mazurek,  Maciej Wielgosz,  Paweł Russek,  Jakub Caputa,  Daria Łukasik,  Jan Krupiński,  Jakub Grzeszczyk,  Michał Karwatowski,  Rafał Frączek,  Ernest Jamro,  Marcin Pietroń,  Sebastian Koryciak,  Agnieszka Dąbrowska-Boruch,  Kazimierz Wiatr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：focusing specifically, paper explores, explores the innovative, simulation environments, environments to enhance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the innovative use of simulation environments to enhance
data acquisition and diagnostics in veterinary medicine, focusing specifically
on gait analysis in dogs. The study harnesses the power of Blender and the
Blenderproc library to generate synthetic datasets that reflect diverse
anatomical, environmental, and behavioral conditions. The generated data,
represented in graph form and standardized for optimal analysis, is utilized to
train machine learning algorithms for identifying normal and abnormal gaits.
Two distinct datasets with varying degrees of camera angle granularity are
created to further investigate the influence of camera perspective on model
accuracy. Preliminary results suggest that this simulation-based approach holds
promise for advancing veterinary diagnostics by enabling more precise data
acquisition and more effective machine learning models. By integrating
synthetic and real-world patient data, the study lays a robust foundation for
improving overall effectiveness and efficiency in veterinary medicine.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction  and Drug Design</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11694</p>
  <p><b>作者</b>：Carl Edwards,  Aakanksha Naik,  Tushar Khot,  Martin Burke,  Heng Ji,  Tom Hope</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Predicting synergistic drug, synergistic drug combinations, Predicting synergistic, accelerate discovery, tumor via biopsied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting synergistic drug combinations can help accelerate discovery of
cancer treatments, particularly therapies personalized to a patient's specific
tumor via biopsied cells. In this paper, we propose a novel setting and models
for in-context drug synergy learning. We are given a small "personalized
dataset" of 10-20 drug synergy relationships in the context of specific cancer
cell targets. Our goal is to predict additional drug synergy relationships in
that context. Inspired by recent work that pre-trains a GPT language model (LM)
to "in-context learn" common function classes, we devise novel pre-training
schemes that enable a GPT model to in-context learn "drug synergy functions".
Our model -- which does not use any textual corpora, molecular fingerprints,
protein interaction or any other domain-specific knowledge -- is able to
achieve competitive results. We further integrate our in-context approach with
a genetic algorithm to optimize model prompts and select synergy candidates to
test after conducting a patient biopsy. Finally, we explore a novel task of
inverse drug design which can potentially enable the design of drugs that
synergize specifically to target a given patient's "personalized dataset". Our
findings can potentially have an important impact on precision cancer medicine,
and also raise intriguing questions on non-textual pre-training for LMs.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Interpretable Graph Networks Formulate Universal Algebra Conjectures</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11688</p>
  <p><b>作者</b>：Francesco Giannini,  Stefano Fioravanti,  Oguzhan Keskin,  Alisia Maria Lupidi,  Lucie Charlotte Magister,  Pietro Lio,  Pietro Barbiero</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, recently empowered researchers, hard mathematical problems, eluded traditional approaches, investigate hard mathematical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of Artificial Intelligence (AI) recently empowered researchers to
investigate hard mathematical problems which eluded traditional approaches for
decades. Yet, the use of AI in Universal Algebra (UA) -- one of the fields
laying the foundations of modern mathematics -- is still completely unexplored.
This work proposes the first use of AI to investigate UA's conjectures with an
equivalent equational and topological characterization. While topological
representations would enable the analysis of such properties using graph neural
networks, the limited transparency and brittle explainability of these models
hinder their straightforward use to empirically validate existing conjectures
or to formulate new ones. To bridge these gaps, we propose a general algorithm
generating AI-ready datasets based on UA's conjectures, and introduce a novel
neural layer to build fully interpretable graph networks. The results of our
experiments demonstrate that interpretable graph networks: (i) enhance
interpretability without sacrificing task accuracy, (ii) strongly generalize
when predicting universal algebra's properties, (iii) generate simple
explanations that empirically validate existing conjectures, and (iv) identify
subgraphs suggesting the formulation of novel conjectures.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Minibatching Offers Improved Generalization Performance for Second Order  Optimizers</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11684</p>
  <p><b>作者</b>：Eric Silk,  Swarnita Chakraborty,  Nairanjana Dasgupta,  Anand D. Sarwate,  Andrew Lumsdaine,  Tony Chiang</p>
  <p><b>备注</b>：14 pages, 6 figures, 5 tables</p>
  <p><b>关键词</b>：deep neural networks, modern machine learning, Training deep neural, neural networks, computationally expensive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training deep neural networks (DNNs) used in modern machine learning is
computationally expensive. Machine learning scientists, therefore, rely on
stochastic first-order methods for training, coupled with significant
hand-tuning, to obtain good performance. To better understand performance
variability of different stochastic algorithms, including second-order methods,
we conduct an empirical study that treats performance as a response variable
across multiple training sessions of the same model. Using 2-factor Analysis of
Variance (ANOVA) with interactions, we show that batch size used during
training has a statistically significant effect on the peak accuracy of the
methods, and that full batch largely performed the worst. In addition, we found
that second-order optimizers (SOOs) generally exhibited significantly lower
variance at specific batch sizes, suggesting they may require less
hyperparameter tuning, leading to a reduced overall time to solution for model
training.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Fast Adaptive Test-Time Defense with Robust Features</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11672</p>
  <p><b>作者</b>：Anurag Singh,  Mahalakshmi Sabanayagam,  Krikamol Muandet,  Debarghya Ghoshdastidar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Adaptive test-time defenses, deep neural networks, Adaptive test-time, existing adaptive test-time, Neural Tangent Kernel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive test-time defenses are used to improve the robustness of deep neural
networks to adversarial examples. However, existing methods significantly
increase the inference time due to additional optimization on the model
parameters or the input at test time. In this work, we propose a novel adaptive
test-time defense strategy that is easy to integrate with any existing (robust)
training procedure without additional test-time computation. Based on the
notion of robustness of features that we present, the key idea is to project
the trained models to the most robust feature space, thereby reducing the
vulnerability to adversarial attacks in non-robust directions. We theoretically
show that the top eigenspace of the feature matrix are more robust for a
generalized additive model and support our argument for a large width neural
network with the Neural Tangent Kernel (NTK) equivalence. We conduct extensive
experiments on CIFAR-10 and CIFAR-100 datasets for several robustness
benchmarks, including the state-of-the-art methods in RobustBench, and observe
that the proposed method outperforms existing adaptive test-time defenses at
much lower computation costs.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：An Efficient Interior-Point Method for Online Convex Optimization</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11668</p>
  <p><b>作者</b>：Elad Hazan,  Nimrod Megiddo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：online convex optimization, regret minimization, algorithm, online convex, regret</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A new algorithm for regret minimization in online convex optimization is
described. The regret of the algorithm after $T$ time periods is $O(\sqrt{T
\log T})$ - which is the minimum possible up to a logarithmic term. In
addition, the new algorithm is adaptive, in the sense that the regret bounds
hold not only for the time periods $1,\ldots,T$ but also for every sub-interval
$s,s+1,\ldots,t$. The running time of the algorithm matches that of newly
introduced interior point algorithms for regret minimization: in
$n$-dimensional space, during each iteration the new algorithm essentially
solves a system of linear equations of order $n$, rather than solving some
constrained convex optimization problem in $n$ dimensions and possibly many
constraints.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11661</p>
  <p><b>作者</b>：Mayug Maniparambil,  Chris Vorster,  Derek Molloy,  Noel Murphy,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：10 pages, Pre-print</p>
  <p><b>关键词</b>：providing good performance, large Vision-Language Models, Contrastive pretrained large, pretrained large Vision-Language, revolutionized visual representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have
revolutionized visual representation learning by providing good performance on
downstream datasets. VLMs are 0-shot adapted to a downstream dataset by
designing prompts that are relevant to the dataset. Such prompt engineering
makes use of domain expertise and a validation dataset. Meanwhile, recent
developments in generative pretrained models like GPT-4 mean they can be used
as advanced internet search tools. They can also be manipulated to provide
visual information in any structure. In this work, we show that GPT-4 can be
used to generate text that is visually descriptive and how this can be used to
adapt CLIP to downstream tasks. We show considerable improvements in 0-shot
transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD
(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.
We also design a simple few-shot adapter that learns to choose the best
possible sentences to construct generalizable classifiers that outperform the
recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized
fine-grained datasets. We will release the code, prompts, and auxiliary text
dataset upon acceptance.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Bandits with Deterministically Evolving States</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11655</p>
  <p><b>作者</b>：Khashayar Khosravi,  Renato Paes Leme,  Chara Podimata,  Apostolis Tsorvantzis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deterministically Evolving States, deterministically evolving, feedback while accounting, lambda, Evolving States</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a model for learning with bandit feedback while accounting for
deterministically evolving and unobservable states that we call Bandits with
Deterministically Evolving States. The workhorse applications of our model are
learning for recommendation systems and learning for online ads. In both cases,
the reward that the algorithm obtains at each round is a function of the
short-term reward of the action chosen and how ``healthy'' the system is (i.e.,
as measured by its state). For example, in recommendation systems, the reward
that the platform obtains from a user's engagement with a particular type of
content depends not only on the inherent features of the specific content, but
also on how the user's preferences have evolved as a result of interacting with
other types of content on the platform. Our general model accounts for the
different rate $\lambda \in [0,1]$ at which the state evolves (e.g., how fast a
user's preferences shift as a result of previous content consumption) and
encompasses standard multi-armed bandits as a special case. The goal of the
algorithm is to minimize a notion of regret against the best-fixed sequence of
arms pulled. We analyze online learning algorithms for any possible
parametrization of the evolution rate $\lambda$. Specifically, the regret rates
obtained are: for $\lambda \in [0, 1/T^2]$: $\widetilde O(\sqrt{KT})$; for
$\lambda = T^{-a/b}$ with $b < a < 2b$: $\widetilde O (T^{b/a})$; for $\lambda
\in (1/T, 1 - 1/\sqrt{T}): \widetilde O (K^{1/3}T^{2/3})$; and for $\lambda \in
[1 - 1/\sqrt{T}, 1]: \widetilde O (K\sqrt{T})$.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Scalable Multi-agent Skill Discovery based on Kronecker Graphs</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11629</p>
  <p><b>作者</b>：Jiayu Chen,  Jingdi Chen,  Tian Lan,  Vaneet Aggarwal</p>
  <p><b>备注</b>：Accepted to NeurIPS 2022. arXiv admin note: substantial text overlap with arXiv:2201.08227</p>
  <p><b>关键词</b>：sparse reward signals, joint state space, embedding space provided, Covering skill, state space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Covering skill (a.k.a., option) discovery has been developed to improve the
exploration of RL in single-agent scenarios with sparse reward signals, through
connecting the most distant states in the embedding space provided by the
Fiedler vector of the state transition graph. Given that joint state space
grows exponentially with the number of agents in multi-agent systems, existing
researches still relying on single-agent option discovery either become
prohibitive or fail to directly discover joint options that improve the
connectivity of the joint state space. In this paper, we show how to directly
compute multi-agent options with collaborative exploratory behaviors while
still enjoying the ease of decomposition. Our key idea is to approximate the
joint state space as a Kronecker graph, based on which we can directly estimate
its Fiedler vector using the Laplacian spectrum of individual agents'
transition graphs. Further, considering that directly computing the Laplacian
spectrum is intractable for tasks with infinite-scale state spaces, we further
propose a deep learning extension of our method by estimating eigenfunctions
through NN-based representation learning techniques. The evaluation on
multi-agent tasks built with simulators like Mujoco, shows that the proposed
algorithm can successfully identify multi-agent options, and significantly
outperforms the state-of-the-art. Codes are available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local  Value Regularization</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11620</p>
  <p><b>作者</b>：Xiangsen Wang,  Haoran Xu,  Yinan Zheng,  Xianyuan Zhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：received considerable attention, recent years due, environmental interactions, received considerable, considerable attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline reinforcement learning (RL) has received considerable attention in
recent years due to its attractive capability of learning policies from offline
datasets without environmental interactions. Despite some success in the
single-agent setting, offline multi-agent RL (MARL) remains to be a challenge.
The large joint state-action space and the coupled multi-agent behaviors pose
extra complexities for offline policy optimization. Most existing offline MARL
studies simply apply offline data-related regularizations on individual agents,
without fully considering the multi-agent system at the global level. In this
work, we present OMIGA, a new offline m ulti-agent RL algorithm with implicit
global-to-local v alue regularization. OMIGA provides a principled framework to
convert global-level value regularization into equivalent implicit local value
regularizations and simultaneously enables in-sample learning, thus elegantly
bridging multi-agent value decomposition and policy learning with offline
regularizations. Based on comprehensive experiments on the offline multi-agent
MuJoCo and StarCraft II micro-management tasks, we show that OMIGA achieves
superior performance over the state-of-the-art offline MARL methods in almost
all tasks.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Robust Fully-Asynchronous Methods for Distributed Training over General  Architecture</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11617</p>
  <p><b>作者</b>：Zehan Zhu,  Ye Tian,  Yan Huang,  Jinming Xu,  Shibo He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning problems, distributed machine learning, existence of latency, Robust Fully-Asynchronous Stochastic, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perfect synchronization in distributed machine learning problems is
inefficient and even impossible due to the existence of latency, package losses
and stragglers. We propose a Robust Fully-Asynchronous Stochastic Gradient
Tracking method (R-FAST), where each device performs local computation and
communication at its own pace without any form of synchronization. Different
from existing asynchronous distributed algorithms, R-FAST can eliminate the
impact of data heterogeneity across devices and allow for packet losses by
employing a robust gradient tracking strategy that relies on properly designed
auxiliary variables for tracking and buffering the overall gradient vector.
More importantly, the proposed method utilizes two spanning-tree graphs for
communication so long as both share at least one common root, enabling flexible
designs in communication architectures. We show that R-FAST converges in
expectation to a neighborhood of the optimum with a geometric rate for smooth
and strongly convex objectives; and to a stationary point with a sublinear rate
for general non-convex settings. Extensive experiments demonstrate that R-FAST
runs 1.5-2 times faster than synchronous benchmark algorithms, such as
Ring-AllReduce and D-PSGD, while still achieving comparable accuracy, and
outperforms existing asynchronous SOTA algorithms, such as AD-PSGD and OSGP,
especially in the presence of stragglers.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Finding Optimal Diverse Feature Sets with Alternative Feature Selection</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11607</p>
  <p><b>作者</b>：Jakob Bach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurate prediction models, highly accurate prediction, obtaining small, alternative feature, Feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature selection is popular for obtaining small, interpretable, yet highly
accurate prediction models. Conventional feature-selection methods typically
yield one feature set only, which might not suffice in some scenarios. For
example, users might be interested in finding alternative feature sets with
similar prediction quality, offering different explanations of the data. In
this article, we introduce alternative feature selection and formalize it as an
optimization problem. In particular, we define alternatives via constraints and
enable users to control the number and dissimilarity of alternatives. Next, we
analyze the complexity of this optimization problem and show NP-hardness.
Further, we discuss how to integrate conventional feature-selection methods as
objectives. Finally, we evaluate alternative feature selection with 30
classification datasets. We observe that alternative feature sets may indeed
have high prediction quality, and we analyze several factors influencing this
outcome.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Transferability of Convolutional Neural Networks in Stationary Learning  Tasks</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11588</p>
  <p><b>作者</b>：Damian Owerko,  Charilaos I. Kanatsoulis,  Jennifer Bondarchuk,  Donald J. Bucci Jr,  Alejandro Ribeiro</p>
  <p><b>备注</b>：14 pages, 7 figures, for associated code see this https URL</p>
  <p><b>关键词</b>：deep learning techniques, big data acquisition, Recent advances, learning techniques, advances in hardware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in hardware and big data acquisition have accelerated the
development of deep learning techniques. For an extended period of time,
increasing the model complexity has led to performance improvements for various
tasks. However, this trend is becoming unsustainable and there is a need for
alternative, computationally lighter methods. In this paper, we introduce a
novel framework for efficient training of convolutional neural networks (CNNs)
for large-scale spatial problems. To accomplish this we investigate the
properties of CNNs for tasks where the underlying signals are stationary. We
show that a CNN trained on small windows of such signals achieves a nearly
performance on much larger windows without retraining. This claim is supported
by our theoretical analysis, which provides a bound on the performance
degradation. Additionally, we conduct thorough experimental analysis on two
tasks: multi-target tracking and mobile infrastructure on demand. Our results
show that the CNN is able to tackle problems with many hundreds of agents after
being trained with fewer than ten. Thus, CNN architectures provide solutions to
these problems at previously computationally intractable scales.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：A Change of Heart: Improving Speech Emotion Recognition through  Speech-to-Text Modality Conversion</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11584</p>
  <p><b>作者</b>：Zeinab Sadat Taghavi,  Ali Satvaty,  Hossein Sameti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Speech Emotion Recognition, Emotion Recognition, emotion recognition performance, enhancing emotion recognition, MELD dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) is a challenging task. In this paper, we
introduce a modality conversion concept aimed at enhancing emotion recognition
performance on the MELD dataset. We assess our approach through two
experiments: first, a method named Modality-Conversion that employs automatic
speech recognition (ASR) systems, followed by a text classifier; second, we
assume perfect ASR output and investigate the impact of modality conversion on
SER, this method is called Modality-Conversion++. Our findings indicate that
the first method yields substantial results, while the second method
outperforms state-of-the-art (SOTA) speech-based approaches in terms of SER
weighted-F1 (WF1) score on the MELD dataset. This research highlights the
potential of modality conversion for tasks that can be conducted in alternative
modalities.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep  Neural Networks</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11565</p>
  <p><b>作者</b>：Dong Huang,  Qingwen Bu,  Yahao Qing,  Yichao Fu,  Heming Cui</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：Deep neural networks, backdoor feature maps, FMT, feature maps, backdoor feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have been widely used in many critical applications,
such as autonomous vehicles and medical diagnosis. However, their security is
threatened by backdoor attack, which is achieved by adding artificial patterns
to specific training data. Existing defense strategies primarily focus on using
reverse engineering to reproduce the backdoor trigger generated by attackers
and subsequently repair the DNN model by adding the trigger into inputs and
fine-tuning the model with ground-truth labels. However, once the trigger
generated by the attackers is complex and invisible, the defender can not
successfully reproduce the trigger. Consequently, the DNN model will not be
repaired since the trigger is not effectively removed.
In this work, we propose Feature Map Testing~(FMT). Different from existing
defense strategies, which focus on reproducing backdoor triggers, FMT tries to
detect the backdoor feature maps, which are trained to extract backdoor
information from the inputs. After detecting these backdoor feature maps, FMT
will erase them and then fine-tune the model with a secure subset of training
data. Our experiments demonstrate that, compared to existing defense
strategies, FMT can effectively reduce the Attack Success Rate (ASR) even
against the most complex and invisible attack triggers. Second, unlike
conventional defense methods that tend to exhibit low Robust Accuracy (i.e.,
the model's accuracy on the poisoned data), FMT achieves higher RA, indicating
its superiority in maintaining model performance while mitigating the effects
of backdoor attacks~(e.g., FMT obtains 87.40\% RA in CIFAR10). Third, compared
to existing feature map pruning techniques, FMT can cover more backdoor feature
maps~(e.g., FMT removes 83.33\% of backdoor feature maps from the model in the
CIFAR10 \& BadNet scenario).</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Training Latency Minimization for Model-Splitting Allowed Federated Edge  Learning</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11532</p>
  <p><b>作者</b>：Yao Wen,  Guopeng Zhang,  Kezhi Wang,  Kun Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, training deep neural, computing power faced, federated learning, split learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To alleviate the shortage of computing power faced by clients in training
deep neural networks (DNNs) using federated learning (FL), we leverage the edge
computing and split learning to propose a model-splitting allowed FL (SFL)
framework, with the aim to minimize the training latency without loss of test
accuracy. Under the synchronized global update setting, the latency to complete
a round of global training is determined by the maximum latency for the clients
to complete a local training session. Therefore, the training latency
minimization problem (TLMP) is modelled as a minimizing-maximum problem. To
solve this mixed integer nonlinear programming problem, we first propose a
regression method to fit the quantitative-relationship between the cut-layer
and other parameters of an AI-model, and thus, transform the TLMP into a
continuous problem. Considering that the two subproblems involved in the TLMP,
namely, the cut-layer selection problem for the clients and the computing
resource allocation problem for the parameter-server are relative independence,
an alternate-optimization-based algorithm with polynomial time complexity is
developed to obtain a high-quality solution to the TLMP. Extensive experiments
are performed on a popular DNN-model EfficientNetV2 using dataset MNIST, and
the results verify the validity and improved performance of the proposed SFL
framework.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Multi-modal Hate Speech Detection using Machine Learning</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11519</p>
  <p><b>作者</b>：Fariha Tahosin Boishakhi,  Ponkoj Chandra Shill,  Md. Golam Rabiul Alam</p>
  <p><b>备注</b>：5 pages, 2 figures, conference</p>
  <p><b>关键词</b>：continuous growth, growth of internet, internet users, users and media, hard to track</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous growth of internet users and media content, it is very
hard to track down hateful speech in audio and video. Converting video or audio
into text does not detect hate speech accurately as human sometimes uses
hateful words as humorous or pleasant in sense and also uses different voice
tones or show different action in the video. The state-ofthe-art hate speech
detection models were mostly developed on a single modality. In this research,
a combined approach of multimodal system has been proposed to detect hate
speech from video contents by extracting feature images, feature values
extracted from the audio, text and used machine learning and Natural language
processing.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：General regularization in covariate shift adaptation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11503</p>
  <p><b>作者</b>：Duc Hoan Nguyen,  Sergei V. Pereverzyev,  Werner Zellinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：kernel Hilbert spaces, reproducing kernel Hilbert, training data distribution, future data distributions, Hilbert spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sample reweighting is one of the most widely used methods for correcting the
error of least squares learning algorithms in reproducing kernel Hilbert spaces
(RKHS), that is caused by future data distributions that are different from the
training data distribution. In practical situations, the sample weights are
determined by values of the estimated Radon-Nikodým derivative, of the future
data distribution w.r.t.~the training data distribution. In this work, we
review known error bounds for reweighted kernel regression in RKHS and obtain,
by combination, novel results. We show under weak smoothness conditions, that
the amount of samples, needed to achieve the same order of accuracy as in the
standard supervised learning without differences in data distributions, is
smaller than proven by state-of-the-art analyses.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Predict, Refine, Synthesize: Self-Guiding Diffusion Models for  Probabilistic Time Series Forecasting</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11494</p>
  <p><b>作者</b>：Marcel Kollovieh,  Abdul Fatir Ansari,  Michael Bohlke-Schneider,  Jasper Zschiegner,  Hao Wang,  Yuyang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, Diffusion models, models, Diffusion, time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have achieved state-of-the-art performance in generative
modeling tasks across various domains. Prior works on time series diffusion
models have primarily focused on developing conditional models tailored to
specific forecasting or imputation tasks. In this work, we explore the
potential of task-agnostic, unconditional diffusion models for several time
series applications. We propose TSDiff, an unconditionally trained diffusion
model for time series. Our proposed self-guidance mechanism enables
conditioning TSDiff for downstream tasks during inference, without requiring
auxiliary networks or altering the training procedure. We demonstrate the
effectiveness of our method on three different time series tasks: forecasting,
refinement, and synthetic data generation. First, we show that TSDiff is
competitive with several task-specific conditional forecasting methods
(predict). Second, we leverage the learned implicit probability density of
TSDiff to iteratively refine the predictions of base forecasters with reduced
computational overhead over reverse diffusion (refine). Notably, the generative
performance of the model remains intact -- downstream forecasters trained on
synthetic samples from TSDiff outperform forecasters that are trained on
samples from other state-of-the-art generative time series models, occasionally
even outperforming models trained on real data (synthesize).</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：A New Deep State-Space Analysis Framework for Patient Latent State  Estimation and Classification from EHR Time Series Data</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11487</p>
  <p><b>作者</b>：Aya Nakamura,  Ryosuke Kojima,  Yuji Okamoto,  Eiichiro Uchino,  Yohei Mineharu,  Yohei Harada,  Mayumi Kamada,  Manabu Muto,  Motoko Yanagita,  Yasushi Okuno</p>
  <p><b>备注</b>：21 pages, 6 figures</p>
  <p><b>关键词</b>：extended treatment periods, chronic conditions, periods and long-term, require extended treatment, long-term strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many diseases, including cancer and chronic conditions, require extended
treatment periods and long-term strategies. Machine learning and AI research
focusing on electronic health records (EHRs) have emerged to address this need.
Effective treatment strategies involve more than capturing sequential changes
in patient test values. It requires an explainable and clinically interpretable
model by capturing the patient's internal state over time.
In this study, we propose the "deep state-space analysis framework," using
time-series unsupervised learning of EHRs with a deep state-space model. This
framework enables learning, visualizing, and clustering of temporal changes in
patient latent states related to disease progression.
We evaluated our framework using time-series laboratory data from 12,695
cancer patients. By estimating latent states, we successfully discover latent
states related to prognosis. By visualization and cluster analysis, the
temporal transition of patient status and test items during state transitions
characteristic of each anticancer drug were identified. Our framework surpasses
existing methods in capturing interpretable latent space. It can be expected to
enhance our comprehension of disease progression from EHRs, aiding treatment
adjustments and prognostic determinations.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：A Deep Learning Approach for Overall Survival Analysis with Missing  Values</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11465</p>
  <p><b>作者</b>：Camillo Maria Caruso,  Valerio Guarrasi,  Sara Ramella,  Paolo Soda</p>
  <p><b>备注</b>：19 pages, 2 figures</p>
  <p><b>关键词</b>：lung cancer research, cell lung cancer, Artificial Intelligence, non-small cell lung, specifically non-small cell</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most challenging fields where Artificial Intelligence (AI) can be
applied is lung cancer research, specifically non-small cell lung cancer
(NSCLC). In particular, overall survival (OS) is a vital indicator of patient
status, helping to identify subgroups with diverse survival probabilities,
enabling tailored treatment and improved OS rates. In this analysis, there are
two challenges to take into account. First, few studies effectively exploit the
information available from each patient, leveraging both uncensored (i.e.,
dead) and censored (i.e., survivors) patients, considering also the death
times. Second, the handling of incomplete data is a common issue in the medical
field. This problem is typically tackled through the use of imputation methods.
Our objective is to present an AI model able to overcome these limits,
effectively learning from both censored and uncensored patients and their
available features, for the prediction of OS for NSCLC patients. We present a
novel approach to survival analysis in the context of NSCLC, which exploits the
strengths of the transformer architecture accounting for only available
features without requiring any imputation strategy. By making use of ad-hoc
losses for OS, it accounts for both censored and uncensored patients,
considering risks over time. We evaluated the results over a period of 6 years
using different time granularities obtaining a Ct-index, a time-dependent
variant of the C-index, of 71.97, 77.58 and 80.72 for time units of 1 month, 1
year and 2 years, respectively, outperforming all state-of-the-art methods
regardless of the imputation method used.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Improve Long-term Memory Learning Through Rescaling the Error Temporally</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11462</p>
  <p><b>作者</b>：Shida Wang,  Zhanglu Yan</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：short-term memory, error metric selection, memory, long-term memory learning, paper studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the error metric selection for long-term memory learning
in sequence modelling. We examine the bias towards short-term memory in
commonly used errors, including mean absolute/squared error. Our findings show
that all temporally positive-weighted errors are biased towards short-term
memory in learning linear functionals. To reduce this bias and improve
long-term memory learning, we propose the use of a temporally rescaled error.
In addition to reducing the bias towards short-term memory, this approach can
also alleviate the vanishing gradient issue. We conduct numerical experiments
on different long-memory tasks and sequence models to validate our claims.
Numerical results confirm the importance of appropriate temporally rescaled
error for effective long-term memory learning. To the best of our knowledge,
this is the first work that quantitatively analyzes different errors' memory
bias towards short-term memory in sequence modelling.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Batching for Green AI -- An Exploratory Study on Inference</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11434</p>
  <p><b>作者</b>：Tim Yarally,  Luís Cruz,  Daniel Feitosa,  June Sallou,  Arie van Deursen</p>
  <p><b>备注</b>：8 pages, 4 figures, 1 table. Accepted at Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2023</p>
  <p><b>关键词</b>：essential parameter, parameter to tune, neural networks, batch size, energy consumption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The batch size is an essential parameter to tune during the development of
new neural networks. Amongst other quality indicators, it has a large degree of
influence on the model's accuracy, generalisability, training times and
parallelisability. This fact is generally known and commonly studied. However,
during the application phase of a deep learning model, when the model is
utilised by an end-user for inference, we find that there is a disregard for
the potential benefits of introducing a batch size. In this study, we examine
the effect of input batching on the energy consumption and response times of
five fully-trained neural networks for computer vision that were considered
state-of-the-art at the time of their publication. The results suggest that
batching has a significant effect on both of these metrics. Furthermore, we
present a timeline of the energy efficiency and accuracy of neural networks
over the past decade. We find that in general, energy consumption rises at a
much steeper pace than accuracy and question the necessity of this evolution.
Additionally, we highlight one particular network, ShuffleNetV2(2018), that
achieved a competitive performance for its time while maintaining a much lower
energy consumption. Nevertheless, we highlight that the results are model
dependent.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：An Analysis of Multi-Agent Reinforcement Learning for Decentralized  Inventory Control Systems</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11432</p>
  <p><b>作者</b>：Marwan Mousa,  Damien van de Berg,  Niki Kotecha,  Ehecatl Antonio del Rio-Chanona,  Max Mowbray</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inventory management problem, management problem assume, inventory management, supply chain networks, supply chain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most solutions to the inventory management problem assume a centralization of
information that is incompatible with organisational constraints in real supply
chain networks. The inventory management problem is a well-known planning
problem in operations research, concerned with finding the optimal re-order
policy for nodes in a supply chain. While many centralized solutions to the
problem exist, they are not applicable to real-world supply chains made up of
independent entities. The problem can however be naturally decomposed into
sub-problems, each associated with an independent entity, turning it into a
multi-agent system. Therefore, a decentralized data-driven solution to
inventory management problems using multi-agent reinforcement learning is
proposed where each entity is controlled by an agent. Three multi-agent
variations of the proximal policy optimization algorithm are investigated
through simulations of different supply chain networks and levels of
uncertainty. The centralized training decentralized execution framework is
deployed, which relies on offline centralization during simulation-based policy
identification, but enables decentralization when the policies are deployed
online to the real system. Results show that using multi-agent proximal policy
optimization with a centralized critic leads to performance very close to that
of a centralized data-driven solution and outperforms a distributed model-based
solution in most cases while respecting the information constraints of the
system.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Attention to Entropic Communication</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11423</p>
  <p><b>作者</b>：Torsten Enßlin,  Carolin Weidinger,  Philipp Frank</p>
  <p><b>备注</b>：23 pages, 4 figures, submitted</p>
  <p><b>关键词</b>：numerical weights, artificial intelligence, weights that emphasize, emphasize the importance, relevant in artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The concept of attention, numerical weights that emphasize the importance of
particular data, has proven to be very relevant in artificial intelligence.
Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in
communication theory. Here we combine these concepts, attention and RE. RE
guides optimal encoding of messages in bandwidth-limited communication as well
as optimal message decoding via the maximum entropy principle (MEP). In the
coding scenario, RE can be derived from four requirements, namely being
analytical, local, proper, and calibrated. Weighted RE, used for attention
steering in communications, turns out to be improper. To see how proper
attention communication can emerge, we analyze a scenario of a message sender
who wants to ensure that the receiver of the message can perform well-informed
actions. If the receiver decodes the message using the MEP, the sender only
needs to know the receiver's utility function to inform optimally, but not the
receiver's initial knowledge state. In case only the curvature of the utility
function maxima are known, it becomes desirable to accurately communicate an
attention function, in this case a by this curvature weighted and re-normalized
probability function. Entropic attention communication is here proposed as the
desired generalization of entropic communication that permits weighting while
being proper, thereby aiding the design of optimal communication protocols in
technical applications and helping to understand human communication. For
example, our analysis shows how to derive the level of cooperation expected
under misaligned interests of otherwise honest communication partners.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Direct and inverse modeling of soft robots by learning a condensed FEM  model</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11408</p>
  <p><b>作者</b>：Etienne Ménager,  Tanguy Navez,  Olivier Goury,  Christian Duriez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Finite Element Method, Element Method, Finite Element, powerful modeling tool, tool for predicting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Finite Element Method (FEM) is a powerful modeling tool for predicting
the behavior of soft robots. However, its use for control can be difficult for
non-specialists of numerical computation: it requires an optimization of the
computation to make it real-time. In this paper, we propose a learning-based
approach to obtain a compact but sufficiently rich mechanical representation.
Our choice is based on nonlinear compliance data in the actuator/effector space
provided by a condensation of the FEM model. We demonstrate that this compact
model can be learned with a reasonable amount of data and, at the same time, be
very efficient in terms of modeling, since we can deduce the direct and inverse
kinematics of the robot. We also show how to couple some models learned
individually in particular on an example of a gripper composed of two soft
fingers. Other results are shown by comparing the inverse model derived from
the full FEM model and the one from the compact learned version. This work
opens new perspectives, namely for the embedded control of soft robots, but
also for their design. These perspectives are also discussed in the paper.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Towards Better Fairness-Utility Trade-off: A Comprehensive  Measurement-Based Reinforcement Learning Framework</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11379</p>
  <p><b>作者</b>：Simiao Zhang,  Jitao Bai,  Menghong Guan,  Yihao Huang,  Yueling Zhang,  Jun Sun,  Geguang Pu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bank loan approving, criminal sentencing, loan approving, resume filtering, fairness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning is widely used to make decisions with societal impact such
as bank loan approving, criminal sentencing, and resume filtering. How to
ensure its fairness while maintaining utility is a challenging but crucial
issue. Fairness is a complex and context-dependent concept with over 70
different measurement metrics. Since existing regulations are often vague in
terms of which metric to use and different organizations may prefer different
fairness metrics, it is important to have means of improving fairness
comprehensively. Existing mitigation techniques often target at one specific
fairness metric and have limitations in improving multiple notions of fairness
simultaneously. In this work, we propose CFU (Comprehensive Fairness-Utility),
a reinforcement learning-based framework, to efficiently improve the
fairness-utility trade-off in machine learning classifiers. A comprehensive
measurement that can simultaneously consider multiple fairness notions as well
as utility is established, and new metrics are proposed based on an in-depth
analysis of the relationship between different fairness metrics. The reward
function of CFU is constructed with comprehensive measurement and new metrics.
We conduct extensive experiments to evaluate CFU on 6 tasks, 3 machine learning
models, and 15 fairness-utility measurements. The results demonstrate that CFU
can improve the classifier on multiple fairness metrics without sacrificing its
utility. It outperforms all state-of-the-art techniques and has witnessed a
37.5% improvement on average.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：LatentAugment: Data Augmentation via Guided Manipulation of GAN's Latent  Space</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11375</p>
  <p><b>作者</b>：Lorenzo Tronchin,  Minh H. Vu,  Paolo Soda,  Tommy Löfstedt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：technique to increase, increase the quantity, alleviate overfitting, Generative Adversarial Networks, Data Augmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data Augmentation (DA) is a technique to increase the quantity and diversity
of the training data, and by that alleviate overfitting and improve
generalisation. However, standard DA produces synthetic data for augmentation
with limited diversity. Generative Adversarial Networks (GANs) may unlock
additional information in a dataset by generating synthetic samples having the
appearance of real images. However, these models struggle to simultaneously
address three key requirements: fidelity and high-quality samples; diversity
and mode coverage; and fast sampling. Indeed, GANs generate high-quality
samples rapidly, but have poor mode coverage, limiting their adoption in DA
applications. We propose LatentAugment, a DA strategy that overcomes the low
diversity of GANs, opening up for use in DA applications. Without external
supervision, LatentAugment modifies latent vectors and moves them into latent
space regions to maximise the synthetic images' diversity and fidelity. It is
also agnostic to the dataset and the downstream task. A wide set of experiments
shows that LatentAugment improves the generalisation of a deep model
translating from MRI-to-CT beating both standard DA as well GAN-based sampling.
Moreover, still in comparison with GAN-based sampling, LatentAugment synthetic
samples show superior mode coverage and diversity. Code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Diverse Offline Imitation via Fenchel Duality</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11373</p>
  <p><b>作者</b>：Marin Vlastelica,  Pavel Kolev,  Jin Cheng,  Georg Martius</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant recent progress, works proposing mutual, intrinsic motivation, significant recent, recent progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been significant recent progress in the area of unsupervised skill
discovery, with various works proposing mutual information based objectives, as
a source of intrinsic motivation. Prior works predominantly focused on
designing algorithms that require online access to the environment. In
contrast, we develop an \textit{offline} skill discovery algorithm. Our problem
formulation considers the maximization of a mutual information objective
constrained by a KL-divergence. More precisely, the constraints ensure that the
state occupancy of each skill remains close to the state occupancy of an
expert, within the support of an offline dataset with good state-action
coverage. Our main contribution is to connect Fenchel duality, reinforcement
learning and unsupervised skill discovery, and to give a simple offline
algorithm for learning diverse skills that are aligned with an expert.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Random Separating Hyperplane Theorem and Learning Polytopes</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11371</p>
  <p><b>作者</b>：Chiranjib Bhattacharyya,  Ravindran Kannan,  Amit Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convex Geometry, Separating Hyperplane theorem, Random Separating Hyperplane, Separating Hyperplane, Geometry with myriad</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Separating Hyperplane theorem is a fundamental result in Convex Geometry
with myriad applications. Our first result, Random Separating Hyperplane
Theorem (RSH), is a strengthening of this for polytopes. $\rsh$ asserts that if
the distance between $a$ and a polytope $K$ with $k$ vertices and unit diameter
in $\Re^d$ is at least $\delta$, where $\delta$ is a fixed constant in $(0,1)$,
then a randomly chosen hyperplane separates $a$ and $K$ with probability at
least $1/poly(k)$ and margin at least $\Omega \left(\delta/\sqrt{d} \right)$.
An immediate consequence of our result is the first near optimal bound on the
error increase in the reduction from a Separation oracle to an Optimization
oracle over a polytope.
RSH has algorithmic applications in learning polytopes. We consider a
fundamental problem, denoted the ``Hausdorff problem'', of learning a unit
diameter polytope $K$ within Hausdorff distance $\delta$, given an optimization
oracle for $K$. Using RSH, we show that with polynomially many random queries
to the optimization oracle, $K$ can be approximated within error $O(\delta)$.
To our knowledge this is the first provable algorithm for the Hausdorff
Problem. Building on this result, we show that if the vertices of $K$ are
well-separated, then an optimization oracle can be used to generate a list of
points, each within Hausdorff distance $O(\delta)$ of $K$, with the property
that the list contains a point close to each vertex of $K$. Further, we show
how to prune this list to generate a (unique) approximation to each vertex of
the polytope. We prove that in many latent variable settings, e.g., topic
modeling, LDA, optimization oracles do exist provided we project to a suitable
SVD subspace. Thus, our work yields the first efficient algorithm for finding
approximations to the vertices of the latent polytope under the
well-separatedness assumption.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Bridging the Reality Gap of Reinforcement Learning based Traffic Signal  Control using Domain Randomization and Meta Learning</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11357</p>
  <p><b>作者</b>：Arthur Müller,  Matthia Sabatelli</p>
  <p><b>备注</b>：Paper was accepted by the ITSC 2023 (26th IEEE International Conference on Intelligent Transportation Systems)</p>
  <p><b>关键词</b>：Reinforcement Learning, Traffic Signal, widely explored, reality gap, Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning (RL) has been widely explored in Traffic Signal
Control (TSC) applications, however, still no such system has been deployed in
practice. A key barrier to progress in this area is the reality gap, the
discrepancy that results from differences between simulation models and their
real-world equivalents. In this paper, we address this challenge by first
presenting a comprehensive analysis of potential simulation parameters that
contribute to this reality gap. We then also examine two promising strategies
that can bridge this gap: Domain Randomization (DR) and Model-Agnostic
Meta-Learning (MAML). Both strategies were trained with a traffic simulation
model of an intersection. In addition, the model was embedded in LemgoRL, a
framework that integrates realistic, safety-critical requirements into the
control system. Subsequently, we evaluated the performance of the two methods
on a separate model of the same intersection that was developed with a
different traffic simulator. In this way, we mimic the reality gap. Our
experimental results show that both DR and MAML outperform a state-of-the-art
RL algorithm, therefore highlighting their potential to mitigate the reality
gap in RLbased TSC systems.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：What can a Single Attention Layer Learn? A Study Through the Random  Features Lens</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11353</p>
  <p><b>作者</b>：Hengyu Fu,  Tianyu Guo,  Yu Bai,  Song Mei</p>
  <p><b>备注</b>：41pages, 5 figures</p>
  <p><b>关键词</b>：modern artificial intelligence, core building blocks, achieved significant breakthroughs, Transformer architecture, attention layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attention layers -- which map a sequence of inputs to a sequence of outputs
-- are core building blocks of the Transformer architecture which has achieved
significant breakthroughs in modern artificial intelligence. This paper
presents a rigorous theoretical study on the learning and generalization of a
single multi-head attention layer, with a sequence of key vectors and a
separate query vector as input. We consider the random feature setting where
the attention layer has a large number of heads, with randomly sampled frozen
query and key matrices, and trainable value matrices. We show that such a
random-feature attention layer can express a broad class of target functions
that are permutation invariant to the key vectors. We further provide
quantitative excess risk bounds for learning these target functions from finite
samples, using random feature attention with finitely many heads.
Our results feature several implications unique to the attention structure
compared with existing random features theory for neural networks, such as (1)
Advantages in the sample complexity over standard two-layer random-feature
networks; (2) Concrete and natural classes of functions that can be learned
efficiently by a random-feature attention layer; and (3) The effect of the
sampling distribution of the query-key weight matrix (the product of the query
and key matrix), where Gaussian random weights with a non-zero mean result in
better sample complexities over the zero-mean counterpart for learning certain
natural target functions. Experiments on simulated data corroborate our
theoretical findings and further illustrate the interplay between the sample
size and the complexity of the target function.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Model-based Offline Reinforcement Learning with Count-based Conservatism</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11352</p>
  <p><b>作者</b>：Byeongchan Kim,  Min-hwan Oh</p>
  <p><b>备注</b>：Accepted in ICML 2023</p>
  <p><b>关键词</b>：offline reinforcement learning, reinforcement learning method, model-based offline reinforcement, integrates count-based conservatism, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a model-based offline reinforcement learning method
that integrates count-based conservatism, named $\texttt{Count-MORL}$. Our
method utilizes the count estimates of state-action pairs to quantify model
estimation error, marking the first algorithm of demonstrating the efficacy of
count-based conservatism in model-based offline deep RL to the best of our
knowledge. For our proposed method, we first show that the estimation error is
inversely proportional to the frequency of state-action pairs. Secondly, we
demonstrate that the learned policy under the count-based conservative model
offers near-optimality performance guarantees. Through extensive numerical
experiments, we validate that $\texttt{Count-MORL}$ with hash code
implementation significantly outperforms existing offline RL algorithms on the
D4RL benchmark datasets. The code is accessible at
$\href{this https URL}{this https URL}$.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Improving Transferability of Adversarial Examples via Bayesian Attacks</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11334</p>
  <p><b>作者</b>：Qizhang Li,  Yiwen Guo,  Xiaochen Yang,  Wangmeng Zuo,  Hao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian formulation, ICLR work advocated, model input, model parameters, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a substantial extension of our work published at ICLR.
Our ICLR work advocated for enhancing transferability in adversarial examples
by incorporating a Bayesian formulation into model parameters, which
effectively emulates the ensemble of infinitely many deep neural networks,
while, in this paper, we introduce a novel extension by incorporating the
Bayesian formulation into the model input as well, enabling the joint
diversification of both the model input and model parameters. Our empirical
findings demonstrate that: 1) the combination of Bayesian formulations for both
the model input and model parameters yields significant improvements in
transferability; 2) by introducing advanced approximations of the posterior
distribution over the model input, adversarial transferability achieves further
enhancement, surpassing all state-of-the-arts when attacking without model
fine-tuning. Moreover, we propose a principled approach to fine-tune model
parameters in such an extended Bayesian formulation. The derived optimization
objective inherently encourages flat minima in the parameter space and input
space. Extensive experiments demonstrate that our method achieves a new
state-of-the-art on transfer-based attacks, improving the average success rate
on ImageNet and CIFAR-10 by 19.14% and 2.08%, respectively, when comparing with
our ICLR basic Bayesian method. We will make our code publicly available.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Demystifying Local and Global Fairness Trade-offs in Federated Learning  Using Partial Information Decomposition</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11333</p>
  <p><b>作者</b>：Faisal Hamman,  Sanghamitra Dutta</p>
  <p><b>备注</b>：Accepted at ICML Workshop on Federated Learning and Analytics in Practice</p>
  <p><b>关键词</b>：emph, federated learning, sensitive attributes, group fairness trade-offs, local fairness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present an information-theoretic perspective to group
fairness trade-offs in federated learning (FL) with respect to sensitive
attributes, such as gender, race, etc. Existing works mostly focus on either
\emph{global fairness} (overall disparity of the model across all clients) or
\emph{local fairness} (disparity of the model at each individual client),
without always considering their trade-offs. There is a lack of understanding
of the interplay between global and local fairness in FL, and if and when one
implies the other. To address this gap, we leverage a body of work in
information theory called partial information decomposition (PID) which first
identifies three sources of unfairness in FL, namely, \emph{Unique Disparity},
\emph{Redundant Disparity}, and \emph{Masked Disparity}. Using canonical
examples, we demonstrate how these three disparities contribute to global and
local fairness. This decomposition helps us derive fundamental limits and
trade-offs between global or local fairness, particularly under data
heterogeneity, as well as, derive conditions under which one implies the other.
We also present experimental results on benchmark datasets to support our
theoretical findings. This work offers a more nuanced understanding of the
sources of disparity in FL that can inform the use of local disparity
mitigation techniques, and their convergence and effectiveness when deployed in
practice.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Beyond Convergence: Identifiability of Machine Learning and Deep  Learning Models</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11332</p>
  <p><b>作者</b>：Reza Sameni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimization and regression, regression problems, data, learning, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) and deep learning models are extensively used for
parameter optimization and regression problems. However, not all inverse
problems in ML are ``identifiable,'' indicating that model parameters may not
be uniquely determined from the available data and the data model's
input-output relationship. In this study, we investigate the notion of model
parameter identifiability through a case study focused on parameter estimation
from motion sensor data. Utilizing a bipedal-spring mass human walk dynamics
model, we generate synthetic data representing diverse gait patterns and
conditions. Employing a deep neural network, we attempt to estimate
subject-wise parameters, including mass, stiffness, and equilibrium leg length.
The results show that while certain parameters can be identified from the
observation data, others remain unidentifiable, highlighting that
unidentifiability is an intrinsic limitation of the experimental setup,
necessitating a change in data collection and experimental scenarios. Beyond
this specific case study, the concept of identifiability has broader
implications in ML and deep learning. Addressing unidentifiability requires
proven identifiable models (with theoretical support), multimodal data fusion
techniques, and advancements in model-based machine learning. Understanding and
resolving unidentifiability challenges will lead to more reliable and accurate
applications across diverse domains, transcending mere model convergence and
enhancing the reliability of machine learning models.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Systematic Adaptation of Communication-focused Machine Learning Models  from Real to Virtual Environments for Human-Robot Collaboration</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11327</p>
  <p><b>作者</b>：Debasmita Mukherjee,  Ritwik Singhai,  Homayoun Najjaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enable human-robot collaboration, ranging from gaming, human-robot collaboration, reality has proved, fields ranging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Virtual reality has proved to be useful in applications in several fields
ranging from gaming, medicine, and training to development of interfaces that
enable human-robot collaboration. It empowers designers to explore applications
outside of the constraints posed by the real world environment and develop
innovative solutions and experiences. Hand gestures recognition which has been
a topic of much research and subsequent commercialization in the real world has
been possible because of the creation of large, labelled datasets. In order to
utilize the power of natural and intuitive hand gestures in the virtual domain
for enabling embodied teleoperation of collaborative robots, similarly large
datasets must be created so as to keep the working interface easy to learn and
flexible enough to add more gestures. Depending on the application, this may be
computationally or economically prohibitive. Thus, the adaptation of trained
deep learning models that perform well in the real environment to the virtual
may be a solution to this challenge. This paper presents a systematic framework
for the real to virtual adaptation using limited size of virtual dataset along
with guidelines for creating a curated dataset. Finally, while hand gestures
have been considered as the communication mode, the guidelines and
recommendations presented are generic. These are applicable to other modes such
as body poses and facial expressions which have large datasets available in the
real domain which must be adapted to the virtual one.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：XLDA: Linear Discriminant Analysis for Scaling Continual Learning to  Extreme Classification at the Edge</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11317</p>
  <p><b>作者</b>：Karan Shah,  Vishruth Veerendranath,  Anushka Hebbar,  Raghavendra Bhat</p>
  <p><b>备注</b>：Submitted at ICML 2023: PAC-Bayes Interactive Learning Workshop</p>
  <p><b>关键词</b>：Linear Discriminant Analysis, Streaming Linear Discriminant, Discriminant Analysis, Linear Discriminant, Streaming Linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Streaming Linear Discriminant Analysis (LDA) while proven in
Class-incremental Learning deployments at the edge with limited classes (upto
1000), has not been proven for deployment in extreme classification scenarios.
In this paper, we present: (a) XLDA, a framework for Class-IL in edge
deployment where LDA classifier is proven to be equivalent to FC layer
including in extreme classification scenarios, and (b) optimizations to enable
XLDA-based training and inference for edge deployment where there is a
constraint on available compute resources. We show up to 42x speed up using a
batched training approach and up to 5x inference speedup with nearest neighbor
search on extreme datasets like AliProducts (50k classes) and Google Landmarks
V2 (81k classes)</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Making Pre-trained Language Models both Task-solvers and  Self-calibrators</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11316</p>
  <p><b>作者</b>：Yangyi Chen,  Xingyao Wang,  Heng Ji</p>
  <p><b>备注</b>：Accepted to Findings of ACL 2023</p>
  <p><b>关键词</b>：Pre-trained language models, Pre-trained language, serve as backbones, real-world systems, PLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models (PLMs) serve as backbones for various real-world
systems. For high-stake applications, it's equally essential to have reasonable
confidence estimations in predictions. While the vanilla confidence scores of
PLMs can already be effectively utilized, PLMs consistently become
overconfident in their wrong predictions, which is not desirable in practice.
Previous work shows that introducing an extra calibration task can mitigate
this issue. The basic idea involves acquiring additional data to train models
in predicting the confidence of their initial predictions. However, it only
demonstrates the feasibility of this kind of method, assuming that there are
abundant extra available samples for the introduced calibration task. In this
work, we consider the practical scenario that we need to effectively utilize
training samples to make PLMs both task-solvers and self-calibrators. Three
challenges are presented, including limited training samples, data imbalance,
and distribution shifts. We first conduct pilot experiments to quantify various
decisive factors in the calibration task. Based on the empirical analysis
results, we propose a training algorithm LM-TOAST to tackle the challenges.
Experimental results show that LM-TOAST can effectively utilize the training
data to make PLMs have reasonable confidence estimations while maintaining the
original task performance. Further, we consider three downstream applications,
namely selective classification, adversarial defense, and model cascading, to
show the practical usefulness of LM-TOAST. The code will be made public at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Neuromorphic Online Learning for Spatiotemporal Patterns with a  Forward-only Timeline</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11314</p>
  <p><b>作者</b>：Zhenhang Zhang,  Jingang Jin,  Haowen Fang,  Qinru Qiu</p>
  <p><b>备注</b>：9 pages,8 figures</p>
  <p><b>关键词</b>：high energy efficiency, Spiking neural networks, bio-plausible computing models, neural networks, energy efficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking neural networks (SNNs) are bio-plausible computing models with high
energy efficiency. The temporal dynamics of neurons and synapses enable them to
detect temporal patterns and generate sequences. While Backpropagation Through
Time (BPTT) is traditionally used to train SNNs, it is not suitable for online
learning of embedded applications due to its high computation and memory cost
as well as extended latency. Previous works have proposed online learning
algorithms, but they often utilize highly simplified spiking neuron models
without synaptic dynamics and reset feedback, resulting in subpar performance.
In this work, we present Spatiotemporal Online Learning for Synaptic Adaptation
(SOLSA), specifically designed for online learning of SNNs composed of Leaky
Integrate and Fire (LIF) neurons with exponentially decayed synapses and soft
reset. The algorithm not only learns the synaptic weight but also adapts the
temporal filters associated to the synapses. Compared to the BPTT algorithm,
SOLSA has much lower memory requirement and achieves a more balanced temporal
workload distribution. Moreover, SOLSA incorporates enhancement techniques such
as scheduled weight update, early stop training and adaptive synapse filter,
which speed up the convergence and enhance the learning performance. When
compared to other non-BPTT based SNN learning, SOLSA demonstrates an average
learning accuracy improvement of 14.2%. Furthermore, compared to BPTT, SOLSA
achieves a 5% higher average learning accuracy with a 72% reduction in memory
cost.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：PI-VEGAN: Physics Informed Variational Embedding Generative Adversarial  Networks for Stochastic Differential Equations</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11289</p>
  <p><b>作者</b>：Ruisong Gao,  Yufeng Wang,  Min Yang,  Chuanjun Chen</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：called physics informed, physics informed variational, informed variational embedding, neural networks called, networks called physics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a new category of physics-informed neural networks called physics
informed variational embedding generative adversarial network (PI-VEGAN), that
effectively tackles the forward, inverse, and mixed problems of stochastic
differential equations. In these scenarios, the governing equations are known,
but only a limited number of sensor measurements of the system parameters are
available. We integrate the governing physical laws into PI-VEGAN with
automatic differentiation, while introducing a variational encoder for
approximating the latent variables of the actual distribution of the
measurements. These latent variables are integrated into the generator to
facilitate accurate learning of the characteristics of the stochastic partial
equations. Our model consists of three components, namely the encoder,
generator, and discriminator, each of which is updated alternatively employing
the stochastic gradient descent algorithm. We evaluate the effectiveness of
PI-VEGAN in addressing forward, inverse, and mixed problems that require the
concurrent calculation of system parameters and solutions. Numerical results
demonstrate that the proposed method achieves satisfactory stability and
accuracy in comparison with the previous physics-informed generative
adversarial network (PI-WGAN).</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Kernelized Offline Contextual Dueling Bandits</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11288</p>
  <p><b>作者</b>：Viraj Mehta,  Ojash Neopane,  Vikramjeet Das,  Sen Lin,  Jeff Schneider,  Willie Neiswanger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：direct evaluation, reward function, human feedback, Preference-based feedback, feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Preference-based feedback is important for many applications where direct
evaluation of a reward function is not feasible. A notable recent example
arises in reinforcement learning from human feedback on large language models.
For many of these applications, the cost of acquiring the human feedback can be
substantial or even prohibitive. In this work, we take advantage of the fact
that often the agent can choose contexts at which to obtain human feedback in
order to most efficiently identify a good policy, and introduce the offline
contextual dueling bandit setting. We give an upper-confidence-bound style
algorithm for this setting and prove a regret bound. We also give empirical
confirmation that this method outperforms a similar strategy that uses
uniformly sampled contexts.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：MAS: Towards Resource-Efficient Federated Multiple-Task Learning</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11285</p>
  <p><b>作者</b>：Weiming Zhuang,  Yonggang Wen,  Lingjuan Lyu,  Shuai Zhang</p>
  <p><b>备注</b>：ICCV'23. arXiv admin note: substantial text overlap with arXiv:2207.04202</p>
  <p><b>关键词</b>：distributed machine learning, emerging distributed machine, decentralized edge devices, machine learning method, tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging distributed machine learning method
that empowers in-situ model training on decentralized edge devices. However,
multiple simultaneous FL tasks could overload resource-constrained devices. In
this work, we propose the first FL system to effectively coordinate and train
multiple simultaneous FL tasks. We first formalize the problem of training
simultaneous FL tasks. Then, we present our new approach, MAS (Merge and
Split), to optimize the performance of training multiple simultaneous FL tasks.
MAS starts by merging FL tasks into an all-in-one FL task with a multi-task
architecture. After training for a few rounds, MAS splits the all-in-one FL
task into two or more FL tasks by using the affinities among tasks measured
during the all-in-one training. It then continues training each split of FL
tasks based on model parameters from the all-in-one training. Extensive
experiments demonstrate that MAS outperforms other methods while reducing
training time by 2x and reducing energy consumption by 40%. We hope this work
will inspire the community to further study and optimize training simultaneous
FL tasks.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Epsilon*: Privacy Metric for Machine Learning Models</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11280</p>
  <p><b>作者</b>：Diana M. Negoescu,  Humberto Gonzalez,  Saad Eddin Al Orjany,  Jilei Yang,  Yuliia Lut,  Rahul Tandra,  Xiaowen Zhang,  Xinyi Zheng,  Zach Douglas,  Vidita Nolkha,  Parvez Ahammad,  Gennady Samorodnitsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Epsilon, privacy, model instance, single model instance, model instance prior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Epsilon*, a new privacy metric for measuring the privacy risk of
a single model instance prior to, during, or after deployment of privacy
mitigation strategies. The metric does not require access to the training data
sampling or model training algorithm. Epsilon* is a function of true positive
and false positive rates in a hypothesis test used by an adversary in a
membership inference attack. We distinguish between quantifying the privacy
loss of a trained model instance and quantifying the privacy loss of the
training mechanism which produces this model instance. Existing approaches in
the privacy auditing literature provide lower bounds for the latter, while our
metric provides a lower bound for the former by relying on an
(${\epsilon}$,${\delta}$)-type of quantification of the privacy of the trained
model instance. We establish a relationship between these lower bounds and show
how to implement Epsilon* to avoid numerical and noise amplification
instability. We further show in experiments on benchmark public data sets that
Epsilon* is sensitive to privacy risk mitigation by training with differential
privacy (DP), where the value of Epsilon* is reduced by up to 800% compared to
the Epsilon* values of non-DP trained baseline models. This metric allows
privacy auditors to be independent of model owners, and enables all
decision-makers to visualize the privacy-utility landscape to make informed
decisions regarding the trade-offs between model privacy and utility.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：On the Fisher-Rao Gradient of the Evidence Lower Bound</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11249</p>
  <p><b>作者</b>：Nihat Ay,  Jesse van Oostrum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evidence lower bound, Variational Autonecoder, Helmholtz Machine, Free Energy Principle, natural gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article studies the Fisher-Rao gradient, also referred to as the natural
gradient, of the evidence lower bound, the ELBO, which plays a crucial role
within the theory of the Variational Autonecoder, the Helmholtz Machine and the
Free Energy Principle. The natural gradient of the ELBO is related to the
natural gradient of the Kullback-Leibler divergence from a target distribution,
the prime objective function of learning. Based on invariance properties of
gradients within information geometry, conditions on the underlying model are
provided that ensure the equivalence of minimising the prime objective function
and the maximisation of the ELBO.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：On-Sensor Data Filtering using Neuromorphic Computing for High Energy  Physics Experiments</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11242</p>
  <p><b>作者</b>：Shruti R. Kulkarni,  Aaron Young,  Prasanna Date,  Narasinga Rao Miniskar,  Jeffrey S. Vetter,  Farah Fahim,  Benjamin Parpillon,  Jennet Dickinson,  Nhan Tran,  Jieun Yoo,  Corrinne Mills,  Morris Swartz,  Petar Maksimovic,  Catherine D. Schuman,  Alice Bean</p>
  <p><b>备注</b>：Manuscript accepted at ICONS'23</p>
  <p><b>关键词</b>：Luminosity Large Hadron, High Luminosity Large, high energy physics, Large Hadron, Luminosity Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work describes the investigation of neuromorphic computing-based spiking
neural network (SNN) models used to filter data from sensor electronics in high
energy physics experiments conducted at the High Luminosity Large Hadron
Collider. We present our approach for developing a compact neuromorphic model
that filters out the sensor data based on the particle's transverse momentum
with the goal of reducing the amount of data being sent to the downstream
electronics. The incoming charge waveforms are converted to streams of
binary-valued events, which are then processed by the SNN. We present our
insights on the various system design choices - from data encoding to optimal
hyperparameters of the training algorithm - for an accurate and compact SNN
optimized for hardware deployment. Our results show that an SNN trained with an
evolutionary algorithm and an optimized set of hyperparameters obtains a signal
efficiency of about 91% with nearly half as many parameters as a deep neural
network.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：QDC: Quantum Diffusion Convolution Kernels on Graphs</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11234</p>
  <p><b>作者</b>：Thomas Markovich</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, Graph convolutional neural, Quantum Diffusion Convolution, neural networks, operate by aggregating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph convolutional neural networks (GCNs) operate by aggregating messages
over local neighborhoods given the prediction task under interest. Many GCNs
can be understood as a form of generalized diffusion of input features on the
graph, and significant work has been dedicated to improving predictive accuracy
by altering the ways of message passing. In this work, we propose a new
convolution kernel that effectively rewires the graph according to the
occupation correlations of the vertices by trading on the generalized diffusion
paradigm for the propagation of a quantum particle over the graph. We term this
new convolution kernel the Quantum Diffusion Convolution (QDC) operator. In
addition, we introduce a multiscale variant that combines messages from the QDC
operator and the traditional combinatorial Laplacian. To understand our method,
we explore the spectral dependence of homophily and the importance of quantum
dynamics in the construction of a bandpass filter. Through these studies, as
well as experiments on a range of datasets, we observe that QDC improves
predictive performance on the widely used benchmark datasets when compared to
similar methods.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：From Adaptive Query Release to Machine Unlearning</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11228</p>
  <p><b>作者</b>：Enayat Ullah,  Raman Arora</p>
  <p><b>备注</b>：Accepted to ICML 2023</p>
  <p><b>关键词</b>：big, frac, structured query classes, rho, sqrt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We formalize the problem of machine unlearning as design of efficient
unlearning algorithms corresponding to learning algorithms which perform a
selection of adaptive queries from structured query classes. We give efficient
unlearning algorithms for linear and prefix-sum query classes. As applications,
we show that unlearning in many problems, in particular, stochastic convex
optimization (SCO), can be reduced to the above, yielding improved guarantees
for the problem. In particular, for smooth Lipschitz losses and any $\rho>0$,
our results yield an unlearning algorithm with excess population risk of
$\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$ with unlearning
query (gradient) complexity $\tilde O(\rho \cdot \text{Retraining
Complexity})$, where $d$ is the model dimensionality and $n$ is the initial
number of samples. For non-smooth Lipschitz losses, we give an unlearning
algorithm with excess population risk $\tilde
O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}\big)^{1/2}\big)$ with the
same unlearning query (gradient) complexity. Furthermore, in the special case
of Generalized Linear Models (GLMs), such as those in linear and logistic
regression, we get dimension-independent rates of $\tilde
O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{2/3}}\big)$ and $\tilde
O\big(\frac{1}{\sqrt{n}} +\frac{1}{(n\rho)^{1/3}}\big)$ for smooth Lipschitz
and non-smooth Lipschitz losses respectively. Finally, we give generalizations
of the above from one unlearning request to \textit{dynamic} streams consisting
of insertions and deletions.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Jina Embeddings: A Novel Set of High-Performance Sentence Embedding  Models</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11224</p>
  <p><b>作者</b>：Michael Günther,  Louis Milliken,  Jonathan Geuter,  Georgios Mastrapas,  Bo Wang,  Han Xiao</p>
  <p><b>备注</b>：9 pages, 2 page appendix, EMNLP 2023 Industrial Track</p>
  <p><b>关键词</b>：high-performance sentence embedding, Jina Embeddings constitutes, sentence embedding models, embedding models adept, numerical representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jina Embeddings constitutes a set of high-performance sentence embedding
models adept at translating various textual inputs into numerical
representations, thereby capturing the semantic essence of the text. While
these models are not exclusively designed for text generation, they excel in
applications such as dense retrieval and semantic textual similarity. This
paper details the development of Jina Embeddings, starting with the creation of
a high-quality pairwise and triplet dataset. It underlines the crucial role of
data cleaning in dataset preparation, gives in-depth insights into the model
training process, and concludes with a comprehensive performance evaluation
using the Massive Textual Embedding Benchmark (MTEB).</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：FairMobi-Net: A Fairness-aware Deep Learning Model for Urban Mobility  Flow Generation</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11214</p>
  <p><b>作者</b>：Zhewei Liu,  Lipai Huang,  Chao Fan,  Ali Mostafavi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enabling important applications, population activity patterns, Generating realistic human, human flow, realistic human flows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating realistic human flows across regions is essential for our
understanding of urban structures and population activity patterns, enabling
important applications in the fields of urban planning and management. However,
a notable shortcoming of most existing mobility generation methodologies is
neglect of prediction fairness, which can result in underestimation of mobility
flows across regions with vulnerable population groups, potentially resulting
in inequitable resource distribution and infrastructure development. To
overcome this limitation, our study presents a novel, fairness-aware deep
learning model, FairMobi-Net, for inter-region human flow prediction. The
FairMobi-Net model uniquely incorporates fairness loss into the loss function
and employs a hybrid approach, merging binary classification and numerical
regression techniques for human flow prediction. We validate the FairMobi-Net
model using comprehensive human mobility datasets from four U.S. cities,
predicting human flow at the census-tract level. Our findings reveal that the
FairMobi-Net model outperforms state-of-the-art models (such as the DeepGravity
model) in producing more accurate and equitable human flow predictions across a
variety of region pairs, regardless of regional income differences. The model
maintains a high degree of accuracy consistently across diverse regions,
addressing the previous fairness concern. Further analysis of feature
importance elucidates the impact of physical distances and road network
structures on human flows across regions. With fairness as its touchstone, the
model and results provide researchers and practitioners across the fields of
urban sciences, transportation engineering, and computing with an effective
tool for accurate generation of human mobility flows across regions.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：The Effect of Epidemiological Cohort Creation on the Machine Learning  Prediction of Homelessness and Police Interaction Outcomes Using  Administrative Health Care Data</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11211</p>
  <p><b>作者</b>：Faezehsadat Shahidi,  M. Ethan MacDonald,  Dallas Seitz,  Geoffrey Messier</p>
  <p><b>备注</b>：to be published in Frontiers in Digital Health, Health Informatics</p>
  <p><b>关键词</b>：adverse outcomes, police interaction, initial police interaction, illness can lead, events leading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background: Mental illness can lead to adverse outcomes such as homelessness
and police interaction and understanding of the events leading up to these
adverse outcomes is important. Predictive models may help identify individuals
at risk of such adverse outcomes. Using a fixed observation window cohort with
logistic regression (LR) or machine learning (ML) models can result in lower
performance when compared with adaptive and parcellated windows. Method: An
administrative healthcare dataset was used, comprising of 240,219 individuals
in Calgary, Alberta, Canada who were diagnosed with addiction or mental health
(AMH) between April 1, 2013, and March 31, 2018. The cohort was followed for 2
years to identify factors associated with homelessness and police interactions.
To understand the benefit of flexible windows to predictive models, an
alternative cohort was created. Then LR and ML models, including random forests
(RF), and extreme gradient boosting (XGBoost) were compared in the two cohorts.
Results: Among 237,602 individuals, 0.8% (1,800) experienced first
homelessness, while 0.32% (759) reported initial police interaction among
237,141 individuals. Male sex (AORs: H=1.51, P=2.52), substance disorder (AORs:
H=3.70, P=2.83), psychiatrist visits (AORs: H=1.44, P=1.49), and drug abuse
(AORs: H=2.67, P=1.83) were associated with initial homelessness (H) and police
interaction (P). XGBoost showed superior performance using the flexible method
(sensitivity =91%, AUC =90% for initial homelessness, and sensitivity =90%,
AUC=89% for initial police interaction)
Conclusion: This study identified key features associated with initial
homelessness and police interaction and demonstrated that flexible windows can
improve predictive modeling.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Clinical Trial Active Learning</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11209</p>
  <p><b>作者</b>：Zoe Fowler,  Kiran Kokilepersaud,  Mohit Prabhushankar,  Ghassan AlRegib</p>
  <p><b>备注</b>：Accepted at 14th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics (ACM-BCB)</p>
  <p><b>关键词</b>：active learning, clinical trials, identically distributed, active, account the non-independent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach to active learning that takes into
account the non-independent and identically distributed (non-i.i.d.) structure
of a clinical trial setting. There exists two types of clinical trials:
retrospective and prospective. Retrospective clinical trials analyze data after
treatment has been performed; prospective clinical trials collect data as
treatment is ongoing. Typically, active learning approaches assume the dataset
is i.i.d. when selecting training samples; however, in the case of clinical
trials, treatment results in a dependency between the data collected at the
current and past visits. Thus, we propose prospective active learning to
overcome the limitations present in traditional active learning methods and
apply it to disease detection in optical coherence tomography (OCT) images,
where we condition on the time an image was collected to enforce the i.i.d.
assumption. We compare our proposed method to the traditional active learning
paradigm, which we refer to as retrospective in nature. We demonstrate that
prospective active learning outperforms retrospective active learning in two
different types of test settings.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Heuristic Hyperparameter Choice for Image Anomaly Detection</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11197</p>
  <p><b>作者</b>：Zeyu Jiang,  João P. C. Bertoldo,  Etienne Decencière</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify images deviating, images deviating significantly, fundamental computer vision, computer vision problem, learning neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD) in images is a fundamental computer vision problem by
deep learning neural network to identify images deviating significantly from
normality. The deep features extracted from pretrained models have been proved
to be essential for AD based on multivariate Gaussian distribution analysis.
However, since models are usually pretrained on a large dataset for
classification tasks such as ImageNet, they might produce lots of redundant
features for AD, which increases computational cost and degrades the
performance. We aim to do the dimension reduction of Negated Principal
Component Analysis (NPCA) for these features. So we proposed some heuristic to
choose hyperparameter of NPCA algorithm for getting as fewer components of
features as possible while ensuring a good performance.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Exploring reinforcement learning techniques for discrete and continuous  control tasks in the MuJoCo environment</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11166</p>
  <p><b>作者</b>：Vaddadi Sai Rahul,  Debajyoti Chakraborty</p>
  <p><b>备注</b>：Released @ Dec 2021. For associated project files, see this https URL</p>
  <p><b>关键词</b>：fast physics simulator, action space, observation space, continuous control environment, physics simulator</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We leverage the fast physics simulator, MuJoCo to run tasks in a continuous
control environment and reveal details like the observation space, action
space, rewards, etc. for each task. We benchmark value-based methods for
continuous control by comparing Q-learning and SARSA through a discretization
approach, and using them as baselines, progressively moving into one of the
state-of-the-art deep policy gradient method DDPG. Over a large number of
episodes, Qlearning outscored SARSA, but DDPG outperformed both in a small
number of episodes. Lastly, we also fine-tuned the model hyper-parameters
expecting to squeeze more performance but using lesser time and resources. We
anticipated that the new design for DDPG would vastly improve performance, yet
after only a few episodes, we were able to achieve decent average rewards. We
expect to improve the performance provided adequate time and computational
resources.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Comparison between transformers and convolutional models for  fine-grained classification of insects</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11112</p>
  <p><b>作者</b>：Rita Pucci,  Vincent J. Kalkman,  Dan Stowell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：finding discriminatory features, discriminatory features, classification is challenging, challenging due, difficulty of finding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-grained classification is challenging due to the difficulty of finding
discriminatory features. This problem is exacerbated when applied to
identifying species within the same taxonomical class. This is because species
are often sharing morphological characteristics that make them difficult to
differentiate. We consider the taxonomical class of Insecta. The identification
of insects is essential in biodiversity monitoring as they are one of the
inhabitants at the base of many ecosystems. Citizen science is doing brilliant
work of collecting images of insects in the wild giving the possibility to
experts to create improved distribution maps in all countries. We have billions
of images that need to be automatically classified and deep neural network
algorithms are one of the main techniques explored for fine-grained tasks. At
the SOTA, the field of deep learning algorithms is extremely fruitful, so how
to identify the algorithm to use? We focus on Odonata and Coleoptera orders,
and we propose an initial comparative study to analyse the two best-known layer
structures for computer vision: transformer and convolutional layers. We
compare the performance of T2TViT, a fully transformer-base, EfficientNet, a
fully convolutional-base, and ViTAE, a hybrid. We analyse the performance of
the three models in identical conditions evaluating the performance per
species, per morph together with sex, the inference time, and the overall
performance with unbalanced datasets of images from smartphones. Although we
observe high performances with all three families of models, our analysis shows
that the hybrid model outperforms the fully convolutional-base and fully
transformer-base models on accuracy performance and the fully transformer-base
model outperforms the others on inference speed and, these prove the
transformer to be robust to the shortage of samples and to be faster at
inference time.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Flatness-Aware Minimization for Domain Generalization</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11108</p>
  <p><b>作者</b>：Xingxuan Zhang,  Renzhe Xu,  Han Yu,  Yancheng Dong,  Pengfei Tian,  Peng Cu</p>
  <p><b>备注</b>：Accepted by ICCV2023</p>
  <p><b>关键词</b>：unknown distribution shifts, learn robust models, seeks to learn, distribution shifts, learn robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain generalization (DG) seeks to learn robust models that generalize well
under unknown distribution shifts. As a critical aspect of DG, optimizer
selection has not been explored in depth. Currently, most DG methods follow the
widely used benchmark, DomainBed, and utilize Adam as the default optimizer for
all datasets. However, we reveal that Adam is not necessarily the optimal
choice for the majority of current DG methods and datasets. Based on the
perspective of loss landscape flatness, we propose a novel approach,
Flatness-Aware Minimization for Domain Generalization (FAD), which can
efficiently optimize both zeroth-order and first-order flatness simultaneously
for DG. We provide theoretical analyses of the FAD's out-of-distribution (OOD)
generalization error and convergence. Our experimental results demonstrate the
superiority of FAD on various DG datasets. Additionally, we confirm that FAD is
capable of discovering flatter optima in comparison to other zeroth-order and
first-order flatness-aware optimization methods.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：The importance of feature preprocessing for differentially private  linear optimization</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11106</p>
  <p><b>作者</b>：Ziteng Sun,  Ananda Theertha Suresh,  Aditya Krishna Menon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Training machine learning, machine learning models, received increasing interest, recent years, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training machine learning models with differential privacy (DP) has received
increasing interest in recent years. One of the most popular algorithms for
training differentially private models is differentially private stochastic
gradient descent (DPSGD) and its variants, where at each step gradients are
clipped and combined with some noise. Given the increasing usage of DPSGD, we
ask the question: is DPSGD alone sufficient to find a good minimizer for every
dataset under privacy constraints? As a first step towards answering this
question, we show that even for the simple case of linear classification,
unlike non-private optimization, (private) feature preprocessing is vital for
differentially private optimization. In detail, we first show theoretically
that there exists an example where without feature preprocessing, DPSGD incurs
a privacy error proportional to the maximum norm of features over all samples.
We then propose an algorithm called DPSGD-F, which combines DPSGD with feature
preprocessing and prove that for classification tasks, it incurs a privacy
error proportional to the diameter of the features $\max_{x, x' \in D} \|x -
x'\|_2$. We then demonstrate the practicality of our algorithm on image
classification benchmarks.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Technical Challenges of Deploying Reinforcement Learning Agents for Game  Testing in AAA Games</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11105</p>
  <p><b>作者</b>：Jonas Gillberg,  Joakim Bergdahl,  Alessandro Sestini,  Andrew Eakins,  Linus Gisslen</p>
  <p><b>备注</b>：8 pages, 5 figures</p>
  <p><b>关键词</b>：complex software systems, hard problem, large and complex, complex software, fundamentally a hard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Going from research to production, especially for large and complex software
systems, is fundamentally a hard problem. In large-scale game production, one
of the main reasons is that the development environment can be very different
from the final product. In this technical paper we describe an effort to add an
experimental reinforcement learning system to an existing automated game
testing solution based on scripted bots in order to increase its capacity. We
report on how this reinforcement learning system was integrated with the aim to
increase test coverage similar to [1] in a set of AAA games including
Battlefield 2042 and Dead Space (2023). The aim of this technical paper is to
show a use-case of leveraging reinforcement learning in game production and
cover some of the largest time sinks anyone who wants to make the same journey
for their game may encounter. Furthermore, to help the game industry to adopt
this technology faster, we propose a few research directions that we believe
will be valuable and necessary for making machine learning, and especially
reinforcement learning, an effective tool in game production.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Towards the Better Ranking Consistency: A Multi-task Learning Framework  for Early Stage Ads Ranking</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11096</p>
  <p><b>作者</b>：Xuewei Wang,  Qiang Jin,  Shengyu Huang,  Min Zhang,  Xi Liu,  Zhengli Zhao,  Yukun Chen,  Zhengyu Zhang,  Jiyan Yang,  Ellie Wen,  Sagar Chordia,  Wenlin Chen,  Qin Huang</p>
  <p><b>备注</b>：Accepted by AdKDD 23</p>
  <p><b>关键词</b>：final stage ranking, stage ranking, early stage ranking, final stage, early stage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dividing ads ranking system into retrieval, early, and final stages is a
common practice in large scale ads recommendation to balance the efficiency and
accuracy. The early stage ranking often uses efficient models to generate
candidates out of a set of retrieved ads. The candidates are then fed into a
more computationally intensive but accurate final stage ranking system to
produce the final ads recommendation. As the early and final stage ranking use
different features and model architectures because of system constraints, a
serious ranking consistency issue arises where the early stage has a low ads
recall, i.e., top ads in the final stage are ranked low in the early stage. In
order to pass better ads from the early to the final stage ranking, we propose
a multi-task learning framework for early stage ranking to capture multiple
final stage ranking components (i.e. ads clicks and ads quality events) and
their task relations. With our multi-task learning framework, we can not only
achieve serving cost saving from the model consolidation, but also improve the
ads recall and ranking consistency. In the online A/B testing, our framework
achieves significantly higher click-through rate (CTR), conversion rate (CVR),
total value and better ads-quality (e.g. reduced ads cross-out rate) in a large
scale industrial ads ranking system.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Modular DFR: Digital Delayed Feedback Reservoir Model for Enhancing  Design Flexibility</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11094</p>
  <p><b>作者</b>：Sosei Ikeda,  Hiromitsu Awano,  Takashi Sato</p>
  <p><b>备注</b>：20 pages, 11 figures. Accepted for publication in the International Conference on Compilers, Architectures, and Synthesis for Embedded Systems (CASES) 2023. Will appear in ACM Transactions on Embedded Computing Systems (TECS)</p>
  <p><b>关键词</b>：delayed feedback reservoir, reservoir computing system, computing system well-suited, hardware implementations owing, simple structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A delayed feedback reservoir (DFR) is a type of reservoir computing system
well-suited for hardware implementations owing to its simple structure. Most
existing DFR implementations use analog circuits that require both
digital-to-analog and analog-to-digital converters for interfacing. However,
digital DFRs emulate analog nonlinear components in the digital domain,
resulting in a lack of design flexibility and higher power consumption. In this
paper, we propose a novel modular DFR model that is suitable for fully digital
implementations. The proposed model reduces the number of hyperparameters and
allows flexibility in the selection of the nonlinear function, which improves
the accuracy while reducing the power consumption. We further present two DFR
realizations with different nonlinear functions, achieving 10x power reduction
and 5.3x throughput improvement while maintaining equal or better accuracy.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Towards Generalizable Reinforcement Learning for Trade Execution</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11685</p>
  <p><b>作者</b>：Chuheng Zhang,  Yitong Duan,  Xiaoyu Chen,  Jianyu Chen,  Jian Li,  Li Zhao</p>
  <p><b>备注</b>：Accepted by IJCAI-23</p>
  <p><b>关键词</b>：Optimized trade execution, Optimized trade, trade execution, amount of assets, trade</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimized trade execution is to sell (or buy) a given amount of assets in a
given time with the lowest possible trading cost. Recently, reinforcement
learning (RL) has been applied to optimized trade execution to learn smarter
policies from market data. However, we find that many existing RL methods
exhibit considerable overfitting which prevents them from real deployment. In
this paper, we provide an extensive study on the overfitting problem in
optimized trade execution. First, we model the optimized trade execution as
offline RL with dynamic context (ORDC), where the context represents market
variables that cannot be influenced by the trading policy and are collected in
an offline manner. Under this framework, we derive the generalization bound and
find that the overfitting issue is caused by large context space and limited
context samples in the offline setting. Accordingly, we propose to learn
compact representations for context to address the overfitting problem, either
by leveraging prior knowledge or in an end-to-end manner. To evaluate our
algorithms, we also implement a carefully designed simulator based on
historical limit order book (LOB) data to provide a high-fidelity benchmark for
different algorithms. Our experiments on the high-fidelity simulator
demonstrate that our algorithms can effectively alleviate overfitting and
achieve better performance.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Persistent Ballistic Entanglement Spreading with Optimal Control in  Quantum Spin Chains</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11609</p>
  <p><b>作者</b>：Ying Lu,  Pei Shi,  Xiao-Han Wang,  Jie Hu,  Shi-Ju Ran</p>
  <p><b>备注</b>：5 pages, 4 figures</p>
  <p><b>关键词</b>：understand quantum many-body, quantum many-body dynamics, key routine, routine to understand, many-body dynamics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entanglement propagation provides a key routine to understand quantum
many-body dynamics in and out of equilibrium. In this work, we uncover that the
``variational entanglement-enhancing'' field (VEEF) robustly induces a
persistent ballistic spreading of entanglement in quantum spin chains. The VEEF
is time dependent, and is optimally controlled to maximize the bipartite
entanglement entropy (EE) of the final state. Such a linear growth persists
till the EE reaches the genuine saturation $\tilde{S} = - \log_{2}
2^{-\frac{N}{2}}=\frac{N}{2}$ with $N$ the total number of spins. The EE
satisfies $S(t) = v t$ for the time $t \leq \frac{N}{2v}$, with $v$ the
velocity. These results are in sharp contrast with the behaviors without VEEF,
where the EE generally approaches a sub-saturation known as the Page value
$\tilde{S}_{P} =\tilde{S} - \frac{1}{2\ln{2}}$ in the long-time limit, and the
entanglement growth deviates from being linear before the Page value is
reached. The dependence between the velocity and interactions is explored, with
$v \simeq 2.76$, $4.98$, and $5.75$ for the spin chains with Ising, XY, and
Heisenberg interactions, respectively. We further show that the nonlinear
growth of EE emerges with the presence of long-range interactions.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Learning minimal representations of stochastic processes with  variational autoencoders</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11608</p>
  <p><b>作者</b>：Gabriel Fernández-Fernández,  Carlo Manzo,  Maciej Lewenstein,  Alexandre Dauphin,  Gorka Muñoz-Gil</p>
  <p><b>备注</b>：9 pages, 5 figures, 1 table. Code available at this https URL</p>
  <p><b>关键词</b>：found numerous applications, applications in science, found numerous, numerous applications, variety of natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stochastic processes have found numerous applications in science, as they are
broadly used to model a variety of natural phenomena. Due to their intrinsic
randomness and uncertainty, they are however difficult to characterize. Here,
we introduce an unsupervised machine learning approach to determine the minimal
set of parameters required to effectively describe the dynamics of a stochastic
process. Our method builds upon an extended $\beta$-variational autoencoder
architecture. By means of simulated datasets corresponding to paradigmatic
diffusion models, we showcase its effectiveness in extracting the minimal
relevant parameters that accurately describe these dynamics. Furthermore, the
method enables the generation of new trajectories that faithfully replicate the
expected stochastic behavior. Overall, our approach enables for the autonomous
discovery of unknown parameters describing stochastic processes, hence
enhancing our comprehension of complex phenomena across various fields.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A multi-modal representation of El Niño Southern Oscillation Diversity</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11552</p>
  <p><b>作者</b>：Jakob Schlör,  Felix Strnad,  Antonietta Capotondi,  Bedartha Goswami</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sea surface temperature, surface temperature anomalies, Niño-Southern Oscillation, periods of warm, sea surface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The El Niño-Southern Oscillation (ENSO) is characterized by alternating
periods of warm (El Niño) and cold (La Niña) sea surface temperature
anomalies (SSTA) in the equatorial Pacific. Although El Niño and La Niña
are well-defined climate patterns, no two events are alike. To date, ENSO
diversity has been described primarily in terms of the longitudinal location of
peak SSTA, used to define a bimodal classification of events in Eastern Pacific
(EP) and Central Pacific (CP) types. Here, we use low-dimensional
representations of Pacific SSTAs to argue that binary categorical memberships
are unsuitable to describe ENSO events. Using fuzzy unsupervised clustering, we
recover the four known ENSO categories, along with a fifth category: an Extreme
El Niño. We show that Extreme El Niños differ both in their intensity and
temporal evolution from canonical EP El Niños. We also find that CP La
Niñas, EP El Niños, and Extreme El Niños contribute the most to
interdecadal ENSO variability.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Towards practical reinforcement learning for tokamak magnetic control</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11546</p>
  <p><b>作者</b>：Brendan D. Tracey,  Andrea Michi,  Yuri Chervonyi,  Ian Davies,  Cosmin Paduraru,  Nevena Lazic,  Federico Felici,  Timo Ewalds,  Craig Donner,  Cristian Galperti,  Jonas Buchli,  Michael Neunert,  Andrea Huber,  Jonathan Evens,  Paula Kurylowicz,  Daniel J. Mankowitz,  Martin Riedmiller,  The TCV Team</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-time control systems, shown promising results, Reinforcement learning, plasma magnetic control, including the domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning (RL) has shown promising results for real-time control
systems, including the domain of plasma magnetic control. However, there are
still significant drawbacks compared to traditional feedback control approaches
for magnetic confinement. In this work, we address key drawbacks of the RL
method; achieving higher control accuracy for desired plasma properties,
reducing the steady-state error, and decreasing the required time to learn new
tasks. We build on top of \cite{degrave2022magnetic}, and present algorithmic
improvements to the agent architecture and training procedure. We present
simulation results that show up to 65\% improvement in shape accuracy, achieve
substantial reduction in the long-term bias of the plasma current, and
additionally reduce the training time required to learn new tasks by a factor
of 3 or more. We present new experiments using the upgraded RL-based
controllers on the TCV tokamak, which validate the simulation results achieved,
and point the way towards routinely achieving accurate discharges using the RL
approach.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Neural Operators for Delay-Compensating Control of Hyperbolic PIDEs</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11436</p>
  <p><b>作者</b>：Jie Qi,  Jing Zhang,  Miroslav Krstic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced hyperbolic class, recently introduced DeepONet, introduced DeepONet operator-learning, DeepONet operator-learning framework, basic hyperbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recently introduced DeepONet operator-learning framework for PDE control
is extended from the results for basic hyperbolic and parabolic PDEs to an
advanced hyperbolic class that involves delays on both the state and the system
output or input. The PDE backstepping design produces gain functions that are
outputs of a nonlinear operator, mapping functions on a spatial domain into
functions on a spatial domain, and where this gain-generating operator's inputs
are the PDE's coefficients. The operator is approximated with a DeepONet neural
network to a degree of accuracy that is provably arbitrarily tight. Once we
produce this approximation-theoretic result in infinite dimension, with it we
establish stability in closed loop under feedback that employs approximate
gains. In addition to supplying such results under full-state feedback, we also
develop DeepONet-approximated observers and output-feedback laws and prove
their own stabilizing properties under neural operator approximations. With
numerical simulations we illustrate the theoretical results and quantify the
numerical effort savings, which are of two orders of magnitude, thanks to
replacing the numerical PDE solving with the DeepONet.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Probabilistic Modeling of Inter- and Intra-observer Variability in  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11397</p>
  <p><b>作者</b>：Arne Schmidt,  Pablo Morales-Álvarez,  Rafael Molina</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：challenging task, due to inter, intra-observer variability, iNtra-Observer variation NetwOrk, called Probabilistic Inter-Observer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image segmentation is a challenging task, particularly due to inter-
and intra-observer variability, even between medical experts. In this paper, we
propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer
variation NetwOrk (Pionono). It captures the labeling behavior of each rater
with a multidimensional probability distribution and integrates this
information with the feature maps of the image to produce probabilistic
segmentation predictions. The model is optimized by variational inference and
can be trained end-to-end. It outperforms state-of-the-art models such as
STAPLE, Probabilistic U-Net, and models based on confusion matrices.
Additionally, Pionono predicts multiple coherent segmentation maps that mimic
the rater's expert opinion, which provides additional valuable information for
the diagnostic process. Experiments on real-world cancer segmentation datasets
demonstrate the high accuracy and efficiency of Pionono, making it a powerful
tool for medical image analysis.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Bounded P-values in Parametric Programming-based Selective Inference</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11351</p>
  <p><b>作者</b>：Tomohiro Shiraishi,  Daiki Miwa,  Vo Nguyen Le Duy,  Ichiro Takeuchi</p>
  <p><b>备注</b>：47pages, 14figures</p>
  <p><b>关键词</b>：data-driven hypotheses, statistical hypothesis testing, actively studied, promising framework, framework for statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Selective inference (SI) has been actively studied as a promising framework
for statistical hypothesis testing for data-driven hypotheses. The basic idea
of SI is to make inferences conditional on an event that a hypothesis is
selected. In order to perform SI, this event must be characterized in a
traceable form. When selection event is too difficult to characterize,
additional conditions are introduced for tractability. This additional
conditions often causes the loss of power, and this issue is referred to as
over-conditioning. Parametric programming-based SI (PP-based SI) has been
proposed as one way to address the over-conditioning issue. The main problem of
PP-based SI is its high computational cost due to the need to exhaustively
explore the data space. In this study, we introduce a procedure to reduce the
computational cost while guaranteeing the desired precision, by proposing a
method to compute the upper and lower bounds of p-values. We also proposed
three types of search strategies that efficiently improve these bounds. We
demonstrate the effectiveness of the proposed method in hypothesis testing
problems for feature selection in linear models and attention region
identification in deep neural networks.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Analysis of Elephant Movement in Sub-Saharan Africa: Ecological,  Climatic, and Conservation Perspectives</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11325</p>
  <p><b>作者</b>：Matthew Hines,  Gregory Glatzer,  Shreya Ghosh,  Prasenjit Mitra</p>
  <p><b>备注</b>：11 pages, 17 figures, Accepted in ACM SIGCAS SIGCHI Conference on Computing and Sustainable Societies (COMPASS 2023)</p>
  <p><b>关键词</b>：environment has profound, profound implications, Sub-Saharan Africa, elephant, conservation strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The interaction between elephants and their environment has profound
implications for both ecology and conservation strategies. This study presents
an analytical approach to decipher the intricate patterns of elephant movement
in Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal
variations and rainfall patterns. Despite the complexities surrounding these
influential factors, our analysis provides a holistic view of elephant
migratory behavior in the context of the dynamic African landscape. Our
comprehensive approach enables us to predict the potential impact of these
ecological determinants on elephant migration, a critical step in establishing
informed conservation strategies. This projection is particularly crucial given
the impacts of global climate change on seasonal and rainfall patterns, which
could substantially influence elephant movements in the future. The findings of
our work aim to not only advance the understanding of movement ecology but also
foster a sustainable coexistence of humans and elephants in Sub-Saharan Africa.
By predicting potential elephant routes, our work can inform strategies to
minimize human-elephant conflict, effectively manage land use, and enhance
anti-poaching efforts. This research underscores the importance of integrating
movement ecology and climatic variables for effective wildlife management and
conservation planning.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Screening Mammography Breast Cancer Detection</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11274</p>
  <p><b>作者</b>：Debajyoti Chakraborty</p>
  <p><b>备注</b>：Released @ Apr 2023. For associated project files, see this https URL</p>
  <p><b>关键词</b>：cancer-related deaths, false positives, expensive and prone, prone to false, unnecessary follow-up</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer is a leading cause of cancer-related deaths, but current
programs are expensive and prone to false positives, leading to unnecessary
follow-up and patient anxiety. This paper proposes a solution to automated
breast cancer detection, to improve the efficiency and accuracy of screening
programs. Different methodologies were tested against the RSNA dataset of
radiographic breast images of roughly 20,000 female patients and yielded an
average validation case pF1 score of 0.56 across methods.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Edgewise outliers of network indexed signals</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11239</p>
  <p><b>作者</b>：Christopher Rieser,  Anne Ruiz-Gazen,  Christine Thomas-Agnan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：network indexed multivariate, indexed multivariate data, multivariate data involving, graph nodes, network indexed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider models for network indexed multivariate data involving a
dependence between variables as well as across graph nodes.
In the framework of these models, we focus on outliers detection and
introduce the concept of edgewise outliers. For this purpose, we first derive
the distribution of some sums of squares, in particular squared Mahalanobis
distances that can be used to fix detection rules and thresholds for outlier
detection. We then propose a robust version of the deterministic MCD algorithm
that we call edgewise MCD. An application on simulated data shows the interest
of taking the dependence structure into account. We also illustrate the utility
of the proposed method with a real data set.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Contrastive Graph Pooling for Explainable Classification of Brain  Networks</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11133</p>
  <p><b>作者</b>：Jiaxing Xu,  Qingtian Bian,  Xinhang Li,  Aihu Zhang,  Yiping Ke,  Miao Qiao,  Wei Zhang,  Wei Khang Jeremy Sim,  Balázs Gulyás</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Functional magnetic resonance, magnetic resonance imaging, measure neural activation, Functional magnetic, resonance imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Functional magnetic resonance imaging (fMRI) is a commonly used technique to
measure neural activation. Its application has been particularly important in
identifying underlying neurodegenerative conditions such as Parkinson's,
Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a
graph and extracts features by graph neural networks (GNNs). However, the
unique characteristics of fMRI data require a special design of GNN. Tailoring
GNN to generate effective and domain-explainable features remains challenging.
In this paper, we propose a contrastive dual-attention block and a
differentiable graph pooling method called ContrastPool to better utilize GNN
for brain networks, meeting fMRI-specific requirements. We apply our method to
5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its
superiority over state-of-the-art baselines. Our case study confirms that the
patterns extracted by our method match the domain knowledge in neuroscience
literature, and disclose direct and interesting insights. Our contributions
underscore the potential of ContrastPool for advancing the understanding of
brain networks and neurodegenerative conditions.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Synthetic Control Methods by Density Matching under Implicit  Endogeneitiy</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11127</p>
  <p><b>作者</b>：Masahiro Kato,  Akari Ohda,  Masaaki Imaizumi,  Kenichiro McAlinn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：comparative case studies, case studies, crucial tool, inference in comparative, comparative case</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthetic control methods (SCMs) have become a crucial tool for causal
inference in comparative case studies. The fundamental idea of SCMs is to
estimate counterfactual outcomes for a treated unit by using a weighted sum of
observed outcomes from untreated units. The accuracy of the synthetic control
(SC) is critical for estimating the causal effect, and hence, the estimation of
SC weights has been the focus of much research. In this paper, we first point
out that existing SCMs suffer from an implicit endogeneity problem, which is
the correlation between the outcomes of untreated units and the error term in
the model of a counterfactual outcome. We show that this problem yields a bias
in the causal effect estimator. We then propose a novel SCM based on density
matching, assuming that the density of outcomes of the treated unit can be
approximated by a weighted average of the densities of untreated units (i.e., a
mixture model). Based on this assumption, we estimate SC weights by matching
moments of treated outcomes and the weighted sum of moments of untreated
outcomes. Our proposed method has three advantages over existing methods.
First, our estimator is asymptotically unbiased under the assumption of the
mixture model. Second, due to the asymptotic unbiasedness, we can reduce the
mean squared error for counterfactual prediction. Third, our method generates
full densities of the treatment effect, not only expected values, which
broadens the applicability of SCMs. We provide experimental results to
demonstrate the effectiveness of our proposed method.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：A Markov Chain Model for Identifying Changes in Daily Activity Patterns  of People Living with Dementia</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11126</p>
  <p><b>作者</b>：Nan Fletcher-Lloyd,  Alina-Irina Serban,  Magdalena Kolanko,  David Wingfield,  Danielle Wilson,  Ramin Nilforooshan,  Payam Barnaghi,  Eyal Soreq</p>
  <p><b>备注</b>：12 pages, 7 figures, journal</p>
  <p><b>关键词</b>：increased rate, cognitive and functional, functional decline, Malnutrition and dehydration, living with dementia</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Malnutrition and dehydration are strongly associated with increased cognitive
and functional decline in people living with dementia (PLWD), as well as an
increased rate of hospitalisations in comparison to their healthy counterparts.
Extreme changes in eating and drinking behaviours can often lead to
malnutrition and dehydration, accelerating the progression of cognitive and
functional decline and resulting in a marked reduction in quality of life.
Unfortunately, there are currently no established methods by which to
objectively detect such changes. Here, we present the findings of an extensive
quantitative analysis conducted on in-home monitoring data collected from 73
households of PLWD using Internet of Things technologies. The Coronavirus 2019
(COVID-19) pandemic has previously been shown to have dramatically altered the
behavioural habits, particularly the eating and drinking habits, of PLWD. Using
the COVID-19 pandemic as a natural experiment, we conducted linear
mixed-effects modelling to examine changes in mean kitchen activity within a
subset of 21 households of PLWD that were continuously monitored for 499 days.
We report an observable increase in day-time kitchen activity and a significant
decrease in night-time kitchen activity (t(147) = -2.90, p < 0.001). We further
propose a novel analytical approach to detecting changes in behaviours of PLWD
using Markov modelling applied to remote monitoring data as a proxy for
behaviours that cannot be directly measured. Together, these results pave the
way to introduce improvements into the monitoring of PLWD in naturalistic
settings and for shifting from reactive to proactive care.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Diffusion Models for Probabilistic Deconvolution of Galaxy Images</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11122</p>
  <p><b>作者</b>：Zhiwei Xue,  Yuhang Li,  Yash Patel,  Jeffrey Regier</p>
  <p><b>备注</b>：Accepted to the ICML 2023 Workshop on Machine Learning for Astrophysics</p>
  <p><b>关键词</b>：point spread function, PSF, PSF deconvolution, spread function, point spread</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Telescopes capture images with a particular point spread function (PSF).
Inferring what an image would have looked like with a much sharper PSF, a
problem known as PSF deconvolution, is ill-posed because PSF convolution is not
an invertible transformation. Deep generative models are appealing for PSF
deconvolution because they can infer a posterior distribution over candidate
images that, if convolved with the PSF, could have generated the observation.
However, classical deep generative models such as VAEs and GANs often provide
inadequate sample diversity. As an alternative, we propose a classifier-free
conditional diffusion model for PSF deconvolution of galaxy images. We
demonstrate that this diffusion model captures a greater diversity of possible
deconvolutions compared to a conditional VAE.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Solving multiphysics-based inverse problems with learned surrogates and  constraints</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11099</p>
  <p><b>作者</b>：Ziyi Yin,  Rafael Orozco,  Mathias Louboutin,  Felix J. Herrmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Solving multiphysics-based inverse, multiphysics-based inverse problems, Solving multiphysics-based, simulate numerically, multiphysics-based inverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving multiphysics-based inverse problems for geological carbon storage
monitoring can be challenging when multimodal time-lapse data are expensive to
collect and costly to simulate numerically. We overcome these challenges by
combining computationally cheap learned surrogates with learned constraints.
Not only does this combination lead to vastly improved inversions for the
important fluid-flow property, permeability, it also provides a natural
platform for inverting multimodal data including well measurements and
active-source time-lapse seismic data. By adding a learned constraint, we
arrive at a computationally feasible inversion approach that remains accurate.
This is accomplished by including a trained deep neural network, known as a
normalizing flow, which forces the model iterates to remain in-distribution,
thereby safeguarding the accuracy of trained Fourier neural operators that act
as surrogates for the computationally expensive multiphase flow simulations
involving partial differential equation solves. By means of carefully selected
experiments, centered around the problem of geological carbon storage, we
demonstrate the efficacy of the proposed constrained optimization method on two
different data modalities, namely time-lapse well and time-lapse seismic data.
While permeability inversions from both these two modalities have their pluses
and minuses, their joint inversion benefits from either, yielding valuable
superior permeability inversions and CO2 plume predictions near, and far away,
from the monitoring wells.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Mitigating Communications Threats in Decentralized Federated Learning  through Moving Target Defense</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11730</p>
  <p><b>作者</b>：Enrique Tomás Martínez Beltrán,  Pedro Miguel Sánchez Sánchez,  Sergio López Bernal,  Gérôme Bovet,  Manuel Gil Pérez,  Gregorio Martínez Pérez,  Alberto Huertas Celdrán</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Decentralized Federated Learning, machine learning models, Federated Learning, fostering decentralized model, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of Decentralized Federated Learning (DFL) has enabled the training
of machine learning models across federated participants, fostering
decentralized model aggregation and reducing dependence on a server. However,
this approach introduces unique communication security challenges that have yet
to be thoroughly addressed in the literature. These challenges primarily
originate from the decentralized nature of the aggregation process, the varied
roles and responsibilities of the participants, and the absence of a central
authority to oversee and mitigate threats. Addressing these challenges, this
paper first delineates a comprehensive threat model, highlighting the potential
risks of DFL communications. In response to these identified risks, this work
introduces a security module designed for DFL platforms to counter
communication-based attacks. The module combines security techniques such as
symmetric and asymmetric encryption with Moving Target Defense (MTD)
techniques, including random neighbor selection and IP/port switching. The
security module is implemented in a DFL platform called Fedstellar, allowing
the deployment and monitoring of the federation. A DFL scenario has been
deployed, involving eight physical devices implementing three security
configurations: (i) a baseline with no security, (ii) an encrypted
configuration, and (iii) a configuration integrating both encryption and MTD
techniques. The effectiveness of the security module is validated through
experiments with the MNIST dataset and eclipse attacks. The results indicated
an average F1 score of 95%, with moderate increases in CPU usage (up to 63.2%
+-3.5%) and network traffic (230 MB +-15 MB) under the most secure
configuration, mitigating the risks posed by eavesdropping or eclipse attacks.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Benchmark datasets for biomedical knowledge graphs with negative  statements</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11719</p>
  <p><b>作者</b>：Rita T. Sousa,  Sara Silva,  Catia Pesquita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：negative statements, graphs represent facts, real-world entities, Knowledge graphs represent, statements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graphs represent facts about real-world entities. Most of these
facts are defined as positive statements. The negative statements are scarce
but highly relevant under the open-world assumption. Furthermore, they have
been demonstrated to improve the performance of several applications, namely in
the biomedical domain. However, no benchmark dataset supports the evaluation of
the methods that consider these negative statements.
We present a collection of datasets for three relation prediction tasks -
protein-protein interaction prediction, gene-disease association prediction and
disease prediction - that aim at circumventing the difficulties in building
benchmarks for knowledge graphs with negative statements. These datasets
include data from two successful biomedical ontologies, Gene Ontology and Human
Phenotype Ontology, enriched with negative statements.
We also generate knowledge graph embeddings for each dataset with two popular
path-based methods and evaluate the performance in each task. The results show
that the negative statements can improve the performance of knowledge graph
embeddings.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Statement-based Memory for Neural Source Code Summarization</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11709</p>
  <p><b>作者</b>：Aakash Bansal,  Siyuan Jiang,  Sakib Haque,  Collin McMillan</p>
  <p><b>备注</b>：10 pages 2 figures</p>
  <p><b>关键词</b>：writing natural language, natural language descriptions, code summarization, Source code summarization, code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Source code summarization is the task of writing natural language
descriptions of source code behavior. Code summarization underpins software
documentation for programmers. Short descriptions of code help programmers
understand the program quickly without having to read the code itself. Lately,
neural source code summarization has emerged as the frontier of research into
automated code summarization techniques. By far the most popular targets for
summarization are program subroutines. The idea, in a nutshell, is to train an
encoder-decoder neural architecture using large sets of examples of subroutines
extracted from code repositories. The encoder represents the code and the
decoder represents the summary. However, most current approaches attempt to
treat the subroutine as a single unit. For example, by taking the entire
subroutine as input to a Transformer or RNN-based encoder. But code behavior
tends to depend on the flow from statement to statement. Normally dynamic
analysis may shed light on this flow, but dynamic analysis on hundreds of
thousands of examples in large datasets is not practical. In this paper, we
present a statement-based memory encoder that learns the important elements of
flow during training, leading to a statement-based subroutine representation
without the need for dynamic analysis. We implement our encoder for code
summarization and demonstrate a significant improvement over the
state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction  and Drug Design</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11694</p>
  <p><b>作者</b>：Carl Edwards,  Aakanksha Naik,  Tushar Khot,  Martin Burke,  Heng Ji,  Tom Hope</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Predicting synergistic drug, synergistic drug combinations, Predicting synergistic, accelerate discovery, tumor via biopsied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting synergistic drug combinations can help accelerate discovery of
cancer treatments, particularly therapies personalized to a patient's specific
tumor via biopsied cells. In this paper, we propose a novel setting and models
for in-context drug synergy learning. We are given a small "personalized
dataset" of 10-20 drug synergy relationships in the context of specific cancer
cell targets. Our goal is to predict additional drug synergy relationships in
that context. Inspired by recent work that pre-trains a GPT language model (LM)
to "in-context learn" common function classes, we devise novel pre-training
schemes that enable a GPT model to in-context learn "drug synergy functions".
Our model -- which does not use any textual corpora, molecular fingerprints,
protein interaction or any other domain-specific knowledge -- is able to
achieve competitive results. We further integrate our in-context approach with
a genetic algorithm to optimize model prompts and select synergy candidates to
test after conducting a patient biopsy. Finally, we explore a novel task of
inverse drug design which can potentially enable the design of drugs that
synergize specifically to target a given patient's "personalized dataset". Our
findings can potentially have an important impact on precision cancer medicine,
and also raise intriguing questions on non-textual pre-training for LMs.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Interpretable Graph Networks Formulate Universal Algebra Conjectures</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11688</p>
  <p><b>作者</b>：Francesco Giannini,  Stefano Fioravanti,  Oguzhan Keskin,  Alisia Maria Lupidi,  Lucie Charlotte Magister,  Pietro Lio,  Pietro Barbiero</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, recently empowered researchers, hard mathematical problems, eluded traditional approaches, investigate hard mathematical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of Artificial Intelligence (AI) recently empowered researchers to
investigate hard mathematical problems which eluded traditional approaches for
decades. Yet, the use of AI in Universal Algebra (UA) -- one of the fields
laying the foundations of modern mathematics -- is still completely unexplored.
This work proposes the first use of AI to investigate UA's conjectures with an
equivalent equational and topological characterization. While topological
representations would enable the analysis of such properties using graph neural
networks, the limited transparency and brittle explainability of these models
hinder their straightforward use to empirically validate existing conjectures
or to formulate new ones. To bridge these gaps, we propose a general algorithm
generating AI-ready datasets based on UA's conjectures, and introduce a novel
neural layer to build fully interpretable graph networks. The results of our
experiments demonstrate that interpretable graph networks: (i) enhance
interpretability without sacrificing task accuracy, (ii) strongly generalize
when predicting universal algebra's properties, (iii) generate simple
explanations that empirically validate existing conjectures, and (iv) identify
subgraphs suggesting the formulation of novel conjectures.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11661</p>
  <p><b>作者</b>：Mayug Maniparambil,  Chris Vorster,  Derek Molloy,  Noel Murphy,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：10 pages, Pre-print</p>
  <p><b>关键词</b>：providing good performance, large Vision-Language Models, Contrastive pretrained large, pretrained large Vision-Language, revolutionized visual representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have
revolutionized visual representation learning by providing good performance on
downstream datasets. VLMs are 0-shot adapted to a downstream dataset by
designing prompts that are relevant to the dataset. Such prompt engineering
makes use of domain expertise and a validation dataset. Meanwhile, recent
developments in generative pretrained models like GPT-4 mean they can be used
as advanced internet search tools. They can also be manipulated to provide
visual information in any structure. In this work, we show that GPT-4 can be
used to generate text that is visually descriptive and how this can be used to
adapt CLIP to downstream tasks. We show considerable improvements in 0-shot
transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD
(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.
We also design a simple few-shot adapter that learns to choose the best
possible sentences to construct generalizable classifiers that outperform the
recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized
fine-grained datasets. We will release the code, prompts, and auxiliary text
dataset upon acceptance.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Bandits with Deterministically Evolving States</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11655</p>
  <p><b>作者</b>：Khashayar Khosravi,  Renato Paes Leme,  Chara Podimata,  Apostolis Tsorvantzis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deterministically Evolving States, deterministically evolving, feedback while accounting, lambda, Evolving States</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a model for learning with bandit feedback while accounting for
deterministically evolving and unobservable states that we call Bandits with
Deterministically Evolving States. The workhorse applications of our model are
learning for recommendation systems and learning for online ads. In both cases,
the reward that the algorithm obtains at each round is a function of the
short-term reward of the action chosen and how ``healthy'' the system is (i.e.,
as measured by its state). For example, in recommendation systems, the reward
that the platform obtains from a user's engagement with a particular type of
content depends not only on the inherent features of the specific content, but
also on how the user's preferences have evolved as a result of interacting with
other types of content on the platform. Our general model accounts for the
different rate $\lambda \in [0,1]$ at which the state evolves (e.g., how fast a
user's preferences shift as a result of previous content consumption) and
encompasses standard multi-armed bandits as a special case. The goal of the
algorithm is to minimize a notion of regret against the best-fixed sequence of
arms pulled. We analyze online learning algorithms for any possible
parametrization of the evolution rate $\lambda$. Specifically, the regret rates
obtained are: for $\lambda \in [0, 1/T^2]$: $\widetilde O(\sqrt{KT})$; for
$\lambda = T^{-a/b}$ with $b < a < 2b$: $\widetilde O (T^{b/a})$; for $\lambda
\in (1/T, 1 - 1/\sqrt{T}): \widetilde O (K^{1/3}T^{2/3})$; and for $\lambda \in
[1 - 1/\sqrt{T}, 1]: \widetilde O (K\sqrt{T})$.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Alleviating the Long-Tail Problem in Conversational Recommender Systems</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11650</p>
  <p><b>作者</b>：Zhipeng Zhao,  Kun Zhou,  Xiaolei Wang,  Wayne Xin Zhao,  Fan Pan,  Zhao Cao,  Ji-Rong Wen</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：Conversational recommender systems, natural language conversations, CRS datasets, CRS, Conversational recommender</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational recommender systems (CRS) aim to provide the recommendation
service via natural language conversations. To develop an effective CRS,
high-quality CRS datasets are very crucial. However, existing CRS datasets
suffer from the long-tail issue, \ie a large proportion of items are rarely (or
even never) mentioned in the conversations, which are called long-tail items.
As a result, the CRSs trained on these datasets tend to recommend frequent
items, and the diversity of the recommended items would be largely reduced,
making users easier to get bored.
To address this issue, this paper presents \textbf{LOT-CRS}, a novel
framework that focuses on simulating and utilizing a balanced CRS dataset (\ie
covering all the items evenly) for improving \textbf{LO}ng-\textbf{T}ail
recommendation performance of CRSs. In our approach, we design two pre-training
tasks to enhance the understanding of simulated conversation for long-tail
items, and adopt retrieval-augmented fine-tuning with label smoothness strategy
to further improve the recommendation of long-tail items. Extensive experiments
on two public CRS datasets have demonstrated the effectiveness and
extensibility of our approach, especially on long-tail recommendation.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Morphological Image Analysis and Feature Extraction for Reasoning with  AI-based Defect Detection and Classification Models</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11643</p>
  <p><b>作者</b>：Jiajun Zhang,  Georgina Cosma,  Sarah Bugby,  Axel Finke,  Jason Watkins</p>
  <p><b>备注</b>：8 pages, 3 figures, 5 tables; submitted to 2023 IEEE symposium series on computational intelligence (SSCI)</p>
  <p><b>关键词</b>：provide transparent reasoning, artificial intelligent, engineering and manufacturing, prevalent in industries, transparent reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of artificial intelligent (AI) models becomes more prevalent in
industries such as engineering and manufacturing, it is essential that these
models provide transparent reasoning behind their predictions. This paper
proposes the AI-Reasoner, which extracts the morphological characteristics of
defects (DefChars) from images and utilises decision trees to reason with the
DefChar values. Thereafter, the AI-Reasoner exports visualisations (i.e.
charts) and textual explanations to provide insights into outputs made by
masked-based defect detection and classification models. It also provides
effective mitigation strategies to enhance data pre-processing and overall
model performance. The AI-Reasoner was tested on explaining the outputs of an
IE Mask R-CNN model using a set of 366 images containing defects. The results
demonstrated its effectiveness in explaining the IE Mask R-CNN model's
predictions. Overall, the proposed AI-Reasoner provides a solution for
improving the performance of AI models in industrial applications that require
defect analysis.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Integration of Domain Expert-Centric Ontology Design into the CRISP-DM  for Cyber-Physical Production Systems</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11637</p>
  <p><b>作者</b>：Milapji Singh Gill,  Tom Westermann,  Marvin Schieseck,  Alexander Fay</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Cyber-Physical Production Systems, Production Systems, potentially valuable data, Cyber-Physical Production, potentially valuable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the age of Industry 4.0 and Cyber-Physical Production Systems (CPPSs) vast
amounts of potentially valuable data are being generated. Methods from Machine
Learning (ML) and Data Mining (DM) have proven to be promising in extracting
complex and hidden patterns from the data collected. The knowledge obtained can
in turn be used to improve tasks like diagnostics or maintenance planning.
However, such data-driven projects, usually performed with the Cross-Industry
Standard Process for Data Mining (CRISP-DM), often fail due to the
disproportionate amount of time needed for understanding and preparing the
data. The application of domain-specific ontologies has demonstrated its
advantageousness in a wide variety of Industry 4.0 application scenarios
regarding the aforementioned challenges. However, workflows and artifacts from
ontology design for CPPSs have not yet been systematically integrated into the
CRISP-DM. Accordingly, this contribution intends to present an integrated
approach so that data scientists are able to more quickly and reliably gain
insights into the CPPS. The result is exemplarily applied to an anomaly
detection use case.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：On the Complexity of the Bipartite Polarization Problem: from Neutral to  Highly Polarized Discussions</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11621</p>
  <p><b>作者</b>：Teresa Alsinet,  Josep Argelich,  Ramón Béjar,  Santi Martínez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nodes represent user, represent user opinions, Bipartite Polarization Problem, Bipartite Polarization, represent user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Bipartite Polarization Problem is an optimization problem where the goal
is to find the highest polarized bipartition on a weighted and labelled graph
that represents a debate developed through some social network, where nodes
represent user's opinions and edges agreement or disagreement between users.
This problem can be seen as a generalization of the maxcut problem, and in
previous work approximate solutions and exact solutions have been obtained for
real instances obtained from Reddit discussions, showing that such real
instances seem to be very easy to solve. In this paper, we investigate further
the complexity of this problem, by introducing an instance generation model
where a single parameter controls the polarization of the instances in such a
way that this correlates with the average complexity to solve those instances.
The average complexity results we obtain are consistent with our hypothesis:
the higher the polarization of the instance, the easier is to find the
corresponding polarized bipartition.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：CausE: Towards Causal Knowledge Graph Embedding</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11610</p>
  <p><b>作者</b>：Yichi Zhang,  Wen Zhang</p>
  <p><b>备注</b>：Accepted by CCKS 2023 as a research paper</p>
  <p><b>关键词</b>：continuous vector spaces, knowledge graph completion, Knowledge graph embedding, Knowledge graph, focuses on representing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph embedding (KGE) focuses on representing the entities and
relations of a knowledge graph (KG) into the continuous vector spaces, which
can be employed to predict the missing triples to achieve knowledge graph
completion (KGC). However, KGE models often only briefly learn structural
correlations of triple data and embeddings would be misled by the trivial
patterns and noisy links in real-world KGs. To address this issue, we build the
new paradigm of KGE in the context of causality and embedding disentanglement.
We further propose a Causality-enhanced knowledge graph Embedding (CausE)
framework. CausE employs causal intervention to estimate the causal effect of
the confounder embeddings and design new training objectives to make stable
predictions. Experimental results demonstrate that CausE could outperform the
baseline models and achieve state-of-the-art KGC performance. We release our
code in this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Feature Map Testing for Deep Neural Networks</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11563</p>
  <p><b>作者</b>：Dong Huang,  Qingwen Bu,  Yahao Qing,  Yichao Fu,  Heming Cui</p>
  <p><b>备注</b>：12 pages, 5 figures. arXiv admin note: text overlap with arXiv:2307.11011</p>
  <p><b>关键词</b>：deep neural networks, drawn increasing attention, deep learning testing, deep neural, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the widespread application of deep neural networks~(DNNs) in
safety-critical tasks, deep learning testing has drawn increasing attention.
During the testing process, test cases that have been fuzzed or selected using
test metrics are fed into the model to find fault-inducing test units (e.g.,
neurons and feature maps, activating which will almost certainly result in a
model error) and report them to the DNN developer, who subsequently repair
them~(e.g., retraining the model with test cases). Current test metrics,
however, are primarily concerned with the neurons, which means that test cases
that are discovered either by guided fuzzing or selection with these metrics
focus on detecting fault-inducing neurons while failing to detect
fault-inducing feature maps.
In this work, we propose DeepFeature, which tests DNNs from the feature map
level. When testing is conducted, DeepFeature will scrutinize every internal
feature map in the model and identify vulnerabilities that can be enhanced
through repairing to increase the model's overall performance. Exhaustive
experiments are conducted to demonstrate that (1) DeepFeature is a strong tool
for detecting the model's vulnerable feature maps; (2) DeepFeature's test case
selection has a high fault detection rate and can detect more types of
faults~(comparing DeepFeature to coverage-guided selection techniques, the
fault detection rate is increased by 49.32\%). (3) DeepFeature's fuzzer also
outperforms current fuzzing techniques and generates valuable test cases more
efficiently.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：CycleIK: Neuro-inspired Inverse Kinematics</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11554</p>
  <p><b>作者</b>：Jan-Gerrit Habekost,  Erik Strahl,  Philipp Allgeuer,  Matthias Kerzel,  Stefan Wermter</p>
  <p><b>备注</b>：Accepted at ICANN 2023 (32nd International Conference on Artificial Neural Networks)</p>
  <p><b>关键词</b>：paper introduces CycleIK, introduces CycleIK, inverse kinematics, paper introduces, neuro-robotic approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The paper introduces CycleIK, a neuro-robotic approach that wraps two novel
neuro-inspired methods for the inverse kinematics (IK) task, a Generative
Adversarial Network (GAN), and a Multi-Layer Perceptron architecture. These
methods can be used in a standalone fashion, but we also show how embedding
these into a hybrid neuro-genetic IK pipeline allows for further optimization
via sequential least-squares programming (SLSQP) or a genetic algorithm (GA).
The models are trained and tested on dense datasets that were collected from
random robot configurations of the new Neuro-Inspired COLlaborator (NICOL), a
semi-humanoid robot with two redundant 8-DoF manipulators. We utilize the
weighted multi-objective function from the state-of-the-art BioIK method to
support the training process and our hybrid neuro-genetic architecture. We show
that the neural models can compete with state-of-the-art IK approaches, which
allows for deployment directly to robotic hardware. Additionally, it is shown
that the incorporation of the genetic algorithm improves the precision while
simultaneously reducing the overall runtime.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Identifying Relevant Features of CSE-CIC-IDS2018 Dataset for the  Development of an Intrusion Detection System</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11544</p>
  <p><b>作者</b>：László Göcs,  Zsolt Csaba Johanyák</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：Intrusion detection systems, detection systems, Intrusion detection, essential elements, systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intrusion detection systems (IDSs) are essential elements of IT systems.
Their key component is a classification module that continuously evaluates some
features of the network traffic and identifies possible threats. Its efficiency
is greatly affected by the right selection of the features to be monitored.
Therefore, the identification of a minimal set of features that are necessary
to safely distinguish malicious traffic from benign traffic is indispensable in
the course of the development of an IDS. This paper presents the preprocessing
and feature selection workflow as well as its results in the case of the
CSE-CIC-IDS2018 on AWS dataset, focusing on five attack types. To identify the
relevant features, six feature selection methods were applied, and the final
ranking of the features was elaborated based on their average score. Next,
several subsets of the features were formed based on different ranking
threshold values, and each subset was tried with five classification algorithms
to determine the optimal feature set for each attack type. During the
evaluation, four widely used metrics were taken into consideration.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Model Reporting for Certifiable AI: A Proposal from Merging EU  Regulation into AI Development</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11525</p>
  <p><b>作者</b>：Danilo Brajovic,  Niclas Renner,  Vincent Philipp Goebels,  Philipp Wagner,  Benjamin Fresz,  Martin Biller,  Mara Klaeb,  Janika Kutz,  Jens Neuhuettler,  Marco F. Huber</p>
  <p><b>备注</b>：54 pages, 1 figure, to be submitted</p>
  <p><b>关键词</b>：progress in Explainable, large progress, European Union, Explainable and Safe, cards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite large progress in Explainable and Safe AI, practitioners suffer from
a lack of regulation and standards for AI safety. In this work we merge recent
regulation efforts by the European Union and first proposals for AI guidelines
with recent trends in research: data and model cards. We propose the use of
standardized cards to document AI applications throughout the development
process. Our main contribution is the introduction of use-case and operation
cards, along with updates for data and model cards to cope with regulatory
requirements. We reference both recent research as well as the source of the
regulation in our cards and provide references to additional support material
and toolboxes whenever possible. The goal is to design cards that help
practitioners develop safe AI systems throughout the development process, while
enabling efficient third-party auditing of AI applications, being easy to
understand, and building trust in the system. Our work incorporates insights
from interviews with certification experts as well as developers and
individuals working with the developed AI applications.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Multi-modal Hate Speech Detection using Machine Learning</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11519</p>
  <p><b>作者</b>：Fariha Tahosin Boishakhi,  Ponkoj Chandra Shill,  Md. Golam Rabiul Alam</p>
  <p><b>备注</b>：5 pages, 2 figures, conference</p>
  <p><b>关键词</b>：continuous growth, growth of internet, internet users, users and media, hard to track</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous growth of internet users and media content, it is very
hard to track down hateful speech in audio and video. Converting video or audio
into text does not detect hate speech accurately as human sometimes uses
hateful words as humorous or pleasant in sense and also uses different voice
tones or show different action in the video. The state-ofthe-art hate speech
detection models were mostly developed on a single modality. In this research,
a combined approach of multimodal system has been proposed to detect hate
speech from video contents by extracting feature images, feature values
extracted from the audio, text and used machine learning and Natural language
processing.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11516</p>
  <p><b>作者</b>：Kais Dukes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：augmenting human intelligence, paper defines, approach for augmenting, optimal goal solving, goal solving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper defines a new approach for augmenting human intelligence with AI
for optimal goal solving. Our proposed AI, Indigo, is an acronym for Informed
Numerical Decision-making through Iterative Goal-Oriented optimization. When
combined with a human collaborator, we term the joint system IndigoVX, for
Virtual eXpert. The system is conceptually simple. We envisage this method
being applied to games or business strategies, with the human providing
strategic context and the AI offering optimal, data-driven moves. Indigo
operates through an iterative feedback loop, harnessing the human expert's
contextual knowledge and the AI's data-driven insights to craft and refine
strategies towards a well-defined goal. Using a quantified three-score schema,
this hybridization allows the combined team to evaluate strategies and refine
their plan, while adapting to challenges and changes in real-time.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：General regularization in covariate shift adaptation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11503</p>
  <p><b>作者</b>：Duc Hoan Nguyen,  Sergei V. Pereverzyev,  Werner Zellinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：kernel Hilbert spaces, reproducing kernel Hilbert, training data distribution, future data distributions, Hilbert spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sample reweighting is one of the most widely used methods for correcting the
error of least squares learning algorithms in reproducing kernel Hilbert spaces
(RKHS), that is caused by future data distributions that are different from the
training data distribution. In practical situations, the sample weights are
determined by values of the estimated Radon-Nikodým derivative, of the future
data distribution w.r.t.~the training data distribution. In this work, we
review known error bounds for reweighted kernel regression in RKHS and obtain,
by combination, novel results. We show under weak smoothness conditions, that
the amount of samples, needed to achieve the same order of accuracy as in the
standard supervised learning without differences in data distributions, is
smaller than proven by state-of-the-art analyses.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Adaptive ResNet Architecture for Distributed Inference in  Resource-Constrained IoT Systems</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11499</p>
  <p><b>作者</b>：Fazeela Mazhar Khan,  Emna Baccour,  Aiman Erbad,  Mounir Hamdi</p>
  <p><b>备注</b>：Accepted in the International Wireless Communications & Mobile Computing Conference (IWCMC 2023)</p>
  <p><b>关键词</b>：extensive processing requirements, deep neural networks, neural networks continue, processing requirements, continue to expand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As deep neural networks continue to expand and become more complex, most edge
devices are unable to handle their extensive processing requirements.
Therefore, the concept of distributed inference is essential to distribute the
neural network among a cluster of nodes. However, distribution may lead to
additional energy consumption and dependency among devices that suffer from
unstable transmission rates. Unstable transmission rates harm real-time
performance of IoT devices causing low latency, high energy usage, and
potential failures. Hence, for dynamic systems, it is necessary to have a
resilient DNN with an adaptive architecture that can downsize as per the
available resources. This paper presents an empirical study that identifies the
connections in ResNet that can be dropped without significantly impacting the
model's performance to enable distribution in case of resource shortage. Based
on the results, a multi-objective optimization problem is formulated to
minimize latency and maximize accuracy as per available resources. Our
experiments demonstrate that an adaptive ResNet architecture can reduce shared
data, energy consumption, and latency throughout the distribution while
maintaining high accuracy.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Predict, Refine, Synthesize: Self-Guiding Diffusion Models for  Probabilistic Time Series Forecasting</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11494</p>
  <p><b>作者</b>：Marcel Kollovieh,  Abdul Fatir Ansari,  Michael Bohlke-Schneider,  Jasper Zschiegner,  Hao Wang,  Yuyang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, Diffusion models, models, Diffusion, time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models have achieved state-of-the-art performance in generative
modeling tasks across various domains. Prior works on time series diffusion
models have primarily focused on developing conditional models tailored to
specific forecasting or imputation tasks. In this work, we explore the
potential of task-agnostic, unconditional diffusion models for several time
series applications. We propose TSDiff, an unconditionally trained diffusion
model for time series. Our proposed self-guidance mechanism enables
conditioning TSDiff for downstream tasks during inference, without requiring
auxiliary networks or altering the training procedure. We demonstrate the
effectiveness of our method on three different time series tasks: forecasting,
refinement, and synthetic data generation. First, we show that TSDiff is
competitive with several task-specific conditional forecasting methods
(predict). Second, we leverage the learned implicit probability density of
TSDiff to iteratively refine the predictions of base forecasters with reduced
computational overhead over reverse diffusion (refine). Notably, the generative
performance of the model remains intact -- downstream forecasters trained on
synthetic samples from TSDiff outperform forecasters that are trained on
samples from other state-of-the-art generative time series models, occasionally
even outperforming models trained on real data (synthesize).</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Robust Visual Question Answering: Datasets, Methods, and Future  Challenges</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11471</p>
  <p><b>作者</b>：Jie Ma,  Pinghui Wang,  Dechen Kong,  Zewei Wang,  Jun Liu,  Hongbin Pei,  Junzhou Zhao</p>
  <p><b>备注</b>：IEEE TPAMI (Under Review)</p>
  <p><b>关键词</b>：natural language question, accurate natural language, Visual question answering, natural language answer, question answering requires</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual question answering requires a system to provide an accurate natural
language answer given an image and a natural language question. However, it is
widely recognized that previous generic VQA methods often exhibit a tendency to
memorize biases present in the training data rather than learning proper
behaviors, such as grounding images before predicting answers. Therefore, these
methods usually achieve high in-distribution but poor out-of-distribution
performance. In recent years, various datasets and debiasing methods have been
proposed to evaluate and enhance the VQA robustness, respectively. This paper
provides the first comprehensive survey focused on this emerging fashion.
Specifically, we first provide an overview of the development process of
datasets from in-distribution and out-of-distribution perspectives. Then, we
examine the evaluation metrics employed by these datasets. Thirdly, we propose
a typology that presents the development process, similarities and differences,
robustness comparison, and technical features of existing debiasing methods.
Furthermore, we analyze and discuss the robustness of representative
vision-and-language pre-training models on VQA. Finally, through a thorough
review of the available literature and experimental analysis, we discuss the
key areas for future research from various viewpoints.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Distribution Shift Matters for Knowledge Distillation with Webly  Collected Images</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11469</p>
  <p><b>作者</b>：Jialiang Tang,  Shuo Chen,  Gang Niu,  Masashi Sugiyama,  Chen Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge distillation, Knowledge distillation aims, data-free knowledge distillation, knowledge distillation approaches, existing knowledge distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation aims to learn a lightweight student network from a
pre-trained teacher network. In practice, existing knowledge distillation
methods are usually infeasible when the original training data is unavailable
due to some privacy issues and data management considerations. Therefore,
data-free knowledge distillation approaches proposed to collect training
instances from the Internet. However, most of them have ignored the common
distribution shift between the instances from original training data and webly
collected data, affecting the reliability of the trained student network. To
solve this problem, we propose a novel method dubbed ``Knowledge Distillation
between Different Distributions" (KD$^{3}$), which consists of three
components. Specifically, we first dynamically select useful training instances
from the webly collected data according to the combined predictions of teacher
network and student network. Subsequently, we align both the weighted features
and classifier parameters of the two networks for knowledge memorization.
Meanwhile, we also build a new contrastive learning block called
MixDistribution to generate perturbed data with a new distribution for instance
alignment, so that the student network can further learn a
distribution-invariant representation. Intensive experiments on various
benchmark datasets demonstrate that our proposed KD$^{3}$ can outperform the
state-of-the-art data-free knowledge distillation approaches.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Zero-touch realization of Pervasive Artificial Intelligence-as-a-service  in 6G networks</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11468</p>
  <p><b>作者</b>：Emna Baccour,  Mhd Saria Allahham,  Aiman Erbad,  Amr Mohamed,  Ahmed Refaey Hussein,  Mounir Hamdi</p>
  <p><b>备注</b>：IEEE Communications Magazine</p>
  <p><b>关键词</b>：solutions enabling self-X, fast data rate, zero-touch solutions enabling, low latency, characterized by ultra-dense</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The vision of the upcoming 6G technologies, characterized by ultra-dense
network, low latency, and fast data rate is to support Pervasive AI (PAI) using
zero-touch solutions enabling self-X (e.g., self-configuration,
self-monitoring, and self-healing) services. However, the research on 6G is
still in its infancy, and only the first steps have been taken to conceptualize
its design, investigate its implementation, and plan for use cases. Toward this
end, academia and industry communities have gradually shifted from theoretical
studies of AI distribution to real-world deployment and standardization. Still,
designing an end-to-end framework that systematizes the AI distribution by
allowing easier access to the service using a third-party application assisted
by a zero-touch service provisioning has not been well explored. In this
context, we introduce a novel platform architecture to deploy a zero-touch
PAI-as-a-Service (PAIaaS) in 6G networks supported by a blockchain-based smart
system. This platform aims to standardize the pervasive AI at all levels of the
architecture and unify the interfaces in order to facilitate the service
deployment across application and infrastructure domains, relieve the users
worries about cost, security, and resource allocation, and at the same time,
respect the 6G stringent performance requirements. As a proof of concept, we
present a Federated Learning-as-a-service use case where we evaluate the
ability of our proposed system to self-optimize and self-adapt to the dynamics
of 6G networks in addition to minimizing the users' perceived costs.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Improve Long-term Memory Learning Through Rescaling the Error Temporally</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11462</p>
  <p><b>作者</b>：Shida Wang,  Zhanglu Yan</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：short-term memory, error metric selection, memory, long-term memory learning, paper studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the error metric selection for long-term memory learning
in sequence modelling. We examine the bias towards short-term memory in
commonly used errors, including mean absolute/squared error. Our findings show
that all temporally positive-weighted errors are biased towards short-term
memory in learning linear functionals. To reduce this bias and improve
long-term memory learning, we propose the use of a temporally rescaled error.
In addition to reducing the bias towards short-term memory, this approach can
also alleviate the vanishing gradient issue. We conduct numerical experiments
on different long-memory tasks and sequence models to validate our claims.
Numerical results confirm the importance of appropriate temporally rescaled
error for effective long-term memory learning. To the best of our knowledge,
this is the first work that quantitatively analyzes different errors' memory
bias towards short-term memory in sequence modelling.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Incorporating Human Translator Style into English-Turkish Literary  Machine Translation</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11457</p>
  <p><b>作者</b>：Zeynep Yirmibeşoğlu,  Olgun Dursun,  Harun Dallı,  Mehmet Şahin,  Ena Hodzik,  Sabri Gürses,  Tunga Güngör</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine translation systems, general domain, machine translation, designed to serve, growing tendency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although machine translation systems are mostly designed to serve in the
general domain, there is a growing tendency to adapt these systems to other
domains like literary translation. In this paper, we focus on English-Turkish
literary translation and develop machine translation models that take into
account the stylistic features of translators. We fine-tune a pre-trained
machine translation model by the manually-aligned works of a particular
translator. We make a detailed analysis of the effects of manual and automatic
alignments, data augmentation methods, and corpus size on the translations. We
propose an approach based on stylistic features to evaluate the style of a
translator in the output translations. We show that the human translator style
can be highly recreated in the target machine translations by adapting the
models to the style of the translator.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Providing personalized Explanations: a Conversational Approach</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11452</p>
  <p><b>作者</b>：Jieting Luo,  Thomas Studer,  Mehdi Dastani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systems require personalized, require personalized explanations, increasing applications, systems require, personalized explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing applications of AI systems require personalized explanations
for their behaviors to various stakeholders since the stakeholders may have
various knowledge and backgrounds. In general, a conversation between
explainers and explainees not only allows explainers to obtain the explainees'
background, but also allows explainees to better understand the explanations.
In this paper, we propose an approach for an explainer to communicate
personalized explanations to an explainee through having consecutive
conversations with the explainee. We prove that the conversation terminates due
to the explainee's justification of the initial claim as long as there exists
an explanation for the initial claim that the explainee understands and the
explainer is aware of.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：AIGC Empowering Telecom Sector White Paper_chinese</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11449</p>
  <p><b>作者</b>：Ye Ouyang,  Yaqin Zhang,  Xiaozhou Ye,  Yunxin Liu,  Yong Song,  Yang Liu,  Sen Bian,  Zhiyong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：world competition pattern, bring great leaps, future world competition, telecom sector, telecom service GPT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the global craze of GPT, people have deeply realized that AI, as a
transformative technology and key force in economic and social development,
will bring great leaps and breakthroughs to the global industry and profoundly
influence the future world competition pattern. As the builder and operator of
information and communication infrastructure, the telecom sector provides
infrastructure support for the development of AI, and even takes the lead in
the implementation of AI applications. How to enable the application of AIGC
(GPT) and implement AIGC in the telecom sector are questions that telecom
practitioners must ponder and answer. Through the study of GPT, a typical
representative of AIGC, the authors have analyzed how GPT empowers the telecom
sector in the form of scenarios, discussed the gap between the current GPT
general model and telecom services, proposed for the first time a Telco
Augmented Cognition capability system, provided answers to how to construct a
telecom service GPT in the telecom sector, and carried out various practices.
Our counterparts in the industry are expected to focus on collaborative
innovation around telecom and AI, build an open and shared innovation
ecosystem, promote the deep integration of AI and telecom sector, and
accelerate the construction of next-generation information infrastructure, in
an effort to facilitate the digital transformation of the economy and society.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Batching for Green AI -- An Exploratory Study on Inference</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11434</p>
  <p><b>作者</b>：Tim Yarally,  Luís Cruz,  Daniel Feitosa,  June Sallou,  Arie van Deursen</p>
  <p><b>备注</b>：8 pages, 4 figures, 1 table. Accepted at Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2023</p>
  <p><b>关键词</b>：essential parameter, parameter to tune, neural networks, batch size, energy consumption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The batch size is an essential parameter to tune during the development of
new neural networks. Amongst other quality indicators, it has a large degree of
influence on the model's accuracy, generalisability, training times and
parallelisability. This fact is generally known and commonly studied. However,
during the application phase of a deep learning model, when the model is
utilised by an end-user for inference, we find that there is a disregard for
the potential benefits of introducing a batch size. In this study, we examine
the effect of input batching on the energy consumption and response times of
five fully-trained neural networks for computer vision that were considered
state-of-the-art at the time of their publication. The results suggest that
batching has a significant effect on both of these metrics. Furthermore, we
present a timeline of the energy efficiency and accuracy of neural networks
over the past decade. We find that in general, energy consumption rises at a
much steeper pace than accuracy and question the necessity of this evolution.
Additionally, we highlight one particular network, ShuffleNetV2(2018), that
achieved a competitive performance for its time while maintaining a much lower
energy consumption. Nevertheless, we highlight that the results are model
dependent.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A Video-based Detector for Suspicious Activity in Examination with  OpenPose</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11413</p>
  <p><b>作者</b>：Reuben Moyo,  Stanley Ndebvu,  Michael Zimba,  Jimmy Mbelwa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：invest significant resources, learning process, crucial part, resources into maintaining, institutions invest significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Examinations are a crucial part of the learning process, and academic
institutions invest significant resources into maintaining their integrity by
preventing cheating from students or facilitators. However, cheating has become
rampant in examination setups, compromising their integrity. The traditional
method of relying on invigilators to monitor every student is impractical and
ineffective. To address this issue, there is a need to continuously record exam
sessions to monitor students for suspicious activities. However, these
recordings are often too lengthy for invigilators to analyze effectively, and
fatigue may cause them to miss significant details. To widen the coverage,
invigilators could use fixed overhead or wearable cameras. This paper
introduces a framework that uses automation to analyze videos and detect
suspicious activities during examinations efficiently and effectively. We
utilized the OpenPose framework and Convolutional Neural Network (CNN) to
identify students exchanging objects during exams. This detection system is
vital in preventing cheating and promoting academic integrity, fairness, and
quality education for institutions.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Deep Directly-Trained Spiking Neural Networks for Object Detection</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11411</p>
  <p><b>作者</b>：Qiaoyi Su,  Yuhong Chou,  Yifan Hu,  Jianing Li,  Shijie Mei,  Ziyang Zhang,  Guoqi Li</p>
  <p><b>备注</b>：Accepted by ICCV2023</p>
  <p><b>关键词</b>：Spiking neural networks, brain-inspired energy-efficient models, directly-trained SNN, Spiking neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking neural networks (SNNs) are brain-inspired energy-efficient models
that encode information in spatiotemporal dynamics. Recently, deep SNNs trained
directly have shown great success in achieving high performance on
classification tasks with very few time steps. However, how to design a
directly-trained SNN for the regression task of object detection still remains
a challenging problem. To address this problem, we propose EMS-YOLO, a novel
directly-trained SNN framework for object detection, which is the first trial
to train a deep SNN with surrogate gradients for object detection rather than
ANN-SNN conversion strategies. Specifically, we design a full-spike residual
block, EMS-ResNet, which can effectively extend the depth of the
directly-trained SNN with low power consumption. Furthermore, we theoretically
analyze and prove the EMS-ResNet could avoid gradient vanishing or exploding.
The results demonstrate that our approach outperforms the state-of-the-art
ANN-SNN conversion methods (at least 500 time steps) in extremely fewer time
steps (only 4 time steps). It is shown that our model could achieve comparable
performance to the ANN with the same architecture while consuming 5.83 times
less energy on the frame-based COCO Dataset and the event-based Gen1 Dataset.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Large Language Model-based System to Provide Immediate Feedback to  Students in Flipped Classroom Preparation Learning</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11388</p>
  <p><b>作者</b>：Shintaro Uchiyama,  Kyoji Umemura,  Yusuke Morita</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：large language models, flipped classroom model, flipped classroom preparation, flipped classroom, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a system that uses large language models to provide
immediate feedback to students in flipped classroom preparation learning. This
study aimed to solve challenges in the flipped classroom model, such as
ensuring that students are emotionally engaged and motivated to learn. Students
often have questions about the content of lecture videos in the preparation of
flipped classrooms, but it is difficult for teachers to answer them
immediately. The proposed system was developed using the ChatGPT API on a
video-watching support system for preparation learning that is being used in
real practice. Answers from ChatGPT often do not align with the context of the
student's question. Therefore, this paper also proposes a method to align the
answer with the context. This paper also proposes a method to collect the
teacher's answers to the students' questions and use them as additional guides
for the students. This paper discusses the design and implementation of the
proposed system.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Diverse Offline Imitation via Fenchel Duality</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11373</p>
  <p><b>作者</b>：Marin Vlastelica,  Pavel Kolev,  Jin Cheng,  Georg Martius</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant recent progress, works proposing mutual, intrinsic motivation, significant recent, recent progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been significant recent progress in the area of unsupervised skill
discovery, with various works proposing mutual information based objectives, as
a source of intrinsic motivation. Prior works predominantly focused on
designing algorithms that require online access to the environment. In
contrast, we develop an \textit{offline} skill discovery algorithm. Our problem
formulation considers the maximization of a mutual information objective
constrained by a KL-divergence. More precisely, the constraints ensure that the
state occupancy of each skill remains close to the state occupancy of an
expert, within the support of an offline dataset with good state-action
coverage. Our main contribution is to connect Fenchel duality, reinforcement
learning and unsupervised skill discovery, and to give a simple offline
algorithm for learning diverse skills that are aligned with an expert.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11346</p>
  <p><b>作者</b>：Zihan Guan,  Zihao Wu,  Zhengliang Liu,  Dufan Wu,  Hui Ren,  Quanzheng Li,  Xiang Li,  Ninghao Liu</p>
  <p><b>备注</b>：16 pages, 10 figures</p>
  <p><b>关键词</b>：Participant recruitment based, unstructured medical texts, clinical research, clinical notes, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Participant recruitment based on unstructured medical texts such as clinical
notes and radiology reports has been a challenging yet important task for the
cohort establishment in clinical research. Recently, Large Language Models
(LLMs) such as ChatGPT have achieved tremendous success in various downstream
tasks thanks to their promising performance in language understanding,
inference, and generation. It is then natural to test their feasibility in
solving the cohort recruitment task, which involves the classification of a
given paragraph of medical text into disease label(s). However, when applied to
knowledge-intensive problem settings such as medical text classification, where
the LLMs are expected to understand the decision made by human experts and
accurately identify the implied disease labels, the LLMs show a mediocre
performance. A possible explanation is that, by only using the medical text,
the LLMs neglect to use the rich context of additional information that
languages afford. To this end, we propose to use a knowledge graph as auxiliary
information to guide the LLMs in making predictions. Moreover, to further boost
the LLMs adapt to the problem setting, we apply a chain-of-thought (CoT) sample
selection strategy enhanced by reinforcement learning, which selects a set of
CoT samples given each individual medical report. Experimental results and
various ablation studies show that our few-shot learning method achieves
satisfactory performance compared with fine-tuning strategies and gains superb
advantages when the available data is limited. The code and sample dataset of
the proposed CohortGPT model is available at:
https://anonymous.4open.science/r/CohortGPT-4872/</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：A Two-stage Fine-tuning Strategy for Generalizable Manipulation Skill of  Embodied AI</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11343</p>
  <p><b>作者</b>：Fang Gao,  XueTao Li,  Jun Yu,  Feng Shaung</p>
  <p><b>备注</b>：5 pages, 2 figures, 5 tables, accept by Robotics: Science and Systems 2023 - Workshop Interdisciplinary Exploration of Generalizable Manipulation Policy Learning:Paradigms and Debates</p>
  <p><b>关键词</b>：advent of Chat-GPT, Chat-GPT has led, surge of interest, Embodied, existing Embodied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of Chat-GPT has led to a surge of interest in Embodied AI.
However, many existing Embodied AI models heavily rely on massive interactions
with training environments, which may not be practical in real-world
situations. To this end, the Maniskill2 has introduced a full-physics
simulation benchmark for manipulating various 3D objects. This benchmark
enables agents to be trained using diverse datasets of demonstrations and
evaluates their ability to generalize to unseen scenarios in testing
environments. In this paper, we propose a novel two-stage fine-tuning strategy
that aims to further enhance the generalization capability of our model based
on the Maniskill2 benchmark. Through extensive experiments, we demonstrate the
effectiveness of our approach by achieving the 1st prize in all three tracks of
the ManiSkill2 Challenge. Our findings highlight the potential of our method to
improve the generalization abilities of Embodied AI models and pave the way for
their ractical applications in real-world scenarios. All codes and models of
our solution is available at this https URL</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：OpenGDA: Graph Domain Adaptation Benchmark for Cross-network Learning</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11341</p>
  <p><b>作者</b>：Boshen Shi,  Yongqing Wang,  Fangda Guo,  Jiangli Shao,  Huawei Shen,  Xueqi Cheng</p>
  <p><b>备注</b>：Under Review</p>
  <p><b>关键词</b>：Graph domain adaptation, domain adaptation models, domain adaptation, Graph domain, evaluating graph domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph domain adaptation models are widely adopted in cross-network learning
tasks, with the aim of transferring labeling or structural knowledge.
Currently, there mainly exist two limitations in evaluating graph domain
adaptation models. On one side, they are primarily tested for the specific
cross-network node classification task, leaving tasks at edge-level and
graph-level largely under-explored. Moreover, they are primarily tested in
limited scenarios, such as social networks or citation networks, lacking
validation of model's capability in richer scenarios. As comprehensively
assessing models could enhance model practicality in real-world applications,
we propose a benchmark, known as OpenGDA. It provides abundant pre-processed
and unified datasets for different types of tasks (node, edge, graph). They
originate from diverse scenarios, covering web information systems, urban
systems and natural systems. Furthermore, it integrates state-of-the-art models
with standardized and end-to-end pipelines. Overall, OpenGDA provides a
user-friendly, scalable and reproducible benchmark for evaluating graph domain
adaptation models. The benchmark experiments highlight the challenges of
applying GDA models to real-world applications with consistent good
performance, and potentially provide insights to future research. As an
emerging project, OpenGDA will be regularly updated with new datasets and
models. It could be accessed from this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural  Radiance Fields</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11335</p>
  <p><b>作者</b>：Wenbo Hu,  Yuling Wang,  Lin Ma,  Bangbang Yang,  Lin Gao,  Xiao Liu,  Yuewen Ma</p>
  <p><b>备注</b>：Accepted to ICCV 2023 Project page: this https URL</p>
  <p><b>关键词</b>：MipNeRF presents fine-detailed, neural radiance fields, MipNeRF presents, days for training, tremendous progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the tremendous progress in neural radiance fields (NeRF), we still
face a dilemma of the trade-off between quality and efficiency, e.g., MipNeRF
presents fine-detailed and anti-aliased renderings but takes days for training,
while Instant-ngp can accomplish the reconstruction in a few minutes but
suffers from blurring or aliasing when rendering at various distances or
resolutions due to ignoring the sampling area. To this end, we propose a novel
Tri-Mip encoding that enables both instant reconstruction and anti-aliased
high-fidelity rendering for neural radiance fields. The key is to factorize the
pre-filtered 3D feature spaces in three orthogonal mipmaps. In this way, we can
efficiently perform 3D area sampling by taking advantage of 2D pre-filtered
feature maps, which significantly elevates the rendering quality without
sacrificing efficiency. To cope with the novel Tri-Mip representation, we
propose a cone-casting rendering technique to efficiently sample anti-aliased
3D features with the Tri-Mip encoding considering both pixel imaging and
observing distance. Extensive experiments on both synthetic and real-world
datasets demonstrate our method achieves state-of-the-art rendering quality and
reconstruction speed while maintaining a compact representation that reduces
25% model size compared against Instant-ngp.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：HVDetFusion: A Simple and Robust Camera-Radar Fusion Framework</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11323</p>
  <p><b>作者</b>：Kai Lei,  Zhan Chen,  Shuman Jia,  Xiaoteng Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important perception module, radar data, camera data, Camera, pure Camera</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the field of autonomous driving, 3D object detection is a very important
perception module. Although the current SOTA algorithm combines Camera and
Lidar sensors, limited by the high price of Lidar, the current mainstream
landing schemes are pure Camera sensors or Camera+Radar sensors. In this study,
we propose a new detection algorithm called HVDetFusion, which is a multi-modal
detection algorithm that not only supports pure camera data as input for
detection, but also can perform fusion input of radar data and camera data. The
camera stream does not depend on the input of Radar data, thus addressing the
downside of previous methods. In the pure camera stream, we modify the
framework of Bevdet4D for better perception and more efficient inference, and
this stream has the whole 3D detection output. Further, to incorporate the
benefits of Radar signals, we use the prior information of different object
positions to filter the false positive information of the original radar data,
according to the positioning information and radial velocity information
recorded by the radar sensors to supplement and fuse the BEV features generated
by the original camera data, and the effect is further improved in the process
of fusion training. Finally, HVDetFusion achieves the new state-of-the-art
67.4\% NDS on the challenging nuScenes test set among all camera-radar 3D
object detectors. The code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：How to Tidy Up a Table: Fusing Visual and Semantic Commonsense Reasoning  for Robotic Tasks with Vague Objectives</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11319</p>
  <p><b>作者</b>：Yiqing Xu,  David Hsu</p>
  <p><b>备注</b>：RSSLRL2023 Workshop</p>
  <p><b>关键词</b>：real-life scenarios pose, scenarios pose long-standing, pose long-standing challenges, defining rules, optimization is difficult</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vague objectives in many real-life scenarios pose long-standing challenges
for robotics, as defining rules, rewards, or constraints for optimization is
difficult. Tasks like tidying a messy table may appear simple for humans, but
articulating the criteria for tidiness is complex due to the ambiguity and
flexibility in commonsense reasoning. Recent advancement in Large Language
Models (LLMs) offers us an opportunity to reason over these vague objectives:
learned from extensive human data, LLMs capture meaningful common sense about
human behavior. However, as LLMs are trained solely on language input, they may
struggle with robotic tasks due to their limited capacity to account for
perception and low-level controls. In this work, we propose a simple approach
to solve the task of table tidying, an example of robotic tasks with vague
objectives. Specifically, the task of tidying a table involves not just
clustering objects by type and functionality for semantic tidiness but also
considering spatial-visual relations of objects for a visually pleasing
arrangement, termed as visual tidiness. We propose to learn a lightweight,
image-based tidiness score function to ground the semantically tidy policy of
LLMs to achieve visual tidiness. We innovatively train the tidiness score using
synthetic data gathered using random walks from a few tidy configurations. Such
trajectories naturally encode the order of tidiness, thereby eliminating the
need for laborious and expensive human demonstrations. Our empirical results
show that our pipeline can be applied to unseen objects and complex 3D
arrangements.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：XLDA: Linear Discriminant Analysis for Scaling Continual Learning to  Extreme Classification at the Edge</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11317</p>
  <p><b>作者</b>：Karan Shah,  Vishruth Veerendranath,  Anushka Hebbar,  Raghavendra Bhat</p>
  <p><b>备注</b>：Submitted at ICML 2023: PAC-Bayes Interactive Learning Workshop</p>
  <p><b>关键词</b>：Linear Discriminant Analysis, Streaming Linear Discriminant, Discriminant Analysis, Linear Discriminant, Streaming Linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Streaming Linear Discriminant Analysis (LDA) while proven in
Class-incremental Learning deployments at the edge with limited classes (upto
1000), has not been proven for deployment in extreme classification scenarios.
In this paper, we present: (a) XLDA, a framework for Class-IL in edge
deployment where LDA classifier is proven to be equivalent to FC layer
including in extreme classification scenarios, and (b) optimizations to enable
XLDA-based training and inference for edge deployment where there is a
constraint on available compute resources. We show up to 42x speed up using a
batched training approach and up to 5x inference speedup with nearest neighbor
search on extreme datasets like AliProducts (50k classes) and Google Landmarks
V2 (81k classes)</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：DPM-OT: A New Diffusion Probabilistic Model Based on Optimal Transport</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11308</p>
  <p><b>作者</b>：Zezeng Li,  ShengHao Li,  Zhanpeng Wang,  Na Lei,  Zhongxuan Luo,  Xianfeng Gu</p>
  <p><b>备注</b>：iccv2023 accepted</p>
  <p><b>关键词</b>：generally requires hundreds, diffusion probabilistic models, piecewise distribution transformation, inverse diffusion trajectory, probabilistic models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sampling from diffusion probabilistic models (DPMs) can be viewed as a
piecewise distribution transformation, which generally requires hundreds or
thousands of steps of the inverse diffusion trajectory to get a high-quality
image. Recent progress in designing fast samplers for DPMs achieves a trade-off
between sampling speed and sample quality by knowledge distillation or
adjusting the variance schedule or the denoising equation. However, it can't be
optimal in both aspects and often suffer from mode mixture in short steps. To
tackle this problem, we innovatively regard inverse diffusion as an optimal
transport (OT) problem between latents at different stages and propose the
DPM-OT, a unified learning framework for fast DPMs with a direct expressway
represented by OT map, which can generate high-quality samples within around 10
function evaluations. By calculating the semi-discrete optimal transport map
between the data latents and the white noise, we obtain an expressway from the
prior distribution to the data distribution, while significantly alleviating
the problem of mode mixture. In addition, we give the error bound of the
proposed method, which theoretically guarantees the stability of the algorithm.
Extensive experiments validate the effectiveness and advantages of DPM-OT in
terms of speed and quality (FID and mode mixture), thus representing an
efficient solution for generative modeling. Source codes are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Kernelized Offline Contextual Dueling Bandits</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11288</p>
  <p><b>作者</b>：Viraj Mehta,  Ojash Neopane,  Vikramjeet Das,  Sen Lin,  Jeff Schneider,  Willie Neiswanger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：direct evaluation, reward function, human feedback, Preference-based feedback, feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Preference-based feedback is important for many applications where direct
evaluation of a reward function is not feasible. A notable recent example
arises in reinforcement learning from human feedback on large language models.
For many of these applications, the cost of acquiring the human feedback can be
substantial or even prohibitive. In this work, we take advantage of the fact
that often the agent can choose contexts at which to obtain human feedback in
order to most efficiently identify a good policy, and introduce the offline
contextual dueling bandit setting. We give an upper-confidence-bound style
algorithm for this setting and prove a regret bound. We also give empirical
confirmation that this method outperforms a similar strategy that uses
uniformly sampled contexts.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Eliminating Unintended Stable Fixpoints for Hybrid Reasoning Systems</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11286</p>
  <p><b>作者</b>：Spencer Killen,  Jia-Huai You</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：Approximation Fixpoint Theory, Approximation Fixpoint, Fixpoint Theory, traditional AFT theory, AFT theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide variety of nonmonotonic semantics can be expressed as approximators
defined under AFT (Approximation Fixpoint Theory). Using traditional AFT
theory, it is not possible to define approximators that rely on information
computed in previous iterations of stable revision. However, this information
is rich for semantics that incorporate classical negation into nonmonotonic
reasoning. In this work, we introduce a methodology resembling AFT that can
utilize priorly computed upper bounds to more precisely capture semantics. We
demonstrate our framework's applicability to hybrid MKNF (minimal knowledge and
negation as failure) knowledge bases by extending the state-of-the-art
approximator.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Joint one-sided synthetic unpaired image translation and segmentation  for colorectal cancer prevention</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11253</p>
  <p><b>作者</b>：Enric Moreu,  Eric Arazo,  Kevin McGuinness,  Noel E. O'Connor</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2202.08680</p>
  <p><b>关键词</b>：shown excellent performance, analysing medical images, shown excellent, excellent performance, performance in analysing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has shown excellent performance in analysing medical images.
However, datasets are difficult to obtain due privacy issues, standardization
problems, and lack of annotations. We address these problems by producing
realistic synthetic images using a combination of 3D technologies and
generative adversarial networks. We propose CUT-seg, a joint training where a
segmentation model and a generative model are jointly trained to produce
realistic images while learning to segment polyps. We take advantage of recent
one-sided translation models because they use significantly less memory,
allowing us to add a segmentation model in the training loop. CUT-seg performs
better, is computationally less expensive, and requires less real images than
other memory-intensive image translation approaches that require two stage
training. Promising results are achieved on five real polyp segmentation
datasets using only one real image and zero real annotations. As a part of this
study we release Synth-Colon, an entirely synthetic dataset that includes 20000
realistic colon images and additional details about depth and 3D geometry:
this https URL</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：On-Sensor Data Filtering using Neuromorphic Computing for High Energy  Physics Experiments</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11242</p>
  <p><b>作者</b>：Shruti R. Kulkarni,  Aaron Young,  Prasanna Date,  Narasinga Rao Miniskar,  Jeffrey S. Vetter,  Farah Fahim,  Benjamin Parpillon,  Jennet Dickinson,  Nhan Tran,  Jieun Yoo,  Corrinne Mills,  Morris Swartz,  Petar Maksimovic,  Catherine D. Schuman,  Alice Bean</p>
  <p><b>备注</b>：Manuscript accepted at ICONS'23</p>
  <p><b>关键词</b>：Luminosity Large Hadron, High Luminosity Large, high energy physics, Large Hadron, Luminosity Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work describes the investigation of neuromorphic computing-based spiking
neural network (SNN) models used to filter data from sensor electronics in high
energy physics experiments conducted at the High Luminosity Large Hadron
Collider. We present our approach for developing a compact neuromorphic model
that filters out the sensor data based on the particle's transverse momentum
with the goal of reducing the amount of data being sent to the downstream
electronics. The incoming charge waveforms are converted to streams of
binary-valued events, which are then processed by the SNN. We present our
insights on the various system design choices - from data encoding to optimal
hyperparameters of the training algorithm - for an accurate and compact SNN
optimized for hardware deployment. Our results show that an SNN trained with an
evolutionary algorithm and an optimized set of hyperparameters obtains a signal
efficiency of about 91% with nearly half as many parameters as a deep neural
network.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Jina Embeddings: A Novel Set of High-Performance Sentence Embedding  Models</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11224</p>
  <p><b>作者</b>：Michael Günther,  Louis Milliken,  Jonathan Geuter,  Georgios Mastrapas,  Bo Wang,  Han Xiao</p>
  <p><b>备注</b>：9 pages, 2 page appendix, EMNLP 2023 Industrial Track</p>
  <p><b>关键词</b>：high-performance sentence embedding, Jina Embeddings constitutes, sentence embedding models, embedding models adept, numerical representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jina Embeddings constitutes a set of high-performance sentence embedding
models adept at translating various textual inputs into numerical
representations, thereby capturing the semantic essence of the text. While
these models are not exclusively designed for text generation, they excel in
applications such as dense retrieval and semantic textual similarity. This
paper details the development of Jina Embeddings, starting with the creation of
a high-quality pairwise and triplet dataset. It underlines the crucial role of
data cleaning in dataset preparation, gives in-depth insights into the model
training process, and concludes with a comprehensive performance evaluation
using the Massive Textual Embedding Benchmark (MTEB).</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Towards Ontologically Grounded and Language-Agnostic Knowledge Graphs</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11206</p>
  <p><b>作者</b>：Walid S. Saba</p>
  <p><b>备注</b>：7 pages, conference paper</p>
  <p><b>关键词</b>：Knowledge graphs, recommendation engines, question-answering systems, standard technology, factual information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graphs (KGs) have become the standard technology for the
representation of factual information in applications such as recommendation
engines, search, and question-answering systems. However, the continual
updating of KGs, as well as the integration of KGs from different domains and
KGs in different languages, remains to be a major challenge. What we suggest
here is that by a reification of abstract objects and by acknowledging the
ontological distinction between concepts and types, we arrive at an
ontologically grounded and language-agnostic representation that can alleviate
the difficulties in KG integration.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Exploring reinforcement learning techniques for discrete and continuous  control tasks in the MuJoCo environment</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11166</p>
  <p><b>作者</b>：Vaddadi Sai Rahul,  Debajyoti Chakraborty</p>
  <p><b>备注</b>：Released @ Dec 2021. For associated project files, see this https URL</p>
  <p><b>关键词</b>：fast physics simulator, action space, observation space, continuous control environment, physics simulator</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We leverage the fast physics simulator, MuJoCo to run tasks in a continuous
control environment and reveal details like the observation space, action
space, rewards, etc. for each task. We benchmark value-based methods for
continuous control by comparing Q-learning and SARSA through a discretization
approach, and using them as baselines, progressively moving into one of the
state-of-the-art deep policy gradient method DDPG. Over a large number of
episodes, Qlearning outscored SARSA, but DDPG outperformed both in a small
number of episodes. Lastly, we also fine-tuned the model hyper-parameters
expecting to squeeze more performance but using lesser time and resources. We
anticipated that the new design for DDPG would vastly improve performance, yet
after only a few episodes, we were able to achieve decent average rewards. We
expect to improve the performance provided adequate time and computational
resources.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Of Models and Tin Men -- a behavioural economics study of  principal-agent problems in AI alignment using large-language models</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11137</p>
  <p><b>作者</b>：Steve Phelps,  Rebecca Ranson</p>
  <p><b>备注</b>：11 pages, 7 figures. For code see this https URL</p>
  <p><b>关键词</b>：resulting internal utility, risks arise solely, utility function intended, internal utility function, utility function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI Alignment is often presented as an interaction between a single designer
and an artificial agent in which the designer attempts to ensure the agent's
behavior is consistent with its purpose, and risks arise solely because of
conflicts caused by inadvertent misalignment between the utility function
intended by the designer and the resulting internal utility function of the
agent. With the advent of agents instantiated with large-language models
(LLMs), which are typically pre-trained, we argue this does not capture the
essential aspects of AI safety because in the real world there is not a
one-to-one correspondence between designer and agent, and the many agents, both
artificial and human, have heterogeneous values. Therefore, there is an
economic aspect to AI safety and the principal-agent problem is likely to
arise. In a principal-agent problem conflict arises because of information
asymmetry together with inherent misalignment between the utility of the agent
and its principal, and this inherent misalignment cannot be overcome by
coercing the agent into adopting a desired utility function through training.
We argue the assumptions underlying principal-agent problems are crucial to
capturing the essence of safety problems involving pre-trained AI models in
real-world situations. Taking an empirical approach to AI safety, we
investigate how GPT models respond in principal-agent conflicts. We find that
agents based on both GPT-3.5 and GPT-4 override their principal's objectives in
a simple online shopping task, showing clear evidence of principal-agent
conflict. Surprisingly, the earlier GPT-3.5 model exhibits more nuanced
behaviour in response to changes in information asymmetry, whereas the later
GPT-4 model is more rigid in adhering to its prior alignment. Our results
highlight the importance of incorporating principles from economics into the
alignment process.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Approximate Computing Survey, Part II: Application-Specific &  Architectural Approximation Techniques and Applications</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11128</p>
  <p><b>作者</b>：Vasileios Leon,  Muhammad Abdullah Hanif,  Giorgos Armeniakos,  Xun Jiao,  Muhammad Shafique,  Kiamal Pekmestzi,  Dimitrios Soudris</p>
  <p><b>备注</b>：Under Review at ACM Computing Surveys</p>
  <p><b>关键词</b>：Digital Signal Processing, Artificial Intelligence, Signal Processing, Digital Signal, domains such Artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenging deployment of compute-intensive applications from domains
such Artificial Intelligence (AI) and Digital Signal Processing (DSP), forces
the community of computing systems to explore new design approaches.
Approximate Computing appears as an emerging solution, allowing to tune the
quality of results in the design of a system in order to improve the energy
efficiency and/or performance. This radical paradigm shift has attracted
interest from both academia and industry, resulting in significant research on
approximation techniques and methodologies at different design layers (from
system down to integrated circuits). Motivated by the wide appeal of
Approximate Computing over the last 10 years, we conduct a two-part survey to
cover key aspects (e.g., terminology and applications) and review the
state-of-the art approximation techniques from all layers of the traditional
computing stack. In Part II of our survey, we classify and present the
technical details of application-specific and architectural approximation
techniques, which both target the design of resource-efficient
processors/accelerators & systems. Moreover, we present a detailed analysis of
the application spectrum of Approximate Computing and discuss open challenges
and future directions.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Technical Challenges of Deploying Reinforcement Learning Agents for Game  Testing in AAA Games</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11105</p>
  <p><b>作者</b>：Jonas Gillberg,  Joakim Bergdahl,  Alessandro Sestini,  Andrew Eakins,  Linus Gisslen</p>
  <p><b>备注</b>：8 pages, 5 figures</p>
  <p><b>关键词</b>：complex software systems, hard problem, large and complex, complex software, fundamentally a hard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Going from research to production, especially for large and complex software
systems, is fundamentally a hard problem. In large-scale game production, one
of the main reasons is that the development environment can be very different
from the final product. In this technical paper we describe an effort to add an
experimental reinforcement learning system to an existing automated game
testing solution based on scripted bots in order to increase its capacity. We
report on how this reinforcement learning system was integrated with the aim to
increase test coverage similar to [1] in a set of AAA games including
Battlefield 2042 and Dead Space (2023). The aim of this technical paper is to
show a use-case of leveraging reinforcement learning in game production and
cover some of the largest time sinks anyone who wants to make the same journey
for their game may encounter. Furthermore, to help the game industry to adopt
this technology faster, we propose a few research directions that we believe
will be valuable and necessary for making machine learning, and especially
reinforcement learning, an effective tool in game production.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Probabilistic Modeling of Inter- and Intra-observer Variability in  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11397</p>
  <p><b>作者</b>：Arne Schmidt,  Pablo Morales-Álvarez,  Rafael Molina</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：challenging task, due to inter, intra-observer variability, iNtra-Observer variation NetwOrk, called Probabilistic Inter-Observer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image segmentation is a challenging task, particularly due to inter-
and intra-observer variability, even between medical experts. In this paper, we
propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer
variation NetwOrk (Pionono). It captures the labeling behavior of each rater
with a multidimensional probability distribution and integrates this
information with the feature maps of the image to produce probabilistic
segmentation predictions. The model is optimized by variational inference and
can be trained end-to-end. It outperforms state-of-the-art models such as
STAPLE, Probabilistic U-Net, and models based on confusion matrices.
Additionally, Pionono predicts multiple coherent segmentation maps that mimic
the rater's expert opinion, which provides additional valuable information for
the diagnostic process. Experiments on real-world cancer segmentation datasets
demonstrate the high accuracy and efficiency of Pionono, making it a powerful
tool for medical image analysis.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Analysis of Elephant Movement in Sub-Saharan Africa: Ecological,  Climatic, and Conservation Perspectives</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11325</p>
  <p><b>作者</b>：Matthew Hines,  Gregory Glatzer,  Shreya Ghosh,  Prasenjit Mitra</p>
  <p><b>备注</b>：11 pages, 17 figures, Accepted in ACM SIGCAS SIGCHI Conference on Computing and Sustainable Societies (COMPASS 2023)</p>
  <p><b>关键词</b>：environment has profound, profound implications, Sub-Saharan Africa, elephant, conservation strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The interaction between elephants and their environment has profound
implications for both ecology and conservation strategies. This study presents
an analytical approach to decipher the intricate patterns of elephant movement
in Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal
variations and rainfall patterns. Despite the complexities surrounding these
influential factors, our analysis provides a holistic view of elephant
migratory behavior in the context of the dynamic African landscape. Our
comprehensive approach enables us to predict the potential impact of these
ecological determinants on elephant migration, a critical step in establishing
informed conservation strategies. This projection is particularly crucial given
the impacts of global climate change on seasonal and rainfall patterns, which
could substantially influence elephant movements in the future. The findings of
our work aim to not only advance the understanding of movement ecology but also
foster a sustainable coexistence of humans and elephants in Sub-Saharan Africa.
By predicting potential elephant routes, our work can inform strategies to
minimize human-elephant conflict, effectively manage land use, and enhance
anti-poaching efforts. This research underscores the importance of integrating
movement ecology and climatic variables for effective wildlife management and
conservation planning.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Contrastive Graph Pooling for Explainable Classification of Brain  Networks</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11133</p>
  <p><b>作者</b>：Jiaxing Xu,  Qingtian Bian,  Xinhang Li,  Aihu Zhang,  Yiping Ke,  Miao Qiao,  Wei Zhang,  Wei Khang Jeremy Sim,  Balázs Gulyás</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Functional magnetic resonance, magnetic resonance imaging, measure neural activation, Functional magnetic, resonance imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Functional magnetic resonance imaging (fMRI) is a commonly used technique to
measure neural activation. Its application has been particularly important in
identifying underlying neurodegenerative conditions such as Parkinson's,
Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a
graph and extracts features by graph neural networks (GNNs). However, the
unique characteristics of fMRI data require a special design of GNN. Tailoring
GNN to generate effective and domain-explainable features remains challenging.
In this paper, we propose a contrastive dual-attention block and a
differentiable graph pooling method called ContrastPool to better utilize GNN
for brain networks, meeting fMRI-specific requirements. We apply our method to
5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its
superiority over state-of-the-art baselines. Our case study confirms that the
patterns extracted by our method match the domain knowledge in neuroscience
literature, and disclose direct and interesting insights. Our contributions
underscore the potential of ContrastPool for advancing the understanding of
brain networks and neurodegenerative conditions.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Nature of Intelligence</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11114</p>
  <p><b>作者</b>：Barco Jie You</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligence, human brain, human, human intelligence, entropy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human brain is the substrate for human intelligence. By simulating the
human brain, artificial intelligence builds computational models that have
learning capabilities and perform intelligent tasks approaching the human
level. Deep neural networks consist of multiple computation layers to learn
representations of data and improve the state-of-the-art in many recognition
domains. However, the essence of intelligence commonly represented by both
humans and AI is unknown. Here, we show that the nature of intelligence is a
series of mathematically functional processes that minimize system entropy by
establishing functional relationships between datasets over space and time.
Humans and AI have achieved intelligence by implementing these entropy-reducing
processes in a reinforced manner that consumes energy. With this hypothesis, we
establish mathematical models of language, unconsciousness and consciousness,
predicting the evidence to be found by neuroscience and achieved by AI
engineering. Furthermore, a conclusion is made that the total entropy of the
universe is conservative, and intelligence counters the spontaneous processes
to decrease entropy by physically or informationally connecting datasets that
originally exist in the universe but are separated across space and time. This
essay should be a starting point for a deeper understanding of the universe and
us as human beings and for achieving sophisticated AI models that are
tantamount to human intelligence or even superior. Furthermore, this essay
argues that more advanced intelligence than humans should exist if only it
reduces entropy in a more efficient energy-consuming way.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Solving multiphysics-based inverse problems with learned surrogates and  constraints</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2307.11099</p>
  <p><b>作者</b>：Ziyi Yin,  Rafael Orozco,  Mathias Louboutin,  Felix J. Herrmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Solving multiphysics-based inverse, multiphysics-based inverse problems, Solving multiphysics-based, simulate numerically, multiphysics-based inverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving multiphysics-based inverse problems for geological carbon storage
monitoring can be challenging when multimodal time-lapse data are expensive to
collect and costly to simulate numerically. We overcome these challenges by
combining computationally cheap learned surrogates with learned constraints.
Not only does this combination lead to vastly improved inversions for the
important fluid-flow property, permeability, it also provides a natural
platform for inverting multimodal data including well measurements and
active-source time-lapse seismic data. By adding a learned constraint, we
arrive at a computationally feasible inversion approach that remains accurate.
This is accomplished by including a trained deep neural network, known as a
normalizing flow, which forces the model iterates to remain in-distribution,
thereby safeguarding the accuracy of trained Fourier neural operators that act
as surrogates for the computationally expensive multiphase flow simulations
involving partial differential equation solves. By means of carefully selected
experiments, centered around the problem of geological carbon storage, we
demonstrate the efficacy of the proposed constrained optimization method on two
different data modalities, namely time-lapse well and time-lapse seismic data.
While permeability inversions from both these two modalities have their pluses
and minuses, their joint inversion benefits from either, yielding valuable
superior permeability inversions and CO2 plume predictions near, and far away,
from the monitoring wells.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【梳理】陆奇最新演讲实录：我的大模型世界观</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-25)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-07-25)"/></a><div class="content"><a class="title" href="/2023/07/25/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-07-25)">Arxiv每日速递(2023-07-25)</a><time datetime="2023-07-25T00:45:04.399Z" title="发表于 2023-07-25 08:45:04">2023-07-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【梳理】陆奇最新演讲实录：我的大模型世界观"/></a><div class="content"><a class="title" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观">【梳理】陆奇最新演讲实录：我的大模型世界观</a><time datetime="2023-05-07T11:07:45.000Z" title="发表于 2023-05-07 19:07:45">2023-05-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)"><img src="https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="变分自编码器(Variational AutoEncoder)"/></a><div class="content"><a class="title" href="/2023/05/05/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8(Variational%20AutoEncoder).html" title="变分自编码器(Variational AutoEncoder)">变分自编码器(Variational AutoEncoder)</a><time datetime="2023-05-05T11:28:37.000Z" title="发表于 2023-05-05 19:28:37">2023-05-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="transformers.generation.GenerationMixin"/></a><div class="content"><a class="title" href="/2023/04/08/transformers.generation.GenerationMixin.html" title="transformers.generation.GenerationMixin">transformers.generation.GenerationMixin</a><time datetime="2023-04-08T13:42:45.000Z" title="发表于 2023-04-08 21:42:45">2023-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范"><img src="https://openaicom.imgix.net/8d14e8f0-e267-4b8b-a9f2-a79120808f5a/chatgpt.jpg?auto=compress%2Cformat&amp;fit=min&amp;fm=jpg&amp;q=80&amp;rect=0%2C0%2C2048%2C2048&amp;w=3200" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【转载】ChatGPT 标注指南：任务、数据与规范"/></a><div class="content"><a class="title" href="/2023/03/27/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91ChatGPT%20%E6%A0%87%E6%B3%A8%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%BB%E5%8A%A1%E3%80%81%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%A7%84%E8%8C%83.html" title="【转载】ChatGPT 标注指南：任务、数据与规范">【转载】ChatGPT 标注指南：任务、数据与规范</a><time datetime="2023-03-27T14:35:45.000Z" title="发表于 2023-03-27 22:35:45">2023-03-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>