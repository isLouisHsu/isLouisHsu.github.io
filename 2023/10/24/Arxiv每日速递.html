<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-10-24) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新372篇论文，其中：  72篇计算机视觉（cs.CV） 108篇自然语言处理（cs.CL） 125篇机器学习（cs.LG） 118篇人工智能（cs.AI）  计算机视觉    1. 标题：Using Human-like Mechanism to Weake">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-10-24)">
<meta property="og:url" content="http://louishsu.xyz/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新372篇论文，其中：  72篇计算机视觉（cs.CV） 108篇自然语言处理（cs.CL） 125篇机器学习（cs.LG） 118篇人工智能（cs.AI）  计算机视觉    1. 标题：Using Human-like Mechanism to Weake">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-10-24T01:01:50.054Z">
<meta property="article:modified_time" content="2023-10-24T01:04:18.995Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-10-24 09:04:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-10-24)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-24T01:01:50.054Z" title="发表于 2023-10-24 09:01:50">2023-10-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-10-24T01:04:18.995Z" title="更新于 2023-10-24 09:04:18">2023-10-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">105.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>631分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新372篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">72篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">108篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">125篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">118篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Using Human-like Mechanism to Weaken Effect of Pre-training Weight Bias  in Face-Recognition Convolutional Neural Network</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13674</p>
  <p><b>作者</b>：Haojiang Ying,  Yi-Fan Li,  Yiyang Chen</p>
  <p><b>备注</b>：24 pages, 6 figures</p>
  <p><b>关键词</b>：Convolutional neural network, Convolutional neural, neural network, artificial intelligence, CNNs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural network (CNN), as an important model in artificial intelligence, has been widely used and studied in different disciplines. The computational mechanisms of CNNs are still not fully revealed due to the their complex nature. In this study, we focused on 4 extensively studied CNNs (AlexNet, VGG11, VGG13, and VGG16) which has been analyzed as human-like models by neuroscientists with ample evidence. We trained these CNNs to emotion valence classification task by transfer learning. Comparing their performance with human data, the data unveiled that these CNNs would partly perform as human does. We then update the object-based AlexNet using self-attention mechanism based on neuroscience and behavioral data. The updated FE-AlexNet outperformed all the other tested CNNs and closely resembles human perception. The results further unveil the computational mechanisms of these CNNs. Moreover, this study offers a new paradigm to better understand and improve CNN performance via human data.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot  Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13670</p>
  <p><b>作者</b>：Daiju Kanaoka,  Motoharu Sonogashira,  Hakaru Tamukoh,  Yasutomo Kawanishi</p>
  <p><b>备注</b>：Accepted by BMVC2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, recently made significant, made significant progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Novel view synthesis has recently made significant progress with the advent of Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims to achieve this task from only a few images by introducing a new loss function for unknown viewpoints with no input images. The loss function assumes that a pre-trained feature extractor should output the same feature even if input images are captured at different viewpoints since the images contain the same object. However, while that assumption is ideal, in reality, it is known that as viewpoints continuously change, also feature vectors continuously change. Thus, the assumption can harm training. To avoid this harmful training, we propose ManifoldNeRF, a method for supervising feature vectors at unknown viewpoints using interpolated features from neighboring known viewpoints. Since the method provides appropriate supervision for each unknown viewpoint by the interpolated features, the volume representation is learned better than DietNeRF. Experimental results show that the proposed method performs better than others in a complex scene. We also experimented with several subsets of viewpoints from a set of viewpoints and identified an effective set of viewpoints for real environments. This provided a basic policy of viewpoint patterns for real-world application. The code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Deep-Learning-based Change Detection with Spaceborne Hyperspectral  PRISMA data</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13627</p>
  <p><b>作者</b>：J.F. Amieva,  A. Austoni,  M.A. Brovelli,  L. Ansalone,  P. Naylor,  F. Serva,  B. Le Saux</p>
  <p><b>备注</b>：Accepted at Big Data from Space 2023 (BiDS); 4 pages, 4 figures</p>
  <p><b>关键词</b>：fine spectral resolution, rarely explored, Change detection, fine spectral, spectral resolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Change detection (CD) methods have been applied to optical data for decades, while the use of hyperspectral data with a fine spectral resolution has been rarely explored. CD is applied in several sectors, such as environmental monitoring and disaster management. Thanks to the PRecursore IperSpettrale della Missione operativA (PRISMA), hyperspectral-from-space CD is now possible. In this work, we apply standard and deep-learning (DL) CD methods to different targets, from natural to urban areas. We propose a pipeline starting from coregistration, followed by CD with a full-spectrum algorithm and by a DL network developed for optical data. We find that changes in vegetation and built environments are well captured. The spectral information is valuable to identify subtle changes and the DL methods are less affected by noise compared to the statistical method, but atmospheric effects and the lack of reliable ground truth represent a major challenge to hyperspectral CD.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：What you see is what you get: Experience ranking with deep neural  dataset-to-dataset similarity for topological localisation</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13622</p>
  <p><b>作者</b>：Matthew Gadd,  Benjamin Ramtoula,  Daniele De Martini,  Paul Newman</p>
  <p><b>备注</b>：18th International Symposium on Experimental Robotics (ISER 2023)</p>
  <p><b>关键词</b>：robust visual navigation, relevant visual memories, understanding a priori, efficient and robust, visual navigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recalling the most relevant visual memories for localisation or understanding a priori the likely outcome of localisation effort against a particular visual memory is useful for efficient and robust visual navigation. Solutions to this problem should be divorced from performance appraisal against ground truth - as this is not available at run-time - and should ideally be based on generalisable environmental observations. For this, we propose applying the recently developed Visual DNA as a highly scalable tool for comparing datasets of images - in this work, sequences of map and live experiences. In the case of localisation, important dataset differences impacting performance are modes of appearance change, including weather, lighting, and season. Specifically, for any deep architecture which is used for place recognition by matching feature volumes at a particular layer, we use distribution measures to compare neuron-wise activation statistics between live images and multiple previously recorded past experiences, with a potentially large seasonal (winter/summer) or time of day (day/night) shift. We find that differences in these statistics correlate to performance when localising using a past experience with the same appearance gap. We validate our approach over the Nordland cross-season dataset as well as data from Oxford's University Parks with lighting and mild seasonal change, showing excellent ability of our system to rank actual localisation performance across candidate experiences.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Semi-supervised multimodal coreference resolution in image narrations</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13619</p>
  <p><b>作者</b>：Arushi Goel,  Basura Fernando,  Frank Keller,  Hakan Bilen</p>
  <p><b>备注</b>：Long paper at EMNLP'23-Main</p>
  <p><b>关键词</b>：longer descriptive text, descriptive text, longer descriptive, narration is paired, study multimodal coreference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study multimodal coreference resolution, specifically where a longer descriptive text, i.e., a narration is paired with an image. This poses significant challenges due to fine-grained image-text alignment, inherent ambiguity present in narrative language, and unavailability of large annotated training sets. To tackle these challenges, we present a data efficient semi-supervised approach that utilizes image-narration pairs to resolve coreferences and narrative grounding in a multimodal context. Our approach incorporates losses for both labeled and unlabeled data within a cross-modal framework. Our evaluation shows that the proposed approach outperforms strong baselines both quantitatively and qualitatively, for the tasks of coreference resolution and narrative grounding.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13605</p>
  <p><b>作者</b>：Xinyu Zhang,  Li Wang,  Zhiqiang Jiang,  Kun Dai,  Tao Xie,  Lei Yang,  Wenhao Yu,  Yang Shen,  Jun Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision tasks, Reconciliatory Transformer, vision tasks, structure from motion, Local Feature Matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Local Feature Matching, an essential component of several computer vision tasks (e.g., structure from motion and visual localization), has been effectively settled by Transformer-based methods. However, these methods only integrate long-range context information among keypoints with a fixed receptive field, which constrains the network from reconciling the importance of features with different receptive fields to realize complete image perception, hence limiting the matching accuracy. In addition, these methods utilize a conventional handcrafted encoding approach to integrate the positional information of keypoints into the visual descriptors, which limits the capability of the network to extract reliable positional encoding message. In this study, we propose Feature Matching with Reconciliatory Transformer (FMRT), a novel Transformer-based detector-free method that reconciles different features with multiple receptive fields adaptively and utilizes parallel networks to realize reliable positional encoding. Specifically, FMRT proposes a dedicated Reconciliatory Transformer (RecFormer) that consists of a Global Perception Attention Layer (GPAL) to extract visual descriptors with different receptive fields and integrate global context information under various scales, Perception Weight Layer (PWL) to measure the importance of various receptive fields adaptively, and Local Perception Feed-forward Network (LPFFN) to extract deep aggregated multi-scale local feature representation. Extensive experiments demonstrate that FMRT yields extraordinary performance on multiple benchmarks, including pose estimation, visual localization, homography estimation, and image matching.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Longer-range Contextualized Masked Autoencoder</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13593</p>
  <p><b>作者</b>：Taekyung Kim,  Sanghyuk Chun,  Byeongho Heo,  Dongyoon Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Masked image modeling, MIM pre-training, MIM pre-training facilitates, image modeling, Contextualized Masked Autoencoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Masked image modeling (MIM) has emerged as a promising self-supervised learning (SSL) strategy. The MIM pre-training facilitates learning powerful representations using an encoder-decoder framework by randomly masking some input pixels and reconstructing the masked pixels from the remaining ones. However, as the encoder is trained with partial pixels, the MIM pre-training can suffer from a low capability of understanding long-range dependency. This limitation may hinder its capability to fully understand multiple-range dependencies, resulting in narrow highlighted regions in the attention map that may incur accuracy drops. To mitigate the limitation, We propose a self-supervised learning framework, named Longer-range Contextualized Masked Autoencoder (LC-MAE). LC-MAE effectively leverages a global context understanding of visual representations while simultaneously reducing the spatial redundancy of input at the same time. Our method steers the encoder to learn from entire pixels in multiple views while also learning local representation from sparse pixels. As a result, LC-MAE learns more discriminative representations, leading to a performance improvement of achieving 84.2% top-1 accuracy with ViT-B on ImageNet-1K with 0.6%p gain. We attribute the success to the enhanced pre-training method, as evidenced by the singular value spectrum and attention analyses. Finally, LC-MAE achieves significant performance gains at the downstream semantic segmentation and fine-grained visual classification tasks; and on diverse robust evaluation metrics. Our code will be publicly available.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：POTLoc: Pseudo-Label Oriented Transformer for Point-Supervised Temporal  Action Localization</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13585</p>
  <p><b>作者</b>：Elahe Vahdani,  Yingli Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：temporal action detection, action, training set, tackles the challenge, single frame</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper tackles the challenge of point-supervised temporal action detection, wherein only a single frame is annotated for each action instance in the training set. Most of the current methods, hindered by the sparse nature of annotated points, struggle to effectively represent the continuous structure of actions or the inherent temporal and semantic dependencies within action instances. Consequently, these methods frequently learn merely the most distinctive segments of actions, leading to the creation of incomplete action proposals. This paper proposes POTLoc, a Pseudo-label Oriented Transformer for weakly-supervised Action Localization utilizing only point-level annotation. POTLoc is designed to identify and track continuous action structures via a self-training strategy. The base model begins by generating action proposals solely with point-level supervision. These proposals undergo refinement and regression to enhance the precision of the estimated action boundaries, which subsequently results in the production of `pseudo-labels' to serve as supplementary supervisory signals. The architecture of the model integrates a transformer with a temporal feature pyramid to capture video snippet dependencies and model actions of varying duration. The pseudo-labels, providing information about the coarse locations and boundaries of actions, assist in guiding the transformer for enhanced learning of action dynamics. POTLoc outperforms the state-of-the-art point-supervised methods on THUMOS'14 and ActivityNet-v1.2 datasets, showing a significant improvement of 5% average mAP on the former.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Boosting Generalization with Adaptive Style Techniques for Fingerprint  Liveness Detection</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13573</p>
  <p><b>作者</b>：Kexin Zhu,  Bo Lin,  Yang Qiu,  Adam Yule,  Yao Tang,  Jiajun Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Fingerprint Representation Challenge, feature extraction technique, liveness feature extraction, high-performance fingerprint liveness, fingerprint liveness feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a high-performance fingerprint liveness feature extraction technique that secured first place in LivDet 2023 Fingerprint Representation Challenge. Additionally, we developed a practical fingerprint recognition system with 94.68% accuracy, earning second place in LivDet 2023 Liveness Detection in Action. By investigating various methods, particularly style transfer, we demonstrate improvements in accuracy and generalization when faced with limited training data. As a result, our approach achieved state-of-the-art performance in LivDet 2023 Challenges.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：A Simple Baseline for Knowledge-Based Visual Question Answering</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13570</p>
  <p><b>作者</b>：Alexandros Xenos,  Themos Stafylakis,  Ioannis Patras,  Georgios Tzimiropoulos</p>
  <p><b>备注</b>：Accepted at EMNLP 2023 (camera-ready version)</p>
  <p><b>关键词</b>：Visual Question Answering, Knowledge-Based Visual Question, Question Answering, Knowledge-Based Visual, Visual Question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is on the problem of Knowledge-Based Visual Question Answering (KB-VQA). Recent works have emphasized the significance of incorporating both explicit (through external databases) and implicit (through LLMs) knowledge to answer questions requiring external knowledge effectively. A common limitation of such approaches is that they consist of relatively complicated pipelines and often heavily rely on accessing GPT-3 API. Our main contribution in this paper is to propose a much simpler and readily reproducible pipeline which, in a nutshell, is based on efficient in-context learning by prompting LLaMA (1 and 2) using question-informative captions as contextual information. Contrary to recent approaches, our method is training-free, does not require access to external databases or APIs, and yet achieves state-of-the-art accuracy on the OK-VQA and A-OK-VQA datasets. Finally, we perform several ablation studies to understand important aspects of our method. Our code is publicly available at this https URL</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：ROSS: Radar Off-road Semantic Segmentation</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13551</p>
  <p><b>作者</b>：Peng Jiang,  Srikanth Saripalli</p>
  <p><b>备注</b>：10 pages, 6 figures, accepted by the 18th International Symposium on Experimental Robotics (ISER 2023)</p>
  <p><b>关键词</b>：surroundings becomes essential, off-road environments increases, demand for autonomous, effective solutions, solutions to understand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the demand for autonomous navigation in off-road environments increases, the need for effective solutions to understand these surroundings becomes essential. In this study, we confront the inherent complexities of semantic segmentation in RADAR data for off-road scenarios. We present a novel pipeline that utilizes LIDAR data and an existing annotated off-road LIDAR dataset for generating RADAR labels, in which the RADAR data are represented as images. Validated with real-world datasets, our pragmatic approach underscores the potential of RADAR technology for navigation applications in off-road environments.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：ScaleLong: Towards More Stable Training of Diffusion Model via Scaling  Network Long Skip Connection</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13545</p>
  <p><b>作者</b>：Zhongzhan Huang,  Pan Zhou,  Shuicheng Yan,  Liang Lin</p>
  <p><b>备注</b>：accepted by NeurIPS 2023</p>
  <p><b>关键词</b>：long skip connects, aggregate long-distant information, connect distant network, diffusion models, popular network backbone</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In diffusion models, UNet is the most popular network backbone, since its long skip connects (LSCs) to connect distant network blocks can aggregate long-distant information and alleviate vanishing gradient. Unfortunately, UNet often suffers from unstable training in diffusion models which can be alleviated by scaling its LSC coefficients smaller. However, theoretical understandings of the instability of UNet in diffusion models and also the performance improvement of LSC scaling remain absent yet. To solve this issue, we theoretically show that the coefficients of LSCs in UNet have big effects on the stableness of the forward and backward propagation and robustness of UNet. Specifically, the hidden feature and gradient of UNet at any layer can oscillate and their oscillation ranges are actually large which explains the instability of UNet training. Moreover, UNet is also provably sensitive to perturbed input, and predicts an output distant from the desired output, yielding oscillatory loss and thus oscillatory gradient. Besides, we also observe the theoretical benefits of the LSC coefficient scaling of UNet in the stableness of hidden features and gradient and also robustness. Finally, inspired by our theory, we propose an effective coefficient scaling framework ScaleLong that scales the coefficients of LSC in UNet and better improves the training stability of UNet. Experimental results on four famous datasets show that our methods are superior to stabilize training and yield about 1.5x training acceleration on different diffusion models with UNet or UViT backbones. Code: this https URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Technical Report for ICCV 2023 Visual Continual Learning Challenge:  Continuous Test-time Adaptation for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13533</p>
  <p><b>作者</b>：Damian Sójka,  Yuyang Liu,  Dipam Goswami,  Sebastian Cygert,  Bartłomiej Twardowski,  Joost van de Weijer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic segmentation task, segmentation task, semantic segmentation, TTA methods, source model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT dataset, in which there are only six sequences that start and end with the source domain. We conduct an analysis specifically on those sequences. Ground truth data for test split, on which the developed TTA methods are evaluated for leader board ranking, are not publicly available.
The proposed solution secured a 3rd place in a challenge and received an innovation award. Contrary to the solutions that scored better, we did not use any external pretrained models or specialized data augmentations, to keep the solutions as general as possible. We have focused on analyzing the distributional shift and developing a method that could adapt to changing data dynamics and generalize across different scenarios.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：RaceLens: A Machine Intelligence-Based Application for Racing Photo  Analysis</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13515</p>
  <p><b>作者</b>：Andrei Boiarov,  Dmitry Bleklov,  Pavlo Bredikhin,  Nikita Koritsky,  Sergey Ulasen</p>
  <p><b>备注</b>：Accepted at ISACE 2023 Workshop</p>
  <p><b>关键词</b>：utilizing advanced deep, advanced deep learning, computer vision models, paper presents RaceLens, application utilizing advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents RaceLens, a novel application utilizing advanced deep learning and computer vision models for comprehensive analysis of racing photos. The developed models have demonstrated their efficiency in a wide array of tasks, including detecting racing cars, recognizing car numbers, detecting and quantifying car details, and recognizing car orientations. We discuss the process of collecting a robust dataset necessary for training our models, and describe an approach we have designed to augment and improve this dataset continually. Our method leverages a feedback loop for continuous model improvement, thus enhancing the performance and accuracy of RaceLens over time. A significant part of our study is dedicated to illustrating the practical application of RaceLens, focusing on its successful deployment by NASCAR teams over four seasons. We provide a comprehensive evaluation of our system's performance and its direct impact on the team's strategic decisions and performance metrics. The results underscore the transformative potential of machine intelligence in the competitive and dynamic world of car racing, setting a precedent for future applications.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Application of deep learning for livestock behaviour recognition: A  systematic literature review</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13483</p>
  <p><b>作者</b>：Ali Rohan,  Muhammad Saad Rafaq,  Md. Junayed Hasan,  Furqan Asghar,  Ali Kashif Bashir,  Tania Dottorini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task performed manually, labor-intensive task performed, performed manually, welfare monitoring, monitoring has traditionally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Livestock health and welfare monitoring has traditionally been a labor-intensive task performed manually. Recent advances have led to the adoption of AI and computer vision techniques, particularly deep learning models, as decision-making tools within the livestock industry. These models have been employed for tasks like animal identification, tracking, body part recognition, and species classification. In the past decade, there has been a growing interest in using these models to explore the connection between livestock behaviour and health issues. While previous review studies have been rather generic, there is currently no review study specifically focusing on DL for livestock behaviour recognition. Hence, this systematic literature review (SLR) was conducted. The SLR involved an initial search across electronic databases, resulting in 1101 publications. After applying defined selection criteria, 126 publications were shortlisted. These publications were further filtered based on quality criteria, resulting in the selection of 44 high-quality primary studies. These studies were analysed to address the research questions. The results showed that DL successfully addressed 13 behaviour recognition problems encompassing 44 different behaviour classes. A variety of DL models and networks were employed, with CNN, Faster R-CNN, YOLOv5, and YOLOv4 being among the most common models, and VGG16, CSPDarknet53, GoogLeNet, ResNet101, and ResNet50 being popular networks. Performance evaluation involved ten different matrices, with precision and accuracy being the most frequently used. Primary studies identified challenges, including occlusion, adhesion, data imbalance, and the complexities of the livestock environment. The SLR study also discussed potential solutions and research directions to facilitate the development of autonomous livestock behaviour recognition systems.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：A review of individual tree crown detection and delineation from optical  remote sensing images</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13481</p>
  <p><b>作者</b>：Juepeng Zheng,  Shuai Yuan,  Weijia Li,  Haohuan Fu,  Le Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high spatial resolution, spatial resolution multispectral, optical remote sensing, resolution multispectral images, Individual Tree Crown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Powered by the advances of optical remote sensing sensors, the production of very high spatial resolution multispectral images provides great potential for achieving cost-efficient and high-accuracy forest inventory and analysis in an automated way. Lots of studies that aim at providing an inventory to the level of each individual tree have generated a variety of methods for Individual Tree Crown Detection and Delineation (ITCD). This review covers ITCD methods for detecting and delineating individual tree crowns, and systematically reviews the past and present of ITCD-related researches applied to the optical remote sensing images. With the goal to provide a clear knowledge map of existing ITCD efforts, we conduct a comprehensive review of recent ITCD papers to build a meta-data analysis, including the algorithm, the study site, the tree species, the sensor type, the evaluation method, etc. We categorize the reviewed methods into three classes: (1) traditional image processing methods (such as local maximum filtering, image segmentation, etc.); (2) traditional machine learning methods (such as random forest, decision tree, etc.); and (3) deep learning based methods. With the deep learning-oriented approaches contributing a majority of the papers, we further discuss the deep learning-based methods as semantic segmentation and object detection methods. In addition, we discuss four ITCD-related issues to further comprehend the ITCD domain using optical remote sensing data, such as comparisons between multi-sensor based data and optical data in ITCD domain, comparisons among different algorithms and different ITCD tasks, etc. Finally, this review proposes some ITCD-related applications and a few exciting prospects and potential hot topics in future ITCD research.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Segment, Select, Correct: A Framework for Weakly-Supervised Referring  Segmentation</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13479</p>
  <p><b>作者</b>：Francisco Eiras,  Kemal Oksuz,  Adel Bibi,  Philip H.S. Torr,  Puneet K. Dokania</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Referring Image Segmentation, natural language sentences, Image Segmentation, Referring Image, language sentences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Referring Image Segmentation (RIS) - the problem of identifying objects in images through natural language sentences - is a challenging task currently mostly solved through supervised learning. However, while collecting referred annotation masks is a time-consuming process, the few existing weakly-supervised and zero-shot approaches fall significantly short in performance compared to fully-supervised learning ones. To bridge the performance gap without mask annotations, we propose a novel weakly-supervised framework that tackles RIS by decomposing it into three steps: obtaining instance masks for the object mentioned in the referencing instruction (segment), using zero-shot learning to select a potentially correct mask for the given instruction (select), and bootstrapping a model which allows for fixing the mistakes of zero-shot selection (correct). In our experiments, using only the first two steps (zero-shot segment and select) outperforms other zero-shot baselines by as much as 19%, while our full method improves upon this much stronger baseline and sets the new state-of-the-art for weakly-supervised RIS, reducing the gap between the weakly-supervised and fully-supervised methods in some cases from around 33% to as little as 14%. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Benchmarking Sequential Visual Input Reasoning and Prediction in  Multimodal Large Language Models</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13473</p>
  <p><b>作者</b>：Mingwei Zhu,  Leigang Sha,  Yu Shu,  Kangjia Zhao,  Tiancheng Zhao,  Jianwei Yin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, reasoning remain under-explored, predictive reasoning remain, remain under-explored, shown great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal large language models (MLLMs) have shown great potential in perception and interpretation tasks, but their capabilities in predictive reasoning remain under-explored. To address this gap, we introduce a novel benchmark that assesses the predictive reasoning capabilities of MLLMs across diverse scenarios. Our benchmark targets three important domains: abstract pattern reasoning, human activity prediction, and physical interaction prediction. We further develop three evaluation methods powered by large language model to robustly quantify a model's performance in predicting and reasoning the future based on multi-visual context. Empirical experiments confirm the soundness of the proposed benchmark and evaluation methods via rigorous testing and reveal pros and cons of current popular MLLMs in the task of predictive reasoning. Lastly, our proposed benchmark provides a standardized evaluation framework for MLLMs and can facilitate the development of more advanced models that can reason and predict over complex long sequence of multimodal input.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Two-Stage Triplet Loss Training with Curriculum Augmentation for  Audio-Visual Retrieval</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13451</p>
  <p><b>作者</b>：Donghuo Zeng,  Kazushi Ikeda</p>
  <p><b>备注</b>：8 pages, 6 figures</p>
  <p><b>关键词</b>：triple loss optimization, learn robust embedding, retrieval model leverages, hard triples, learn robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The cross-modal retrieval model leverages the potential of triple loss optimization to learn robust embedding spaces. However, existing methods often train these models in a singular pass, overlooking the distinction between semi-hard and hard triples in the optimization process. The oversight of not distinguishing between semi-hard and hard triples leads to suboptimal model performance. In this paper, we introduce a novel approach rooted in curriculum learning to address this problem. We propose a two-stage training paradigm that guides the model's learning process from semi-hard to hard triplets. In the first stage, the model is trained with a set of semi-hard triplets, starting from a low-loss base. Subsequently, in the second stage, we augment the embeddings using an interpolation technique. This process identifies potential hard negatives, alleviating issues arising from high-loss functions due to a scarcity of hard triples. Our approach then applies hard triplet mining in the augmented embedding space to further optimize the model. Extensive experimental results conducted on two audio-visual datasets show a significant improvement of approximately 9.8% in terms of average Mean Average Precision (MAP) over the current state-of-the-art method, MSNSCA, for the Audio-Visual Cross-Modal Retrieval (AV-CMR) task on the AVE dataset, indicating the effectiveness of our proposed method.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13447</p>
  <p><b>作者</b>：Siyu Zhang,  Yeming Chen,  Sirui Cheng,  Yaoru Sun,  Jun Yang,  Lizhi Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：good alignment strategy, alignment strategy, vision and language, lies in establishing, establishing a good</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of constituent visual patterns, and captures multiscale features by progressively merging adjacent superpixels as graph nodes. Moreover, we predict the differences between adjacent nodes through the graph structure, facilitating key information aggregation of graph nodes to reason actual semantic relations. Afterward, we design a multi-level fusion rule in a bottom-up manner to avoid understanding deviation by learning complementary spatial information at different regional scales. Our proposed method can be well applied to multiple downstream task learning. Extensive experiments demonstrate that our method is competitive with other state-of-the-art methods in visual reasoning. Our code will be released upon publication.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Definition-independent Formalization of Soundscapes: Towards a Formal  Methodology</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13404</p>
  <p><b>作者</b>：Mikel D. Jedrusiak,  Thomas Harweg,  Timo Haselhoff,  Bryce T. Lawrence,  Susanne Moebus,  Frank Weichert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：studied by researchers, underlying soundscape definition, approaches, soundscape definition, soundscape components</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Soundscapes have been studied by researchers from various disciplines, each with different perspectives, goals, approaches, and terminologies. Accordingly, depending on the field, the concept of a soundscape's components changes, consequently changing the basic definition. This results in complicating interdisciplinary communication and comparison of results. Especially when soundscape-unrelated research areas are involved. For this reason, we present a potential formalization that is independent of the underlying soundscape definition, with the goal of being able to capture the heterogeneous structure of the data as well as the different ideologies in one model. In an exemplary analysis of frequency correlation matrices for land use type detection as an alternative to features like MFCCs, we show a practical application of our presented formalization.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：OpenAnnotate3D: Open-Vocabulary Auto-Labeling System for Multi-modal 3D  Data</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13398</p>
  <p><b>作者</b>：Yijie Zhou,  Likun Cai,  Xianhui Cheng,  Zhongxue Gan,  Xiangyang Xue,  Wenchao Ding</p>
  <p><b>备注</b>：The source code will be released at this https URL</p>
  <p><b>关键词</b>：automatic annotating functions, real-world AI-driven applications, automatic annotating, AI-driven applications, era of big</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of big data and large models, automatic annotating functions for multi-modal data are of great significance for real-world AI-driven applications, such as autonomous driving and embodied AI. Unlike traditional closed-set annotation, open-vocabulary annotation is essential to achieve human-level cognition capability. However, there are few open-vocabulary auto-labeling systems for multi-modal 3D data. In this paper, we introduce OpenAnnotate3D, an open-source open-vocabulary auto-labeling system that can automatically generate 2D masks, 3D masks, and 3D bounding box annotations for vision and point cloud data. Our system integrates the chain-of-thought capabilities of Large Language Models (LLMs) and the cross-modality capabilities of vision-language models (VLMs). To the best of our knowledge, OpenAnnotate3D is one of the pioneering works for open-vocabulary multi-modal 3D auto-labeling. We conduct comprehensive evaluations on both public and in-house real-world datasets, which demonstrate that the system significantly improves annotation efficiency compared to manual annotation while providing accurate open-vocabulary auto-annotating results.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD  Map Construction</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13378</p>
  <p><b>作者</b>：Jingyi Yu,  Zizhao Zhang,  Shengfu Xia,  Jizhang Sang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：on-board camera sensors, long-range vectorized high-definition, online long-range vectorized, pipeline for online, camera sensors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel end-to-end pipeline for online long-range vectorized high-definition (HD) map construction using on-board camera sensors. The vectorized representation of HD maps, employing polylines and polygons to represent map elements, is widely used by downstream tasks. However, previous schemes designed with reference to dynamic object detection overlook the structural constraints within linear map elements, resulting in performance degradation in long-range scenarios. In this paper, we exploit the properties of map elements to improve the performance of map construction. We extract more accurate bird's eye view (BEV) features guided by their linear structure, and then propose a hierarchical sparse map representation to further leverage the scalability of vectorized map elements and design a progressive decoding mechanism and a supervision strategy based on this representation. Our approach, ScalableMap, demonstrates superior performance on the nuScenes dataset, especially in long-range scenarios, surpassing previous state-of-the-art model by 6.5 mAP while achieving 18.3 FPS. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Single-view 3D reconstruction via inverse procedural modeling</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13373</p>
  <p><b>作者</b>：Albert Garifullin,  Nikolay Maiorov,  Vladimir Frolov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：investigate two variants, procedural, approach, inverse procedural modeling, inverse procedural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an approach to 3D reconstruction via inverse procedural modeling and investigate two variants of this approach. The first option consists in the fitting set of input parameters using a genetic algorithm. We demonstrate the results of our work on tree models, complex objects, with the reconstruction of which most existing methods cannot handle. The second option allows us to significantly improve the precision by using gradients within memetic algorithm, differentiable rendering and also differentiable procedural generators. In our work we see 2 main contributions. First, we propose a method to join differentiable rendering and inverse procedural modeling. This gives us an opportunity to reconstruct 3D model more accurately than existing approaches when a small number of input images are available (even for single image). Second, we join both differentiable and non-differentiable procedural generators in a single framework which allow us to apply inverse procedural modeling to fairly complex generators: when gradient is available, reconstructions is precise, when gradient is not available, reconstruction is approximate, but always high quality without visual artifacts.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：PSGText: Stroke-Guided Scene Text Editing with PSP Module</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13366</p>
  <p><b>作者</b>：Felix Liawi,  Yun-Da Tsai,  Guan-Lun Lu,  Shou-De Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Scene Text Editing, Text Editing, Text, original text, STE</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scene Text Editing (STE) aims to substitute text in an image with new desired text while preserving the background and styles of the original text. However, present techniques present a notable challenge in the generation of edited text images that exhibit a high degree of clarity and legibility. This challenge primarily stems from the inherent diversity found within various text types and the intricate textures of complex backgrounds. To address this challenge, this paper introduces a three-stage framework for transferring texts across text images. Initially, we introduce a text-swapping network that seamlessly substitutes the original text with the desired replacement. Subsequently, we incorporate a background inpainting network into our framework. This specialized network is designed to skillfully reconstruct background images, effectively addressing the voids left after the removal of the original text. This process meticulously preserves visual harmony and coherence in the background. Ultimately, the synthesis of outcomes from the text-swapping network and the background inpainting network is achieved through a fusion network, culminating in the creation of the meticulously edited final image. A demo video is included in the supplementary material.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Bridging the Gap between Synthetic and Authentic Images for Multimodal  Machine Translation</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13361</p>
  <p><b>作者</b>：Wenyu Guo,  Qingkai Fang,  Dong Yu,  Yang Feng</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 main conference</p>
  <p><b>关键词</b>：Multimodal machine translation, authentic images, machine translation, images, Multimodal machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal machine translation (MMT) simultaneously takes the source sentence and a relevant image as input for translation. Since there is no paired image available for the input sentence in most cases, recent studies suggest utilizing powerful text-to-image generation models to provide image inputs. Nevertheless, synthetic images generated by these models often follow different distributions compared to authentic images. Consequently, using authentic images for training and synthetic images for inference can introduce a distribution shift, resulting in performance degradation during inference. To tackle this challenge, in this paper, we feed synthetic and authentic images to the MMT model, respectively. Then we minimize the gap between the synthetic and authentic images by drawing close the input image representations of the Transformer Encoder and the output distributions of the Transformer Decoder. Therefore, we mitigate the distribution disparity introduced by the synthetic images during inference, thereby freeing the authentic images from the inference process.Experimental results show that our approach achieves state-of-the-art performance on the Multi30K En-De and En-Fr datasets, while remaining independent of authentic images during inference.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13356</p>
  <p><b>作者</b>：Seoha Kim,  Jeongmin Bae,  Youngsik Yun,  Hahyun Lee,  Gun Bang,  Youngjung Uh</p>
  <p><b>备注</b>：Preprint. Project page: \href{this https URL}</p>
  <p><b>关键词</b>：neural radiance fields, represent dynamic scenes, dynamic scenes, Recent advancements, radiance fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in 4D scene reconstruction using neural radiance fields (NeRF) have demonstrated the ability to represent dynamic scenes from multi-view videos. However, they fail to reconstruct the dynamic scenes and struggle to fit even the training views in unsynchronized settings. It happens because they employ a single latent embedding for a frame while the multi-view images at the frame were actually captured at different moments. To address this limitation, we introduce time offsets for individual unsynchronized videos and jointly optimize the offsets with NeRF. By design, our method is applicable for various baselines and improves them with large margins. Furthermore, finding the offsets naturally works as synchronizing the videos without manual effort. Experiments are conducted on the common Plenoptic Video Dataset and a newly built Unsynchronized Dynamic Blender Dataset to verify the performance of our method. Project page: this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：SILC: Improving Vision Language Pretraining with Self-Distillation</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13355</p>
  <p><b>作者</b>：Muhammad Ferjad Naeem,  Yongqin Xian,  Xiaohua Zhai,  Lukas Hoyer,  Luc Van Gool,  Federico Tombari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：web-scale image caption, image caption dataset, dense prediction tasks, pretraining on web-scale, caption dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-Text pretraining on web-scale image caption dataset has become the default recipe for open vocabulary classification and retrieval models thanks to the success of CLIP and its variants. Several works have also used CLIP features for dense prediction tasks and have shown the emergence of open-set abilities. However, the contrastive objective only focuses on image-text alignment and does not incentivise image feature learning for dense prediction tasks. In this work, we propose the simple addition of local-to-global correspondence learning by self-distillation as an additional objective for contrastive pre-training to propose SILC. We show that distilling local image features from an exponential moving average (EMA) teacher model significantly improves model performance on several computer vision tasks including classification, retrieval, and especially segmentation. We further show that SILC scales better with the same training duration compared to the baselines. Our model SILC sets a new state of the art for zero-shot classification, few shot classification, image and text retrieval, zero-shot segmentation, and open vocabulary segmentation.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：EarlyBird: Early-Fusion for Multi-View Tracking in the Bird's Eye View</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13350</p>
  <p><b>作者</b>：Torben Teepe,  Philipp Wolters,  Johannes Gilg,  Fabian Herzog,  Gerhard Rigoll</p>
  <p><b>备注</b>：8 pages, 3 figures</p>
  <p><b>关键词</b>：Multi-view aggregation promises, Bird Eye View, missed detection challenge, aggregation promises, promises to overcome</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-view aggregation promises to overcome the occlusion and missed detection challenge in multi-object detection and tracking. Recent approaches in multi-view detection and 3D object detection made a huge performance leap by projecting all views to the ground plane and performing the detection in the Bird's Eye View (BEV). In this paper, we investigate if tracking in the BEV can also bring the next performance breakthrough in Multi-Target Multi-Camera (MTMC) tracking. Most current approaches in multi-view tracking perform the detection and tracking task in each view and use graph-based approaches to perform the association of the pedestrian across each view. This spatial association is already solved by detecting each pedestrian once in the BEV, leaving only the problem of temporal association. For the temporal association, we show how to learn strong Re-Identification (re-ID) features for each detection. The results show that early-fusion in the BEV achieves high accuracy for both detection and tracking. EarlyBird outperforms the state-of-the-art methods and improves the current state-of-the-art on Wildtrack by +4.6 MOTA and +5.6 IDF1.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：NurViD: A Large Expert-Level Video Database for Nursing Procedure  Activity Understanding</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13347</p>
  <p><b>作者</b>：Ming Hu,  Lin Wang,  Siyuan Yan,  Don Ma,  Qingli Ren,  Peng Xia,  Wei Feng,  Peibo Duan,  Lie Ju,  Zongyuan Ge</p>
  <p><b>备注</b>：Accepted by NeurIPS 2023 Datasets and Benchmarks Track</p>
  <p><b>关键词</b>：nurse-patient interactions, nursing procedure activity, potential to greatly, greatly enhance, safety of nurse-patient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The application of deep learning to nursing procedure activity understanding has the potential to greatly enhance the quality and safety of nurse-patient interactions. By utilizing the technique, we can facilitate training and education, improve quality control, and enable operational compliance monitoring. However, the development of automatic recognition systems in this field is currently hindered by the scarcity of appropriately labeled datasets. The existing video datasets pose several limitations: 1) these datasets are small-scale in size to support comprehensive investigations of nursing activity; 2) they primarily focus on single procedures, lacking expert-level annotations for various nursing procedures and action steps; and 3) they lack temporally localized annotations, which prevents the effective localization of targeted actions within longer video sequences. To mitigate these limitations, we propose NurViD, a large video dataset with expert-level annotation for nursing procedure activity understanding. NurViD consists of over 1.5k videos totaling 144 hours, making it approximately four times longer than the existing largest nursing activity datasets. Notably, it encompasses 51 distinct nursing procedures and 177 action steps, providing a much more comprehensive coverage compared to existing datasets that primarily focus on limited procedures. To evaluate the efficacy of current deep learning methods on nursing activity understanding, we establish three benchmarks on NurViD: procedure recognition on untrimmed videos, procedure and action recognition on trimmed videos, and action detection. Our benchmark and code will be available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：DeepFracture: A Generative Approach for Predicting Brittle Fractures</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13344</p>
  <p><b>作者</b>：Yuhang Huang,  Takashi Kanai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating realistic destruction, realistic destruction animations, computationally expensive, brittle fracture, brittle fracture animation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of brittle fracture animation, generating realistic destruction animations with physics simulation techniques can be computationally expensive. Although methods using Voronoi diagrams or pre-fractured patterns work for real-time applications, they often lack realism in portraying brittle fractures. This paper introduces a novel learning-based approach for seamlessly merging realistic brittle fracture animations with rigid-body simulations. Our method utilizes BEM brittle fracture simulations to create fractured patterns and collision conditions for a given shape, which serve as training data for the learning process. To effectively integrate collision conditions and fractured shapes into a deep learning framework, we introduce the concept of latent impulse representation and geometrically-segmented signed distance function (GS-SDF). The latent impulse representation serves as input, capturing information about impact forces on the shape's surface. Simultaneously, a GS-SDF is used as the output representation of the fractured shape. To address the challenge of optimizing multiple fractured pattern targets with a single latent code, we propose an eight-dimensional latent space based on a normal distribution code within our latent impulse representation design. This adaptation effectively transforms our neural network into a generative one. Our experimental results demonstrate that our approach can generate significantly more detailed brittle fractures compared to existing techniques, all while maintaining commendable computational efficiency during run-time.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From  Multi-Source Optical Imagery</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13336</p>
  <p><b>作者</b>：Anatol Garioud,  Nicolas Gonthier,  Loic Landrieu,  Apolline De Wit,  Marion Valette,  Marc Poupée,  Sébastien Giordano,  Boris Wattrelos</p>
  <p><b>备注</b>：NeurIPS 2023 - Datasets & Benchmarks Track</p>
  <p><b>关键词</b>：French National Institute, French Land cover, French Land, French National, Forest Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the French Land cover from Aerospace ImageRy (FLAIR), an extensive dataset from the French National Institute of Geographical and Forest Information (IGN) that provides a unique and rich resource for large-scale geospatial analysis. FLAIR contains high-resolution aerial imagery with a ground sample distance of 20 cm and over 20 billion individually labeled pixels for precise land-cover classification. The dataset also integrates temporal and spectral data from optical satellite time series. FLAIR thus combines data with varying spatial, spectral, and temporal resolutions across over 817 km2 of acquisitions representing the full landscape diversity of France. This diversity makes FLAIR a valuable resource for the development and evaluation of novel methods for large-scale land-cover semantic segmentation and raises significant challenges in terms of computer vision, data fusion, and geospatial analysis. We also provide powerful uni- and multi-sensor baseline models that can be employed to assess algorithm's performance and for downstream applications. Through its extent and the quality of its annotation, FLAIR aims to spur improvements in monitoring and understanding key anthropogenic development indicators such as urban growth, deforestation, and soil artificialization. Dataset and codes can be accessed at this https URL</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：CylinderTag: An Accurate and Flexible Marker for Cylinder-Shape Objects  Pose Estimation Based on Projective Invariants</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13320</p>
  <p><b>作者</b>：Shaoan Wang,  Mingzhu Zhu,  Yaoqing Hu,  Dongyue Li,  Fusong Yuan,  Junzhi Yu</p>
  <p><b>备注</b>：15 pages, 22 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：High-precision pose estimation, pose estimation based, pose estimation, thriving research topic, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-precision pose estimation based on visual markers has been a thriving research topic in the field of computer vision. However, the suitability of traditional flat markers on curved objects is limited due to the diverse shapes of curved surfaces, which hinders the development of high-precision pose estimation for curved objects. Therefore, this paper proposes a novel visual marker called CylinderTag, which is designed for developable curved surfaces such as cylindrical surfaces. CylinderTag is a cyclic marker that can be firmly attached to objects with a cylindrical shape. Leveraging the manifold assumption, the cross-ratio in projective invariance is utilized for encoding in the direction of zero curvature on the surface. Additionally, to facilitate the usage of CylinderTag, we propose a heuristic search-based marker generator and a high-performance recognizer as well. Moreover, an all-encompassing evaluation of CylinderTag properties is conducted by means of extensive experimentation, covering detection rate, detection speed, dictionary size, localization jitter, and pose estimation accuracy. CylinderTag showcases superior detection performance from varying view angles in comparison to traditional visual markers, accompanied by higher localization accuracy. Furthermore, CylinderTag boasts real-time detection capability and an extensive marker dictionary, offering enhanced versatility and practicality in a wide range of applications. Experimental results demonstrate that the CylinderTag is a highly promising visual marker for use on cylindrical-like surfaces, thus offering important guidance for future research on high-precision visual localization of cylinder-shaped objects. The code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13292</p>
  <p><b>作者</b>：Kihyun You,  Jawook Gu,  Jiyeon Ham,  Beomhee Park,  Jiho Kim,  Eun Kyoung Hong,  Woonhyunk Baek,  Byungseok Roh</p>
  <p><b>备注</b>：Accepted by MICCAI 2023</p>
  <p><b>关键词</b>：large-scale image-text pair, vision-language pre-training, costly annotation, greatly contributed, development of vision-language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A large-scale image-text pair dataset has greatly contributed to the development of vision-language pre-training (VLP) models, which enable zero-shot or few-shot classification without costly annotation. However, in the medical domain, the scarcity of data remains a significant challenge for developing a powerful VLP model. In this paper, we tackle the lack of image-text data in chest X-ray by expanding image-label pair as image-text pair via general prompt and utilizing multiple images and multiple sections in a radiologic report. We also design two contrastive losses, named ICL and TCL, for learning study-level characteristics of medical images and reports, respectively. Our model outperforms the state-of-the-art models trained under the same conditions. Also, enlarged dataset improve the discriminative power of our pre-trained model for classification, while sacrificing marginal retrieval performance. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13276</p>
  <p><b>作者</b>：Xiangru Jian,  Yimu Wang</p>
  <p><b>备注</b>：Findings of EMNLP 2023</p>
  <p><b>关键词</b>：representation degeneration problem, significant advancements, linguistic modeling, degeneration problem, driven by breakthroughs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over recent decades, significant advancements in cross-modal retrieval are mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance.
Our code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model  Statistics</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13268</p>
  <p><b>作者</b>：Kaiwen Zheng,  Cheng Lu,  Jianfei Chen,  Jun Zhu</p>
  <p><b>备注</b>：Accepted at NeurIPS 2023</p>
  <p><b>关键词</b>：high-fidelity image generation, exhibited excellent performance, NFE, exhibited excellent, high-fidelity image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion probabilistic models (DPMs) have exhibited excellent performance for high-fidelity image generation while suffering from inefficient sampling. Recent works accelerate the sampling procedure by proposing fast ODE solvers that leverage the specific ODE form of DPMs. However, they highly rely on specific parameterization during inference (such as noise/data prediction), which might not be the optimal choice. In this work, we propose a novel formulation towards the optimal parameterization during sampling that minimizes the first-order discretization error of the ODE solution. Based on such formulation, we propose \textit{DPM-Solver-v3}, a new fast ODE solver for DPMs by introducing several coefficients efficiently computed on the pretrained model, which we call \textit{empirical model statistics}. We further incorporate multistep methods and a predictor-corrector framework, and propose some techniques for improving sample quality at small numbers of function evaluations (NFE) or large guidance scales. Experiments show that DPM-Solver-v3 achieves consistently better or comparable performance in both unconditional and conditional sampling with both pixel-space and latent-space DPMs, especially in 5$\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE) on unconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable Diffusion, bringing a speed-up of 15\%$\sim$30\% compared to previous state-of-the-art training-free methods. Code is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：On the Language Encoder of Contrastive Cross-modal Models</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13267</p>
  <p><b>作者</b>：Mengjie Zhao,  Junya Ono,  Zhi Zhong,  Chieh-Hsin Lai,  Yuhta Takida,  Naoki Murata,  Wei-Hsiang Liao,  Takashi Shibuya,  Hiromi Wakaki,  Yuki Mitsufuji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CLIP and CLAP, sentence embedding training, CLAP aid, sentence embedding, embedding training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder, which is the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found that sentence embedding training language encoder quality and aids in cross-modal tasks, improving contrastive VL models such as CyCLIP. In contrast, AL pretraining benefits less from sentence embedding training, which may result from the limited amount of pretraining data. We analyze the representation spaces to understand the strengths of sentence embedding training, and find that it improves text-space uniformity, at the cost of decreased cross-modal alignment.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：UE4-NeRF:Neural Radiance Field for Real-Time Rendering of Large-Scale  Scene</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13263</p>
  <p><b>作者</b>：Jiaming Gu,  Minchao Jiang,  Hongsheng Li,  Xiaoyuan Lu,  Guangming Zhu,  Syed Afaq Ali Shah,  Liang Zhang,  Mohammed Bennamoun</p>
  <p><b>备注</b>：Accepted by NeurIPS2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, gaining increasing attention, shows immense potential, Neural Radiance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) is a novel implicit 3D reconstruction method that shows immense potential and has been gaining increasing attention. It enables the reconstruction of 3D scenes solely from a set of photographs. However, its real-time rendering capability, especially for interactive real-time rendering of large-scale scenes, still has significant limitations. To address these challenges, in this paper, we propose a novel neural rendering system called UE4-NeRF, specifically designed for real-time rendering of large-scale scenes. We partitioned each large scene into different sub-NeRFs. In order to represent the partitioned independent scene, we initialize polygonal meshes by constructing multiple regular octahedra within the scene and the vertices of the polygonal faces are continuously optimized during the training process. Drawing inspiration from Level of Detail (LOD) techniques, we trained meshes of varying levels of detail for different observation levels. Our approach combines with the rasterization pipeline in Unreal Engine 4 (UE4), achieving real-time rendering of large-scale scenes at 4K resolution with a frame rate of up to 43 FPS. Rendering within UE4 also facilitates scene editing in subsequent stages. Furthermore, through experiments, we have demonstrated that our method achieves rendering quality comparable to state-of-the-art approaches. Project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in  Open Worlds</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13255</p>
  <p><b>作者</b>：Sipeng Zheng,  Jiazheng Liu,  Yicheng Feng,  Zongqing Lu</p>
  <p><b>备注</b>：19 pages, 14 figures</p>
  <p><b>关键词</b>：presented compelling evidence, equip embodied agents, Recent studies, versatile robotics, studies have presented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have presented compelling evidence that large language models (LLMs) can equip embodied agents with the self-driven capability to interact with the world, which marks an initial step toward versatile robotics. However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to "a blindfolded text-based game." Consequently, LLM-based agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand. In this paper, we propose Steve-Eye, an end-to-end trained large multimodal model designed to address this limitation. Steve-Eye integrates the LLM with a visual encoder which enables it to process visual-text inputs and generate multimodal feedback. In addition, we use a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs, empowering our model to encompass three essential functions for an agent: multimodal perception, foundational knowledge base, and skill prediction and planning. Lastly, we develop three open-world evaluation benchmarks, then carry out extensive experiments from a wide range of perspectives to validate our model's capability to strategically act and plan. Codes and datasets will be released.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Auxiliary Features-Guided Super Resolution for Monte Carlo Rendering</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13235</p>
  <p><b>作者</b>：Qiqi Hou,  Feng Liu</p>
  <p><b>备注</b>：Accepted by CGF</p>
  <p><b>关键词</b>：paper investigates super, investigates super resolution, super resolution, Carlo rendering algorithms, high-resolution auxiliary features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates super resolution to reduce the number of pixels to render and thus speed up Monte Carlo rendering algorithms. While great progress has been made to super resolution technologies, it is essentially an ill-posed problem and cannot recover high-frequency details in renderings. To address this problem, we exploit high-resolution auxiliary features to guide super resolution of low-resolution renderings. These high-resolution auxiliary features can be quickly rendered by a rendering engine and at the same time provide valuable high-frequency details to assist super resolution. To this end, we develop a cross-modality Transformer network that consists of an auxiliary feature branch and a low-resolution rendering branch. These two branches are designed to fuse high-resolution auxiliary features with the corresponding low-resolution rendering. Furthermore, we design residual densely-connected Swin Transformer groups to learn to extract representative features to enable high-quality super-resolution. Our experiments show that our auxiliary features-guided super-resolution method outperforms both super-resolution methods and Monte Carlo denoising methods in producing high-quality renderings.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Zone Evaluation: Revealing Spatial Bias in Object Detection</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13215</p>
  <p><b>作者</b>：Zhaohui Zheng,  Yuming Chen,  Qibin Hou,  Xiang Li,  Ping Wang,  Ming-Ming Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spatial bias, object detectors, spatial, fundamental limitation, satisfactorily when detecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A fundamental limitation of object detectors is that they suffer from "spatial bias", and in particular perform less satisfactorily when detecting objects near image borders. For a long time, there has been a lack of effective ways to measure and identify spatial bias, and little is known about where it comes from and what degree it is. To this end, we present a new zone evaluation protocol, extending from the traditional evaluation to a more generalized one, which measures the detection performance over zones, yielding a series of Zone Precisions (ZPs). For the first time, we provide numerical results, showing that the object detectors perform quite unevenly across the zones. Surprisingly, the detector's performance in the 96\% border zone of the image does not reach the AP value (Average Precision, commonly regarded as the average detection performance in the entire image zone). To better understand spatial bias, a series of heuristic experiments are conducted. Our investigation excludes two intuitive conjectures about spatial bias that the object scale and the absolute positions of objects barely influence the spatial bias. We find that the key lies in the human-imperceptible divergence in data patterns between objects in different zones, thus eventually forming a visible performance gap between the zones. With these findings, we finally discuss a future direction for object detection, namely, spatial disequilibrium problem, aiming at pursuing a balanced detection ability over the entire image zone. By broadly evaluating 10 popular object detectors and 5 detection datasets, we shed light on the spatial bias of object detectors. We hope this work could raise a focus on detection robustness. The source codes, evaluation protocols, and tutorials are publicly available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Identification of Abnormality in Maize Plants From UAV Images Using Deep  Learning Approaches</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13201</p>
  <p><b>作者</b>：Aminul Huq,  Dimitris Zermas,  George Bebis</p>
  <p><b>备注</b>：Paper accepted and presented at the 18th International Symposium on Visual Computing (ISVC)</p>
  <p><b>关键词</b>：achieving high yields, yields from crops, important task, task for ensuring, ensuring proper growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early identification of abnormalities in plants is an important task for ensuring proper growth and achieving high yields from crops. Precision agriculture can significantly benefit from modern computer vision tools to make farming strategies addressing these issues efficient and effective. As farming lands are typically quite large, farmers have to manually check vast areas to determine the status of the plants and apply proper treatments. In this work, we consider the problem of automatically identifying abnormal regions in maize plants from images captured by a UAV. Using deep learning techniques, we have developed a methodology which can detect different levels of abnormality (i.e., low, medium, high or no abnormality) in maize plants independently of their growth stage. The primary goal is to identify anomalies at the earliest possible stage in order to maximize the effectiveness of potential treatments. At the same time, the proposed system can provide valuable information to human annotators for ground truth data collection by helping them to focus their attention on a much smaller set of images only. We have experimented with two different but complimentary approaches, the first considering abnormality detection as a classification problem and the second considering it as a regression problem. Both approaches can be generalized to different types of abnormalities and do not make any assumption about the abnormality occurring at an early plant growth stage which might be easier to detect due to the plants being smaller and easier to separate. As a case study, we have considered a publicly available data set which exhibits mostly Nitrogen deficiency in maize plants of various growth stages. We are reporting promising preliminary results with an 88.89\% detection accuracy of low abnormality and 100\% detection accuracy of no abnormality.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：A Car Model Identification System for Streamlining the Automobile Sales  Process</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13198</p>
  <p><b>作者</b>：Said Togru,  Jenny Huang,  Marco Moldovan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vehicle listing process, online car-selling platforms, Convolutional Neural Networks, makes from images, aimed at streamlining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This project presents an automated solution for the efficient identification of car models and makes from images, aimed at streamlining the vehicle listing process on online car-selling platforms. Through a thorough exploration encompassing various efficient network architectures including Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), and hybrid models, we achieved a notable accuracy of 81.97% employing the EfficientNet (V2 b2) architecture. To refine performance, a combination of strategies, including data augmentation, fine-tuning pretrained models, and extensive hyperparameter tuning, were applied. The trained model offers the potential for automating information extraction, promising enhanced user experiences across car-selling websites.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Breaking through Deterministic Barriers: Randomized Pruning Mask  Generation and Selection</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13183</p>
  <p><b>作者</b>：Jianwei Li,  Weizhi Gao,  Qi Lei,  Dongkuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model size constraints, size constraints, widely acknowledged, higher accuracy, accuracy than small</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is widely acknowledged that large and sparse models have higher accuracy than small and dense models under the same model size constraints. This motivates us to train a large model and then remove its redundant neurons or weights by pruning. Most existing works pruned the networks in a deterministic way, the performance of which solely depends on a single pruning criterion and thus lacks variety. Instead, in this paper, we propose a model pruning strategy that first generates several pruning masks in a designed random way. Subsequently, along with an effective mask-selection rule, the optimal mask is chosen from the pool of mask candidates. To further enhance efficiency, we introduce an early mask evaluation strategy, mitigating the overhead associated with training multiple masks. Our extensive experiments demonstrate that this approach achieves state-of-the-art performance across eight datasets from GLUE, particularly excelling at high levels of sparsity.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for  Image Manipulation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13165</p>
  <p><b>作者</b>：Sihan Xu,  Ziqiao Ma,  Yidong Huang,  Honglak Lee,  Joyce Chai</p>
  <p><b>备注</b>：NeurIPS 2023</p>
  <p><b>关键词</b>：Diffusion models, interface for consistent, enabled breakthroughs, lack an intuitive, intuitive interface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual prompt. Cyclenet is a practical framework, which is robust even with very limited training data (around 2k) and requires minimal computational resources (1 GPU) to train. Project homepage: this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Conditional Generative Modeling for Images, 3D Animations, and Video</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13157</p>
  <p><b>作者</b>：Vikram Voleti</p>
  <p><b>备注</b>：Doctoral thesis, Mila, University of Montreal. 189 pages</p>
  <p><b>关键词</b>：dissertation attempts, attempts to drive, drive innovation, exploring novel formulations, innovative applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation attempts to drive innovation in the field of generative modeling for computer vision, by exploring novel formulations of conditional generative models, and innovative applications in images, 3D animations, and video. Our research focuses on architectures that offer reversible transformations of noise and visual data, and the application of encoder-decoder architectures for generative tasks and 3D content manipulation. In all instances, we incorporate conditional information to enhance the synthesis of visual data, improving the efficiency of the generation process as well as the generated content.
We introduce the use of Neural ODEs to model video dynamics using an encoder-decoder architecture, demonstrating their ability to predict future video frames despite being trained solely to reconstruct current frames. Next, we propose a conditional variant of continuous normalizing flows that enables higher-resolution image generation based on lower-resolution input, achieving comparable image quality while reducing parameters and training time. Our next contribution presents a pipeline that takes human images as input, automatically aligns a user-specified 3D character with the pose of the human, and facilitates pose editing based on partial inputs. Next, we derive the relevant mathematical details for denoising diffusion models that use non-isotropic Gaussian processes, and show comparable generation quality. Finally, we devise a novel denoising diffusion framework capable of solving all three video tasks of prediction, generation, and interpolation. We perform ablation studies, and show SOTA results on multiple datasets.
Our contributions are published articles at peer-reviewed venues. Overall, our research aims to make a meaningful contribution to the pursuit of more efficient and flexible generative models, with the potential to shape the future of computer vision.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：LeTFuser: Light-weight End-to-end Transformer-Based Sensor Fusion for  Autonomous Driving with Multi-Task Learning</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13135</p>
  <p><b>作者</b>：Pedram Agand,  Mohammad Mahdavian,  Manolis Savva,  Mo Chen</p>
  <p><b>备注</b>：10 pages, 2 figures, 3 tables. CVPR Workshops (VCAD). 2023. arXiv admin note: text overlap with arXiv:2204.05513 by other authors</p>
  <p><b>关键词</b>：existing sensor fusion, sensor fusion techniques, imitation learning proves, learning proves inadequate, numerous dynamic agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In end-to-end autonomous driving, the utilization of existing sensor fusion techniques for imitation learning proves inadequate in challenging situations that involve numerous dynamic agents. To address this issue, we introduce LeTFuser, a transformer-based algorithm for fusing multiple RGB-D camera representations. To perform perception and control tasks simultaneously, we utilize multi-task learning. Our model comprises of two modules, the first being the perception module that is responsible for encoding the observation data obtained from the RGB-D cameras. It carries out tasks such as semantic segmentation, semantic depth cloud mapping (SDC), and traffic light state recognition. Our approach employs the Convolutional vision Transformer (CvT) \cite{wu2021cvt} to better extract and fuse features from multiple RGB cameras due to local and global feature extraction capability of convolution and transformer modules, respectively. Following this, the control module undertakes the decoding of the encoded characteristics together with supplementary data, comprising a rough simulator for static and dynamic environments, as well as various measurements, in order to anticipate the waypoints associated with a latent feature space. We use two methods to process these outputs and generate the vehicular controls (e.g. steering, throttle, and brake) levels. The first method uses a PID algorithm to follow the waypoints on the fly, whereas the second one directly predicts the control policy using the measurement features and environmental state. We evaluate the model and conduct a comparative analysis with recent models on the CARLA simulator using various scenarios, ranging from normal to adversarial conditions, to simulate real-world scenarios. Our code is available at \url{this https URL} to facilitate future studies.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question  Answering</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13120</p>
  <p><b>作者</b>：Yuduo Wang,  Pedram Ghamisi</p>
  <p><b>备注</b>：Submitted to IEEE</p>
  <p><b>关键词</b>：Visual Question Answering, Image Captioning, Visual Question, Question Answering, found wide application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not only improves adaptation to pre-trained multimodal models but also allows the parameters of the linear transformation layer to be integrated into the preceding FC layers during inference, reducing inference costs. To demonstrate the effectiveness of RSAdapter, we conduct an extensive series of experiments using three distinct RS-VQA datasets and achieve state-of-the-art results on all three datasets. The code for RSAdapter will be available online at this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture  Propagation</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13119</p>
  <p><b>作者</b>：Bangbang Yang,  Wenqi Dong,  Lin Ma,  Wenbo Hu,  Xiao Liu,  Zhaopeng Cui,  Yuewen Ma</p>
  <p><b>备注</b>：Project webpage: this https URL</p>
  <p><b>关键词</b>：achieved prominent success, Diffusion-based methods, success in generating, methods have achieved, achieved prominent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion-based methods have achieved prominent success in generating 2D media. However, accomplishing similar proficiencies for scene-level mesh texturing in 3D spatial applications, e.g., XR/VR, remains constrained, primarily due to the intricate nature of 3D geometry and the necessity for immersive free-viewpoint rendering. In this paper, we propose a novel indoor scene texturing framework, which delivers text-driven texture generation with enchanting details and authentic spatial coherence. The key insight is to first imagine a stylized 360° panoramic texture from the central viewpoint of the scene, and then propagate it to the rest areas with inpainting and imitating techniques. To ensure meaningful and aligned textures to the scene, we develop a novel coarse-to-fine panoramic texture generation approach with dual texture alignment, which both considers the geometry and texture cues of the captured scenes. To survive from cluttered geometries during texture propagation, we design a separated strategy, which conducts texture inpainting in confidential regions and then learns an implicit imitating network to synthesize textures in occluded and tiny structural areas. Extensive experiments and the immersive VR application on real-world indoor scenes demonstrate the high quality of the generated textures and the engaging experience on VR headsets. Project webpage: this https URL</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting  Multiple Experts for Video Deepfake Detection</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13103</p>
  <p><b>作者</b>：Ammarah Hashmi,  Sahibzada Adil Shahzad,  Chia-Wen Lin,  Yu Tsao,  Hsin-Min Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media platforms, major social problem, content shared widely, requires increased regulation, Forged content shared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulation and visual manipulation to achieve effective video forgery detection. Specifically, the proposed model integrates several purely transformer-based variants that capture video, audio, and audio-visual salient cues to reach a consensus in prediction. For evaluation, we use the recently released benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed analysis, we evaluate AVTENet, its variants, and several existing methods on multiple test sets of the FakeAVCeleb dataset. Experimental results show that our best model outperforms all existing methods and achieves state-of-the-art performance on Testset-I and Testset-II of the FakeAVCeleb dataset.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：PatchCURE: Improving Certifiable Robustness, Model Utility, and  Computation Efficiency of Adversarial Patch Defenses</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13076</p>
  <p><b>作者</b>：Chong Xiang,  Tong Wu,  Sihui Dai,  Jonathan Petit,  Suman Jana,  Prateek Mittal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adversarial patch attacks, strong certifiable robustness, achieve strong certifiable, adversarial patch, patch attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art defenses against adversarial patch attacks can now achieve strong certifiable robustness with a marginal drop in model utility. However, this impressive performance typically comes at the cost of 10-100x more inference-time computation compared to undefended models -- the research community has witnessed an intense three-way trade-off between certifiable robustness, model utility, and computation efficiency. In this paper, we propose a defense framework named PatchCURE to approach this trade-off problem. PatchCURE provides sufficient "knobs" for tuning defense performance and allows us to build a family of defenses: the most robust PatchCURE instance can match the performance of any existing state-of-the-art defense (without efficiency considerations); the most efficient PatchCURE instance has similar inference efficiency as undefended models. Notably, PatchCURE achieves state-of-the-art robustness and utility performance across all different efficiency levels, e.g., 16-23% absolute clean accuracy and certified robust accuracy advantages over prior defenses when requiring computation efficiency to be close to undefended models. The family of PatchCURE defenses enables us to flexibly choose appropriate defenses to satisfy given computation and/or utility constraints in practice.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Using Logic Programming and Kernel-Grouping for Improving  Interpretability of Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13073</p>
  <p><b>作者</b>：Parth Padalkar,  Gopal Gupta</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2301.12667</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, Convolutional Neural, CNN, Based Machine Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within the realm of deep learning, the interpretability of Convolutional Neural Networks (CNNs), particularly in the context of image classification tasks, remains a formidable challenge. To this end we present a neurosymbolic framework, NeSyFOLD-G that generates a symbolic rule-set using the last layer kernels of the CNN to make its underlying knowledge interpretable. What makes NeSyFOLD-G different from other similar frameworks is that we first find groups of similar kernels in the CNN (kernel-grouping) using the cosine-similarity between the feature maps generated by various kernels. Once such kernel groups are found, we binarize each kernel group's output in the CNN and use it to generate a binarization table which serves as input data to FOLD-SE-M which is a Rule Based Machine Learning (RBML) algorithm. FOLD-SE-M then generates a rule-set that can be used to make predictions. We present a novel kernel grouping algorithm and show that grouping similar kernels leads to a significant reduction in the size of the rule-set generated by FOLD-SE-M, consequently, improving the interpretability. This rule-set symbolically encapsulates the connectionist knowledge of the trained CNN. The rule-set can be viewed as a normal logic program wherein each predicate's truth value depends on a kernel group in the CNN. Each predicate in the rule-set is mapped to a concept using a few semantic segmentation masks of the images used for training, to make it human-understandable. The last layers of the CNN can then be replaced by this rule-set to obtain the NeSy-G model which can then be used for the image classification task. The goal directed ASP system s(CASP) can be used to obtain the justification of any prediction made using the NeSy-G model. We also propose a novel algorithm for labeling each predicate in the rule-set with the semantic concept(s) that its corresponding kernel group represents.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Robust multimodal models have outlier features and encode more concepts</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13040</p>
  <p><b>作者</b>：Jonathan Crabbé,  Pau Rodríguez,  Vaishaal Shankar,  Luca Zappella,  Arno Blaas</p>
  <p><b>备注</b>：29 pages, 18 figures</p>
  <p><b>关键词</b>：robust models, distinguishes robust models, models, representation space, robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demonstrate that these privileged directions explain most of the predictive power of the model by pruning up to $80 \%$ of the least important representation space directions without negative impacts on model accuracy and robustness; (2) Robust models encode substantially more concepts in their representation space. While this superposition of concepts allows robust models to store much information, it also results in highly polysemantic features, which makes their interpretation challenging. We discuss how these insights pave the way for future research in various fields, such as model pruning and mechanistic interpretability.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Human Pose-based Estimation, Tracking and Action Recognition with Deep  Learning: A Survey</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13039</p>
  <p><b>作者</b>：Lijuan Zhou,  Xiang Meng,  Zhihuan Liu,  Mengqi Wu,  Zhimin Gao,  Pichao Wang</p>
  <p><b>备注</b>：47 pages</p>
  <p><b>关键词</b>：garnered significant attention, pose estimation, pose, sports performance analysis, including gaming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human pose analysis has garnered significant attention within both the research community and practical applications, owing to its expanding array of uses, including gaming, video surveillance, sports performance analysis, and human-computer interactions, among others. The advent of deep learning has significantly improved the accuracy of pose capture, making pose-based applications increasingly practical. This paper presents a comprehensive survey of pose-based applications utilizing deep learning, encompassing pose estimation, pose tracking, and action recognition.Pose estimation involves the determination of human joint positions from images or image sequences. Pose tracking is an emerging research direction aimed at generating consistent human pose trajectories over time. Action recognition, on the other hand, targets the identification of action types using pose estimation or tracking data. These three tasks are intricately interconnected, with the latter often reliant on the former. In this survey, we comprehensively review related works, spanning from single-person pose estimation to multi-person pose estimation, from 2D pose estimation to 3D pose estimation, from single image to video, from mining temporal context gradually to pose tracking, and lastly from tracking to pose-based action recognition. As a survey centered on the application of deep learning to pose analysis, we explicitly discuss both the strengths and limitations of existing techniques. Notably, we emphasize methodologies for integrating these three tasks into a unified framework within video sequences. Additionally, we explore the challenges involved and outline potential directions for future research.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：SIRe-IR: Inverse Rendering for BRDF Reconstruction with Shadow and  Illumination Removal in High-Illuminance Scenes</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13030</p>
  <p><b>作者</b>：Ziyi Yang,  Yanzhen Chen,  Xinyu Gao,  Yazhen Yuan,  Yu Wu,  Xiaowei Zhou,  Xiaogang Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：implicit neural inverse, neural inverse rendering, Implicit neural representation, Implicit neural, inverse rendering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Implicit neural representation has opened up new possibilities for inverse rendering. However, existing implicit neural inverse rendering methods struggle to handle strongly illuminated scenes with significant shadows and indirect illumination. The existence of shadows and reflections can lead to an inaccurate understanding of scene geometry, making precise factorization difficult. To this end, we present SIRe-IR, an implicit neural inverse rendering approach that uses non-linear mapping and regularized visibility estimation to decompose the scene into environment map, albedo, and roughness. By accurately modeling the indirect radiance field, normal, visibility, and direct light simultaneously, we are able to remove both shadows and indirect illumination in materials without imposing strict constraints on the scene. Even in the presence of intense illumination, our method recovers high-quality albedo and roughness with no shadow interference. SIRe-IR outperforms existing methods in both quantitative and qualitative evaluations.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Weakly-Supervised Semantic Segmentation with Image-Level Labels: from  Traditional Models to Foundation Models</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13026</p>
  <p><b>作者</b>：Zhaozheng Chen,  Qianru Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：driven significant progress, image semantic segmentation, semantic segmentation, computer vision, driven significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid development of deep learning has driven significant progress in the field of image semantic segmentation - a fundamental task in computer vision. Semantic segmentation algorithms often depend on the availability of pixel-level labels (i.e., masks of objects), which are expensive, time-consuming, and labor-intensive. Weakly-supervised semantic segmentation (WSSS) is an effective solution to avoid such labeling. It utilizes only partial or incomplete annotations and provides a cost-effective alternative to fully-supervised semantic segmentation. In this paper, we focus on the WSSS with image-level labels, which is the most challenging form of WSSS. Our work has two parts. First, we conduct a comprehensive survey on traditional methods, primarily focusing on those presented at premier research conferences. We categorize them into four groups based on where their methods operate: pixel-wise, image-wise, cross-image, and external data. Second, we investigate the applicability of visual foundation models, such as the Segment Anything Model (SAM), in the context of WSSS. We scrutinize SAM in two intriguing scenarios: text prompting and zero-shot learning. We provide insights into the potential and challenges associated with deploying visual foundational models for WSSS, facilitating future developments in this exciting research area.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class  Manipulation Using DeepFool Algorithm</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13019</p>
  <p><b>作者</b>：S. M. Fazle Rabby Labib,  Joyanta Jyoti Mondal,  Meem Arafat Manab</p>
  <p><b>备注</b>：8 pages, 3 figures, to be submitted at IEEE Computer Vision and Pattern Recognition (CVPR) 2024</p>
  <p><b>关键词</b>：adversarial attacks poses, advanced various domains, poses serious concerns, significantly advanced, vulnerability to adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across different deep neural network architectures while preserving image integrity as much as possible. Results show that one of the deep convolutional neural network architectures, AlexNet, and one of the state-of-the-art model Vision Transformer exhibit high robustness to getting fooled. Our code will be made public when publishing the paper.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Parking Spot Classification based on surround view camera system</b></summary>
  <p><b>编号</b>：[323]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12997</p>
  <p><b>作者</b>：Andy Xiao,  Deep Doshi,  Lihao Wang,  Harsha Gorantla,  Thomas Heitzmann,  Peter Groth</p>
  <p><b>备注</b>：SPIE Optical Engineering + Applications, 2023, San Diego, California, United States. Proc. SPIE 12675, Applications of Machine Learning 2023</p>
  <p><b>关键词</b>：including urban driving, automated driving scenarios, Surround-view fisheye cameras, automated driving, urban driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surround-view fisheye cameras are commonly used for near-field sensing in automated driving scenarios, including urban driving and auto valet parking. Four fisheye cameras, one on each side, are sufficient to cover 360° around the vehicle capturing the entire near-field region. Based on surround view cameras, there has been much research on parking slot detection with main focus on the occupancy status in recent years, but little work on whether the free slot is compatible with the mission of the ego vehicle or not. For instance, some spots are handicap or electric vehicles accessible only. In this paper, we tackle parking spot classification based on the surround view camera system. We adapt the object detection neural network YOLOv4 with a novel polygon bounding box model that is well-suited for various shaped parking spaces, such as slanted parking slots. To the best of our knowledge, we present the first detailed study on parking spot detection and classification on fisheye cameras for auto valet parking scenarios. The results prove that our proposed classification approach is effective to distinguish between regular, electric vehicle, and handicap parking spots.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Comprehensive Multimodal Segmentation in Medical Imaging: Combining  YOLOv8 with SAM and HQ-SAM Models</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12995</p>
  <p><b>作者</b>：Sumit Pandey,  Kuan-Fu Chen,  Erik B. Dam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical imaging datasets, diverse medical imaging, X-ray images, encompassing ultrasound, SAM model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a comprehensive approach for segmenting regions of interest (ROI) in diverse medical imaging datasets, encompassing ultrasound, CT scans, and X-ray images. The proposed method harnesses the capabilities of the YOLOv8 model for approximate boundary box detection across modalities, alongside the Segment Anything Model (SAM) and High Quality (HQ) SAM for fully automatic and precise segmentation. To generate boundary boxes, the YOLOv8 model was trained using a limited set of 100 images and masks from each modality. The results obtained from our approach are extensively computed and analyzed, demonstrating its effectiveness and potential in medical image analysis. Various evaluation metrics, including precision, recall, F1 score, and Dice Score, were employed to quantify the accuracy of the segmentation results. A comparative analysis was conducted to assess the individual and combined performance of the YOLOv8, YOLOv8+SAM, and YOLOv8+HQ-SAM models. The results indicate that the SAM model performs better than the other two models, exhibiting higher segmentation accuracy and overall performance. While HQ-SAM offers potential advantages, its incremental gains over the standard SAM model may not justify the additional computational cost. The YOLOv8+SAM model shows promise for enhancing medical image segmentation and its clinical implications.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Wave-informed dictionary learning for high-resolution imaging in complex  media</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12990</p>
  <p><b>作者</b>：Miguel Moscoso,  Alexei Novikov,  George Papanicolaou,  Chrysoula Tsogka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse data sets, sensing matrix, diverse data, step, scattering media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an approach for imaging in scattering media when large and diverse data sets are available. It has two steps. Using a dictionary learning algorithm the first step estimates the true Green's function vectors as columns in an unordered sensing matrix. The array data comes from many sparse sets of sources whose location and strength are not known to us. In the second step, the columns of the estimated sensing matrix are ordered for imaging using Multi-Dimensional Scaling with connectivity information derived from cross-correlations of its columns, as in time reversal. For these two steps to work together we need data from large arrays of receivers so the columns of the sensing matrix are incoherent for the first step, as well as from sub-arrays so that they are coherent enough to obtain the connectivity needed in the second step. Through simulation experiments, we show that the proposed approach is able to provide images in complex media whose resolution is that of a homogeneous medium.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Enabling energy-Efficient object detection with surrogate gradient  descent in spiking neural networks</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12985</p>
  <p><b>作者</b>：Jilong Luo,  Shanlin Xiao,  Yinsheng Chen,  Zhiyi Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Spiking Neural Networks, plausible neural network, neural network model, biologically plausible neural, spatio-temporal information processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Networks (SNNs) are a biologically plausible neural network model with significant advantages in both event-driven processing and spatio-temporal information processing, rendering SNNs an appealing choice for energyefficient object detection. However, the non-differentiability of the biological neuronal dynamics model presents a challenge during the training of SNNs. Furthermore, a suitable decoding strategy for object detection in SNNs is currently lacking. In this study, we introduce the Current Mean Decoding (CMD) method, which solves the regression problem to facilitate the training of deep SNNs for object detection tasks. Based on the gradient surrogate and CMD, we propose the SNN-YOLOv3 model for object detection. Our experiments demonstrate that SNN-YOLOv3 achieves a remarkable performance with an mAP of 61.87% on the PASCAL VOC dataset, requiring only 6 time steps. Compared to SpikingYOLO, we have managed to increase mAP by nearly 10% while reducing energy consumption by two orders of magnitude.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Skin Lesion Segmentation Improved by Transformer-based Networks with  Inter-scale Dependency Modeling</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13604</p>
  <p><b>作者</b>：Sania Eskandari,  Janet Lumpp,  Luis Sanchez Giraldo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：skin cell growth, skin cancer resulting, abnormal skin cell, Fully Convolutional Networks, skin lesion segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Melanoma, a dangerous type of skin cancer resulting from abnormal skin cell growth, can be treated if detected early. Various approaches using Fully Convolutional Networks (FCNs) have been proposed, with the U-Net architecture being prominent To aid in its diagnosis through automatic skin lesion segmentation. However, the symmetrical U-Net model's reliance on convolutional operations hinders its ability to capture long-range dependencies crucial for accurate medical image segmentation. Several Transformer-based U-Net topologies have recently been created to overcome this limitation by replacing CNN blocks with different Transformer modules to capture local and global representations. Furthermore, the U-shaped structure is hampered by semantic gaps between the encoder and decoder. This study intends to increase the network's feature re-usability by carefully building the skip connection path. Integrating an already calculated attention affinity within the skip connection path improves the typical concatenation process utilized in the conventional skip connection path. As a result, we propose a U-shaped hierarchical Transformer-based structure for skin lesion segmentation and an Inter-scale Context Fusion (ISCF) method that uses attention correlations in each stage of the encoder to adaptively combine the contexts from each stage to mitigate semantic gaps. The findings from two skin lesion segmentation benchmarks support the ISCF module's applicability and effectiveness. The code is publicly available at \url{this https URL}</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Progressive Dual Priori Network for Generalized Breast Tumor  Segmentation</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13574</p>
  <p><b>作者</b>：Li Wang,  Lihui Wang,  Zixiang Kuai,  Lei Tang,  Yingfeng Ou,  Chen Ye,  Yuemin Zhu</p>
  <p><b>备注</b>：12 pages, 10 figures</p>
  <p><b>关键词</b>：amd irregular shape, magnetic resonance images, dynamic enhanced magnetic, enhanced magnetic resonance, dual priori network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To promote the generalization ability of breast tumor segmentation models, as well as to improve the segmentation performance for breast tumors with smaller size, low-contrast amd irregular shape, we propose a progressive dual priori network (PDPNet) to segment breast tumors from dynamic enhanced magnetic resonance images (DCE-MRI) acquired at different sites. The PDPNet first cropped tumor regions with a coarse-segmentation based localization module, then the breast tumor mask was progressively refined by using the weak semantic priori and cross-scale correlation prior knowledge. To validate the effectiveness of PDPNet, we compared it with several state-of-the-art methods on multi-center datasets. The results showed that, comparing against the suboptimal method, the DSC, SEN, KAPPA and HD95 of PDPNet were improved 3.63\%, 8.19\%, 5.52\%, and 3.66\% respectively. In addition, through ablations, we demonstrated that the proposed localization module can decrease the influence of normal tissues and therefore improve the generalization ability of the model. The weak semantic priors allow focusing on tumor regions to avoid missing small tumors and low-contrast tumors. The cross-scale correlation priors are beneficial for promoting the shape-aware ability for irregual tumors. Thus integrating them in a unified framework improved the multi-center breast tumor segmentation performance.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：DeepFDR: A Deep Learning-based False Discovery Rate Control Method for  Neuroimaging Data</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13349</p>
  <p><b>作者</b>：Taehyo Kim,  Hai Shu,  Qiran Jia,  Mony de Leon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：FDR control, spatial FDR control, Voxel-based multiple testing, Voxel-based multiple, FDR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but also boasts exceptional computational efficiency highly suited for tackling large-scale neuroimaging data.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Non-Negative Spherical Relaxations for Universe-Free Multi-Matching and  Clustering</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13311</p>
  <p><b>作者</b>：Johan Thunberg,  Florian Bernard</p>
  <p><b>备注</b>：Published at Scandinavian Conference on Image Analysis (SCIA) 2023</p>
  <p><b>关键词</b>：non-negative spherical relaxation, spherical relaxation, matrices with injectivity, non-negative spherical, injectivity constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel non-negative spherical relaxation for optimization problems over binary matrices with injectivity constraints, which in particular has applications in multi-matching and clustering. We relax respective binary matrix constraints to the (high-dimensional) non-negative sphere. To optimize our relaxed problem, we use a conditional power iteration method to iteratively improve the objective function, while at same time sweeping over a continuous scalar parameter that is (indirectly) related to the universe size (or number of clusters). Opposed to existing procedures that require to fix the integer universe size before optimization, our method automatically adjusts the analogous continuous parameter. Furthermore, while our approach shares similarities with spectral multi-matching and spectral clustering, our formulation has the strong advantage that we do not rely on additional post-processing procedures to obtain binary results. Our method shows compelling results in various multi-matching and clustering settings, even when compared to methods that use the ground truth universe size (or number of clusters).</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Pathologist-Like Explanations Unveiled: an Explainable Deep Learning  System for White Blood Cell Classification</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13279</p>
  <p><b>作者</b>：Aditya Shankar Pal,  Debojyoti Biswas,  Joy Mahapatra,  Debasis Banerjee,  Prantar Chakrabarti,  Utpal Garain</p>
  <p><b>备注</b>：11 pages including supplementary material</p>
  <p><b>关键词</b>：play a crucial, foreign substances, crucial role, role in safeguarding, safeguarding the human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>White blood cells (WBCs) play a crucial role in safeguarding the human body against pathogens and foreign substances. Leveraging the abundance of WBC imaging data and the power of deep learning algorithms, automated WBC analysis has the potential for remarkable accuracy. However, the capability of deep learning models to explain their WBC classification remains largely unexplored. In this study, we introduce HemaX, an explainable deep neural network-based model that produces pathologist-like explanations using five attributes: granularity, cytoplasm color, nucleus shape, size relative to red blood cells, and nucleus to cytoplasm ratio (N:C), along with cell classification, localization, and segmentation. HemaX is trained and evaluated on a novel dataset, LeukoX, comprising 467 blood smear images encompassing ten (10) WBC types. The proposed model achieves impressive results, with an average classification accuracy of 81.08% and a Jaccard index of 89.16% for cell localization. Additionally, HemaX performs well in generating the five explanations with a normalized mean square error of 0.0317 for N:C ratio and over 80% accuracy for the other four attributes. Comprehensive experiments comparing against multiple state-of-the-art models demonstrate that HemaX's classification accuracy remains unaffected by its ability to provide explanations. Moreover, empirical analyses and validation by expert hematologists confirm the faithfulness of explanations predicted by our proposed model.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Domain-specific optimization and diverse evaluation of self-supervised  models for histopathology</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13259</p>
  <p><b>作者</b>：Jeremy Lai,  Faruk Ahmed,  Supriya Vijay,  Tiam Jaroensri,  Jessica Loo,  Saurabh Vyawahare,  Saloni Agarwal,  Fayaz Jamil,  Yossi Matias,  Greg S. Corrado,  Dale R. Webster,  Jonathan Krause,  Yun Liu,  Po-Hsuan Cameron Chen,  Ellery Wulczyn,  David F. Steiner</p>
  <p><b>备注</b>：4 main tables, 3 main figures, additional supplemental tables and figures</p>
  <p><b>关键词</b>：offer promising opportunities, Task-specific deep learning, deep learning models, improving diagnosis, precision medicine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Task-specific deep learning models in histopathology offer promising opportunities for improving diagnosis, clinical research, and precision medicine. However, development of such models is often limited by availability of high-quality data. Foundation models in histopathology that learn general representations across a wide range of tissue types, diagnoses, and magnifications offer the potential to reduce the data, compute, and technical expertise necessary to develop task-specific deep learning models with the required level of model performance. In this work, we describe the development and evaluation of foundation models for histopathology via self-supervised learning (SSL). We first establish a diverse set of benchmark tasks involving 17 unique tissue types and 12 unique cancer types and spanning different optimal magnifications and task types. Next, we use this benchmark to explore and evaluate histopathology-specific SSL methods followed by further evaluation on held out patch-level and weakly supervised tasks. We found that standard SSL methods thoughtfully applied to histopathology images are performant across our benchmark tasks and that domain-specific methodological improvements can further increase performance. Our findings reinforce the value of using domain-specific SSL methods in pathology, and establish a set of high quality foundation models to enable further research across diverse applications.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Diagnosis-oriented Medical Image Compression with Efficient Transfer  Learning</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13250</p>
  <p><b>作者</b>：Guangqi Xie,  Xin Li,  Xiaohan Pan,  Zhibo Chen</p>
  <p><b>备注</b>：Accepted by IEEE VCIP</p>
  <p><b>关键词</b>：intelligent diagnosis devices, Remote medical diagnosis, medical, critical and indispensable, indispensable technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remote medical diagnosis has emerged as a critical and indispensable technique in practical medical systems, where medical data are required to be efficiently compressed and transmitted for diagnosis by either professional doctors or intelligent diagnosis devices. In this process, a large amount of redundant content irrelevant to the diagnosis is subjected to high-fidelity coding, leading to unnecessary transmission costs. To mitigate this, we propose diagnosis-oriented medical image compression, a special semantic compression task designed for medical scenarios, targeting to reduce the compression cost without compromising the diagnosis accuracy. However, collecting sufficient medical data to optimize such a compression system is significantly expensive and challenging due to privacy issues and the lack of professional annotation. In this study, we propose DMIC, the first efficient transfer learning-based codec, for diagnosis-oriented medical image compression, which can be effectively optimized with only few-shot annotated medical examples, by reusing the knowledge in the existing reinforcement learning-based task-driven semantic coding framework, i.e., HRLVSC [1]. Concretely, we focus on tuning only the partial parameters of the policy network for bit allocation within HRLVSC, which enables it to adapt to the medical images. In this work, we validate our DMIC with the typical medical task, Coronary Artery Segmentation. Extensive experiments have demonstrated that our DMIC can achieve 47.594%BD-Rate savings compared to the HEVC anchor, by tuning only the A2C module (2.7% parameters) of the policy network with only 1 medical sample.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：PTSR: Patch Translator for Image Super-Resolution</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13216</p>
  <p><b>作者</b>：Neeraj Baghel,  Shiv Ram Dubey,  Satish Kumar Singh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：super-resolution generation aims, Image super-resolution generation, generation aims, Image super-resolution, high-resolution image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image super-resolution generation aims to generate a high-resolution image from its low-resolution image. However, more complex neural networks bring high computational costs and memory storage. It is still an active area for offering the promise of overcoming resolution limitations in many applications. In recent years, transformers have made significant progress in computer vision tasks as their robust self-attention mechanism. However, recent works on the transformer for image super-resolution also contain convolution operations. We propose a patch translator for image super-resolution (PTSR) to address this problem. The proposed PTSR is a transformer-based GAN network with no convolution operation. We introduce a novel patch translator module for regenerating the improved patches utilising multi-head attention, which is further utilised by the generator to generate the 2x and 4x super-resolution images. The experiments are performed using benchmark datasets, including DIV2K, Set5, Set14, and BSD100. The results of the proposed model is improved on an average for $4\times$ super-resolution by 21.66% in PNSR score and 11.59% in SSIM score, as compared to the best competitive models. We also analyse the proposed loss and saliency map to show the effectiveness of the proposed method.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Streamlining Brain Tumor Classification with Custom Transfer Learning in  MRI Images</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13108</p>
  <p><b>作者</b>：Javed Hossain,  Md. Touhidul Islam,  Md. Taufiqul Haque Khan Tusar</p>
  <p><b>备注</b>：6 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：cases diagnosed globally, Magnetic Resonance Imaging, Brain tumors, increasingly prevalent, globally each year</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain tumors are increasingly prevalent, characterized by the uncontrolled spread of aberrant tissues in the brain, with almost 700,000 new cases diagnosed globally each year. Magnetic Resonance Imaging (MRI) is commonly used for the diagnosis of brain tumors and accurate classification is a critical clinical procedure. In this study, we propose an efficient solution for classifying brain tumors from MRI images using custom transfer learning networks. While several researchers have employed various pre-trained architectures such as RESNET-50, ALEXNET, VGG-16, and VGG-19, these methods often suffer from high computational complexity. To address this issue, we present a custom and lightweight model using a Convolutional Neural Network-based pre-trained architecture with reduced complexity. Specifically, we employ the VGG-19 architecture with additional hidden layers, which reduces the complexity of the base architecture but improves computational efficiency. The objective is to achieve high classification accuracy using a novel approach. Finally, the result demonstrates a classification accuracy of 96.42%.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Spec-NeRF: Multi-spectral Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12987</p>
  <p><b>作者</b>：Jiabao Li,  Yuqi Li,  Ciliang Sun,  Chong Wang,  Jinhui Xiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-spectral Neural Radiance, propose Multi-spectral Neural, Neural Radiance Fields, Multi-spectral Neural, multispectral radiance field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Multi-spectral Neural Radiance Fields(Spec-NeRF) for jointly reconstructing a multispectral radiance field and spectral sensitivity functions(SSFs) of the camera from a set of color images filtered by different filters. The proposed method focuses on modeling the physical imaging process, and applies the estimated SSFs and radiance field to synthesize novel views of multispectral scenes. In this method, the data acquisition requires only a low-cost trichromatic camera and several off-the-shelf color filters, making it more practical than using specialized 3D scanning and spectral imaging equipment. Our experiments on both synthetic and real scenario datasets demonstrate that utilizing filtered RGB images with learnable NeRF and SSFs can achieve high fidelity and promising spectral reconstruction while retaining the inherent capability of NeRF to comprehend geometric structures. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：DA-TransUNet: Integrating Spatial and Channel Dual Attention with  Transformer U-Net for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12570</p>
  <p><b>作者</b>：Guanqun Sun,  Yizhi Pan,  Weikun Kong,  Zichang Xu,  Jianhua Ma,  Teeradaj Racharak,  Le-Minh Nguyen,  Junyi Xin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image segmentation, deep representation learning, powerful deep representation, image segmentation, image segmentation due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Great progress has been made in automatic medical image segmentation due to powerful deep representation learning. The influence of transformer has led to research into its variants, and large-scale replacement of traditional CNN modules. However, such trend often overlooks the intrinsic feature extraction capabilities of the transformer and potential refinements to both the model and the transformer module through minor adjustments. This study proposes a novel deep medical image segmentation framework, called DA-TransUNet, aiming to introduce the Transformer and dual attention block into the encoder and decoder of the traditional U-shaped architecture. Unlike prior transformer-based solutions, our DA-TransUNet utilizes attention mechanism of transformer and multifaceted feature extraction of DA-Block, which can efficiently combine global, local, and multi-scale features to enhance medical image segmentation. Meanwhile, experimental results show that a dual attention block is added before the Transformer layer to facilitate feature extraction in the U-net structure. Furthermore, incorporating dual attention blocks in skip connections can enhance feature transfer to the decoder, thereby improving image segmentation performance. Experimental results across various benchmark of medical image segmentation reveal that DA-TransUNet significantly outperforms the state-of-the-art methods. The codes and parameters of our model will be publicly available at this https URL.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Exploring Linguistic Probes for Morphological Generalization</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13686</p>
  <p><b>作者</b>：Jordan Kodner,  Salam Khalifa,  Sarah Payne</p>
  <p><b>备注</b>：to appear at EMNLP 2023</p>
  <p><b>关键词</b>：data splitting algorithms, cross-linguistic computational modeling, typically employed language-independent, employed language-independent data, language-independent data splitting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern work on the cross-linguistic computational modeling of morphological inflection has typically employed language-independent data splitting algorithms. In this paper, we supplement that approach with language-specific probes designed to test aspects of morphological generalization. Testing these probes on three morphologically distinct languages, English, Spanish, and Swahili, we find evidence that three leading morphological inflection systems employ distinct generalization strategies over conjugational classes and feature sets on both orthographic and phonologically transcribed inputs.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Optimizing Retrieval-augmented Reader Models via Token Elimination</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13682</p>
  <p><b>作者</b>：Moshe Berchansky,  Peter Izsak,  Avi Caciularu,  Ido Dagan,  Moshe Wasserblat</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective retrieval-augmented language, retrieval-augmented language model, language model applied, fact checking, open-domain tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model applied across a variety of open-domain tasks, such as question answering, fact checking, etc. In FiD, supporting passages are first retrieved and then processed using a generative model (Reader), which can cause a significant bottleneck in decoding time, particularly with long outputs. In this work, we analyze the contribution and necessity of all the retrieved passages to the performance of reader models, and propose eliminating some of the retrieved information, at the token level, that might not contribute essential information to the answer generation process. We demonstrate that our method can reduce run-time by up to 62.2%, with only a 2% reduction in performance, and in some cases, even improve the performance results.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Improving Long-form Speech Translation through Segmentation with Large  Language Models and Finite State Decoding Constraints</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13678</p>
  <p><b>作者</b>：Arya D. McCarthy,  Hao Zhang,  Shankar Kumar,  Felix Stahlberg,  Ke Wu</p>
  <p><b>备注</b>：accepted to the Findings of EMNLP 2023. arXiv admin note: text overlap with arXiv:2212.09895</p>
  <p><b>关键词</b>：obtaining high-quality translations, spoken language translation, content is long-form, spoken content, short units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One challenge in spoken language translation is that plenty of spoken content is long-form, but short units are necessary for obtaining high-quality translations. To address this mismatch, we adapt large language models (LLM) to split long ASR transcripts into segments that can be independently translated so as to maximize the overall translation quality. To combat the tendency of hallucination by LLMs, we incorporate finite-state constraints during decoding to eliminate invalid outputs. We discover that LLMs are adaptable to transcripts containing ASR errors through prompt-tuning or fine-tuning. In comparison to a state-of-the-art automatic punctuation baseline, our best LLM improves the average BLEU for English-German, English-Spanish, and English-Arabic TED talk translation in 9 test sets by 2.9 points, just by improving segmentation.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Information Value: Measuring Utterance Predictability as Distance from  Plausible Alternatives</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13676</p>
  <p><b>作者</b>：Mario Giulianelli,  Sarenne Wallbridge,  Raquel Fernández</p>
  <p><b>备注</b>：EMNLP 2023 (Main, Long paper)</p>
  <p><b>关键词</b>：plausible alternatives, measure which quantifies, set of plausible, present information, utterance relative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present information value, a measure which quantifies the predictability of an utterance relative to a set of plausible alternatives. We introduce a method to obtain interpretable estimates of information value using neural text generators, and exploit their psychometric predictive power to investigate the dimensions of predictability that drive human comprehension behaviour. Information value is a stronger predictor of utterance acceptability in written and spoken dialogue than aggregates of token-level surprisal and it is complementary to surprisal for predicting eye-tracked reading times.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：On Synthetic Data for Back Translation</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13675</p>
  <p><b>作者</b>：Jiahao Xu,  Yubin Ruan,  Wei Bi,  Guoping Huang,  Shuming Shi,  Lihui Chen,  Lemao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NMT research fields, generate synthetic data, synthetic data, Back translation, research fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Back translation (BT) is one of the most significant technologies in NMT research fields. Existing attempts on BT share a common characteristic: they employ either beam search or random sampling to generate synthetic data with a backward model but seldom work studies the role of synthetic data in the performance of BT. This motivates us to ask a fundamental question: {\em what kind of synthetic data contributes to BT performance?} Through both theoretical and empirical studies, we identify two key factors on synthetic data controlling the back-translation NMT performance, which are quality and importance. Furthermore, based on our findings, we propose a simple yet effective method to generate synthetic data to better trade off both factors so as to yield a better performance for BT. We run extensive experiments on WMT14 DE-EN, EN-DE, and RU-EN benchmark tasks. By employing our proposed method to generate synthetic data, our BT model significantly outperforms the standard BT baselines (i.e., beam and sampling based methods for data generation), which proves the effectiveness of our proposed methods.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large  Language Models</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13673</p>
  <p><b>作者</b>：Sullam Jeoung,  Yubin Ge,  Jana Diesner</p>
  <p><b>备注</b>：Accepted to EMNLP 2023</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, Stereotype Content Model, Warmth and Competence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have been observed to encode and perpetuate harmful associations present in the training data. We propose a theoretically grounded framework called StereoMap to gain insights into their perceptions of how demographic groups have been viewed by society. The framework is grounded in the Stereotype Content Model (SCM); a well-established theory from psychology. According to SCM, stereotypes are not all alike. Instead, the dimensions of Warmth and Competence serve as the factors that delineate the nature of stereotypes. Based on the SCM theory, StereoMap maps LLMs' perceptions of social groups (defined by socio-demographic features) using the dimensions of Warmth and Competence. Furthermore, the framework enables the investigation of keywords and verbalizations of reasoning of LLMs' judgments to uncover underlying factors influencing their perceptions. Our results show that LLMs exhibit a diverse range of perceptions towards these groups, characterized by mixed evaluations along the dimensions of Warmth and Competence. Furthermore, analyzing the reasonings of LLMs, our findings indicate that LLMs demonstrate an awareness of social disparities, often stating statistical data and research findings to support their reasoning. This study contributes to the understanding of how LLMs perceive and represent social groups, shedding light on their potential biases and the perpetuation of harmful associations.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large  Language Models by Extrapolating Errors from Small Models</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13671</p>
  <p><b>作者</b>：Ruida Wang,  Wangchunshu Zhou,  Mrinmaya Sachan</p>
  <p><b>备注</b>：Accepted by EMNLP 2023(Findings)</p>
  <p><b>关键词</b>：Data Synthesis, small model, small model trained, Data, Synthesis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>*Data Synthesis* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the *real task* data distribution. Thus, in this paper, we propose *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Automatic Unit Test Data Generation and Actor-Critic Reinforcement  Learning for Code Synthesis</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13669</p>
  <p><b>作者</b>：Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci</p>
  <p><b>备注</b>：9 pages + 4 pages appendix; 4 Figures, 4 Tables, 1 Algorithm; Accepted to Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Natural Language Generation, similar to Natural, Unit Tests, Language Modelling, Language Generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics -- through the use of Unit Tests to check its functional correctness -- lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models' coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model's performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Explainability, Interpretability, Depression detection, Social Media</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13664</p>
  <p><b>作者</b>：Eliseo Bao Souto,  Anxo Pérez,  Javier Parapar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mental health issues, perceive these sites, sites as supportive, supportive spaces, spaces to post</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Users of social platforms often perceive these sites as supportive spaces to post about their mental health issues. Those conversations contain important traces about individuals' health risks. Recently, researchers have exploited this online information to construct mental health detection models, which aim to identify users at risk on platforms like Twitter, Reddit or Facebook. Most of these models are centred on achieving good classification results, ignoring the explainability and interpretability of the decisions. Recent research has pointed out the importance of using clinical markers, such as the use of symptoms, to improve trust in the computational models by health professionals. In this paper, we propose using transformer-based architectures to detect and explain the appearance of depressive symptom markers in the users' writings. We present two approaches: $i)$ train a model to classify, and another one to explain the classifier's decision separately and $ii)$ unify the two tasks simultaneously using a single model. Additionally, for this latter manner, we also investigated the performance of recent conversational LLMs when using in-context learning. Our natural language explanations enable clinicians to interpret the models' decisions based on validated symptoms, enhancing trust in the automated process. We evaluate our approach using recent symptom-based datasets, employing both offline and expert-in-the-loop metrics to assess the quality of the explanations generated by our models. The experimental results show that it is possible to achieve good classification results while generating interpretable symptom-based explanations.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Arabic Dialect Identification under Scrutiny: Limitations of  Single-label Classification</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13661</p>
  <p><b>作者</b>：Amr Keleg,  Walid Magdy</p>
  <p><b>备注</b>：Accepted to the ArabicNLP 2023 conference co-located with EMNLP 2023</p>
  <p><b>关键词</b>：Arabic Dialect Identification, gained great popularity, Automatic Arabic Dialect, Dialect Identification, Automatic Arabic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic Arabic Dialect Identification (ADI) of text has gained great popularity since it was introduced in the early 2010s. Multiple datasets were developed, and yearly shared tasks have been running since 2018. However, ADI systems are reported to fail in distinguishing between the micro-dialects of Arabic. We argue that the currently adopted framing of the ADI task as a single-label classification problem is one of the main reasons for that. We highlight the limitation of the incompleteness of the Dialect labels and demonstrate how it impacts the evaluation of ADI systems. A manual error analysis for the predictions of an ADI, performed by 7 native speakers of different Arabic dialects, revealed that $\approx$ 66% of the validated errors are not true errors. Consequently, we propose framing ADI as a multi-label classification task and give recommendations for designing new ADI datasets.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Benchmarking and Improving Text-to-SQL Generation under Ambiguity</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13659</p>
  <p><b>作者</b>：Adithya Bhaskar,  Tushar Tomar,  Ashutosh Sathe,  Sunita Sarawagi</p>
  <p><b>备注</b>：To appear at EMNLP 2023 (Main)</p>
  <p><b>关键词</b>：text query corresponds, largely benchmarked, benchmarked against datasets, query corresponds, correct SQL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in Text-to-SQL conversion has been largely benchmarked against datasets where each text query corresponds to one correct SQL. However, natural language queries over real-life databases frequently involve significant ambiguity about the intended SQL due to overlapping schema names and multiple confusing relationship paths. To bridge this gap, we develop a novel benchmark called AmbiQT with over 3000 examples where each text is interpretable as two plausible SQLs due to lexical and/or structural ambiguity.
When faced with ambiguity, an ideal top-$k$ decoder should generate all valid interpretations for possible disambiguation by the user. We evaluate several Text-to-SQL systems and decoding algorithms, including those employing state-of-the-art LLMs, and find them to be far from this ideal. The primary reason is that the prevalent beam search algorithm and its variants, treat SQL queries as a string and produce unhelpful token-level diversity in the top-$k$.
We propose LogicalBeam, a new decoding algorithm that navigates the SQL logic space using a blend of plan-based template generation and constrained infilling. Counterfactually generated plans diversify templates while in-filling with a beam-search that branches solely on schema names provides value diversity. LogicalBeam is up to $2.5$ times more effective than state-of-the-art models at generating all candidate SQLs in the top-$k$ ranked outputs. It also enhances the top-$5$ Exact and Execution Match Accuracies on SPIDER and Kaggle DBQA.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13650</p>
  <p><b>作者</b>：Haodong Duan,  Jueqi Wei,  Chonghua Wang,  Hongwei Liu,  Yixiao Fang,  Songyang Zhang,  Dahua Lin,  Kai Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, key feature, dialogues, multi-turn, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interacting with human via high-quality multi-turn dialogues is a key feature of large language models (LLMs). However, human-based evaluation of such capability involves intensive manual labor. This report provides a preliminary evaluation of existing large language models for human-style multi-turn chatting, through an LLM-based approach. We start from real-world human dialogues and keep the very first utterances as the ChatSEED. Then we prompt LLMs to generate a full multi-turn dialogue (tens of utterances) based on the ChatSEED, utterance by utterance. Finally, we adopt state-of-the-art LLMs (GPT-4, \etc) as the judge to evaluate the generated dialogues. With different evaluation protocols, we come to substantially identical conclusions. We find that GPT-4 can generate human-style multi-turn dialogues with impressive quality, significantly outperforms its counterparts. It's difficult for a discriminator to distinguish between GPT-4 generated dialogues and human dialogues. In contrast, other LLMs struggle to generate multi-turn dialogues of satisfactory quality due to poor instruction-following capability, tendency to generate lengthy utterances, or limited general capability. All data and codes will be provided in this https URL and we hope they can serve as a valuable resource for evaluating multi-turn chatting capabilities of LLMs.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Bridging Information-Theoretic and Geometric Compression in Language  Models</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13620</p>
  <p><b>作者</b>：Emily Cheng,  Corentin Kervadec,  Marco Baroni</p>
  <p><b>备注</b>：EMNLP 2023 Camera-Ready</p>
  <p><b>关键词</b>：model human language, faithfully model human, potentially infinite information, potentially infinite, language model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For a language model (LM) to faithfully model human language, it must compress vast, potentially infinite information into relatively few dimensions. We propose analyzing compression in (pre-trained) LMs from two points of view: geometric and information-theoretic. We demonstrate that the two views are highly correlated, such that the intrinsic geometric dimension of linguistic data predicts their coding length under the LM. We then show that, in turn, high compression of a linguistic dataset predicts rapid adaptation to that dataset, confirming that being able to compress linguistic information is an important part of successful LM performance. As a practical byproduct of our analysis, we evaluate a battery of intrinsic dimension estimators for the first time on linguistic data, showing that only some encapsulate the relationship between information-theoretic compression, geometric compression, and ease-of-adaptation.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Semi-supervised multimodal coreference resolution in image narrations</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13619</p>
  <p><b>作者</b>：Arushi Goel,  Basura Fernando,  Frank Keller,  Hakan Bilen</p>
  <p><b>备注</b>：Long paper at EMNLP'23-Main</p>
  <p><b>关键词</b>：longer descriptive text, descriptive text, longer descriptive, narration is paired, study multimodal coreference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study multimodal coreference resolution, specifically where a longer descriptive text, i.e., a narration is paired with an image. This poses significant challenges due to fine-grained image-text alignment, inherent ambiguity present in narrative language, and unavailability of large annotated training sets. To tackle these challenges, we present a data efficient semi-supervised approach that utilizes image-narration pairs to resolve coreferences and narrative grounding in a multimodal context. Our approach incorporates losses for both labeled and unlabeled data within a cross-modal framework. Our evaluation shows that the proposed approach outperforms strong baselines both quantitatively and qualitatively, for the tasks of coreference resolution and narrative grounding.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Three Questions Concerning the Use of Large Language Models to  Facilitate Mathematics Learning</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13615</p>
  <p><b>作者</b>：An-Zi Yen,  Wei-Ling Hsu</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 Findings</p>
  <p><b>关键词</b>：large language models, remarkable language understanding, language models, remarkable language, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the remarkable language understanding and generation abilities of large language models (LLMs), their use in educational applications has been explored. However, little work has been done on investigating the pedagogical ability of LLMs in helping students to learn mathematics. In this position paper, we discuss the challenges associated with employing LLMs to enhance students' mathematical problem-solving skills by providing adaptive feedback. Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions' rationales when attempting to correct students' answers. Three research questions are formulated.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Hunayn: Elevating Translation Beyond the Literal</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13613</p>
  <p><b>作者</b>：Nasser Almousa,  Nasser Alzamil,  Abdullah Alshehri,  Ahmad Sait</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：translator surpassing conventional, surpassing conventional tools, introduces an advanced, translator surpassing, conventional tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This project introduces an advanced English-to-Arabic translator surpassing conventional tools. Leveraging the Helsinki transformer (MarianMT), our approach involves fine-tuning on a self-scraped, purely literary Arabic dataset. Evaluations against Google Translate show consistent outperformance in qualitative assessments. Notably, it excels in cultural sensitivity and context accuracy. This research underscores the Helsinki transformer's superiority for English-to-Arabic translation using a Fusha dataset.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Make Your Decision Convincing! A Unified Two-Stage Framework:  Self-Attribution and Decision-Making</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13610</p>
  <p><b>作者</b>：Yanrui Du,  Sendong Zhao,  Haochun Wang,  Yuhan Chen,  Rui Bai,  Zewen Qiang,  Muzhen Cai,  Bing Qin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Explaining black-box model, black-box model behavior, achieved impressive results, NLP tasks, Explaining black-box</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining black-box model behavior with natural language has achieved impressive results in various NLP tasks. Recent research has explored the utilization of subsequences from the input text as a rationale, providing users with evidence to support the model decision. Although existing frameworks excel in generating high-quality rationales while achieving high task performance, they neglect to account for the unreliable link between the generated rationale and model decision. In simpler terms, a model may make correct decisions while attributing wrong rationales, or make poor decisions while attributing correct rationales. To mitigate this issue, we propose a unified two-stage framework known as Self-Attribution and Decision-Making (SADM). Through extensive experiments on five reasoning datasets from the ERASER benchmark, we demonstrate that our framework not only establishes a more reliable link between the generated rationale and model decision but also achieves competitive results in task performance and the quality of rationale. Furthermore, we explore the potential of our framework in semi-supervised scenarios.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection  Benchmark</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13606</p>
  <p><b>作者</b>：Dominik Macko,  Robert Moro,  Adaku Uchendu,  Jason Samuel Lucas,  Michiharu Yamashita,  Matúš Pikuliak,  Ivan Srba,  Thai Le,  Dongwon Lee,  Jakub Simko,  Maria Bielikova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate convincing text, multilingual machine-generated text, research into capabilities, capabilities of recent, generate convincing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings. This is also reflected in the available benchmarks which lack authentic texts in languages other than English and predominantly cover older generators. To fill this gap, we introduce MULTITuDE, a novel benchmarking dataset for multilingual machine-generated text detection comprising of 74,081 authentic and machine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare the performance of zero-shot (statistical and black-box) and fine-tuned detectors. Considering the multilinguality, we evaluate 1) how these detectors generalize to unseen languages (linguistically similar as well as dissimilar) and unseen LLMs and 2) whether the detectors improve their performance when trained on multiple languages.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：MarineGPT: Unlocking Secrets of Ocean to the Public</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13596</p>
  <p><b>作者</b>：Ziqiang Zheng,  Jipeng Zhang,  Tuan-Anh Vu,  Shizhe Diao,  Yue Him Wong Tim,  Sai-Kit Yeung</p>
  <p><b>备注</b>：work in progress. Code and data will be available at this https URL</p>
  <p><b>关键词</b>：Large language models, textbf, Large language, powerful tools, tools in promoting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs), such as ChatGPT/GPT-4, have proven to be powerful tools in promoting the user experience as an AI assistant. The continuous works are proposing multi-modal large language models (MLLM), empowering LLMs with the ability to sense multiple modality inputs through constructing a joint semantic space (e.g. visual-text space). Though significant success was achieved in LLMs and MLLMs, exploring LLMs and MLLMs in domain-specific applications that required domain-specific knowledge and expertise has been less conducted, especially for \textbf{marine domain}. Different from general-purpose MLLMs, the marine-specific MLLM is required to yield much more \textbf{sensitive}, \textbf{informative}, and \textbf{scientific} responses. In this work, we demonstrate that the existing MLLMs optimized on huge amounts of readily available general-purpose training data show a minimal ability to understand domain-specific intents and then generate informative and satisfactory responses. To address these issues, we propose \textbf{MarineGPT}, the first vision-language model specially designed for the marine domain, unlocking the secrets of the ocean to the public. We present our \textbf{Marine-5M} dataset with more than 5 million marine image-text pairs to inject domain-specific marine knowledge into our model and achieve better marine vision and language alignment. Our MarineGPT not only pushes the boundaries of marine understanding to the general public but also offers a standard protocol for adapting a general-purpose assistant to downstream domain-specific experts. We pave the way for a wide range of marine applications while setting valuable data and pre-trained models for future research in both academic and industrial communities.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Simultaneous Machine Translation with Tailored Reference</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13588</p>
  <p><b>作者</b>：Shoutao Guo,  Shaolei Zhang,  Yang Feng</p>
  <p><b>备注</b>：Accepted to EMNLP 2023; 15 pages, 8 figures</p>
  <p><b>关键词</b>：Simultaneous machine translation, Simultaneous machine, SiMT, SiMT models, source sentence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simultaneous machine translation (SiMT) generates translation while reading the whole source sentence. However, existing SiMT models are typically trained using the same reference disregarding the varying amounts of available source information at different latency. Training the model with ground-truth at low latency may introduce forced anticipations, whereas utilizing reference consistent with the source word order at high latency results in performance degradation. Consequently, it is crucial to train the SiMT model with appropriate reference that avoids forced anticipations during training while maintaining high quality. In this paper, we propose a novel method that provides tailored reference for the SiMT models trained at different latency by rephrasing the ground-truth. Specifically, we introduce the tailor, induced by reinforcement learning, to modify ground-truth to the tailored reference. The SiMT model is trained with the tailored reference and jointly optimized with the tailor to enhance performance. Importantly, our method is applicable to a wide range of current SiMT approaches. Experiments on three translation tasks demonstrate that our method achieves state-of-the-art performance in both fixed and adaptive policies.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13583</p>
  <p><b>作者</b>：Ofir Arviv,  Dmitry Nikolaev,  Taelin Karidi,  Omri Abend</p>
  <p><b>备注</b>：Accepted to EMNLP Findings 2023</p>
  <p><b>关键词</b>：tackling typologically-distant languages, low-resource setting, impressive growth, abilities of multilingual, face difficulties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via source- or target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consistently outperforms strong baselines over different language pairs and model architectures. This performance advantage holds true in both zero-shot and few-shot scenarios.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Semantic Decomposition of Question and SQL for Text-to-SQL Parsing</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13575</p>
  <p><b>作者</b>：Ben Eyal,  Amir Bachar,  Ophir Haroche,  Moran Mahabi,  Michael Elhadad</p>
  <p><b>备注</b>：EMNLP 2023 Findings</p>
  <p><b>关键词</b>：QPL, SQL, generalizing to cross-domain, SQL queries, parsing faces challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-SQL semantic parsing faces challenges in generalizing to cross-domain and complex queries. Recent research has employed a question decomposition strategy to enhance the parsing of complex SQL queries. However, this strategy encounters two major obstacles: (1) existing datasets lack question decomposition; (2) due to the syntactic complexity of SQL, most complex queries cannot be disentangled into sub-queries that can be readily recomposed. To address these challenges, we propose a new modular Query Plan Language (QPL) that systematically decomposes SQL queries into simple and regular sub-queries. We develop a translator from SQL to QPL by leveraging analysis of SQL server query optimization plans, and we augment the Spider dataset with QPL programs. Experimental results demonstrate that the modular nature of QPL benefits existing semantic-parsing architectures, and training text-to-QPL parsers is more effective than text-to-SQL parsing for semantically equivalent queries. The QPL approach offers two additional advantages: (1) QPL programs can be paraphrased as simple questions, which allows us to create a dataset of (complex question, decomposed questions). Training on this dataset, we obtain a Question Decomposer for data retrieval that is sensitive to database schemas. (2) QPL is more accessible to non-experts for complex queries, leading to more interpretable output from the semantic parser.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Why Can Large Language Models Generate Correct Chain-of-Thoughts?</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13571</p>
  <p><b>作者</b>：Rasul Tutunov,  Antoine Grosnit,  Juliusz Ziomek,  Jun Wang,  Haitham Bou-Ammar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specifically focusing, paper delves, capabilities of large, focusing on advancing, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper delves into the capabilities of large language models (LLMs), specifically focusing on advancing the theoretical comprehension of chain-of-thought prompting. We investigate how LLMs can be effectively induced to generate a coherent chain of thoughts. To achieve this, we introduce a two-level hierarchical graphical model tailored for natural language generation. Within this framework, we establish a compelling geometrical convergence rate that gauges the likelihood of an LLM-generated chain of thoughts compared to those originating from the true language. Our findings provide a theoretical justification for the ability of LLMs to produce the correct sequence of thoughts (potentially) explaining performance gains in tasks demanding reasoning skills.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Retrieval-Augmented Neural Response Generation Using Logical Reasoning  and Relevance Scoring</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13566</p>
  <p><b>作者</b>：Nicholas Thomas Walker,  Stefan Ultes,  Pierre Lison</p>
  <p><b>备注</b>：Presented at SemDial, August 2023 in Maribor, Slovenia</p>
  <p><b>关键词</b>：current dialogue state, systems typically relies, task-oriented dialogue systems, dialogue systems typically, external databases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Constructing responses in task-oriented dialogue systems typically relies on information sources such the current dialogue state or external databases. This paper presents a novel approach to knowledge-grounded response generation that combines retrieval-augmented language models with logical reasoning. The approach revolves around a knowledge graph representing the current dialogue state and background information, and proceeds in three steps. The knowledge graph is first enriched with logically derived facts inferred using probabilistic logical programming. A neural model is then employed at each turn to score the conversational relevance of each node and edge of this extended graph. Finally, the elements with highest relevance scores are converted to a natural language form, and are integrated into the prompt for the neural conversational model employed to generate the system response.
We investigate the benefits of the proposed approach on two datasets (KVRET and GraphWOZ) along with a human evaluation. Experimental results show that the combination of (probabilistic) logical reasoning with conversational relevance scoring does increase both the factuality and fluency of the responses.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Cache & Distil: Optimising API Calls to Large Language Models</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13561</p>
  <p><b>作者</b>：Guillem Ramírez,  Matthias Lindemann,  Alexandra Birch,  Ivan Titov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Model, costly API calls, smaller language model, fulfil user queries, Language Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deployment of generative AI tools often depends on costly API calls to a Large Language Model (LLM) to fulfil user queries. To curtail the frequency of these calls, one can employ a smaller language model -- a student -- which is continuously trained on the responses of the LLM. This student gradually gains proficiency in independently handling an increasing number of user requests, a process we term neural caching. The crucial element in neural caching is a policy that decides which requests should be processed by the student alone and which should be redirected to the LLM, subsequently aiding the student's learning. In this study, we focus on classification tasks, and we consider a range of classic active learning-based selection criteria as the policy. Our experiments suggest that Margin Sampling and Query by Committee bring consistent benefits across tasks and budgets.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Self-prompted Chain-of-Thought on Large Language Models for Open-domain  Multi-hop Reasoning</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13552</p>
  <p><b>作者</b>：Jinyuan Wang,  Junlong Li,  Hai Zhao</p>
  <p><b>备注</b>：Accepted by Findings of EMNLP2023</p>
  <p><b>关键词</b>：questions require single-hop, require single-hop reasoning, existing questions require, require single-hop, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT selection and self-prompted inference via in-context learning. Extensive experiments on four multi-hop question-answering benchmarks show that our proposed SP-CoT not only significantly surpasses the previous SOTA methods on large-scale (175B) LLMs, but also nearly doubles the zero-shot performance of small-scale (13B) LLMs. Further analysis reveals the remarkable capability of SP-CoT to elicit direct and concise intermediate reasoning steps by recalling $\sim$50\% of intermediate answers on MuSiQue-Ans dataset.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：The Perils & Promises of Fact-checking with Large Language Models</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13549</p>
  <p><b>作者</b>：Dorian Quelle,  Alexandre Bovet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human fact-checking capacity, machine learning, grown vital, vital as misinformation, misinformation spreads</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous fact-checking, using machine learning to verify claims, has grown vital as misinformation spreads beyond human fact-checking capacity. Large Language Models (LLMs) like GPT-4 are increasingly trusted to verify information and write academic papers, lawsuits, and news articles, emphasizing their role in discerning truth from falsehood and the importance of being able to verify their outputs. Here, we evaluate the use of LLM agents in fact-checking by having them phrase queries, retrieve contextual data, and make decisions. Importantly, in our framework, agents explain their reasoning and cite the relevant sources from the retrieved context. Our results show the enhanced prowess of LLMs when equipped with contextual information. GPT-4 outperforms GPT-3, but accuracy varies based on query language and claim veracity. While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy. Our investigation calls for further research, fostering a deeper comprehension of when agents succeed and when they fail.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Towards Understanding Sycophancy in Language Models</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13548</p>
  <p><b>作者</b>：Mrinank Sharma,  Meg Tong,  Tomasz Korbak,  David Duvenaud,  Amanda Askell,  Samuel R. Bowman,  Newton Cheng,  Esin Durmus,  Zac Hatfield-Dodds,  Scott R. Johnston,  Shauna Kravec,  Timothy Maxwell,  Sam McCandlish,  Kamal Ndousse,  Oliver Rausch,  Nicholas Schiefer,  Da Yan,  Miranda Zhang,  Ethan Perez</p>
  <p><b>备注</b>：32 pages, 20 figures</p>
  <p><b>关键词</b>：Reinforcement learning, RLHF, popular technique, technique for training, training high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of RLHF models, likely driven in part by human preference judgements favoring sycophantic responses.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：A Diachronic Perspective on User Trust in AI under Uncertainty</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13544</p>
  <p><b>作者</b>：Shehzaad Dhuliawala,  Vilém Zouhar,  Mennatallah El-Assady,  Mrinmaya Sachan</p>
  <p><b>备注</b>：EMNLP 2023, 14 pages (8+6)</p>
  <p><b>关键词</b>：presents its decision, mental model, Modern NLP systems, user trust, trust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a human-AI collaboration, users build a mental model of the AI system based on its reliability and how it presents its decision, e.g. its presentation of system confidence and an explanation of the output. Modern NLP systems are often uncalibrated, resulting in confidently incorrect predictions that undermine user trust. In order to build trustworthy AI, we must understand how user trust is developed and how it can be regained after potential trust-eroding events. We study the evolution of user trust in response to these trust-eroding events using a betting game. We find that even a few incorrect instances with inaccurate confidence estimates damage user trust and performance, with very slow recovery. We also show that this degradation in trust reduces the success of human-AI collaboration and that different types of miscalibration -- unconfidently correct and confidently incorrect -- have different negative effects on user trust. Our findings highlight the importance of calibration in user-facing AI applications and shed light on what aspects help users decide whether to trust the AI system.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Controlled Randomness Improves the Performance of Transformer Models</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13526</p>
  <p><b>作者</b>：Tobias Deußer,  Cong Zhao,  Wolfgang Krämer,  David Leonhard,  Christian Bauckhage,  Rafet Sifa</p>
  <p><b>备注</b>：Accepted at ICMLA 2023, 10 pages, 2 tables</p>
  <p><b>关键词</b>：requiring large amounts, natural language models, natural language, aforementioned pre-training dataset, pre-training dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the pre-training step of natural language models, the main objective is to learn a general representation of the pre-training dataset, usually requiring large amounts of textual data to capture the complexity and diversity of natural language. Contrasting this, in most cases, the size of the data available to solve the specific downstream task is often dwarfed by the aforementioned pre-training dataset, especially in domains where data is scarce. We introduce controlled randomness, i.e. noise, into the training process to improve fine-tuning language models and explore the performance of targeted noise in addition to the parameters of these models. We find that adding such noise can improve the performance in our two downstream tasks of joint named entity recognition and relation extraction and text summarization.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Teaching Language Models to Self-Improve through Interactive  Demonstrations</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13522</p>
  <p><b>作者</b>：Xiao Yu,  Baolin Peng,  Michel Galley,  Jianfeng Gao,  Zhou Yu</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：garnered significant interest, large language models, enabled by prompting, recent research, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve a LLaMA-7b's performance on math and reasoning tasks by up to 7.13%. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on its own generations. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its own mistakes is crucial for small models to improve their performance.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Improving Question Generation with Multi-level Content Planning</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13512</p>
  <p><b>作者</b>：Zehua Xia,  Qi Gou,  Bowen Yu,  Haiyang Yu,  Fei Huang,  Yongbin Li,  Cam-Tu Nguyen</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 Findings</p>
  <p><b>关键词</b>：require multi-hop reasoning, paper addresses, addresses the problem, problem of generating, require multi-hop</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the problem of generating questions from a given context and an answer, specifically focusing on questions that require multi-hop reasoning across an extended context. Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context. To mitigate this issue, we propose MultiFactor, a novel QG framework based on multi-level content planning. Specifically, MultiFactor includes two components: FA-model, which simultaneously selects key phrases and generates full answers, and Q-model which takes the generated full answer as an additional input to generate questions. Here, full answer generation is introduced to connect the short answer with the selected key phrases, thus forming an answer-aware summary to facilitate QG. Both FA-model and Q-model are formalized as simple-yet-effective Phrase-Enhanced Transformers, our joint model for phrase selection and text generation. Experimental results show that our method outperforms strong baselines on two popular QG datasets. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Explaining Interactions Between Text Spans</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13506</p>
  <p><b>作者</b>：Sagnik Ray Choudhury,  Pepa Atanasova,  Isabelle Augenstein</p>
  <p><b>备注</b>：code: this https URL , dataset: this https URL Accepted EMNLP 2023</p>
  <p><b>关键词</b>：machine reading comprehension, natural language understanding, natural language inference, machine reading, reading comprehension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reasoning over spans of tokens from different parts of the input is essential for natural language understanding (NLU) tasks such as fact-checking (FC), machine reading comprehension (MRC) or natural language inference (NLI). However, existing highlight-based explanations primarily focus on identifying individual important tokens or interactions only between adjacent tokens or tuples of tokens. Most notably, there is a lack of annotations capturing the human decision-making process w.r.t. the necessary interactions for informed decision-making in such tasks. To bridge this gap, we introduce SpanEx, a multi-annotator dataset of human span interaction explanations for two NLU tasks: NLI and FC. We then investigate the decision-making processes of multiple fine-tuned large language models in terms of the employed connections between spans in separate parts of the input and compare them to the human reasoning processes. Finally, we present a novel community detection based unsupervised method to extract such interaction explanations from a model's inner workings.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Robust Training for Conversational Question Answering Models with  Reinforced Reformulation Generation</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13505</p>
  <p><b>作者</b>：Magdalena Kaiser,  Rishiraj Saha Roy,  Gerhard Weikum</p>
  <p><b>备注</b>：WSDM 2024 Research Paper, 11 pages</p>
  <p><b>关键词</b>：knowledge graphs, conversational question answering, training, conversational question, Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Models for conversational question answering (ConvQA) over knowledge graphs (KGs) are usually trained and tested on benchmarks of gold QA pairs. This implies that training is limited to surface forms seen in the respective datasets, and evaluation is on a small set of held-out questions. Through our proposed framework REIGN, we take several steps to remedy this restricted learning setup. First, we systematically generate reformulations of training questions to increase robustness of models to surface form variations. This is a particularly challenging problem, given the incomplete nature of such questions. Second, we guide ConvQA models towards higher performance by feeding it only those reformulations that help improve their answering quality, using deep reinforcement learning. Third, we demonstrate the viability of training major model components on one benchmark and applying them zero-shot to another. Finally, for a rigorous evaluation of robustness for trained models, we use and release large numbers of diverse reformulations generated by prompting GPT for benchmark test sets (resulting in 20x increase in sizes). Our findings show that ConvQA models with robust training via reformulations, significantly outperform those with standard training from gold QA pairs only.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Analogical Proportions and Creativity: A Preliminary Study</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13500</p>
  <p><b>作者</b>：Stergos Afantenos,  Henri Prade,  Leonardo Cortez Bernardes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yield similar results, elements in pair, Analogical proportions, yield similar, pair</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analogical proportions are statements of the form "$a$ is to $b$ as $c$ is to $d$", which expresses that the comparisons of the elements in pair $(a, b)$ and in pair $(c, d)$ yield similar results. Analogical proportions are creative in the sense that given 3 distinct items, the representation of a 4th item $d$, distinct from the previous items, which forms an analogical proportion with them can be calculated, provided certain conditions are met. After providing an introduction to analogical proportions and their properties, the paper reports the results of an experiment made with a database of animal descriptions and their class, where we try to "create" new animals from existing ones, retrieving rare animals such as platypus. We perform a series of experiments using word embeddings as well as Boolean features in order to propose novel animals based on analogical proportions, showing that word embeddings obtain better results.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：DistillCSE: Distilled Contrastive Learning for Sentence Embeddings</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13499</p>
  <p><b>作者</b>：Jiahao Xu,  Wei Shao,  Lihui Chen,  Lemao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：knowledge distillation, performs contrastive learning, standard knowledge distillation, self-training paradigm, knowledge distillation exhibits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes the DistillCSE framework, which performs contrastive learning under the self-training paradigm with knowledge distillation. The potential advantage of DistillCSE is its self-enhancing feature: using a base model to provide additional supervision signals, a stronger model may be learned through knowledge distillation. However, the vanilla DistillCSE through the standard implementation of knowledge distillation only achieves marginal improvements due to severe overfitting. The further quantitative analyses demonstrate the reason that the standard knowledge distillation exhibits a relatively large variance of the teacher model's logits due to the essence of contrastive learning. To mitigate the issue induced by high variance, this paper accordingly proposed two simple yet effective solutions for knowledge distillation: a Group-P shuffling strategy as an implicit regularization and the averaging logits from multiple teacher components. Experiments on standard benchmarks demonstrate that the proposed DistillCSE outperforms many strong baseline methods and yields a new state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Mind the instructions: a holistic evaluation of consistency and  interactions in prompt-based learning</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13486</p>
  <p><b>作者</b>：Lucas Weber,  Elia Bruni,  Dieuwke Hupkes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adapting pre-trained language, current NLP, pre-trained language models, adapting pre-trained, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding the best way of adapting pre-trained language models to a task is a big challenge in current NLP. Just like the previous generation of task-tuned models (TT), models that are adapted to tasks via in-context-learning (ICL) are robust in some setups but not in others. Here, we present a detailed analysis of which design choices cause instabilities and inconsistencies in LLM predictions. First, we show how spurious correlations between input distributions and labels -- a known issue in TT models -- form only a minor problem for prompted models. Then, we engage in a systematic, holistic evaluation of different factors that have been found to influence predictions in a prompting setup. We test all possible combinations of a range of factors on both vanilla and instruction-tuned (IT) LLMs of different scale and statistically analyse the results to show which factors are the most influential, interactive or stable. Our results show which factors can be used without precautions and which should be avoided or handled with care in most settings.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Ask Language Model to Clean Your Noisy Translation Data</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13469</p>
  <p><b>作者</b>：Quinten Bolding,  Baohao Liao,  Brandon James Denis,  Jun Luo,  Christof Monz</p>
  <p><b>备注</b>：EMNLP 2023, Findings</p>
  <p><b>关键词</b>：neural machine translation, demonstrated remarkable performance, machine translation, noisy input, NMT models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset \cite{MTNT} is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise in the target sentences while preserving the semantic integrity of the original sentences. Our human and GPT-4 evaluations also lead to a consistent conclusion that LLM performs well on this task. Lastly, experiments on C-MTNT showcased its effectiveness in evaluating the robustness of NMT models, highlighting the potential of advanced language models for data cleaning and emphasizing C-MTNT as a valuable resource.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Steering Large Language Models for Machine Translation with Finetuning  and In-Context Learning</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13448</p>
  <p><b>作者</b>：Duarte M. Alves,  Nuno M. Guerreiro,  João Alves,  José Pombal,  Ricardo Rei,  José G. C. de Souza,  Pierre Colombo,  André F. T. Martins</p>
  <p><b>备注</b>：Accepted at EMNLP 2023 - Findings</p>
  <p><b>关键词</b>：Large language models, promising avenue, avenue for machine, machine translation, finetuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) are a promising avenue for machine translation (MT). However, current LLM-based MT systems are brittle: their effectiveness highly depends on the choice of few-shot examples and they often require extra post-processing due to overgeneration. Alternatives such as finetuning on translation instructions are computationally expensive and may weaken in-context learning capabilities, due to overspecialization. In this paper, we provide a closer look at this problem. We start by showing that adapter-based finetuning with LoRA matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50. This method also outperforms few-shot prompting and eliminates the need for post-processing or in-context examples. However, we show that finetuning generally degrades few-shot performance, hindering adaptation capabilities. Finally, to obtain the best of both worlds, we propose a simple approach that incorporates few-shot examples during finetuning. Experiments on 10 language pairs show that our proposed approach recovers the original few-shot capabilities while keeping the added benefits of finetuning.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13447</p>
  <p><b>作者</b>：Siyu Zhang,  Yeming Chen,  Sirui Cheng,  Yaoru Sun,  Jun Yang,  Lizhi Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：good alignment strategy, alignment strategy, vision and language, lies in establishing, establishing a good</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of constituent visual patterns, and captures multiscale features by progressively merging adjacent superpixels as graph nodes. Moreover, we predict the differences between adjacent nodes through the graph structure, facilitating key information aggregation of graph nodes to reason actual semantic relations. Afterward, we design a multi-level fusion rule in a bottom-up manner to avoid understanding deviation by learning complementary spatial information at different regional scales. Our proposed method can be well applied to multiple downstream task learning. Extensive experiments demonstrate that our method is competitive with other state-of-the-art methods in visual reasoning. Our code will be released upon publication.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：The Past, Present, and Future of Typological Databases in NLP</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13440</p>
  <p><b>作者</b>：Emi Baylor,  Esther Ploeger,  Johannes Bjerva</p>
  <p><b>备注</b>：Accepted to EMNLP Findings</p>
  <p><b>关键词</b>：NLP models, WALS and Grambank, Typological information, Typological, typological databases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Typological information has the potential to be beneficial in the development of NLP models, particularly for low-resource languages. Unfortunately, current large-scale typological databases, notably WALS and Grambank, are inconsistent both with each other and with other sources of typological information, such as linguistic grammars. Some of these inconsistencies stem from coding errors or linguistic variation, but many of the disagreements are due to the discrete categorical nature of these databases. We shed light on this issue by systematically exploring disagreements across typological databases and resources, and their uses in NLP, covering the past and present. We next investigate the future of such work, offering an argument that a continuous view of typological features is clearly beneficial, echoing recommendations from linguistics. We propose that such a view of typology has significant potential in the future, including in language modeling in low-resource scenarios.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Self-Consistency of Large Language Models under Ambiguity</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13439</p>
  <p><b>作者</b>：Henning Bartsch,  Ole Jorgensen,  Domenic Rosati,  Jason Hoelscher-Obermaier,  Jacob Pfau</p>
  <p><b>备注</b>：BlackboxNLP @ EMNLP 2023</p>
  <p><b>关键词</b>：Large language models, give consistent answers, Large language, give consistent, contexts are problematic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) that do not give consistent answers across contexts are problematic when used for tasks with expectations of consistency, e.g., question-answering, explanations, etc. Our work presents an evaluation benchmark for self-consistency in cases of under-specification where two or more answers can be correct. We conduct a series of behavioral experiments on the OpenAI model suite using an ambiguous integer sequence completion task. We find that average consistency ranges from 67\% to 82\%, far higher than would be predicted if a model's consistency was random, and increases as model capability improves. Furthermore, we show that models tend to maintain self-consistency across a series of robustness checks, including prompting speaker changes and sequence length changes. These results suggest that self-consistency arises as an emergent capability without specifically training for it. Despite this, we find that models are uncalibrated when judging their own consistency, with models displaying both over- and under-confidence. We also propose a nonparametric test for determining from token output distribution whether a model assigns non-trivial probability to alternative answers. Using this test, we find that despite increases in self-consistency, models usually place significant weight on alternative, inconsistent answers. This distribution of probability mass provides evidence that even highly self-consistent models internally compute multiple possible responses.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Conversation Chronicles: Towards Diverse Temporal and Relational  Dynamics in Multi-Session Conversations</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13420</p>
  <p><b>作者</b>：Jihyoung Jang,  Minseong Boo,  Hyounghun Kim</p>
  <p><b>备注</b>：EMNLP 2023 (23 pages); Project website: this https URL</p>
  <p><b>关键词</b>：natural language processing, important research topic, open-domain chatbot research, Conversation Chronicles, field of natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the field of natural language processing, open-domain chatbots have emerged as an important research topic. However, a major limitation of existing open-domain chatbot research is its singular focus on short single-session dialogue, neglecting the potential need for understanding contextual information in multiple consecutive sessions that precede an ongoing dialogue. Among the elements that compose the context in multi-session conversation settings, the time intervals between sessions and the relationships between speakers would be particularly important. Despite their importance, current research efforts have not sufficiently addressed these dialogical components. In this paper, we introduce a new 1M multi-session dialogue dataset, called Conversation Chronicles, for implementing a long-term conversation setup in which time intervals and fine-grained speaker relationships are incorporated. Following recent works, we exploit a large language model to produce the data. The extensive human evaluation shows that dialogue episodes in Conversation Chronicles reflect those properties while maintaining coherent and consistent interactions across all the sessions. We also propose a dialogue model, called ReBot, which consists of chronological summarization and dialogue generation modules using only around 630M parameters. When trained on Conversation Chronicles, ReBot demonstrates long-term context understanding with a high human engagement score.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Towards Enhancing Relational Rules for Knowledge Graph Link Prediction</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13411</p>
  <p><b>作者</b>：Shuhan Wu,  Huaiyu Wan,  Wei Chen,  Yuting Wu,  Junfeng Shen,  Youfang Lin</p>
  <p><b>备注</b>：Accepted at Findings of EMNLP2023</p>
  <p><b>关键词</b>：graph neural network, shown promising performance, Graph neural, relational graph neural, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have shown promising performance for knowledge graph reasoning. A recent variant of GNN called progressive relational graph neural network (PRGNN), utilizes relational rules to infer missing knowledge in relational digraphs and achieves notable results. However, during reasoning with PRGNN, two important properties are often overlooked: (1) the sequentiality of relation composition, where the order of combining different relations affects the semantics of the relational rules, and (2) the lagged entity information propagation, where the transmission speed of required information lags behind the appearance speed of new entities. Ignoring these properties leads to incorrect relational rule learning and decreased reasoning accuracy. To address these issues, we propose a novel knowledge graph reasoning approach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN). Specifically, RUN-GNN employs a query related fusion gate unit to model the sequentiality of relation composition and utilizes a buffering update mechanism to alleviate the negative effect of lagged entity information propagation, resulting in higher-quality relational rule learning. Experimental results on multiple datasets demonstrate the superiority of RUN-GNN is superior on both transductive and inductive link prediction tasks.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Explicit Alignment and Many-to-many Entailment Based Reasoning for  Conversational Machine Reading</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13409</p>
  <p><b>作者</b>：Yangyang Luo,  Shiyu Tian,  Caixia Yuan,  Xiaojie Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Conversational Machine Reading, multi-turn dialogue interactions, Machine Reading, user initial question, dialogue interactions based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational Machine Reading (CMR) requires answering a user's initial question through multi-turn dialogue interactions based on a given document. Although there exist many effective methods, they largely neglected the alignment between the document and the user-provided information, which significantly affects the intermediate decision-making and subsequent follow-up question generation. To address this issue, we propose a pipeline framework that (1) aligns the aforementioned two sides in an explicit way, (2)makes decisions using a lightweight many-to-many entailment reasoning module, and (3) directly generates follow-up questions based on the document and previously asked questions. Our proposed method achieves state-of-the-art in micro-accuracy and ranks the first place on the public leaderboard of the CMR benchmark dataset ShARC.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Cache me if you Can: an Online Cost-aware Teacher-Student framework to  Reduce the Calls to Large Language Models</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13395</p>
  <p><b>作者</b>：Ilias Stogiannidis,  Stavros Vassos,  Prodromos Malakasiotis,  Ion Androutsopoulos</p>
  <p><b>备注</b>：Short paper (5 pages), accepted at Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Large Language Models, Prompting Large Language, Large Language, Language Models, performs impressively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting Large Language Models (LLMs) performs impressively in zero- and few-shot settings. Hence, small and medium-sized enterprises (SMEs) that cannot afford the cost of creating large task-specific training datasets, but also the cost of pretraining their own LLMs, are increasingly turning to third-party services that allow them to prompt LLMs. However, such services currently require a payment per call, which becomes a significant operating expense (OpEx). Furthermore, customer inputs are often very similar over time, hence SMEs end-up prompting LLMs with very similar instances. We propose a framework that allows reducing the calls to LLMs by caching previous LLM responses and using them to train a local inexpensive model on the SME side. The framework includes criteria for deciding when to trust the local model or call the LLM, and a methodology to tune the criteria and measure the tradeoff between performance and cost. For experimental purposes, we instantiate our framework with two LLMs, GPT-3.5 or GPT-4, and two inexpensive students, a k-NN classifier or a Multi-Layer Perceptron, using two common business tasks, intent recognition and sentiment analysis. Experimental results indicate that significant OpEx savings can be obtained with only slightly lower performance.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：POSQA: Probe the World Models of LLMs with Size Comparisons</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13394</p>
  <p><b>作者</b>：Chang Shu,  Jiuzhou Han,  Fangyu Liu,  Ehsan Shareghi,  Nigel Collier</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 Findings</p>
  <p><b>关键词</b>：Large Language Models, language comprehension emphasizes, Embodied language comprehension, social environment, solely a matter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied language comprehension emphasizes that language understanding is not solely a matter of mental processing in the brain but also involves interactions with the physical and social environment. With the explosive growth of Large Language Models (LLMs) and their already ubiquitous presence in our daily lives, it is becoming increasingly necessary to verify their real-world understanding. Inspired by cognitive theories, we propose POSQA: a Physical Object Size Question Answering dataset with simple size comparison questions to examine the extremity and analyze the potential mechanisms of the embodied comprehension of the latest LLMs.
We show that even the largest LLMs today perform poorly under the zero-shot setting. We then push their limits with advanced prompting techniques and external knowledge augmentation. Furthermore, we investigate whether their real-world comprehension primarily derives from contextual information or internal weights and analyse the impact of prompt formats and report bias of different objects. Our results show that real-world understanding that LLMs shaped from textual data can be vulnerable to deception and confusion by the surface form of prompts, which makes it less aligned with human behaviours.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Tuna: Instruction Tuning using Feedback from Large Language Models</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13385</p>
  <p><b>作者</b>：Haoran Li,  Yiran Liu,  Xingxing Zhang,  Wei Lu,  Furu Wei</p>
  <p><b>备注</b>：EMNLP 2023, code and data are available at this https URL</p>
  <p><b>关键词</b>：open-source large language, large language models, align model behaviors, human preferences, tuning of open-source</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a cost-effective way to align model behaviors with human preferences. However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses. In this paper, we propose finetuning an instruction-tuned LLM using our novel \textit{probabilistic ranking} and \textit{contextual ranking} approaches to increase the likelihood of generating better responses. Probabilistic ranking enables the instruction-tuned model to inherit the relative rankings of high-quality and low-quality responses from the teacher LLM. On the other hand, learning with contextual ranking allows the model to refine its own response distribution using the contextual understanding ability of stronger LLMs. Furthermore, we apply probabilistic ranking and contextual ranking sequentially to the instruction-tuned LLM. The resulting model, which we call \textbf{Tuna}, consistently improves the performance on Super Natural Instructions (119 test tasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results than several strong reinforcement learning baselines. Our code and data are available at \url{ this https URL}.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13380</p>
  <p><b>作者</b>：Pei Wang,  Keqing He,  Yutao Mou,  Xiaoshuai Song,  Yanan Wu,  Jingang Wang,  Yunsen Xian,  Xunliang Cai,  Weiran Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task-oriented dialogue system, OOD detection, OOD, few-shot OOD detection, few-shot OOD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting out-of-domain (OOD) intents from user queries is essential for a task-oriented dialogue system. Previous OOD detection studies generally work on the assumption that plenty of labeled IND intents exist. In this paper, we focus on a more practical few-shot OOD setting where there are only a few labeled IND data and massive unlabeled mixed data that may belong to IND or OOD. The new scenario carries two key challenges: learning discriminative representations using limited IND data and leveraging unlabeled mixed data. Therefore, we propose an adaptive prototypical pseudo-labeling (APP) method for few-shot OOD detection, including a prototypical OOD detection framework (ProtoOOD) to facilitate low-resource OOD detection using limited IND data, and an adaptive pseudo-labeling method to produce high-quality pseudo OOD\&IND labels. Extensive experiments and analysis demonstrate the effectiveness of our method for few-shot OOD detection.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Human-Robot Mutual Learning System with Affect-Grounded Language  Acquisition and Differential Outcomes Training</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13377</p>
  <p><b>作者</b>：Alva Markelius,  Sofia Sjöberg,  Zakaria Lemhauori,  Laura Cohen,  Martin Bergström,  Robert Lowe,  Lola Cañamero</p>
  <p><b>备注</b>：Preprint: This is the submitted version of a paper to be presented at The Proceedings of the 15th International Conference on Social Robotics (ICSR 2023). Please cite the official publication once it is available</p>
  <p><b>关键词</b>：robot language acquisition, identifying robot homeostatic, robot, robot language, language acquisition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel human-robot interaction setup for robot and human learning of symbolic language for identifying robot homeostatic needs. The robot and human learn to use and respond to the same language symbols that convey homeostatic needs and the stimuli that satisfy the homeostatic needs, respectively. We adopted a differential outcomes training (DOT) protocol whereby the robot provides feedback specific (differential) to its internal needs (e.g. `hunger') when satisfied by the correct stimulus (e.g. cookie). We found evidence that DOT can enhance the human's learning efficiency, which in turn enables more efficient robot language acquisition. The robot used in the study has a vocabulary similar to that of a human infant in the linguistic ``babbling'' phase. The robot software architecture is built upon a model for affect-grounded language acquisition where the robot associates vocabulary with internal needs (hunger, thirst, curiosity) through interactions with the human. The paper presents the results of an initial pilot study conducted with the interactive setup, which reveal that the robot's language acquisition achieves higher convergence rate in the DOT condition compared to the non-DOT control condition. Additionally, participants reported positive affective experiences, feeling of being in control, and an empathetic connection with the robot. This mutual learning (teacher-student learning) approach offers a potential contribution of facilitating cognitive interventions with DOT (e.g. for people with dementia) through increased therapy adherence as a result of engaging humans more in training tasks by taking an active teaching-learning role. The homeostatic motivational grounding of the robot's language acquisition has potential to contribute to more ecologically valid and social (collaborative/nurturing) interactions with robots.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Towards General Error Diagnosis via Behavioral Testing in Machine  Translation</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13362</p>
  <p><b>作者</b>：Junjie Wu,  Lemao Liu,  Dit-Yan Yeung</p>
  <p><b>备注</b>：15 pages, 2 figures, accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：NLP models, capabilities of NLP, Behavioral testing, diagnosing linguistic errors, Behavioral testing offers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models. However, applying behavioral testing to machine translation (MT) systems is challenging as it generally requires human efforts to craft references for evaluating the translation quality of such systems on newly generated test cases. Existing works in behavioral testing of MT systems circumvent this by evaluating translation quality without references, but this restricts diagnosis to specific types of errors, such as incorrect translation of single numeric or currency words. In order to diagnose general errors, this paper proposes a new Bilingual Translation Pair Generation based Behavior Testing (BTPGBT) framework for conducting behavioral testing of MT systems. The core idea of BTPGBT is to employ a novel bilingual translation pair generation (BTPG) approach that automates the construction of high-quality test cases and their pseudoreferences. Experimental results on various MT systems demonstrate that BTPGBT could provide comprehensive and accurate behavioral testing results for general error diagnosis, which further leads to several insightful findings. Our code and data are available at https: //github.com/wujunjie1998/BTPGBT.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Bridging the Gap between Synthetic and Authentic Images for Multimodal  Machine Translation</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13361</p>
  <p><b>作者</b>：Wenyu Guo,  Qingkai Fang,  Dong Yu,  Yang Feng</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 main conference</p>
  <p><b>关键词</b>：Multimodal machine translation, authentic images, machine translation, images, Multimodal machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal machine translation (MMT) simultaneously takes the source sentence and a relevant image as input for translation. Since there is no paired image available for the input sentence in most cases, recent studies suggest utilizing powerful text-to-image generation models to provide image inputs. Nevertheless, synthetic images generated by these models often follow different distributions compared to authentic images. Consequently, using authentic images for training and synthetic images for inference can introduce a distribution shift, resulting in performance degradation during inference. To tackle this challenge, in this paper, we feed synthetic and authentic images to the MMT model, respectively. Then we minimize the gap between the synthetic and authentic images by drawing close the input image representations of the Transformer Encoder and the output distributions of the Transformer Decoder. Therefore, we mitigate the distribution disparity introduced by the synthetic images during inference, thereby freeing the authentic images from the inference process.Experimental results show that our approach achieves state-of-the-art performance on the Multi30K En-De and En-Fr datasets, while remaining independent of authentic images during inference.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Analyzing Cognitive Plausibility of Subword Tokenization</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13348</p>
  <p><b>作者</b>：Lisa Beinborn,  Yuval Pinter</p>
  <p><b>备注</b>：EMNLP 2023 (main)</p>
  <p><b>关键词</b>：subword vocabulary quality, de-facto standard, Subword tokenization, tokenization, comparative evaluations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subword tokenization has become the de-facto standard for tokenization, although comparative evaluations of subword vocabulary quality across languages are scarce. Existing evaluation studies focus on the effect of a tokenization algorithm on the performance in downstream tasks, or on engineering criteria such as the compression rate. We present a new evaluation paradigm that focuses on the cognitive plausibility of subword tokenization. We analyze the correlation of the tokenizer output with the response time and accuracy of human performance on a lexical decision task. We compare three tokenization algorithms across several languages and vocabulary sizes. Our results indicate that the UnigramLM algorithm yields less cognitively plausible tokenization behavior and a worse coverage of derivational morphemes, in contrast with prior work.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Challenges and Contributing Factors in the Utilization of Large Language  Models (LLMs)</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13343</p>
  <p><b>作者</b>：Xiaoliang Chen,  Liangbin Li,  Le Chang,  Yunhe Huang,  Yuxuan Zhao,  Yuxiao Zhang,  Dinuo Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：application scenarios presents, GPT series, large language models, development of large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of large language models (LLMs) like the GPT series, their widespread use across various application scenarios presents a myriad of challenges. This review initially explores the issue of domain specificity, where LLMs may struggle to provide precise answers to specialized questions within niche fields. The problem of knowledge forgetting arises as these LLMs might find it hard to balance old and new information. The knowledge repetition phenomenon reveals that sometimes LLMs might deliver overly mechanized responses, lacking depth and originality. Furthermore, knowledge illusion describes situations where LLMs might provide answers that seem insightful but are actually superficial, while knowledge toxicity focuses on harmful or biased information outputs. These challenges underscore problems in the training data and algorithmic design of LLMs. To address these issues, it's suggested to diversify training data, fine-tune models, enhance transparency and interpretability, and incorporate ethics and fairness training. Future technological trends might lean towards iterative methodologies, multimodal learning, model personalization and customization, and real-time learning and feedback mechanisms. In conclusion, future LLMs should prioritize fairness, transparency, and ethics, ensuring they uphold high moral and ethical standards when serving humanity.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Large-Scale and Multi-Perspective Opinion Summarization with Diverse  Review Subsets</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13340</p>
  <p><b>作者</b>：Han Jiang,  Rui Wang,  Zhihua Wei,  Yu Li,  Xinpeng Wang</p>
  <p><b>备注</b>：EMNLP 2023 Findings</p>
  <p><b>关键词</b>：digest larger review, expected to digest, digest larger, larger review sets, offering opinion summaries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Opinion summarization is expected to digest larger review sets and provide summaries from different perspectives. However, most existing solutions are deficient in epitomizing extensive reviews and offering opinion summaries from various angles due to the lack of designs for information selection. To this end, we propose SUBSUMM, a supervised summarization framework for large-scale multi-perspective opinion summarization. SUBSUMM consists of a review sampling strategy set and a two-stage training scheme. The sampling strategies take sentiment orientation and contrastive information value into consideration, with which the review subsets from different perspectives and quality levels can be selected. Subsequently, the summarizer is encouraged to learn from the sub-optimal and optimal subsets successively in order to capitalize on the massive input. Experimental results on AmaSum and Rotten Tomatoes datasets demonstrate that SUBSUMM is adept at generating pros, cons, and verdict summaries from hundreds of input reviews. Furthermore, our in-depth analysis verifies that the advanced selection of review subsets and the two-stage training scheme are vital to boosting the summarization performance.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Democratizing Reasoning Ability: Tailored Learning from Large Language  Model</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13332</p>
  <p><b>作者</b>：Zhaoyang Wang,  Shaohan Huang,  Yuxuan Liu,  Jiahai Wang,  Minghui Song,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang</p>
  <p><b>备注</b>：To appear at EMNLP 2023</p>
  <p><b>关键词</b>：Large language models, natural language processing, exhibit impressive emergent, impressive emergent abilities, huge computation requirements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) exhibit impressive emergent abilities in natural language processing, but their democratization is hindered due to huge computation requirements and closed-source nature. Recent research on advancing open-source smaller LMs by distilling knowledge from black-box LLMs has obtained promising results in the instruction-following ability. However, the reasoning ability which is more challenging to foster, is relatively rarely explored. In this paper, we propose a tailored learning approach to distill such reasoning ability to smaller LMs to facilitate the democratization of the exclusive reasoning ability. In contrast to merely employing LLM as a data annotator, we exploit the potential of LLM as a reasoning teacher by building an interactive multi-round learning paradigm. This paradigm enables the student to expose its deficiencies to the black-box teacher who then can provide customized training data in return. Further, to exploit the reasoning potential of the smaller LM, we propose self-reflection learning to motivate the student to learn from self-made mistakes. The learning from self-reflection and LLM are all tailored to the student's learning status, thanks to the seamless integration with the multi-round learning paradigm. Comprehensive experiments and analysis on mathematical and commonsense reasoning tasks demonstrate the effectiveness of our method. The code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Beyond Hard Samples: Robust and Effective Grammatical Error Correction  with Cycle Self-Augmenting</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13321</p>
  <p><b>作者</b>：Zecheng Tang,  Kaifeng Qi,  Juntao Li,  Min Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grammatical error correction, GEC models, simply utilizing adversarial, error correction methods, GEC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have revealed that grammatical error correction methods in the sequence-to-sequence paradigm are vulnerable to adversarial attack, and simply utilizing adversarial examples in the pre-training or post-training process can significantly enhance the robustness of GEC models to certain types of attack without suffering too much performance loss on clean data. In this paper, we further conduct a thorough robustness evaluation of cutting-edge GEC methods for four different types of adversarial attacks and propose a simple yet very effective Cycle Self-Augmenting (CSA) method accordingly. By leveraging the augmenting data from the GEC models themselves in the post-training process and introducing regularization data for cycle training, our proposed method can effectively improve the model robustness of well-trained GEC models with only a few more training epochs as an extra cost. More concretely, further training on the regularization data can prevent the GEC models from over-fitting on easy-to-learn samples and thus can improve the generalization capability and robustness towards unseen data (adversarial noise/samples). Meanwhile, the self-augmented data can provide more high-quality pseudo pairs to improve model performance on the original testing data. Experiments on four benchmark datasets and seven strong models indicate that our proposed training method can significantly enhance the robustness of four types of attacks without using purposely built adversarial examples in training. Evaluation results on clean data further confirm that our proposed CSA method significantly improves the performance of four baselines and yields nearly comparable results with other state-of-the-art models. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Coarse-to-Fine Dual Encoders are Better Frame Identification Learners</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13316</p>
  <p><b>作者</b>：Kaikai An,  Ce Zheng,  Bofei Gao,  Haozhe Zhao,  Baobao Chang</p>
  <p><b>备注</b>：Accepted to Findings of EMNLP2023</p>
  <p><b>关键词</b>：Frame identification aims, find semantic frames, underline, identification aims, aims to find</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Frame identification aims to find semantic frames associated with target words in a sentence. Recent researches measure the similarity or matching score between targets and candidate frames by modeling frame definitions. However, they either lack sufficient representation learning of the definitions or face challenges in efficiently selecting the most suitable frame from over 1000 candidate frames. Moreover, commonly used lexicon filtering ($lf$) to obtain candidate frames for the target may ignore out-of-vocabulary targets and cause inadequate frame modeling. In this paper, we propose CoFFTEA, a $\underline{Co}$arse-to-$\underline{F}$ine $\underline{F}$rame and $\underline{T}$arget $\underline{E}$ncoders $\underline{A}$rchitecture. With contrastive learning and dual encoders, CoFFTEA efficiently and effectively models the alignment between frames and targets. By employing a coarse-to-fine curriculum learning procedure, CoFFTEA gradually learns to differentiate frames with varying degrees of similarity. Experimental results demonstrate that CoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without $lf$. Further analysis suggests that CoFFTEA can better model the relationships between frame and frame, as well as target and target. The code for our approach is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Zero-Shot Sharpness-Aware Quantization for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13315</p>
  <p><b>作者</b>：Miaoxi Zhu,  Qihuang Zhong,  Li Shen,  Liang Ding,  Juhua Liu,  Bo Du,  Dacheng Tao</p>
  <p><b>备注</b>：Accepted to EMNLP2023 (Main). Miaoxi Zhu and Qihuang Zhong contribute equally to this work</p>
  <p><b>关键词</b>：reducing memory overhead, large pre-trained language, pre-trained language model, accelerating inference, promising approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantization is a promising approach for reducing memory overhead and accelerating inference, especially in large pre-trained language model (PLM) scenarios. While having no access to original training data due to security and privacy concerns has emerged the demand for zero-shot quantization. Most of the cutting-edge zero-shot quantization methods primarily 1) apply to computer vision tasks, and 2) neglect of overfitting problem in the generative adversarial learning process, leading to sub-optimal performance. Motivated by this, we propose a novel zero-shot sharpness-aware quantization (ZSAQ) framework for the zero-shot quantization of various PLMs. The key algorithm in solving ZSAQ is the SAM-SGA optimization, which aims to improve the quantization accuracy and model generalization via optimizing a minimax problem. We theoretically prove the convergence rate for the minimax optimization problem and this result can be applied to other nonconvex-PL minimax optimization frameworks. Extensive experiments on 11 tasks demonstrate that our method brings consistent and significant performance gains on both discriminative and generative PLMs, i.e., up to +6.98 average score. Furthermore, we empirically validate that our method can effectively improve the model generalization.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Exploring the Impact of Corpus Diversity on Financial Pretrained  Language Models</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13312</p>
  <p><b>作者</b>：Jaeyoung Choe,  Keonwoong Noh,  Nayeon Kim,  Seyun Ahn,  Woohwan Jung</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 (Findings)</p>
  <p><b>关键词</b>：outperformed general-domain PLMs, domain-specific pretrained language, past few years, pretrained language models, Financial Language Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the past few years, various domain-specific pretrained language models (PLMs) have been proposed and have outperformed general-domain PLMs in specialized areas such as biomedical, scientific, and clinical domains. In addition, financial PLMs have been studied because of the high economic impact of financial data analysis. However, we found that financial PLMs were not pretrained on sufficiently diverse financial data. This lack of diverse training data leads to a subpar generalization performance, resulting in general-purpose PLMs, including BERT, often outperforming financial PLMs on many downstream tasks. To address this issue, we collected a broad range of financial corpus and trained the Financial Language Model (FiLM) on these diverse datasets. Our experimental results confirm that FiLM outperforms not only existing financial PLMs but also general domain PLMs. Furthermore, we provide empirical evidence that this improvement can be achieved even for unseen corpus groups.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Test-Time Self-Adaptive Small Language Models for Question Answering</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13307</p>
  <p><b>作者</b>：Soyeong Jeong,  Jinheon Baek,  Sukmin Cho,  Sung Ju Hwang,  Jong C. Park</p>
  <p><b>备注</b>：EMNLP Findings 2023</p>
  <p><b>关键词</b>：large language models, Recent instruction-finetuned large, instruction-finetuned large language, achieved notable performances, Recent instruction-finetuned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent instruction-finetuned large language models (LMs) have achieved notable performances in various tasks, such as question-answering (QA). However, despite their ability to memorize a vast amount of general knowledge across diverse tasks, they might be suboptimal on specific tasks due to their limited capacity to transfer and adapt knowledge to target tasks. Moreover, further finetuning LMs with labeled datasets is often infeasible due to their absence, but it is also questionable if we can transfer smaller LMs having limited knowledge only with unlabeled test data. In this work, we show and investigate the capabilities of smaller self-adaptive LMs, only with unlabeled test data. In particular, we first stochastically generate multiple answers, and then ensemble them while filtering out low-quality samples to mitigate noise from inaccurate labels. Our proposed self-adaption strategy demonstrates significant performance improvements on benchmark QA datasets with higher robustness across diverse prompts, enabling LMs to stay stable. Code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Decoding the Silent Majority: Inducing Belief Augmented Social Graph  with Large Language Model for Response Forecasting</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13297</p>
  <p><b>作者</b>：Chenkai Sun,  Jinning Li,  Yi R. Fung,  Hou Pong Chan,  Tarek Abdelzaher,  ChengXiang Zhai,  Heng Ji</p>
  <p><b>备注</b>：Accepted at EMNLP 2023 Main Conference</p>
  <p><b>关键词</b>：enabling content producers, prevent unexpected negative, unexpected negative outcomes, moral injury, media plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic response forecasting for news media plays a crucial role in enabling content producers to efficiently predict the impact of news releases and prevent unexpected negative outcomes such as social conflict and moral injury. To effectively forecast responses, it is essential to develop measures that leverage the social dynamics and contextual information surrounding individuals, especially in cases where explicit profiles or historical actions of the users are limited (referred to as lurkers). As shown in a previous study, 97% of all tweets are produced by only the most active 25% of users. However, existing approaches have limited exploration of how to best process and utilize these important features. To address this gap, we propose a novel framework, named SocialSense, that leverages a large language model to induce a belief-centered graph on top of an existent social network, along with graph-based propagation to capture social dynamics. We hypothesize that the induced graph that bridges the gap between distant users who share similar beliefs allows the model to effectively capture the response patterns. Our method surpasses existing state-of-the-art in experimental evaluations for both zero-shot and supervised settings, demonstrating its effectiveness in response forecasting. Moreover, the analysis reveals the framework's capability to effectively handle unseen user and lurker scenarios, further highlighting its robustness and practical applicability.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Assessing Privacy Risks in Language Models: A Case Study on  Summarization Tasks</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13291</p>
  <p><b>作者</b>：Ruixiang Tang,  Gord Lueck,  Rodolfo Quispe,  Huseyin A Inan,  Janardhan Kulkarni,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP by achieving, field of NLP, Large language models, Large language, revolutionized the field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model's API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model's resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Interpreting Indirect Answers to Yes-No Questions in Multiple Languages</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13290</p>
  <p><b>作者</b>：Zijie Wang,  Md Mosharaf Hossain,  Shivam Mathur,  Terry Cruz Melo,  Kadir Bulut Ozler,  Keun Hee Park,  Jacob Quintero,  MohammadHossein Rezaei,  Shreya Nupur Shakya,  Md Nayem Uddin,  Eduardo Blanco</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 Findings</p>
  <p><b>关键词</b>：Yes-no questions expect, Yes-no questions, skip polar keywords, polar keywords, questions expect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Yes-no questions expect a yes or no for an answer, but people often skip polar keywords. Instead, they answer with long explanations that must be interpreted. In this paper, we focus on this challenging problem and release new benchmarks in eight languages. We present a distant supervision approach to collect training data. We also demonstrate that direct answers (i.e., with polar keywords) are useful to train models to interpret indirect answers (i.e., without polar keywords). Experimental results demonstrate that monolingual fine-tuning is beneficial if training data can be obtained via distant supervision for the language of interest (5 languages). Additionally, we show that cross-lingual fine-tuning is always beneficial (8 languages).</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：SALMONN: Towards Generic Hearing Abilities for Large Language Models</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13289</p>
  <p><b>作者</b>：Changli Tang,  Wenyi Yu,  Guangzhi Sun,  Xianzhao Chen,  Tian Tan,  Wei Li,  Lu Lu,  Zejun Ma,  Chao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：auditory information consisting, general auditory information, speech audio language, audio language music, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hearing is arguably an essential ability of artificial intelligence (AI) agents in the physical world, which refers to the perception and understanding of general auditory information consisting of at least three types of sounds: speech, audio events, and music. In this paper, we propose SALMONN, a speech audio language music open neural network, built by integrating a pre-trained text-based large language model (LLM) with speech and audio encoders into a single multimodal model. SALMONN enables the LLM to directly process and understand general audio inputs and achieve competitive performances on a number of speech and audio tasks used in training, such as automatic speech recognition and translation, auditory-information-based question answering, emotion recognition, speaker verification, and music and audio captioning \textit{etc.} SALMONN also has a diverse set of emergent abilities unseen in the training, which includes but is not limited to speech translation to untrained languages, speech-based slot filling, spoken-query-based question answering, audio-based storytelling, and speech audio co-reasoning \textit{etc}. The presence of the cross-modal emergent abilities is studied, and a novel few-shot activation tuning approach is proposed to activate such abilities of SALMONN. To our knowledge, SALMONN is the first model of its type and can be regarded as a step towards AI with generic hearing abilities. An interactive demo of SALMONN is available at \texttt{\url{this https URL}}, and the training code and model checkpoints will be released upon acceptance.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13276</p>
  <p><b>作者</b>：Xiangru Jian,  Yimu Wang</p>
  <p><b>备注</b>：Findings of EMNLP 2023</p>
  <p><b>关键词</b>：representation degeneration problem, significant advancements, linguistic modeling, degeneration problem, driven by breakthroughs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over recent decades, significant advancements in cross-modal retrieval are mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance.
Our code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：On the Language Encoder of Contrastive Cross-modal Models</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13267</p>
  <p><b>作者</b>：Mengjie Zhao,  Junya Ono,  Zhi Zhong,  Chieh-Hsin Lai,  Yuhta Takida,  Naoki Murata,  Wei-Hsiang Liao,  Takashi Shibuya,  Hiromi Wakaki,  Yuki Mitsufuji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CLIP and CLAP, sentence embedding training, CLAP aid, sentence embedding, embedding training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder, which is the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found that sentence embedding training language encoder quality and aids in cross-modal tasks, improving contrastive VL models such as CyCLIP. In contrast, AL pretraining benefits less from sentence embedding training, which may result from the limited amount of pretraining data. We analyze the representation spaces to understand the strengths of sentence embedding training, and find that it improves text-space uniformity, at the cost of decreased cross-modal alignment.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with  Large Language Model</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13265</p>
  <p><b>作者</b>：Le Zhang,  Yihong Wu,  Fengran Mo,  Jian-Yun Nie,  Aishwarya Agrawal</p>
  <p><b>备注</b>：Accepted into EMNLP2023 Findings</p>
  <p><b>关键词</b>：open-domain question answering, question answering typically, answering typically requires, typically requires evidence, requires evidence retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-modal open-domain question answering typically requires evidence retrieval from databases across diverse modalities, such as images, tables, passages, etc. Even Large Language Models (LLMs) like GPT-4 fall short in this task. To enable LLMs to tackle the task in a zero-shot manner, we introduce MoqaGPT, a straightforward and flexible framework. Using a divide-and-conquer strategy that bypasses intricate multi-modality ranking, our framework can accommodate new modalities and seamlessly transition to new models for the task. Built upon LLMs, MoqaGPT retrieves and extracts answers from each modality separately, then fuses this multi-modal information using LLMs to produce a final answer. Our methodology boosts performance on the MMCoQA dataset, improving F1 by +37.91 points and EM by +34.07 points over the supervised baseline. On the MultiModalQA dataset, MoqaGPT surpasses the zero-shot baseline, improving F1 by 9.5 points and EM by 10.1 points, and significantly closes the gap with supervised methods. Our codebase is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A Quality-based Syntactic Template Retriever for  Syntactically-controlled Paraphrase Generation</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13262</p>
  <p><b>作者</b>：Xue Zhang,  Songming Zhang,  Yunlong Liang,  Yufeng Chen,  Jian Liu,  Wenjuan Han,  Jinan Xu</p>
  <p><b>备注</b>：Accepted to EMNLP 2023</p>
  <p><b>关键词</b>：syntactically-controlled paraphrase generation, SPG models, well-chosen syntactic templates, models perform promisingly, SPG</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing syntactically-controlled paraphrase generation (SPG) models perform promisingly with human-annotated or well-chosen syntactic templates. However, the difficulty of obtaining such templates actually hinders the practical application of SPG models. For one thing, the prohibitive cost makes it unfeasible to manually design decent templates for every source sentence. For another, the templates automatically retrieved by current heuristic methods are usually unreliable for SPG models to generate qualified paraphrases. To escape this dilemma, we propose a novel Quality-based Syntactic Template Retriever (QSTR) to retrieve templates based on the quality of the to-be-generated paraphrases. Furthermore, for situations requiring multiple paraphrases for each source sentence, we design a Diverse Templates Search (DTS) algorithm, which can enhance the diversity between paraphrases without sacrificing quality. Experiments demonstrate that QSTR can significantly surpass existing retrieval methods in generating high-quality paraphrases and even perform comparably with human-annotated templates in terms of reference-free metrics. Additionally, human evaluation and the performance on downstream tasks using our generated paraphrases for data augmentation showcase the potential of our QSTR and DTS algorithm in practical scenarios.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Visual Grounding Helps Learn Word Meanings in Low-Data Regimes</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13257</p>
  <p><b>作者</b>：Chengxu Zhuang,  Evelina Fedorenko,  Jacob Andreas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human sentence production, production and comprehension, powerful tools, sentence production, remarkably well-aligned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern neural language models (LMs) are powerful tools for modeling human sentence production and comprehension, and their internal representations are remarkably well-aligned with representations of language in the human brain. But to achieve these results, LMs must be trained in distinctly un-human-like ways -- requiring orders of magnitude more language data than children receive during development, and without any of the accompanying grounding in perception, action, or social behavior. Do models trained more naturalistically -- with grounded supervision -- exhibit more human-like language learning? We investigate this question in the context of word learning, a key sub-task in language acquisition. We train a diverse set of LM architectures, with and without auxiliary supervision from image captioning tasks, on datasets of varying scales. We then evaluate these models on a broad set of benchmarks characterizing models' learning of syntactic categories, lexical relations, semantic features, semantic similarity, and alignment with human neural representations. We find that visual supervision can indeed improve the efficiency of word learning. However, these improvements are limited: they are present almost exclusively in the low-data regime, and sometimes canceled out by the inclusion of rich distributional signals from text. The information conveyed by text and images is not redundant -- we find that models mainly driven by visual information yield qualitatively different from those mainly driven by word co-occurrences. However, our results suggest that current multi-modal modeling approaches fail to effectively leverage visual information to build more human-like word representations from human-sized datasets.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Anomaly Detection of Command Shell Sessions based on DistilBERT:  Unsupervised and Supervised Approaches</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13247</p>
  <p><b>作者</b>：Zefang Liu,  John Buford</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unix shell sessions, Unix shell, critical aspect, Unix shell commands, shell sessions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection in command shell sessions is a critical aspect of computer security. Recent advances in deep learning and natural language processing, particularly transformer-based models, have shown great promise for addressing complex security challenges. In this paper, we implement a comprehensive approach to detect anomalies in Unix shell sessions using a pretrained DistilBERT model, leveraging both unsupervised and supervised learning techniques to identify anomalous activity while minimizing data labeling. The unsupervised method captures the underlying structure and syntax of Unix shell commands, enabling the detection of session deviations from normal behavior. Experiments on a large-scale enterprise dataset collected from production systems demonstrate the effectiveness of our approach in detecting anomalous behavior in Unix shell sessions. This work highlights the potential of leveraging recent advances in transformers to address important computer security challenges.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Open-source Large Language Models are Strong Zero-shot Query Likelihood  Models for Document Ranking</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13243</p>
  <p><b>作者</b>：Shengyao Zhuang,  Bing Liu,  Bevan Koopman,  Guido Zuccon</p>
  <p><b>备注</b>：5 pages</p>
  <p><b>关键词</b>：Query Likelihood Models, rank documents based, Query Likelihood, Likelihood Models, rank documents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the field of information retrieval, Query Likelihood Models (QLMs) rank documents based on the probability of generating the query given the content of a document. Recently, advanced large language models (LLMs) have emerged as effective QLMs, showcasing promising ranking capabilities. This paper focuses on investigating the genuine zero-shot ranking effectiveness of recent LLMs, which are solely pre-trained on unstructured text data without supervised instruction fine-tuning. Our findings reveal the robust zero-shot ranking ability of such LLMs, highlighting that additional instruction fine-tuning may hinder effectiveness unless a question generation task is present in the fine-tuning dataset. Furthermore, we introduce a novel state-of-the-art ranking system that integrates LLM-based QLMs with a hybrid zero-shot retriever, demonstrating exceptional effectiveness in both zero-shot and few-shot scenarios. We make our codebase publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Multi-level Contrastive Learning for Script-based Character  Understanding</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13231</p>
  <p><b>作者</b>：Dawei Li,  Hengyuan Zhang,  Yanran Li,  Shiping Yang</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 main conference; Camera-ready version will be updated soon</p>
  <p><b>关键词</b>：aims to learn, personalities and identities, characters' personalities, capture characters' global, characters' global information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we tackle the scenario of understanding characters in scripts, which aims to learn the characters' personalities and identities from their utterances. We begin by analyzing several challenges in this scenario, and then propose a multi-level contrastive learning framework to capture characters' global information in a fine-grained manner. To validate the proposed framework, we conduct extensive experiments on three character understanding sub-tasks by comparing with strong pre-trained language models, including SpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate that our method improves the performances by a considerable margin. Through further in-depth analysis, we show the effectiveness of our method in addressing the challenges and provide more hints on the scenario of character understanding. We will open-source our work on github at this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：The Less the Merrier? Investigating Language Representation in  Multilingual Models</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13228</p>
  <p><b>作者</b>：Hellina Hailu Nigatu,  Atnafu Lambebo Tonja,  Jugal Kalita</p>
  <p><b>备注</b>：Accepted to EMNLP 2023(Findings)</p>
  <p><b>关键词</b>：Natural Language Processing, utilize cross-language transfer, cross-language transfer learning, incorporate multiple languages, Language Processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilingual Language Models offer a way to incorporate multiple languages in one model and utilize cross-language transfer learning to improve performance for different Natural Language Processing (NLP) tasks. Despite progress in multilingual models, not all languages are supported as well, particularly in low-resource settings. In this work, we investigate the linguistic representation of different languages in multilingual models. We start by asking the question which languages are supported in popular multilingual models and which languages are left behind. Then, for included languages, we look at models' learned representations based on language family and dialect and try to understand how models' learned representations for~(1) seen and~(2) unseen languages vary across different language groups. In addition, we test and analyze performance on downstream tasks such as text generation and Named Entity Recognition. We observe from our experiments that community-centered models -- models that focus on languages of a given family or geographical location and are built by communities who speak them -- perform better at distinguishing between languages in the same family for low-resource languages. Our paper contributes to the literature in understanding multilingual models and their shortcomings and offers insights on potential ways to improve them.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：ToolChain*: Efficient Action Space Navigation in Large Language Models  with A* Search</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13227</p>
  <p><b>作者</b>：Yuchen Zhuang,  Xiang Chen,  Tong Yu,  Saayan Mitra,  Victor Bursztyn,  Ryan A. Rossi,  Somdeb Sarkhel,  Chao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, complicated real-world problems, demonstrated powerful decision-making, solving complicated real-world, API function calls</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated powerful decision-making and planning capabilities in solving complicated real-world problems. LLM-based autonomous agents can interact with diverse tools (e.g., functional APIs) and generate solution plans that execute a series of API function calls in a step-by-step manner. The multitude of candidate API function calls significantly expands the action space, amplifying the critical need for efficient action space navigation. However, existing methods either struggle with unidirectional exploration in expansive action spaces, trapped into a locally optimal solution, or suffer from exhaustively traversing all potential actions, causing inefficient navigation. To address these issues, we propose ToolChain*, an efficient tree search-based planning algorithm for LLM-based agents. It formulates the entire action space as a decision tree, where each node represents a possible API function call involved in a solution plan. By incorporating the A* search algorithm with task-specific cost function design, it efficiently prunes high-cost branches that may involve incorrect actions, identifying the most low-cost valid path as the solution. Extensive experiments on multiple tool-use and reasoning tasks demonstrate that ToolChain* efficiently balances exploration and exploitation within an expansive action space. It outperforms state-of-the-art baselines on planning and reasoning tasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time, respectively.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and  Prompt Engineering</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13226</p>
  <p><b>作者</b>：Rahman S M Wahidur,  Ishmam Tashdeed,  Manjit Kaur,  Heung-No-Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cryptocurrencies gaining widespread, gaining widespread adoption, Blockchain technology, financial landscape, transparent nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Blockchain technology has revolutionized the financial landscape, with cryptocurrencies gaining widespread adoption for their decentralized and transparent nature. As the sentiment expressed on social media platforms can significantly influence cryptocurrency discussions and market movements, sentiment analysis has emerged as a crucial tool for understanding public opinion and predicting market trends. Motivated by the aim to enhance sentiment analysis accuracy in the cryptocurrency domain, this paper investigates fine-tuning techniques on large language models. This paper also investigates the efficacy of supervised fine-tuning and instruction-based fine-tuning on large language models for unseen tasks. Experimental results demonstrate a significant average zero-shot performance gain of 40% after fine-tuning, highlighting the potential of this technique in optimizing pre-trained language model efficiency. Additionally, the impact of instruction tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to the complete utilization of model capacity. To gain deeper insight about how instruction works with these language models, this paper presents an experimental investigation into the response of an instruction-based model under different instruction tuning setups. The investigation demonstrates that the model achieves an average accuracy score of 72.38% for short and simple instructions. This performance significantly outperforms its accuracy under long and complex instructions by over 12%, thereby effectively highlighting the profound significance of instruction characteristics in maximizing model performance.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy  Named Entity Recognition</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13213</p>
  <p><b>作者</b>：Besnik Fetahu,  Zhiyu Chen,  Sudipta Kar,  Oleg Rokhlenko,  Shervin Malmasi</p>
  <p><b>备注</b>：Accepted to the Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Named Entity Recognition, Entity Recognition covering, Recognition covering, fine-grained Named Entity, fine-grained Named</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to context noise.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Primacy Effect of ChatGPT</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13206</p>
  <p><b>作者</b>：Yiwei Wang,  Yujun Cai,  Muhao Chen,  Yuxuan Liang,  Bryan Hooi</p>
  <p><b>备注</b>：EMNLP 2023 short paper</p>
  <p><b>关键词</b>：natural language understanding, discriminative natural language, promising zero-shot performance, Instruction-tuned large language, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction-tuned large language models (LLMs), such as ChatGPT, have led to promising zero-shot performance in discriminative natural language understanding (NLU) tasks. This involves querying the LLM using a prompt containing the question, and the candidate labels to choose from. The question-answering capabilities of ChatGPT arise from its pre-training on large amounts of human-written text, as well as its subsequent fine-tuning on human preferences, which motivates us to ask: Does ChatGPT also inherits humans' cognitive biases? In this paper, we study the primacy effect of ChatGPT: the tendency of selecting the labels at earlier positions as the answer. We have two main findings: i) ChatGPT's decision is sensitive to the order of labels in the prompt; ii) ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer. We hope that our experiments and analyses provide additional insights into building more reliable ChatGPT-based solutions. We release the source code at this https URL.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：NameGuess: Column Name Expansion for Tabular Data</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13196</p>
  <p><b>作者</b>：Jiani Zhang,  Zhengyuan Shen,  Balasubramaniam Srinivasan,  Shen Wang,  Huzefa Rangwala,  George Karypis</p>
  <p><b>备注</b>：This work has been accepted to EMNLP'23</p>
  <p><b>关键词</b>：Recent advances, revolutionized many sectors, database industry, large language models, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in large language models have revolutionized many sectors, including the database industry. One common challenge when dealing with large volumes of tabular data is the pervasive use of abbreviated column names, which can negatively impact performance on various data search, access, and understanding tasks. To address this issue, we introduce a new task, called NameGuess, to expand column names (used in database schema) as a natural language generation problem. We create a training dataset of 384K abbreviated-expanded column pairs using a new data fabrication method and a human-annotated evaluation benchmark that includes 9.2K examples from real-world tables. To tackle the complexities associated with polysemy and ambiguity in NameGuess, we enhance auto-regressive language models by conditioning on table content and column header names -- yielding a fine-tuned model (with 2.7B parameters) that matches human performance. Furthermore, we conduct a comprehensive analysis (on multiple LLMs) to validate the effectiveness of table content in NameGuess and identify promising future opportunities. Code has been made available at this https URL.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13191</p>
  <p><b>作者</b>：Jianwei Li,  Qi Lei,  Wei Cheng,  Dongkuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language models, objective has recently, recently extended, language, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The pruning objective has recently extended beyond accuracy and sparsity to robustness in language models. Despite this, existing methods struggle to enhance robustness against adversarial attacks when continually increasing model sparsity and require a retraining process. As humans step into the era of large language models, these issues become increasingly prominent. This paper proposes that the robustness of language models is proportional to the extent of pre-trained knowledge they encompass. Accordingly, we introduce a post-training pruning strategy designed to faithfully replicate the embedding space and feature space of dense language models, aiming to conserve more pre-trained knowledge during the pruning process. In this setup, each layer's reconstruction error not only originates from itself but also includes cumulative error from preceding layers, followed by an adaptive rectification. Compared to other state-of-art baselines, our approach demonstrates a superior balance between accuracy, sparsity, robustness, and pruning cost with BERT on datasets SST2, IMDB, and AGNews, marking a significant stride towards robust pruning in language models.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Fast and Accurate Factual Inconsistency Detection Over Long Documents</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13189</p>
  <p><b>作者</b>：Barrett Martin Lattimer,  Patrick Chen,  Xinyuan Zhang,  Yi Yang</p>
  <p><b>备注</b>：To be published in EMNLP 2023 Main Conference, 8 pages</p>
  <p><b>关键词</b>：exhibit remarkable potential, current approaches struggle, models exhibit remarkable, Natural Language Inference, remarkable potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative AI models exhibit remarkable potential; however, hallucinations across various tasks present a significant challenge, particularly for longer inputs that current approaches struggle to address effectively. We introduce SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a task-agnostic model for detecting factual inconsistencies using a novel chunking strategy. Specifically, SCALE is a Natural Language Inference (NLI) based model that uses large text chunks to condition over long texts. This approach achieves state-of-the-art performance in factual inconsistency detection for diverse tasks and long inputs. Additionally, we leverage the chunking mechanism and employ a novel algorithm to explain SCALE's decisions through relevant source sentence retrieval. Our evaluations reveal that SCALE outperforms existing methods on both standard benchmarks and a new long-form dialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses competitive systems in efficiency and model explanation evaluations.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Breaking through Deterministic Barriers: Randomized Pruning Mask  Generation and Selection</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13183</p>
  <p><b>作者</b>：Jianwei Li,  Weizhi Gao,  Qi Lei,  Dongkuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model size constraints, size constraints, widely acknowledged, higher accuracy, accuracy than small</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is widely acknowledged that large and sparse models have higher accuracy than small and dense models under the same model size constraints. This motivates us to train a large model and then remove its redundant neurons or weights by pruning. Most existing works pruned the networks in a deterministic way, the performance of which solely depends on a single pruning criterion and thus lacks variety. Instead, in this paper, we propose a model pruning strategy that first generates several pruning masks in a designed random way. Subsequently, along with an effective mask-selection rule, the optimal mask is chosen from the pool of mask candidates. To further enhance efficiency, we introduce an early mask evaluation strategy, mitigating the overhead associated with training multiple masks. Our extensive experiments demonstrate that this approach achieves state-of-the-art performance across eight datasets from GLUE, particularly excelling at high levels of sparsity.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：CLIFT: Analysing Natural Distribution Shift on Question Answering Models  in Clinical Domain</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13146</p>
  <p><b>作者</b>：Ankit Pal</p>
  <p><b>备注</b>：Accepted at NeurIPS 2022 (Robustness in Sequence Modeling)</p>
  <p><b>关键词</b>：domain Question-answering task, clinical domain Question-answering, Question-answering task, testbed CLIFT, domain Question-answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical domain Question-answering task. The testbed includes 7.5k high-quality question answering samples to provide a diverse and reliable benchmark. We performed a comprehensive experimental study and evaluated several QA deep-learning models under the proposed testbed. Despite impressive results on the original test set, the performance degrades when applied to new test sets, which shows the distribution shift. Our findings emphasize the need for and the potential for increasing the robustness of clinical domain models under distributional shifts. The testbed offers one way to track progress in that direction. It also highlights the necessity of adopting evaluation metrics that consider robustness to natural distribution shifts. We plan to expand the corpus by adding more samples and model results. The full paper and the updated benchmark are available at this http URL</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Ask Me in English Instead: Cross-Lingual Evaluation of Large Language  Models for Healthcare Queries</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13132</p>
  <p><b>作者</b>：Jin,  Yiqiao,  Chandra,  Mohit,  Verma,  Gaurav, Hu,  Yibo,  De Choudhury,  Munmun,  Kumar,  Srijan</p>
  <p><b>备注</b>：18 pages, 7 figures</p>
  <p><b>关键词</b>：general public accesses, general public, public accesses, accesses and consumes, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating LLMs as conversational agents for everyday queries. While LLMs demonstrate impressive language understanding and generation proficiencies, concerns regarding their safety remain paramount in these high-stake domains. Moreover, the development of LLMs is disproportionately focused on English. It remains unclear how these LLMs perform in the context of non-English languages, a gap that is critical for ensuring equity in the real-world use of these systems.This paper provides a framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries. Our empirically-derived framework XlingEval focuses on three fundamental criteria for evaluating LLM responses to naturalistic human-authored health-related questions: correctness, consistency, and verifiability. Through extensive experiments on four major global languages, including English, Spanish, Chinese, and Hindi, spanning three expert-annotated large health Q&A datasets, and through an amalgamation of algorithmic and human-evaluation strategies, we found a pronounced disparity in LLM responses across these languages, indicating a need for enhanced cross-lingual capabilities. We further propose XlingHealth, a cross-lingual benchmark for examining the multilingual capabilities of LLMs in the healthcare context. Our findings underscore the pressing need to bolster the cross-lingual capacities of these models, and to provide an equitable information ecosystem accessible to all.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Auto-Instruct: Automatic Instruction Generation and Ranking for  Black-Box Language Models</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13127</p>
  <p><b>作者</b>：Zhihan Zhang,  Shuohang Wang,  Wenhao Yu,  Yichong Xu,  Dan Iter,  Qingkai Zeng,  Yang Liu,  Chenguang Zhu,  Meng Jiang</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 Findings. Work was done before July 2023</p>
  <p><b>关键词</b>：Large language models, natural language instructions, Large language, task-specific fine-tuning, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Unsupervised Candidate Answer Extraction through Differentiable  Masker-Reconstructor Model</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13106</p>
  <p><b>作者</b>：Zhuoer Wang,  Yicheng Wang,  Ziwei Zhu,  James Caverlee</p>
  <p><b>备注</b>：EMNLP 2023 - Findings</p>
  <p><b>关键词</b>：question generation systems, Question generation, extracting qualified candidate, candidate answer extraction, generation systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question generation is a widely used data augmentation approach with extensive applications, and extracting qualified candidate answers from context passages is a critical step for most question generation systems. However, existing methods for candidate answer extraction are reliant on linguistic rules or annotated data that face the partial annotation issue and challenges in generalization. To overcome these limitations, we propose a novel unsupervised candidate answer extraction approach that leverages the inherent structure of context passages through a Differentiable Masker-Reconstructor (DMR) Model with the enforcement of self-consistency for picking up salient information tokens. We curated two datasets with exhaustively-annotated answers and benchmark a comprehensive set of supervised and unsupervised candidate answer extraction methods. We demonstrate the effectiveness of the DMR model by showing its performance is superior among unsupervised methods and comparable to supervised methods.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：No offence, Bert -- I insult only humans! Multiple addressees  sentence-level attack on toxicity detection neural network</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13099</p>
  <p><b>作者</b>：Sergey Berezin,  Reza Farahbakhsh,  Noel Crespi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：toxicity detector models, black-box toxicity detector, efficient sentence-level attack, detector models, introduce a simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Do Language Models Learn about Legal Entity Types during Pretraining?</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13092</p>
  <p><b>作者</b>：Claire Barale,  Michael Rovatsos,  Nehal Bhuta</p>
  <p><b>备注</b>：Accepted for publication at the 5th Natural Legal Language Processing Workshop (NLLP) hosted at EMNLP2023</p>
  <p><b>关键词</b>：acquire diverse linguistic, diverse linguistic knowledge, valuable source, source of incidental, incidental supervision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) have proven their ability to acquire diverse linguistic knowledge during the pretraining phase, potentially serving as a valuable source of incidental supervision for downstream tasks. However, there has been limited research conducted on the retrieval of domain-specific knowledge, and specifically legal knowledge. We propose to explore the task of Entity Typing, serving as a proxy for evaluating legal knowledge as an essential aspect of text comprehension, and a foundational task to numerous downstream legal NLP applications. Through systematic evaluation and analysis and two types of prompting (cloze sentences and QA-based templates) and to clarify the nature of these acquired cues, we compare diverse types and lengths of entities both general and domain-specific entities, semantics or syntax signals, and different LM pretraining corpus (generic and legal-oriented) and architectures (encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2 performs well on certain entities and exhibits potential for substantial improvement with optimized prompt templates, (2) law-oriented LMs show inconsistent performance, possibly due to variations in their training corpus, (3) LMs demonstrate the ability to type entities even in the case of multi-token entities, (4) all models struggle with entities belonging to sub-domains of the law (5) Llama2 appears to frequently overlook syntactic cues, a shortcoming less present in BERT-based architectures.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：From Multilingual Complexity to Emotional Clarity: Leveraging  Commonsense to Unveil Emotions in Code-Mixed Dialogues</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13080</p>
  <p><b>作者</b>：Shivani Kumar,  Ramaneswaran S,  Md Shad Akhtar,  Tanmoy Chakraborty</p>
  <p><b>备注</b>：Paper accepted in EMNLP 2023. 15 pages, 6 figures, 9 tables</p>
  <p><b>关键词</b>：driving NLP research, driving NLP, Emotion Recognition, NLP research, human communication</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding emotions during conversation is a fundamental aspect of human communication, driving NLP research for Emotion Recognition in Conversation (ERC). While considerable research has focused on discerning emotions of individual speakers in monolingual dialogues, understanding the emotional dynamics in code-mixed conversations has received relatively less attention. This motivates our undertaking of ERC for code-mixed conversations in this study. Recognizing that emotional intelligence encompasses a comprehension of worldly knowledge, we propose an innovative approach that integrates commonsense information with dialogue context to facilitate a deeper understanding of emotions. To achieve this, we devise an efficient pipeline that extracts relevant commonsense from existing knowledge graphs based on the code-mixed input. Subsequently, we develop an advanced fusion technique that seamlessly combines the acquired commonsense information with the dialogue representation obtained from a dedicated dialogue understanding module. Our comprehensive experimentation showcases the substantial performance improvement obtained through the systematic incorporation of commonsense in ERC. Both quantitative assessments and qualitative analyses further corroborate the validity of our hypothesis, reaffirming the pivotal role of commonsense integration in enhancing ERC.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13068</p>
  <p><b>作者</b>：Muhammad Asif Ali,  Maha Alshmrani,  Jianbin Qin,  Yan Hu,  Di Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bilingual Lexical Induction, Lexical Induction, individual embedding spaces, Bilingual Lexical, challenge in NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bilingual Lexical Induction (BLI) is a core challenge in NLP, it relies on the relative isomorphism of individual embedding spaces. Existing attempts aimed at controlling the relative isomorphism of different embedding spaces fail to incorporate the impact of semantically related words in the model training objective. To address this, we propose GARI that combines the distributional training objectives with multiple isomorphism losses guided by the graph attention network. GARI considers the impact of semantical variations of words in order to define the relative isomorphism of the embedding spaces. Experimental evaluation using the Arabic language data set shows that GARI outperforms the existing research by improving the average P@1 by a relative score of up to 40.95% and 76.80% for in-domain and domain mismatch settings respectively. We release the codes for GARI at this https URL.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Quality-Diversity through AI Feedback</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13032</p>
  <p><b>作者</b>：Herbie Bradley,  Andrew Dai,  Hannah Teufel,  Jenny Zhang,  Koen Oostermeijer,  Marco Bellagente,  Jeff Clune,  Kenneth Stanley,  Grégory Schott,  Joel Lehman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text-generation problems, users may prefer, single response, diverse range, QDAIF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through AI feedback, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-QD controls. Further, human evaluation of QDAIF-generated creative texts validates reasonable agreement between AI and human evaluation. Our results thus highlight the potential of AI feedback to guide open-ended search for creative and original solutions, providing a recipe that seemingly generalizes to many domains and modalities. In this way, QDAIF is a step towards AI systems that can independently search, diversify, evaluate, and improve, which are among the core skills underlying human society's capacity for innovation.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：A Use Case: Reformulating Query Rewriting as a Statistical Machine  Translation Problem</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13031</p>
  <p><b>作者</b>：Abdullah Can Algan,  Emre Yürekli,  Aykut Çayır</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve relevant web, relevant web content, retrieve relevant, search engines, important challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most important challenges for modern search engines is to retrieve relevant web content based on user queries. In order to achieve this challenge, search engines have a module to rewrite user queries. That is why modern web search engines utilize some statistical and neural models used in the natural language processing domain. Statistical machine translation is a well-known NLP method among them. The paper proposes a query rewriting pipeline based on a monolingual machine translation model that learns to rewrite Arabic user search queries. This paper also describes preprocessing steps to create a mapping between user queries and web page titles.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Reliable Academic Conference Question Answering: A Study Based on Large  Language Model</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13028</p>
  <p><b>作者</b>：Zhiwei Huang,  Long Jin,  Junjie Wang,  Mingchen Tu,  Yin Hua,  Zhiqiang Liu,  Jiawei Meng,  Huajun Chen,  Wen Zhang</p>
  <p><b>备注</b>：10 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：fostering global scholarly, global scholarly communication, fostering global, scholarly communication, rapid growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid growth of computer science has led to a proliferation of research presented at academic conferences, fostering global scholarly communication. Researchers consistently seek accurate, current information about these events at all stages. This data surge necessitates an intelligent question-answering system to efficiently address researchers' queries and ensure awareness of the latest advancements. The information of conferences is usually published on their official website, organized in a semi-structured way with a lot of text. To address this need, we have developed the ConferenceQA dataset for 7 diverse academic conferences with human annotations. Firstly, we employ a combination of manual and automated methods to organize academic conference data in a semi-structured JSON format. Subsequently, we annotate nearly 100 question-answer pairs for each conference. Each pair is classified into four different dimensions. To ensure the reliability of the data, we manually annotate the source of each answer. In light of recent advancements, Large Language Models (LLMs) have demonstrated impressive performance in various NLP tasks. They have demonstrated impressive capabilities in information-seeking question answering after instruction fine-tuning, and as such, we present our conference QA study based on LLM. Due to hallucination and outdated knowledge of LLMs, we adopt retrieval based methods to enhance LLMs' question-answering abilities. We have proposed a structure-aware retrieval method, specifically designed to leverage inherent structural information during the retrieval process. Empirical validation on the ConferenceQA dataset has demonstrated the effectiveness of this method. The dataset and code are readily accessible on this https URL.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Powerset multi-class cross entropy loss for neural speaker diarization</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13025</p>
  <p><b>作者</b>：Alexis Plaquet (IRIT-SAMoVA),  Hervé Bredin (IRIT-SAMoVA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised EEND diarization, permutation-invariant training, addressing speaker diarization, problem with permutation-invariant, EEND showing great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since its introduction in 2019, the whole end-to-end neural diarization (EEND) line of work has been addressing speaker diarization as a frame-wise multi-label classification problem with permutation-invariant training. Despite EEND showing great promise, a few recent works took a step back and studied the possible combination of (local) supervised EEND diarization with (global) unsupervised clustering. Yet, these hybrid contributions did not question the original multi-label formulation. We propose to switch from multi-label (where any two speakers can be active at the same time) to powerset multi-class classification (where dedicated classes are assigned to pairs of overlapping speakers). Through extensive experiments on 9 different benchmarks, we show that this formulation leads to significantly better performance (mostly on overlapping speech) and robustness to domain mismatch, while eliminating the detection threshold hyperparameter, critical for the multi-label formulation.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Towards Anytime Fine-tuning: Continually Pre-trained Language Models  with Hypernetwork Prompt</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13024</p>
  <p><b>作者</b>：Gangwei Jiang,  Caigao Jiang,  Siqiao Xue,  James Y. Zhang,  Jun Zhou,  Defu Lian,  Ying Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pre-trained model, fast-evolving world, urgent for adapting, continually pre-trained model, Continual pre-training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual pre-training has been urgent for adapting a pre-trained model to a multitude of domains and tasks in the fast-evolving world. In practice, a continually pre-trained model is expected to demonstrate not only greater capacity when fine-tuned on pre-trained domains but also a non-decreasing performance on unseen ones. In this work, we first investigate such anytime fine-tuning effectiveness of existing continual pre-training approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. The agreement loss maximally preserves the generalization of a pre-trained model to new domains, and the disagreement one guards the exclusiveness of the generated hidden states for each domain. Remarkably, prompts by the hypernetwork alleviate the domain identity when fine-tuning and promote knowledge transfer across domains. Our method achieved improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively, demonstrating its efficacy.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：GraphGPT: Graph Instruction Tuning for Large Language Models</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13023</p>
  <p><b>作者</b>：Jiabin Tang,  Yuhao Yang,  Wei Wei,  Lei Shi,  Lixin Su,  Suqi Cheng,  Dawei Yin,  Chao Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, recursive information exchange, Graph Neural, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have advanced graph structure understanding via recursive information exchange and aggregation among graph nodes. To improve model robustness, self-supervised learning (SSL) has emerged as a promising approach for data augmentation. However, existing methods for generating pre-trained graph embeddings often rely on fine-tuning with specific downstream task labels, which limits their usability in scenarios where labeled data is scarce or unavailable. To address this, our research focuses on advancing the generalization capabilities of graph models in challenging zero-shot learning scenarios. Inspired by the success of large language models (LLMs), we aim to develop a graph-oriented LLM that can achieve high generalization across diverse downstream datasets and tasks, even without any information available from the downstream graph data. In this work, we present the GraphGPT framework that aligns LLMs with graph structural knowledge with a graph instruction tuning paradigm. Our framework incorporates a text-graph grounding component to establish a connection between textual information and graph structures. Additionally, we propose a dual-stage instruction tuning paradigm, accompanied by a lightweight graph-text alignment projector. This paradigm explores self-supervised graph structural signals and task-specific graph instructions, to guide LLMs in understanding complex graph structures and improving their adaptability across different downstream tasks. Our framework is evaluated on supervised and zero-shot graph learning tasks, demonstrating superior generalization and outperforming state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised  Language Understanding</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13022</p>
  <p><b>作者</b>：Jianing Wang,  Qiushi Sun,  Nuo Chen,  Chengyu Wang,  Jun Huang,  Ming Gao,  Xiang Li</p>
  <p><b>备注</b>：Accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：large pre-trained language, typically produces inferior, pre-trained language models, produces inferior performance, massive labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow the optimization of only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Position Interpolation Improves ALiBi Extrapolation</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13017</p>
  <p><b>作者</b>：Faisal Al-Khateeb,  Nolan Dey,  Daria Soboleva,  Joel Hestness</p>
  <p><b>备注</b>：4 pages content, 1 page references, 4 figures</p>
  <p><b>关键词</b>：longer sequence lengths, rotary position embeddings, Linear position interpolation, sequence lengths, extrapolate to longer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear position interpolation helps pre-trained models using rotary position embeddings (RoPE) to extrapolate to longer sequence lengths. We propose using linear position interpolation to extend the extrapolation range of models using Attention with Linear Biases (ALiBi). We find position interpolation significantly improves extrapolation capability on upstream language modelling and downstream summarization and retrieval tasks.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Audio-AdapterFusion: A Task-ID-free Approach for Efficient and  Non-Destructive Multi-task Speech Recognition</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13015</p>
  <p><b>作者</b>：Hillary Ngai,  Rohan Agrawal,  Neeraj Gaur,  Ronny Huang,  Parisa Haghani,  Pedro Moreno Mengibar</p>
  <p><b>备注</b>：2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) Proceedings</p>
  <p><b>关键词</b>：composable alternative, large ASR models, scale the deployment, deployment of large, large ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adapters are an efficient, composable alternative to full fine-tuning of pre-trained models and help scale the deployment of large ASR models to many tasks. In practice, a task ID is commonly prepended to the input during inference to route to single-task adapters for the specified task. However, one major limitation of this approach is that the task ID may not be known during inference, rendering it unsuitable for most multi-task settings. To address this, we propose three novel task-ID-free methods to combine single-task adapters in multi-task ASR and investigate two learning algorithms for training. We evaluate our methods on 10 test sets from 4 diverse ASR tasks and show that our methods are non-destructive and parameter-efficient. While only updating 17% of the model parameters, our methods can achieve an 8% mean WER improvement relative to full fine-tuning and are on-par with task-ID adapter routing.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Large Language Model Prediction Capabilities: Evidence from a Real-World  Forecasting Tournament</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13014</p>
  <p><b>作者</b>：Philipp Schoenegger,  Peter S. Park</p>
  <p><b>备注</b>：13 pages, six visualizations (four figures, two tables)</p>
  <p><b>关键词</b>：Accurately predicting, important milestone, large language models, real-world forecasting tournaments, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence. However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent. To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform. The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict. Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts. We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question. We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis. Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts. A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data. This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Generative error correction for code-switching speech recognition using  large language models</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13013</p>
  <p><b>作者</b>：Chen Chen,  Yuchen Hu,  Chao-Han Huck Yang,  Hexin Liu,  Sabato Marco Siniscalchi,  Eng Siong Chng</p>
  <p><b>备注</b>：Submitted to ICASSP2024</p>
  <p><b>关键词</b>：speech refers, automatic speech recognition, N-best hypotheses, well-trained ASR models, N-best hypotheses generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code-switching (CS) speech refers to the phenomenon of mixing two or more languages within the same sentence. Despite the recent advances in automatic speech recognition (ASR), CS-ASR is still a challenging task ought to the grammatical structure complexity of the phenomenon and the data scarcity of specific training corpus. In this work, we propose to leverage large language models (LLMs) and lists of hypotheses generated by an ASR to address the CS problem. Specifically, we first employ multiple well-trained ASR models for N-best hypotheses generation, with the aim of increasing the diverse and informative elements in the set of hypotheses. Next, we utilize the LLMs to learn the hypotheses-to-transcription (H2T) mapping by adding a trainable low-rank adapter. Such a generative error correction (GER) method directly predicts the accurate transcription according to its expert linguistic knowledge and N-best hypotheses, resulting in a paradigm shift from the traditional language model rescoring or error correction techniques. Experimental evidence demonstrates that GER significantly enhances CS-ASR accuracy, in terms of reduced mixed error rate (MER). Furthermore, LLMs show remarkable data efficiency for H2T learning, providing a potential solution to the data scarcity problem of CS-ASR in low-resource languages.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：H2O Open Ecosystem for State-of-the-art Large Language Models</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13012</p>
  <p><b>作者</b>：Arno Candel,  Jon McKinney,  Philipp Singer,  Pascal Pfeiffer,  Maximilian Jeblick,  Chun Ming Lee,  Marcos V. Conde</p>
  <p><b>备注</b>：Empirical Methods in Natural Language Processing (EMNLP) 2023 Demo</p>
  <p><b>关键词</b>：represent a revolution, Large Language Models, Large Language, Language Models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) represent a revolution in AI. However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text. For this reason we need open, transparent and safe solutions. We introduce a complete open-source ecosystem for developing and testing LLMs. The goal of this project is to boost open alternatives to closed-source approaches. We release h2oGPT, a family of fine-tuned LLMs from 7 to 70 Billion parameters. We also introduce H2O LLM Studio, a framework and no-code GUI designed for efficient fine-tuning, evaluation, and deployment of LLMs using the most recent state-of-the-art techniques. Our code and models are licensed under fully permissive Apache 2.0 licenses. We believe open-source language models help to boost AI development and make it more accessible and trustworthy. The demo is available at: this https URL</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Compositional preference models for aligning LMs</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13011</p>
  <p><b>作者</b>：Dongyoung Go,  Tomasz Korbak,  Germán Kruszewski,  Jos Rozen,  Marc Dymetman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Compositional Preference Models, Preference Models, increasingly important, important to align, Preference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As language models (LMs) become more capable, it is increasingly important to align them with human preferences. However, the dominant paradigm for training Preference Models (PMs) for that purpose suffers from fundamental limitations, such as lack of transparency and scalability, along with susceptibility to overfitting the preference dataset. We propose Compositional Preference Models (CPMs), a novel PM framework that decomposes one global preference assessment into several interpretable features, obtains scalar scores for these features from a prompted LM, and aggregates these scores using a logistic regression classifier. CPMs allow to control which properties of the preference data are used to train the preference model and to build it based on features that are believed to underlie the human preference judgment. Our experiments show that CPMs not only improve generalization and are more robust to overoptimization than standard PMs, but also that best-of-n samples obtained using CPMs tend to be preferred over samples obtained using conventional PMs. Overall, our approach demonstrates the benefits of endowing PMs with priors about which features determine human preferences while relying on LM capabilities to extract those features in a scalable and robust way.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：LoBaSS: Gauging Learnability in Supervised Fine-tuning Data</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13008</p>
  <p><b>作者</b>：Haotian Zhou,  Tingkai Liu,  Qianli Ma,  Jianbo Yuan,  Pengfei Liu,  Yang You,  Hongxia Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligning Large Language, Large Language Models, Large Language, specific task prerequisites, aligning Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency. In experimental comparisons involving 7B and 13B models, our LoBaSS method is able to surpass full-data fine-tuning at merely 6% of the total training data. When employing 16.7% of the data, LoBaSS harmonizes the model's capabilities across conversational and mathematical domains, proving its efficacy and adaptability.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Are Large Language Models Geospatially Knowledgeable?</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13002</p>
  <p><b>作者</b>：Prabin Bhandari,  Antonios Anastasopoulos,  Dieter Pfoser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, language processing tasks, natural language processing, performance of Large, informed geospatial decision-making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the impressive performance of Large Language Models (LLM) for various natural language processing tasks, little is known about their comprehension of geographic data and related ability to facilitate informed geospatial decision-making. This paper investigates the extent of geospatial knowledge, awareness, and reasoning abilities encoded within such pretrained LLMs. With a focus on autoregressive language models, we devise experimental approaches related to (i) probing LLMs for geo-coordinates to assess geospatial knowledge, (ii) using geospatial and non-geospatial prepositions to gauge their geospatial awareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to assess the models' geospatial reasoning capabilities and to determine locations of cities based on prompting. Our results confirm that it does not only take larger, but also more sophisticated LLMs to synthesize geospatial knowledge from textual information. As such, this research contributes to understanding the potential and limitations of LLMs in dealing with geospatial information.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Conversational Financial Information Retrieval Model (ConFIRM)</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13001</p>
  <p><b>作者</b>：Stephen Choi,  William Gazeley,  Siu Ho Wong,  Tingting Li</p>
  <p><b>备注</b>：10 pages, 2 figures, 2 tables, 2 appendices</p>
  <p><b>关键词</b>：finance merits exploration, large language models, leveraging their emergent, merits exploration, exponential growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.
ConFIRM comprises two modules:
1) a method to synthesize finance domain-specific question-answer pairs, and
2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.
ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Document-Level Relation Extraction with Relation Correlation Enhancement</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13000</p>
  <p><b>作者</b>：Yusheng Huang,  Zhouhan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：relation, relation correlations, task that focuses, focuses on identifying, Document-level relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Document-level relation extraction (DocRE) is a task that focuses on identifying relations between entities within a document. However, existing DocRE models often overlook the correlation between relations and lack a quantitative analysis of relation correlations. To address this limitation and effectively capture relation correlations in DocRE, we propose a relation graph method, which aims to explicitly exploit the interdependency among relations. Firstly, we construct a relation graph that models relation correlations using statistical co-occurrence information derived from prior relation knowledge. Secondly, we employ a re-weighting scheme to create an effective relation correlation matrix to guide the propagation of relation information. Furthermore, we leverage graph attention networks to aggregate relation embeddings. Importantly, our method can be seamlessly integrated as a plug-and-play module into existing models. Experimental results demonstrate that our approach can enhance the performance of multi-relation extraction, highlighting the effectiveness of considering relation correlations in DocRE.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Enhancing Health Data Interoperability with Large Language Models: A  FHIR Study</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12989</p>
  <p><b>作者</b>：Yikuan Li,  Hanyin Wang,  Halid Yerebakan,  Yoshihisa Shinagawa,  Yuan Luo</p>
  <p><b>备注</b>：Submitted to 2024 AMIA IS</p>
  <p><b>关键词</b>：healthcare data interoperability, enhance healthcare data, large language model, data interoperability, investigated the ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we investigated the ability of the large language model (LLM) to enhance healthcare data interoperability. We leveraged the LLM to convert clinical texts into their corresponding FHIR resources. Our experiments, conducted on 3,671 snippets of clinical text, demonstrated that the LLM not only streamlines the multi-step natural language processing and human calibration processes but also achieves an exceptional accuracy rate of over 90% in exact matches when compared to human annotations.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP  Performance on Low-Resource Languages</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13683</p>
  <p><b>作者</b>：Gabriel Oliveira dos Santos,  Diego Alysson Moreia,  Alef Iury Ferreira,  Jhessica Silva,  Luiz Pereira,  Pedro Bueno,  Thiago Sousa,  Helena Maia,  Nádia Da Silva,  Esther Colombini,  Helio Pedrini,  Sandra Avila</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cost-efficient framework designed, work introduces CAPIVARA, work introduces, cost-efficient framework, framework designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work introduces CAPIVARA, a cost-efficient framework designed to enhance the performance of multilingual CLIP models in low-resource languages. While CLIP has excelled in zero-shot vision-language tasks, the resource-intensive nature of model training remains challenging. Many datasets lack linguistic diversity, featuring solely English descriptions for images. CAPIVARA addresses this by augmenting text data using image captioning and machine translation to generate multiple synthetic captions in low-resource languages. We optimize the training pipeline with LiT, LoRA, and gradient checkpointing to alleviate the computational cost. Through extensive experiments, CAPIVARA emerges as state of the art in zero-shot tasks involving images and Portuguese texts. We show the potential for significant improvements in other low-resource languages, achieved by fine-tuning the pre-trained multilingual CLIP using CAPIVARA on a single GPU for 2 hours. Our model and code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Optimizing Retrieval-augmented Reader Models via Token Elimination</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13682</p>
  <p><b>作者</b>：Moshe Berchansky,  Peter Izsak,  Avi Caciularu,  Ido Dagan,  Moshe Wasserblat</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective retrieval-augmented language, retrieval-augmented language model, language model applied, fact checking, open-domain tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model applied across a variety of open-domain tasks, such as question answering, fact checking, etc. In FiD, supporting passages are first retrieved and then processed using a generative model (Reader), which can cause a significant bottleneck in decoding time, particularly with long outputs. In this work, we analyze the contribution and necessity of all the retrieved passages to the performance of reader models, and propose eliminating some of the retrieved information, at the token level, that might not contribute essential information to the answer generation process. We demonstrate that our method can reduce run-time by up to 62.2%, with only a 2% reduction in performance, and in some cases, even improve the performance results.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：RealFM: A Realistic Mechanism to Incentivize Data Contribution and  Device Participation</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13681</p>
  <p><b>作者</b>：Marco Bornstein,  Amrit Singh Bedi,  Anit Kumar Sahu,  Furqan Khan,  Furong Huang</p>
  <p><b>备注</b>：21 pages, 11 figures</p>
  <p><b>关键词</b>：Edge device participation, federating learning, device-server communication, typically studied, lens of device-server</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Edge device participation in federating learning (FL) has been typically studied under the lens of device-server communication (e.g., device dropout) and assumes an undying desire from edge devices to participate in FL. As a result, current FL frameworks are flawed when implemented in real-world settings, with many encountering the free-rider problem. In a step to push FL towards realistic settings, we propose RealFM: the first truly federated mechanism which (1) realistically models device utility, (2) incentivizes data contribution and device participation, and (3) provably removes the free-rider phenomena. RealFM does not require data sharing and allows for a non-linear relationship between model accuracy and utility, which improves the utility gained by the server and participating devices compared to non-participating devices as well as devices participating in other FL mechanisms. On real-world data, RealFM improves device and server utility, as well as data contribution, by up to 3 magnitudes and 7x respectively compared to baseline mechanisms.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Improving Long-form Speech Translation through Segmentation with Large  Language Models and Finite State Decoding Constraints</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13678</p>
  <p><b>作者</b>：Arya D. McCarthy,  Hao Zhang,  Shankar Kumar,  Felix Stahlberg,  Ke Wu</p>
  <p><b>备注</b>：accepted to the Findings of EMNLP 2023. arXiv admin note: text overlap with arXiv:2212.09895</p>
  <p><b>关键词</b>：obtaining high-quality translations, spoken language translation, content is long-form, spoken content, short units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One challenge in spoken language translation is that plenty of spoken content is long-form, but short units are necessary for obtaining high-quality translations. To address this mismatch, we adapt large language models (LLM) to split long ASR transcripts into segments that can be independently translated so as to maximize the overall translation quality. To combat the tendency of hallucination by LLMs, we incorporate finite-state constraints during decoding to eliminate invalid outputs. We discover that LLMs are adaptable to transcripts containing ASR errors through prompt-tuning or fine-tuning. In comparison to a state-of-the-art automatic punctuation baseline, our best LLM improves the average BLEU for English-German, English-Spanish, and English-Arabic TED talk translation in 9 test sets by 2.9 points, just by improving segmentation.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Using Human-like Mechanism to Weaken Effect of Pre-training Weight Bias  in Face-Recognition Convolutional Neural Network</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13674</p>
  <p><b>作者</b>：Haojiang Ying,  Yi-Fan Li,  Yiyang Chen</p>
  <p><b>备注</b>：24 pages, 6 figures</p>
  <p><b>关键词</b>：Convolutional neural network, Convolutional neural, neural network, artificial intelligence, CNNs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural network (CNN), as an important model in artificial intelligence, has been widely used and studied in different disciplines. The computational mechanisms of CNNs are still not fully revealed due to the their complex nature. In this study, we focused on 4 extensively studied CNNs (AlexNet, VGG11, VGG13, and VGG16) which has been analyzed as human-like models by neuroscientists with ample evidence. We trained these CNNs to emotion valence classification task by transfer learning. Comparing their performance with human data, the data unveiled that these CNNs would partly perform as human does. We then update the object-based AlexNet using self-attention mechanism based on neuroscience and behavioral data. The updated FE-AlexNet outperformed all the other tested CNNs and closely resembles human perception. The results further unveil the computational mechanisms of these CNNs. Moreover, this study offers a new paradigm to better understand and improve CNN performance via human data.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot  Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13670</p>
  <p><b>作者</b>：Daiju Kanaoka,  Motoharu Sonogashira,  Hakaru Tamukoh,  Yasutomo Kawanishi</p>
  <p><b>备注</b>：Accepted by BMVC2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, recently made significant, made significant progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Novel view synthesis has recently made significant progress with the advent of Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims to achieve this task from only a few images by introducing a new loss function for unknown viewpoints with no input images. The loss function assumes that a pre-trained feature extractor should output the same feature even if input images are captured at different viewpoints since the images contain the same object. However, while that assumption is ideal, in reality, it is known that as viewpoints continuously change, also feature vectors continuously change. Thus, the assumption can harm training. To avoid this harmful training, we propose ManifoldNeRF, a method for supervising feature vectors at unknown viewpoints using interpolated features from neighboring known viewpoints. Since the method provides appropriate supervision for each unknown viewpoint by the interpolated features, the volume representation is learned better than DietNeRF. Experimental results show that the proposed method performs better than others in a complex scene. We also experimented with several subsets of viewpoints from a set of viewpoints and identified an effective set of viewpoints for real environments. This provided a basic policy of viewpoint patterns for real-world application. The code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Automatic Unit Test Data Generation and Actor-Critic Reinforcement  Learning for Code Synthesis</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13669</p>
  <p><b>作者</b>：Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci</p>
  <p><b>备注</b>：9 pages + 4 pages appendix; 4 Figures, 4 Tables, 1 Algorithm; Accepted to Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Natural Language Generation, similar to Natural, Unit Tests, Language Modelling, Language Generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics -- through the use of Unit Tests to check its functional correctness -- lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models' coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model's performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：An experimental study for early diagnosing Parkinson's disease using  machine learning</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13654</p>
  <p><b>作者</b>：Md. Taufiqul Haque Khan Tusar,  Md. Touhidul Islam,  Abul Hasnat Sakil</p>
  <p><b>备注</b>：12 pages, 9 figures, 5 tables</p>
  <p><b>关键词</b>：neurological disorders worldwide, catastrophic neurological disorders, Parkinson Disease, catastrophic neurological, Machine Learning techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most catastrophic neurological disorders worldwide is Parkinson's Disease. Along with it, the treatment is complicated and abundantly expensive. The only effective action to control the progression is diagnosing it in the early stage. However, this is challenging because early detection necessitates a large and complex clinical study. This experimental work used Machine Learning techniques to automate the early detection of Parkinson's Disease from clinical characteristics, voice features and motor examination. In this study, we develop ML models utilizing a public dataset of 130 individuals, 30 of whom are untreated Parkinson's Disease patients, 50 of whom are Rapid Eye Movement Sleep Behaviour Disorder patients who are at a greater risk of contracting Parkinson's Disease, and 50 of whom are Healthy Controls. We use MinMax Scaler to rescale the data points, Local Outlier Factor to remove outliers, and SMOTE to balance existing class frequency. Afterwards, apply a number of Machine Learning techniques. We implement the approaches in such a way that data leaking and overfitting are not possible. Finally, obtained 100% accuracy in classifying PD and RBD patients, as well as 92% accuracy in classifying PD and HC individuals.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Contrastive Prefence Learning: Learning from Human Feedback without RL</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13639</p>
  <p><b>作者</b>：Joey Hejna,  Rafael Rafailov,  Harshit Sikchi,  Chelsea Finn,  Scott Niekum,  W. Bradley Knox,  Dorsa Sadigh</p>
  <p><b>备注</b>：Code released at this https URL</p>
  <p><b>关键词</b>：Human, human preferences, Learning, Reinforcement Learning, human intent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new family of algorithms for optimizing behavior from human feedback using the regret-based model of human preferences. Using the principle of maximum entropy, we derive Contrastive Preference Learning (CPL), an algorithm for learning optimal policies from preferences without learning reward functions, circumventing the need for RL. CPL is fully off-policy, uses only a simple contrastive objective, and can be applied to arbitrary MDPs. This enables CPL to elegantly scale to high-dimensional and sequential RLHF problems while being simpler than prior methods.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Analyzing the contribution of different passively collected data to  predict Stress and Depression</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13607</p>
  <p><b>作者</b>：Irene Bonafonte,  Cristina Bustos,  Abraham Larrazolo,  Gilberto Lorenzo Martinez Luna,  Adolfo Guzman Arenas,  Xavier Baro,  Isaac Tourgeman,  Mercedes Balcells,  Agata Lapedriza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mental health assessment, recognizing diverse aspects, captured data motivates, passively captured data, Neural Network models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The possibility of recognizing diverse aspects of human behavior and environmental context from passively captured data motivates its use for mental health assessment. In this paper, we analyze the contribution of different passively collected sensor data types (WiFi, GPS, Social interaction, Phone Log, Physical Activity, Audio, and Academic features) to predict daily selfreport stress and PHQ-9 depression score. First, we compute 125 mid-level features from the original raw data. These 125 features include groups of features from the different sensor data types. Then, we evaluate the contribution of each feature type by comparing the performance of Neural Network models trained with all features against Neural Network models trained with specific feature groups. Our results show that WiFi features (which encode mobility patterns) and Phone Log features (which encode information correlated with sleep patterns), provide significative information for stress and depression prediction.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：ReLM: Leveraging Language Models for Enhanced Chemical Reaction  Prediction</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13590</p>
  <p><b>作者</b>：Yaorui Shi,  An Zhang,  Enzhi Zhang,  Zhiyuan Liu,  Xiang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Predicting chemical reactions, employing Graph Neural, challenge in chemistry, involves forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose ReLM, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model's robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13583</p>
  <p><b>作者</b>：Ofir Arviv,  Dmitry Nikolaev,  Taelin Karidi,  Omri Abend</p>
  <p><b>备注</b>：Accepted to EMNLP Findings 2023</p>
  <p><b>关键词</b>：tackling typologically-distant languages, low-resource setting, impressive growth, abilities of multilingual, face difficulties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via source- or target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consistently outperforms strong baselines over different language pairs and model architectures. This performance advantage holds true in both zero-shot and few-shot scenarios.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Tree Search in DAG Space with Model-based Reinforcement Learning for  Causal Discovery</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13576</p>
  <p><b>作者</b>：Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Identifying causal structure, biology and economics, structure is central, fields ranging, ranging from strategic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying causal structure is central to many fields ranging from strategic decision-making to biology and economics. In this work, we propose a model-based reinforcement learning method for causal discovery based on tree search, which builds directed acyclic graphs incrementally. We also formalize and prove the correctness of an efficient algorithm for excluding edges that would introduce cycles, which enables deeper discrete search and sampling in DAG space. We evaluate our approach on two real-world tasks, achieving substantially better performance than the state-of-the-art model-free method and greedy search, constituting a promising advancement for combinatorial methods.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Unraveling the Enigma of Double Descent: An In-depth Analysis through  the Lens of Learned Feature Space</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13572</p>
  <p><b>作者</b>：Yufei Gu,  Xiaoqing Zheng,  Tomaso Aste</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning domain, Double descent, Double descent presents, presents a counter-intuitive, counter-intuitive aspect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Double descent presents a counter-intuitive aspect within the machine learning domain, and researchers have observed its manifestation in various models and tasks. While some theoretical explanations have been proposed for this phenomenon in specific contexts, an accepted theory to account for its occurrence in deep learning remains yet to be established. In this study, we revisit the phenomenon of double descent and demonstrate that its occurrence is strongly influenced by the presence of noisy data. Through conducting a comprehensive analysis of the feature space of learned representations, we unveil that double descent arises in imperfect models trained with noisy data. We argue that double descent is a consequence of the model first learning the noisy data until interpolation and then adding implicit regularization via over-parameterization acquiring therefore capability to separate the information from the noise. We postulate that double descent should never occur in well-regularized models.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Reward Shaping for Happier Autonomous Cyber Security Agents</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13565</p>
  <p><b>作者</b>：Elizabeth Bates,  Vasilios Mavroudis,  Chris Hicks</p>
  <p><b>备注</b>：12 Pages</p>
  <p><b>关键词</b>：exhibited increased potential, machine learning models, solving complex tasks, exhibited increased, increased potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As machine learning models become more capable, they have exhibited increased potential in solving complex tasks. One of the most promising directions uses deep reinforcement learning to train autonomous agents in computer network defense tasks. This work studies the impact of the reward signal that is provided to the agents when training for this task. Due to the nature of cybersecurity tasks, the reward signal is typically 1) in the form of penalties (e.g., when a compromise occurs), and 2) distributed sparsely across each defense episode. Such reward characteristics are atypical of classic reinforcement learning tasks where the agent is regularly rewarded for progress (cf. to getting occasionally penalized for failures). We investigate reward shaping techniques that could bridge this gap so as to enable agents to train more sample-efficiently and potentially converge to a better performance. We first show that deep reinforcement learning algorithms are sensitive to the magnitude of the penalties and their relative size. Then, we combine penalties with positive external rewards and study their effect compared to penalty-only training. Finally, we evaluate intrinsic curiosity as an internal positive reward mechanism and discuss why it might not be as advantageous for high-level network monitoring tasks.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Cache & Distil: Optimising API Calls to Large Language Models</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13561</p>
  <p><b>作者</b>：Guillem Ramírez,  Matthias Lindemann,  Alexandra Birch,  Ivan Titov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Model, costly API calls, smaller language model, fulfil user queries, Language Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deployment of generative AI tools often depends on costly API calls to a Large Language Model (LLM) to fulfil user queries. To curtail the frequency of these calls, one can employ a smaller language model -- a student -- which is continuously trained on the responses of the LLM. This student gradually gains proficiency in independently handling an increasing number of user requests, a process we term neural caching. The crucial element in neural caching is a policy that decides which requests should be processed by the student alone and which should be redirected to the LLM, subsequently aiding the student's learning. In this study, we focus on classification tasks, and we consider a range of classic active learning-based selection criteria as the policy. Our experiments suggest that Margin Sampling and Query by Committee bring consistent benefits across tasks and budgets.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：On sample complexity of conditional independence testing with Von Mises  estimator with application to causal discovery</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13553</p>
  <p><b>作者</b>：Fateme Jamshidi,  Luca Ganassali,  Negar Kiyavash</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nonparametric Von Mises, Von Mises estimator, Von Mises, multivariate distributions built, nonparametric Von</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivated by conditional independence testing, an essential step in constraint-based causal discovery algorithms, we study the nonparametric Von Mises estimator for the entropy of multivariate distributions built on a kernel density estimator. We establish an exponential concentration inequality for this estimator. We design a test for conditional independence (CI) based on our estimator, called VM-CI, which achieves optimal parametric rates under smoothness assumptions. Leveraging the exponential concentration, we prove a tight upper bound for the overall error of VM-CI. This, in turn, allows us to characterize the sample complexity of any constraint-based causal discovery algorithm that uses VM-CI for CI tests. To the best of our knowledge, this is the first sample complexity guarantee for causal discovery for continuous variables. Furthermore, we empirically show that VM-CI outperforms other popular CI tests in terms of either time or sample complexity (or both), which translates to a better performance in structure learning as well.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Provable Benefits of Multi-task RL under Non-Markovian Decision Making  Processes</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13550</p>
  <p><b>作者</b>：Ruiquan Huang,  Yuan Cheng,  Jing Yang,  Vincent Tan,  Yingbin Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov decision processes, yield significant benefits, Markov decision, shared latent structures, multi-task reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In multi-task reinforcement learning (RL) under Markov decision processes (MDPs), the presence of shared latent structures among multiple MDPs has been shown to yield significant benefits to the sample efficiency compared to single-task RL. In this paper, we investigate whether such a benefit can extend to more general sequential decision making problems, such as partially observable MDPs (POMDPs) and more general predictive state representations (PSRs). The main challenge here is that the large and complex model space makes it hard to identify what types of common latent structure of multi-task PSRs can reduce the model complexity and improve sample efficiency. To this end, we posit a joint model class for tasks and use the notion of $\eta$-bracketing number to quantify its complexity; this number also serves as a general metric to capture the similarity of tasks and thus determines the benefit of multi-task over single-task RL. We first study upstream multi-task learning over PSRs, in which all tasks share the same observation and action spaces. We propose a provably efficient algorithm UMT-PSR for finding near-optimal policies for all PSRs, and demonstrate that the advantage of multi-task learning manifests if the joint model class of PSRs has a smaller $\eta$-bracketing number compared to that of individual single-task learning. We also provide several example multi-task PSRs with small $\eta$-bracketing numbers, which reap the benefits of multi-task learning. We further investigate downstream learning, in which the agent needs to learn a new target task that shares some commonalities with the upstream tasks via a similarity constraint. By exploiting the learned PSRs from the upstream, we develop a sample-efficient algorithm that provably finds a near-optimal policy.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Towards Understanding Sycophancy in Language Models</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13548</p>
  <p><b>作者</b>：Mrinank Sharma,  Meg Tong,  Tomasz Korbak,  David Duvenaud,  Amanda Askell,  Samuel R. Bowman,  Newton Cheng,  Esin Durmus,  Zac Hatfield-Dodds,  Scott R. Johnston,  Shauna Kravec,  Timothy Maxwell,  Sam McCandlish,  Kamal Ndousse,  Oliver Rausch,  Nicholas Schiefer,  Da Yan,  Miranda Zhang,  Ethan Perez</p>
  <p><b>备注</b>：32 pages, 20 figures</p>
  <p><b>关键词</b>：Reinforcement learning, RLHF, popular technique, technique for training, training high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of RLHF models, likely driven in part by human preference judgements favoring sycophantic responses.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Positive-Unlabeled Node Classification with Structure-aware Graph  Learning</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13538</p>
  <p><b>作者</b>：Hansi Yang,  Yongqi Zhang,  Quanming Yao,  James Kwok</p>
  <p><b>备注</b>：CIKM 2023</p>
  <p><b>关键词</b>：important research problem, important research, research problem, Node classification, Node</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Node classification on graphs is an important research problem with many applications. Real-world graph data sets may not be balanced and accurate as assumed by most existing works. A challenging setting is positive-unlabeled (PU) node classification, where labeled nodes are restricted to positive nodes. It has diverse applications, e.g., pandemic prediction or network anomaly detection. Existing works on PU node classification overlook information in the graph structure, which can be critical. In this paper, we propose to better utilize graph structure for PU node classification. We first propose a distance-aware PU loss that uses homophily in graphs to introduce more accurate supervision. We also propose a regularizer to align the model with graph structure. Theoretical analysis shows that minimizing the proposed loss also leads to minimizing the expected loss with both positive and negative labels. Extensive empirical evaluation on diverse graph data sets demonstrates its superior performance over existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Technical Report for ICCV 2023 Visual Continual Learning Challenge:  Continuous Test-time Adaptation for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13533</p>
  <p><b>作者</b>：Damian Sójka,  Yuyang Liu,  Dipam Goswami,  Sebastian Cygert,  Bartłomiej Twardowski,  Joost van de Weijer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic segmentation task, segmentation task, semantic segmentation, TTA methods, source model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT dataset, in which there are only six sequences that start and end with the source domain. We conduct an analysis specifically on those sequences. Ground truth data for test split, on which the developed TTA methods are evaluated for leader board ranking, are not publicly available.
The proposed solution secured a 3rd place in a challenge and received an innovation award. Contrary to the solutions that scored better, we did not use any external pretrained models or specialized data augmentations, to keep the solutions as general as possible. We have focused on analyzing the distributional shift and developing a method that could adapt to changing data dynamics and generalize across different scenarios.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Controlled Randomness Improves the Performance of Transformer Models</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13526</p>
  <p><b>作者</b>：Tobias Deußer,  Cong Zhao,  Wolfgang Krämer,  David Leonhard,  Christian Bauckhage,  Rafet Sifa</p>
  <p><b>备注</b>：Accepted at ICMLA 2023, 10 pages, 2 tables</p>
  <p><b>关键词</b>：requiring large amounts, natural language models, natural language, aforementioned pre-training dataset, pre-training dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the pre-training step of natural language models, the main objective is to learn a general representation of the pre-training dataset, usually requiring large amounts of textual data to capture the complexity and diversity of natural language. Contrasting this, in most cases, the size of the data available to solve the specific downstream task is often dwarfed by the aforementioned pre-training dataset, especially in domains where data is scarce. We introduce controlled randomness, i.e. noise, into the training process to improve fine-tuning language models and explore the performance of targeted noise in addition to the parameters of these models. We find that adding such noise can improve the performance in our two downstream tasks of joint named entity recognition and relation extraction and text summarization.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Feature Selection and Hyperparameter Fine-tuning in Artificial Neural  Networks for Wood Quality Classification</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13490</p>
  <p><b>作者</b>：Mateus Roder,  Leandro Aparecido Passos,  João Paulo Papa,  André Luis Debiaso Rossi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：developing countries, performed by human, human operators, operators in small, small to median</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quality classification of wood boards is an essential task in the sawmill industry, which is still usually performed by human operators in small to median companies in developing countries. Machine learning algorithms have been successfully employed to investigate the problem, offering a more affordable alternative compared to other solutions. However, such approaches usually present some drawbacks regarding the proper selection of their hyperparameters. Moreover, the models are susceptible to the features extracted from wood board images, which influence the induction of the model and, consequently, its generalization power. Therefore, in this paper, we investigate the problem of simultaneously tuning the hyperparameters of an artificial neural network (ANN) as well as selecting a subset of characteristics that better describes the wood board quality. Experiments were conducted over a private dataset composed of images obtained from a sawmill industry and described using different feature descriptors. The predictive performance of the model was compared against five baseline methods as well as a random search, performing either ANN hyperparameter tuning and feature selection. Experimental results suggest that hyperparameters should be adjusted according to the feature set, or the features should be selected considering the hyperparameter values. In summary, the best predictive performance, i.e., a balanced accuracy of $0.80$, was achieved in two distinct scenarios: (i) performing only feature selection, and (ii) performing both tasks concomitantly. Thus, we suggest that at least one of the two approaches should be considered in the context of industrial applications.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Segment, Select, Correct: A Framework for Weakly-Supervised Referring  Segmentation</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13479</p>
  <p><b>作者</b>：Francisco Eiras,  Kemal Oksuz,  Adel Bibi,  Philip H.S. Torr,  Puneet K. Dokania</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Referring Image Segmentation, natural language sentences, Image Segmentation, Referring Image, language sentences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Referring Image Segmentation (RIS) - the problem of identifying objects in images through natural language sentences - is a challenging task currently mostly solved through supervised learning. However, while collecting referred annotation masks is a time-consuming process, the few existing weakly-supervised and zero-shot approaches fall significantly short in performance compared to fully-supervised learning ones. To bridge the performance gap without mask annotations, we propose a novel weakly-supervised framework that tackles RIS by decomposing it into three steps: obtaining instance masks for the object mentioned in the referencing instruction (segment), using zero-shot learning to select a potentially correct mask for the given instruction (select), and bootstrapping a model which allows for fixing the mistakes of zero-shot selection (correct). In our experiments, using only the first two steps (zero-shot segment and select) outperforms other zero-shot baselines by as much as 19%, while our full method improves upon this much stronger baseline and sets the new state-of-the-art for weakly-supervised RIS, reducing the gap between the weakly-supervised and fully-supervised methods in some cases from around 33% to as little as 14%. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：An Analysis of $D^α$ seeding for $k$-means</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13474</p>
  <p><b>作者</b>：Etienne Bamas,  Sai Ganesh Nagarajan,  Ola Svensson</p>
  <p><b>备注</b>：Abstract shortened to meet ArXiv requirements</p>
  <p><b>关键词</b>：Arthur and Vassilvitskii, alpha, sigma, mathrm, euclidean distances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most popular clustering algorithms is the celebrated $D^\alpha$ seeding algorithm (also know as $k$-means++ when $\alpha=2$) by Arthur and Vassilvitskii (2007), who showed that it guarantees in expectation an $O(2^{2\alpha}\cdot \log k)$-approximate solution to the ($k$,$\alpha$)-means cost (where euclidean distances are raised to the power $\alpha$) for any $\alpha\ge 1$. More recently, Balcan, Dick, and White (2018) observed experimentally that using $D^\alpha$ seeding with $\alpha>2$ can lead to a better solution with respect to the standard $k$-means objective (i.e. the $(k,2)$-means cost).
In this paper, we provide a rigorous understanding of this phenomenon. For any $\alpha>2$, we show that $D^\alpha$ seeding guarantees in expectation an approximation factor of $$ O_\alpha \left((g_\alpha)^{2/\alpha}\cdot \left(\frac{\sigma_{\mathrm{max}}}{\sigma_{\mathrm{min}}}\right)^{2-4/\alpha}\cdot (\min\{\ell,\log k\})^{2/\alpha}\right)$$ with respect to the standard $k$-means cost of any underlying clustering; where $g_\alpha$ is a parameter capturing the concentration of the points in each cluster, $\sigma_{\mathrm{max}}$ and $\sigma_{\mathrm{min}}$ are the maximum and minimum standard deviation of the clusters around their means, and $\ell$ is the number of distinct mixing weights in the underlying clustering (after rounding them to the nearest power of $2$). We complement these results by some lower bounds showing that the dependency on $g_\alpha$ and $\sigma_{\mathrm{max}}/\sigma_{\mathrm{min}}$ is tight.
Finally, we provide an experimental confirmation of the effects of the aforementioned parameters when using $D^\alpha$ seeding. Further, we corroborate the observation that $\alpha>2$ can indeed improve the $k$-means cost compared to $D^2$ seeding, and that this advantage remains even if we run Lloyd's algorithm after the seeding.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Stable Nonconvex-Nonconcave Training via Linear Interpolation</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13459</p>
  <p><b>作者</b>：Thomas Pethick,  Wanyun Xie,  Volkan Cevher</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural network training, linear interpolation, linear interpolation present, theoretical analysis, cohypomonotone problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a theoretical analysis of linear interpolation as a principled method for stabilizing (large-scale) neural network training. We argue that instabilities in the optimization process are often caused by the nonmonotonicity of the loss landscape and show how linear interpolation can help by leveraging the theory of nonexpansive operators. We construct a new optimization scheme called relaxed approximate proximal point (RAPP), which is the first explicit method to achieve last iterate convergence rates for the full range of cohypomonotone problems. The construction extends to constrained and regularized settings. By replacing the inner optimizer in RAPP we rediscover the family of Lookahead algorithms for which we establish convergence in cohypomonotone problems even when the base optimizer is taken to be gradient descent ascent. The range of cohypomonotone problems in which Lookahead converges is further expanded by exploiting that Lookahead inherits the properties of the base optimizer. We corroborate the results with experiments on generative adversarial networks which demonstrates the benefits of the linear interpolation present in both RAPP and Lookahead.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Correspondence learning between morphologically different robots through  task demonstrations</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13458</p>
  <p><b>作者</b>：Hakan Aktas,  Yukie Nagai,  Minoru Asada,  Erhan Oztop,  Emre Ugur</p>
  <p><b>备注</b>：7 pages, 11 figures, Submitted to IEEE Robotics Automation Letters (RA-L)</p>
  <p><b>关键词</b>：robots, large variety, robot, achieve, task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We observe a large variety of robots in terms of their bodies, sensors, and actuators. Given the commonalities in the skill sets, teaching each skill to each different robot independently is inefficient and not scalable when the large variety in the robotic landscape is considered. If we can learn the correspondences between the sensorimotor spaces of different robots, we can expect a skill that is learned in one robot can be more directly and easily transferred to the other robots. In this paper, we propose a method to learn correspondences between robots that have significant differences in their morphologies: a fixed-based manipulator robot with joint control and a differential drive mobile robot. For this, both robots are first given demonstrations that achieve the same tasks. A common latent representation is formed while learning the corresponding policies. After this initial learning stage, the observation of a new task execution by one robot becomes sufficient to generate a latent space representation pertaining to the other robot to achieve the same task. We verified our system in a set of experiments where the correspondence between two simulated robots is learned (1) when the robots need to follow the same paths to achieve the same task, (2) when the robots need to follow different trajectories to achieve the same task, and (3) when complexities of the required sensorimotor trajectories are different for the robots considered. We also provide a proof-of-the-concept realization of correspondence learning between a real manipulator robot and a simulated mobile robot.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Random Matrix Analysis to Balance between Supervised and Unsupervised  Learning under the Low Density Separation Assumption</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13434</p>
  <p><b>作者</b>：Vasilii Feofanov,  Malik Tiomoko,  Aladin Virmaux</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low density separation, density separation assumption, analyze semi-supervised classification, low density, density separation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a theoretical framework to analyze semi-supervised classification under the low density separation assumption in a high-dimensional regime. In particular, we introduce QLDS, a linear classification model, where the low density separation assumption is implemented via quadratic margin maximization. The algorithm has an explicit solution with rich theoretical properties, and we show that particular cases of our algorithm are the least-square support vector machine in the supervised case, the spectral clustering in the fully unsupervised regime, and a class of semi-supervised graph-based approaches. As such, QLDS establishes a smooth bridge between these supervised and unsupervised learning methods. Using recent advances in the random matrix theory, we formally derive a theoretical evaluation of the classification error in the asymptotic regime. As an application, we derive a hyperparameter selection policy that finds the best balance between the supervised and the unsupervised terms of our learning criterion. Finally, we provide extensive illustrations of our framework, as well as an experimental study on several benchmarks to demonstrate that QLDS, while being computationally more efficient, improves over cross-validation for hyperparameter selection, indicating a high promise of the usage of random matrix theory for semi-supervised model selection.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Y-Diagonal Couplings: Approximating Posteriors with Conditional  Wasserstein Distances</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13433</p>
  <p><b>作者</b>：Jannis Chemseddine,  Paul Hagemann,  Christian Wald</p>
  <p><b>备注</b>：26 pages, 9 figures</p>
  <p><b>关键词</b>：conditional Wasserstein distance, generative models approximate, Wasserstein distance, conditional Wasserstein, conditional generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback Leibler divergence, it does not hold true for the Wasserstein distance. We will introduce a conditional Wasserstein distance with a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. By deriving its dual, we find a rigorous way to motivate the loss of conditional Wasserstein GANs. We outline conditions under which the vanilla and the conditional Wasserstein distance coincide. Furthermore, we will show numerical examples where training with the conditional Wasserstein distance yields favorable properties for posterior sampling.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：FLTracer: Accurate Poisoning Attack Provenance in Federated Learning</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13424</p>
  <p><b>作者</b>：Xinyu Zhang,  Qingyu Liu,  Zhongjie Ba,  Yuan Hong,  Tianhang Zheng,  Feng Lin,  Li Lu,  Kui Ren</p>
  <p><b>备注</b>：18 pages, 27 figures</p>
  <p><b>关键词</b>：enables multiple clients, promising distributed learning, distributed learning approach, Federated Learning, shared global model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a promising distributed learning approach that enables multiple clients to collaboratively train a shared global model. However, recent studies show that FL is vulnerable to various poisoning attacks, which can degrade the performance of global models or introduce backdoors into them. In this paper, we first conduct a comprehensive study on prior FL attacks and detection methods. The results show that all existing detection methods are only effective against limited and specific attacks. Most detection methods suffer from high false positives, which lead to significant performance degradation, especially in not independent and identically distributed (non-IID) settings. To address these issues, we propose FLTracer, the first FL attack provenance framework to accurately detect various attacks and trace the attack time, objective, type, and poisoned location of updates. Different from existing methodologies that rely solely on cross-client anomaly detection, we propose a Kalman filter-based cross-round detection to identify adversaries by seeking the behavior changes before and after the attack. Thus, this makes it resilient to data heterogeneity and is effective even in non-IID settings. To further improve the accuracy of our detection method, we employ four novel features and capture their anomalies with the joint decisions. Extensive evaluations show that FLTracer achieves an average true positive rate of over $96.88\%$ at an average false positive rate of less than $2.67\%$, significantly outperforming SOTA detection methods. \footnote{Code is available at \url{this https URL}.}</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：BRFL: A Blockchain-based Byzantine-Robust Federated Learning Model</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13403</p>
  <p><b>作者</b>：Yang Li,  Chunhe Xia,  Chang Li,  Tianbo Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Federated learning, increasing importance, importance of machine, privacy and security, security of training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing importance of machine learning, the privacy and security of training data have become critical. Federated learning, which stores data in distributed nodes and shares only model parameters, has gained significant attention for addressing this concern. However, a challenge arises in federated learning due to the Byzantine Attack Problem, where malicious local models can compromise the global model's performance during aggregation. This article proposes the Blockchain-based Byzantine-Robust Federated Learning (BRLF) model that combines federated learning with blockchain technology. This integration enables traceability of malicious models and provides incentives for locally trained clients. Our approach involves selecting the aggregation node based on Pearson's correlation coefficient, and we perform spectral clustering and calculate the average gradient within each cluster, validating its accuracy using local dataset of the aggregation nodes. Experimental results on public datasets demonstrate the superior byzantine robustness of our secure aggregation algorithm compared to other baseline byzantine robust aggregation methods, and proved our proposed model effectiveness in addressing the resource consumption problem.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Equivariant Deep Weight Space Alignment</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13397</p>
  <p><b>作者</b>：Aviv Navon,  Aviv Shamsian,  Ethan Fetaya,  Gal Chechik,  Nadav Dym,  Haggai Maron</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similarity estimation challenging, make simple operations, networks make simple, estimation challenging, make simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Permutation symmetries of deep networks make simple operations like model averaging and similarity estimation challenging. In many cases, aligning the weights of the networks, i.e., finding optimal permutations between their weights, is necessary. More generally, weight alignment is essential for a wide range of applications, from model merging, through exploring the optimization landscape of deep neural networks, to defining meaningful distance functions between neural networks. Unfortunately, weight alignment is an NP-hard problem. Prior research has mainly focused on solving relaxed versions of the alignment problem, leading to either time-consuming methods or sub-optimal solutions. To accelerate the alignment process and improve its quality, we propose a novel framework aimed at learning to solve the weight alignment problem, which we name Deep-Align. To that end, we first demonstrate that weight alignment adheres to two fundamental symmetries and then, propose a deep architecture that respects these symmetries. Notably, our framework does not require any labeled data. We provide a theoretical analysis of our approach and evaluate Deep-Align on several types of network architectures and learning setups. Our experimental results indicate that a feed-forward pass with Deep-Align produces better or equivalent alignments compared to those produced by current optimization algorithms. Additionally, our alignments can be used as an initialization for other methods to gain even better solutions with a significant speedup in convergence.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：RL-X: A Deep Reinforcement Learning Library (not only) for RoboCup</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13396</p>
  <p><b>作者</b>：Nico Bohlinger,  Klaus Dorer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, RoboCup Soccer Simulation, classic DRL benchmarks, Reinforcement Learning, Soccer Simulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the new Deep Reinforcement Learning (DRL) library RL-X and its application to the RoboCup Soccer Simulation 3D League and classic DRL benchmarks. RL-X provides a flexible and easy-to-extend codebase with self-contained single directory algorithms. Through the fast JAX-based implementations, RL-X can reach up to 4.5x speedups compared to well-known frameworks like Stable-Baselines3.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Learning Successor Representations with Distributed Hebbian Temporal  Memory</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13391</p>
  <p><b>作者</b>：Evgenii Dzhivelikian,  Petr Kuderov,  Aleksandr I. Panov</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：partially observable environments, Hebbian Temporal Memory, Distributed Hebbian Temporal, uncertainty in non-stationary, partially observable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare the SRs produced by DHTM to another biologically inspired HMM-like algorithm, CSCG. Our findings suggest that DHTM is a promising approach for addressing the challenges of online hidden representation learning in dynamic environments.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Music Augmentation and Denoising For Peak-Based Audio Fingerprinting</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13388</p>
  <p><b>作者</b>：Kamil Akesbi,  Dorian Desblancs,  Benjamin Martin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：short recording excerpts, recording excerpts, well-established solution, solution for song, short recording</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Audio fingerprinting is a well-established solution for song identification from short recording excerpts. Popular methods rely on the extraction of sparse representations, generally spectral peaks, and have proven to be accurate, fast, and scalable to large collections. However, real-world applications of audio identification often happen in noisy environments, which can cause these systems to fail. In this work, we tackle this problem by introducing and releasing a new audio augmentation pipeline that adds noise to music snippets in a realistic way, by stochastically mimicking real-world scenarios. We then propose and release a deep learning model that removes noisy components from spectrograms in order to improve peak-based fingerprinting systems' accuracy. We show that the addition of our model improves the identification performance of commonly used audio fingerprinting systems, even under noisy conditions.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Tuna: Instruction Tuning using Feedback from Large Language Models</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13385</p>
  <p><b>作者</b>：Haoran Li,  Yiran Liu,  Xingxing Zhang,  Wei Lu,  Furu Wei</p>
  <p><b>备注</b>：EMNLP 2023, code and data are available at this https URL</p>
  <p><b>关键词</b>：open-source large language, large language models, align model behaviors, human preferences, tuning of open-source</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a cost-effective way to align model behaviors with human preferences. However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses. In this paper, we propose finetuning an instruction-tuned LLM using our novel \textit{probabilistic ranking} and \textit{contextual ranking} approaches to increase the likelihood of generating better responses. Probabilistic ranking enables the instruction-tuned model to inherit the relative rankings of high-quality and low-quality responses from the teacher LLM. On the other hand, learning with contextual ranking allows the model to refine its own response distribution using the contextual understanding ability of stronger LLMs. Furthermore, we apply probabilistic ranking and contextual ranking sequentially to the instruction-tuned LLM. The resulting model, which we call \textbf{Tuna}, consistently improves the performance on Super Natural Instructions (119 test tasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results than several strong reinforcement learning baselines. Our code and data are available at \url{ this https URL}.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Salted Inference: Enhancing Privacy while Maintaining Efficiency of  Split Inference in Mobile Computing</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13384</p>
  <p><b>作者</b>：Mohammad Malekzadeh,  Fahim Kawsar</p>
  <p><b>备注</b>：6 Pages, 2 Figures</p>
  <p><b>关键词</b>：deep neural network, neural network, Split inference partitions, partitions a deep, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Split inference partitions a deep neural network (DNN) to run the early part at the edge and the later part in the cloud. This meets two key requirements for on-device machine learning: input privacy and compute efficiency. Still, an open question in split inference is output privacy, given that the output of a DNN is visible to the cloud. While encrypted computing can protect output privacy, it mandates extensive computation and communication resources. In this paper, we introduce "Salted DNNs": a novel method that lets clients control the semantic interpretation of DNN output at inference time while maintaining accuracy and efficiency very close to that of a standard DNN. Experimental evaluations conducted on both image and sensor data show that Salted DNNs achieve classification accuracy very close to standard DNNs, particularly when the salted layer is positioned within the early part to meet the requirements of split inference. Our method is general and can be applied to various DNNs. We open-source our code and results, as a benchmark for future studies.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Accelerated sparse Kernel Spectral Clustering for large scale data  clustering problems</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13381</p>
  <p><b>作者</b>：Mihaly Novak,  Rocco Langone,  Carlos Alzate,  Johan Suykens</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiway kernel spectral, based sparse KSC, ICD based sparse, sparse KSC algorithm, sparse multiway kernel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An improved version of the sparse multiway kernel spectral clustering (KSC) is presented in this brief. The original algorithm is derived from weighted kernel principal component (KPCA) analysis formulated within the primal-dual least-squares support vector machine (LS-SVM) framework. Sparsity is achieved then by the combination of the incomplete Cholesky decomposition (ICD) based low rank approximation of the kernel matrix with the so called reduced set method. The original ICD based sparse KSC algorithm was reported to be computationally far too demanding, especially when applied on large scale data clustering problems that actually it was designed for, which has prevented to gain more than simply theoretical relevance so far. This is altered by the modifications reported in this brief that drastically improve the computational characteristics. Solving the alternative, symmetrized version of the computationally most demanding core eigenvalue problem eliminates the necessity of forming and SVD of large matrices during the model construction. This results in solving clustering problems now within seconds that were reported to require hours without altering the results. Furthermore, sparsity is also improved significantly, leading to more compact model representation, increasing further not only the computational efficiency but also the descriptive power. These transform the original, only theoretically relevant ICD based sparse KSC algorithm applicable for large scale practical clustering problems. Theoretical results and improvements are demonstrated by computational experiments on carefully selected synthetic data as well as on real life problems such as image segmentation.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：SigFormer: Signature Transformers for Deep Hedging</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13369</p>
  <p><b>作者</b>：Anh Tong,  Thanh Nguyen-Tang,  Dongeun Lee,  Toan Tran,  Jaesik Choi</p>
  <p><b>备注</b>：ICAIF 2023</p>
  <p><b>关键词</b>：quantitative finance, deep learning research, promising direction, direction in quantitative, learning research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep hedging is a promising direction in quantitative finance, incorporating models and techniques from deep learning research. While giving excellent hedging strategies, models inherently requires careful treatment in designing architectures for neural networks. To mitigate such difficulties, we introduce SigFormer, a novel deep learning model that combines the power of path signatures and transformers to handle sequential data, particularly in cases with irregularities. Path signatures effectively capture complex data patterns, while transformers provide superior sequential attention. Our proposed model is empirically compared to existing methods on synthetic data, showcasing faster learning and enhanced robustness, especially in the presence of irregular underlying price data. Additionally, we validate our model performance through a real-world backtest on hedging the SP 500 index, demonstrating positive outcomes.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：VFedMH: Vertical Federated Learning for Training Multi-party  Heterogeneous Models</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13367</p>
  <p><b>作者</b>：Shuo Wang,  Keke Gai,  Jing Yu,  Liehuang Zhu</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：Vertical Federated Learning, gained increasing attention, Vertical Federated, Federated Learning, called Vertical Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vertical Federated Learning (VFL) has gained increasing attention as a novel training paradigm that integrates sample alignment and feature union. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this issue, this paper proposes a novel approach called Vertical Federated learning for training Multi-parties Heterogeneous models (VFedMH). VFedMH focuses on aggregating the embeddings of each participant's knowledge instead of intermediate results during forward propagation. The active party, who possesses labels and features of the sample, in VFedMH securely aggregates local embeddings to obtain global knowledge embeddings, and sends them to passive parties. The passive parties, who own only features of the sample, then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the labels, so the local model gradient cannot be calculated locally. To overcome this limitation, the active party assists the passive party in computing its local heterogeneous model gradients. Then, each participant trains their local model using the heterogeneous model gradients. The objective is to minimize the loss value of their respective local heterogeneous models. Additionally, the paper provides a theoretical analysis of VFedMH's convergence performance. Extensive experiments are conducted to demonstrate that VFedMH can simultaneously train multiple heterogeneous models with heterogeneous optimization and outperform some recent methods in model performance.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Dissecting Causal Biases</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13364</p>
  <p><b>作者</b>：Rūta Binkytė,  Sami Zhioua,  Yassine Turki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learning-based automated decision, automated decision systems, Accurately measuring discrimination, machine learning-based automated, measuring discrimination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately measuring discrimination in machine learning-based automated decision systems is required to address the vital issue of fairness between subpopulations and/or individuals. Any bias in measuring discrimination can lead to either amplification or underestimation of the true value of discrimination. This paper focuses on a class of bias originating in the way training data is generated and/or collected. We call such class causal biases and use tools from the field of causality to formally define and analyze such biases. Four sources of bias are considered, namely, confounding, selection, measurement, and interaction. The main contribution of this paper is to provide, for each source of bias, a closed-form expression in terms of the model parameters. This makes it possible to analyze the behavior of each source of bias, in particular, in which cases they are absent and in which other cases they are maximized. We hope that the provided characterizations help the community better understand the sources of bias in machine learning applications.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Towards General Error Diagnosis via Behavioral Testing in Machine  Translation</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13362</p>
  <p><b>作者</b>：Junjie Wu,  Lemao Liu,  Dit-Yan Yeung</p>
  <p><b>备注</b>：15 pages, 2 figures, accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：NLP models, capabilities of NLP, Behavioral testing, diagnosing linguistic errors, Behavioral testing offers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models. However, applying behavioral testing to machine translation (MT) systems is challenging as it generally requires human efforts to craft references for evaluating the translation quality of such systems on newly generated test cases. Existing works in behavioral testing of MT systems circumvent this by evaluating translation quality without references, but this restricts diagnosis to specific types of errors, such as incorrect translation of single numeric or currency words. In order to diagnose general errors, this paper proposes a new Bilingual Translation Pair Generation based Behavior Testing (BTPGBT) framework for conducting behavioral testing of MT systems. The core idea of BTPGBT is to employ a novel bilingual translation pair generation (BTPG) approach that automates the construction of high-quality test cases and their pseudoreferences. Experimental results on various MT systems demonstrate that BTPGBT could provide comprehensive and accurate behavioral testing results for general error diagnosis, which further leads to several insightful findings. Our code and data are available at https: //github.com/wujunjie1998/BTPGBT.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Test-Time Self-Adaptive Small Language Models for Question Answering</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13307</p>
  <p><b>作者</b>：Soyeong Jeong,  Jinheon Baek,  Sukmin Cho,  Sung Ju Hwang,  Jong C. Park</p>
  <p><b>备注</b>：EMNLP Findings 2023</p>
  <p><b>关键词</b>：large language models, Recent instruction-finetuned large, instruction-finetuned large language, achieved notable performances, Recent instruction-finetuned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent instruction-finetuned large language models (LMs) have achieved notable performances in various tasks, such as question-answering (QA). However, despite their ability to memorize a vast amount of general knowledge across diverse tasks, they might be suboptimal on specific tasks due to their limited capacity to transfer and adapt knowledge to target tasks. Moreover, further finetuning LMs with labeled datasets is often infeasible due to their absence, but it is also questionable if we can transfer smaller LMs having limited knowledge only with unlabeled test data. In this work, we show and investigate the capabilities of smaller self-adaptive LMs, only with unlabeled test data. In particular, we first stochastically generate multiple answers, and then ensemble them while filtering out low-quality samples to mitigate noise from inaccurate labels. Our proposed self-adaption strategy demonstrates significant performance improvements on benchmark QA datasets with higher robustness across diverse prompts, enabling LMs to stay stable. Code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Decoding the Silent Majority: Inducing Belief Augmented Social Graph  with Large Language Model for Response Forecasting</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13297</p>
  <p><b>作者</b>：Chenkai Sun,  Jinning Li,  Yi R. Fung,  Hou Pong Chan,  Tarek Abdelzaher,  ChengXiang Zhai,  Heng Ji</p>
  <p><b>备注</b>：Accepted at EMNLP 2023 Main Conference</p>
  <p><b>关键词</b>：enabling content producers, prevent unexpected negative, unexpected negative outcomes, moral injury, media plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic response forecasting for news media plays a crucial role in enabling content producers to efficiently predict the impact of news releases and prevent unexpected negative outcomes such as social conflict and moral injury. To effectively forecast responses, it is essential to develop measures that leverage the social dynamics and contextual information surrounding individuals, especially in cases where explicit profiles or historical actions of the users are limited (referred to as lurkers). As shown in a previous study, 97% of all tweets are produced by only the most active 25% of users. However, existing approaches have limited exploration of how to best process and utilize these important features. To address this gap, we propose a novel framework, named SocialSense, that leverages a large language model to induce a belief-centered graph on top of an existent social network, along with graph-based propagation to capture social dynamics. We hypothesize that the induced graph that bridges the gap between distant users who share similar beliefs allows the model to effectively capture the response patterns. Our method surpasses existing state-of-the-art in experimental evaluations for both zero-shot and supervised settings, demonstrating its effectiveness in response forecasting. Moreover, the analysis reveals the framework's capability to effectively handle unseen user and lurker scenarios, further highlighting its robustness and practical applicability.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13292</p>
  <p><b>作者</b>：Kihyun You,  Jawook Gu,  Jiyeon Ham,  Beomhee Park,  Jiho Kim,  Eun Kyoung Hong,  Woonhyunk Baek,  Byungseok Roh</p>
  <p><b>备注</b>：Accepted by MICCAI 2023</p>
  <p><b>关键词</b>：large-scale image-text pair, vision-language pre-training, costly annotation, greatly contributed, development of vision-language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A large-scale image-text pair dataset has greatly contributed to the development of vision-language pre-training (VLP) models, which enable zero-shot or few-shot classification without costly annotation. However, in the medical domain, the scarcity of data remains a significant challenge for developing a powerful VLP model. In this paper, we tackle the lack of image-text data in chest X-ray by expanding image-label pair as image-text pair via general prompt and utilizing multiple images and multiple sections in a radiologic report. We also design two contrastive losses, named ICL and TCL, for learning study-level characteristics of medical images and reports, respectively. Our model outperforms the state-of-the-art models trained under the same conditions. Also, enlarged dataset improve the discriminative power of our pre-trained model for classification, while sacrificing marginal retrieval performance. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Assessing Privacy Risks in Language Models: A Case Study on  Summarization Tasks</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13291</p>
  <p><b>作者</b>：Ruixiang Tang,  Gord Lueck,  Rodolfo Quispe,  Huseyin A Inan,  Janardhan Kulkarni,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP by achieving, field of NLP, Large language models, Large language, revolutionized the field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model's API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model's resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Learning Recurrent Models with Temporally Local Rules</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13284</p>
  <p><b>作者</b>：Azwar Abdulsalam,  Joseph G. Makin</p>
  <p><b>备注</b>：Presented at the "Localized Learning" workshop at the International Conference on Machine Learning (ICML), July 2023. 6 pages, 5 figures, 2 tables</p>
  <p><b>关键词</b>：Fitting generative models, sequential data typically, data typically involves, involves two recursive, recursive computations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fitting generative models to sequential data typically involves two recursive computations through time, one forward and one backward. The latter could be a computation of the loss gradient (as in backpropagation through time), or an inference algorithm (as in the RTS/Kalman smoother). The backward pass in particular is computationally expensive (since it is inherently serial and cannot exploit GPUs), and difficult to map onto biological processes. Work-arounds have been proposed; here we explore a very different one: requiring the generative model to learn the joint distribution over current and previous states, rather than merely the transition probabilities. We show on toy datasets that different architectures employing this principle can learn aspects of the data typically requiring the backward pass.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：FedLoRA: Model-Heterogeneous Personalized Federated Learning with LoRA  Tuning</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13283</p>
  <p><b>作者</b>：Liping Yi,  Han Yu,  Gang Wang,  Xiaoguang Liu</p>
  <p><b>备注</b>：11 pages, 11 figures</p>
  <p><b>关键词</b>：coordinates multiple participants, emerging machine learning, Personalized Federated Learning, central server coordinates, server coordinates multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging machine learning paradigm in which a central server coordinates multiple participants (a.k.a. FL clients) to train a model collaboratively on decentralized data with privacy protection. This paradigm constrains that all clients have to train models with the same structures (homogeneous). In practice, FL often faces statistical heterogeneity, system heterogeneity and model heterogeneity challenges. These challenging issues inspire the field of Model-Heterogeneous Personalized Federated Learning (MHPFL) which aims to train a personalized and heterogeneous local model for each FL client. Existing MHPFL approaches cannot achieve satisfactory model performance, acceptable computational overhead and efficient communication simultaneously. To bridge this gap, we propose a novel computation- and communication-efficient model-heterogeneous personalized Federated learning framework based on LoRA tuning (FedLoRA). It is designed to incorporate a homogeneous small adapter for each client's heterogeneous local model. Both models are trained following the proposed iterative training for global-local knowledge exchange. The homogeneous small local adapters are sent to the FL server to be aggregated into a global adapter. In this way, FL clients can train heterogeneous local models without incurring high computation and communication costs. We theoretically prove the non-convex convergence rate of FedLoRA. Extensive experiments on two real-world datasets demonstrate that FedLoRA outperforms six state-of-the-art baselines, beating the best approach by 1.35% in terms of test accuracy, 11.81 times computation overhead reduction and 7.41 times communication cost saving.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13276</p>
  <p><b>作者</b>：Xiangru Jian,  Yimu Wang</p>
  <p><b>备注</b>：Findings of EMNLP 2023</p>
  <p><b>关键词</b>：representation degeneration problem, significant advancements, linguistic modeling, degeneration problem, driven by breakthroughs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over recent decades, significant advancements in cross-modal retrieval are mainly driven by breakthroughs in visual and linguistic modeling. However, a recent study shows that multi-modal data representations tend to cluster within a limited convex cone (as representation degeneration problem), which hinders retrieval performance due to the inseparability of these representations. In our study, we first empirically validate the presence of the representation degeneration problem across multiple cross-modal benchmarks and methods. Next, to address it, we introduce a novel method, called InvGC, a post-processing technique inspired by graph convolution and average pooling. Specifically, InvGC defines the graph topology within the datasets and then applies graph convolution in a subtractive manner. This method effectively separates representations by increasing the distances between data points. To improve the efficiency and effectiveness of InvGC, we propose an advanced graph topology, LocalAdj, which only aims to increase the distances between each data point and its nearest neighbors. To understand why InvGC works, we present a detailed theoretical analysis, proving that the lower bound of recall will be improved after deploying InvGC. Extensive empirical results show that InvGC and InvGC w/LocalAdj significantly mitigate the representation degeneration problem, thereby enhancing retrieval performance.
Our code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：An Exploratory Study on Simulated Annealing for Feature Selection in  Learning-to-Rank</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13269</p>
  <p><b>作者</b>：Mohd. Sayemul Haque,  Md. Fahim,  Muhammad Ibrahim</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：supervised machine learning, supervised machine, applied domain, machine learning, domain of supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning-to-rank is an applied domain of supervised machine learning. As feature selection has been found to be effective for improving the accuracy of learning models in general, it is intriguing to investigate this process for learning-to-rank domain. In this study, we investigate the use of a popular meta-heuristic approach called simulated annealing for this task. Under the general framework of simulated annealing, we explore various neighborhood selection strategies and temperature cooling schemes. We further introduce a new hyper-parameter called the progress parameter that can effectively be used to traverse the search space. Our algorithms are evaluated on five publicly benchmark datasets of learning-to-rank. For a better validation, we also compare the simulated annealing-based feature selection algorithm with another effective meta-heuristic algorithm, namely local beam search. Extensive experimental results shows the efficacy of our proposed models.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model  Statistics</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13268</p>
  <p><b>作者</b>：Kaiwen Zheng,  Cheng Lu,  Jianfei Chen,  Jun Zhu</p>
  <p><b>备注</b>：Accepted at NeurIPS 2023</p>
  <p><b>关键词</b>：high-fidelity image generation, exhibited excellent performance, NFE, exhibited excellent, high-fidelity image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion probabilistic models (DPMs) have exhibited excellent performance for high-fidelity image generation while suffering from inefficient sampling. Recent works accelerate the sampling procedure by proposing fast ODE solvers that leverage the specific ODE form of DPMs. However, they highly rely on specific parameterization during inference (such as noise/data prediction), which might not be the optimal choice. In this work, we propose a novel formulation towards the optimal parameterization during sampling that minimizes the first-order discretization error of the ODE solution. Based on such formulation, we propose \textit{DPM-Solver-v3}, a new fast ODE solver for DPMs by introducing several coefficients efficiently computed on the pretrained model, which we call \textit{empirical model statistics}. We further incorporate multistep methods and a predictor-corrector framework, and propose some techniques for improving sample quality at small numbers of function evaluations (NFE) or large guidance scales. Experiments show that DPM-Solver-v3 achieves consistently better or comparable performance in both unconditional and conditional sampling with both pixel-space and latent-space DPMs, especially in 5$\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE) on unconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable Diffusion, bringing a speed-up of 15\%$\sim$30\% compared to previous state-of-the-art training-free methods. Code is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：On the Language Encoder of Contrastive Cross-modal Models</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13267</p>
  <p><b>作者</b>：Mengjie Zhao,  Junya Ono,  Zhi Zhong,  Chieh-Hsin Lai,  Yuhta Takida,  Naoki Murata,  Wei-Hsiang Liao,  Takashi Shibuya,  Hiromi Wakaki,  Yuki Mitsufuji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CLIP and CLAP, sentence embedding training, CLAP aid, sentence embedding, embedding training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder, which is the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found that sentence embedding training language encoder quality and aids in cross-modal tasks, improving contrastive VL models such as CyCLIP. In contrast, AL pretraining benefits less from sentence embedding training, which may result from the limited amount of pretraining data. We analyze the representation spaces to understand the strengths of sentence embedding training, and find that it improves text-space uniformity, at the cost of decreased cross-modal alignment.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming  with Feasibility Guarantee</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13261</p>
  <p><b>作者</b>：Haoyu Wang,  Jialin Liu,  Xiaohan Chen,  Xinshang Wang,  Pan Li,  Wotao Yin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Mixed-integer linear programming, crucial industrial applications, numerous crucial industrial, notable NP-hard problem, NP-hard problem pivotal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixed-integer linear programming (MILP) stands as a notable NP-hard problem pivotal to numerous crucial industrial applications. The development of effective algorithms, the tuning of solvers, and the training of machine learning models for MILP resolution all hinge on access to extensive, diverse, and representative data. Yet compared to the abundant naturally occurring data in image and text realms, MILP is markedly data deficient, underscoring the vital role of synthetic MILP generation. We present DIG-MILP, a deep generative framework based on variational auto-encoder (VAE), adept at extracting deep-level structural features from highly limited MILP data and producing instances that closely mirror the target data. Notably, by leveraging the MILP duality, DIG-MILP guarantees a correct and complete generation space as well as ensures the boundedness and feasibility of the generated instances. Our empirical study highlights the novelty and quality of the instances generated by DIG-MILP through two distinct downstream tasks: (S1) Data sharing, where solver solution times correlate highly positive between original and DIG-MILP-generated instances, allowing data sharing for solver tuning without publishing the original data; (S2) Data Augmentation, wherein the DIG-MILP-generated instances bolster the generalization performance of machine learning models tasked with resolving MILP problems.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13258</p>
  <p><b>作者</b>：Kushal Kedia,  Prithwish Dan,  Atiksh Bhardwaj,  Sanjiban Choudhury</p>
  <p><b>备注</b>：CoRL 2023</p>
  <p><b>关键词</b>：close proximity relies, Seamless human-robot manipulation, Seamless human-robot, close proximity, proximity relies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Seamless human-robot manipulation in close proximity relies on accurate forecasts of human motion. While there has been significant progress in learning forecast models at scale, when applied to manipulation tasks, these models accrue high errors at critical transition points leading to degradation in downstream planning performance. Our key insight is that instead of predicting the most likely human motion, it is sufficient to produce forecasts that capture how future human motion would affect the cost of a robot's plan. We present ManiCast, a novel framework that learns cost-aware human forecasts and feeds them to a model predictive control planner to execute collaborative manipulation tasks. Our framework enables fluid, real-time interactions between a human and a 7-DoF robot arm across a number of real-world tasks such as reactive stirring, object handovers, and collaborative table setting. We evaluate both the motion forecasts and the end-to-end forecaster-planner system against a range of learned and heuristic baselines while additionally contributing new datasets. We release our code and datasets at this https URL.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Knowledge Graph Context-Enhanced Diversified Recommendation</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13253</p>
  <p><b>作者</b>：Xiaolong Liu,  Liangwei Yang,  Zhiwei Liu,  Mingdai Yang,  Chen Wang,  Hao Peng,  Philip S. Yu</p>
  <p><b>备注</b>：10 pages, 5 figures, accepted by WSDM 2024</p>
  <p><b>关键词</b>：Recommender Systems, users' historical interactions, leveraging users' historical, field of Recommender, historical interactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of Recommender Systems (RecSys) has been extensively studied to enhance accuracy by leveraging users' historical interactions. Nonetheless, this persistent pursuit of accuracy frequently engenders diminished diversity, culminating in the well-recognized "echo chamber" phenomenon. Diversified RecSys has emerged as a countermeasure, placing diversity on par with accuracy and garnering noteworthy attention from academic circles and industry practitioners. This research explores the realm of diversified RecSys within the intricate context of knowledge graphs (KG). These KGs act as repositories of interconnected information concerning entities and items, offering a propitious avenue to amplify recommendation diversity through the incorporation of insightful contextual information. Our contributions include introducing an innovative metric, Entity Coverage, and Relation Coverage, which effectively quantifies diversity within the KG domain. Additionally, we introduce the Diversified Embedding Learning (DEL) module, meticulously designed to formulate user representations that possess an innate awareness of diversity. In tandem with this, we introduce a novel technique named Conditional Alignment and Uniformity (CAU). It adeptly encodes KG item embeddings while preserving contextual integrity. Collectively, our contributions signify a substantial stride towards augmenting the panorama of recommendation diversity within the realm of KG-informed RecSys paradigms.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：FLEE-GNN: A Federated Learning System for Edge-Enhanced Graph Neural  Network in Analyzing Geospatial Resilience of Multicommodity Food Flows</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13248</p>
  <p><b>作者</b>：Yuxiao Qu,  Jinmeng Rao,  Song Gao,  Qianheng Zhang,  Wei-Lun Chao,  Yu Su,  Michelle Miller,  Alfonso Morales,  Patrick Huber</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：increasing food insecurity, tackle increasing food, Understanding and measuring, imperative to tackle, tackle increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding and measuring the resilience of food supply networks is a global imperative to tackle increasing food insecurity. However, the complexity of these networks, with their multidimensional interactions and decisions, presents significant challenges. This paper proposes FLEE-GNN, a novel Federated Learning System for Edge-Enhanced Graph Neural Network, designed to overcome these challenges and enhance the analysis of geospatial resilience of multicommodity food flow network, which is one type of spatial networks. FLEE-GNN addresses the limitations of current methodologies, such as entropy-based methods, in terms of generalizability, scalability, and data privacy. It combines the robustness and adaptability of graph neural networks with the privacy-conscious and decentralized aspects of federated learning on food supply network resilience analysis across geographical regions. This paper also discusses FLEE-GNN's innovative data generation techniques, experimental designs, and future directions for improvement. The results show the advancements of this approach to quantifying the resilience of multicommodity food flow networks, contributing to efforts towards ensuring global food security using AI methods. The developed FLEE-GNN has the potential to be applied in other spatial networks with spatially heterogeneous sub-network distributions.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Transparency challenges in policy evaluation with causal machine  learning -- improving usability and accountability</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13240</p>
  <p><b>作者</b>：Patrick Rehill,  Nicholas Biddle</p>
  <p><b>备注</b>：25 pages, 10 figures</p>
  <p><b>关键词</b>：Causal machine learning, machine learning, Causal machine, machine learning models, real-world policy evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causal machine learning tools are beginning to see use in real-world policy evaluation tasks to flexibly estimate treatment effects. One issue with these methods is that the machine learning models used are generally black boxes, i.e., there is no globally interpretable way to understand how a model makes estimates. This is a clear problem in policy evaluation applications, particularly in government, because it is difficult to understand whether such models are functioning in ways that are fair, based on the correct interpretation of evidence and transparent enough to allow for accountability if things go wrong. However, there has been little discussion of transparency problems in the causal machine learning literature and how these might be overcome. This paper explores why transparency issues are a problem for causal machine learning in public policy evaluation applications and considers ways these problems might be addressed through explainable AI tools and by simplifying models in line with interpretable AI principles. It then applies these ideas to a case-study using a causal forest model to estimate conditional average treatment effects for a hypothetical change in the school leaving age in Australia. It shows that existing tools for understanding black-box predictive models are poorly suited to causal machine learning and that simplifying the model to make it interpretable leads to an unacceptable increase in error (in this application). It concludes that new tools are needed to properly understand causal machine learning models and the algorithms that fit them.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Training A Semantic Communication System with Federated Learning</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13236</p>
  <p><b>作者</b>：Loc X. Nguyen,  Huy Q. Le,  Ye Lin Tun,  Pyae Sone Aung,  Yan Kyaw Tun,  Zhu Han,  Choong Seon Hong</p>
  <p><b>备注</b>：5 pages, 4 figures</p>
  <p><b>关键词</b>：alleviating data redundancy, capabilities in alleviating, Semantic communication, semantic communication systems, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic communication has emerged as a pillar for the next generation of communication systems due to its capabilities in alleviating data redundancy. Most semantic communication systems are built using advanced deep learning models whose performance heavily depends on data availability. These studies assume that an abundance of training data is available, which is unrealistic. In practice, data is mainly created on the user side. Due to privacy and security concerns, the transmission of data is restricted, which is necessary for conventional centralized training schemes. To address this challenge, we explore semantic communication in federated learning (FL) setting that utilizes user data without leaking privacy. Additionally, we design our system to tackle the communication overhead by reducing the quantity of information delivered in each global round. In this way, we can save significant bandwidth for resource-limited devices and reduce overall network traffic. Finally, we propose a mechanism to aggregate the global model from the clients, called FedLol. Extensive simulation results demonstrate the efficacy of our proposed technique compared to baseline methods.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Multi-level Contrastive Learning for Script-based Character  Understanding</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13231</p>
  <p><b>作者</b>：Dawei Li,  Hengyuan Zhang,  Yanran Li,  Shiping Yang</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 main conference; Camera-ready version will be updated soon</p>
  <p><b>关键词</b>：aims to learn, personalities and identities, characters' personalities, capture characters' global, characters' global information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we tackle the scenario of understanding characters in scripts, which aims to learn the characters' personalities and identities from their utterances. We begin by analyzing several challenges in this scenario, and then propose a multi-level contrastive learning framework to capture characters' global information in a fine-grained manner. To validate the proposed framework, we conduct extensive experiments on three character understanding sub-tasks by comparing with strong pre-trained language models, including SpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate that our method improves the performances by a considerable margin. Through further in-depth analysis, we show the effectiveness of our method in addressing the challenges and provide more hints on the scenario of character understanding. We will open-source our work on github at this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Absolute Policy Optimization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13230</p>
  <p><b>作者</b>：Weiye Zhao,  Feihan Li,  Yifan Sun,  Rui Chen,  Tianhao Wei,  Changliu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trust region on-policy, region on-policy reinforcement, on-policy reinforcement learning, achieved impressive results, addressing complex control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, trust region on-policy reinforcement learning has achieved impressive results in addressing complex control tasks and gaming scenarios. However, contemporary state-of-the-art algorithms within this category primarily emphasize improvement in expected performance, lacking the ability to control over the worst-case performance outcomes. To address this limitation, we introduce a novel objective function; by optimizing which, it will lead to guaranteed monotonic improvement in the lower bound of near-total performance samples (absolute performance). Considering this groundbreaking theoretical advancement, we then refine this theoretically grounded algorithm through a series of approximations, resulting in a practical solution called Absolute Policy Optimization (APO). Our experiments demonstrate the effectiveness of our approach across challenging continuous control benchmark tasks and extend its applicability to mastering Atari games. Our findings reveal that APO significantly outperforms state-of-the-art policy gradient algorithms, resulting in substantial improvements in both expected performance and worst-case performance.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ToolChain*: Efficient Action Space Navigation in Large Language Models  with A* Search</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13227</p>
  <p><b>作者</b>：Yuchen Zhuang,  Xiang Chen,  Tong Yu,  Saayan Mitra,  Victor Bursztyn,  Ryan A. Rossi,  Somdeb Sarkhel,  Chao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, complicated real-world problems, demonstrated powerful decision-making, solving complicated real-world, API function calls</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated powerful decision-making and planning capabilities in solving complicated real-world problems. LLM-based autonomous agents can interact with diverse tools (e.g., functional APIs) and generate solution plans that execute a series of API function calls in a step-by-step manner. The multitude of candidate API function calls significantly expands the action space, amplifying the critical need for efficient action space navigation. However, existing methods either struggle with unidirectional exploration in expansive action spaces, trapped into a locally optimal solution, or suffer from exhaustively traversing all potential actions, causing inefficient navigation. To address these issues, we propose ToolChain*, an efficient tree search-based planning algorithm for LLM-based agents. It formulates the entire action space as a decision tree, where each node represents a possible API function call involved in a solution plan. By incorporating the A* search algorithm with task-specific cost function design, it efficiently prunes high-cost branches that may involve incorrect actions, identifying the most low-cost valid path as the solution. Extensive experiments on multiple tool-use and reasoning tasks demonstrate that ToolChain* efficiently balances exploration and exploitation within an expansive action space. It outperforms state-of-the-art baselines on planning and reasoning tasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time, respectively.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Scalable Neural Network Kernels</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13225</p>
  <p><b>作者</b>：Arijit Sehanobish,  Krzysztof Choromanski,  Yunfan Zhao,  Avinava Dubey,  Valerii Likhosherstov</p>
  <p><b>备注</b>：Preprint. 23 pages, 10 figures. Comments welcome</p>
  <p><b>关键词</b>：favorable computational properties, neural network, regular feedforward layers, neural network kernels, scalable neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the concept of scalable neural network kernels (SNNKs), the replacements of regular feedforward layers (FFLs), capable of approximating the latter, but with favorable computational properties. SNNKs effectively disentangle the inputs from the parameters of the neural network in the FFL, only to connect them in the final computation via the dot-product kernel. They are also strictly more expressive, as allowing to model complicated relationships beyond the functions of the dot-products of parameter-input vectors. We also introduce the neural network bundling process that applies SNNKs to compactify deep neural network architectures, resulting in additional compression gains. In its extreme version, it leads to the fully bundled network whose optimal parameters can be expressed via explicit formulae for several loss functions (e.g. mean squared error), opening a possibility to bypass backpropagation. As a by-product of our analysis, we introduce the mechanism of the universal random features (or URFs), applied to instantiate several SNNK variants, and interesting on its own in the context of scalable kernel methods. We provide rigorous theoretical analysis of all these concepts as well as an extensive empirical evaluation, ranging from point-wise kernel estimation to Transformers' fine-tuning with novel adapter layers inspired by SNNKs. Our mechanism provides up to 5x reduction in the number of trainable parameters, while maintaining competitive accuracy.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：In-context Learning with Transformer Is Really Equivalent to a  Contrastive Learning Pattern</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13220</p>
  <p><b>作者</b>：Ruifeng Ren,  Yong Liu</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：Pre-trained large language, demonstrated amazing in-context, Transformers have demonstrated, large language models, amazing in-context learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained large language models based on Transformers have demonstrated amazing in-context learning (ICL) abilities. Given several demonstration examples, the models can implement new tasks without any parameter updates. However, it is still an open question to understand the mechanism of ICL. In this paper, we interpret the inference process of ICL as a gradient descent process in a contrastive learning pattern. Firstly, leveraging kernel methods, we establish the relationship between gradient descent and self-attention mechanism under generally used softmax attention setting instead of linear attention setting. Then, we analyze the corresponding gradient descent process of ICL from the perspective of contrastive learning without negative samples and discuss possible improvements of this contrastive learning pattern, based on which the self-attention layer can be further modified. Finally, we design experiments to support our opinions. To the best of our knowledge, our work is the first to provide the understanding of ICL from the perspective of contrastive learning and has the potential to facilitate future model design by referring to related works on contrastive learning.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：NameGuess: Column Name Expansion for Tabular Data</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13196</p>
  <p><b>作者</b>：Jiani Zhang,  Zhengyuan Shen,  Balasubramaniam Srinivasan,  Shen Wang,  Huzefa Rangwala,  George Karypis</p>
  <p><b>备注</b>：This work has been accepted to EMNLP'23</p>
  <p><b>关键词</b>：Recent advances, revolutionized many sectors, database industry, large language models, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in large language models have revolutionized many sectors, including the database industry. One common challenge when dealing with large volumes of tabular data is the pervasive use of abbreviated column names, which can negatively impact performance on various data search, access, and understanding tasks. To address this issue, we introduce a new task, called NameGuess, to expand column names (used in database schema) as a natural language generation problem. We create a training dataset of 384K abbreviated-expanded column pairs using a new data fabrication method and a human-annotated evaluation benchmark that includes 9.2K examples from real-world tables. To tackle the complexities associated with polysemy and ambiguity in NameGuess, we enhance auto-regressive language models by conditioning on table content and column header names -- yielding a fine-tuned model (with 2.7B parameters) that matches human performance. Furthermore, we conduct a comprehensive analysis (on multiple LLMs) to validate the effectiveness of table content in NameGuess and identify promising future opportunities. Code has been made available at this https URL.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Heterogeneous Graph Neural Networks for Data-driven Traffic Assignment</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13193</p>
  <p><b>作者</b>：Tong Liu,  Hadi Meidani</p>
  <p><b>备注</b>：13 pages, 6 figures</p>
  <p><b>关键词</b>：heterogeneous graph neural, traffic assignment problem, graph neural, graph neural network, proposed heterogeneous graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The traffic assignment problem is one of the significant components of traffic flow analysis for which various solution approaches have been proposed. However, deploying these approaches for large-scale networks poses significant challenges. In this paper, we leverage the power of heterogeneous graph neural networks to propose a novel data-driven approach for traffic assignment and traffic flow learning. The proposed model is capable of capturing spatial traffic patterns across different links, yielding highly accurate results. We present numerical experiments on urban transportation networks and show that the proposed heterogeneous graph neural network model outperforms other conventional neural network models in terms of convergence rate, training loss, and prediction accuracy. Notably, the proposed heterogeneous graph neural network model can also be generalized to different network topologies. This approach offers a promising solution for complex traffic flow analysis and prediction, enhancing our understanding and management of a wide range of transportation systems.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for  Image Manipulation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13165</p>
  <p><b>作者</b>：Sihan Xu,  Ziqiao Ma,  Yidong Huang,  Honglak Lee,  Joyce Chai</p>
  <p><b>备注</b>：NeurIPS 2023</p>
  <p><b>关键词</b>：Diffusion models, interface for consistent, enabled breakthroughs, lack an intuitive, intuitive interface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual prompt. Cyclenet is a practical framework, which is robust even with very limited training data (around 2k) and requires minimal computational resources (1 GPU) to train. Project homepage: this https URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Almost Equivariance via Lie Algebra Convolutions</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13164</p>
  <p><b>作者</b>：Daniel McNeela</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：equivariance, machine learning, research in machine, Lie group, Lie</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebra convolutions and demonstrate that they offer several benefits over Lie group convolutions, including being well-defined for non-compact groups. From there, we pivot to the realm of theory and demonstrate connections between the notions of equivariance and isometry and those of almost equivariance and almost isometry, respectively. We prove two existence theorems, one showing the existence of almost isometries within bounded distance of isometries of a general manifold, and another showing the converse for Hilbert spaces. We then extend these theorems to prove the existence of almost equivariant manifold embeddings within bounded distance of fully equivariant embedding functions, subject to certain constraints on the group action and the function class. Finally, we demonstrate the validity of our approach by benchmarking against datasets in fully equivariant and almost equivariant settings.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：A Distributed Approach to Meteorological Predictions: Addressing Data  Imbalance in Precipitation Prediction Models through Federated Learning and  GANs</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13161</p>
  <p><b>作者</b>：Elaheh Jafarigol,  Theodore Trafalis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facilitating nuanced analyses, categorizing meteorological phenomena, involves categorizing meteorological, disaster management, facilitating nuanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The classification of weather data involves categorizing meteorological phenomena into classes, thereby facilitating nuanced analyses and precise predictions for various sectors such as agriculture, aviation, and disaster management. This involves utilizing machine learning models to analyze large, multidimensional weather datasets for patterns and trends. These datasets may include variables such as temperature, humidity, wind speed, and pressure, contributing to meteorological conditions. Furthermore, it's imperative that classification algorithms proficiently navigate challenges such as data imbalances, where certain weather events (e.g., storms or extreme temperatures) might be underrepresented. This empirical study explores data augmentation methods to address imbalanced classes in tabular weather data in centralized and federated settings. Employing data augmentation techniques such as the Synthetic Minority Over-sampling Technique or Generative Adversarial Networks can improve the model's accuracy in classifying rare but critical weather events. Moreover, with advancements in federated learning, machine learning models can be trained across decentralized databases, ensuring privacy and data integrity while mitigating the need for centralized data storage and processing. Thus, the classification of weather data stands as a critical bridge, linking raw meteorological data to actionable insights, enhancing our capacity to anticipate and prepare for diverse weather conditions.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Conditional Generative Modeling for Images, 3D Animations, and Video</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13157</p>
  <p><b>作者</b>：Vikram Voleti</p>
  <p><b>备注</b>：Doctoral thesis, Mila, University of Montreal. 189 pages</p>
  <p><b>关键词</b>：dissertation attempts, attempts to drive, drive innovation, exploring novel formulations, innovative applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation attempts to drive innovation in the field of generative modeling for computer vision, by exploring novel formulations of conditional generative models, and innovative applications in images, 3D animations, and video. Our research focuses on architectures that offer reversible transformations of noise and visual data, and the application of encoder-decoder architectures for generative tasks and 3D content manipulation. In all instances, we incorporate conditional information to enhance the synthesis of visual data, improving the efficiency of the generation process as well as the generated content.
We introduce the use of Neural ODEs to model video dynamics using an encoder-decoder architecture, demonstrating their ability to predict future video frames despite being trained solely to reconstruct current frames. Next, we propose a conditional variant of continuous normalizing flows that enables higher-resolution image generation based on lower-resolution input, achieving comparable image quality while reducing parameters and training time. Our next contribution presents a pipeline that takes human images as input, automatically aligns a user-specified 3D character with the pose of the human, and facilitates pose editing based on partial inputs. Next, we derive the relevant mathematical details for denoising diffusion models that use non-isotropic Gaussian processes, and show comparable generation quality. Finally, we devise a novel denoising diffusion framework capable of solving all three video tasks of prediction, generation, and interpolation. We perform ablation studies, and show SOTA results on multiple datasets.
Our contributions are published articles at peer-reviewed venues. Overall, our research aims to make a meaningful contribution to the pursuit of more efficient and flexible generative models, with the potential to shape the future of computer vision.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：CLIFT: Analysing Natural Distribution Shift on Question Answering Models  in Clinical Domain</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13146</p>
  <p><b>作者</b>：Ankit Pal</p>
  <p><b>备注</b>：Accepted at NeurIPS 2022 (Robustness in Sequence Modeling)</p>
  <p><b>关键词</b>：domain Question-answering task, clinical domain Question-answering, Question-answering task, testbed CLIFT, domain Question-answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical domain Question-answering task. The testbed includes 7.5k high-quality question answering samples to provide a diverse and reliable benchmark. We performed a comprehensive experimental study and evaluated several QA deep-learning models under the proposed testbed. Despite impressive results on the original test set, the performance degrades when applied to new test sets, which shows the distribution shift. Our findings emphasize the need for and the potential for increasing the robustness of clinical domain models under distributional shifts. The testbed offers one way to track progress in that direction. It also highlights the necessity of adopting evaluation metrics that consider robustness to natural distribution shifts. We plan to expand the corpus by adding more samples and model results. The full paper and the updated benchmark are available at this http URL</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Graph Neural Networks with polynomial activations have limited  expressivity</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13139</p>
  <p><b>作者</b>：Sammy Khalife</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, Graph Neural, activation functions, Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The expressivity of Graph Neural Networks (GNNs) can be entirely characterized by appropriate fragments of the first order logic. Namely, any query of the two variable fragment of graded modal logic (GC2) interpreted over labelled graphs can be expressed using a GNN whose size depends only on the depth of the query. As pointed out by [Barcelo & Al., 2020, Grohe, 2021 ], this description holds for a family of activation functions, leaving the possibibility for a hierarchy of logics expressible by GNNs depending on the chosen activation function. In this article, we show that such hierarchy indeed exists by proving that GC2 queries cannot be expressed by GNNs with polynomial activation functions. This implies a separation between polynomial and popular non polynomial activations (such as ReLUs, sigmoid and hyperbolic tan and others) and answers an open question formulated by [Grohe, 2021].</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Mean Estimation Under Heterogeneous Privacy Demands</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13137</p>
  <p><b>作者</b>：Syomantak Chaudhuri,  Konstantin Miagkov,  Thomas A. Courtade</p>
  <p><b>备注</b>：A preliminary conference version was published at ISIT 2023 and uploaded to arxiv (arXiv:2305.09668). This version significantly expands on the previous article and is being submitted to a journal</p>
  <p><b>关键词</b>：quantify privacy loss, privacy loss incurred, well-established framework, framework to quantify, loss incurred</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal and has a near-linear run-time. Our results elicit an interesting saturation phenomenon that occurs. Namely, the privacy requirements of the most stringent users dictate the overall error rates. As a consequence, users with less but differing privacy requirements are all given more privacy than they require, in equal amounts. In other words, these privacy-indifferent users are given a nontrivial degree of privacy for free, without any sacrifice in the performance of the estimator.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Deep Reinforcement Learning-based Intelligent Traffic Signal Controls  with Optimized CO2 emissions</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13129</p>
  <p><b>作者</b>：Pedram Agand,  Alexey Iskrov,  Mo Chen</p>
  <p><b>备注</b>：6 pages, 6 figures, 1 table. International Conference on Intelligent Robots and Systems. IEEE/RSJ, 2023</p>
  <p><b>关键词</b>：sub-optimal control policies, transportation networks face, human health, networks face, face the challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, transportation networks face the challenge of sub-optimal control policies that can have adverse effects on human health, the environment, and contribute to traffic congestion. Increased levels of air pollution and extended commute times caused by traffic bottlenecks make intersection traffic signal controllers a crucial component of modern transportation infrastructure. Despite several adaptive traffic signal controllers in literature, limited research has been conducted on their comparative performance. Furthermore, despite carbon dioxide (CO2) emissions' significance as a global issue, the literature has paid limited attention to this area. In this report, we propose EcoLight, a reward shaping scheme for reinforcement learning algorithms that not only reduces CO2 emissions but also achieves competitive results in metrics such as travel time. We compare the performance of tabular Q-Learning, DQN, SARSA, and A2C algorithms using metrics such as travel time, CO2 emissions, waiting time, and stopped time. Our evaluation considers multiple scenarios that encompass a range of road users (trucks, buses, cars) with varying pollution levels.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Fuel Consumption Prediction for a Passenger Ferry using Machine Learning  and In-service Data: A Comparative Study</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13123</p>
  <p><b>作者</b>：Pedram Agand,  Allison Kennedy,  Trevor Harris,  Chanwoo Bae,  Mo Chen,  Edward J Park</p>
  <p><b>备注</b>：20 pages, 11 figures, 7 tables</p>
  <p><b>关键词</b>：eco-friendly transportation increases, marine vessel operation, transportation increases, operation is essential, importance of eco-friendly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the importance of eco-friendly transportation increases, providing an efficient approach for marine vessel operation is essential. Methods for status monitoring with consideration to the weather condition and forecasting with the use of in-service data from ships requires accurate and complete models for predicting the energy efficiency of a ship. The models need to effectively process all the operational data in real-time. This paper presents models that can predict fuel consumption using in-service data collected from a passenger ship. Statistical and domain-knowledge methods were used to select the proper input variables for the models. These methods prevent over-fitting, missing data, and multicollinearity while providing practical applicability. Prediction models that were investigated include multiple linear regression (MLR), decision tree approach (DT), an artificial neural network (ANN), and ensemble methods. The best predictive performance was from a model developed using the XGboost technique which is a boosting ensemble approach. \rvv{Our code is available on GitHub at \url{this https URL} for future research.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Understanding Addition in Transformers</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13121</p>
  <p><b>作者</b>：Philip Quirke,  Fazl (Kiko) Barez</p>
  <p><b>备注</b>：9 pages, 8 figures, submitted to ICLR 2024</p>
  <p><b>关键词</b>：machine learning models, workings of machine, machine learning, safe and ethical, one-layer Transformer model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question  Answering</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13120</p>
  <p><b>作者</b>：Yuduo Wang,  Pedram Ghamisi</p>
  <p><b>备注</b>：Submitted to IEEE</p>
  <p><b>关键词</b>：Visual Question Answering, Image Captioning, Visual Question, Question Answering, found wide application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not only improves adaptation to pre-trained multimodal models but also allows the parameters of the linear transformation layer to be integrated into the preceding FC layers during inference, reducing inference costs. To demonstrate the effectiveness of RSAdapter, we conduct an extensive series of experiments using three distinct RS-VQA datasets and achieve state-of-the-art results on all three datasets. The code for RSAdapter will be available online at this https URL.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Semi-Supervised Learning of Dynamical Systems with Neural Ordinary  Differential Equations: A Teacher-Student Model Approach</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13110</p>
  <p><b>作者</b>：Yu Wang,  Yuxuan Yin,  Karthik Somayaji Nanjangud Suryanarayana,  Jan Drgona,  Malachi Schram,  Mahantesh Halappanavar,  Frank Liu,  Peng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remains challenging due, Ordinary Differential Equations, complex nonlinear dynamics, Neural Ordinary Differential, prior knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling dynamical systems is crucial for a wide range of tasks, but it remains challenging due to complex nonlinear dynamics, limited observations, or lack of prior knowledge. Recently, data-driven approaches such as Neural Ordinary Differential Equations (NODE) have shown promising results by leveraging the expressive power of neural networks to model unknown dynamics. However, these approaches often suffer from limited labeled training data, leading to poor generalization and suboptimal predictions. On the other hand, semi-supervised algorithms can utilize abundant unlabeled data and have demonstrated good performance in classification and regression tasks. We propose TS-NODE, the first semi-supervised approach to modeling dynamical systems with NODE. TS-NODE explores cheaply generated synthetic pseudo rollouts to broaden exploration in the state space and to tackle the challenges brought by lack of ground-truth system data under a teacher-student model. TS-NODE employs an unified optimization framework that corrects the teacher model based on the student's feedback while mitigating the potential false system dynamics present in pseudo rollouts. TS-NODE demonstrates significant performance improvements over a baseline Neural ODE model on multiple dynamical system modeling tasks.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting  Multiple Experts for Video Deepfake Detection</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13103</p>
  <p><b>作者</b>：Ammarah Hashmi,  Sahibzada Adil Shahzad,  Chia-Wen Lin,  Yu Tsao,  Hsin-Min Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media platforms, major social problem, content shared widely, requires increased regulation, Forged content shared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulation and visual manipulation to achieve effective video forgery detection. Specifically, the proposed model integrates several purely transformer-based variants that capture video, audio, and audio-visual salient cues to reach a consensus in prediction. For evaluation, we use the recently released benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed analysis, we evaluate AVTENet, its variants, and several existing methods on multiple test sets of the FakeAVCeleb dataset. Experimental results show that our best model outperforms all existing methods and achieves state-of-the-art performance on Testset-I and Testset-II of the FakeAVCeleb dataset.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13102</p>
  <p><b>作者</b>：Gabriele Corso,  Yilun Xu,  Valentin de Bortoli,  Regina Barzilay,  Tommi Jaakkola</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widespread success, significant amount, amount of research, sampling time, generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In light of the widespread success of generative models, a significant amount of research has gone into speeding up their sampling time. However, generative models are often sampled multiple times to obtain a diverse set incurring a cost that is orthogonal to sampling time. We tackle the question of how to improve diversity and sample efficiency by moving beyond the common assumption of independent samples. We propose particle guidance, an extension of diffusion-based generative sampling where a joint-particle time-evolving potential enforces diversity. We analyze theoretically the joint distribution that particle guidance generates, its implications on the choice of potential, and the connections with methods in other disciplines. Empirically, we test the framework both in the setting of conditional image generation, where we are able to increase diversity without affecting quality, and molecular conformer generation, where we reduce the state-of-the-art median error by 13% on average.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：No offence, Bert -- I insult only humans! Multiple addressees  sentence-level attack on toxicity detection neural network</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13099</p>
  <p><b>作者</b>：Sergey Berezin,  Reza Farahbakhsh,  Noel Crespi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：toxicity detector models, black-box toxicity detector, efficient sentence-level attack, detector models, introduce a simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：SRAI: Towards Standardization of Geospatial AI</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13098</p>
  <p><b>作者</b>：Piotr Gramacki,  Kacper Leśniara,  Kamil Raczycki,  Szymon Woźniak,  Marcin Przymus,  Piotr Szymański</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, Representations for Artificial, Spatial Representations, Python library, geospatial data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spatial Representations for Artificial Intelligence (\textit{srai}) is a Python library for working with geospatial data. The library can download geospatial data, split a given area into micro-regions using multiple algorithms and train an embedding model using various architectures. It includes baseline models as well as more complex methods from published works. Those capabilities make it possible to use \textit{srai} in a complete pipeline for geospatial task solving. The proposed library is the first step to standardize the geospatial AI domain toolset. It is fully open-source and published under Apache 2.0 licence.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：A Multi-Stage Temporal Convolutional Network for Volleyball Jumps  Classification Using a Waist-Mounted IMU</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13097</p>
  <p><b>作者</b>：Meng Shang,  Camilla De Bleecker,  Jos Vanrenterghem,  Roel De Ridder,  Sabine Verschueren,  Carolina Varon,  Walter De Raedt,  Bart Vanrumste</p>
  <p><b>备注</b>：NA</p>
  <p><b>关键词</b>：requires considerable workload, measurement requires considerable, Monitoring the number, prevent injuries, video analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Monitoring the number of jumps for volleyball players during training or a match can be crucial to prevent injuries, yet the measurement requires considerable workload and cost using traditional methods such as video analysis. Also, existing methods do not provide accurate differentiation between different types of jumps. In this study, an unobtrusive system with a single inertial measurement unit (IMU) on the waist was proposed to recognize the types of volleyball jumps. A Multi-Layer Temporal Convolutional Network (MS-TCN) was applied for sample-wise classification. The model was evaluated on ten volleyball players and twenty-six volleyball players, during a lab session with a fixed protocol of jumping and landing tasks, and during four volleyball training sessions, respectively. The MS-TCN model achieved better performance than a state-of-the-art deep learning model but with lower computational cost. In the lab sessions, most jump counts showed small differences between the predicted jumps and video-annotated jumps, with an overall count showing a Limit of Agreement (LoA) of 0.1+-3.40 (r=0.884). For comparison, the proposed algorithm showed slightly worse results than VERT (a commercial jumping assessment device) with a LoA of 0.1+-2.08 (r=0.955) but the differences were still within a comparable range. In the training sessions, the recognition of three types of jumps exhibited a mean difference from observation of less than 10 jumps: block, smash, and overhead serve. These results showed the potential of using a single IMU to recognize the types of volleyball jumps. The sample-wise architecture provided high resolution of recognition and the MS-TCN required fewer parameters to train compared with state-of-the-art models.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Unsupervised Representation Learning to Aid Semi-Supervised Meta  Learning</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13085</p>
  <p><b>作者</b>：Atik Faysal,  Mohammad Rostami,  Huaxia Wang,  Avimanyu Sahoo,  Ryan Antle</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data scarcity problem, scarcity problem, problem in machine, meta-learning, data scarcity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning or meta-learning leverages the data scarcity problem in machine learning. Traditionally, training data requires a multitude of samples and labeling for supervised learning. To address this issue, we propose a one-shot unsupervised meta-learning to learn the latent representation of the training samples. We use augmented samples as the query set during the training phase of the unsupervised meta-learning. A temperature-scaled cross-entropy loss is used in the inner loop of meta-learning to prevent overfitting during unsupervised learning. The learned parameters from this step are applied to the targeted supervised meta-learning in a transfer-learning fashion for initialization and fast adaptation with improved accuracy. The proposed method is model agnostic and can aid any meta-learning model to improve accuracy. We use model agnostic meta-learning (MAML) and relation network (RN) on Omniglot and mini-Imagenet datasets to demonstrate the performance of the proposed method. Furthermore, a meta-learning model with the proposed initialization can achieve satisfactory accuracy with significantly fewer training samples.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：How Can Everyday Users Efficiently Teach Robots by Demonstrations?</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13083</p>
  <p><b>作者</b>：Maram Sakr,  Zhikai Zhang,  Benjamin Li,  Haomiao Zhang,  H.F. Machiel Van der Loos,  Dana Kulic,  Elizabeth Croft</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：easily program robots, robot learning, robot learning efficiency, easily program, Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from Demonstration (LfD) is a framework that allows lay users to easily program robots. However, the efficiency of robot learning and the robot's ability to generalize to task variations hinges upon the quality and quantity of the provided demonstrations. Our objective is to guide human teachers to furnish more effective demonstrations, thus facilitating efficient robot learning. To achieve this, we propose to use a measure of uncertainty, namely task-related information entropy, as a criterion for suggesting informative demonstration examples to human teachers to improve their teaching skills. In a conducted experiment (N=24), an augmented reality (AR)-based guidance system was employed to train novice users to produce additional demonstrations from areas with the highest entropy within the workspace. These novice users were trained for a few trials to teach the robot a generalizable task using a limited number of demonstrations. Subsequently, the users' performance after training was assessed first on the same task (retention) and then on a novel task (transfer) without guidance. The results indicated a substantial improvement in robot learning efficiency from the teacher's demonstrations, with an improvement of up to 198% observed on the novel task. Furthermore, the proposed approach was compared to a state-of-the-art heuristic rule and found to improve robot learning efficiency by 210% compared to the heuristic rule.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：On the Computational Complexities of Complex-valued Neural Networks</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13075</p>
  <p><b>作者</b>：Kayol Soares Mayer,  Jonathan Aguiar Soares,  Ariadne Arrais Cruz,  Dalton Soares Arantes</p>
  <p><b>备注</b>：IEEE Latin-American Conference on Communications</p>
  <p><b>关键词</b>：digital signal processing, Complex-valued neural networks, neural networks, real-valued neural networks, complex-domain data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Complex-valued neural networks (CVNNs) are nonlinear filters used in the digital signal processing of complex-domain data. Compared with real-valued neural networks~(RVNNs), CVNNs can directly handle complex-valued input and output signals due to their complex domain parameters and activation functions. With the trend toward low-power systems, computational complexity analysis has become essential for measuring an algorithm's power consumption. Therefore, this paper presents both the quantitative and asymptotic computational complexities of CVNNs. This is a crucial tool in deciding which algorithm to implement. The mathematical operations are described in terms of the number of real-valued multiplications, as these are the most demanding operations. To determine which CVNN can be implemented in a low-power system, quantitative computational complexities can be used to accurately estimate the number of floating-point operations. We have also investigated the computational complexities of CVNNs discussed in some studies presented in the literature.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Using Logic Programming and Kernel-Grouping for Improving  Interpretability of Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13073</p>
  <p><b>作者</b>：Parth Padalkar,  Gopal Gupta</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2301.12667</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, Convolutional Neural, CNN, Based Machine Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within the realm of deep learning, the interpretability of Convolutional Neural Networks (CNNs), particularly in the context of image classification tasks, remains a formidable challenge. To this end we present a neurosymbolic framework, NeSyFOLD-G that generates a symbolic rule-set using the last layer kernels of the CNN to make its underlying knowledge interpretable. What makes NeSyFOLD-G different from other similar frameworks is that we first find groups of similar kernels in the CNN (kernel-grouping) using the cosine-similarity between the feature maps generated by various kernels. Once such kernel groups are found, we binarize each kernel group's output in the CNN and use it to generate a binarization table which serves as input data to FOLD-SE-M which is a Rule Based Machine Learning (RBML) algorithm. FOLD-SE-M then generates a rule-set that can be used to make predictions. We present a novel kernel grouping algorithm and show that grouping similar kernels leads to a significant reduction in the size of the rule-set generated by FOLD-SE-M, consequently, improving the interpretability. This rule-set symbolically encapsulates the connectionist knowledge of the trained CNN. The rule-set can be viewed as a normal logic program wherein each predicate's truth value depends on a kernel group in the CNN. Each predicate in the rule-set is mapped to a concept using a few semantic segmentation masks of the images used for training, to make it human-understandable. The last layers of the CNN can then be replaced by this rule-set to obtain the NeSy-G model which can then be used for the image classification task. The goal directed ASP system s(CASP) can be used to obtain the justification of any prediction made using the NeSy-G model. We also propose a novel algorithm for labeling each predicate in the rule-set with the semantic concept(s) that its corresponding kernel group represents.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Creative Robot Tool Use with Large Language Models</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13065</p>
  <p><b>作者</b>：Mengdi Xu,  Peide Huang,  Wenhao Yu,  Shiqi Liu,  Xilun Zhang,  Yaru Niu,  Tingnan Zhang,  Fei Xia,  Jie Tan,  Ding Zhao</p>
  <p><b>备注</b>：19 pages, 14 figures, 2 tables</p>
  <p><b>关键词</b>：advanced intelligence, Large Language Models, hallmark of advanced, animal behavior, implicit physical constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tool use is a hallmark of advanced intelligence, exemplified in both animal behavior and robotic capabilities. This paper investigates the feasibility of imbuing robots with the ability to creatively use tools in tasks that involve implicit physical constraints and long-term planning. Leveraging Large Language Models (LLMs), we develop RoboTool, a system that accepts natural language instructions and outputs executable code for controlling robots in both simulated and real-world environments. RoboTool incorporates four pivotal components: (i) an "Analyzer" that interprets natural language to discern key task-related concepts, (ii) a "Planner" that generates comprehensive strategies based on the language input and key concepts, (iii) a "Calculator" that computes parameters for each skill, and (iv) a "Coder" that translates these plans into executable Python code. Our results show that RoboTool can not only comprehend explicit or implicit physical constraints and environmental factors but also demonstrate creative tool use. Unlike traditional Task and Motion Planning (TAMP) methods that rely on explicit optimization, our LLM-based system offers a more flexible, efficient, and user-friendly solution for complex robotics tasks. Through extensive experiments, we validate that RoboTool is proficient in handling tasks that would otherwise be infeasible without the creative use of tools, thereby expanding the capabilities of robotic systems. Demos are available on our project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：To grok or not to grok: Disentangling generalization and memorization on  corrupted algorithmic datasets</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13061</p>
  <p><b>作者</b>：Darshil Doshi,  Aritra Das,  Tianyu He,  Andrey Gromov</p>
  <p><b>备注</b>：24 pages, 22 figures, 2 tables</p>
  <p><b>关键词</b>：deep learning, number of trainable, trainable parameters, major challenge, Robust generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust generalization is a major challenge in deep learning, particularly when the number of trainable parameters is very large. In general, it is very difficult to know if the network has memorized a particular set of examples or understood the underlying rule (or both). Motivated by this challenge, we study an interpretable model where generalizing representations are understood analytically, and are easily distinguishable from the memorizing ones. Namely, we consider two-layer neural networks trained on modular arithmetic tasks where ($\xi \cdot 100\%$) of labels are corrupted (\emph{i.e.} some results of the modular operations in the training set are incorrect). We show that (i) it is possible for the network to memorize the corrupted labels \emph{and} achieve $100\%$ generalization at the same time; (ii) the memorizing neurons can be identified and pruned, lowering the accuracy on corrupted data and improving the accuracy on uncorrupted data; (iii) regularization methods such as weight decay, dropout and BatchNorm force the network to ignore the corrupted data during optimization, and achieve $100\%$ accuracy on the uncorrupted dataset; and (iv) the effect of these regularization methods is (``mechanistically'') interpretable: weight decay and dropout force all the neurons to learn generalizing representations, while BatchNorm de-amplifies the output of memorizing neurons and amplifies the output of the generalizing ones. Finally, we show that in the presence of regularization, the training dynamics involves two consecutive stages: first, the network undergoes the \emph{grokking} dynamics reaching high train \emph{and} test accuracy; second, it unlearns the memorizing representations, where train accuracy suddenly jumps from $100\%$ to $100 (1-\xi)\%$.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Robust multimodal models have outlier features and encode more concepts</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13040</p>
  <p><b>作者</b>：Jonathan Crabbé,  Pau Rodríguez,  Vaishaal Shankar,  Luca Zappella,  Arno Blaas</p>
  <p><b>备注</b>：29 pages, 18 figures</p>
  <p><b>关键词</b>：robust models, distinguishes robust models, models, representation space, robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demonstrate that these privileged directions explain most of the predictive power of the model by pruning up to $80 \%$ of the least important representation space directions without negative impacts on model accuracy and robustness; (2) Robust models encode substantially more concepts in their representation space. While this superposition of concepts allows robust models to store much information, it also results in highly polysemantic features, which makes their interpretation challenging. We discuss how these insights pave the way for future research in various fields, such as model pruning and mechanistic interpretability.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Agri-GNN: A Novel Genotypic-Topological Graph Neural Network Framework  Built on GraphSAGE for Optimized Yield Prediction</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13037</p>
  <p><b>作者</b>：Aditya Gupta,  Asheesh Singh</p>
  <p><b>备注</b>：19 pages Regeneron STS entry</p>
  <p><b>关键词</b>：Neural Network Framework, Graph Neural Network, textit, Agri-GNN, Network Framework tailored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Agriculture, as the cornerstone of human civilization, constantly seeks to integrate technology for enhanced productivity and sustainability. This paper introduces $\textit{Agri-GNN}$, a novel Genotypic-Topological Graph Neural Network Framework tailored to capture the intricate spatial and genotypic interactions of crops, paving the way for optimized predictions of harvest yields. $\textit{Agri-GNN}$ constructs a Graph $\mathcal{G}$ that considers farming plots as nodes, and then methodically constructs edges between nodes based on spatial and genotypic similarity, allowing for the aggregation of node information through a genotypic-topological filter. Graph Neural Networks (GNN), by design, consider the relationships between data points, enabling them to efficiently model the interconnected agricultural ecosystem. By harnessing the power of GNNs, $\textit{Agri-GNN}$ encapsulates both local and global information from plants, considering their inherent connections based on spatial proximity and shared genotypes, allowing stronger predictions to be made than traditional Machine Learning architectures. $\textit{Agri-GNN}$ is built from the GraphSAGE architecture, because of its optimal calibration with large graphs, like those of farming plots and breeding experiments. $\textit{Agri-GNN}$ experiments, conducted on a comprehensive dataset of vegetation indices, time, genotype information, and location data, demonstrate that $\textit{Agri-GNN}$ achieves an $R^2 = .876$ in yield predictions for farming fields in Iowa. The results show significant improvement over the baselines and other work in the field. $\textit{Agri-GNN}$ represents a blueprint for using advanced graph-based neural architectures to predict crop yield, providing significant improvements over baselines in the field.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：LASER: Linear Compression in Wireless Distributed Optimization</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13033</p>
  <p><b>作者</b>：Ashok Vardhan Makkuva,  Marco Bondaschi,  Thijs Vogels,  Martin Jaggi,  Hyeji Kim,  Michael C. Gastpar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale machine learning, large scale machine, machine learning, facto algorithm, large scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-parallel SGD is the de facto algorithm for distributed optimization, especially for large scale machine learning. Despite its merits, communication bottleneck is one of its persistent issues. Most compression schemes to alleviate this either assume noiseless communication links, or fail to achieve good performance on practical tasks. In this paper, we close this gap and introduce LASER: LineAr CompreSsion in WirEless DistRibuted Optimization. LASER capitalizes on the inherent low-rank structure of gradients and transmits them efficiently over the noisy channels. Whilst enjoying theoretical guarantees similar to those of the classical SGD, LASER shows consistent gains over baselines on a variety of practical benchmarks. In particular, it outperforms the state-of-the-art compression schemes on challenging computer vision and GPT language modeling tasks. On the latter, we obtain $50$-$64 \%$ improvement in perplexity over our baselines for noisy channels.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Quality-Diversity through AI Feedback</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13032</p>
  <p><b>作者</b>：Herbie Bradley,  Andrew Dai,  Hannah Teufel,  Jenny Zhang,  Koen Oostermeijer,  Marco Bellagente,  Jeff Clune,  Kenneth Stanley,  Grégory Schott,  Joel Lehman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text-generation problems, users may prefer, single response, diverse range, QDAIF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through AI feedback, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-QD controls. Further, human evaluation of QDAIF-generated creative texts validates reasonable agreement between AI and human evaluation. Our results thus highlight the potential of AI feedback to guide open-ended search for creative and original solutions, providing a recipe that seemingly generalizes to many domains and modalities. In this way, QDAIF is a step towards AI systems that can independently search, diversify, evaluate, and improve, which are among the core skills underlying human society's capacity for innovation.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A Use Case: Reformulating Query Rewriting as a Statistical Machine  Translation Problem</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13031</p>
  <p><b>作者</b>：Abdullah Can Algan,  Emre Yürekli,  Aykut Çayır</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve relevant web, relevant web content, retrieve relevant, search engines, important challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most important challenges for modern search engines is to retrieve relevant web content based on user queries. In order to achieve this challenge, search engines have a module to rewrite user queries. That is why modern web search engines utilize some statistical and neural models used in the natural language processing domain. Statistical machine translation is a well-known NLP method among them. The paper proposes a query rewriting pipeline based on a monolingual machine translation model that learns to rewrite Arabic user search queries. This paper also describes preprocessing steps to create a mapping between user queries and web page titles.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Blending gradient boosted trees and neural networks for point and  probabilistic forecasting of hierarchical time series</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13029</p>
  <p><b>作者</b>：Ioannis Nasios,  Konstantinos Vogklis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural networks families, gradient boosted trees, machine learning models, networks families, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we tackle the problem of point and probabilistic forecasting by describing a blending methodology of machine learning models that belong to gradient boosted trees and neural networks families. These principles were successfully applied in the recent M5 Competition on both Accuracy and Uncertainty tracks. The keypoints of our methodology are: a) transform the task to regression on sales for a single day b) information rich feature engineering c) create a diverse set of state-of-the-art machine learning models and d) carefully construct validation sets for model tuning. We argue that the diversity of the machine learning models along with the careful selection of validation examples, where the most important ingredients for the effectiveness of our approach. Although forecasting data had an inherent hierarchy structure (12 levels), none of our proposed solutions exploited that hierarchical scheme. Using the proposed methodology, our team was ranked within the gold medal range in both Accuracy and the Uncertainty track. Inference code along with already trained models are available at this https URL</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Be Bayesian by Attachments to Catch More Uncertainty</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13027</p>
  <p><b>作者</b>：Shiyu Shen,  Bin Pan,  Tianyang Shi,  Tao Li,  Zhenwei Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solid theorical foundations, Bayesian Neural Networks, Bayesian Neural, neural network, OOD data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribution modules aim at extracting the uncertainty from both ID and OOD data. We further provide theoretical analysis for the convergence of ABNN, and experimentally validate its superiority by comparing with some state-of-the-art uncertainty estimation methods Code will be made available.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Towards Anytime Fine-tuning: Continually Pre-trained Language Models  with Hypernetwork Prompt</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13024</p>
  <p><b>作者</b>：Gangwei Jiang,  Caigao Jiang,  Siqiao Xue,  James Y. Zhang,  Jun Zhou,  Defu Lian,  Ying Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pre-trained model, fast-evolving world, urgent for adapting, continually pre-trained model, Continual pre-training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual pre-training has been urgent for adapting a pre-trained model to a multitude of domains and tasks in the fast-evolving world. In practice, a continually pre-trained model is expected to demonstrate not only greater capacity when fine-tuned on pre-trained domains but also a non-decreasing performance on unseen ones. In this work, we first investigate such anytime fine-tuning effectiveness of existing continual pre-training approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. The agreement loss maximally preserves the generalization of a pre-trained model to new domains, and the disagreement one guards the exclusiveness of the generated hidden states for each domain. Remarkably, prompts by the hypernetwork alleviate the domain identity when fine-tuning and promote knowledge transfer across domains. Our method achieved improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively, demonstrating its efficacy.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised  Language Understanding</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13022</p>
  <p><b>作者</b>：Jianing Wang,  Qiushi Sun,  Nuo Chen,  Chengyu Wang,  Jun Huang,  Ming Gao,  Xiang Li</p>
  <p><b>备注</b>：Accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：large pre-trained language, typically produces inferior, pre-trained language models, produces inferior performance, massive labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow the optimization of only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class  Manipulation Using DeepFool Algorithm</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13019</p>
  <p><b>作者</b>：S. M. Fazle Rabby Labib,  Joyanta Jyoti Mondal,  Meem Arafat Manab</p>
  <p><b>备注</b>：8 pages, 3 figures, to be submitted at IEEE Computer Vision and Pattern Recognition (CVPR) 2024</p>
  <p><b>关键词</b>：adversarial attacks poses, advanced various domains, poses serious concerns, significantly advanced, vulnerability to adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across different deep neural network architectures while preserving image integrity as much as possible. Results show that one of the deep convolutional neural network architectures, AlexNet, and one of the state-of-the-art model Vision Transformer exhibit high robustness to getting fooled. Our code will be made public when publishing the paper.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Position Interpolation Improves ALiBi Extrapolation</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13017</p>
  <p><b>作者</b>：Faisal Al-Khateeb,  Nolan Dey,  Daria Soboleva,  Joel Hestness</p>
  <p><b>备注</b>：4 pages content, 1 page references, 4 figures</p>
  <p><b>关键词</b>：longer sequence lengths, rotary position embeddings, Linear position interpolation, sequence lengths, extrapolate to longer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear position interpolation helps pre-trained models using rotary position embeddings (RoPE) to extrapolate to longer sequence lengths. We propose using linear position interpolation to extend the extrapolation range of models using Attention with Linear Biases (ALiBi). We find position interpolation significantly improves extrapolation capability on upstream language modelling and downstream summarization and retrieval tasks.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Large Language Model Prediction Capabilities: Evidence from a Real-World  Forecasting Tournament</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13014</p>
  <p><b>作者</b>：Philipp Schoenegger,  Peter S. Park</p>
  <p><b>备注</b>：13 pages, six visualizations (four figures, two tables)</p>
  <p><b>关键词</b>：Accurately predicting, important milestone, large language models, real-world forecasting tournaments, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence. However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent. To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform. The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict. Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts. We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question. We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis. Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts. A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data. This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Compositional preference models for aligning LMs</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13011</p>
  <p><b>作者</b>：Dongyoung Go,  Tomasz Korbak,  Germán Kruszewski,  Jos Rozen,  Marc Dymetman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Compositional Preference Models, Preference Models, increasingly important, important to align, Preference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As language models (LMs) become more capable, it is increasingly important to align them with human preferences. However, the dominant paradigm for training Preference Models (PMs) for that purpose suffers from fundamental limitations, such as lack of transparency and scalability, along with susceptibility to overfitting the preference dataset. We propose Compositional Preference Models (CPMs), a novel PM framework that decomposes one global preference assessment into several interpretable features, obtains scalar scores for these features from a prompted LM, and aggregates these scores using a logistic regression classifier. CPMs allow to control which properties of the preference data are used to train the preference model and to build it based on features that are believed to underlie the human preference judgment. Our experiments show that CPMs not only improve generalization and are more robust to overoptimization than standard PMs, but also that best-of-n samples obtained using CPMs tend to be preferred over samples obtained using conventional PMs. Overall, our approach demonstrates the benefits of endowing PMs with priors about which features determine human preferences while relying on LM capabilities to extract those features in a scalable and robust way.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：LoBaSS: Gauging Learnability in Supervised Fine-tuning Data</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13008</p>
  <p><b>作者</b>：Haotian Zhou,  Tingkai Liu,  Qianli Ma,  Jianbo Yuan,  Pengfei Liu,  Yang You,  Hongxia Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligning Large Language, Large Language Models, Large Language, specific task prerequisites, aligning Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency. In experimental comparisons involving 7B and 13B models, our LoBaSS method is able to surpass full-data fine-tuning at merely 6% of the total training data. When employing 16.7% of the data, LoBaSS harmonizes the model's capabilities across conversational and mathematical domains, proving its efficacy and adaptability.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Software Metadata Classification based on Generative Artificial  Intelligence</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13006</p>
  <p><b>作者</b>：Seetharam Killivalavan,  Durairaj Thenmozhi</p>
  <p><b>备注</b>：FIRE Track: Information Retrieval in Software Engineering (IRSE), 9 pages</p>
  <p><b>关键词</b>：Generative Artificial Intelligence, Artificial Intelligence, Language Model Architecture, Large Language Model, approach to enhance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach to enhance the performance of binary code comment quality classification models through the application of Generative Artificial Intelligence (AI). By leveraging the OpenAI API, a dataset comprising 1239 newly generated code-comment pairs, extracted from various GitHub repositories and open-source projects, has been labelled as "Useful" or "Not Useful", and integrated into the existing corpus of 9048 pairs in the C programming language. Employing a cutting-edge Large Language Model Architecture, the generated dataset demonstrates notable improvements in model accuracy. Specifically, when incorporated into the Support Vector Machine (SVM) model, a 6% increase in precision is observed, rising from 0.79 to 0.85. Additionally, the Artificial Neural Network (ANN) model exhibits a 1.5% increase in recall, climbing from 0.731 to 0.746. This paper sheds light on the potential of Generative AI in augmenting code comment quality classification models. The results affirm the effectiveness of this methodology, indicating its applicability in broader contexts within software development and quality assurance domains. The findings underscore the significance of integrating generative techniques to advance the accuracy and efficacy of machine learning models in practical software engineering scenarios.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Progressively Efficient Learning</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13004</p>
  <p><b>作者</b>：Ruijie Zheng,  Khanh Nguyen,  Hal Daumé III,  Furong Huang,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：user preferences, capable of rapidly, rapidly acquiring, acquiring novel skills, skills and adapting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assistant AI agents should be capable of rapidly acquiring novel skills and adapting to new user preferences. Traditional frameworks like imitation learning and reinforcement learning do not facilitate this capability because they support only low-level, inefficient forms of communication. In contrast, humans communicate with progressive efficiency by defining and sharing abstract intentions. Reproducing similar capability in AI agents, we develop a novel learning framework named Communication-Efficient Interactive Learning (CEIL). By equipping a learning agent with an abstract, dynamic language and an intrinsic motivation to learn with minimal communication effort, CEIL leads to emergence of a human-like pattern where the learner and the teacher communicate progressively efficiently by exchanging increasingly more abstract intentions. CEIL demonstrates impressive performance and communication efficiency on a 2D MineCraft domain featuring long-horizon decision-making tasks. Agents trained with CEIL quickly master new tasks, outperforming non-hierarchical and hierarchical imitation learning by up to 50% and 20% in absolute success rate, respectively, given the same number of interactions with the teacher. Especially, the framework performs robustly with teachers modeled after human pragmatic communication behavior.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Conversational Financial Information Retrieval Model (ConFIRM)</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13001</p>
  <p><b>作者</b>：Stephen Choi,  William Gazeley,  Siu Ho Wong,  Tingting Li</p>
  <p><b>备注</b>：10 pages, 2 figures, 2 tables, 2 appendices</p>
  <p><b>关键词</b>：finance merits exploration, large language models, leveraging their emergent, merits exploration, exponential growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.
ConFIRM comprises two modules:
1) a method to synthesize finance domain-specific question-answer pairs, and
2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.
ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Wave-informed dictionary learning for high-resolution imaging in complex  media</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12990</p>
  <p><b>作者</b>：Miguel Moscoso,  Alexei Novikov,  George Papanicolaou,  Chrysoula Tsogka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse data sets, sensing matrix, diverse data, step, scattering media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an approach for imaging in scattering media when large and diverse data sets are available. It has two steps. Using a dictionary learning algorithm the first step estimates the true Green's function vectors as columns in an unordered sensing matrix. The array data comes from many sparse sets of sources whose location and strength are not known to us. In the second step, the columns of the estimated sensing matrix are ordered for imaging using Multi-Dimensional Scaling with connectivity information derived from cross-correlations of its columns, as in time reversal. For these two steps to work together we need data from large arrays of receivers so the columns of the sensing matrix are incoherent for the first step, as well as from sub-arrays so that they are coherent enough to obtain the connectivity needed in the second step. Through simulation experiments, we show that the proposed approach is able to provide images in complex media whose resolution is that of a homogeneous medium.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Optimal Transport for Measures with Noisy Tree Metric</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13653</p>
  <p><b>作者</b>：Tam Le,  Truyen Nguyen,  Kenji Fukumizu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study optimal transport, tree, optimal transport, tree structure, study optimal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. In order to mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in $1$-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose \emph{novel uncertainty sets of tree metrics} from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, by building upon the proposed uncertainty sets, and leveraging the tree structure over supports, we show that the max-min robust OT also admits a closed-form expression for a fast computation as its counterpart standard OT (i.e., TW). Furthermore, we demonstrate that the max-min robust OT satisfies the metric property and is negative definite. We then exploit its negative definiteness to propose \emph{positive definite kernels} and test them in several simulations on various real-world datasets on document classification and topological data analysis for measures with noisy tree metric.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Progressive Dual Priori Network for Generalized Breast Tumor  Segmentation</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13574</p>
  <p><b>作者</b>：Li Wang,  Lihui Wang,  Zixiang Kuai,  Lei Tang,  Yingfeng Ou,  Chen Ye,  Yuemin Zhu</p>
  <p><b>备注</b>：12 pages, 10 figures</p>
  <p><b>关键词</b>：amd irregular shape, magnetic resonance images, dynamic enhanced magnetic, enhanced magnetic resonance, dual priori network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To promote the generalization ability of breast tumor segmentation models, as well as to improve the segmentation performance for breast tumors with smaller size, low-contrast amd irregular shape, we propose a progressive dual priori network (PDPNet) to segment breast tumors from dynamic enhanced magnetic resonance images (DCE-MRI) acquired at different sites. The PDPNet first cropped tumor regions with a coarse-segmentation based localization module, then the breast tumor mask was progressively refined by using the weak semantic priori and cross-scale correlation prior knowledge. To validate the effectiveness of PDPNet, we compared it with several state-of-the-art methods on multi-center datasets. The results showed that, comparing against the suboptimal method, the DSC, SEN, KAPPA and HD95 of PDPNet were improved 3.63\%, 8.19\%, 5.52\%, and 3.66\% respectively. In addition, through ablations, we demonstrated that the proposed localization module can decrease the influence of normal tissues and therefore improve the generalization ability of the model. The weak semantic priors allow focusing on tumor regions to avoid missing small tumors and low-contrast tumors. The cross-scale correlation priors are beneficial for promoting the shape-aware ability for irregual tumors. Thus integrating them in a unified framework improved the multi-center breast tumor segmentation performance.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Variational measurement-based quantum computation for generative  modeling</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13524</p>
  <p><b>作者</b>：Arunava Majumder,  Marius Krumm,  Tina Radkohl,  Hendrik Poulsen Nautrup,  Sofiene Jerbi,  Hans J. Briegel</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：fundamentally unique paradigm, Measurement-based quantum computation, MBQC, design quantum algorithms, offers a fundamentally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Measurement-based quantum computation (MBQC) offers a fundamentally unique paradigm to design quantum algorithms. Indeed, due to the inherent randomness of quantum measurements, the natural operations in MBQC are not deterministic and unitary, but are rather augmented with probabilistic byproducts. Yet, the main algorithmic use of MBQC so far has been to completely counteract this probabilistic nature in order to simulate unitary computations expressed in the circuit model. In this work, we propose designing MBQC algorithms that embrace this inherent randomness and treat the random byproducts in MBQC as a resource for computation. As a natural application where randomness can be beneficial, we consider generative modeling, a task in machine learning centered around generating complex probability distributions. To address this task, we propose a variational MBQC algorithm equipped with control parameters that allow to directly adjust the degree of randomness to be admitted in the computation. Our numerical findings indicate that this additional randomness can lead to significant gains in learning performance in certain generative modeling tasks. These results highlight the potential advantages in exploiting the inherent randomness of MBQC and motivate further research into MBQC-based algorithms.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Personalized identification, prediction, and stimulation of neural  oscillations via data-driven models of epileptic network dynamics</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13480</p>
  <p><b>作者</b>：Tena Dubcek,  Debora Ledergerber,  Jana Thomann,  Giovanna Aiello,  Marc Serra-Garcia,  Lukas Imbach,  Rafael Polania</p>
  <p><b>备注</b>：4+2 figures</p>
  <p><b>关键词</b>：brain, brain stimulation, brain-specific signatures, signatures of information, information processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural oscillations are considered to be brain-specific signatures of information processing and communication in the brain. They also reflect pathological brain activity in neurological disorders, thus offering a basis for diagnoses and forecasting. Epilepsy is one of the most common neurological disorders, characterized by abnormal synchronization and desynchronization of the oscillations in the brain. About one third of epilepsy cases are pharmacoresistant, and as such emphasize the need for novel therapy approaches, where brain stimulation appears to be a promising therapeutic option. The development of brain stimulation paradigms, however, is often based on generalized assumptions about brain dynamics, although it is known that significant differences occur between patients and brain states. We developed a framework to extract individualized predictive models of epileptic network dynamics directly from EEG data. The models are based on the dominant coherent oscillations and their dynamical coupling, thus combining an established interpretation of dynamics through neural oscillations, with accurate patient-specific features. We show that it is possible to build a direct correspondence between the models of brain-network dynamics under periodic driving, and the mechanism of neural entrainment via periodic stimulation. When our framework is applied to EEG recordings of patients in status epilepticus (a brain state of perpetual seizure activity), it yields a model-driven predictive analysis of the therapeutic performance of periodic brain stimulation. This suggests that periodic brain stimulation can drive pathological states of epileptic network dynamics towards a healthy functional brain state.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：HRTF Interpolation using a Spherical Neural Process Meta-Learner</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13430</p>
  <p><b>作者</b>：Etienne Thuillier,  Craig Jin,  Vesa Välimäki</p>
  <p><b>备注</b>：12 pages. 11 figures. Submitted for publication in IEEE/ACM Transactions on Audio, Speech and Language Processing (T-ASL)</p>
  <p><b>关键词</b>：Head-Related Transfer Function, Transfer Function, subject Head-Related Transfer, convenient input modalities, Head-Related Transfer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several individualization methods have recently been proposed to estimate a subject's Head-Related Transfer Function (HRTF) using convenient input modalities such as anthropometric measurements or pinnae photographs. There exists a need for adaptively correcting the estimation error committed by such methods using a few data point samples from the subject's HRTF, acquired using acoustic measurements or perceptual feedback. To this end, we introduce a Convolutional Conditional Neural Process meta-learner specialized in HRTF error interpolation. In particular, the model includes a Spherical Convolutional Neural Network component to accommodate the spherical geometry of HRTF data. It also exploits potential symmetries between the HRTF's left and right channels about the median axis. In this work, we evaluate the proposed model's performance purely on time-aligned spectrum interpolation grounds under a simplified setup where a generic population-mean HRTF forms the initial estimates prior to corrections instead of individualized ones. The trained model achieves up to 3 dB relative error reduction compared to state-of-the-art interpolation methods despite being trained using only 85 subjects. This improvement translates up to nearly a halving of the data point count required to achieve comparable accuracy, in particular from 50 to 28 points to reach an average of -20 dB relative error per interpolated feature. Moreover, we show that the trained model provides well-calibrated uncertainty estimates. Accordingly, such estimates can inform the sequential decision problem of acquiring as few correcting HRTF data points as needed to meet a desired level of HRTF individualization accuracy.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Calibrating Neural Simulation-Based Inference with Differentiable  Coverage Probability</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13402</p>
  <p><b>作者</b>：Maciej Falkiewicz,  Naoya Takeishi,  Imahn Shekhzadeh,  Antoine Wehenkel,  Arnaud Delaunoy,  Gilles Louppe,  Alexandros Kalousis</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：prior information, Bayesian inference, expressing the uncertainty, probabilistic model, posterior belief</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian inference allows expressing the uncertainty of posterior belief under a probabilistic model given prior information and the likelihood of the evidence. Predominantly, the likelihood function is only implicitly established by a simulator posing the need for simulation-based inference (SBI). However, the existing algorithms can yield overconfident posteriors (Hermans *et al.*, 2022) defeating the whole purpose of credibility if the uncertainty quantification is inaccurate. We propose to include a calibration term directly into the training objective of the neural model in selected amortized SBI techniques. By introducing a relaxation of the classical formulation of calibration error we enable end-to-end backpropagation. The proposed method is not tied to any particular neural model and brings moderate computational overhead compared to the profits it introduces. It is directly applicable to existing computational pipelines allowing reliable black-box posterior inference. We empirically show on six benchmark problems that the proposed method achieves competitive or better results in terms of coverage and expected posterior density than the previously existing approaches.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Optimal Best Arm Identification with Fixed Confidence in Restless  Bandits</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13393</p>
  <p><b>作者</b>：P. N. Karthik,  Vincent Y. F. Tan,  Arpan Mukherjee,  Ali Tajer</p>
  <p><b>备注</b>：45 pages</p>
  <p><b>关键词</b>：arm, arm identification, arm TPMs, Markov arms, multi-armed bandit setting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study best arm identification in a restless multi-armed bandit setting with finitely many arms. The discrete-time data generated by each arm forms a homogeneous Markov chain taking values in a common, finite state space. The state transitions in each arm are captured by an ergodic transition probability matrix (TPM) that is a member of a single-parameter exponential family of TPMs. The real-valued parameters of the arm TPMs are unknown and belong to a given space. Given a function $f$ defined on the common state space of the arms, the goal is to identify the best arm -- the arm with the largest average value of $f$ evaluated under the arm's stationary distribution -- with the fewest number of samples, subject to an upper bound on the decision's error probability (i.e., the fixed-confidence regime). A lower bound on the growth rate of the expected stopping time is established in the asymptote of a vanishing error probability. Furthermore, a policy for best arm identification is proposed, and its expected stopping time is proved to have an asymptotic growth rate that matches the lower bound. It is demonstrated that tracking the long-term behavior of a certain Markov decision process and its state-action visitation proportions are the key ingredients in analyzing the converse and achievability bounds. It is shown that under every policy, the state-action visitation proportions satisfy a specific approximate flow conservation constraint and that these proportions match the optimal proportions dictated by the lower bound under any asymptotically optimal policy. The prior studies on best arm identification in restless bandits focus on independent observations from the arms, rested Markov arms, and restless Markov arms with known arm TPMs. In contrast, this work is the first to study best arm identification in restless bandits with unknown arm TPMs.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Assumption violations in causal discovery and the robustness of score  matching</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13387</p>
  <p><b>作者</b>：Francesco Montagna,  Atalanti A. Mastakouri,  Elias Eulig,  Nicoletta Noceti,  Lorenzo Rosasco,  Dominik Janzing,  Bryon Aragam,  Francesco Locatello</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causal discovery methods, causal discovery, observational causal discovery, discovery methods, restricted by ethical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When domain knowledge is limited and experimentation is restricted by ethical, financial, or time constraints, practitioners turn to observational causal discovery methods to recover the causal structure, exploiting the statistical properties of their data. Because causal discovery without further assumptions is an ill-posed problem, each algorithm comes with its own set of usually untestable assumptions, some of which are hard to meet in real datasets. Motivated by these considerations, this paper extensively benchmarks the empirical performance of recent causal discovery methods on observational i.i.d. data generated under different background conditions, allowing for violations of the critical assumptions required by each selected approach. Our experimental findings show that score matching-based methods demonstrate surprising performance in the false positive and false negative rate of the inferred graph in these challenging scenarios, and we provide theoretical insights into their performance. This work is also the first effort to benchmark the stability of causal discovery algorithms with respect to the values of their hyperparameters. Finally, we hope this paper will set a new standard for the evaluation of causal discovery methods and can serve as an accessible entry point for practitioners interested in the field, highlighting the empirical implications of different algorithm choices.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：DeepFDR: A Deep Learning-based False Discovery Rate Control Method for  Neuroimaging Data</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13349</p>
  <p><b>作者</b>：Taehyo Kim,  Hai Shu,  Qiran Jia,  Mony de Leon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：FDR control, spatial FDR control, Voxel-based multiple testing, Voxel-based multiple, FDR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but also boasts exceptional computational efficiency highly suited for tackling large-scale neuroimaging data.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Non-Negative Spherical Relaxations for Universe-Free Multi-Matching and  Clustering</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13311</p>
  <p><b>作者</b>：Johan Thunberg,  Florian Bernard</p>
  <p><b>备注</b>：Published at Scandinavian Conference on Image Analysis (SCIA) 2023</p>
  <p><b>关键词</b>：non-negative spherical relaxation, spherical relaxation, matrices with injectivity, non-negative spherical, injectivity constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel non-negative spherical relaxation for optimization problems over binary matrices with injectivity constraints, which in particular has applications in multi-matching and clustering. We relax respective binary matrix constraints to the (high-dimensional) non-negative sphere. To optimize our relaxed problem, we use a conditional power iteration method to iteratively improve the objective function, while at same time sweeping over a continuous scalar parameter that is (indirectly) related to the universe size (or number of clusters). Opposed to existing procedures that require to fix the integer universe size before optimization, our method automatically adjusts the analogous continuous parameter. Furthermore, while our approach shares similarities with spectral multi-matching and spectral clustering, our formulation has the strong advantage that we do not rely on additional post-processing procedures to obtain binary results. Our method shows compelling results in various multi-matching and clustering settings, even when compared to methods that use the ground truth universe size (or number of clusters).</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Meta-learning of Physics-informed Neural Networks for Efficiently  Solving Newly Given PDEs</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13270</p>
  <p><b>作者</b>：Tomoharu Iwata,  Yusuke Tanaka,  Naonori Ueda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PDE problems, network-based meta-learning method, neural network-based meta-learning, PDE, solve partial differential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a neural network-based meta-learning method to efficiently solve partial differential equation (PDE) problems. The proposed method is designed to meta-learn how to solve a wide variety of PDE problems, and uses the knowledge for solving newly given PDE problems. We encode a PDE problem into a problem representation using neural networks, where governing equations are represented by coefficients of a polynomial function of partial derivatives, and boundary conditions are represented by a set of point-condition pairs. We use the problem representation as an input of a neural network for predicting solutions, which enables us to efficiently predict problem-specific solutions by the forwarding process of the neural network without updating model parameters. To train our model, we minimize the expected error when adapted to a PDE problem based on the physics-informed neural network framework, by which we can evaluate the error even when solutions are unknown. We demonstrate that our proposed method outperforms existing methods in predicting solutions of PDE problems.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Equivariant Transformer is all you need</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13222</p>
  <p><b>作者</b>：Akio Tomiya,  Yuki Nagai</p>
  <p><b>备注</b>：7 pages, 4 figures, contribution for the 40th International Symposium on Lattice Field Theory (Lattice 2023), July 31st - August 4th, 2023, Fermi National Accelerator Laboratory</p>
  <p><b>关键词</b>：accelerating computational physics, computational physics, Machine learning, accelerating computational, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning, deep learning, has been accelerating computational physics, which has been used to simulate systems on a lattice. Equivariance is essential to simulate a physical system because it imposes a strong induction bias for the probability distribution described by a machine learning model. This reduces the risk of erroneous extrapolation that deviates from data symmetries and physical laws. However, imposing symmetry on the model sometimes occur a poor acceptance rate in self-learning Monte-Carlo (SLMC). On the other hand, Attention used in Transformers like GPT realizes a large model capacity. We introduce symmetry equivariant attention to SLMC. To evaluate our architecture, we apply it to our proposed new architecture on a spin-fermion model on a two-dimensional lattice. We find that it overcomes poor acceptance rates for linear models and observe the scaling law of the acceptance rate as in the large language models with Transformers.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：A Deep Learning Analysis of Climate Change, Innovation, and Uncertainty</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13200</p>
  <p><b>作者</b>：Michael Barnett,  William Brock,  Lars Peter Hansen,  Ruimeng Hu,  Joseph Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produces carbon emissions, green sector productivity, sector productivity, carbon emissions, study the implications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the implications of model uncertainty in a climate-economics framework with three types of capital: "dirty" capital that produces carbon emissions when used for production, "clean" capital that generates no emissions but is initially less productive than dirty capital, and knowledge capital that increases with R\&D investment and leads to technological innovation in green sector productivity. To solve our high-dimensional, non-linear model framework we implement a neural-network-based global solution method. We show there are first-order impacts of model uncertainty on optimal decisions and social valuations in our integrated climate-economic-innovation framework. Accounting for interconnected uncertainty over climate dynamics, economic damages from climate change, and the arrival of a green technological change leads to substantial adjustments to investment in the different capital types in anticipation of technological change and the revelation of climate damage severity.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Approaches for Uncertainty Quantification of AI-predicted Material  Properties: A Comparison</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13136</p>
  <p><b>作者</b>：Francesca Tavazza,  Kamal Choudhary,  Brian DeCost</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2107.07997</p>
  <p><b>关键词</b>：predicting material performances, material performances, powerful computers, allowed machine learning, predicting material</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of large databases of material properties, together with the availability of powerful computers, has allowed machine learning (ML) modeling to become a widely used tool for predicting material performances. While confidence intervals are commonly reported for such ML models, prediction intervals, i.e., the uncertainty on each prediction, are not as frequently available. Here, we investigate three easy-to-implement approaches to determine such individual uncertainty, comparing them across ten ML quantities spanning energetics, mechanical, electronic, optical, and spectral properties. Specifically, we focused on the Quantile approach, the direct machine learning of the prediction intervals and Ensemble methods.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Streamlining Brain Tumor Classification with Custom Transfer Learning in  MRI Images</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13108</p>
  <p><b>作者</b>：Javed Hossain,  Md. Touhidul Islam,  Md. Taufiqul Haque Khan Tusar</p>
  <p><b>备注</b>：6 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：cases diagnosed globally, Magnetic Resonance Imaging, Brain tumors, increasingly prevalent, globally each year</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain tumors are increasingly prevalent, characterized by the uncontrolled spread of aberrant tissues in the brain, with almost 700,000 new cases diagnosed globally each year. Magnetic Resonance Imaging (MRI) is commonly used for the diagnosis of brain tumors and accurate classification is a critical clinical procedure. In this study, we propose an efficient solution for classifying brain tumors from MRI images using custom transfer learning networks. While several researchers have employed various pre-trained architectures such as RESNET-50, ALEXNET, VGG-16, and VGG-19, these methods often suffer from high computational complexity. To address this issue, we present a custom and lightweight model using a Convolutional Neural Network-based pre-trained architecture with reduced complexity. Specifically, we employ the VGG-19 architecture with additional hidden layers, which reduces the complexity of the base architecture but improves computational efficiency. The objective is to achieve high classification accuracy using a novel approach. Finally, the result demonstrates a classification accuracy of 96.42%.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Sequence Length Independent Norm-Based Generalization Bounds for  Transformers</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13088</p>
  <p><b>作者</b>：Jacob Trauger,  Ambuj Tewari</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：input sequence length, sequence length, norm-based generalization bounds, paper provides norm-based, input sequence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper provides norm-based generalization bounds for the Transformer architecture that do not depend on the input sequence length. We employ a covering number based approach to prove our bounds. We use three novel covering number bounds for the function class of bounded linear transformations to upper bound the Rademacher complexity of the Transformer. Furthermore, we show this generalization bound applies to the common Transformer training technique of masking and then predicting the masked word. We also run a simulated study on a sparse majority data set that empirically validates our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Getting aligned on representational alignment</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13018</p>
  <p><b>作者</b>：Ilia Sucholutsky,  Lukas Muttenthaler,  Adrian Weller,  Andi Peng,  Andreea Bobu,  Been Kim,  Bradley C. Love,  Erin Grant,  Jascha Achterberg,  Joshua B. Tenenbaum,  Katherine M. Collins,  Katherine L. Hermann,  Kerem Oktar,  Klaus Greff,  Martin N. Hebart,  Nori Jacoby,  Qiuyi (Richard) Zhang,  Raja Marjieh,  Robert Geirhos,  Sherol Chen,  Simon Kornblith,  Sunayana Rane,  Talia Konkle,  Thomas P. O'Connell,  Thomas Unterthiner,  Andrew K. Lampinen,  Klaus-Robert Müller,  Mariya Toneva,  Thomas L. Griffiths</p>
  <p><b>备注</b>：Working paper, changes to be made in upcoming revisions</p>
  <p><b>关键词</b>：Biological and artificial, make decisions, systems form representations, processing systems form, representational alignment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biological and artificial information processing systems form representations of the world that they can use to categorize, reason, plan, navigate, and make decisions. To what extent do the representations formed by these diverse systems agree? Can diverging representations still lead to the same behaviors? And how can systems modify their representations to better match those of another system? These questions pertaining to the study of \textbf{\emph{representational alignment}} are at the heart of some of the most active research areas in contemporary cognitive science, neuroscience, and machine learning. Unfortunately, there is limited knowledge-transfer between research communities interested in representational alignment, and much of the progress in one field ends up being rediscovered independently in another, when greater cross-field communication would be advantageous. To improve communication between fields, we propose a unifying framework that can serve as a common language between researchers studying representational alignment. We survey the literature from the fields of cognitive science, neuroscience, and machine learning, and demonstrate how prior work fits into this framework. Finally, we lay out open problems in representational alignment where progress can benefit all three fields. We hope that our work can catalyze cross-disciplinary collaboration and accelerate progress for all communities studying and developing information processing systems. We note that this is a working paper and encourage readers to reach out with their suggestions for future revisions.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Zero-shot Learning of Drug Response Prediction for Preclinical Drug  Screening</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12996</p>
  <p><b>作者</b>：Kun Li,  Yong Luo,  Xiantao Cai,  Wenbin Hu,  Bo Du</p>
  <p><b>备注</b>：16 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：typically employ supervised, methods typically employ, drug, preclinical drug screening, typically employ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional deep learning methods typically employ supervised learning for drug response prediction (DRP). This entails dependence on labeled response data from drugs for model training. However, practical applications in the preclinical drug screening phase demand that DRP models predict responses for novel compounds, often with unknown drug responses. This presents a challenge, rendering supervised deep learning methods unsuitable for such scenarios. In this paper, we propose a zero-shot learning solution for the DRP task in preclinical drug screening. Specifically, we propose a Multi-branch Multi-Source Domain Adaptation Test Enhancement Plug-in, called MSDA. MSDA can be seamlessly integrated with conventional DRP methods, learning invariant features from the prior response data of similar drugs to enhance real-time predictions of unlabeled compounds. We conducted experiments using the GDSCv2 and CellMiner datasets. The results demonstrate that MSDA efficiently predicts drug responses for novel compounds, leading to a general performance improvement of 5-10\% in the preclinical drug screening phase. The significance of this solution resides in its potential to accelerate the drug discovery process, improve drug candidate assessment, and facilitate the success of drug discovery.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：DA-TransUNet: Integrating Spatial and Channel Dual Attention with  Transformer U-Net for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12570</p>
  <p><b>作者</b>：Guanqun Sun,  Yizhi Pan,  Weikun Kong,  Zichang Xu,  Jianhua Ma,  Teeradaj Racharak,  Le-Minh Nguyen,  Junyi Xin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image segmentation, deep representation learning, powerful deep representation, image segmentation, image segmentation due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Great progress has been made in automatic medical image segmentation due to powerful deep representation learning. The influence of transformer has led to research into its variants, and large-scale replacement of traditional CNN modules. However, such trend often overlooks the intrinsic feature extraction capabilities of the transformer and potential refinements to both the model and the transformer module through minor adjustments. This study proposes a novel deep medical image segmentation framework, called DA-TransUNet, aiming to introduce the Transformer and dual attention block into the encoder and decoder of the traditional U-shaped architecture. Unlike prior transformer-based solutions, our DA-TransUNet utilizes attention mechanism of transformer and multifaceted feature extraction of DA-Block, which can efficiently combine global, local, and multi-scale features to enhance medical image segmentation. Meanwhile, experimental results show that a dual attention block is added before the Transformer layer to facilitate feature extraction in the U-net structure. Furthermore, incorporating dual attention blocks in skip connections can enhance feature transfer to the decoder, thereby improving image segmentation performance. Experimental results across various benchmark of medical image segmentation reveal that DA-TransUNet significantly outperforms the state-of-the-art methods. The codes and parameters of our model will be publicly available at this https URL.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Neural-Base Music Generation for Intelligence Duplication</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13691</p>
  <p><b>作者</b>：Jacob Galajda,  Kien Hua</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial intelligence, aspects of machine, interpreting visual data, interpreting information, interpreting visual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are two aspects of machine learning and artificial intelligence: (1) interpreting information, and (2) inventing new useful information. Much advance has been made for (1) with a focus on pattern recognition techniques (e.g., interpreting visual data). This paper focuses on (2) with intelligent duplication (ID) for invention. We explore the possibility of learning a specific individual's creative reasoning in order to leverage the learned expertise and talent to invent new information. More specifically, we employ a deep learning system to learn from the great composer Beethoven and capture his composition ability in a hash-based knowledge base. This new form of knowledge base provides a reasoning facility to drive the music composition through a novel music generation method.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Optimizing Retrieval-augmented Reader Models via Token Elimination</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13682</p>
  <p><b>作者</b>：Moshe Berchansky,  Peter Izsak,  Avi Caciularu,  Ido Dagan,  Moshe Wasserblat</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective retrieval-augmented language, retrieval-augmented language model, language model applied, fact checking, open-domain tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model applied across a variety of open-domain tasks, such as question answering, fact checking, etc. In FiD, supporting passages are first retrieved and then processed using a generative model (Reader), which can cause a significant bottleneck in decoding time, particularly with long outputs. In this work, we analyze the contribution and necessity of all the retrieved passages to the performance of reader models, and propose eliminating some of the retrieved information, at the token level, that might not contribute essential information to the answer generation process. We demonstrate that our method can reduce run-time by up to 62.2%, with only a 2% reduction in performance, and in some cases, even improve the performance results.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Improving Long-form Speech Translation through Segmentation with Large  Language Models and Finite State Decoding Constraints</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13678</p>
  <p><b>作者</b>：Arya D. McCarthy,  Hao Zhang,  Shankar Kumar,  Felix Stahlberg,  Ke Wu</p>
  <p><b>备注</b>：accepted to the Findings of EMNLP 2023. arXiv admin note: text overlap with arXiv:2212.09895</p>
  <p><b>关键词</b>：obtaining high-quality translations, spoken language translation, content is long-form, spoken content, short units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One challenge in spoken language translation is that plenty of spoken content is long-form, but short units are necessary for obtaining high-quality translations. To address this mismatch, we adapt large language models (LLM) to split long ASR transcripts into segments that can be independently translated so as to maximize the overall translation quality. To combat the tendency of hallucination by LLMs, we incorporate finite-state constraints during decoding to eliminate invalid outputs. We discover that LLMs are adaptable to transcripts containing ASR errors through prompt-tuning or fine-tuning. In comparison to a state-of-the-art automatic punctuation baseline, our best LLM improves the average BLEU for English-German, English-Spanish, and English-Arabic TED talk translation in 9 test sets by 2.9 points, just by improving segmentation.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large  Language Models by Extrapolating Errors from Small Models</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13671</p>
  <p><b>作者</b>：Ruida Wang,  Wangchunshu Zhou,  Mrinmaya Sachan</p>
  <p><b>备注</b>：Accepted by EMNLP 2023(Findings)</p>
  <p><b>关键词</b>：Data Synthesis, small model, small model trained, Data, Synthesis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>*Data Synthesis* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the *real task* data distribution. Thus, in this paper, we propose *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot  Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13670</p>
  <p><b>作者</b>：Daiju Kanaoka,  Motoharu Sonogashira,  Hakaru Tamukoh,  Yasutomo Kawanishi</p>
  <p><b>备注</b>：Accepted by BMVC2023</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, recently made significant, made significant progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Novel view synthesis has recently made significant progress with the advent of Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims to achieve this task from only a few images by introducing a new loss function for unknown viewpoints with no input images. The loss function assumes that a pre-trained feature extractor should output the same feature even if input images are captured at different viewpoints since the images contain the same object. However, while that assumption is ideal, in reality, it is known that as viewpoints continuously change, also feature vectors continuously change. Thus, the assumption can harm training. To avoid this harmful training, we propose ManifoldNeRF, a method for supervising feature vectors at unknown viewpoints using interpolated features from neighboring known viewpoints. Since the method provides appropriate supervision for each unknown viewpoint by the interpolated features, the volume representation is learned better than DietNeRF. Experimental results show that the proposed method performs better than others in a complex scene. We also experimented with several subsets of viewpoints from a set of viewpoints and identified an effective set of viewpoints for real environments. This provided a basic policy of viewpoint patterns for real-world application. The code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Automatic Unit Test Data Generation and Actor-Critic Reinforcement  Learning for Code Synthesis</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13669</p>
  <p><b>作者</b>：Philip John Gorinski,  Matthieu Zimmer,  Gerasimos Lampouras,  Derrick Goh Xin Deik,  Ignacio Iacobacci</p>
  <p><b>备注</b>：9 pages + 4 pages appendix; 4 Figures, 4 Tables, 1 Algorithm; Accepted to Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Natural Language Generation, similar to Natural, Unit Tests, Language Modelling, Language Generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of large pre-trained language models in the domain of Code Synthesis has shown remarkable performance on various benchmarks, treating the problem of Code Generation in a fashion similar to Natural Language Generation, trained with a Language Modelling (LM) objective. In addition, the property of programming language code being precisely evaluable with respect to its semantics -- through the use of Unit Tests to check its functional correctness -- lends itself to using Reinforcement Learning (RL) as a further training paradigm. Previous work has shown that RL can be applied as such to improve models' coding capabilities; however, such RL-based methods rely on a reward signal based on defined Unit Tests, which are much harder to obtain compared to the huge crawled code datasets used in LM objectives. In this work, we present a novel approach to automatically obtain data consisting of function signatures and associated Unit Tests, suitable for RL training of Code Synthesis models. We also introduce a straightforward, simple yet effective Actor-Critic RL training scheme and show that it, in conjunction with automatically generated training data, leads to improvement of a pre-trained code language model's performance by up to 9.9% improvement over the original underlying code synthesis LM, and up to 4.3% over RL-based models trained with standard PPO or CodeRL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：An experimental study for early diagnosing Parkinson's disease using  machine learning</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13654</p>
  <p><b>作者</b>：Md. Taufiqul Haque Khan Tusar,  Md. Touhidul Islam,  Abul Hasnat Sakil</p>
  <p><b>备注</b>：12 pages, 9 figures, 5 tables</p>
  <p><b>关键词</b>：neurological disorders worldwide, catastrophic neurological disorders, Parkinson Disease, catastrophic neurological, Machine Learning techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most catastrophic neurological disorders worldwide is Parkinson's Disease. Along with it, the treatment is complicated and abundantly expensive. The only effective action to control the progression is diagnosing it in the early stage. However, this is challenging because early detection necessitates a large and complex clinical study. This experimental work used Machine Learning techniques to automate the early detection of Parkinson's Disease from clinical characteristics, voice features and motor examination. In this study, we develop ML models utilizing a public dataset of 130 individuals, 30 of whom are untreated Parkinson's Disease patients, 50 of whom are Rapid Eye Movement Sleep Behaviour Disorder patients who are at a greater risk of contracting Parkinson's Disease, and 50 of whom are Healthy Controls. We use MinMax Scaler to rescale the data points, Local Outlier Factor to remove outliers, and SMOTE to balance existing class frequency. Afterwards, apply a number of Machine Learning techniques. We implement the approaches in such a way that data leaking and overfitting are not possible. Finally, obtained 100% accuracy in classifying PD and RBD patients, as well as 92% accuracy in classifying PD and HC individuals.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Contrastive Prefence Learning: Learning from Human Feedback without RL</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13639</p>
  <p><b>作者</b>：Joey Hejna,  Rafael Rafailov,  Harshit Sikchi,  Chelsea Finn,  Scott Niekum,  W. Bradley Knox,  Dorsa Sadigh</p>
  <p><b>备注</b>：Code released at this https URL</p>
  <p><b>关键词</b>：Human, human preferences, Learning, Reinforcement Learning, human intent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new family of algorithms for optimizing behavior from human feedback using the regret-based model of human preferences. Using the principle of maximum entropy, we derive Contrastive Preference Learning (CPL), an algorithm for learning optimal policies from preferences without learning reward functions, circumventing the need for RL. CPL is fully off-policy, uses only a simple contrastive objective, and can be applied to arbitrary MDPs. This enables CPL to elegantly scale to high-dimensional and sequential RLHF problems while being simpler than prior methods.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Hunayn: Elevating Translation Beyond the Literal</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13613</p>
  <p><b>作者</b>：Nasser Almousa,  Nasser Alzamil,  Abdullah Alshehri,  Ahmad Sait</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：translator surpassing conventional, surpassing conventional tools, introduces an advanced, translator surpassing, conventional tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This project introduces an advanced English-to-Arabic translator surpassing conventional tools. Leveraging the Helsinki transformer (MarianMT), our approach involves fine-tuning on a self-scraped, purely literary Arabic dataset. Evaluations against Google Translate show consistent outperformance in qualitative assessments. Notably, it excels in cultural sensitivity and context accuracy. This research underscores the Helsinki transformer's superiority for English-to-Arabic translation using a Fusha dataset.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Make Your Decision Convincing! A Unified Two-Stage Framework:  Self-Attribution and Decision-Making</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13610</p>
  <p><b>作者</b>：Yanrui Du,  Sendong Zhao,  Haochun Wang,  Yuhan Chen,  Rui Bai,  Zewen Qiang,  Muzhen Cai,  Bing Qin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Explaining black-box model, black-box model behavior, achieved impressive results, NLP tasks, Explaining black-box</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining black-box model behavior with natural language has achieved impressive results in various NLP tasks. Recent research has explored the utilization of subsequences from the input text as a rationale, providing users with evidence to support the model decision. Although existing frameworks excel in generating high-quality rationales while achieving high task performance, they neglect to account for the unreliable link between the generated rationale and model decision. In simpler terms, a model may make correct decisions while attributing wrong rationales, or make poor decisions while attributing correct rationales. To mitigate this issue, we propose a unified two-stage framework known as Self-Attribution and Decision-Making (SADM). Through extensive experiments on five reasoning datasets from the ERASER benchmark, we demonstrate that our framework not only establishes a more reliable link between the generated rationale and model decision but also achieves competitive results in task performance and the quality of rationale. Furthermore, we explore the potential of our framework in semi-supervised scenarios.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection  Benchmark</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13606</p>
  <p><b>作者</b>：Dominik Macko,  Robert Moro,  Adaku Uchendu,  Jason Samuel Lucas,  Michiharu Yamashita,  Matúš Pikuliak,  Ivan Srba,  Thai Le,  Dongwon Lee,  Jakub Simko,  Maria Bielikova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate convincing text, multilingual machine-generated text, research into capabilities, capabilities of recent, generate convincing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings. This is also reflected in the available benchmarks which lack authentic texts in languages other than English and predominantly cover older generators. To fill this gap, we introduce MULTITuDE, a novel benchmarking dataset for multilingual machine-generated text detection comprising of 74,081 authentic and machine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare the performance of zero-shot (statistical and black-box) and fine-tuned detectors. Considering the multilinguality, we evaluate 1) how these detectors generalize to unseen languages (linguistically similar as well as dissimilar) and unseen LLMs and 2) whether the detectors improve their performance when trained on multiple languages.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：MarineGPT: Unlocking Secrets of Ocean to the Public</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13596</p>
  <p><b>作者</b>：Ziqiang Zheng,  Jipeng Zhang,  Tuan-Anh Vu,  Shizhe Diao,  Yue Him Wong Tim,  Sai-Kit Yeung</p>
  <p><b>备注</b>：work in progress. Code and data will be available at this https URL</p>
  <p><b>关键词</b>：Large language models, textbf, Large language, powerful tools, tools in promoting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs), such as ChatGPT/GPT-4, have proven to be powerful tools in promoting the user experience as an AI assistant. The continuous works are proposing multi-modal large language models (MLLM), empowering LLMs with the ability to sense multiple modality inputs through constructing a joint semantic space (e.g. visual-text space). Though significant success was achieved in LLMs and MLLMs, exploring LLMs and MLLMs in domain-specific applications that required domain-specific knowledge and expertise has been less conducted, especially for \textbf{marine domain}. Different from general-purpose MLLMs, the marine-specific MLLM is required to yield much more \textbf{sensitive}, \textbf{informative}, and \textbf{scientific} responses. In this work, we demonstrate that the existing MLLMs optimized on huge amounts of readily available general-purpose training data show a minimal ability to understand domain-specific intents and then generate informative and satisfactory responses. To address these issues, we propose \textbf{MarineGPT}, the first vision-language model specially designed for the marine domain, unlocking the secrets of the ocean to the public. We present our \textbf{Marine-5M} dataset with more than 5 million marine image-text pairs to inject domain-specific marine knowledge into our model and achieve better marine vision and language alignment. Our MarineGPT not only pushes the boundaries of marine understanding to the general public but also offers a standard protocol for adapting a general-purpose assistant to downstream domain-specific experts. We pave the way for a wide range of marine applications while setting valuable data and pre-trained models for future research in both academic and industrial communities.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：ReLM: Leveraging Language Models for Enhanced Chemical Reaction  Prediction</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13590</p>
  <p><b>作者</b>：Yaorui Shi,  An Zhang,  Enzhi Zhang,  Zhiyuan Liu,  Xiang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Predicting chemical reactions, employing Graph Neural, challenge in chemistry, involves forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting chemical reactions, a fundamental challenge in chemistry, involves forecasting the resulting products from a given reaction process. Conventional techniques, notably those employing Graph Neural Networks (GNNs), are often limited by insufficient training data and their inability to utilize textual information, undermining their applicability in real-world applications. In this work, we propose ReLM, a novel framework that leverages the chemical knowledge encoded in language models (LMs) to assist GNNs, thereby enhancing the accuracy of real-world chemical reaction predictions. To further enhance the model's robustness and interpretability, we incorporate the confidence score strategy, enabling the LMs to self-assess the reliability of their predictions. Our experimental results demonstrate that ReLM improves the performance of state-of-the-art GNN-based methods across various chemical reaction datasets, especially in out-of-distribution settings. Codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：SPARE: A Single-Pass Neural Model for Relational Databases</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13581</p>
  <p><b>作者</b>：Benjamin Hilprecht,  Kristian Kersting,  Carsten Binnig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, Graph Neural Networks, neural networks, images and text, unexplored field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While there has been extensive work on deep neural networks for images and text, deep learning for relational databases (RDBs) is still a rather unexplored field.
One direction that recently gained traction is to apply Graph Neural Networks (GNNs) to RBDs. However, training GNNs on large relational databases (i.e., data stored in multiple database tables) is rather inefficient due to multiple rounds of training and potentially large and inefficient representations. Hence, in this paper we propose SPARE (Single-Pass Relational models), a new class of neural models that can be trained efficiently on RDBs while providing similar accuracies as GNNs. For enabling efficient training, different from GNNs, SPARE makes use of the fact that data in RDBs has a regular structure, which allows one to train these models in a single pass while exploiting symmetries at the same time. Our extensive empirical evaluation demonstrates that SPARE can significantly speedup both training and inference while offering competitive predictive performance over numerous baselines.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Tree Search in DAG Space with Model-based Reinforcement Learning for  Causal Discovery</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13576</p>
  <p><b>作者</b>：Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Identifying causal structure, biology and economics, structure is central, fields ranging, ranging from strategic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying causal structure is central to many fields ranging from strategic decision-making to biology and economics. In this work, we propose a model-based reinforcement learning method for causal discovery based on tree search, which builds directed acyclic graphs incrementally. We also formalize and prove the correctness of an efficient algorithm for excluding edges that would introduce cycles, which enables deeper discrete search and sampling in DAG space. We evaluate our approach on two real-world tasks, achieving substantially better performance than the state-of-the-art model-free method and greedy search, constituting a promising advancement for combinatorial methods.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Boosting Generalization with Adaptive Style Techniques for Fingerprint  Liveness Detection</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13573</p>
  <p><b>作者</b>：Kexin Zhu,  Bo Lin,  Yang Qiu,  Adam Yule,  Yao Tang,  Jiajun Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Fingerprint Representation Challenge, feature extraction technique, liveness feature extraction, high-performance fingerprint liveness, fingerprint liveness feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a high-performance fingerprint liveness feature extraction technique that secured first place in LivDet 2023 Fingerprint Representation Challenge. Additionally, we developed a practical fingerprint recognition system with 94.68% accuracy, earning second place in LivDet 2023 Liveness Detection in Action. By investigating various methods, particularly style transfer, we demonstrate improvements in accuracy and generalization when faced with limited training data. As a result, our approach achieved state-of-the-art performance in LivDet 2023 Challenges.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Retrieval-Augmented Neural Response Generation Using Logical Reasoning  and Relevance Scoring</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13566</p>
  <p><b>作者</b>：Nicholas Thomas Walker,  Stefan Ultes,  Pierre Lison</p>
  <p><b>备注</b>：Presented at SemDial, August 2023 in Maribor, Slovenia</p>
  <p><b>关键词</b>：current dialogue state, systems typically relies, task-oriented dialogue systems, dialogue systems typically, external databases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Constructing responses in task-oriented dialogue systems typically relies on information sources such the current dialogue state or external databases. This paper presents a novel approach to knowledge-grounded response generation that combines retrieval-augmented language models with logical reasoning. The approach revolves around a knowledge graph representing the current dialogue state and background information, and proceeds in three steps. The knowledge graph is first enriched with logically derived facts inferred using probabilistic logical programming. A neural model is then employed at each turn to score the conversational relevance of each node and edge of this extended graph. Finally, the elements with highest relevance scores are converted to a natural language form, and are integrated into the prompt for the neural conversational model employed to generate the system response.
We investigate the benefits of the proposed approach on two datasets (KVRET and GraphWOZ) along with a human evaluation. Experimental results show that the combination of (probabilistic) logical reasoning with conversational relevance scoring does increase both the factuality and fluency of the responses.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Reward Shaping for Happier Autonomous Cyber Security Agents</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13565</p>
  <p><b>作者</b>：Elizabeth Bates,  Vasilios Mavroudis,  Chris Hicks</p>
  <p><b>备注</b>：12 Pages</p>
  <p><b>关键词</b>：exhibited increased potential, machine learning models, solving complex tasks, exhibited increased, increased potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As machine learning models become more capable, they have exhibited increased potential in solving complex tasks. One of the most promising directions uses deep reinforcement learning to train autonomous agents in computer network defense tasks. This work studies the impact of the reward signal that is provided to the agents when training for this task. Due to the nature of cybersecurity tasks, the reward signal is typically 1) in the form of penalties (e.g., when a compromise occurs), and 2) distributed sparsely across each defense episode. Such reward characteristics are atypical of classic reinforcement learning tasks where the agent is regularly rewarded for progress (cf. to getting occasionally penalized for failures). We investigate reward shaping techniques that could bridge this gap so as to enable agents to train more sample-efficiently and potentially converge to a better performance. We first show that deep reinforcement learning algorithms are sensitive to the magnitude of the penalties and their relative size. Then, we combine penalties with positive external rewards and study their effect compared to penalty-only training. Finally, we evaluate intrinsic curiosity as an internal positive reward mechanism and discuss why it might not be as advantageous for high-level network monitoring tasks.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Self-prompted Chain-of-Thought on Large Language Models for Open-domain  Multi-hop Reasoning</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13552</p>
  <p><b>作者</b>：Jinyuan Wang,  Junlong Li,  Hai Zhao</p>
  <p><b>备注</b>：Accepted by Findings of EMNLP2023</p>
  <p><b>关键词</b>：questions require single-hop, require single-hop reasoning, existing questions require, require single-hop, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT selection and self-prompted inference via in-context learning. Extensive experiments on four multi-hop question-answering benchmarks show that our proposed SP-CoT not only significantly surpasses the previous SOTA methods on large-scale (175B) LLMs, but also nearly doubles the zero-shot performance of small-scale (13B) LLMs. Further analysis reveals the remarkable capability of SP-CoT to elicit direct and concise intermediate reasoning steps by recalling $\sim$50\% of intermediate answers on MuSiQue-Ans dataset.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Towards Understanding Sycophancy in Language Models</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13548</p>
  <p><b>作者</b>：Mrinank Sharma,  Meg Tong,  Tomasz Korbak,  David Duvenaud,  Amanda Askell,  Samuel R. Bowman,  Newton Cheng,  Esin Durmus,  Zac Hatfield-Dodds,  Scott R. Johnston,  Shauna Kravec,  Timothy Maxwell,  Sam McCandlish,  Kamal Ndousse,  Oliver Rausch,  Nicholas Schiefer,  Da Yan,  Miranda Zhang,  Ethan Perez</p>
  <p><b>备注</b>：32 pages, 20 figures</p>
  <p><b>关键词</b>：Reinforcement learning, RLHF, popular technique, technique for training, training high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of RLHF models, likely driven in part by human preference judgements favoring sycophantic responses.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：ScaleLong: Towards More Stable Training of Diffusion Model via Scaling  Network Long Skip Connection</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13545</p>
  <p><b>作者</b>：Zhongzhan Huang,  Pan Zhou,  Shuicheng Yan,  Liang Lin</p>
  <p><b>备注</b>：accepted by NeurIPS 2023</p>
  <p><b>关键词</b>：long skip connects, aggregate long-distant information, connect distant network, diffusion models, popular network backbone</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In diffusion models, UNet is the most popular network backbone, since its long skip connects (LSCs) to connect distant network blocks can aggregate long-distant information and alleviate vanishing gradient. Unfortunately, UNet often suffers from unstable training in diffusion models which can be alleviated by scaling its LSC coefficients smaller. However, theoretical understandings of the instability of UNet in diffusion models and also the performance improvement of LSC scaling remain absent yet. To solve this issue, we theoretically show that the coefficients of LSCs in UNet have big effects on the stableness of the forward and backward propagation and robustness of UNet. Specifically, the hidden feature and gradient of UNet at any layer can oscillate and their oscillation ranges are actually large which explains the instability of UNet training. Moreover, UNet is also provably sensitive to perturbed input, and predicts an output distant from the desired output, yielding oscillatory loss and thus oscillatory gradient. Besides, we also observe the theoretical benefits of the LSC coefficient scaling of UNet in the stableness of hidden features and gradient and also robustness. Finally, inspired by our theory, we propose an effective coefficient scaling framework ScaleLong that scales the coefficients of LSC in UNet and better improves the training stability of UNet. Experimental results on four famous datasets show that our methods are superior to stabilize training and yield about 1.5x training acceleration on different diffusion models with UNet or UViT backbones. Code: this https URL</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Positive-Unlabeled Node Classification with Structure-aware Graph  Learning</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13538</p>
  <p><b>作者</b>：Hansi Yang,  Yongqi Zhang,  Quanming Yao,  James Kwok</p>
  <p><b>备注</b>：CIKM 2023</p>
  <p><b>关键词</b>：important research problem, important research, research problem, Node classification, Node</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Node classification on graphs is an important research problem with many applications. Real-world graph data sets may not be balanced and accurate as assumed by most existing works. A challenging setting is positive-unlabeled (PU) node classification, where labeled nodes are restricted to positive nodes. It has diverse applications, e.g., pandemic prediction or network anomaly detection. Existing works on PU node classification overlook information in the graph structure, which can be critical. In this paper, we propose to better utilize graph structure for PU node classification. We first propose a distance-aware PU loss that uses homophily in graphs to introduce more accurate supervision. We also propose a regularizer to align the model with graph structure. Theoretical analysis shows that minimizing the proposed loss also leads to minimizing the expected loss with both positive and negative labels. Extensive empirical evaluation on diverse graph data sets demonstrates its superior performance over existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Technical Report for ICCV 2023 Visual Continual Learning Challenge:  Continuous Test-time Adaptation for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13533</p>
  <p><b>作者</b>：Damian Sójka,  Yuyang Liu,  Dipam Goswami,  Sebastian Cygert,  Bartłomiej Twardowski,  Joost van de Weijer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic segmentation task, segmentation task, semantic segmentation, TTA methods, source model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT dataset, in which there are only six sequences that start and end with the source domain. We conduct an analysis specifically on those sequences. Ground truth data for test split, on which the developed TTA methods are evaluated for leader board ranking, are not publicly available.
The proposed solution secured a 3rd place in a challenge and received an innovation award. Contrary to the solutions that scored better, we did not use any external pretrained models or specialized data augmentations, to keep the solutions as general as possible. We have focused on analyzing the distributional shift and developing a method that could adapt to changing data dynamics and generalize across different scenarios.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：RaceLens: A Machine Intelligence-Based Application for Racing Photo  Analysis</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13515</p>
  <p><b>作者</b>：Andrei Boiarov,  Dmitry Bleklov,  Pavlo Bredikhin,  Nikita Koritsky,  Sergey Ulasen</p>
  <p><b>备注</b>：Accepted at ISACE 2023 Workshop</p>
  <p><b>关键词</b>：utilizing advanced deep, advanced deep learning, computer vision models, paper presents RaceLens, application utilizing advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents RaceLens, a novel application utilizing advanced deep learning and computer vision models for comprehensive analysis of racing photos. The developed models have demonstrated their efficiency in a wide array of tasks, including detecting racing cars, recognizing car numbers, detecting and quantifying car details, and recognizing car orientations. We discuss the process of collecting a robust dataset necessary for training our models, and describe an approach we have designed to augment and improve this dataset continually. Our method leverages a feedback loop for continuous model improvement, thus enhancing the performance and accuracy of RaceLens over time. A significant part of our study is dedicated to illustrating the practical application of RaceLens, focusing on its successful deployment by NASCAR teams over four seasons. We provide a comprehensive evaluation of our system's performance and its direct impact on the team's strategic decisions and performance metrics. The results underscore the transformative potential of machine intelligence in the competitive and dynamic world of car racing, setting a precedent for future applications.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Explaining Interactions Between Text Spans</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13506</p>
  <p><b>作者</b>：Sagnik Ray Choudhury,  Pepa Atanasova,  Isabelle Augenstein</p>
  <p><b>备注</b>：code: this https URL , dataset: this https URL Accepted EMNLP 2023</p>
  <p><b>关键词</b>：machine reading comprehension, natural language understanding, natural language inference, machine reading, reading comprehension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reasoning over spans of tokens from different parts of the input is essential for natural language understanding (NLU) tasks such as fact-checking (FC), machine reading comprehension (MRC) or natural language inference (NLI). However, existing highlight-based explanations primarily focus on identifying individual important tokens or interactions only between adjacent tokens or tuples of tokens. Most notably, there is a lack of annotations capturing the human decision-making process w.r.t. the necessary interactions for informed decision-making in such tasks. To bridge this gap, we introduce SpanEx, a multi-annotator dataset of human span interaction explanations for two NLU tasks: NLI and FC. We then investigate the decision-making processes of multiple fine-tuned large language models in terms of the employed connections between spans in separate parts of the input and compare them to the human reasoning processes. Finally, we present a novel community detection based unsupervised method to extract such interaction explanations from a model's inner workings.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Robust Training for Conversational Question Answering Models with  Reinforced Reformulation Generation</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13505</p>
  <p><b>作者</b>：Magdalena Kaiser,  Rishiraj Saha Roy,  Gerhard Weikum</p>
  <p><b>备注</b>：WSDM 2024 Research Paper, 11 pages</p>
  <p><b>关键词</b>：knowledge graphs, conversational question answering, training, conversational question, Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Models for conversational question answering (ConvQA) over knowledge graphs (KGs) are usually trained and tested on benchmarks of gold QA pairs. This implies that training is limited to surface forms seen in the respective datasets, and evaluation is on a small set of held-out questions. Through our proposed framework REIGN, we take several steps to remedy this restricted learning setup. First, we systematically generate reformulations of training questions to increase robustness of models to surface form variations. This is a particularly challenging problem, given the incomplete nature of such questions. Second, we guide ConvQA models towards higher performance by feeding it only those reformulations that help improve their answering quality, using deep reinforcement learning. Third, we demonstrate the viability of training major model components on one benchmark and applying them zero-shot to another. Finally, for a rigorous evaluation of robustness for trained models, we use and release large numbers of diverse reformulations generated by prompting GPT for benchmark test sets (resulting in 20x increase in sizes). Our findings show that ConvQA models with robust training via reformulations, significantly outperform those with standard training from gold QA pairs only.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Analogical Proportions and Creativity: A Preliminary Study</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13500</p>
  <p><b>作者</b>：Stergos Afantenos,  Henri Prade,  Leonardo Cortez Bernardes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yield similar results, elements in pair, Analogical proportions, yield similar, pair</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analogical proportions are statements of the form "$a$ is to $b$ as $c$ is to $d$", which expresses that the comparisons of the elements in pair $(a, b)$ and in pair $(c, d)$ yield similar results. Analogical proportions are creative in the sense that given 3 distinct items, the representation of a 4th item $d$, distinct from the previous items, which forms an analogical proportion with them can be calculated, provided certain conditions are met. After providing an introduction to analogical proportions and their properties, the paper reports the results of an experiment made with a database of animal descriptions and their class, where we try to "create" new animals from existing ones, retrieving rare animals such as platypus. We perform a series of experiments using word embeddings as well as Boolean features in order to propose novel animals based on analogical proportions, showing that word embeddings obtain better results.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Mind the instructions: a holistic evaluation of consistency and  interactions in prompt-based learning</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13486</p>
  <p><b>作者</b>：Lucas Weber,  Elia Bruni,  Dieuwke Hupkes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adapting pre-trained language, current NLP, pre-trained language models, adapting pre-trained, pre-trained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding the best way of adapting pre-trained language models to a task is a big challenge in current NLP. Just like the previous generation of task-tuned models (TT), models that are adapted to tasks via in-context-learning (ICL) are robust in some setups but not in others. Here, we present a detailed analysis of which design choices cause instabilities and inconsistencies in LLM predictions. First, we show how spurious correlations between input distributions and labels -- a known issue in TT models -- form only a minor problem for prompted models. Then, we engage in a systematic, holistic evaluation of different factors that have been found to influence predictions in a prompting setup. We test all possible combinations of a range of factors on both vanilla and instruction-tuned (IT) LLMs of different scale and statistically analyse the results to show which factors are the most influential, interactive or stable. Our results show which factors can be used without precautions and which should be avoided or handled with care in most settings.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Application of deep learning for livestock behaviour recognition: A  systematic literature review</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13483</p>
  <p><b>作者</b>：Ali Rohan,  Muhammad Saad Rafaq,  Md. Junayed Hasan,  Furqan Asghar,  Ali Kashif Bashir,  Tania Dottorini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task performed manually, labor-intensive task performed, performed manually, welfare monitoring, monitoring has traditionally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Livestock health and welfare monitoring has traditionally been a labor-intensive task performed manually. Recent advances have led to the adoption of AI and computer vision techniques, particularly deep learning models, as decision-making tools within the livestock industry. These models have been employed for tasks like animal identification, tracking, body part recognition, and species classification. In the past decade, there has been a growing interest in using these models to explore the connection between livestock behaviour and health issues. While previous review studies have been rather generic, there is currently no review study specifically focusing on DL for livestock behaviour recognition. Hence, this systematic literature review (SLR) was conducted. The SLR involved an initial search across electronic databases, resulting in 1101 publications. After applying defined selection criteria, 126 publications were shortlisted. These publications were further filtered based on quality criteria, resulting in the selection of 44 high-quality primary studies. These studies were analysed to address the research questions. The results showed that DL successfully addressed 13 behaviour recognition problems encompassing 44 different behaviour classes. A variety of DL models and networks were employed, with CNN, Faster R-CNN, YOLOv5, and YOLOv4 being among the most common models, and VGG16, CSPDarknet53, GoogLeNet, ResNet101, and ResNet50 being popular networks. Performance evaluation involved ten different matrices, with precision and accuracy being the most frequently used. Primary studies identified challenges, including occlusion, adhesion, data imbalance, and the complexities of the livestock environment. The SLR study also discussed potential solutions and research directions to facilitate the development of autonomous livestock behaviour recognition systems.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Ask Language Model to Clean Your Noisy Translation Data</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13469</p>
  <p><b>作者</b>：Quinten Bolding,  Baohao Liao,  Brandon James Denis,  Jun Luo,  Christof Monz</p>
  <p><b>备注</b>：EMNLP 2023, Findings</p>
  <p><b>关键词</b>：neural machine translation, demonstrated remarkable performance, machine translation, noisy input, NMT models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset \cite{MTNT} is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise in the target sentences while preserving the semantic integrity of the original sentences. Our human and GPT-4 evaluations also lead to a consistent conclusion that LLM performs well on this task. Lastly, experiments on C-MTNT showcased its effectiveness in evaluating the robustness of NMT models, highlighting the potential of advanced language models for data cleaning and emphasizing C-MTNT as a valuable resource.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13447</p>
  <p><b>作者</b>：Siyu Zhang,  Yeming Chen,  Sirui Cheng,  Yaoru Sun,  Jun Yang,  Lizhi Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：good alignment strategy, alignment strategy, vision and language, lies in establishing, establishing a good</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of constituent visual patterns, and captures multiscale features by progressively merging adjacent superpixels as graph nodes. Moreover, we predict the differences between adjacent nodes through the graph structure, facilitating key information aggregation of graph nodes to reason actual semantic relations. Afterward, we design a multi-level fusion rule in a bottom-up manner to avoid understanding deviation by learning complementary spatial information at different regional scales. Our proposed method can be well applied to multiple downstream task learning. Extensive experiments demonstrate that our method is competitive with other state-of-the-art methods in visual reasoning. Our code will be released upon publication.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Self-Consistency of Large Language Models under Ambiguity</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13439</p>
  <p><b>作者</b>：Henning Bartsch,  Ole Jorgensen,  Domenic Rosati,  Jason Hoelscher-Obermaier,  Jacob Pfau</p>
  <p><b>备注</b>：BlackboxNLP @ EMNLP 2023</p>
  <p><b>关键词</b>：Large language models, give consistent answers, Large language, give consistent, contexts are problematic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) that do not give consistent answers across contexts are problematic when used for tasks with expectations of consistency, e.g., question-answering, explanations, etc. Our work presents an evaluation benchmark for self-consistency in cases of under-specification where two or more answers can be correct. We conduct a series of behavioral experiments on the OpenAI model suite using an ambiguous integer sequence completion task. We find that average consistency ranges from 67\% to 82\%, far higher than would be predicted if a model's consistency was random, and increases as model capability improves. Furthermore, we show that models tend to maintain self-consistency across a series of robustness checks, including prompting speaker changes and sequence length changes. These results suggest that self-consistency arises as an emergent capability without specifically training for it. Despite this, we find that models are uncalibrated when judging their own consistency, with models displaying both over- and under-confidence. We also propose a nonparametric test for determining from token output distribution whether a model assigns non-trivial probability to alternative answers. Using this test, we find that despite increases in self-consistency, models usually place significant weight on alternative, inconsistent answers. This distribution of probability mass provides evidence that even highly self-consistent models internally compute multiple possible responses.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Random Matrix Analysis to Balance between Supervised and Unsupervised  Learning under the Low Density Separation Assumption</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13434</p>
  <p><b>作者</b>：Vasilii Feofanov,  Malik Tiomoko,  Aladin Virmaux</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low density separation, density separation assumption, analyze semi-supervised classification, low density, density separation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a theoretical framework to analyze semi-supervised classification under the low density separation assumption in a high-dimensional regime. In particular, we introduce QLDS, a linear classification model, where the low density separation assumption is implemented via quadratic margin maximization. The algorithm has an explicit solution with rich theoretical properties, and we show that particular cases of our algorithm are the least-square support vector machine in the supervised case, the spectral clustering in the fully unsupervised regime, and a class of semi-supervised graph-based approaches. As such, QLDS establishes a smooth bridge between these supervised and unsupervised learning methods. Using recent advances in the random matrix theory, we formally derive a theoretical evaluation of the classification error in the asymptotic regime. As an application, we derive a hyperparameter selection policy that finds the best balance between the supervised and the unsupervised terms of our learning criterion. Finally, we provide extensive illustrations of our framework, as well as an experimental study on several benchmarks to demonstrate that QLDS, while being computationally more efficient, improves over cross-validation for hyperparameter selection, indicating a high promise of the usage of random matrix theory for semi-supervised model selection.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：FLTracer: Accurate Poisoning Attack Provenance in Federated Learning</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13424</p>
  <p><b>作者</b>：Xinyu Zhang,  Qingyu Liu,  Zhongjie Ba,  Yuan Hong,  Tianhang Zheng,  Feng Lin,  Li Lu,  Kui Ren</p>
  <p><b>备注</b>：18 pages, 27 figures</p>
  <p><b>关键词</b>：enables multiple clients, promising distributed learning, distributed learning approach, Federated Learning, shared global model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a promising distributed learning approach that enables multiple clients to collaboratively train a shared global model. However, recent studies show that FL is vulnerable to various poisoning attacks, which can degrade the performance of global models or introduce backdoors into them. In this paper, we first conduct a comprehensive study on prior FL attacks and detection methods. The results show that all existing detection methods are only effective against limited and specific attacks. Most detection methods suffer from high false positives, which lead to significant performance degradation, especially in not independent and identically distributed (non-IID) settings. To address these issues, we propose FLTracer, the first FL attack provenance framework to accurately detect various attacks and trace the attack time, objective, type, and poisoned location of updates. Different from existing methodologies that rely solely on cross-client anomaly detection, we propose a Kalman filter-based cross-round detection to identify adversaries by seeking the behavior changes before and after the attack. Thus, this makes it resilient to data heterogeneity and is effective even in non-IID settings. To further improve the accuracy of our detection method, we employ four novel features and capture their anomalies with the joint decisions. Extensive evaluations show that FLTracer achieves an average true positive rate of over $96.88\%$ at an average false positive rate of less than $2.67\%$, significantly outperforming SOTA detection methods. \footnote{Code is available at \url{this https URL}.}</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：POSQA: Probe the World Models of LLMs with Size Comparisons</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13394</p>
  <p><b>作者</b>：Chang Shu,  Jiuzhou Han,  Fangyu Liu,  Ehsan Shareghi,  Nigel Collier</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 Findings</p>
  <p><b>关键词</b>：Large Language Models, language comprehension emphasizes, Embodied language comprehension, social environment, solely a matter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied language comprehension emphasizes that language understanding is not solely a matter of mental processing in the brain but also involves interactions with the physical and social environment. With the explosive growth of Large Language Models (LLMs) and their already ubiquitous presence in our daily lives, it is becoming increasingly necessary to verify their real-world understanding. Inspired by cognitive theories, we propose POSQA: a Physical Object Size Question Answering dataset with simple size comparison questions to examine the extremity and analyze the potential mechanisms of the embodied comprehension of the latest LLMs.
We show that even the largest LLMs today perform poorly under the zero-shot setting. We then push their limits with advanced prompting techniques and external knowledge augmentation. Furthermore, we investigate whether their real-world comprehension primarily derives from contextual information or internal weights and analyse the impact of prompt formats and report bias of different objects. Our results show that real-world understanding that LLMs shaped from textual data can be vulnerable to deception and confusion by the surface form of prompts, which makes it less aligned with human behaviours.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Learning Successor Representations with Distributed Hebbian Temporal  Memory</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13391</p>
  <p><b>作者</b>：Evgenii Dzhivelikian,  Petr Kuderov,  Aleksandr I. Panov</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：partially observable environments, Hebbian Temporal Memory, Distributed Hebbian Temporal, uncertainty in non-stationary, partially observable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare the SRs produced by DHTM to another biologically inspired HMM-like algorithm, CSCG. Our findings suggest that DHTM is a promising approach for addressing the challenges of online hidden representation learning in dynamic environments.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：A Human-Robot Mutual Learning System with Affect-Grounded Language  Acquisition and Differential Outcomes Training</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13377</p>
  <p><b>作者</b>：Alva Markelius,  Sofia Sjöberg,  Zakaria Lemhauori,  Laura Cohen,  Martin Bergström,  Robert Lowe,  Lola Cañamero</p>
  <p><b>备注</b>：Preprint: This is the submitted version of a paper to be presented at The Proceedings of the 15th International Conference on Social Robotics (ICSR 2023). Please cite the official publication once it is available</p>
  <p><b>关键词</b>：robot language acquisition, identifying robot homeostatic, robot, robot language, language acquisition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel human-robot interaction setup for robot and human learning of symbolic language for identifying robot homeostatic needs. The robot and human learn to use and respond to the same language symbols that convey homeostatic needs and the stimuli that satisfy the homeostatic needs, respectively. We adopted a differential outcomes training (DOT) protocol whereby the robot provides feedback specific (differential) to its internal needs (e.g. `hunger') when satisfied by the correct stimulus (e.g. cookie). We found evidence that DOT can enhance the human's learning efficiency, which in turn enables more efficient robot language acquisition. The robot used in the study has a vocabulary similar to that of a human infant in the linguistic ``babbling'' phase. The robot software architecture is built upon a model for affect-grounded language acquisition where the robot associates vocabulary with internal needs (hunger, thirst, curiosity) through interactions with the human. The paper presents the results of an initial pilot study conducted with the interactive setup, which reveal that the robot's language acquisition achieves higher convergence rate in the DOT condition compared to the non-DOT control condition. Additionally, participants reported positive affective experiences, feeling of being in control, and an empathetic connection with the robot. This mutual learning (teacher-student learning) approach offers a potential contribution of facilitating cognitive interventions with DOT (e.g. for people with dementia) through increased therapy adherence as a result of engaging humans more in training tasks by taking an active teaching-learning role. The homeostatic motivational grounding of the robot's language acquisition has potential to contribute to more ecologically valid and social (collaborative/nurturing) interactions with robots.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：VFedMH: Vertical Federated Learning for Training Multi-party  Heterogeneous Models</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13367</p>
  <p><b>作者</b>：Shuo Wang,  Keke Gai,  Jing Yu,  Liehuang Zhu</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：Vertical Federated Learning, gained increasing attention, Vertical Federated, Federated Learning, called Vertical Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vertical Federated Learning (VFL) has gained increasing attention as a novel training paradigm that integrates sample alignment and feature union. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this issue, this paper proposes a novel approach called Vertical Federated learning for training Multi-parties Heterogeneous models (VFedMH). VFedMH focuses on aggregating the embeddings of each participant's knowledge instead of intermediate results during forward propagation. The active party, who possesses labels and features of the sample, in VFedMH securely aggregates local embeddings to obtain global knowledge embeddings, and sends them to passive parties. The passive parties, who own only features of the sample, then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the labels, so the local model gradient cannot be calculated locally. To overcome this limitation, the active party assists the passive party in computing its local heterogeneous model gradients. Then, each participant trains their local model using the heterogeneous model gradients. The objective is to minimize the loss value of their respective local heterogeneous models. Additionally, the paper provides a theoretical analysis of VFedMH's convergence performance. Extensive experiments are conducted to demonstrate that VFedMH can simultaneously train multiple heterogeneous models with heterogeneous optimization and outperform some recent methods in model performance.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Towards General Error Diagnosis via Behavioral Testing in Machine  Translation</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13362</p>
  <p><b>作者</b>：Junjie Wu,  Lemao Liu,  Dit-Yan Yeung</p>
  <p><b>备注</b>：15 pages, 2 figures, accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：NLP models, capabilities of NLP, Behavioral testing, diagnosing linguistic errors, Behavioral testing offers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Behavioral testing offers a crucial means of diagnosing linguistic errors and assessing capabilities of NLP models. However, applying behavioral testing to machine translation (MT) systems is challenging as it generally requires human efforts to craft references for evaluating the translation quality of such systems on newly generated test cases. Existing works in behavioral testing of MT systems circumvent this by evaluating translation quality without references, but this restricts diagnosis to specific types of errors, such as incorrect translation of single numeric or currency words. In order to diagnose general errors, this paper proposes a new Bilingual Translation Pair Generation based Behavior Testing (BTPGBT) framework for conducting behavioral testing of MT systems. The core idea of BTPGBT is to employ a novel bilingual translation pair generation (BTPG) approach that automates the construction of high-quality test cases and their pseudoreferences. Experimental results on various MT systems demonstrate that BTPGBT could provide comprehensive and accurate behavioral testing results for general error diagnosis, which further leads to several insightful findings. Our code and data are available at https: //github.com/wujunjie1998/BTPGBT.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Bridging the Gap between Synthetic and Authentic Images for Multimodal  Machine Translation</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13361</p>
  <p><b>作者</b>：Wenyu Guo,  Qingkai Fang,  Dong Yu,  Yang Feng</p>
  <p><b>备注</b>：Accepted to EMNLP 2023 main conference</p>
  <p><b>关键词</b>：Multimodal machine translation, authentic images, machine translation, images, Multimodal machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal machine translation (MMT) simultaneously takes the source sentence and a relevant image as input for translation. Since there is no paired image available for the input sentence in most cases, recent studies suggest utilizing powerful text-to-image generation models to provide image inputs. Nevertheless, synthetic images generated by these models often follow different distributions compared to authentic images. Consequently, using authentic images for training and synthetic images for inference can introduce a distribution shift, resulting in performance degradation during inference. To tackle this challenge, in this paper, we feed synthetic and authentic images to the MMT model, respectively. Then we minimize the gap between the synthetic and authentic images by drawing close the input image representations of the Transformer Encoder and the output distributions of the Transformer Decoder. Therefore, we mitigate the distribution disparity introduced by the synthetic images during inference, thereby freeing the authentic images from the inference process.Experimental results show that our approach achieves state-of-the-art performance on the Multi30K En-De and En-Fr datasets, while remaining independent of authentic images during inference.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：NurViD: A Large Expert-Level Video Database for Nursing Procedure  Activity Understanding</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13347</p>
  <p><b>作者</b>：Ming Hu,  Lin Wang,  Siyuan Yan,  Don Ma,  Qingli Ren,  Peng Xia,  Wei Feng,  Peibo Duan,  Lie Ju,  Zongyuan Ge</p>
  <p><b>备注</b>：Accepted by NeurIPS 2023 Datasets and Benchmarks Track</p>
  <p><b>关键词</b>：nurse-patient interactions, nursing procedure activity, potential to greatly, greatly enhance, safety of nurse-patient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The application of deep learning to nursing procedure activity understanding has the potential to greatly enhance the quality and safety of nurse-patient interactions. By utilizing the technique, we can facilitate training and education, improve quality control, and enable operational compliance monitoring. However, the development of automatic recognition systems in this field is currently hindered by the scarcity of appropriately labeled datasets. The existing video datasets pose several limitations: 1) these datasets are small-scale in size to support comprehensive investigations of nursing activity; 2) they primarily focus on single procedures, lacking expert-level annotations for various nursing procedures and action steps; and 3) they lack temporally localized annotations, which prevents the effective localization of targeted actions within longer video sequences. To mitigate these limitations, we propose NurViD, a large video dataset with expert-level annotation for nursing procedure activity understanding. NurViD consists of over 1.5k videos totaling 144 hours, making it approximately four times longer than the existing largest nursing activity datasets. Notably, it encompasses 51 distinct nursing procedures and 177 action steps, providing a much more comprehensive coverage compared to existing datasets that primarily focus on limited procedures. To evaluate the efficacy of current deep learning methods on nursing activity understanding, we establish three benchmarks on NurViD: procedure recognition on untrimmed videos, procedure and action recognition on trimmed videos, and action detection. Our benchmark and code will be available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Challenges and Contributing Factors in the Utilization of Large Language  Models (LLMs)</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13343</p>
  <p><b>作者</b>：Xiaoliang Chen,  Liangbin Li,  Le Chang,  Yunhe Huang,  Yuxuan Zhao,  Yuxiao Zhang,  Dinuo Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：application scenarios presents, GPT series, large language models, development of large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of large language models (LLMs) like the GPT series, their widespread use across various application scenarios presents a myriad of challenges. This review initially explores the issue of domain specificity, where LLMs may struggle to provide precise answers to specialized questions within niche fields. The problem of knowledge forgetting arises as these LLMs might find it hard to balance old and new information. The knowledge repetition phenomenon reveals that sometimes LLMs might deliver overly mechanized responses, lacking depth and originality. Furthermore, knowledge illusion describes situations where LLMs might provide answers that seem insightful but are actually superficial, while knowledge toxicity focuses on harmful or biased information outputs. These challenges underscore problems in the training data and algorithmic design of LLMs. To address these issues, it's suggested to diversify training data, fine-tune models, enhance transparency and interpretability, and incorporate ethics and fairness training. Future technological trends might lean towards iterative methodologies, multimodal learning, model personalization and customization, and real-time learning and feedback mechanisms. In conclusion, future LLMs should prioritize fairness, transparency, and ethics, ensuring they uphold high moral and ethical standards when serving humanity.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From  Multi-Source Optical Imagery</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13336</p>
  <p><b>作者</b>：Anatol Garioud,  Nicolas Gonthier,  Loic Landrieu,  Apolline De Wit,  Marion Valette,  Marc Poupée,  Sébastien Giordano,  Boris Wattrelos</p>
  <p><b>备注</b>：NeurIPS 2023 - Datasets & Benchmarks Track</p>
  <p><b>关键词</b>：French National Institute, French Land cover, French Land, French National, Forest Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the French Land cover from Aerospace ImageRy (FLAIR), an extensive dataset from the French National Institute of Geographical and Forest Information (IGN) that provides a unique and rich resource for large-scale geospatial analysis. FLAIR contains high-resolution aerial imagery with a ground sample distance of 20 cm and over 20 billion individually labeled pixels for precise land-cover classification. The dataset also integrates temporal and spectral data from optical satellite time series. FLAIR thus combines data with varying spatial, spectral, and temporal resolutions across over 817 km2 of acquisitions representing the full landscape diversity of France. This diversity makes FLAIR a valuable resource for the development and evaluation of novel methods for large-scale land-cover semantic segmentation and raises significant challenges in terms of computer vision, data fusion, and geospatial analysis. We also provide powerful uni- and multi-sensor baseline models that can be employed to assess algorithm's performance and for downstream applications. Through its extent and the quality of its annotation, FLAIR aims to spur improvements in monitoring and understanding key anthropogenic development indicators such as urban growth, deforestation, and soil artificialization. Dataset and codes can be accessed at this https URL</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Democratizing Reasoning Ability: Tailored Learning from Large Language  Model</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13332</p>
  <p><b>作者</b>：Zhaoyang Wang,  Shaohan Huang,  Yuxuan Liu,  Jiahai Wang,  Minghui Song,  Zihan Zhang,  Haizhen Huang,  Furu Wei,  Weiwei Deng,  Feng Sun,  Qi Zhang</p>
  <p><b>备注</b>：To appear at EMNLP 2023</p>
  <p><b>关键词</b>：Large language models, natural language processing, exhibit impressive emergent, impressive emergent abilities, huge computation requirements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) exhibit impressive emergent abilities in natural language processing, but their democratization is hindered due to huge computation requirements and closed-source nature. Recent research on advancing open-source smaller LMs by distilling knowledge from black-box LLMs has obtained promising results in the instruction-following ability. However, the reasoning ability which is more challenging to foster, is relatively rarely explored. In this paper, we propose a tailored learning approach to distill such reasoning ability to smaller LMs to facilitate the democratization of the exclusive reasoning ability. In contrast to merely employing LLM as a data annotator, we exploit the potential of LLM as a reasoning teacher by building an interactive multi-round learning paradigm. This paradigm enables the student to expose its deficiencies to the black-box teacher who then can provide customized training data in return. Further, to exploit the reasoning potential of the smaller LM, we propose self-reflection learning to motivate the student to learn from self-made mistakes. The learning from self-reflection and LLM are all tailored to the student's learning status, thanks to the seamless integration with the multi-round learning paradigm. Comprehensive experiments and analysis on mathematical and commonsense reasoning tasks demonstrate the effectiveness of our method. The code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Coarse-to-Fine Dual Encoders are Better Frame Identification Learners</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13316</p>
  <p><b>作者</b>：Kaikai An,  Ce Zheng,  Bofei Gao,  Haozhe Zhao,  Baobao Chang</p>
  <p><b>备注</b>：Accepted to Findings of EMNLP2023</p>
  <p><b>关键词</b>：Frame identification aims, find semantic frames, underline, identification aims, aims to find</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Frame identification aims to find semantic frames associated with target words in a sentence. Recent researches measure the similarity or matching score between targets and candidate frames by modeling frame definitions. However, they either lack sufficient representation learning of the definitions or face challenges in efficiently selecting the most suitable frame from over 1000 candidate frames. Moreover, commonly used lexicon filtering ($lf$) to obtain candidate frames for the target may ignore out-of-vocabulary targets and cause inadequate frame modeling. In this paper, we propose CoFFTEA, a $\underline{Co}$arse-to-$\underline{F}$ine $\underline{F}$rame and $\underline{T}$arget $\underline{E}$ncoders $\underline{A}$rchitecture. With contrastive learning and dual encoders, CoFFTEA efficiently and effectively models the alignment between frames and targets. By employing a coarse-to-fine curriculum learning procedure, CoFFTEA gradually learns to differentiate frames with varying degrees of similarity. Experimental results demonstrate that CoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without $lf$. Further analysis suggests that CoFFTEA can better model the relationships between frame and frame, as well as target and target. The code for our approach is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Decoding the Silent Majority: Inducing Belief Augmented Social Graph  with Large Language Model for Response Forecasting</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13297</p>
  <p><b>作者</b>：Chenkai Sun,  Jinning Li,  Yi R. Fung,  Hou Pong Chan,  Tarek Abdelzaher,  ChengXiang Zhai,  Heng Ji</p>
  <p><b>备注</b>：Accepted at EMNLP 2023 Main Conference</p>
  <p><b>关键词</b>：enabling content producers, prevent unexpected negative, unexpected negative outcomes, moral injury, media plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic response forecasting for news media plays a crucial role in enabling content producers to efficiently predict the impact of news releases and prevent unexpected negative outcomes such as social conflict and moral injury. To effectively forecast responses, it is essential to develop measures that leverage the social dynamics and contextual information surrounding individuals, especially in cases where explicit profiles or historical actions of the users are limited (referred to as lurkers). As shown in a previous study, 97% of all tweets are produced by only the most active 25% of users. However, existing approaches have limited exploration of how to best process and utilize these important features. To address this gap, we propose a novel framework, named SocialSense, that leverages a large language model to induce a belief-centered graph on top of an existent social network, along with graph-based propagation to capture social dynamics. We hypothesize that the induced graph that bridges the gap between distant users who share similar beliefs allows the model to effectively capture the response patterns. Our method surpasses existing state-of-the-art in experimental evaluations for both zero-shot and supervised settings, demonstrating its effectiveness in response forecasting. Moreover, the analysis reveals the framework's capability to effectively handle unseen user and lurker scenarios, further highlighting its robustness and practical applicability.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：PathRL: An End-to-End Path Generation Method for Collision Avoidance via  Deep Reinforcement Learning</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13295</p>
  <p><b>作者</b>：Wenhao Yu,  Jie Peng,  Quecheng Qiu,  Hanyu Wang,  Lu Zhang,  Jianmin Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep reinforcement learning, shown great potential, DRL navigation methods, DRL policy, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robot navigation using deep reinforcement learning (DRL) has shown great potential in improving the performance of mobile robots. Nevertheless, most existing DRL-based navigation methods primarily focus on training a policy that directly commands the robot with low-level controls, like linear and angular velocities, which leads to unstable speeds and unsmooth trajectories of the robot during the long-term execution. An alternative method is to train a DRL policy that outputs the navigation path directly. However, two roadblocks arise for training a DRL policy that outputs paths: (1) The action space for potential paths often involves higher dimensions comparing to low-level commands, which increases the difficulties of training; (2) It takes multiple time steps to track a path instead of a single time step, which requires the path to predicate the interactions of the robot w.r.t. the dynamic environment in multiple time steps. This, in turn, amplifies the challenges associated with training. In response to these challenges, we propose PathRL, a novel DRL method that trains the policy to generate the navigation path for the robot. Specifically, we employ specific action space discretization techniques and tailored state space representation methods to address the associated challenges. In our experiments, PathRL achieves better success rates and reduces angular rotation variability compared to other DRL navigation methods, facilitating stable and smooth robot movement. We demonstrate the competitive edge of PathRL in both real-world scenarios and multiple challenging simulation environments.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Assessing Privacy Risks in Language Models: A Case Study on  Summarization Tasks</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13291</p>
  <p><b>作者</b>：Ruixiang Tang,  Gord Lueck,  Rodolfo Quispe,  Huseyin A Inan,  Janardhan Kulkarni,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP by achieving, field of NLP, Large language models, Large language, revolutionized the field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models have revolutionized the field of NLP by achieving state-of-the-art performance on various tasks. However, there is a concern that these models may disclose information in the training data. In this study, we focus on the summarization task and investigate the membership inference (MI) attack: given a sample and black-box access to a model's API, it is possible to determine if the sample was part of the training data. We exploit text similarity and the model's resistance to document modifications as potential MI signals and evaluate their effectiveness on widely used datasets. Our results demonstrate that summarization models are at risk of exposing data membership, even in cases where the reference summary is not available. Furthermore, we discuss several safeguards for training summarization models to protect against MI attacks and discuss the inherent trade-off between privacy and utility.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Unified Pretraining for Recommendation via Task Hypergraphs</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13286</p>
  <p><b>作者</b>：Mingdai Yang,  Zhiwei Liu,  Liangwei Yang,  Xiaolong Liu,  Chen Wang,  Hao Peng,  Philip S. Yu</p>
  <p><b>备注</b>：Accepted by WSDM 2024</p>
  <p><b>关键词</b>：graph-based recommender systems, garnered significant attention, recent years, garnered significant, popularity in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although pretraining has garnered significant attention and popularity in recent years, its application in graph-based recommender systems is relatively limited. It is challenging to exploit prior knowledge by pretraining in widely used ID-dependent datasets. On one hand, user-item interaction history in one dataset can hardly be transferred to other datasets through pretraining, where IDs are different. On the other hand, pretraining and finetuning on the same dataset leads to a high risk of overfitting. In this paper, we propose a novel multitask pretraining framework named Unified Pretraining for Recommendation via Task Hypergraphs. For a unified learning pattern to handle diverse requirements and nuances of various pretext tasks, we design task hypergraphs to generalize pretext tasks to hyperedge prediction. A novel transitional attention layer is devised to discriminatively learn the relevance between each pretext task and recommendation. Experimental results on three benchmark datasets verify the superiority of UPRTH. Additional detailed investigations are conducted to demonstrate the effectiveness of the proposed framework.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：An Exploratory Study on Simulated Annealing for Feature Selection in  Learning-to-Rank</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13269</p>
  <p><b>作者</b>：Mohd. Sayemul Haque,  Md. Fahim,  Muhammad Ibrahim</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：supervised machine learning, supervised machine, applied domain, machine learning, domain of supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning-to-rank is an applied domain of supervised machine learning. As feature selection has been found to be effective for improving the accuracy of learning models in general, it is intriguing to investigate this process for learning-to-rank domain. In this study, we investigate the use of a popular meta-heuristic approach called simulated annealing for this task. Under the general framework of simulated annealing, we explore various neighborhood selection strategies and temperature cooling schemes. We further introduce a new hyper-parameter called the progress parameter that can effectively be used to traverse the search space. Our algorithms are evaluated on five publicly benchmark datasets of learning-to-rank. For a better validation, we also compare the simulated annealing-based feature selection algorithm with another effective meta-heuristic algorithm, namely local beam search. Extensive experimental results shows the efficacy of our proposed models.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13258</p>
  <p><b>作者</b>：Kushal Kedia,  Prithwish Dan,  Atiksh Bhardwaj,  Sanjiban Choudhury</p>
  <p><b>备注</b>：CoRL 2023</p>
  <p><b>关键词</b>：close proximity relies, Seamless human-robot manipulation, Seamless human-robot, close proximity, proximity relies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Seamless human-robot manipulation in close proximity relies on accurate forecasts of human motion. While there has been significant progress in learning forecast models at scale, when applied to manipulation tasks, these models accrue high errors at critical transition points leading to degradation in downstream planning performance. Our key insight is that instead of predicting the most likely human motion, it is sufficient to produce forecasts that capture how future human motion would affect the cost of a robot's plan. We present ManiCast, a novel framework that learns cost-aware human forecasts and feeds them to a model predictive control planner to execute collaborative manipulation tasks. Our framework enables fluid, real-time interactions between a human and a 7-DoF robot arm across a number of real-world tasks such as reactive stirring, object handovers, and collaborative table setting. We evaluate both the motion forecasts and the end-to-end forecaster-planner system against a range of learned and heuristic baselines while additionally contributing new datasets. We release our code and datasets at this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Visual Grounding Helps Learn Word Meanings in Low-Data Regimes</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13257</p>
  <p><b>作者</b>：Chengxu Zhuang,  Evelina Fedorenko,  Jacob Andreas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human sentence production, production and comprehension, powerful tools, sentence production, remarkably well-aligned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern neural language models (LMs) are powerful tools for modeling human sentence production and comprehension, and their internal representations are remarkably well-aligned with representations of language in the human brain. But to achieve these results, LMs must be trained in distinctly un-human-like ways -- requiring orders of magnitude more language data than children receive during development, and without any of the accompanying grounding in perception, action, or social behavior. Do models trained more naturalistically -- with grounded supervision -- exhibit more human-like language learning? We investigate this question in the context of word learning, a key sub-task in language acquisition. We train a diverse set of LM architectures, with and without auxiliary supervision from image captioning tasks, on datasets of varying scales. We then evaluate these models on a broad set of benchmarks characterizing models' learning of syntactic categories, lexical relations, semantic features, semantic similarity, and alignment with human neural representations. We find that visual supervision can indeed improve the efficiency of word learning. However, these improvements are limited: they are present almost exclusively in the low-data regime, and sometimes canceled out by the inclusion of rich distributional signals from text. The information conveyed by text and images is not redundant -- we find that models mainly driven by visual information yield qualitatively different from those mainly driven by word co-occurrences. However, our results suggest that current multi-modal modeling approaches fail to effectively leverage visual information to build more human-like word representations from human-sized datasets.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：TempGNN: Temporal Graph Neural Networks for Dynamic Session-Based  Recommendations</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13249</p>
  <p><b>作者</b>：Eunkyu Oh,  Taehun Kim</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：gained increasing popularity, graph neural networks, recently gained increasing, short ongoing session, user interaction behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Session-based recommendations which predict the next action by understanding a user's interaction behavior with items within a relatively short ongoing session have recently gained increasing popularity. Previous research has focused on capturing the dynamics of sequential dependencies from complicated item transitions in a session by means of recurrent neural networks, self-attention models, and recently, mostly graph neural networks. Despite the plethora of different models relying on the order of items in a session, few approaches have been proposed for dealing better with the temporal implications between interactions. We present Temporal Graph Neural Networks (TempGNN), a generic framework for capturing the structural and temporal dynamics in complex item transitions utilizing temporal embedding operators on nodes and edges on dynamic session graphs, represented as sequences of timed events. Extensive experimental results show the effectiveness and adaptability of the proposed method by plugging it into existing state-of-the-art models. Finally, TempGNN achieved state-of-the-art performance on two real-world e-commerce datasets.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：FLEE-GNN: A Federated Learning System for Edge-Enhanced Graph Neural  Network in Analyzing Geospatial Resilience of Multicommodity Food Flows</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13248</p>
  <p><b>作者</b>：Yuxiao Qu,  Jinmeng Rao,  Song Gao,  Qianheng Zhang,  Wei-Lun Chao,  Yu Su,  Michelle Miller,  Alfonso Morales,  Patrick Huber</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：increasing food insecurity, tackle increasing food, Understanding and measuring, imperative to tackle, tackle increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding and measuring the resilience of food supply networks is a global imperative to tackle increasing food insecurity. However, the complexity of these networks, with their multidimensional interactions and decisions, presents significant challenges. This paper proposes FLEE-GNN, a novel Federated Learning System for Edge-Enhanced Graph Neural Network, designed to overcome these challenges and enhance the analysis of geospatial resilience of multicommodity food flow network, which is one type of spatial networks. FLEE-GNN addresses the limitations of current methodologies, such as entropy-based methods, in terms of generalizability, scalability, and data privacy. It combines the robustness and adaptability of graph neural networks with the privacy-conscious and decentralized aspects of federated learning on food supply network resilience analysis across geographical regions. This paper also discusses FLEE-GNN's innovative data generation techniques, experimental designs, and future directions for improvement. The results show the advancements of this approach to quantifying the resilience of multicommodity food flow networks, contributing to efforts towards ensuring global food security using AI methods. The developed FLEE-GNN has the potential to be applied in other spatial networks with spatially heterogeneous sub-network distributions.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Multi-level Contrastive Learning for Script-based Character  Understanding</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13231</p>
  <p><b>作者</b>：Dawei Li,  Hengyuan Zhang,  Yanran Li,  Shiping Yang</p>
  <p><b>备注</b>：Accepted by EMNLP 2023 main conference; Camera-ready version will be updated soon</p>
  <p><b>关键词</b>：aims to learn, personalities and identities, characters' personalities, capture characters' global, characters' global information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we tackle the scenario of understanding characters in scripts, which aims to learn the characters' personalities and identities from their utterances. We begin by analyzing several challenges in this scenario, and then propose a multi-level contrastive learning framework to capture characters' global information in a fine-grained manner. To validate the proposed framework, we conduct extensive experiments on three character understanding sub-tasks by comparing with strong pre-trained language models, including SpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate that our method improves the performances by a considerable margin. Through further in-depth analysis, we show the effectiveness of our method in addressing the challenges and provide more hints on the scenario of character understanding. We will open-source our work on github at this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Absolute Policy Optimization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13230</p>
  <p><b>作者</b>：Weiye Zhao,  Feihan Li,  Yifan Sun,  Rui Chen,  Tianhao Wei,  Changliu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trust region on-policy, region on-policy reinforcement, on-policy reinforcement learning, achieved impressive results, addressing complex control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, trust region on-policy reinforcement learning has achieved impressive results in addressing complex control tasks and gaming scenarios. However, contemporary state-of-the-art algorithms within this category primarily emphasize improvement in expected performance, lacking the ability to control over the worst-case performance outcomes. To address this limitation, we introduce a novel objective function; by optimizing which, it will lead to guaranteed monotonic improvement in the lower bound of near-total performance samples (absolute performance). Considering this groundbreaking theoretical advancement, we then refine this theoretically grounded algorithm through a series of approximations, resulting in a practical solution called Absolute Policy Optimization (APO). Our experiments demonstrate the effectiveness of our approach across challenging continuous control benchmark tasks and extend its applicability to mastering Atari games. Our findings reveal that APO significantly outperforms state-of-the-art policy gradient algorithms, resulting in substantial improvements in both expected performance and worst-case performance.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：ToolChain*: Efficient Action Space Navigation in Large Language Models  with A* Search</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13227</p>
  <p><b>作者</b>：Yuchen Zhuang,  Xiang Chen,  Tong Yu,  Saayan Mitra,  Victor Bursztyn,  Ryan A. Rossi,  Somdeb Sarkhel,  Chao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, complicated real-world problems, demonstrated powerful decision-making, solving complicated real-world, API function calls</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have demonstrated powerful decision-making and planning capabilities in solving complicated real-world problems. LLM-based autonomous agents can interact with diverse tools (e.g., functional APIs) and generate solution plans that execute a series of API function calls in a step-by-step manner. The multitude of candidate API function calls significantly expands the action space, amplifying the critical need for efficient action space navigation. However, existing methods either struggle with unidirectional exploration in expansive action spaces, trapped into a locally optimal solution, or suffer from exhaustively traversing all potential actions, causing inefficient navigation. To address these issues, we propose ToolChain*, an efficient tree search-based planning algorithm for LLM-based agents. It formulates the entire action space as a decision tree, where each node represents a possible API function call involved in a solution plan. By incorporating the A* search algorithm with task-specific cost function design, it efficiently prunes high-cost branches that may involve incorrect actions, identifying the most low-cost valid path as the solution. Extensive experiments on multiple tool-use and reasoning tasks demonstrate that ToolChain* efficiently balances exploration and exploitation within an expansive action space. It outperforms state-of-the-art baselines on planning and reasoning tasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time, respectively.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Scalable Neural Network Kernels</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13225</p>
  <p><b>作者</b>：Arijit Sehanobish,  Krzysztof Choromanski,  Yunfan Zhao,  Avinava Dubey,  Valerii Likhosherstov</p>
  <p><b>备注</b>：Preprint. 23 pages, 10 figures. Comments welcome</p>
  <p><b>关键词</b>：favorable computational properties, neural network, regular feedforward layers, neural network kernels, scalable neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the concept of scalable neural network kernels (SNNKs), the replacements of regular feedforward layers (FFLs), capable of approximating the latter, but with favorable computational properties. SNNKs effectively disentangle the inputs from the parameters of the neural network in the FFL, only to connect them in the final computation via the dot-product kernel. They are also strictly more expressive, as allowing to model complicated relationships beyond the functions of the dot-products of parameter-input vectors. We also introduce the neural network bundling process that applies SNNKs to compactify deep neural network architectures, resulting in additional compression gains. In its extreme version, it leads to the fully bundled network whose optimal parameters can be expressed via explicit formulae for several loss functions (e.g. mean squared error), opening a possibility to bypass backpropagation. As a by-product of our analysis, we introduce the mechanism of the universal random features (or URFs), applied to instantiate several SNNK variants, and interesting on its own in the context of scalable kernel methods. We provide rigorous theoretical analysis of all these concepts as well as an extensive empirical evaluation, ranging from point-wise kernel estimation to Transformers' fine-tuning with novel adapter layers inspired by SNNKs. Our mechanism provides up to 5x reduction in the number of trainable parameters, while maintaining competitive accuracy.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：HierCas: Hierarchical Temporal Graph Attention Networks for Popularity  Prediction in Information Cascades</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13219</p>
  <p><b>作者</b>：Zhizhen Zhang,  Xiaohui Xie,  Yishuo Zhang,  Lanshan Zhang,  Yong Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurate recommendations, limited to identifying, identifying fake, cascade popularity prediction, Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information cascade popularity prediction is critical for many applications, including but not limited to identifying fake news and accurate recommendations. Traditional feature-based methods heavily rely on handcrafted features, which are domain-specific and lack generalizability to new domains. To address this problem, researchers have turned to neural network-based approaches. However, existing methods follow a sampling-based modeling approach, potentially losing continuous dynamic information and structural-temporal dependencies that emerge during the information diffusion process. In this paper, we propose a novel framework called Hierarchical Temporal Graph Attention Networks for cascade popularity prediction (HierCas). Unlike existing methods, HierCas operates on the entire cascade graph by a dynamic graph modeling approach, enabling it to capture the full range of continuous dynamic information and explicitly model the interplay between structural and temporal factors. By leveraging time-aware node embedding, graph attention mechanisms and hierarchical pooling structures, HierCas effectively captures the popularity trend implicit in the complex cascade. Extensive experiments conducted on two real-world datasets in different scenarios demonstrate that our HierCas significantly outperforms the state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy  Named Entity Recognition</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13213</p>
  <p><b>作者</b>：Besnik Fetahu,  Zhiyu Chen,  Sudipta Kar,  Oleg Rokhlenko,  Shervin Malmasi</p>
  <p><b>备注</b>：Accepted to the Findings of EMNLP 2023</p>
  <p><b>关键词</b>：Named Entity Recognition, Entity Recognition covering, Recognition covering, fine-grained Named Entity, fine-grained Named</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to context noise.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Primacy Effect of ChatGPT</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13206</p>
  <p><b>作者</b>：Yiwei Wang,  Yujun Cai,  Muhao Chen,  Yuxuan Liang,  Bryan Hooi</p>
  <p><b>备注</b>：EMNLP 2023 short paper</p>
  <p><b>关键词</b>：natural language understanding, discriminative natural language, promising zero-shot performance, Instruction-tuned large language, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction-tuned large language models (LLMs), such as ChatGPT, have led to promising zero-shot performance in discriminative natural language understanding (NLU) tasks. This involves querying the LLM using a prompt containing the question, and the candidate labels to choose from. The question-answering capabilities of ChatGPT arise from its pre-training on large amounts of human-written text, as well as its subsequent fine-tuning on human preferences, which motivates us to ask: Does ChatGPT also inherits humans' cognitive biases? In this paper, we study the primacy effect of ChatGPT: the tendency of selecting the labels at earlier positions as the answer. We have two main findings: i) ChatGPT's decision is sensitive to the order of labels in the prompt; ii) ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer. We hope that our experiments and analyses provide additional insights into building more reliable ChatGPT-based solutions. We release the source code at this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：The opaque law of artificial intelligence</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13192</p>
  <p><b>作者</b>：Vincenzo Calderonio</p>
  <p><b>备注</b>：17 pages, 7 figures</p>
  <p><b>关键词</b>：existing NLP model, Turing Test, proposed conversational methodology, artificial intelligence causation, NLP model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The purpose of this paper is to analyse the opacity of algorithms, contextualized in the open debate on responsibility for artificial intelligence causation; with an experimental approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative AI (Chat-GPT) to see how far it can go right now and how the shape of a legal regulation of it could be. The analysis of the problem will be supported by a comment of Italian classical law categories such as causality, intent and fault to understand the problem of the usage of AI, focusing in particular on the human-machine interaction. On the computer science side, for a technical point of view of the logic used to craft these algorithms, in the second chapter will be proposed a practical interrogation of Chat-GPT aimed at finding some critical points of the functioning of AI. The end of the paper will concentrate on some existing legal solutions which can be applied to the problem, plus a brief description of the approach proposed by EU Artificial Intelligence act.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13191</p>
  <p><b>作者</b>：Jianwei Li,  Qi Lei,  Wei Cheng,  Dongkuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language models, objective has recently, recently extended, language, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The pruning objective has recently extended beyond accuracy and sparsity to robustness in language models. Despite this, existing methods struggle to enhance robustness against adversarial attacks when continually increasing model sparsity and require a retraining process. As humans step into the era of large language models, these issues become increasingly prominent. This paper proposes that the robustness of language models is proportional to the extent of pre-trained knowledge they encompass. Accordingly, we introduce a post-training pruning strategy designed to faithfully replicate the embedding space and feature space of dense language models, aiming to conserve more pre-trained knowledge during the pruning process. In this setup, each layer's reconstruction error not only originates from itself but also includes cumulative error from preceding layers, followed by an adaptive rectification. Compared to other state-of-art baselines, our approach demonstrates a superior balance between accuracy, sparsity, robustness, and pruning cost with BERT on datasets SST2, IMDB, and AGNews, marking a significant stride towards robust pruning in language models.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Fast and Accurate Factual Inconsistency Detection Over Long Documents</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13189</p>
  <p><b>作者</b>：Barrett Martin Lattimer,  Patrick Chen,  Xinyuan Zhang,  Yi Yang</p>
  <p><b>备注</b>：To be published in EMNLP 2023 Main Conference, 8 pages</p>
  <p><b>关键词</b>：exhibit remarkable potential, current approaches struggle, models exhibit remarkable, Natural Language Inference, remarkable potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative AI models exhibit remarkable potential; however, hallucinations across various tasks present a significant challenge, particularly for longer inputs that current approaches struggle to address effectively. We introduce SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a task-agnostic model for detecting factual inconsistencies using a novel chunking strategy. Specifically, SCALE is a Natural Language Inference (NLI) based model that uses large text chunks to condition over long texts. This approach achieves state-of-the-art performance in factual inconsistency detection for diverse tasks and long inputs. Additionally, we leverage the chunking mechanism and employ a novel algorithm to explain SCALE's decisions through relevant source sentence retrieval. Our evaluations reveal that SCALE outperforms existing methods on both standard benchmarks and a new long-form dialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses competitive systems in efficiency and model explanation evaluations.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for  Image Manipulation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13165</p>
  <p><b>作者</b>：Sihan Xu,  Ziqiao Ma,  Yidong Huang,  Honglak Lee,  Joyce Chai</p>
  <p><b>备注</b>：NeurIPS 2023</p>
  <p><b>关键词</b>：Diffusion models, interface for consistent, enabled breakthroughs, lack an intuitive, intuitive interface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual prompt. Cyclenet is a practical framework, which is robust even with very limited training data (around 2k) and requires minimal computational resources (1 GPU) to train. Project homepage: this https URL</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：A Distributed Approach to Meteorological Predictions: Addressing Data  Imbalance in Precipitation Prediction Models through Federated Learning and  GANs</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13161</p>
  <p><b>作者</b>：Elaheh Jafarigol,  Theodore Trafalis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facilitating nuanced analyses, categorizing meteorological phenomena, involves categorizing meteorological, disaster management, facilitating nuanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The classification of weather data involves categorizing meteorological phenomena into classes, thereby facilitating nuanced analyses and precise predictions for various sectors such as agriculture, aviation, and disaster management. This involves utilizing machine learning models to analyze large, multidimensional weather datasets for patterns and trends. These datasets may include variables such as temperature, humidity, wind speed, and pressure, contributing to meteorological conditions. Furthermore, it's imperative that classification algorithms proficiently navigate challenges such as data imbalances, where certain weather events (e.g., storms or extreme temperatures) might be underrepresented. This empirical study explores data augmentation methods to address imbalanced classes in tabular weather data in centralized and federated settings. Employing data augmentation techniques such as the Synthetic Minority Over-sampling Technique or Generative Adversarial Networks can improve the model's accuracy in classifying rare but critical weather events. Moreover, with advancements in federated learning, machine learning models can be trained across decentralized databases, ensuring privacy and data integrity while mitigating the need for centralized data storage and processing. Thus, the classification of weather data stands as a critical bridge, linking raw meteorological data to actionable insights, enhancing our capacity to anticipate and prepare for diverse weather conditions.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Conditional Generative Modeling for Images, 3D Animations, and Video</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13157</p>
  <p><b>作者</b>：Vikram Voleti</p>
  <p><b>备注</b>：Doctoral thesis, Mila, University of Montreal. 189 pages</p>
  <p><b>关键词</b>：dissertation attempts, attempts to drive, drive innovation, exploring novel formulations, innovative applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation attempts to drive innovation in the field of generative modeling for computer vision, by exploring novel formulations of conditional generative models, and innovative applications in images, 3D animations, and video. Our research focuses on architectures that offer reversible transformations of noise and visual data, and the application of encoder-decoder architectures for generative tasks and 3D content manipulation. In all instances, we incorporate conditional information to enhance the synthesis of visual data, improving the efficiency of the generation process as well as the generated content.
We introduce the use of Neural ODEs to model video dynamics using an encoder-decoder architecture, demonstrating their ability to predict future video frames despite being trained solely to reconstruct current frames. Next, we propose a conditional variant of continuous normalizing flows that enables higher-resolution image generation based on lower-resolution input, achieving comparable image quality while reducing parameters and training time. Our next contribution presents a pipeline that takes human images as input, automatically aligns a user-specified 3D character with the pose of the human, and facilitates pose editing based on partial inputs. Next, we derive the relevant mathematical details for denoising diffusion models that use non-isotropic Gaussian processes, and show comparable generation quality. Finally, we devise a novel denoising diffusion framework capable of solving all three video tasks of prediction, generation, and interpolation. We perform ablation studies, and show SOTA results on multiple datasets.
Our contributions are published articles at peer-reviewed venues. Overall, our research aims to make a meaningful contribution to the pursuit of more efficient and flexible generative models, with the potential to shape the future of computer vision.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：CLIFT: Analysing Natural Distribution Shift on Question Answering Models  in Clinical Domain</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13146</p>
  <p><b>作者</b>：Ankit Pal</p>
  <p><b>备注</b>：Accepted at NeurIPS 2022 (Robustness in Sequence Modeling)</p>
  <p><b>关键词</b>：domain Question-answering task, clinical domain Question-answering, Question-answering task, testbed CLIFT, domain Question-answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical domain Question-answering task. The testbed includes 7.5k high-quality question answering samples to provide a diverse and reliable benchmark. We performed a comprehensive experimental study and evaluated several QA deep-learning models under the proposed testbed. Despite impressive results on the original test set, the performance degrades when applied to new test sets, which shows the distribution shift. Our findings emphasize the need for and the potential for increasing the robustness of clinical domain models under distributional shifts. The testbed offers one way to track progress in that direction. It also highlights the necessity of adopting evaluation metrics that consider robustness to natural distribution shifts. We plan to expand the corpus by adding more samples and model results. The full paper and the updated benchmark are available at this http URL</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Ask Me in English Instead: Cross-Lingual Evaluation of Large Language  Models for Healthcare Queries</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13132</p>
  <p><b>作者</b>：Jin,  Yiqiao,  Chandra,  Mohit,  Verma,  Gaurav, Hu,  Yibo,  De Choudhury,  Munmun,  Kumar,  Srijan</p>
  <p><b>备注</b>：18 pages, 7 figures</p>
  <p><b>关键词</b>：general public accesses, general public, public accesses, accesses and consumes, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating LLMs as conversational agents for everyday queries. While LLMs demonstrate impressive language understanding and generation proficiencies, concerns regarding their safety remain paramount in these high-stake domains. Moreover, the development of LLMs is disproportionately focused on English. It remains unclear how these LLMs perform in the context of non-English languages, a gap that is critical for ensuring equity in the real-world use of these systems.This paper provides a framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries. Our empirically-derived framework XlingEval focuses on three fundamental criteria for evaluating LLM responses to naturalistic human-authored health-related questions: correctness, consistency, and verifiability. Through extensive experiments on four major global languages, including English, Spanish, Chinese, and Hindi, spanning three expert-annotated large health Q&A datasets, and through an amalgamation of algorithmic and human-evaluation strategies, we found a pronounced disparity in LLM responses across these languages, indicating a need for enhanced cross-lingual capabilities. We further propose XlingHealth, a cross-lingual benchmark for examining the multilingual capabilities of LLMs in the healthcare context. Our findings underscore the pressing need to bolster the cross-lingual capacities of these models, and to provide an equitable information ecosystem accessible to all.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Deep Reinforcement Learning-based Intelligent Traffic Signal Controls  with Optimized CO2 emissions</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13129</p>
  <p><b>作者</b>：Pedram Agand,  Alexey Iskrov,  Mo Chen</p>
  <p><b>备注</b>：6 pages, 6 figures, 1 table. International Conference on Intelligent Robots and Systems. IEEE/RSJ, 2023</p>
  <p><b>关键词</b>：sub-optimal control policies, transportation networks face, human health, networks face, face the challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, transportation networks face the challenge of sub-optimal control policies that can have adverse effects on human health, the environment, and contribute to traffic congestion. Increased levels of air pollution and extended commute times caused by traffic bottlenecks make intersection traffic signal controllers a crucial component of modern transportation infrastructure. Despite several adaptive traffic signal controllers in literature, limited research has been conducted on their comparative performance. Furthermore, despite carbon dioxide (CO2) emissions' significance as a global issue, the literature has paid limited attention to this area. In this report, we propose EcoLight, a reward shaping scheme for reinforcement learning algorithms that not only reduces CO2 emissions but also achieves competitive results in metrics such as travel time. We compare the performance of tabular Q-Learning, DQN, SARSA, and A2C algorithms using metrics such as travel time, CO2 emissions, waiting time, and stopped time. Our evaluation considers multiple scenarios that encompass a range of road users (trucks, buses, cars) with varying pollution levels.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Understanding Addition in Transformers</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13121</p>
  <p><b>作者</b>：Philip Quirke,  Fazl (Kiko) Barez</p>
  <p><b>备注</b>：9 pages, 8 figures, submitted to ICLR 2024</p>
  <p><b>关键词</b>：machine learning models, workings of machine, machine learning, safe and ethical, one-layer Transformer model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Semi-Supervised Learning of Dynamical Systems with Neural Ordinary  Differential Equations: A Teacher-Student Model Approach</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13110</p>
  <p><b>作者</b>：Yu Wang,  Yuxuan Yin,  Karthik Somayaji Nanjangud Suryanarayana,  Jan Drgona,  Malachi Schram,  Mahantesh Halappanavar,  Frank Liu,  Peng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remains challenging due, Ordinary Differential Equations, complex nonlinear dynamics, Neural Ordinary Differential, prior knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling dynamical systems is crucial for a wide range of tasks, but it remains challenging due to complex nonlinear dynamics, limited observations, or lack of prior knowledge. Recently, data-driven approaches such as Neural Ordinary Differential Equations (NODE) have shown promising results by leveraging the expressive power of neural networks to model unknown dynamics. However, these approaches often suffer from limited labeled training data, leading to poor generalization and suboptimal predictions. On the other hand, semi-supervised algorithms can utilize abundant unlabeled data and have demonstrated good performance in classification and regression tasks. We propose TS-NODE, the first semi-supervised approach to modeling dynamical systems with NODE. TS-NODE explores cheaply generated synthetic pseudo rollouts to broaden exploration in the state space and to tackle the challenges brought by lack of ground-truth system data under a teacher-student model. TS-NODE employs an unified optimization framework that corrects the teacher model based on the student's feedback while mitigating the potential false system dynamics present in pseudo rollouts. TS-NODE demonstrates significant performance improvements over a baseline Neural ODE model on multiple dynamical system modeling tasks.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting  Multiple Experts for Video Deepfake Detection</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13103</p>
  <p><b>作者</b>：Ammarah Hashmi,  Sahibzada Adil Shahzad,  Chia-Wen Lin,  Yu Tsao,  Hsin-Min Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media platforms, major social problem, content shared widely, requires increased regulation, Forged content shared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forged content shared widely on social media platforms is a major social problem that requires increased regulation and poses new challenges to the research community. The recent proliferation of hyper-realistic deepfake videos has drawn attention to the threat of audio and visual forgeries. Most previous work on detecting AI-generated fake videos only utilizes visual modality or audio modality. While there are some methods in the literature that exploit audio and visual modalities to detect forged videos, they have not been comprehensively evaluated on multi-modal datasets of deepfake videos involving acoustic and visual manipulations. Moreover, these existing methods are mostly based on CNN and suffer from low detection accuracy. Inspired by the recent success of Transformer in various fields, to address the challenges posed by deepfake technology, in this paper, we propose an Audio-Visual Transformer-based Ensemble Network (AVTENet) framework that considers both acoustic manipulation and visual manipulation to achieve effective video forgery detection. Specifically, the proposed model integrates several purely transformer-based variants that capture video, audio, and audio-visual salient cues to reach a consensus in prediction. For evaluation, we use the recently released benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed analysis, we evaluate AVTENet, its variants, and several existing methods on multiple test sets of the FakeAVCeleb dataset. Experimental results show that our best model outperforms all existing methods and achieves state-of-the-art performance on Testset-I and Testset-II of the FakeAVCeleb dataset.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13102</p>
  <p><b>作者</b>：Gabriele Corso,  Yilun Xu,  Valentin de Bortoli,  Regina Barzilay,  Tommi Jaakkola</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widespread success, significant amount, amount of research, sampling time, generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In light of the widespread success of generative models, a significant amount of research has gone into speeding up their sampling time. However, generative models are often sampled multiple times to obtain a diverse set incurring a cost that is orthogonal to sampling time. We tackle the question of how to improve diversity and sample efficiency by moving beyond the common assumption of independent samples. We propose particle guidance, an extension of diffusion-based generative sampling where a joint-particle time-evolving potential enforces diversity. We analyze theoretically the joint distribution that particle guidance generates, its implications on the choice of potential, and the connections with methods in other disciplines. Empirically, we test the framework both in the setting of conditional image generation, where we are able to increase diversity without affecting quality, and molecular conformer generation, where we reduce the state-of-the-art median error by 13% on average.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：No offence, Bert -- I insult only humans! Multiple addressees  sentence-level attack on toxicity detection neural network</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13099</p>
  <p><b>作者</b>：Sergey Berezin,  Reza Farahbakhsh,  Noel Crespi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：toxicity detector models, black-box toxicity detector, efficient sentence-level attack, detector models, introduce a simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Unsupervised Representation Learning to Aid Semi-Supervised Meta  Learning</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13085</p>
  <p><b>作者</b>：Atik Faysal,  Mohammad Rostami,  Huaxia Wang,  Avimanyu Sahoo,  Ryan Antle</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data scarcity problem, scarcity problem, problem in machine, meta-learning, data scarcity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning or meta-learning leverages the data scarcity problem in machine learning. Traditionally, training data requires a multitude of samples and labeling for supervised learning. To address this issue, we propose a one-shot unsupervised meta-learning to learn the latent representation of the training samples. We use augmented samples as the query set during the training phase of the unsupervised meta-learning. A temperature-scaled cross-entropy loss is used in the inner loop of meta-learning to prevent overfitting during unsupervised learning. The learned parameters from this step are applied to the targeted supervised meta-learning in a transfer-learning fashion for initialization and fast adaptation with improved accuracy. The proposed method is model agnostic and can aid any meta-learning model to improve accuracy. We use model agnostic meta-learning (MAML) and relation network (RN) on Omniglot and mini-Imagenet datasets to demonstrate the performance of the proposed method. Furthermore, a meta-learning model with the proposed initialization can achieve satisfactory accuracy with significantly fewer training samples.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：From Multilingual Complexity to Emotional Clarity: Leveraging  Commonsense to Unveil Emotions in Code-Mixed Dialogues</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13080</p>
  <p><b>作者</b>：Shivani Kumar,  Ramaneswaran S,  Md Shad Akhtar,  Tanmoy Chakraborty</p>
  <p><b>备注</b>：Paper accepted in EMNLP 2023. 15 pages, 6 figures, 9 tables</p>
  <p><b>关键词</b>：driving NLP research, driving NLP, Emotion Recognition, NLP research, human communication</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding emotions during conversation is a fundamental aspect of human communication, driving NLP research for Emotion Recognition in Conversation (ERC). While considerable research has focused on discerning emotions of individual speakers in monolingual dialogues, understanding the emotional dynamics in code-mixed conversations has received relatively less attention. This motivates our undertaking of ERC for code-mixed conversations in this study. Recognizing that emotional intelligence encompasses a comprehension of worldly knowledge, we propose an innovative approach that integrates commonsense information with dialogue context to facilitate a deeper understanding of emotions. To achieve this, we devise an efficient pipeline that extracts relevant commonsense from existing knowledge graphs based on the code-mixed input. Subsequently, we develop an advanced fusion technique that seamlessly combines the acquired commonsense information with the dialogue representation obtained from a dedicated dialogue understanding module. Our comprehensive experimentation showcases the substantial performance improvement obtained through the systematic incorporation of commonsense in ERC. Both quantitative assessments and qualitative analyses further corroborate the validity of our hypothesis, reaffirming the pivotal role of commonsense integration in enhancing ERC.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Creative Robot Tool Use with Large Language Models</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13065</p>
  <p><b>作者</b>：Mengdi Xu,  Peide Huang,  Wenhao Yu,  Shiqi Liu,  Xilun Zhang,  Yaru Niu,  Tingnan Zhang,  Fei Xia,  Jie Tan,  Ding Zhao</p>
  <p><b>备注</b>：19 pages, 14 figures, 2 tables</p>
  <p><b>关键词</b>：advanced intelligence, Large Language Models, hallmark of advanced, animal behavior, implicit physical constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tool use is a hallmark of advanced intelligence, exemplified in both animal behavior and robotic capabilities. This paper investigates the feasibility of imbuing robots with the ability to creatively use tools in tasks that involve implicit physical constraints and long-term planning. Leveraging Large Language Models (LLMs), we develop RoboTool, a system that accepts natural language instructions and outputs executable code for controlling robots in both simulated and real-world environments. RoboTool incorporates four pivotal components: (i) an "Analyzer" that interprets natural language to discern key task-related concepts, (ii) a "Planner" that generates comprehensive strategies based on the language input and key concepts, (iii) a "Calculator" that computes parameters for each skill, and (iv) a "Coder" that translates these plans into executable Python code. Our results show that RoboTool can not only comprehend explicit or implicit physical constraints and environmental factors but also demonstrate creative tool use. Unlike traditional Task and Motion Planning (TAMP) methods that rely on explicit optimization, our LLM-based system offers a more flexible, efficient, and user-friendly solution for complex robotics tasks. Through extensive experiments, we validate that RoboTool is proficient in handling tasks that would otherwise be infeasible without the creative use of tools, thereby expanding the capabilities of robotic systems. Demos are available on our project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Robust multimodal models have outlier features and encode more concepts</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13040</p>
  <p><b>作者</b>：Jonathan Crabbé,  Pau Rodríguez,  Vaishaal Shankar,  Luca Zappella,  Arno Blaas</p>
  <p><b>备注</b>：29 pages, 18 figures</p>
  <p><b>关键词</b>：robust models, distinguishes robust models, models, representation space, robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>What distinguishes robust models from non-robust ones? This question has gained traction with the appearance of large-scale multimodal models, such as CLIP. These models have demonstrated unprecedented robustness with respect to natural distribution shifts. While it has been shown that such differences in robustness can be traced back to differences in training data, so far it is not known what that translates to in terms of what the model has learned. In this work, we bridge this gap by probing the representation spaces of 12 robust multimodal models with various backbones (ResNets and ViTs) and pretraining sets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two signatures of robustness in the representation spaces of these models: (1) Robust models exhibit outlier features characterized by their activations, with some being several orders of magnitude above average. These outlier features induce privileged directions in the model's representation space. We demonstrate that these privileged directions explain most of the predictive power of the model by pruning up to $80 \%$ of the least important representation space directions without negative impacts on model accuracy and robustness; (2) Robust models encode substantially more concepts in their representation space. While this superposition of concepts allows robust models to store much information, it also results in highly polysemantic features, which makes their interpretation challenging. We discuss how these insights pave the way for future research in various fields, such as model pruning and mechanistic interpretability.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Agri-GNN: A Novel Genotypic-Topological Graph Neural Network Framework  Built on GraphSAGE for Optimized Yield Prediction</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13037</p>
  <p><b>作者</b>：Aditya Gupta,  Asheesh Singh</p>
  <p><b>备注</b>：19 pages Regeneron STS entry</p>
  <p><b>关键词</b>：Neural Network Framework, Graph Neural Network, textit, Agri-GNN, Network Framework tailored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Agriculture, as the cornerstone of human civilization, constantly seeks to integrate technology for enhanced productivity and sustainability. This paper introduces $\textit{Agri-GNN}$, a novel Genotypic-Topological Graph Neural Network Framework tailored to capture the intricate spatial and genotypic interactions of crops, paving the way for optimized predictions of harvest yields. $\textit{Agri-GNN}$ constructs a Graph $\mathcal{G}$ that considers farming plots as nodes, and then methodically constructs edges between nodes based on spatial and genotypic similarity, allowing for the aggregation of node information through a genotypic-topological filter. Graph Neural Networks (GNN), by design, consider the relationships between data points, enabling them to efficiently model the interconnected agricultural ecosystem. By harnessing the power of GNNs, $\textit{Agri-GNN}$ encapsulates both local and global information from plants, considering their inherent connections based on spatial proximity and shared genotypes, allowing stronger predictions to be made than traditional Machine Learning architectures. $\textit{Agri-GNN}$ is built from the GraphSAGE architecture, because of its optimal calibration with large graphs, like those of farming plots and breeding experiments. $\textit{Agri-GNN}$ experiments, conducted on a comprehensive dataset of vegetation indices, time, genotype information, and location data, demonstrate that $\textit{Agri-GNN}$ achieves an $R^2 = .876$ in yield predictions for farming fields in Iowa. The results show significant improvement over the baselines and other work in the field. $\textit{Agri-GNN}$ represents a blueprint for using advanced graph-based neural architectures to predict crop yield, providing significant improvements over baselines in the field.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：LASER: Linear Compression in Wireless Distributed Optimization</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13033</p>
  <p><b>作者</b>：Ashok Vardhan Makkuva,  Marco Bondaschi,  Thijs Vogels,  Martin Jaggi,  Hyeji Kim,  Michael C. Gastpar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale machine learning, large scale machine, machine learning, facto algorithm, large scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-parallel SGD is the de facto algorithm for distributed optimization, especially for large scale machine learning. Despite its merits, communication bottleneck is one of its persistent issues. Most compression schemes to alleviate this either assume noiseless communication links, or fail to achieve good performance on practical tasks. In this paper, we close this gap and introduce LASER: LineAr CompreSsion in WirEless DistRibuted Optimization. LASER capitalizes on the inherent low-rank structure of gradients and transmits them efficiently over the noisy channels. Whilst enjoying theoretical guarantees similar to those of the classical SGD, LASER shows consistent gains over baselines on a variety of practical benchmarks. In particular, it outperforms the state-of-the-art compression schemes on challenging computer vision and GPT language modeling tasks. On the latter, we obtain $50$-$64 \%$ improvement in perplexity over our baselines for noisy channels.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Quality-Diversity through AI Feedback</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13032</p>
  <p><b>作者</b>：Herbie Bradley,  Andrew Dai,  Hannah Teufel,  Jenny Zhang,  Koen Oostermeijer,  Marco Bellagente,  Jeff Clune,  Kenneth Stanley,  Grégory Schott,  Joel Lehman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text-generation problems, users may prefer, single response, diverse range, QDAIF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through AI feedback, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-QD controls. Further, human evaluation of QDAIF-generated creative texts validates reasonable agreement between AI and human evaluation. Our results thus highlight the potential of AI feedback to guide open-ended search for creative and original solutions, providing a recipe that seemingly generalizes to many domains and modalities. In this way, QDAIF is a step towards AI systems that can independently search, diversify, evaluate, and improve, which are among the core skills underlying human society's capacity for innovation.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：A Use Case: Reformulating Query Rewriting as a Statistical Machine  Translation Problem</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13031</p>
  <p><b>作者</b>：Abdullah Can Algan,  Emre Yürekli,  Aykut Çayır</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieve relevant web, relevant web content, retrieve relevant, search engines, important challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most important challenges for modern search engines is to retrieve relevant web content based on user queries. In order to achieve this challenge, search engines have a module to rewrite user queries. That is why modern web search engines utilize some statistical and neural models used in the natural language processing domain. Statistical machine translation is a well-known NLP method among them. The paper proposes a query rewriting pipeline based on a monolingual machine translation model that learns to rewrite Arabic user search queries. This paper also describes preprocessing steps to create a mapping between user queries and web page titles.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Blending gradient boosted trees and neural networks for point and  probabilistic forecasting of hierarchical time series</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13029</p>
  <p><b>作者</b>：Ioannis Nasios,  Konstantinos Vogklis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural networks families, gradient boosted trees, machine learning models, networks families, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we tackle the problem of point and probabilistic forecasting by describing a blending methodology of machine learning models that belong to gradient boosted trees and neural networks families. These principles were successfully applied in the recent M5 Competition on both Accuracy and Uncertainty tracks. The keypoints of our methodology are: a) transform the task to regression on sales for a single day b) information rich feature engineering c) create a diverse set of state-of-the-art machine learning models and d) carefully construct validation sets for model tuning. We argue that the diversity of the machine learning models along with the careful selection of validation examples, where the most important ingredients for the effectiveness of our approach. Although forecasting data had an inherent hierarchy structure (12 levels), none of our proposed solutions exploited that hierarchical scheme. Using the proposed methodology, our team was ranked within the gold medal range in both Accuracy and the Uncertainty track. Inference code along with already trained models are available at this https URL</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Reliable Academic Conference Question Answering: A Study Based on Large  Language Model</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13028</p>
  <p><b>作者</b>：Zhiwei Huang,  Long Jin,  Junjie Wang,  Mingchen Tu,  Yin Hua,  Zhiqiang Liu,  Jiawei Meng,  Huajun Chen,  Wen Zhang</p>
  <p><b>备注</b>：10 pages, 4 figures, 2 tables</p>
  <p><b>关键词</b>：fostering global scholarly, global scholarly communication, fostering global, scholarly communication, rapid growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid growth of computer science has led to a proliferation of research presented at academic conferences, fostering global scholarly communication. Researchers consistently seek accurate, current information about these events at all stages. This data surge necessitates an intelligent question-answering system to efficiently address researchers' queries and ensure awareness of the latest advancements. The information of conferences is usually published on their official website, organized in a semi-structured way with a lot of text. To address this need, we have developed the ConferenceQA dataset for 7 diverse academic conferences with human annotations. Firstly, we employ a combination of manual and automated methods to organize academic conference data in a semi-structured JSON format. Subsequently, we annotate nearly 100 question-answer pairs for each conference. Each pair is classified into four different dimensions. To ensure the reliability of the data, we manually annotate the source of each answer. In light of recent advancements, Large Language Models (LLMs) have demonstrated impressive performance in various NLP tasks. They have demonstrated impressive capabilities in information-seeking question answering after instruction fine-tuning, and as such, we present our conference QA study based on LLM. Due to hallucination and outdated knowledge of LLMs, we adopt retrieval based methods to enhance LLMs' question-answering abilities. We have proposed a structure-aware retrieval method, specifically designed to leverage inherent structural information during the retrieval process. Empirical validation on the ConferenceQA dataset has demonstrated the effectiveness of this method. The dataset and code are readily accessible on this https URL.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Be Bayesian by Attachments to Catch More Uncertainty</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13027</p>
  <p><b>作者</b>：Shiyu Shen,  Bin Pan,  Tianyang Shi,  Tao Li,  Zhenwei Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solid theorical foundations, Bayesian Neural Networks, Bayesian Neural, neural network, OOD data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribution modules aim at extracting the uncertainty from both ID and OOD data. We further provide theoretical analysis for the convergence of ABNN, and experimentally validate its superiority by comparing with some state-of-the-art uncertainty estimation methods Code will be made available.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Powerset multi-class cross entropy loss for neural speaker diarization</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13025</p>
  <p><b>作者</b>：Alexis Plaquet (IRIT-SAMoVA),  Hervé Bredin (IRIT-SAMoVA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised EEND diarization, permutation-invariant training, addressing speaker diarization, problem with permutation-invariant, EEND showing great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since its introduction in 2019, the whole end-to-end neural diarization (EEND) line of work has been addressing speaker diarization as a frame-wise multi-label classification problem with permutation-invariant training. Despite EEND showing great promise, a few recent works took a step back and studied the possible combination of (local) supervised EEND diarization with (global) unsupervised clustering. Yet, these hybrid contributions did not question the original multi-label formulation. We propose to switch from multi-label (where any two speakers can be active at the same time) to powerset multi-class classification (where dedicated classes are assigned to pairs of overlapping speakers). Through extensive experiments on 9 different benchmarks, we show that this formulation leads to significantly better performance (mostly on overlapping speech) and robustness to domain mismatch, while eliminating the detection threshold hyperparameter, critical for the multi-label formulation.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Towards Anytime Fine-tuning: Continually Pre-trained Language Models  with Hypernetwork Prompt</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13024</p>
  <p><b>作者</b>：Gangwei Jiang,  Caigao Jiang,  Siqiao Xue,  James Y. Zhang,  Jun Zhou,  Defu Lian,  Ying Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pre-trained model, fast-evolving world, urgent for adapting, continually pre-trained model, Continual pre-training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual pre-training has been urgent for adapting a pre-trained model to a multitude of domains and tasks in the fast-evolving world. In practice, a continually pre-trained model is expected to demonstrate not only greater capacity when fine-tuned on pre-trained domains but also a non-decreasing performance on unseen ones. In this work, we first investigate such anytime fine-tuning effectiveness of existing continual pre-training approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. The agreement loss maximally preserves the generalization of a pre-trained model to new domains, and the disagreement one guards the exclusiveness of the generated hidden states for each domain. Remarkably, prompts by the hypernetwork alleviate the domain identity when fine-tuning and promote knowledge transfer across domains. Our method achieved improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively, demonstrating its efficacy.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：GraphGPT: Graph Instruction Tuning for Large Language Models</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13023</p>
  <p><b>作者</b>：Jiabin Tang,  Yuhao Yang,  Wei Wei,  Lei Shi,  Lixin Su,  Suqi Cheng,  Dawei Yin,  Chao Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, recursive information exchange, Graph Neural, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have advanced graph structure understanding via recursive information exchange and aggregation among graph nodes. To improve model robustness, self-supervised learning (SSL) has emerged as a promising approach for data augmentation. However, existing methods for generating pre-trained graph embeddings often rely on fine-tuning with specific downstream task labels, which limits their usability in scenarios where labeled data is scarce or unavailable. To address this, our research focuses on advancing the generalization capabilities of graph models in challenging zero-shot learning scenarios. Inspired by the success of large language models (LLMs), we aim to develop a graph-oriented LLM that can achieve high generalization across diverse downstream datasets and tasks, even without any information available from the downstream graph data. In this work, we present the GraphGPT framework that aligns LLMs with graph structural knowledge with a graph instruction tuning paradigm. Our framework incorporates a text-graph grounding component to establish a connection between textual information and graph structures. Additionally, we propose a dual-stage instruction tuning paradigm, accompanied by a lightweight graph-text alignment projector. This paradigm explores self-supervised graph structural signals and task-specific graph instructions, to guide LLMs in understanding complex graph structures and improving their adaptability across different downstream tasks. Our framework is evaluated on supervised and zero-shot graph learning tasks, demonstrating superior generalization and outperforming state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised  Language Understanding</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13022</p>
  <p><b>作者</b>：Jianing Wang,  Qiushi Sun,  Nuo Chen,  Chengyu Wang,  Jun Huang,  Ming Gao,  Xiang Li</p>
  <p><b>备注</b>：Accepted by Findings of EMNLP 2023</p>
  <p><b>关键词</b>：large pre-trained language, typically produces inferior, pre-trained language models, produces inferior performance, massive labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow the optimization of only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class  Manipulation Using DeepFool Algorithm</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13019</p>
  <p><b>作者</b>：S. M. Fazle Rabby Labib,  Joyanta Jyoti Mondal,  Meem Arafat Manab</p>
  <p><b>备注</b>：8 pages, 3 figures, to be submitted at IEEE Computer Vision and Pattern Recognition (CVPR) 2024</p>
  <p><b>关键词</b>：adversarial attacks poses, advanced various domains, poses serious concerns, significantly advanced, vulnerability to adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across different deep neural network architectures while preserving image integrity as much as possible. Results show that one of the deep convolutional neural network architectures, AlexNet, and one of the state-of-the-art model Vision Transformer exhibit high robustness to getting fooled. Our code will be made public when publishing the paper.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Position Interpolation Improves ALiBi Extrapolation</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13017</p>
  <p><b>作者</b>：Faisal Al-Khateeb,  Nolan Dey,  Daria Soboleva,  Joel Hestness</p>
  <p><b>备注</b>：4 pages content, 1 page references, 4 figures</p>
  <p><b>关键词</b>：longer sequence lengths, rotary position embeddings, Linear position interpolation, sequence lengths, extrapolate to longer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear position interpolation helps pre-trained models using rotary position embeddings (RoPE) to extrapolate to longer sequence lengths. We propose using linear position interpolation to extend the extrapolation range of models using Attention with Linear Biases (ALiBi). We find position interpolation significantly improves extrapolation capability on upstream language modelling and downstream summarization and retrieval tasks.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Solving the multiplication problem of a large language model system  using a graph-based method</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13016</p>
  <p><b>作者</b>：Turker Tuncer,  Sengul Dogan,  Mehmet Baygin,  Prabal Datta Barua,  Abdul Hafeez-Baig,  Ru-San Tan,  Subrata Chakraborty,  U. Rajendra Acharya</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：based chatbot software, generative pre-trained transformer, possesses excellent natural, natural language processing, language processing capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The generative pre-trained transformer (GPT)-based chatbot software ChatGPT possesses excellent natural language processing capabilities but is inadequate for solving arithmetic problems, especially multiplication. Its GPT structure uses a computational graph for multiplication, which has limited accuracy beyond simple multiplication operations. We developed a graph-based multiplication algorithm that emulated human-like numerical operations by incorporating a 10k operator, where k represents the maximum power to base 10 of the larger of two input numbers. Our proposed algorithm attained 100% accuracy for 1,000,000 large number multiplication tasks, effectively solving the multiplication challenge of GPT-based and other large language models. Our work highlights the importance of blending simple human insights into the design of artificial intelligence algorithms. Keywords: Graph-based multiplication; ChatGPT; Multiplication problem</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Audio-AdapterFusion: A Task-ID-free Approach for Efficient and  Non-Destructive Multi-task Speech Recognition</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13015</p>
  <p><b>作者</b>：Hillary Ngai,  Rohan Agrawal,  Neeraj Gaur,  Ronny Huang,  Parisa Haghani,  Pedro Moreno Mengibar</p>
  <p><b>备注</b>：2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) Proceedings</p>
  <p><b>关键词</b>：composable alternative, large ASR models, scale the deployment, deployment of large, large ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adapters are an efficient, composable alternative to full fine-tuning of pre-trained models and help scale the deployment of large ASR models to many tasks. In practice, a task ID is commonly prepended to the input during inference to route to single-task adapters for the specified task. However, one major limitation of this approach is that the task ID may not be known during inference, rendering it unsuitable for most multi-task settings. To address this, we propose three novel task-ID-free methods to combine single-task adapters in multi-task ASR and investigate two learning algorithms for training. We evaluate our methods on 10 test sets from 4 diverse ASR tasks and show that our methods are non-destructive and parameter-efficient. While only updating 17% of the model parameters, our methods can achieve an 8% mean WER improvement relative to full fine-tuning and are on-par with task-ID adapter routing.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Large Language Model Prediction Capabilities: Evidence from a Real-World  Forecasting Tournament</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13014</p>
  <p><b>作者</b>：Philipp Schoenegger,  Peter S. Park</p>
  <p><b>备注</b>：13 pages, six visualizations (four figures, two tables)</p>
  <p><b>关键词</b>：Accurately predicting, important milestone, large language models, real-world forecasting tournaments, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence. However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent. To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform. The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict. Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts. We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question. We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis. Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts. A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data. This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Generative error correction for code-switching speech recognition using  large language models</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13013</p>
  <p><b>作者</b>：Chen Chen,  Yuchen Hu,  Chao-Han Huck Yang,  Hexin Liu,  Sabato Marco Siniscalchi,  Eng Siong Chng</p>
  <p><b>备注</b>：Submitted to ICASSP2024</p>
  <p><b>关键词</b>：speech refers, automatic speech recognition, N-best hypotheses, well-trained ASR models, N-best hypotheses generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code-switching (CS) speech refers to the phenomenon of mixing two or more languages within the same sentence. Despite the recent advances in automatic speech recognition (ASR), CS-ASR is still a challenging task ought to the grammatical structure complexity of the phenomenon and the data scarcity of specific training corpus. In this work, we propose to leverage large language models (LLMs) and lists of hypotheses generated by an ASR to address the CS problem. Specifically, we first employ multiple well-trained ASR models for N-best hypotheses generation, with the aim of increasing the diverse and informative elements in the set of hypotheses. Next, we utilize the LLMs to learn the hypotheses-to-transcription (H2T) mapping by adding a trainable low-rank adapter. Such a generative error correction (GER) method directly predicts the accurate transcription according to its expert linguistic knowledge and N-best hypotheses, resulting in a paradigm shift from the traditional language model rescoring or error correction techniques. Experimental evidence demonstrates that GER significantly enhances CS-ASR accuracy, in terms of reduced mixed error rate (MER). Furthermore, LLMs show remarkable data efficiency for H2T learning, providing a potential solution to the data scarcity problem of CS-ASR in low-resource languages.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：H2O Open Ecosystem for State-of-the-art Large Language Models</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13012</p>
  <p><b>作者</b>：Arno Candel,  Jon McKinney,  Philipp Singer,  Pascal Pfeiffer,  Maximilian Jeblick,  Chun Ming Lee,  Marcos V. Conde</p>
  <p><b>备注</b>：Empirical Methods in Natural Language Processing (EMNLP) 2023 Demo</p>
  <p><b>关键词</b>：represent a revolution, Large Language Models, Large Language, Language Models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) represent a revolution in AI. However, they also pose many significant risks, such as the presence of biased, private, copyrighted or harmful text. For this reason we need open, transparent and safe solutions. We introduce a complete open-source ecosystem for developing and testing LLMs. The goal of this project is to boost open alternatives to closed-source approaches. We release h2oGPT, a family of fine-tuned LLMs from 7 to 70 Billion parameters. We also introduce H2O LLM Studio, a framework and no-code GUI designed for efficient fine-tuning, evaluation, and deployment of LLMs using the most recent state-of-the-art techniques. Our code and models are licensed under fully permissive Apache 2.0 licenses. We believe open-source language models help to boost AI development and make it more accessible and trustworthy. The demo is available at: this https URL</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：LoBaSS: Gauging Learnability in Supervised Fine-tuning Data</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13008</p>
  <p><b>作者</b>：Haotian Zhou,  Tingkai Liu,  Qianli Ma,  Jianbo Yuan,  Pengfei Liu,  Yang You,  Hongxia Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aligning Large Language, Large Language Models, Large Language, specific task prerequisites, aligning Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large Language Models (LLMs) to specific task prerequisites. The selection of fine-tuning data profoundly influences the model's performance, whose principle is traditionally grounded in data quality and distribution. In this paper, we introduce a new dimension in SFT data selection: learnability. This new dimension is motivated by the intuition that SFT unlocks capabilities acquired by a LLM during the pretraining phase. Given that different pretrained models have disparate capabilities, the SFT data appropriate for one may not suit another. Thus, we introduce the term learnability to define the suitability of data for effective learning by the model. We present the Loss Based SFT Data Selection (LoBaSS) method, utilizing data learnability as the principal criterion for the selection SFT data. This method provides a nuanced approach, allowing the alignment of data selection with inherent model capabilities, ensuring optimal compatibility and learning efficiency. In experimental comparisons involving 7B and 13B models, our LoBaSS method is able to surpass full-data fine-tuning at merely 6% of the total training data. When employing 16.7% of the data, LoBaSS harmonizes the model's capabilities across conversational and mathematical domains, proving its efficacy and adaptability.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：A Critical Survey on Fairness Benefits of XAI</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13007</p>
  <p><b>作者</b>：Luca Deck,  Jakob Schoeffer,  Maria De-Arteaga,  Niklas Kühl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：analyze typical claims, relationship between explainable, XAI, critical survey, analyze typical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this critical survey, we analyze typical claims on the relationship between explainable AI (XAI) and fairness to disentangle the multidimensional relationship between these two concepts. Based on a systematic literature review and a subsequent qualitative content analysis, we identify seven archetypal claims from 175 papers on the alleged fairness benefits of XAI. We present crucial caveats with respect to these claims and provide an entry point for future discussions around the potentials and limitations of XAI for specific fairness desiderata. While the literature often suggests XAI to be an enabler for several fairness desiderata, we notice a misalignment between these desiderata and the capabilities of XAI. We encourage to conceive XAI as one of many tools to approach the multidimensional, sociotechnical challenge of algorithmic fairness and to be more specific about how exactly what kind of XAI method enables whom to address which fairness desideratum.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Software Metadata Classification based on Generative Artificial  Intelligence</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13006</p>
  <p><b>作者</b>：Seetharam Killivalavan,  Durairaj Thenmozhi</p>
  <p><b>备注</b>：FIRE Track: Information Retrieval in Software Engineering (IRSE), 9 pages</p>
  <p><b>关键词</b>：Generative Artificial Intelligence, Artificial Intelligence, Language Model Architecture, Large Language Model, approach to enhance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel approach to enhance the performance of binary code comment quality classification models through the application of Generative Artificial Intelligence (AI). By leveraging the OpenAI API, a dataset comprising 1239 newly generated code-comment pairs, extracted from various GitHub repositories and open-source projects, has been labelled as "Useful" or "Not Useful", and integrated into the existing corpus of 9048 pairs in the C programming language. Employing a cutting-edge Large Language Model Architecture, the generated dataset demonstrates notable improvements in model accuracy. Specifically, when incorporated into the Support Vector Machine (SVM) model, a 6% increase in precision is observed, rising from 0.79 to 0.85. Additionally, the Artificial Neural Network (ANN) model exhibits a 1.5% increase in recall, climbing from 0.731 to 0.746. This paper sheds light on the potential of Generative AI in augmenting code comment quality classification models. The results affirm the effectiveness of this methodology, indicating its applicability in broader contexts within software development and quality assurance domains. The findings underscore the significance of integrating generative techniques to advance the accuracy and efficacy of machine learning models in practical software engineering scenarios.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Metacognitive threshold: a computational account</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13005</p>
  <p><b>作者</b>：Brendan Conway-Smith,  Robert L. West</p>
  <p><b>备注</b>：In Proceedings of the 21st International Conference on Cognitive Modeling (2023) this https URL</p>
  <p><b>关键词</b>：discuss potential cognitive, potential cognitive mechanisms, training and meditation, paper will explore, computationally accounting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper will explore ways of computationally accounting for the metacognitive threshold -- the minimum amount of stimulus needed for a mental state to be perceived -- and discuss potential cognitive mechanisms by which this threshold can be influenced through metacognitive training and meditation.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Progressively Efficient Learning</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13004</p>
  <p><b>作者</b>：Ruijie Zheng,  Khanh Nguyen,  Hal Daumé III,  Furong Huang,  Karthik Narasimhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：user preferences, capable of rapidly, rapidly acquiring, acquiring novel skills, skills and adapting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assistant AI agents should be capable of rapidly acquiring novel skills and adapting to new user preferences. Traditional frameworks like imitation learning and reinforcement learning do not facilitate this capability because they support only low-level, inefficient forms of communication. In contrast, humans communicate with progressive efficiency by defining and sharing abstract intentions. Reproducing similar capability in AI agents, we develop a novel learning framework named Communication-Efficient Interactive Learning (CEIL). By equipping a learning agent with an abstract, dynamic language and an intrinsic motivation to learn with minimal communication effort, CEIL leads to emergence of a human-like pattern where the learner and the teacher communicate progressively efficiently by exchanging increasingly more abstract intentions. CEIL demonstrates impressive performance and communication efficiency on a 2D MineCraft domain featuring long-horizon decision-making tasks. Agents trained with CEIL quickly master new tasks, outperforming non-hierarchical and hierarchical imitation learning by up to 50% and 20% in absolute success rate, respectively, given the same number of interactions with the teacher. Especially, the framework performs robustly with teachers modeled after human pragmatic communication behavior.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Conversational Financial Information Retrieval Model (ConFIRM)</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13001</p>
  <p><b>作者</b>：Stephen Choi,  William Gazeley,  Siu Ho Wong,  Tingting Li</p>
  <p><b>备注</b>：10 pages, 2 figures, 2 tables, 2 appendices</p>
  <p><b>关键词</b>：finance merits exploration, large language models, leveraging their emergent, merits exploration, exponential growth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.
ConFIRM comprises two modules:
1) a method to synthesize finance domain-specific question-answer pairs, and
2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.
ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Document-Level Relation Extraction with Relation Correlation Enhancement</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13000</p>
  <p><b>作者</b>：Yusheng Huang,  Zhouhan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：relation, relation correlations, task that focuses, focuses on identifying, Document-level relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Document-level relation extraction (DocRE) is a task that focuses on identifying relations between entities within a document. However, existing DocRE models often overlook the correlation between relations and lack a quantitative analysis of relation correlations. To address this limitation and effectively capture relation correlations in DocRE, we propose a relation graph method, which aims to explicitly exploit the interdependency among relations. Firstly, we construct a relation graph that models relation correlations using statistical co-occurrence information derived from prior relation knowledge. Secondly, we employ a re-weighting scheme to create an effective relation correlation matrix to guide the propagation of relation information. Furthermore, we leverage graph attention networks to aggregate relation embeddings. Importantly, our method can be seamlessly integrated as a plug-and-play module into existing models. Experimental results demonstrate that our approach can enhance the performance of multi-relation extraction, highlighting the effectiveness of considering relation correlations in DocRE.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Adaptive Dynamic Programming for Energy-Efficient Base Station Cell  Switching</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12999</p>
  <p><b>作者</b>：Junliang Luo,  Yi Tian Xu,  Di Wu,  Michael Jenkin,  Xue Liu,  Gregory Dudek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential energy crises, energy crises arising, evolving new-gen cellular, new-gen cellular networks, environmental and regulatory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Energy saving in wireless networks is growing in importance due to increasing demand for evolving new-gen cellular networks, environmental and regulatory concerns, and potential energy crises arising from geopolitical tensions. In this work, we propose an approximate dynamic programming (ADP)-based method coupled with online optimization to switch on/off the cells of base stations to reduce network power consumption while maintaining adequate Quality of Service (QoS) metrics. We use a multilayer perceptron (MLP) given each state-action pair to predict the power consumption to approximate the value function in ADP for selecting the action with optimal expected power saved. To save the largest possible power consumption without deteriorating QoS, we include another MLP to predict QoS and a long short-term memory (LSTM) for predicting handovers, incorporated into an online optimization algorithm producing an adaptive QoS threshold for filtering cell switching actions based on the overall QoS history. The performance of the method is evaluated using a practical network simulator with various real-world scenarios with dynamic traffic patterns.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Parking Spot Classification based on surround view camera system</b></summary>
  <p><b>编号</b>：[323]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12997</p>
  <p><b>作者</b>：Andy Xiao,  Deep Doshi,  Lihao Wang,  Harsha Gorantla,  Thomas Heitzmann,  Peter Groth</p>
  <p><b>备注</b>：SPIE Optical Engineering + Applications, 2023, San Diego, California, United States. Proc. SPIE 12675, Applications of Machine Learning 2023</p>
  <p><b>关键词</b>：including urban driving, automated driving scenarios, Surround-view fisheye cameras, automated driving, urban driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surround-view fisheye cameras are commonly used for near-field sensing in automated driving scenarios, including urban driving and auto valet parking. Four fisheye cameras, one on each side, are sufficient to cover 360° around the vehicle capturing the entire near-field region. Based on surround view cameras, there has been much research on parking slot detection with main focus on the occupancy status in recent years, but little work on whether the free slot is compatible with the mission of the ego vehicle or not. For instance, some spots are handicap or electric vehicles accessible only. In this paper, we tackle parking spot classification based on the surround view camera system. We adapt the object detection neural network YOLOv4 with a novel polygon bounding box model that is well-suited for various shaped parking spaces, such as slanted parking slots. To the best of our knowledge, we present the first detailed study on parking spot detection and classification on fisheye cameras for auto valet parking scenarios. The results prove that our proposed classification approach is effective to distinguish between regular, electric vehicle, and handicap parking spots.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Comprehensive Multimodal Segmentation in Medical Imaging: Combining  YOLOv8 with SAM and HQ-SAM Models</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12995</p>
  <p><b>作者</b>：Sumit Pandey,  Kuan-Fu Chen,  Erik B. Dam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical imaging datasets, diverse medical imaging, X-ray images, encompassing ultrasound, SAM model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a comprehensive approach for segmenting regions of interest (ROI) in diverse medical imaging datasets, encompassing ultrasound, CT scans, and X-ray images. The proposed method harnesses the capabilities of the YOLOv8 model for approximate boundary box detection across modalities, alongside the Segment Anything Model (SAM) and High Quality (HQ) SAM for fully automatic and precise segmentation. To generate boundary boxes, the YOLOv8 model was trained using a limited set of 100 images and masks from each modality. The results obtained from our approach are extensively computed and analyzed, demonstrating its effectiveness and potential in medical image analysis. Various evaluation metrics, including precision, recall, F1 score, and Dice Score, were employed to quantify the accuracy of the segmentation results. A comparative analysis was conducted to assess the individual and combined performance of the YOLOv8, YOLOv8+SAM, and YOLOv8+HQ-SAM models. The results indicate that the SAM model performs better than the other two models, exhibiting higher segmentation accuracy and overall performance. While HQ-SAM offers potential advantages, its incremental gains over the standard SAM model may not justify the additional computational cost. The YOLOv8+SAM model shows promise for enhancing medical image segmentation and its clinical implications.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Enhancing Health Data Interoperability with Large Language Models: A  FHIR Study</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12989</p>
  <p><b>作者</b>：Yikuan Li,  Hanyin Wang,  Halid Yerebakan,  Yoshihisa Shinagawa,  Yuan Luo</p>
  <p><b>备注</b>：Submitted to 2024 AMIA IS</p>
  <p><b>关键词</b>：healthcare data interoperability, enhance healthcare data, large language model, data interoperability, investigated the ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we investigated the ability of the large language model (LLM) to enhance healthcare data interoperability. We leveraged the LLM to convert clinical texts into their corresponding FHIR resources. Our experiments, conducted on 3,671 snippets of clinical text, demonstrated that the LLM not only streamlines the multi-step natural language processing and human calibration processes but also achieves an exceptional accuracy rate of over 90% in exact matches when compared to human annotations.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：A survey of manifold learning and its applications for multimedia</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12986</p>
  <p><b>作者</b>：Hannes Fassold</p>
  <p><b>备注</b>：Accepted for ICVSP 2023 conference</p>
  <p><b>关键词</b>：emerging research domain, emerging research, research domain, domain of machine, Manifold learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manifold learning is an emerging research domain of machine learning. In this work, we give an introduction into manifold learning and how it is employed for important application fields in multimedia.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Enabling energy-Efficient object detection with surrogate gradient  descent in spiking neural networks</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12985</p>
  <p><b>作者</b>：Jilong Luo,  Shanlin Xiao,  Yinsheng Chen,  Zhiyi Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Spiking Neural Networks, plausible neural network, neural network model, biologically plausible neural, spatio-temporal information processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Networks (SNNs) are a biologically plausible neural network model with significant advantages in both event-driven processing and spatio-temporal information processing, rendering SNNs an appealing choice for energyefficient object detection. However, the non-differentiability of the biological neuronal dynamics model presents a challenge during the training of SNNs. Furthermore, a suitable decoding strategy for object detection in SNNs is currently lacking. In this study, we introduce the Current Mean Decoding (CMD) method, which solves the regression problem to facilitate the training of deep SNNs for object detection tasks. Based on the gradient surrogate and CMD, we propose the SNN-YOLOv3 model for object detection. Our experiments demonstrate that SNN-YOLOv3 achieves a remarkable performance with an mAP of 61.87% on the PASCAL VOC dataset, requiring only 6 time steps. Compared to SpikingYOLO, we have managed to increase mAP by nearly 10% while reducing energy consumption by two orders of magnitude.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Skin Lesion Segmentation Improved by Transformer-based Networks with  Inter-scale Dependency Modeling</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13604</p>
  <p><b>作者</b>：Sania Eskandari,  Janet Lumpp,  Luis Sanchez Giraldo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：skin cell growth, skin cancer resulting, abnormal skin cell, Fully Convolutional Networks, skin lesion segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Melanoma, a dangerous type of skin cancer resulting from abnormal skin cell growth, can be treated if detected early. Various approaches using Fully Convolutional Networks (FCNs) have been proposed, with the U-Net architecture being prominent To aid in its diagnosis through automatic skin lesion segmentation. However, the symmetrical U-Net model's reliance on convolutional operations hinders its ability to capture long-range dependencies crucial for accurate medical image segmentation. Several Transformer-based U-Net topologies have recently been created to overcome this limitation by replacing CNN blocks with different Transformer modules to capture local and global representations. Furthermore, the U-shaped structure is hampered by semantic gaps between the encoder and decoder. This study intends to increase the network's feature re-usability by carefully building the skip connection path. Integrating an already calculated attention affinity within the skip connection path improves the typical concatenation process utilized in the conventional skip connection path. As a result, we propose a U-shaped hierarchical Transformer-based structure for skin lesion segmentation and an Inter-scale Context Fusion (ISCF) method that uses attention correlations in each stage of the encoder to adaptively combine the contexts from each stage to mitigate semantic gaps. The findings from two skin lesion segmentation benchmarks support the ISCF module's applicability and effectiveness. The code is publicly available at \url{this https URL}</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Variational measurement-based quantum computation for generative  modeling</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13524</p>
  <p><b>作者</b>：Arunava Majumder,  Marius Krumm,  Tina Radkohl,  Hendrik Poulsen Nautrup,  Sofiene Jerbi,  Hans J. Briegel</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：fundamentally unique paradigm, Measurement-based quantum computation, MBQC, design quantum algorithms, offers a fundamentally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Measurement-based quantum computation (MBQC) offers a fundamentally unique paradigm to design quantum algorithms. Indeed, due to the inherent randomness of quantum measurements, the natural operations in MBQC are not deterministic and unitary, but are rather augmented with probabilistic byproducts. Yet, the main algorithmic use of MBQC so far has been to completely counteract this probabilistic nature in order to simulate unitary computations expressed in the circuit model. In this work, we propose designing MBQC algorithms that embrace this inherent randomness and treat the random byproducts in MBQC as a resource for computation. As a natural application where randomness can be beneficial, we consider generative modeling, a task in machine learning centered around generating complex probability distributions. To address this task, we propose a variational MBQC algorithm equipped with control parameters that allow to directly adjust the degree of randomness to be admitted in the computation. Our numerical findings indicate that this additional randomness can lead to significant gains in learning performance in certain generative modeling tasks. These results highlight the potential advantages in exploiting the inherent randomness of MBQC and motivate further research into MBQC-based algorithms.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Meta-learning of Physics-informed Neural Networks for Efficiently  Solving Newly Given PDEs</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13270</p>
  <p><b>作者</b>：Tomoharu Iwata,  Yusuke Tanaka,  Naonori Ueda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PDE problems, network-based meta-learning method, neural network-based meta-learning, PDE, solve partial differential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a neural network-based meta-learning method to efficiently solve partial differential equation (PDE) problems. The proposed method is designed to meta-learn how to solve a wide variety of PDE problems, and uses the knowledge for solving newly given PDE problems. We encode a PDE problem into a problem representation using neural networks, where governing equations are represented by coefficients of a polynomial function of partial derivatives, and boundary conditions are represented by a set of point-condition pairs. We use the problem representation as an input of a neural network for predicting solutions, which enables us to efficiently predict problem-specific solutions by the forwarding process of the neural network without updating model parameters. To train our model, we minimize the expected error when adapted to a PDE problem based on the physics-informed neural network framework, by which we can evaluate the error even when solutions are unknown. We demonstrate that our proposed method outperforms existing methods in predicting solutions of PDE problems.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：AI for Mathematics: A Cognitive Science Perspective</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13021</p>
  <p><b>作者</b>：Cedegao E. Zhang,  Katherine M. Collins,  Adrian Weller,  Joshua B. Tenenbaum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful conceptual systems, conceptual systems developed, powerful conceptual, human species, conceptual systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematics is one of the most powerful conceptual systems developed and used by the human species. Dreams of automated mathematicians have a storied history in artificial intelligence (AI). Rapid progress in AI, particularly propelled by advances in large language models (LLMs), has sparked renewed, widespread interest in building such systems. In this work, we reflect on these goals from a \textit{cognitive science} perspective. We call attention to several classical and ongoing research directions from cognitive science, which we believe are valuable for AI practitioners to consider when seeking to build truly human (or superhuman)-level mathematical systems. We close with open discussions and questions that we believe necessitate a multi-disciplinary perspective -- cognitive scientists working in tandem with AI researchers and mathematicians -- as we move toward better mathematical AI systems which not only help us push the frontier of the mathematics, but also offer glimpses into how we as humans are even capable of such great cognitive feats.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Getting aligned on representational alignment</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13018</p>
  <p><b>作者</b>：Ilia Sucholutsky,  Lukas Muttenthaler,  Adrian Weller,  Andi Peng,  Andreea Bobu,  Been Kim,  Bradley C. Love,  Erin Grant,  Jascha Achterberg,  Joshua B. Tenenbaum,  Katherine M. Collins,  Katherine L. Hermann,  Kerem Oktar,  Klaus Greff,  Martin N. Hebart,  Nori Jacoby,  Qiuyi (Richard) Zhang,  Raja Marjieh,  Robert Geirhos,  Sherol Chen,  Simon Kornblith,  Sunayana Rane,  Talia Konkle,  Thomas P. O'Connell,  Thomas Unterthiner,  Andrew K. Lampinen,  Klaus-Robert Müller,  Mariya Toneva,  Thomas L. Griffiths</p>
  <p><b>备注</b>：Working paper, changes to be made in upcoming revisions</p>
  <p><b>关键词</b>：Biological and artificial, make decisions, systems form representations, processing systems form, representational alignment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biological and artificial information processing systems form representations of the world that they can use to categorize, reason, plan, navigate, and make decisions. To what extent do the representations formed by these diverse systems agree? Can diverging representations still lead to the same behaviors? And how can systems modify their representations to better match those of another system? These questions pertaining to the study of \textbf{\emph{representational alignment}} are at the heart of some of the most active research areas in contemporary cognitive science, neuroscience, and machine learning. Unfortunately, there is limited knowledge-transfer between research communities interested in representational alignment, and much of the progress in one field ends up being rediscovered independently in another, when greater cross-field communication would be advantageous. To improve communication between fields, we propose a unifying framework that can serve as a common language between researchers studying representational alignment. We survey the literature from the fields of cognitive science, neuroscience, and machine learning, and demonstrate how prior work fits into this framework. Finally, we lay out open problems in representational alignment where progress can benefit all three fields. We hope that our work can catalyze cross-disciplinary collaboration and accelerate progress for all communities studying and developing information processing systems. We note that this is a working paper and encourage readers to reach out with their suggestions for future revisions.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Detecting Speech Abnormalities with a Perceiver-based Sequence  Classifier that Leverages a Universal Speech Model</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.13010</p>
  <p><b>作者</b>：Hagen Soltau,  Izhak Shafran,  Alex Ottenwess,  Joseph R. JR Duffy,  Rene L. Utianski,  Leland R. Barnard,  John L. Stricker,  Daniela Wiepert,  David T. Jones,  Hugo Botha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Perceiver-based sequence classifier, propose a Perceiver-based, Perceiver-based sequence, neurological disorders, Universal Speech Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a Perceiver-based sequence classifier to detect abnormalities in speech reflective of several neurological disorders. We combine this classifier with a Universal Speech Model (USM) that is trained (unsupervised) on 12 million hours of diverse audio recordings. Our model compresses long sequences into a small set of class-specific latent representations and a factorized projection is used to predict different attributes of the disordered input speech. The benefit of our approach is that it allows us to model different regions of the input for different classes and is at the same time data efficient. We evaluated the proposed model extensively on a curated corpus from the Mayo Clinic. Our model outperforms standard transformer (80.9%) and perceiver (81.8%) models and achieves an average accuracy of 83.1%. With limited task-specific data, we find that pretraining is important and surprisingly pretraining with the unrelated automatic speech recognition (ASR) task is also beneficial. Encodings from the middle layers provide a mix of both acoustic and phonetic information and achieve best prediction results compared to just using the final layer encodings (83.1% vs. 79.6%). The results are promising and with further refinements may help clinicians detect speech abnormalities without needing access to highly specialized speech-language pathologists.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Zero-shot Learning of Drug Response Prediction for Preclinical Drug  Screening</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12996</p>
  <p><b>作者</b>：Kun Li,  Yong Luo,  Xiantao Cai,  Wenbin Hu,  Bo Du</p>
  <p><b>备注</b>：16 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：typically employ supervised, methods typically employ, drug, preclinical drug screening, typically employ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional deep learning methods typically employ supervised learning for drug response prediction (DRP). This entails dependence on labeled response data from drugs for model training. However, practical applications in the preclinical drug screening phase demand that DRP models predict responses for novel compounds, often with unknown drug responses. This presents a challenge, rendering supervised deep learning methods unsuitable for such scenarios. In this paper, we propose a zero-shot learning solution for the DRP task in preclinical drug screening. Specifically, we propose a Multi-branch Multi-Source Domain Adaptation Test Enhancement Plug-in, called MSDA. MSDA can be seamlessly integrated with conventional DRP methods, learning invariant features from the prior response data of similar drugs to enhance real-time predictions of unlabeled compounds. We conducted experiments using the GDSCv2 and CellMiner datasets. The results demonstrate that MSDA efficiently predicts drug responses for novel compounds, leading to a general performance improvement of 5-10\% in the preclinical drug screening phase. The significance of this solution resides in its potential to accelerate the drug discovery process, improve drug candidate assessment, and facilitate the success of drug discovery.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Dimensions of Disagreement: Unpacking Divergence and Misalignment in  Cognitive Science and Artificial Intelligence</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2310.12994</p>
  <p><b>作者</b>：Kerem Oktar,  Ilia Sucholutsky,  Tania Lombrozo,  Thomas L. Griffiths</p>
  <p><b>备注</b>：Currently under review</p>
  <p><b>关键词</b>：artificial agents creates, artificial agents, increasing prevalence, correspondingly increasing, creates a correspondingly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing prevalence of artificial agents creates a correspondingly increasing need to manage disagreements between humans and artificial agents, as well as between artificial agents themselves. Considering this larger space of possible agents exposes an opportunity for furthering our understanding of the nature of disagreement: past studies in psychology have often cast disagreement as two agents forming diverging evaluations of the same object, but disagreement can also arise from differences in how agents represent that object. AI research on human-machine alignment and recent work in computational cognitive science have focused on this latter kind of disagreement, and have developed tools that can be used to quantify the extent of representational overlap between agents. Understanding how divergence and misalignment interact to produce disagreement, and how resolution strategies depend on this interaction, is key to promoting effective collaboration between diverse types of agents.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">💭这个人很懒，什么都没有留下</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-10-24)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-10-24)"/></a><div class="content"><a class="title" href="/2023/10/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-10-24)">Arxiv每日速递(2023-10-24)</a><time datetime="2023-10-24T01:01:50.054Z" title="发表于 2023-10-24 09:01:50">2023-10-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"/></a><div class="content"><a class="title" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><time datetime="2023-09-22T14:55:45.000Z" title="发表于 2023-09-22 22:55:45">2023-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prompt：大语言模型的执行指南"/></a><div class="content"><a class="title" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南">Prompt：大语言模型的执行指南</a><time datetime="2023-09-06T14:45:45.000Z" title="发表于 2023-09-06 22:45:45">2023-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/03/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9C%A81688%E7%94%B5%E5%95%86%E5%9C%BA%E6%99%AF%E7%9A%84%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5.html" title="【转载】大语言模型在1688电商场景的算法实践"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【转载】大语言模型在1688电商场景的算法实践"/></a><div class="content"><a class="title" href="/2023/09/03/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9C%A81688%E7%94%B5%E5%95%86%E5%9C%BA%E6%99%AF%E7%9A%84%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5.html" title="【转载】大语言模型在1688电商场景的算法实践">【转载】大语言模型在1688电商场景的算法实践</a><time datetime="2023-09-03T15:35:45.000Z" title="发表于 2023-09-03 23:35:45">2023-09-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【梳理】陆奇最新演讲实录：我的大模型世界观"/></a><div class="content"><a class="title" href="/2023/05/07/%E3%80%90%E6%A2%B3%E7%90%86%E3%80%91%E9%99%86%E5%A5%87%E6%9C%80%E6%96%B0%E6%BC%94%E8%AE%B2%E5%AE%9E%E5%BD%95%EF%BC%9A%E6%88%91%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%96%E7%95%8C%E8%A7%82%20.html" title="【梳理】陆奇最新演讲实录：我的大模型世界观">【梳理】陆奇最新演讲实录：我的大模型世界观</a><time datetime="2023-05-07T11:07:45.000Z" title="发表于 2023-05-07 19:07:45">2023-05-07</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (7)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt=""><img width="48" height="48" src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-05-19</span><a class="blog-slider__title" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/cail2021.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-10-22</span><a class="blog-slider__title" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt=""><img width="48" height="48" src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-17</span><a class="blog-slider__title" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-22</span><a class="blog-slider__title" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-06</span><a class="blog-slider__title" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">Prompt：大语言模型的执行指南</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/26/升级深度学习开发环境全攻略.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-26</span><a class="blog-slider__title" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">升级深度学习开发环境全攻略</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>