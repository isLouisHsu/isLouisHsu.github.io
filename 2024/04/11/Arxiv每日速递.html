<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2024-04-11) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。 统计 今日共更新386篇论文，其中：  62篇自然语言处理（cs.CL） 99篇计算机视觉（cs.CV） 113篇机器学习（cs.LG） 101篇人工智能（cs.AI）  自然语言处理    1. 标题：InternLM-XComposer2-4KHD: A Pioneer">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2024-04-11)">
<meta property="og:url" content="http://louishsu.xyz/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。 统计 今日共更新386篇论文，其中：  62篇自然语言处理（cs.CL） 99篇计算机视觉（cs.CV） 113篇机器学习（cs.LG） 101篇人工智能（cs.AI）  自然语言处理    1. 标题：InternLM-XComposer2-4KHD: A Pioneer">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2024-04-11T00:36:50.526Z">
<meta property="article:modified_time" content="2024-04-11T00:39:29.343Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2024-04-11 08:39:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zealdocs.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zeal：离线文档浏览器，其灵感来自 OS X平台上的 Dash，目前支持 Window 和 Liunx，基于 QT5</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wise-system-monitor.en.softonic.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Wise System Monitor：监控从系统到本地网络的所有运行情况</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="http://www.uderzo.it/main_products/space_sniffer/index.html"><i class="fa-fw fa-regular fa-star"></i><span> Space Sniffer：磁盘空间分析工具</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zealdocs.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zeal：离线文档浏览器，其灵感来自 OS X平台上的 Dash，目前支持 Window 和 Liunx，基于 QT5</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wise-system-monitor.en.softonic.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Wise System Monitor：监控从系统到本地网络的所有运行情况</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="http://www.uderzo.it/main_products/space_sniffer/index.html"><i class="fa-fw fa-regular fa-star"></i><span> Space Sniffer：磁盘空间分析工具</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2024-04-11)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-11T00:36:50.526Z" title="发表于 2024-04-11 08:36:50">2024-04-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-11T00:39:29.343Z" title="更新于 2024-04-11 08:39:29">2024-04-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>79分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新386篇论文，其中：</p>
<ul>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">62篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">99篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">113篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">101篇人工智能（cs.AI）</a></li>
</ul>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model  Handling Resolutions from 336 Pixels to 4K HD</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06512">https://arxiv.org/abs/2404.06512</a></p>
  <p><b>作者</b>：Xiaoyi Dong,  Pan Zhang,  Yuhang Zang,  Yuhang Cao,  Bin Wang,  Linke Ouyang,  Songyang Zhang,  Haodong Duan,  Wenwei Zhang,  Yining Li,  Hang Yan,  Yang Gao,  Zhe Chen,  Xinyue Zhang,  Wei Li,  Jingwen Li,  Wenhai Wang,  Kai Chen,  Conghui He,  Xingcheng Zhang,  Jifeng Dai,  Yu Qiao,  Dahua Lin,  Jiaqi Wang</p>
  <p><b>备注</b>：Code and models are publicly available at this https URL</p>
  <p><b>关键词</b>：Large Vision-Language Model, comprehending fine-grained visual, fine-grained visual content, visual content due, Large Vision-Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Large Vision-Language Model (LVLM) field has seen significant advancements, yet its progression has been hindered by challenges in comprehending fine-grained visual content due to limited resolution. Recent efforts have aimed to enhance the high-resolution understanding capabilities of LVLMs, yet they remain capped at approximately 1500 x 1500 pixels and constrained to a relatively narrow resolution range. This paper represents InternLM-XComposer2-4KHD, a groundbreaking exploration into elevating LVLM resolution capabilities up to 4K HD (3840 x 1600) and beyond. Concurrently, considering the ultra-high resolution may not be necessary in all scenarios, it supports a wide range of diverse resolutions from 336 pixels to 4K standard, significantly broadening its scope of applicability. Specifically, this research advances the patch division paradigm by introducing a novel extension: dynamic resolution with automatic patch configuration. It maintains the training image aspect ratios while automatically varying patch counts and configuring layouts based on a pre-trained Vision Transformer (ViT) (336 x 336), leading to dynamic training resolution from 336 pixels to 4K standard. Our research demonstrates that scaling training resolution up to 4K HD leads to consistent performance enhancements without hitting the ceiling of potential improvements. InternLM-XComposer2-4KHD shows superb capability that matches or even surpasses GPT-4V and Gemini Pro in 10 of the 16 benchmarks. The InternLM-XComposer2-4KHD model series with 7B parameters are publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：On the Effect of (Near) Duplicate Subwords in Language Modelling</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06508">https://arxiv.org/abs/2404.06508</a></p>
  <p><b>作者</b>：Anton Schäfer,  Thomas Hofmann,  Imanol Schlag,  Tiago Pimentel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：core part, part of language, subwords, duplicates, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tokenisation is a core part of language models (LMs). It involves splitting a character sequence into subwords which are assigned arbitrary indices before being served to the LM. While typically lossless, however, this process may lead to less sample efficient LM training: as it removes character-level information, it could make it harder for LMs to generalise across similar subwords, such as now and Now. We refer to such subwords as near duplicates. In this paper, we study the impact of near duplicate subwords on LM training efficiency. First, we design an experiment that gives us an upper bound to how much we should expect a model to improve if we could perfectly generalise across near duplicates. We do this by duplicating each subword in our LM's vocabulary, creating perfectly equivalent classes of subwords. Experimentally, we find that LMs need roughly 17% more data when trained in a fully duplicated setting. Second, we investigate the impact of naturally occurring near duplicates on LMs. Here, we see that merging them considerably hurts LM performance. Therefore, although subword duplication negatively impacts LM training efficiency, naturally occurring near duplicates may not be as similar as anticipated, limiting the potential for performance improvements.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Comparing Two Model Designs for Clinical Note Generation; Is an LLM a  Useful Evaluator of Consistency?</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06503">https://arxiv.org/abs/2404.06503</a></p>
  <p><b>作者</b>：Nathan Brake,  Thomas Schaaf</p>
  <p><b>备注</b>：Accepted to NAACL 2024 Findings</p>
  <p><b>关键词</b>：SOAP note, SOAP note based, clinical note consistency, clinical note, physicians are responsible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following an interaction with a patient, physicians are responsible for the submission of clinical documentation, often organized as a SOAP note. A clinical note is not simply a summary of the conversation but requires the use of appropriate medical terminology. The relevant information can then be extracted and organized according to the structure of the SOAP note. In this paper we analyze two different approaches to generate the different sections of a SOAP note based on the audio recording of the conversation, and specifically examine them in terms of note consistency. The first approach generates the sections independently, while the second method generates them all together. In this work we make use of PEGASUS-X Transformer models and observe that both methods lead to similar ROUGE values (less than 1% difference) and have no difference in terms of the Factuality metric. We perform a human evaluation to measure aspects of consistency and demonstrate that LLMs like Llama2 can be used to perform the same tasks with roughly the same agreement as the human annotators. Between the Llama2 analysis and the human reviewers we observe a Cohen Kappa inter-rater reliability of 0.79, 1.00, and 0.32 for consistency of age, gender, and body part injury, respectively. With this we demonstrate the usefulness of leveraging an LLM to measure quality indicators that can be identified by humans but are not currently captured by automatic metrics. This allows scaling evaluation to larger data sets, and we find that clinical note consistency improves by generating each new section conditioned on the output of all previously generated sections.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Pitfalls of Conversational LLMs on News Debiasing</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06488">https://arxiv.org/abs/2404.06488</a></p>
  <p><b>作者</b>：Ipek Baris Schlicht,  Defne Altiok,  Maryanne Taouk,  Lucie Flek</p>
  <p><b>备注</b>：The paper is accepted at the DELITE workshop which is co-located at COLING/LREC</p>
  <p><b>关键词</b>：conversational Large Language, Large Language Models, Large Language, paper addresses debiasing, conversational Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses debiasing in news editing and evaluates the effectiveness of conversational Large Language Models in this task. We designed an evaluation checklist tailored to news editors' perspectives, obtained generated texts from three popular conversational models using a subset of a publicly available dataset in media bias, and evaluated the texts according to the designed checklist. Furthermore, we examined the models as evaluator for checking the quality of debiased model outputs. Our findings indicate that none of the LLMs are perfect in debiasing. Notably, some models, including ChatGPT, introduced unnecessary changes that may impact the author's style and create misinformation. Lastly, we show that the models do not perform as proficiently as domain experts in evaluating the quality of debiased outputs.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06480">https://arxiv.org/abs/2404.06480</a></p>
  <p><b>作者</b>：Chonghua Wang,  Haodong Duan,  Songyang Zhang,  Dahua Lin,  Kai Chen</p>
  <p><b>备注</b>：NAACL 2024</p>
  <p><b>关键词</b>：shown increasing interest, extremely long documents, large language model, enhancing LLMs' capability, handle extremely long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the large language model (LLM) community has shown increasing interest in enhancing LLMs' capability to handle extremely long documents. As various long-text techniques and model architectures emerge, the precise and detailed evaluation of models' long-text capabilities has become increasingly important. Existing long-text evaluation benchmarks, such as L-Eval and LongBench, construct long-text test sets based on open-source datasets, focusing mainly on QA and summarization tasks. These datasets include test samples of varying lengths (from 2k to 32k+) entangled together, making it challenging to assess model capabilities across different length ranges. Moreover, they do not cover the ultralong settings (100k+ tokens) that the latest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a length-adaptable benchmark for evaluating the long-context understanding of LLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which enable a more reliable evaluation of LLMs' long context capabilities. These benchmarks support intricate manipulation of the length of test cases, and can easily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art closed-source API models and 6 open-source models with Ada-LEval. The evaluation results demonstrate the limitations of current LLMs, especially in ultra-long-context settings. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Text-Based Reasoning About Vector Graphics</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06479">https://arxiv.org/abs/2404.06479</a></p>
  <p><b>作者</b>：Zhenhailong Wang,  Joy Hsu,  Xingyao Wang,  Kuan-Hao Huang,  Manling Li,  Jiajun Wu,  Heng Ji</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：broad vision-language benchmarks, solving simple mazes, comparing line lengths, vector graphics, Scalable Vector Graphics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While large multimodal models excel in broad vision-language benchmarks, they often struggle with tasks requiring precise perception of low-level visual details, such as comparing line lengths or solving simple mazes. In particular, this failure mode persists in question-answering tasks about vector graphics -- images composed purely of 2D objects and shapes. To address this challenge, we propose the Visually Descriptive Language Model (VDLM), which performs text-based reasoning about vector graphics. VDLM leverages Scalable Vector Graphics (SVG) for a more precise visual description and first uses an off-the-shelf raster-to-SVG algorithm for encoding. Since existing language models cannot understand raw SVGs in a zero-shot setting, VDLM then bridges SVG with pretrained language models through a newly introduced intermediate symbolic representation, Primal Visual Description (PVD), comprising primitive attributes (e.g., shape, position, measurement) with their corresponding predicted values. PVD is task-agnostic and represents visual primitives that are universal across all vector graphics. It can be learned with procedurally generated (SVG, PVD) pairs and also enables the direct use of LLMs for generalization to complex reasoning tasks. By casting an image to a text-based representation, we can leverage the power of language models to learn alignment from SVG to visual primitives and generalize to unseen question-answering tasks. Empirical results show that VDLM achieves stronger zero-shot performance compared to state-of-the-art LMMs, such as GPT-4V, in various low-level multimodal perception and reasoning tasks on vector graphics. We additionally present extensive analyses on VDLM's performance, demonstrating that our framework offers better interpretability due to its disentangled perception and reasoning processes. Project page: this https URL</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot  Systems</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06413">https://arxiv.org/abs/2404.06413</a></p>
  <p><b>作者</b>：Kunal Garg,  Jacob Arkin,  Songyuan Zhang,  Nicholas Roy,  Chuchu Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-agent robotic systems, low-level control policy, Multi-agent robotic, robotic systems, smooth low-level control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent robotic systems are prone to deadlocks in an obstacle environment where the system can get stuck away from its desired location under a smooth low-level control policy. Without an external intervention, often in terms of a high-level command, it is not possible to guarantee that just a low-level control policy can resolve such deadlocks. Utilizing the generalizability and low data requirements of large language models (LLMs), this paper explores the possibility of using LLMs for deadlock resolution. We propose a hierarchical control framework where an LLM resolves deadlocks by assigning a leader and direction for the leader to move along. A graph neural network (GNN) based low-level distributed control policy executes the assigned plan. We systematically study various prompting techniques to improve LLM's performance in resolving deadlocks. In particular, as part of prompt engineering, we provide in-context examples for LLMs. We conducted extensive experiments on various multi-robot environments with up to 15 agents and 40 obstacles. Our results demonstrate that LLM-based high-level planners are effective in resolving deadlocks in MRS.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：AgentQuest: A Modular Benchmark Framework to Measure Progress and  Improve LLM Agents</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06411">https://arxiv.org/abs/2404.06411</a></p>
  <p><b>作者</b>：Luca Gioacchini,  Giuseppe Siracusano,  Davide Sanvito,  Kiril Gashteovski,  David Friede,  Roberto Bifulco,  Carolin Lawrence</p>
  <p><b>备注</b>：Accepted at the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2024)</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, multi-step reasoning tasks, made by Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advances made by Large Language Models (LLMs) have led to the pursuit of LLM agents that can solve intricate, multi-step reasoning tasks. As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress. However, existing benchmarks are often narrow and simply compute overall task success. To face these issues, we propose AgentQuest -- a framework where (i) both benchmarks and metrics are modular and easily extensible through well documented and easy-to-use APIs; (ii) we offer two new evaluation metrics that can reliably track LLM agent progress while solving a task. We exemplify the utility of the metrics on two use cases wherein we identify common failure points and refine the agent architecture to obtain a significant performance increase. Together with the research community, we hope to extend AgentQuest further and therefore we make it available under this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Take a Look at it! Rethinking How to Evaluate Language Model Jailbreak</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06407">https://arxiv.org/abs/2404.06407</a></p>
  <p><b>作者</b>：Hongyu Cai,  Arjun Arunasalam,  Leo Y. Lin,  Antonio Bianchi,  Z. Berkay Celik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly integrated, jailbreak, evaluation, Large language models, evaluation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have become increasingly integrated with various applications. To ensure that LLMs do not generate unsafe responses, they are aligned with safeguards that specify what content is restricted. However, such alignment can be bypassed to produce prohibited content using a technique commonly referred to as jailbreak. Different systems have been proposed to perform the jailbreak automatically. These systems rely on evaluation methods to determine whether a jailbreak attempt is successful. However, our analysis reveals that current jailbreak evaluation methods have two limitations. (1) Their objectives lack clarity and do not align with the goal of identifying unsafe responses. (2) They oversimplify the jailbreak result as a binary outcome, successful or not.
In this paper, we propose three metrics, safeguard violation, informativeness, and relative truthfulness, to evaluate language model jailbreak. Additionally, we demonstrate how these metrics correlate with the goal of different malicious actors. To compute these metrics, we introduce a multifaceted approach that extends the natural language generation evaluation method after preprocessing the response. We evaluate our metrics on a benchmark dataset produced from three malicious intent datasets and three jailbreak systems. The benchmark dataset is labeled by three annotators. We compare our multifaceted approach with three existing jailbreak evaluation methods. Experiments demonstrate that our multifaceted evaluation outperforms existing methods, with F1 scores improving on average by 17% compared to existing baselines. Our findings motivate the need to move away from the binary view of the jailbreak problem and incorporate a more comprehensive evaluation to ensure the safety of the language model.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Wu's Method can Boost Symbolic AI to Rival Silver Medalists and  AlphaGeometry to Outperform Gold Medalists at IMO Geometry</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06405">https://arxiv.org/abs/2404.06405</a></p>
  <p><b>作者</b>：Shiven Sinha,  Ameya Prabhu,  Ponnurangam Kumaraguru,  Siddharth Bhat,  Matthias Bethge</p>
  <p><b>备注</b>：Work in Progress. Released for wider feedback</p>
  <p><b>关键词</b>：geometric theorems constitutes, Proving geometric theorems, automated theorem proving, International Mathematical Olympiad, visual reasoning combining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Proving geometric theorems constitutes a hallmark of visual reasoning combining both intuitive and logical skills. Therefore, automated theorem proving of Olympiad-level geometry problems is considered a notable milestone in human-level automated reasoning. The introduction of AlphaGeometry, a neuro-symbolic model trained with 100 million synthetic samples, marked a major breakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO) problems whereas the reported baseline based on Wu's method solved only ten. In this note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry, and find that Wu's method is surprisingly strong. Wu's method alone can solve 15 problems, and some of them are not solved by any of the other methods. This leads to two key findings: (i) Combining Wu's method with the classic synthetic methods of deductive databases and angle, ratio, and distance chasing solves 21 out of 30 methods by just using a CPU-only laptop with a time limit of 5 minutes per problem. Essentially, this classic method solves just 4 problems less than AlphaGeometry and establishes the first fully symbolic baseline strong enough to rival the performance of an IMO silver medalist. (ii) Wu's method even solves 2 of the 5 problems that AlphaGeometry failed to solve. Thus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art for automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the first AI method which outperforms an IMO gold medalist.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：MiniCPM: Unveiling the Potential of Small Language Models with Scalable  Training Strategies</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06395">https://arxiv.org/abs/2404.06395</a></p>
  <p><b>作者</b>：Shengding Hu,  Yuge Tu,  Xu Han,  Chaoqun He,  Ganqu Cui,  Xiang Long,  Zhi Zheng,  Yewei Fang,  Yuxiang Huang,  Weilin Zhao,  Xinrong Zhang,  Zheng Leng Thai,  Kaihuo Zhang,  Chongyi Wang,  Yuan Yao,  Chenyang Zhao,  Jie Zhou,  Jie Cai,  Zhongwu Zhai,  Ning Ding,  Chao Jia,  Guoyang Zeng,  Dahai Li,  Zhiyuan Liu,  Maosong Sun</p>
  <p><b>备注</b>：17 pages paper, 7 pages Appendix</p>
  <p><b>关键词</b>：developing Large Language, Large Language Models, Large Language, Small Language Models, developing Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This scenario underscores the importance of exploring the potential of Small Language Models (SLMs) as a resource-efficient alternative. In this context, we introduce MiniCPM, specifically the 1.2B and 2.4B non-embedding parameter variants, not only excel in their respective categories but also demonstrate capabilities on par with 7B-13B LLMs. While focusing on SLMs, our approach exhibits scalability in both model and data dimensions for future LLM research. Regarding model scaling, we employ extensive model wind tunnel experiments for stable and optimal scaling. For data scaling, we introduce a Warmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to continuous training and domain adaptation. We present an in-depth analysis of the intriguing training dynamics that occurred in the WSD LRS. With WSD LRS, we are now able to efficiently study data-model scaling law without extensive retraining experiments on both axes of model and data, from which we derive the much higher compute optimal data-model ratio than Chinchilla Optimal. Additionally, we introduce MiniCPM family, including MiniCPM-DPO, MiniCPM-MoE and MiniCPM-128K, whose excellent performance further cementing MiniCPM's foundation in diverse SLM applications. MiniCPM models are available publicly at this https URL .</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Event Extraction in Basque: Typologically motivated Cross-Lingual  Transfer-Learning Analysis</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06392">https://arxiv.org/abs/2404.06392</a></p>
  <p><b>作者</b>：Mikel Zubillaga,  Oscar Sainz,  Ainara Estarrona,  Oier Lopez de Lacalle,  Eneko Agirre</p>
  <p><b>备注</b>：Accepted at LREC-Coling 2024</p>
  <p><b>关键词</b>：Multilingual Language Model, Event Extraction, Language Model, Multilingual Event Extraction, event extraction dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-lingual transfer-learning is widely used in Event Extraction for low-resource languages and involves a Multilingual Language Model that is trained in a source language and applied to the target language. This paper studies whether the typological similarity between source and target languages impacts the performance of cross-lingual transfer, an under-explored topic. We first focus on Basque as the target language, which is an ideal target language because it is typologically different from surrounding languages. Our experiments on three Event Extraction tasks show that the shared linguistic characteristic between source and target languages does have an impact on transfer quality. Further analysis of 72 language pairs reveals that for tasks that involve token classification such as entity and event trigger identification, common writing script and morphological features produce higher quality cross-lingual transfer. In contrast, for tasks involving structural prediction like argument extraction, common word order is the most relevant feature. In addition, we show that when increasing the training size, not all the languages scale in the same way in the cross-lingual setting. To perform the experiments we introduce EusIE, an event extraction dataset for Basque, which follows the Multilingual Event Extraction dataset (MEE). The dataset and code are publicly available.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Latent Distance Guided Alignment Training for Large Language Models</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06390">https://arxiv.org/abs/2404.06390</a></p>
  <p><b>作者</b>：Haotian Luo,  Wenhao Zheng,  Huaxiu Yao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, RLHF and DPO, crucial characteristic, characteristic of large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensuring alignment with human preferences is a crucial characteristic of large language models (LLMs). Presently, the primary alignment methods, RLHF and DPO, require extensive human annotation, which is expensive despite their efficacy. The significant expenses associated with current alignment techniques motivate researchers to investigate the development of annotation-free alignment training methods. In pursuit of improved alignment without relying on external annotation, we introduce Latent Distance Guided Alignment Training (LD-Align). This approach seeks to align the model with a high-quality supervised fine-tune dataset using guidance from a latent space. The latent space is generated through sample reconstruction, akin to auto-encoding. Consequently, we utilize the distance between sample pairs in the latent space to guide DPO-based alignment training. Extensive experimentation and evaluation show the efficacy of our proposed method in achieving notable alignment.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Model Generation from Requirements with LLMs: an Exploratory Study</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06371">https://arxiv.org/abs/2404.06371</a></p>
  <p><b>作者</b>：Alessio Ferrari,  Sallam Abualhaija,  Chetan Arora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improve stakeholders' communication, Complementing natural language, Complementing natural, system design, improve stakeholders'</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Complementing natural language (NL) requirements with graphical models can improve stakeholders' communication and provide directions for system design. However, creating models from requirements involves manual effort. The advent of generative large language models (LLMs), ChatGPT being a notable example, offers promising avenues for automated assistance in model generation. This paper investigates the capability of ChatGPT to generate a specific type of model, i.e., UML sequence diagrams, from NL requirements. We conduct a qualitative study in which we examine the sequence diagrams generated by ChatGPT for 28 requirements documents of various types and from different domains. Observations from the analysis of the generated diagrams have systematically been captured through evaluation logs, and categorized through thematic analysis. Our results indicate that, although the models generally conform to the standard and exhibit a reasonable level of understandability, their completeness and correctness with respect to the specified requirements often present challenges. This issue is particularly pronounced in the presence of requirements smells, such as ambiguity and inconsistency. The insights derived from this study can influence the practical utilization of LLMs in the RE process, and open the door to novel RE-specific prompting strategies targeting effective model generation.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：ClinLinker: Medical Entity Linking of Clinical Concept Mentions in  Spanish</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06367">https://arxiv.org/abs/2404.06367</a></p>
  <p><b>作者</b>：Fernando Gallego,  Guillermo López-García,  Luis Gasco-Sánchez,  Martin Krallinger,  Francisco J. Veredas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language processing techniques, natural language processing, named entity recognition, electronic health records, significantly advanced clinical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advances in natural language processing techniques, such as named entity recognition and normalization to widely used standardized terminologies like UMLS or SNOMED-CT, along with the digitalization of electronic health records, have significantly advanced clinical text analysis. This study presents ClinLinker, a novel approach employing a two-phase pipeline for medical entity linking that leverages the potential of in-domain adapted language models for biomedical text mining: initial candidate retrieval using a SapBERT-based bi-encoder and subsequent re-ranking with a cross-encoder, trained by following a contrastive-learning strategy to be tailored to medical concepts in Spanish. This methodology, focused initially on content in Spanish, substantially outperforming multilingual language models designed for the same purpose. This is true even for complex scenarios involving heterogeneous medical terminologies and being trained on a subset of the original data. Our results, evaluated using top-k accuracy at 25 and other top-k metrics, demonstrate our approach's performance on two distinct clinical entity linking Gold Standard corpora, DisTEMIST (diseases) and MedProcNER (clinical procedures), outperforming previous benchmarks by 40 points in DisTEMIST and 43 points in MedProcNER, both normalized to SNOMED-CT codes. These findings highlight our approach's ability to address language-specific nuances and set a new benchmark in entity linking, offering a potent tool for enhancing the utility of digital medical records. The resulting system is of practical value, both for large scale automatic generation of structured data derived from clinical records, as well as for exhaustive extraction and harmonization of predefined clinical variables of interest.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：SurveyAgent: A Conversational System for Personalized and Efficient  Research Survey</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06364">https://arxiv.org/abs/2404.06364</a></p>
  <p><b>作者</b>：Xintao Wang,  Jiangjie Chen,  Nianqi Li,  Lida Chen,  Xinfeng Yuan,  Wei Shi,  Xuyang Ge,  Rui Xu,  Yanghua Xiao</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：rapidly advancing research, advancing research fields, managing and staying, rapidly advancing, staying abreast</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the rapidly advancing research fields such as AI, managing and staying abreast of the latest scientific literature has become a significant challenge for researchers. Although previous efforts have leveraged AI to assist with literature searches, paper recommendations, and question-answering, a comprehensive support system that addresses the holistic needs of researchers has been lacking. This paper introduces SurveyAgent, a novel conversational system designed to provide personalized and efficient research survey assistance to researchers. SurveyAgent integrates three key modules: Knowledge Management for organizing papers, Recommendation for discovering relevant literature, and Query Answering for engaging with content on a deeper level. This system stands out by offering a unified platform that supports researchers through various stages of their literature review process, facilitated by a conversational interface that prioritizes user interaction and personalization. Our evaluation demonstrates SurveyAgent's effectiveness in streamlining research activities, showcasing its capability to facilitate how researchers interact with scientific literature.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Generalizable Sarcasm Detection Is Just Around The Corner, Of Course!</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06357">https://arxiv.org/abs/2404.06357</a></p>
  <p><b>作者</b>：Hyewon Jang,  Diego Frassinelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, online vs. offline, offline conversations, aggressive vs. humorous, humorous mocking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We tested the robustness of sarcasm detection models by examining their behavior when fine-tuned on four sarcasm datasets containing varying characteristics of sarcasm: label source (authors vs. third-party), domain (social media/online vs. offline conversations/dialogues), style (aggressive vs. humorous mocking). We tested their prediction performance on the same dataset (intra-dataset) and across different datasets (cross-dataset). For intra-dataset predictions, models consistently performed better when fine-tuned with third-party labels rather than with author labels. For cross-dataset predictions, most models failed to generalize well to the other datasets, implying that one type of dataset cannot represent all sorts of sarcasm with different styles and domains. Compared to the existing datasets, models fine-tuned on the new dataset we release in this work showed the highest generalizability to other datasets. With a manual inspection of the datasets and post-hoc analysis, we attributed the difficulty in generalization to the fact that sarcasm actually comes in different domains and styles. We argue that future sarcasm research should take the broad scope of sarcasm into account.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：RAR-b: Reasoning as Retrieval Benchmark</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06347">https://arxiv.org/abs/2404.06347</a></p>
  <p><b>作者</b>：Chenghao Xiao,  G Thomas Hudson,  Noura Al Moubayed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Semantic textual similartiy, emerging Retrieval-augmented Generation, embedding models, Retrieval-augmented Generation, Semantic textual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic textual similartiy (STS) and information retrieval tasks (IR) tasks have been the two major avenues to record the progress of embedding models in the past few years. Under the emerging Retrieval-augmented Generation (RAG) paradigm, we envision the need to evaluate next-level language understanding abilities of embedding models, and take a conscious look at the reasoning abilities stored in them. Addressing this, we pose the question: Can retrievers solve reasoning problems? By transforming reasoning tasks into retrieval tasks, we find that without specifically trained for reasoning-level language understanding, current state-of-the-art retriever models may still be far from being competent for playing the role of assisting LLMs, especially in reasoning-intensive tasks. Moreover, albeit trained to be aware of instructions, instruction-aware IR models are often better off without instructions in inference time for reasoning tasks, posing an overlooked retriever-LLM behavioral gap for the research community to align. However, recent decoder-based embedding models show great promise in narrowing the gap, highlighting the pathway for embedding models to achieve reasoning-level language understanding. We also show that, although current off-the-shelf re-ranker models fail on these tasks, injecting reasoning abilities into them through fine-tuning still appears easier than doing so to bi-encoders, and we are able to achieve state-of-the-art performance across all tasks by fine-tuning a reranking model. We release Reasoning as Retrieval Benchmark (RAR-b), a holistic suite of tasks and settings to evaluate the reasoning abilities stored in retriever models. RAR-b is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Finding fake reviews in e-commerce platforms by using hybrid algorithms</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06339">https://arxiv.org/abs/2404.06339</a></p>
  <p><b>作者</b>：Mathivanan Periasamy,  Rohith Mahadevan,  Bagiya Lakshmi S,  Raja CSP Raman,  Hasan Kumar S,  Jasper Jessiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Support Vector Machine, Decision Tree classifiers, language processing, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentiment analysis, a vital component in natural language processing, plays a crucial role in understanding the underlying emotions and opinions expressed in textual data. In this paper, we propose an innovative ensemble approach for sentiment analysis for finding fake reviews that amalgamate the predictive capabilities of Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Decision Tree classifiers. Our ensemble architecture strategically combines these diverse models to capitalize on their strengths while mitigating inherent weaknesses, thereby achieving superior accuracy and robustness in fake review prediction. By combining all the models of our classifiers, the predictive performance is boosted and it also fosters adaptability to varied linguistic patterns and nuances present in real-world datasets. The metrics accounted for on fake reviews demonstrate the efficacy and competitiveness of the proposed ensemble method against traditional single-model approaches. Our findings underscore the potential of ensemble techniques in advancing the state-of-the-art in finding fake reviews using hybrid algorithms, with implications for various applications in different social media and e-platforms to find the best reviews and neglect the fake ones, eliminating puffery and bluffs.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：nEMO: Dataset of Emotional Speech in Polish</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06292">https://arxiv.org/abs/2404.06292</a></p>
  <p><b>作者</b>：Iwona Christop</p>
  <p><b>备注</b>：Accepted for LREC-Coling 2024</p>
  <p><b>关键词</b>：recent years due, Speech emotion recognition, customer service, applications in healthcare, dialogue systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech emotion recognition has become increasingly important in recent years due to its potential applications in healthcare, customer service, and personalization of dialogue systems. However, a major issue in this field is the lack of datasets that adequately represent basic emotional states across various language families. As datasets covering Slavic languages are rare, there is a need to address this research gap. This paper presents the development of nEMO, a novel corpus of emotional speech in Polish. The dataset comprises over 3 hours of samples recorded with the participation of nine actors portraying six emotional states: anger, fear, happiness, sadness, surprise, and a neutral state. The text material used was carefully selected to represent the phonetics of the Polish language adequately. The corpus is freely available under the terms of a Creative Commons license (CC BY-NC-SA 4.0).</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：LLMs' Reading Comprehension Is Affected by Parametric Knowledge and  Struggles with Hypothetical Statements</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06283">https://arxiv.org/abs/2404.06283</a></p>
  <p><b>作者</b>：Victoria Basmov,  Yoav Goldberg,  Reut Tsarfaty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：context-based question answering, natural language understanding, assess language models', language models' natural, models' natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of reading comprehension (RC), often implemented as context-based question answering (QA), provides a primary means to assess language models' natural language understanding (NLU) capabilities. Yet, when applied to large language models (LLMs) with extensive built-in world knowledge, this method can be deceptive. If the context aligns with the LLMs' internal knowledge, it is hard to discern whether the models' answers stem from context comprehension or from LLMs' internal information. Conversely, using data that conflicts with the models' knowledge creates erroneous trends which distort the results. To address this issue, we suggest to use RC on imaginary data, based on fictitious facts and entities. This task is entirely independent of the models' world knowledge, enabling us to evaluate LLMs' linguistic abilities without the interference of parametric knowledge. Testing ChatGPT, GPT-4, LLaMA 2 and Mixtral on such imaginary data, we uncover a class of linguistic phenomena posing a challenge to current LLMs, involving thinking in terms of alternative, hypothetical scenarios. While all the models handle simple affirmative and negative contexts with high accuracy, they are much more prone to error when dealing with modal and conditional contexts. Crucially, these phenomena also trigger the LLMs' vulnerability to knowledge-conflicts again. In particular, while some models prove virtually unaffected by knowledge conflicts in affirmative and negative contexts, when faced with more semantically involved modal and conditional environments, they often fail to separate the text from their internal knowledge.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Dimensionality Reduction in Sentence Transformer Vector Databases with  Fast Fourier Transform</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06278">https://arxiv.org/abs/2404.06278</a></p>
  <p><b>作者</b>：Vitaly Bulgakov,  Alec Segal</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：enabling efficient storage, Fast Fourier Transform, faster computation, enabling efficient, efficient storage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality reduction in vector databases is pivotal for streamlining AI data management, enabling efficient storage, faster computation, and improved model performance. This paper explores the benefits of reducing vector database dimensions, with a focus on computational efficiency and overcoming the curse of dimensionality. We introduce a novel application of Fast Fourier Transform (FFT) to dimensionality reduction, a method previously underexploited in this context. By demonstrating its utility across various AI domains, including Retrieval-Augmented Generation (RAG) models and image processing, this FFT-based approach promises to improve data retrieval processes and enhance the efficiency and scalability of AI solutions. The incorporation of FFT may not only optimize operations in real-time processing and recommendation systems but also extend to advanced image processing techniques, where dimensionality reduction can significantly improve performance and analysis efficiency. This paper advocates for the broader adoption of FFT in vector database management, marking a significant stride towards addressing the challenges of data volume and complexity in AI research and applications. Unlike many existing approaches, we directly handle the embedding vectors produced by the model after processing a test input.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Understanding Cross-Lingual Alignment -- A Survey</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06228">https://arxiv.org/abs/2404.06228</a></p>
  <p><b>作者</b>：Katharina Hämmerl,  Jindřich Libovický,  Alexander Fraser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multilingual language models, recent years, Cross-lingual alignment, multilingual language, meaningful similarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising insights from throughout the field. We present different understandings of cross-lingual alignment and their limitations. We provide a qualitative summary of results from a large number of surveyed papers. Finally, we discuss how these insights may be applied not only to encoder models, where this topic has been heavily studied, but also to encoder-decoder or even decoder-only models, and argue that an effective trade-off between language-neutral and language-specific information is key.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Low-Cost Generation and Evaluation of Dictionary Example Sentences</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06224">https://arxiv.org/abs/2404.06224</a></p>
  <p><b>作者</b>：Bill Cai,  Clarence Boon Liang Ng,  Daniel Tan,  Shelvia Hotama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：manually creating quality, illustrating word definitions, definitions and usage, play an important, important role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dictionary example sentences play an important role in illustrating word definitions and usage, but manually creating quality sentences is challenging. Prior works have demonstrated that language models can be trained to generate example sentences. However, they relied on costly customized models and word sense datasets for generation and evaluation of their work. Rapid advancements in foundational models present the opportunity to create low-cost, zero-shot methods for the generation and evaluation of dictionary example sentences. We introduce a new automatic evaluation metric called OxfordEval that measures the win-rate of generated sentences against existing Oxford Dictionary sentences. OxfordEval shows high alignment with human judgments, enabling large-scale automated quality evaluation. We experiment with various LLMs and configurations to generate dictionary sentences across word classes. We complement this with a novel approach of using masked language models to identify and select sentences that best exemplify word meaning. The eventual model, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences according to OxfordEval, compared to 39.8% win rate for prior model-generated sentences.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：VI-OOD: A Unified Representation Learning Framework for Textual  Out-of-distribution Detection</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06217">https://arxiv.org/abs/2404.06217</a></p>
  <p><b>作者</b>：Li-Ming Zhan,  Bo Liu,  Xiao-Ming Wu</p>
  <p><b>备注</b>：COLING 2024</p>
  <p><b>关键词</b>：OOD detection, textual OOD detection, deep neural networks, OOD detection methods, OOD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection plays a crucial role in ensuring the safety and reliability of deep neural networks in various applications. While there has been a growing focus on OOD detection in visual data, the field of textual OOD detection has received less attention. Only a few attempts have been made to directly apply general OOD detection methods to natural language processing (NLP) tasks, without adequately considering the characteristics of textual data. In this paper, we delve into textual OOD detection with Transformers. We first identify a key problem prevalent in existing OOD detection methods: the biased representation learned through the maximization of the conditional likelihood $p(y\mid x)$ can potentially result in subpar performance. We then propose a novel variational inference framework for OOD detection (VI-OOD), which maximizes the likelihood of the joint distribution $p(x, y)$ instead of $p(y\mid x)$. VI-OOD is tailored for textual OOD detection by efficiently exploiting the representations of pre-trained Transformers. Through comprehensive experiments on various text classification tasks, VI-OOD demonstrates its effectiveness and wide applicability. Our code has been released at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：[Call for Papers] The 2nd BabyLM Challenge: Sample-efficient pretraining  on a developmentally plausible corpus</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06214">https://arxiv.org/abs/2404.06214</a></p>
  <p><b>作者</b>：Leshem Choshen,  Ryan Cotterell,  Michael Y. Hu,  Tal Linzen,  Aaron Mueller,  Candace Ross,  Alex Warstadt,  Ethan Wilcox,  Adina Williams,  Chengxu Zhuang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successful BabyLM Challenge, year successful BabyLM, successful BabyLM, year challenge, BabyLM Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>After last year's successful BabyLM Challenge, the competition will be hosted again in 2024/2025. The overarching goals of the challenge remain the same; however, some of the competition rules will be different. The big changes for this year's competition are as follows: First, we replace the loose track with a paper track, which allows (for example) non-model-based submissions, novel cognitively-inspired benchmarks, or analysis techniques. Second, we are relaxing the rules around pretraining data, and will now allow participants to construct their own datasets provided they stay within the 100M-word or 10M-word budget. Third, we introduce a multimodal vision-and-language track, and will release a corpus of 50% text-only and 50% image-text multimodal data as a starting point for LM model training. The purpose of this CfP is to provide rules for this year's challenge, explain these rule changes and their rationale in greater detail, give a timeline of this year's competition, and provide answers to frequently asked questions from last year's challenge.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Elephants Never Forget: Memorization and Learning of Tabular Data in  Large Language Models</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06209">https://arxiv.org/abs/2404.06209</a></p>
  <p><b>作者</b>：Sebastian Bordt,  Harsha Nori,  Vanessa Rodrigues,  Besmira Nushi,  Rich Caruana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown how Large, Large Language, set of tasks, diverse set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Specifically, we introduce a variety of different techniques to assess whether a language model has seen a tabular dataset during training. This investigation reveals that LLMs have memorized many popular tabular datasets verbatim. We then compare the few-shot learning performance of LLMs on datasets that were seen during training to the performance on datasets released after training. We find that LLMs perform better on datasets seen during training, indicating that memorization leads to overfitting. At the same time, LLMs show non-trivial performance on novel datasets and are surprisingly robust to data transformations. We then investigate the in-context statistical learning abilities of LLMs. Without fine-tuning, we find them to be limited. This suggests that much of the few-shot performance on novel datasets is due to the LLM's world knowledge. Overall, our results highlight the importance of testing whether an LLM has seen an evaluation dataset during pre-training. We make the exposure tests we developed available as the tabmemcheck Python package at this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Clue-Instruct: Text-Based Clue Generation for Educational Crossword  Puzzles</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06186">https://arxiv.org/abs/2404.06186</a></p>
  <p><b>作者</b>：Andrea Zugarini,  Kamyar Zeinalipour,  Surya Sai Kadali,  Marco Maggini,  Marco Gori,  Leonardo Rigutini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular linguistic games, Large Language Models, students in learning, Large Language, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crossword puzzles are popular linguistic games often used as tools to engage students in learning. Educational crosswords are characterized by less cryptic and more factual clues that distinguish them from traditional crossword puzzles. Despite there exist several publicly available clue-answer pair databases for traditional crosswords, educational clue-answer pairs datasets are missing. In this article, we propose a methodology to build educational clue generation datasets that can be used to instruct Large Language Models (LLMs). By gathering from Wikipedia pages informative content associated with relevant keywords, we use Large Language Models to automatically generate pedagogical clues related to the given input keyword and its context. With such an approach, we created clue-instruct, a dataset containing 44,075 unique examples with text-keyword pairs associated with three distinct crossword clues. We used clue-instruct to instruct different LLMs to generate educational clues from a given input content and keyword. Both human and automatic evaluations confirmed the quality of the generated clues, thus validating the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Characterizing Multimodal Long-form Summarization: A Case Study on  Financial Reports</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06162">https://arxiv.org/abs/2404.06162</a></p>
  <p><b>作者</b>：Tianyu Cao,  Natraj Raman,  Danial Dervovic,  Chenhao Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, natural language processing, language models, large language, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models (LLMs) expand the power of natural language processing to handle long inputs, rigorous and systematic analyses are necessary to understand their abilities and behavior. A salient application is summarization, due to its ubiquity and controversy (e.g., researchers have declared the death of summarization). In this paper, we use financial report summarization as a case study because financial reports not only are long but also use numbers and tables extensively. We propose a computational framework for characterizing multimodal long-form summarization and investigate the behavior of Claude 2.0/2.1, GPT-4/3.5, and Command. We find that GPT-3.5 and Command fail to perform this summarization task meaningfully. For Claude 2 and GPT-4, we analyze the extractiveness of the summary and identify a position bias in LLMs. This position bias disappears after shuffling the input for Claude, which suggests that Claude has the ability to recognize important information. We also conduct a comprehensive investigation on the use of numeric data in LLM-generated summaries and offer a taxonomy of numeric hallucination. We employ prompt engineering to improve GPT-4's use of numbers with limited success. Overall, our analyses highlight the strong capability of Claude 2 in handling long multimodal inputs compared to GPT-4.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：(Not) Understanding Latin Poetic Style with Deep Learning</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06150">https://arxiv.org/abs/2404.06150</a></p>
  <p><b>作者</b>：Ben Nagy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classical Latin verse, understand authorial style, classical Latin, metrical features, configured neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article summarizes some mostly unsuccessful attempts to understand authorial style by examining the attention of various neural networks (LSTMs and CNNs) trained on a corpus of classical Latin verse that has been encoded to include sonic and metrical features. Carefully configured neural networks are shown to be extremely strong authorship classifiers, so it is hoped that they might therefore teach `traditional' readers something about how the authors differ in style. Sadly their reasoning is, so far, inscrutable. While the overall goal has not yet been reached, this work reports some useful findings in terms of effective ways to encode and embed verse, the relative strengths and weaknesses of the neural network families, and useful (and not so useful) techniques for designing and inspecting NN models in this domain. This article suggests that, for poetry, CNNs are better choices than LSTMs -- they train more quickly, have equivalent accuracy, and (potentially) offer better interpretability. Based on a great deal of experimentation, it also suggests that simple, trainable embeddings are more effective than domain-specific schemes, and stresses the importance of techniques to reduce overfitting, like dropout and batch normalization.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Cendol: Open Instruction-tuned Generative Large Language Models for  Indonesian Languages</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06138">https://arxiv.org/abs/2404.06138</a></p>
  <p><b>作者</b>：Samuel Cahyawijaya,  Holy Lovenia,  Fajri Koto,  Rifki Afina Putri,  Emmanuel Dave,  Jhonson Lee,  Nuur Shadieq,  Wawan Cenggoro,  Salsabil Maulana Akbar,  Muhammad Ihza Mahendra,  Dea Annisayanti Putri,  Bryan Wilie,  Genta Indra Winata,  Alham Fikri Aji,  Ayu Purwarianti,  Pascale Fung</p>
  <p><b>备注</b>：Cendol models are released under Apache 2.0 license and will be made publicly available soon</p>
  <p><b>关键词</b>：show remarkable human-like, remarkable human-like capability, show remarkable, remarkable human-like, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) show remarkable human-like capability in various domains and languages. However, a notable quality gap arises in low-resource languages, e.g., Indonesian indigenous languages, rendering them ineffective and inefficient in such linguistic contexts. To bridge this quality gap, we introduce Cendol, a collection of Indonesian LLMs encompassing both decoder-only and encoder-decoder architectures across a range of model sizes. We highlight Cendol's effectiveness across a diverse array of tasks, attaining 20% improvement, and demonstrate its capability to generalize to unseen tasks and indigenous languages of Indonesia. Furthermore, Cendol models showcase improved human favorability despite their limitations in capturing indigenous knowledge and cultural values in Indonesia. In addition, we discuss the shortcomings of parameter-efficient tunings, such as LoRA, for language adaptation. Alternatively, we propose the usage of vocabulary adaptation to enhance efficiency. Lastly, we evaluate the safety of Cendol and showcase that safety in pre-training in one language such as English is transferable to low-resource languages, such as Indonesian, even without RLHF and safety fine-tuning.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for  Hallucination Detection</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06137">https://arxiv.org/abs/2404.06137</a></p>
  <p><b>作者</b>：Elisei Rykov,  Yana Shishkina,  Kseniia Petrushina,  Kseniia Titova,  Sergey Petrakov,  Alexander Panchenko</p>
  <p><b>备注</b>：12 pages, 10 tables, 3 figures</p>
  <p><b>关键词</b>：hallucination detection task, hallucination detection, detection task, systems developed, encompassing diverse baselines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present our novel systems developed for the SemEval-2024 hallucination detection task. Our investigation spans a range of strategies to compare model predictions with reference standards, encompassing diverse baselines, the refinement of pre-trained encoders through supervised learning, and an ensemble approaches utilizing several high-performing models. Through these explorations, we introduce three distinct methods that exhibit strong performance metrics. To amplify our training data, we generate additional training samples from unlabelled training subset. Furthermore, we provide a detailed comparative analysis of our approaches. Notably, our premier method achieved a commendable 9th place in the competition's model-agnostic track and 17th place in model-aware track, highlighting its effectiveness and potential.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Detection of fields of applications in biomedical abstracts with the  support of argumentation elements</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06121">https://arxiv.org/abs/2404.06121</a></p>
  <p><b>作者</b>：Mariana Neves</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potentially improve searching, complete text, scientific literature, potentially improve, improve searching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Focusing on particular facts, instead of the complete text, can potentially improve searching for specific information in the scientific literature. In particular, argumentative elements allow focusing on specific parts of a publication, e.g., the background section or the claims from the authors. We evaluated some tools for the extraction of argumentation elements for a specific task in biomedicine, namely, for detecting the fields of the application in a biomedical publication, e.g, whether it addresses the problem of disease diagnosis or drug development. We performed experiments with the PubMedBERT pre-trained model, which was fine-tuned on a specific corpus for the task. We compared the use of title and abstract to restricting to only some argumentative elements. The top F1 scores ranged from 0.22 to 0.84, depending on the field of application. The best argumentative labels were the ones related the conclusion and background sections of an abstract.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Exploring the Necessity of Visual Modality in Multimodal Machine  Translation using Authentic Datasets</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06107">https://arxiv.org/abs/2404.06107</a></p>
  <p><b>作者</b>：Zi Long,  Zhenhao Tang,  Xianghua Fu,  Jian Chen,  Shilong Hou,  Jinze Lyu</p>
  <p><b>备注</b>：bucc 2024 accepted</p>
  <p><b>关键词</b>：Recent research, marginal advantages, dispensable or offers, offers only marginal, multimodal machine translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research in the field of multimodal machine translation (MMT) has indicated that the visual modality is either dispensable or offers only marginal advantages. However, most of these conclusions are drawn from the analysis of experimental results based on a limited set of bilingual sentence-image pairs, such as Multi30k. In these kinds of datasets, the content of one bilingual parallel sentence pair must be well represented by a manually annotated image, which is different from the real-world translation scenario. In this work, we adhere to the universal multimodal machine translation framework proposed by Tang et al. (2022). This approach allows us to delve into the impact of the visual modality on translation efficacy by leveraging real-world translation datasets. Through a comprehensive exploration via probing tasks, we find that the visual modality proves advantageous for the majority of authentic translation datasets. Notably, the translation performance primarily hinges on the alignment and coherence between textual and visual contents. Furthermore, our results suggest that visual information serves a supplementary role in multimodal translation and can be substituted.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Making Old Kurdish Publications Processable by Augmenting Available  Optical Character Recognition Engines</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06101">https://arxiv.org/abs/2404.06101</a></p>
  <p><b>作者</b>：Blnd Yaseen,  Hossein Hassani</p>
  <p><b>备注</b>：30 pages, 21 figures, 2 tables</p>
  <p><b>关键词</b>：brought to Kurdistan, Optical Character Recognition, Kurdish libraries, early days, days when printing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Kurdish libraries have many historical publications that were printed back in the early days when printing devices were brought to Kurdistan. Having a good Optical Character Recognition (OCR) to help process these publications and contribute to the Kurdish languages resources which is crucial as Kurdish is considered a low-resource language. Current OCR systems are unable to extract text from historical documents as they have many issues, including being damaged, very fragile, having many marks left on them, and often written in non-standard fonts and more. This is a massive obstacle in processing these documents as currently processing them requires manual typing which is very time-consuming. In this study, we adopt an open-source OCR framework by Google, Tesseract version 5.0, that has been used to extract text for various languages. Currently, there is no public dataset, and we developed our own by collecting historical documents from Zheen Center for Documentation and Research, which were printed before 1950 and resulted in a dataset of 1233 images of lines with transcription of each. Then we used the Arabic model as our base model and trained the model using the dataset. We used different methods to evaluate our model, Tesseracts built-in evaluator lstmeval indicated a Character Error Rate (CER) of 0.755%. Additionally, Ocreval demonstrated an average character accuracy of 84.02%. Finally, we developed a web application to provide an easy- to-use interface for end-users, allowing them to interact with the model by inputting an image of a page and extracting the text. Having an extensive dataset is crucial to develop OCR systems with reasonable accuracy, as currently, no public datasets are available for historical Kurdish documents; this posed a significant challenge in our work. Additionally, the unaligned spaces between characters and words proved another challenge with our work.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：All in One: An Empirical Study of GPT for Few-Shot Aspect-Based  Sentiment Anlaysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06063">https://arxiv.org/abs/2404.06063</a></p>
  <p><b>作者</b>：Baoxing Jiang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：natural language processing, Aspect-Based Sentiment Analysis, highly challenging task, Sentiment Analysis, Generative Pre-trained Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aspect-Based Sentiment Analysis (ABSA) is an indispensable and highly challenging task in natural language processing. Current efforts have focused on specific sub-tasks, making it difficult to comprehensively cover all sub-tasks within the ABSA domain. With the development of Generative Pre-trained Transformers (GPTs), there came inspiration for a one-stop solution to sentiment analysis. In this study, we used GPTs for all sub-tasks of few-shot ABSA while defining a general learning paradigm for this application. We propose the All in One (AiO) model, a simple yet effective two-stage model for all ABSA sub-tasks. In the first stage, a specific backbone network learns the semantic information of the review and generates heuristically enhanced candidates. In the second stage, AiO leverages GPT contextual learning capabilities to generate predictions. The study conducted comprehensive comparative and ablation experiments on five benchmark datasets, and the results show that AiO can effectively handle all ABSA sub-tasks, even with few-shot data.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Identifying Shopping Intent in Product QA for Proactive Recommendations</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06017">https://arxiv.org/abs/2404.06017</a></p>
  <p><b>作者</b>：Besnik Fetahu,  Nachshon Cohen,  Elad Haramaty,  Liane Lewin-Eytan,  Oleg Rokhlenko,  Shervin Malmasi</p>
  <p><b>备注</b>：Accepted at IronGraphs@ECIR'2024</p>
  <p><b>关键词</b>：smart devices allowing, instantly access information, devices allowing users, Shopping, ubiquitous in smart</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voice assistants have become ubiquitous in smart devices allowing users to instantly access information via voice questions. While extensive research has been conducted in question answering for voice search, little attention has been paid on how to enable proactive recommendations from a voice assistant to its users. This is a highly challenging problem that often leads to user friction, mainly due to recommendations provided to the users at the wrong time. We focus on the domain of e-commerce, namely in identifying Shopping Product Questions (SPQs), where the user asking a product-related question may have an underlying shopping need. Identifying a user's shopping need allows voice assistants to enhance shopping experience by determining when to provide recommendations, such as product or deal recommendations, or proactive shopping actions recommendation. Identifying SPQs is a challenging problem and cannot be done from question text alone, and thus requires to infer latent user behavior patterns inferred from user's past shopping history. We propose features that capture the user's latent shopping behavior from their purchase history, and combine them using a novel Mixture-of-Experts (MoE) model. Our evaluation shows that the proposed approach is able to identify SPQs with a high score of F1=0.91. Furthermore, based on an online evaluation with real voice assistant users, we identify SPQs in real-time and recommend shopping actions to users to add the queried product into their shopping list. We demonstrate that we are able to accurately identify SPQs, as indicated by the significantly higher rate of added products to users' shopping lists when being prompted after SPQs vs random PQs.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free  Information Retrieval</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06004">https://arxiv.org/abs/2404.06004</a></p>
  <p><b>作者</b>：Kento Tatsuno,  Daisuke Miyashita,  Taiga Ikeda,  Kiyoshi Ishiyama,  Kazunari Sumiyoshi,  Jun Deguchi</p>
  <p><b>备注</b>：5 pages, 6 figures and 4 tables</p>
  <p><b>关键词</b>：approximate proximity graphs, approximate nearest neighbor, good recall-speed balance, DiskANN achieves good, achieves good recall-speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In approximate nearest neighbor search (ANNS) methods based on approximate proximity graphs, DiskANN achieves good recall-speed balance for large-scale datasets using both of RAM and storage. Despite it claims to save memory usage by loading compressed vectors by product quantization (PQ), its memory usage increases in proportion to the scale of datasets. In this paper, we propose All-in-Storage ANNS with Product Quantization (AiSAQ), which offloads the compressed vectors to storage. Our method achieves $\sim$10 MB memory usage in query search even with billion-scale datasets with minor performance degradation. AiSAQ also reduces the index load time before query search, which enables the index switch between muitiple billion-scale datasets and significantly enhances the flexibility of retrieval-augmented generation (RAG). This method is applicable to all graph-based ANNS algorithms and can be combined with higher-spec ANNS methods in the future.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation  of Large Language Models</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06003">https://arxiv.org/abs/2404.06003</a></p>
  <p><b>作者</b>：Zhuohao Yu,  Chang Gao,  Wenjin Yao,  Yidong Wang,  Zhengran Zeng,  Wei Ye,  Jindong Wang,  Yue Zhang,  Shikun Zhang</p>
  <p><b>备注</b>：We open-source all our code at: this https URL</p>
  <p><b>关键词</b>：large language model, language model, rapid development, development of large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid development of large language model (LLM) evaluation methodologies and datasets has led to a profound challenge: integrating state-of-the-art evaluation techniques cost-effectively while ensuring reliability, reproducibility, and efficiency. Currently, there is a notable absence of a unified and adaptable framework that seamlessly integrates various evaluation approaches. Moreover, the reliability of evaluation findings is often questionable due to potential data contamination, with the evaluation efficiency commonly overlooked when facing the substantial costs associated with LLM inference. In response to these challenges, we introduce FreeEval, a modular and scalable framework crafted to enable trustworthy and efficient automatic evaluations of LLMs. Firstly, FreeEval's unified abstractions simplify the integration and improve the transparency of diverse evaluation methodologies, encompassing dynamic evaluation that demand sophisticated LLM interactions. Secondly, the framework integrates meta-evaluation techniques like human evaluation and data contamination detection, which, along with dynamic evaluation modules in the platform, enhance the fairness of the evaluation outcomes. Lastly, FreeEval is designed with a high-performance infrastructure, including distributed computation and caching strategies, enabling extensive evaluations across multi-node, multi-GPU clusters for open-source and proprietary LLMs.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Privacy Preserving Prompt Engineering: A Survey</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06001">https://arxiv.org/abs/2404.06001</a></p>
  <p><b>作者</b>：Kennedy Edemacu,  Xintao Wu</p>
  <p><b>备注</b>：23 pages, 8 figures</p>
  <p><b>关键词</b>：demonstrated significant proficiency, natural language processing, Pre-trained language models, general natural language, demonstrated significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models (PLMs) have demonstrated significant proficiency in solving a wide range of general natural language processing (NLP) tasks. Researchers have observed a direct correlation between the performance of these models and their sizes. As a result, the sizes of these models have notably expanded in recent years, persuading researchers to adopt the term large language models (LLMs) to characterize the larger-sized PLMs. The increased size is accompanied by a distinct capability known as in-context learning (ICL), which represents a specialized form of prompting. This enables the utilization of LLMs for specific downstream tasks by presenting them with demonstration examples while keeping the model parameters frozen. Although interesting, privacy concerns have become a major obstacle in its widespread usage. Multiple studies have examined the privacy risks linked to ICL and prompting in general, and have devised techniques to alleviate these risks. Thus, there is a necessity to organize these mitigation techniques for the benefit of the community. This survey provides a systematic overview of the privacy protection methods employed during ICL and prompting in general. We review, analyze, and compare different methods under this paradigm. Furthermore, we provide a summary of the resources accessible for the development of these frameworks. Finally, we discuss the limitations of these frameworks and offer a detailed examination of the promising areas that necessitate further exploration.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM  Experts</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05993">https://arxiv.org/abs/2404.05993</a></p>
  <p><b>作者</b>：Shaona Ghosh,  Prasoon Varshney,  Erick Galinkin,  Christopher Parisien</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, content safety, safety</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As Large Language Models (LLMs) and generative AI become more widespread, the content safety risks associated with their use also increase. We find a notable deficiency in high-quality content safety datasets and benchmarks that comprehensively cover a wide range of critical safety areas. To address this, we define a broad content safety risk taxonomy, comprising 13 critical risk and 9 sparse risk categories. Additionally, we curate AEGISSAFETYDATASET, a new dataset of approximately 26, 000 human-LLM interaction instances, complete with human annotations adhering to the taxonomy. We plan to release this dataset to the community to further research and to help benchmark LLM models for safety. To demonstrate the effectiveness of the dataset, we instruction-tune multiple LLM-based safety models. We show that our models (named AEGISSAFETYEXPERTS), not only surpass or perform competitively with the state-of-the-art LLM-based safety models and general purpose LLMs, but also exhibit robustness across multiple jail-break attack categories. We also show how using AEGISSAFETYDATASET during the LLM alignment phase does not negatively impact the performance of the aligned models on MT Bench scores. Furthermore, we propose AEGIS, a novel application of a no-regret online adaptation framework with strong theoretical guarantees, to perform content moderation with an ensemble of LLM content safety experts in deployment</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Event-enhanced Retrieval in Real-time Search</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05989">https://arxiv.org/abs/2404.05989</a></p>
  <p><b>作者</b>：Yanan Zhang,  Xiaoling Bai,  Tianhua Zhou</p>
  <p><b>备注</b>：LREC-COLING 2024</p>
  <p><b>关键词</b>：eliminating LLM illusions, recent retrieval-augmented methods, LLM illusions, eliminating LLM, engine retrieval systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The embedding-based retrieval (EBR) approach is widely used in mainstream search engine retrieval systems and is crucial in recent retrieval-augmented methods for eliminating LLM illusions. However, existing EBR models often face the "semantic drift" problem and insufficient focus on key information, leading to a low adoption rate of retrieval results in subsequent steps. This issue is especially noticeable in real-time search scenarios, where the various expressions of popular events on the Internet make real-time retrieval heavily reliant on crucial event information. To tackle this problem, this paper proposes a novel approach called EER, which enhances real-time retrieval performance by improving the dual-encoder model of traditional EBR. We incorporate contrastive learning to accompany pairwise learning for encoder optimization. Furthermore, to strengthen the focus on critical event information in events, we include a decoder module after the document encoder, introduce a generative event triplet extraction scheme based on prompt-tuning, and correlate the events with query encoder optimization through comparative learning. This decoder module can be removed during inference. Extensive experiments demonstrate that EER can significantly improve the real-time search retrieval performance. We believe that this approach will provide new perspectives in the field of information retrieval. The codes and dataset are available at this https URL .</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Does Transformer Interpretability Transfer to RNNs?</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05971">https://arxiv.org/abs/2404.05971</a></p>
  <p><b>作者</b>：Gonçalo Paulo,  Thomas Marshall,  Nora Belrose</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Mamba and RWKV, neural network architectures, recurrent neural network, language modeling perplexity, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in recurrent neural network architectures, such as Mamba and RWKV, have enabled RNNs to match or exceed the performance of equal-size transformers in terms of language modeling perplexity and downstream evaluations, suggesting that future systems may be built on completely new architectures. In this paper, we examine if selected interpretability methods originally designed for transformer language models will transfer to these up-and-coming recurrent architectures. Specifically, we focus on steering model outputs via contrastive activation addition, on eliciting latent predictions via the tuned lens, and eliciting latent knowledge from models fine-tuned to produce false outputs under certain conditions. Our results show that most of these techniques are effective when applied to RNNs, and we show that it is possible to improve some of them by taking advantage of RNNs' compressed state.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Optimization Methods for Personalizing Large Language Models through  Retrieval Augmentation</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05970">https://arxiv.org/abs/2404.05970</a></p>
  <p><b>作者</b>：Alireza Salemi,  Surya Kallumadi,  Hamed Zamani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：studies retrieval-augmented approaches, large language models, personalizing large language, paper studies retrieval-augmented, applications and domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies retrieval-augmented approaches for personalizing large language models (LLMs), which potentially have a substantial impact on various applications and domains. We propose the first attempt to optimize the retrieval models that deliver a limited number of personal documents to large language models for the purpose of personalized generation. We develop two optimization algorithms that solicit feedback from the downstream personalized generation tasks for retrieval optimization--one based on reinforcement learning whose reward function is defined using any arbitrary metric for personalized generation and another based on knowledge distillation from the downstream LLM to the retrieval model. This paper also introduces a pre- and post-generation retriever selection model that decides what retriever to choose for each LLM input. Extensive experiments on diverse tasks from the language model personalization (LaMP) benchmark reveal statistically significant improvements in six out of seven datasets.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：JSTR: Judgment Improves Scene Text Recognition</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05967">https://arxiv.org/abs/2404.05967</a></p>
  <p><b>作者</b>：Masato Fujitake</p>
  <p><b>备注</b>：IntelliSys 2024</p>
  <p><b>关键词</b>：text recognition tasks, scene text recognition, text recognition, text recognition accuracy, tasks by judging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a method for enhancing the accuracy of scene text recognition tasks by judging whether the image and text match each other. While previous studies focused on generating the recognition results from input images, our approach also considers the model's misrecognition results to understand its error tendencies, thus improving the text recognition pipeline. This method boosts text recognition accuracy by providing explicit feedback on the data that the model is likely to misrecognize by predicting correct or incorrect between the image and text. The experimental results on publicly available datasets demonstrate that our proposed method outperforms the baseline and state-of-the-art methods in scene text recognition.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：THOUGHTSCULPT: Reasoning with Intermediate Revision and Search</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05966">https://arxiv.org/abs/2404.05966</a></p>
  <p><b>作者</b>：Yizhou Chi,  Kevin Yang,  Dan Klein</p>
  <p><b>备注</b>：Code and data available at this https URL</p>
  <p><b>关键词</b>：Monte Carlo Tree, Carlo Tree Search, decomposed into components, Story Outline Improvement, present THOUGHTSCULPT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present THOUGHTSCULPT, a general reasoning and search method for tasks with outputs that can be decomposed into components. THOUGHTSCULPT explores a search tree of potential solutions using Monte Carlo Tree Search (MCTS), building solutions one action at a time and evaluating according to any domain-specific heuristic, which in practice is often simply an LLM evaluator. Critically, our action space includes revision actions: THOUGHTSCULPT may choose to revise part of its previous output rather than continuing to build the rest of its output. Empirically, THOUGHTSCULPT outperforms state-of-the-art reasoning methods across three challenging tasks: Story Outline Improvement (up to +30% interestingness), Mini-Crosswords Solving (up to +16% word success rate), and Constrained Generation (up to +10% concept coverage).</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05961">https://arxiv.org/abs/2404.05961</a></p>
  <p><b>作者</b>：Parishad BehnamGhader,  Vaibhav Adlakha,  Marius Mosbach,  Dzmitry Bahdanau,  Nicolas Chapados,  Siva Reddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：today NLP tasks, today NLP, NLP tasks, NLP, Text Embeddings Benchmark</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large decoder-only language models (LLMs) are the state-of-the-art models on most of today's NLP tasks and benchmarks. Yet, the community is only slowly adopting these models for text embedding tasks, which require rich contextualized representations. In this work, we introduce LLM2Vec, a simple unsupervised approach that can transform any decoder-only LLM into a strong text encoder. LLM2Vec consists of three simple steps: 1) enabling bidirectional attention, 2) masked next token prediction, and 3) unsupervised contrastive learning. We demonstrate the effectiveness of LLM2Vec by applying it to 3 popular LLMs ranging from 1.3B to 7B parameters and evaluate the transformed models on English word- and sequence-level tasks. We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB). Moreover, when combining LLM2Vec with supervised contrastive learning, we achieve state-of-the-art performance on MTEB among models that train only on publicly available data. Our strong empirical results and extensive analysis demonstrate that LLMs can be effectively transformed into universal text encoders in a parameter-efficient manner without the need for expensive adaptation or synthetic GPT-4 generated data.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page  Understanding and Grounding?</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05955">https://arxiv.org/abs/2404.05955</a></p>
  <p><b>作者</b>：Junpeng Liu,  Yifan Song,  Bill Yuchen Lin,  Wai Lam,  Graham Neubig,  Yuanzhi Li,  Xiang Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language models, Multimodal Large Language, Large Language, Language models, web domain remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal Large Language models (MLLMs) have shown promise in web-related tasks, but evaluating their performance in the web domain remains a challenge due to the lack of comprehensive benchmarks. Existing benchmarks are either designed for general multimodal tasks, failing to capture the unique characteristics of web pages, or focus on end-to-end web agent tasks, unable to measure fine-grained abilities such as OCR, understanding, and grounding. In this paper, we introduce \bench{}, a multimodal benchmark designed to assess the capabilities of MLLMs across a variety of web tasks. \bench{} consists of seven tasks, and comprises 1.5K human-curated instances from 139 real websites, covering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3 series, and GPT-4V(ision) on \bench{}, revealing significant challenges and performance gaps. Further analysis highlights the limitations of current MLLMs, including inadequate grounding in text-rich environments and subpar performance with low-resolution image inputs. We believe \bench{} will serve as a valuable resource for the research community and contribute to the creation of more powerful and versatile MLLMs for web-related applications.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Interplay of Machine Translation, Diacritics, and Diacritization</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05943">https://arxiv.org/abs/2404.05943</a></p>
  <p><b>作者</b>：Wei-Rui Chen,  Ife Adebara,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：Accepted to NAACL 2024 Main Conference</p>
  <p><b>关键词</b>：multi-task learning setting, machine translation, effect of keeping, multi-task learning, research questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate two research questions: (1) how do machine translation (MT) and diacritization influence the performance of each other in a multi-task learning setting (2) the effect of keeping (vs. removing) diacritics on MT performance. We examine these two questions in both high-resource (HR) and low-resource (LR) settings across 55 different languages (36 African languages and 19 European languages). For (1), results show that diacritization significantly benefits MT in the LR scenario, doubling or even tripling performance for some languages, but harms MT in the HR scenario. We find that MT harms diacritization in LR but benefits significantly in HR for some languages. For (2), MT performance is similar regardless of diacritics being kept or removed. In addition, we propose two classes of metrics to measure the complexity of a diacritical system, finding these metrics to correlate positively with the performance of our diacritization models. Overall, our work provides insights for developing MT and diacritization systems under different data size conditions and may have implications that generalize beyond the 55 languages we investigate.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：The Hallucinations Leaderboard -- An Open Effort to Measure  Hallucinations in Large Language Models</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05904">https://arxiv.org/abs/2404.05904</a></p>
  <p><b>作者</b>：Giwon Hong,  Aryo Pradipta Gema,  Rohit Saxena,  Xiaotang Du,  Ping Nie,  Yu Zhao,  Laura Perez-Beltrachini,  Max Ryabinin,  Xuanli He,  Pasquale Minervini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Large Language Models, Language Processing, generate human-like text, Natural Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have transformed the Natural Language Processing (NLP) landscape with their remarkable ability to understand and generate human-like text. However, these models are prone to ``hallucinations'' -- outputs that do not align with factual reality or the input context. This paper introduces the Hallucinations Leaderboard, an open initiative to quantitatively measure and compare the tendency of each model to produce hallucinations. The leaderboard uses a comprehensive set of benchmarks focusing on different aspects of hallucinations, such as factuality and faithfulness, across various tasks, including question-answering, summarisation, and reading comprehension. Our analysis provides insights into the performance of different models, guiding researchers and practitioners in choosing the most reliable models for their applications.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05902">https://arxiv.org/abs/2404.05902</a></p>
  <p><b>作者</b>：Michael Lutz,  Arth Bohra,  Manvel Saroyan,  Artem Harutyunyan,  Giovanni Campagna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieving both generalization, challenging problem, generalization and accuracy, accuracy remains, remains a challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of web agent research, achieving both generalization and accuracy remains a challenging problem. Due to high variance in website structure, existing approaches often fail. Moreover, existing fine-tuning and in-context learning techniques fail to generalize across multiple websites. We introduce Wilbur, an approach that uses a differentiable ranking model and a novel instruction synthesis technique to optimally populate a black-box large language model's prompt with task demonstrations from previous runs. To maximize end-to-end success rates, we also propose an intelligent backtracking mechanism that learns and recovers from its mistakes. Finally, we show that our ranking model can be trained on data from a generative auto-curriculum which samples representative goals from an LLM, runs the agent, and automatically evaluates it, with no manual annotation. Wilbur achieves state-of-the-art results on the WebVoyager benchmark, beating text-only models by 8% overall, and up to 36% on certain websites. On the same benchmark, Wilbur is within 5% of a strong multi-modal model despite only receiving textual inputs, and further analysis reveals a substantial number of failures are due to engineering challenges of operating the web.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Use of a Structured Knowledge Base Enhances Metadata Curation by Large  Language Models</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05893">https://arxiv.org/abs/2404.05893</a></p>
  <p><b>作者</b>：Sowmya S. Sundaram,  Benjamin Solomon,  Avani Khatri,  Anisha Laumas,  Purvesh Khatri,  Mark A. Musen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ensuring the findability, reusability of datasets, play a crucial, crucial role, role in ensuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Metadata play a crucial role in ensuring the findability, accessibility, interoperability, and reusability of datasets. This paper investigates the potential of large language models (LLMs), specifically GPT-4, to improve adherence to metadata standards. We conducted experiments on 200 random data records describing human samples relating to lung cancer from the NCBI BioSample repository, evaluating GPT-4's ability to suggest edits for adherence to metadata standards. We computed the adherence accuracy of field name-field value pairs through a peer review process, and we observed a marginal average improvement in adherence to the standard data dictionary from 79% to 80% (p<0.01). we then prompted gpt-4 with domain information in the form of textual descriptions cedar templates and recorded a significant improvement to 97% from 79% (p<0.01). these results indicate that, while llms may not be able correct legacy metadata ensure satisfactory adherence standards when unaided, they do show promise for use automated curation integrated structured knowledge base.< p>
  </0.01).></p></details>
</details>
<details>
  <summary>53. <b>标题：Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05892">https://arxiv.org/abs/2404.05892</a></p>
  <p><b>作者</b>：Bo Peng,  Daniel Goldstein,  Quentin Anthony,  Alon Albalak,  Eric Alcaide,  Stella Biderman,  Eugene Cheah,  Teddy Ferdinan,  Haowen Hou,  Przemysław Kazienko,  Kranthi Kiran GV,  Jan Kocoń,  Bartłomiej Koptyra,  Satyapriya Krishna,  Ronald McClelland Jr.,  Niklas Muennighoff,  Fares Obeid,  Atsushi Saito,  Guangyu Song,  Haoqin Tu,  Stanisław Woźniak,  Ruichong Zhang,  Bingchen Zhao,  Qihang Zhao,  Peng Zhou,  Jian Zhu,  Rui-Jie Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sequence models improving, https URL, present Eagle, RWKV, https URL Time-parallel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of benchmarks. We release all our models on HuggingFace under the Apache 2.0 license. Models at: this https URL Training code at: this https URL Inference code at: this https URL Time-parallel training code at: this https URL</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Eraser: Jailbreaking Defense in Large Language Models via Unlearning  Harmful Knowledge</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05880">https://arxiv.org/abs/2404.05880</a></p>
  <p><b>作者</b>：Weikai Lu,  Ziqian Zeng,  Jianwei Wang,  Zhengdong Lu,  Zelin Chen,  Huiping Zhuang,  Cen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enable Large Language, Large Language Models, Large Language, generate harmful content, enable Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jailbreaking attacks can enable Large Language Models (LLMs) to bypass the safeguard and generate harmful content. Existing jailbreaking defense methods have failed to address the fundamental issue that harmful knowledge resides within the model, leading to potential jailbreak risks for LLMs. In this paper, we propose a novel defense method called Eraser, which mainly includes three goals: unlearning harmful knowledge, retaining general knowledge, and maintaining safety alignment. The intuition is that if an LLM forgets the specific knowledge required to answer a harmful question, it will no longer have the ability to answer harmful questions. The training of Erase does not actually require the model's own harmful knowledge, and it can benefit from unlearning general answers related to harmful queries, which means it does not need assistance from the red team. The experimental results show that Eraser can significantly reduce the jailbreaking success rate for various attacks without compromising the general capabilities of the model.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：CodecLM: Aligning Language Models with Tailored Synthetic Data</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05875">https://arxiv.org/abs/2404.05875</a></p>
  <p><b>作者</b>：Zifeng Wang,  Chun-Liang Li,  Vincent Perot,  Long T. Le,  Jin Miao,  Zizhao Zhang,  Chen-Yu Lee,  Tomas Pfister</p>
  <p><b>备注</b>：Accepted to Findings of NAACL 2024</p>
  <p><b>关键词</b>：large language models, users' actual goals, aligning large language, next-token prediction objective, specific task instructions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users' actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data. Recent works focus on generating diverse instructions and applying LLM to increase instruction complexity, often neglecting downstream use cases. It remains unclear how to tailor high-quality data to elicit better instruction-following abilities in different target instruction distributions and LLMs. To this end, we introduce CodecLM, a general framework for adaptively generating high-quality synthetic data for LLM alignment with different downstream instruction distributions and LLMs. Drawing on the Encode-Decode principles, we use LLMs as codecs to guide the data generation process. We first encode seed instructions into metadata, which are concise keywords generated on-the-fly to capture the target instruction distribution, and then decode metadata to create tailored instructions. We also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain instruction following benchmarks validate the effectiveness of CodecLM over the current state-of-the-arts.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Negative Preference Optimization: From Catastrophic Collapse to  Effective Unlearning</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05868">https://arxiv.org/abs/2404.05868</a></p>
  <p><b>作者</b>：Ruiqi Zhang,  Licong Lin,  Yu Bai,  Song Mei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, model utilities, LLM unlearning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) often memorize sensitive, private, or copyrighted data during pre-training. LLM unlearning aims to eliminate the influence of undesirable data from the pre-trained model while preserving the model's utilities on other tasks. Several practical methods have recently been proposed for LLM unlearning, mostly based on gradient ascent (GA) on the loss of undesirable data. However, on certain unlearning tasks, these methods either fail to effectively unlearn the target data or suffer from catastrophic collapse -- a drastic degradation of the model's utilities.
In this paper, we propose Negative Preference Optimization (NPO), a simple alignment-inspired method that could efficiently and effectively unlearn a target dataset. We theoretically show that the progression toward catastrophic collapse by minimizing the NPO loss is exponentially slower than GA. Through experiments on synthetic data and the benchmark TOFU dataset, we demonstrate that NPO-based methods achieve a better balance between unlearning the undesirable data and maintaining the model's utilities. We also observe that NPO-based methods generate more sensible outputs than GA-based methods, whose outputs are often gibberish. Remarkably, on TOFU, NPO-based methods are the first to achieve reasonable unlearning results in forgetting 50% (or more) of the training data, whereas existing methods already struggle with forgetting 10% of training data.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：GeniL: A Multilingual Dataset on Generalizing Language</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05866">https://arxiv.org/abs/2404.05866</a></p>
  <p><b>作者</b>：Aida Mostafazadeh Davani,  Sagar Gubbi,  Sunipa Dev,  Shachi Dave,  Vinodkumar Prabhakaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：societal biases learned, inherit societal biases, instance stereotypes associating, LLMs are increasingly, digital ecosystem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LLMs are increasingly transforming our digital ecosystem, but they often inherit societal biases learned from their training data, for instance stereotypes associating certain attributes with specific identity groups. While whether and how these biases are mitigated may depend on the specific use cases, being able to effectively detect instances of stereotype perpetuation is a crucial first step. Current methods to assess presence of stereotypes in generated language rely on simple template or co-occurrence based measures, without accounting for the variety of sentential contexts they manifest in. We argue that understanding the sentential context is crucial for detecting instances of generalization. We distinguish two types of generalizations: (1) language that merely mentions the presence of a generalization ("people think the French are very rude"), and (2) language that reinforces such a generalization ("as French they must be rude"), from non-generalizing context ("My French friends think I am rude"). For meaningful stereotype evaluations, we need to reliably distinguish such instances of generalizations. We introduce the new task of detecting generalization in language, and build GeniL, a multilingual dataset of over 50K sentences from 9 languages (English, Arabic, Bengali, Spanish, French, Hindi, Indonesian, Malay, and Portuguese) annotated for instances of generalizations. We demonstrate that the likelihood of a co-occurrence being an instance of generalization is usually low, and varies across different languages, identity groups, and attributes. We build classifiers to detect generalization in language with an overall PR-AUC of 58.7, with varying degrees of performance across languages. Our research provides data and tools to enable a nuanced understanding of stereotype perpetuation, a crucial step towards more inclusive and responsible language technologies.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Softmax Attention with Constant Cost per Token</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05843">https://arxiv.org/abs/2404.05843</a></p>
  <p><b>作者</b>：Franz A. Heinsen</p>
  <p><b>备注</b>：Source code and instructions for replicating our results are online at this https URL</p>
  <p><b>关键词</b>：quantifying pairwise query-key, pairwise query-key similarity, attention mechanism applied, scaled dot-products, applied by Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a simple modification to the conventional attention mechanism applied by Transformers: Instead of quantifying pairwise query-key similarity with scaled dot-products, we quantify it with the logarithms of scaled dot-products of exponentials. Attention becomes expressible as a composition of log-sums of exponentials that is linearizable, with a latent space of constant size, enabling sequential application with constant time and space complexity per token. We implement our modification, verify that it works in practice, and conclude that it is a promising alternative to conventional attention.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05839">https://arxiv.org/abs/2404.05839</a></p>
  <p><b>作者</b>：Milan Straka,  Jana Straková,  Federica Gamba</p>
  <p><b>备注</b>：Accepted to EvaLatin 2024</p>
  <p><b>关键词</b>：Parsing shared task, Dependency Parsing shared, Dependency Parsing, present LatinPipe, shared task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present LatinPipe, the winning submission to the EvaLatin 2024 Dependency Parsing shared task. Our system consists of a fine-tuned concatenation of base and large pre-trained LMs, with a dot-product attention head for parsing and softmax classification heads for morphology to jointly learn both dependency parsing and morphological analysis. It is trained by sampling from seven publicly available Latin corpora, utilizing additional harmonization of annotations to achieve a more unified annotation style. Before fine-tuning, we train the system for a few initial epochs with frozen weights. We also add additional local relative contextualization by stacking the BiLSTM layers on top of the Transformer(s). Finally, we ensemble output probability distributions from seven randomly instantiated networks for the final submission. The code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：SambaLingo: Teaching Large Language Models New Languages</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05829">https://arxiv.org/abs/2404.05829</a></p>
  <p><b>作者</b>：Zoltan Csaki,  Bo Li,  Jonathan Li,  Qiantong Xu,  Pian Pawakapan,  Leon Zhang,  Yun Du,  Hengyu Zhao,  Changran Hu,  Urmish Thakker</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：widespread availability, remains a substantial, substantial gap, availability across diverse, capabilities and availability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the widespread availability of LLMs, there remains a substantial gap in their capabilities and availability across diverse languages. One approach to address these issues has been to take an existing pre-trained LLM and continue to train it on new languages. While prior works have experimented with language adaptation, many questions around best practices and methodology have not been covered. In this paper, we present a comprehensive investigation into the adaptation of LLMs to new languages. Our study covers the key components in this process, including vocabulary extension, direct preference optimization and the data scarcity problem for human alignment in low-resource languages. We scale these experiments across 9 languages and 2 parameter scales (7B and 70B). We compare our models against Llama 2, Aya-101, XGLM, BLOOM and existing language experts, outperforming all prior published baselines. Additionally, all evaluation code and checkpoints are made public to facilitate future research.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Responsible Generative AI: What to Generate and What Not</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05783">https://arxiv.org/abs/2404.05783</a></p>
  <p><b>作者</b>：Jindong Gu</p>
  <p><b>备注</b>：74 pages, 10 figures</p>
  <p><b>关键词</b>：received significant attention, large language models, large language, received significant, significant attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, generative AI (GenAI), like large language models and text-to-image models, has received significant attention across various domains. However, ensuring the responsible generation of content by these models is crucial for their real-world applicability. This raises an interesting question: \textit{What should responsible GenAI generate, and what should it not?} To answer the question, this paper investigates the practical responsible requirements of both textual and visual generative models, outlining five key considerations: generating truthful content, avoiding toxic content, refusing harmful instruction, leaking no training data-related content, and ensuring generated content identifiable. Specifically, we review recent advancements and challenges in addressing these requirements. Besides, we discuss and emphasize the importance of responsible GenAI across healthcare, education, finance, and artificial general intelligence domains. Through a unified perspective on both textual and visual generative models, this paper aims to provide insights into practical safety-related issues and further benefit the community in building responsible GenAI.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Enhancing Inference Efficiency of Large Language Models: Investigating  Optimization Strategies and Architectural Innovations</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05741">https://arxiv.org/abs/2404.05741</a></p>
  <p><b>作者</b>：Georgy Tyukin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, models train quicker, Language Models, train quicker</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models are growing in size, and we expect them to continue to do so, as larger models train quicker. However, this increase in size will severely impact inference costs. Therefore model compression is important, to retain the performance of larger models, but with a reduced cost of running them. In this thesis we explore the methods of model compression, and we empirically demonstrate that the simple method of skipping latter attention sublayers in Transformer LLMs is an effective method of model compression, as these layers prove to be redundant, whilst also being incredibly computationally expensive. We observed a 21% speed increase in one-token generation for Llama 2 7B, whilst surprisingly and unexpectedly improving performance over several common benchmarks.</p>
  </details>
</details>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model  Handling Resolutions from 336 Pixels to 4K HD</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06512">https://arxiv.org/abs/2404.06512</a></p>
  <p><b>作者</b>：Xiaoyi Dong,  Pan Zhang,  Yuhang Zang,  Yuhang Cao,  Bin Wang,  Linke Ouyang,  Songyang Zhang,  Haodong Duan,  Wenwei Zhang,  Yining Li,  Hang Yan,  Yang Gao,  Zhe Chen,  Xinyue Zhang,  Wei Li,  Jingwen Li,  Wenhai Wang,  Kai Chen,  Conghui He,  Xingcheng Zhang,  Jifeng Dai,  Yu Qiao,  Dahua Lin,  Jiaqi Wang</p>
  <p><b>备注</b>：Code and models are publicly available at this https URL</p>
  <p><b>关键词</b>：Large Vision-Language Model, comprehending fine-grained visual, fine-grained visual content, visual content due, Large Vision-Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Large Vision-Language Model (LVLM) field has seen significant advancements, yet its progression has been hindered by challenges in comprehending fine-grained visual content due to limited resolution. Recent efforts have aimed to enhance the high-resolution understanding capabilities of LVLMs, yet they remain capped at approximately 1500 x 1500 pixels and constrained to a relatively narrow resolution range. This paper represents InternLM-XComposer2-4KHD, a groundbreaking exploration into elevating LVLM resolution capabilities up to 4K HD (3840 x 1600) and beyond. Concurrently, considering the ultra-high resolution may not be necessary in all scenarios, it supports a wide range of diverse resolutions from 336 pixels to 4K standard, significantly broadening its scope of applicability. Specifically, this research advances the patch division paradigm by introducing a novel extension: dynamic resolution with automatic patch configuration. It maintains the training image aspect ratios while automatically varying patch counts and configuring layouts based on a pre-trained Vision Transformer (ViT) (336 x 336), leading to dynamic training resolution from 336 pixels to 4K standard. Our research demonstrates that scaling training resolution up to 4K HD leads to consistent performance enhancements without hitting the ceiling of potential improvements. InternLM-XComposer2-4KHD shows superb capability that matches or even surpasses GPT-4V and Gemini Pro in 10 of the 16 benchmarks. The InternLM-XComposer2-4KHD model series with 7B parameters are publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：MoReVQA: Exploring Modular Reasoning Models for Video Question Answering</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06511">https://arxiv.org/abs/2404.06511</a></p>
  <p><b>作者</b>：Juhong Min,  Shyamal Buch,  Arsha Nagrani,  Minsu Cho,  Cordelia Schmid</p>
  <p><b>备注</b>：CVPR 2024</p>
  <p><b>关键词</b>：video question answering, modular reasoning framework, question answering, paper addresses, video question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the task of video question answering (videoQA) via a decomposed multi-stage, modular reasoning framework. Previous modular methods have shown promise with a single planning stage ungrounded in visual content. However, through a simple and effective baseline, we find that such systems can lead to brittle behavior in practice for challenging videoQA settings. Thus, unlike traditional single-stage planning methods, we propose a multi-stage system consisting of an event parser, a grounding stage, and a final reasoning stage in conjunction with an external memory. All stages are training-free, and performed using few-shot prompting of large models, creating interpretable intermediate outputs at each stage. By decomposing the underlying planning and task complexity, our method, MoReVQA, improves over prior work on standard videoQA benchmarks (NExT-QA, iVQA, EgoSchema, ActivityNet-QA) with state-of-the-art results, and extensions to related tasks (grounded videoQA, paragraph captioning).</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Can Feedback Enhance Semantic Grounding in Large Vision-Language Models?</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06510">https://arxiv.org/abs/2404.06510</a></p>
  <p><b>作者</b>：Yuan-Hong Liao,  Rafid Mahmood,  Sanja Fidler,  David Acuna</p>
  <p><b>备注</b>：31 pages, 15 figures</p>
  <p><b>关键词</b>：collecting domain-specific training, involves collecting domain-specific, domain-specific training data, network architectures, training recipes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Enhancing semantic grounding abilities in Vision-Language Models (VLMs) often involves collecting domain-specific training data, refining the network architectures, or modifying the training recipes. In this work, we venture into an orthogonal direction and explore whether VLMs can improve their semantic grounding by "receiving" feedback, without requiring in-domain data, fine-tuning, or modifications to the network architectures. We systematically analyze this hypothesis using a feedback mechanism composed of a binary signal. We find that if prompted appropriately, VLMs can utilize feedback both in a single step and iteratively, showcasing the potential of feedback as an alternative technique to improve grounding in internet-scale VLMs. Furthermore, VLMs, like LLMs, struggle to self-correct errors out-of-the-box. However, we find that this issue can be mitigated via a binary verification mechanism. Finally, we explore the potential and limitations of amalgamating these findings and applying them iteratively to automatically enhance VLMs' grounding performance, showing grounding accuracy consistently improves using automated feedback across all models in all settings investigated. Overall, our iterative framework improves semantic grounding in VLMs by more than 15 accuracy points under noise-free feedback and up to 5 accuracy points under a simple automated binary verification mechanism. The project website is hosted at this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Reconstructing Hand-Held Objects in 3D</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06507">https://arxiv.org/abs/2404.06507</a></p>
  <p><b>作者</b>：Jane Wu,  Georgios Pavlakos,  Georgia Gkioxari,  Jitendra Malik</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：object, hand, Objects manipulated, single RGB image, RGB images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objects manipulated by the hand (i.e., manipulanda) are particularly challenging to reconstruct from in-the-wild RGB images or videos. Not only does the hand occlude much of the object, but also the object is often only visible in a small number of image pixels. At the same time, two strong anchors emerge in this setting: (1) estimated 3D hands help disambiguate the location and scale of the object, and (2) the set of manipulanda is small relative to all possible objects. With these insights in mind, we present a scalable paradigm for handheld object reconstruction that builds on recent breakthroughs in large language/vision models and 3D object datasets. Our model, MCC-Hand-Object (MCC-HO), jointly reconstructs hand and object geometry given a single RGB image and inferred 3D hand as inputs. Subsequently, we use GPT-4(V) to retrieve a 3D object model that matches the object in the image and rigidly align the model to the network-inferred geometry; we call this alignment Retrieval-Augmented Reconstruction (RAR). Experiments demonstrate that MCC-HO achieves state-of-the-art performance on lab and Internet datasets, and we show how RAR can be used to automatically obtain 3D labels for in-the-wild images of hand-object interactions.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Flying with Photons: Rendering Novel Views of Propagating Light</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06493">https://arxiv.org/abs/2404.06493</a></p>
  <p><b>作者</b>：Anagh Malik,  Noah Juravsky,  Ryan Po,  Gordon Wetzstein,  Kiriakos N. Kutulakos,  David B. Lindell</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：moving camera viewpoints, technique that seeks, seeks to synthesize, neural rendering technique, synthesize videos</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an imaging and neural rendering technique that seeks to synthesize videos of light propagating through a scene from novel, moving camera viewpoints. Our approach relies on a new ultrafast imaging setup to capture a first-of-its kind, multi-viewpoint video dataset with picosecond-level temporal resolution. Combined with this dataset, we introduce an efficient neural volume rendering framework based on the transient field. This field is defined as a mapping from a 3D point and 2D direction to a high-dimensional, discrete-time signal that represents time-varying radiance at ultrafast timescales. Rendering with transient fields naturally accounts for effects due to the finite speed of light, including viewpoint-dependent appearance changes caused by light propagation delays to the camera. We render a range of complex effects, including scattering, specular reflection, refraction, and diffraction. Additionally, we demonstrate removing viewpoint-dependent propagation delays using a time warping procedure, rendering of relativistic effects, and video synthesis of direct and global components of light transport.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：RhythmMamba: Fast Remote Physiological Measurement with Arbitrary Length  Videos</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06483">https://arxiv.org/abs/2404.06483</a></p>
  <p><b>作者</b>：Bochao Zou,  Zizheng Guo,  Xiaocheng Hu,  Huimin Ma</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2402.12788</p>
  <p><b>关键词</b>：holding great potential, detecting physiological signals, Remote photoplethysmography, affective computing, holding great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remote photoplethysmography (rPPG) is a non-contact method for detecting physiological signals from facial videos, holding great potential in various applications such as healthcare, affective computing, and anti-spoofing. Existing deep learning methods struggle to address two core issues of rPPG simultaneously: extracting weak rPPG signals from video segments with large spatiotemporal redundancy and understanding the periodic patterns of rPPG among long contexts. This represents a trade-off between computational complexity and the ability to capture long-range dependencies, posing a challenge for rPPG that is suitable for deployment on mobile devices. Based on the in-depth exploration of Mamba's comprehension of spatial and temporal information, this paper introduces RhythmMamba, an end-to-end Mamba-based method that employs multi-temporal Mamba to constrain both periodic patterns and short-term trends, coupled with frequency domain feed-forward to enable Mamba to robustly understand the quasi-periodic patterns of rPPG. Extensive experiments show that RhythmMamba achieves state-of-the-art performance with reduced parameters and lower computational complexity. The proposed RhythmMamba can be applied to video segments of any length without performance degradation. The codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Text-Based Reasoning About Vector Graphics</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06479">https://arxiv.org/abs/2404.06479</a></p>
  <p><b>作者</b>：Zhenhailong Wang,  Joy Hsu,  Xingyao Wang,  Kuan-Hao Huang,  Manling Li,  Jiajun Wu,  Heng Ji</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：broad vision-language benchmarks, solving simple mazes, comparing line lengths, vector graphics, Scalable Vector Graphics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While large multimodal models excel in broad vision-language benchmarks, they often struggle with tasks requiring precise perception of low-level visual details, such as comparing line lengths or solving simple mazes. In particular, this failure mode persists in question-answering tasks about vector graphics -- images composed purely of 2D objects and shapes. To address this challenge, we propose the Visually Descriptive Language Model (VDLM), which performs text-based reasoning about vector graphics. VDLM leverages Scalable Vector Graphics (SVG) for a more precise visual description and first uses an off-the-shelf raster-to-SVG algorithm for encoding. Since existing language models cannot understand raw SVGs in a zero-shot setting, VDLM then bridges SVG with pretrained language models through a newly introduced intermediate symbolic representation, Primal Visual Description (PVD), comprising primitive attributes (e.g., shape, position, measurement) with their corresponding predicted values. PVD is task-agnostic and represents visual primitives that are universal across all vector graphics. It can be learned with procedurally generated (SVG, PVD) pairs and also enables the direct use of LLMs for generalization to complex reasoning tasks. By casting an image to a text-based representation, we can leverage the power of language models to learn alignment from SVG to visual primitives and generalize to unseen question-answering tasks. Empirical results show that VDLM achieves stronger zero-shot performance compared to state-of-the-art LMMs, such as GPT-4V, in various low-level multimodal perception and reasoning tasks on vector graphics. We additionally present extensive analyses on VDLM's performance, demonstrating that our framework offers better interpretability due to its disentangled perception and reasoning processes. Project page: this https URL</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Learning State-Invariant Representations of Objects from Image  Collections with State, Pose, and Viewpoint Changes</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06470">https://arxiv.org/abs/2404.06470</a></p>
  <p><b>作者</b>：Rohan Sarkar,  Avinash Kak</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：state, state invariance, learning object representations, invariance, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We add one more invariance - state invariance - to the more commonly used other invariances for learning object representations for recognition and retrieval. By state invariance, we mean robust with respect to changes in the structural form of the object, such as when an umbrella is folded, or when an item of clothing is tossed on the floor. Since humans generally have no difficulty in recognizing objects despite such state changes, we are naturally faced with the question of whether it is possible to devise a neural architecture with similar abilities. To that end, we present a novel dataset, ObjectsWithStateChange, that captures state and pose variations in the object images recorded from arbitrary viewpoints. We believe that this dataset will facilitate research in fine-grained object recognition and retrieval of objects that are capable of state changes. The goal of such research would be to train models capable of generating object embeddings that remain invariant to state changes while also staying invariant to transformations induced by changes in viewpoint, pose, illumination, etc. To demonstrate the usefulness of the ObjectsWithStateChange dataset, we also propose a curriculum learning strategy that uses the similarity relationships in the learned embedding space after each epoch to guide the training process. The model learns discriminative features by comparing visually similar objects within and across different categories, encouraging it to differentiate between objects that may be challenging to distinguish due to changes in their state. We believe that this strategy enhances the model's ability to capture discriminative features for fine-grained tasks that may involve objects with state changes, leading to performance improvements on object-level tasks not only on our new dataset, but also on two other challenging multi-view datasets such as ModelNet40 and ObjectPI.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：PURE: Turning Polysemantic Neurons Into Pure Features by Identifying  Relevant Circuits</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06453">https://arxiv.org/abs/2404.06453</a></p>
  <p><b>作者</b>：Maximilian Dreyer,  Erblina Purelku,  Johanna Vielhaben,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：14 pages (4 pages manuscript, 2 pages references, 8 pages appendix)</p>
  <p><b>关键词</b>：Deep Neural Networks, mechanistic interpretability aims, Deep Neural, Neural Networks, field of mechanistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of mechanistic interpretability aims to study the role of individual neurons in Deep Neural Networks. Single neurons, however, have the capability to act polysemantically and encode for multiple (unrelated) features, which renders their interpretation difficult. We present a method for disentangling polysemanticity of any Deep Neural Network by decomposing a polysemantic neuron into multiple monosemantic "virtual" neurons. This is achieved by identifying the relevant sub-graph ("circuit") for each "pure" feature. We demonstrate how our approach allows us to find and disentangle various polysemantic units of ResNet models trained on ImageNet. While evaluating feature visualizations using CLIP, our method effectively disentangles representations, improving upon methods based on neuron activations. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：SmartControl: Enhancing ControlNet for Handling Rough Visual Conditions</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06451">https://arxiv.org/abs/2404.06451</a></p>
  <p><b>作者</b>：Xiaoyu Liu,  Yuxiang Wei,  Ming Liu,  Xianhui Lin,  Peiran Ren,  Xuansong Xie,  Wangmeng Zuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Human visual imagination, Iron Man playing, Man playing guitar, Pyramid in Egypt, imagination usually begins</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human visual imagination usually begins with analogies or rough sketches. For example, given an image with a girl playing guitar before a building, one may analogously imagine how it seems like if Iron Man playing guitar before Pyramid in Egypt. Nonetheless, visual condition may not be precisely aligned with the imaginary result indicated by text prompt, and existing layout-controllable text-to-image (T2I) generation models is prone to producing degraded generated results with obvious artifacts. To address this issue, we present a novel T2I generation method dubbed SmartControl, which is designed to modify the rough visual conditions for adapting to text prompt. The key idea of our SmartControl is to relax the visual condition on the areas that are conflicted with text prompts. In specific, a Control Scale Predictor (CSP) is designed to identify the conflict regions and predict the local control scales, while a dataset with text prompts and rough visual conditions is constructed for training CSP. It is worth noting that, even with a limited number (e.g., 1,000~2,000) of training samples, our SmartControl can generalize well to unseen objects. Extensive experiments on four typical visual condition types clearly show the efficacy of our SmartControl against state-of-the-arts. Source code, pre-trained models, and datasets are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：The Central Spanning Tree Problem</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06447">https://arxiv.org/abs/2404.06447</a></p>
  <p><b>作者</b>：Enrique Fita Sanmartín,  Christoph Schnörr,  Fred A. Hamprecht</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spanning tree, data analysis tasks, Spanning, central spanning tree, Steiner trees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spanning trees are an important primitive in many data analysis tasks, when a data set needs to be summarized in terms of its "skeleton", or when a tree-shaped graph over all observations is required for downstream processing. Popular definitions of spanning trees include the minimum spanning tree and the optimum distance spanning tree, a.k.a. the minimum routing cost tree. When searching for the shortest spanning tree but admitting additional branching points, even shorter spanning trees can be realized: Steiner trees. Unfortunately, both minimum spanning and Steiner trees are not robust with respect to noise in the observations; that is, small perturbations of the original data set often lead to drastic changes in the associated spanning trees. In response, we make two contributions when the data lies in a Euclidean space: on the theoretical side, we introduce a new optimization problem, the "(branched) central spanning tree", which subsumes all previously mentioned definitions as special cases. On the practical side, we show empirically that the (branched) central spanning tree is more robust to noise in the data, and as such is better suited to summarize a data set in terms of its skeleton. We also propose a heuristic to address the NP-hard optimization problem, and illustrate its use on single cell RNA expression data from biology and 3D point clouds of plants.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Multi-scale Dynamic and Hierarchical Relationship Modeling for Facial  Action Units Recognition</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06443">https://arxiv.org/abs/2404.06443</a></p>
  <p><b>作者</b>：Zihan Wang,  Siyang Song,  Cheng Luo,  Songhe Deng,  Weicheng Xie,  Linlin Shen</p>
  <p><b>备注</b>：Accepted to CVPR2024</p>
  <p><b>关键词</b>：close facial regions, Human facial action, facial action units, regions show stronger, action units</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human facial action units (AUs) are mutually related in a hierarchical manner, as not only they are associated with each other in both spatial and temporal domains but also AUs located in the same/close facial regions show stronger relationships than those of different facial regions. While none of existing approach thoroughly model such hierarchical inter-dependencies among AUs, this paper proposes to comprehensively model multi-scale AU-related dynamic and hierarchical spatio-temporal relationship among AUs for their occurrences recognition. Specifically, we first propose a novel multi-scale temporal differencing network with an adaptive weighting block to explicitly capture facial dynamics across frames at different spatial scales, which specifically considers the heterogeneity of range and magnitude in different AUs' activation. Then, a two-stage strategy is introduced to hierarchically model the relationship among AUs based on their spatial distribution (i.e., local and cross-region AU relationship modelling). Experimental results achieved on BP4D and DISFA show that our approach is the new state-of-the-art in the field of AU occurrence recognition. Our code is publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：QueSTMaps: Queryable Semantic Topological Maps for 3D Scene  Understanding</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06442">https://arxiv.org/abs/2404.06442</a></p>
  <p><b>作者</b>：Yash Mehan,  Kumaraditya Gupta,  Rohit Jayanti,  Anirudh Govil,  Sourav Garg,  Madhava Krishna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：floorplan extraction, scene, Understanding, semantic, structural organisation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the structural organisation of 3D indoor scenes in terms of rooms is often accomplished via floorplan extraction. Robotic tasks such as planning and navigation require a semantic understanding of the scene as well. This is typically achieved via object-level semantic segmentation. However, such methods struggle to segment out topological regions like "kitchen" in the scene. In this work, we introduce a two-step pipeline. First, we extract a topological map, i.e., floorplan of the indoor scene using a novel multi-channel occupancy representation. Then, we generate CLIP-aligned features and semantic labels for every room instance based on the objects it contains using a self-attention transformer. Our language-topology alignment supports natural language querying, e.g., a "place to cook" locates the "kitchen". We outperform the current state-of-the-art on room segmentation by ~20% and room classification by ~12%. Our detailed qualitative analysis and ablation studies provide insights into the problem of joint structural and semantic 3D scene understanding.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Seasonal Fire Prediction using Spatio-Temporal Deep Neural Networks</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06437">https://arxiv.org/abs/2404.06437</a></p>
  <p><b>作者</b>：Dimitrios Michail,  Lefki-Ioanna Panagiotou,  Charalampos Davalas,  Ioannis Prapas,  Spyros Kondylatos,  Nikolaos Ioannis Bountos,  Ioannis Papoutsis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：climate change expected, fire weather conditions, exacerbate fire weather, weather conditions, disaster mitigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With climate change expected to exacerbate fire weather conditions, the accurate anticipation of wildfires on a global scale becomes increasingly crucial for disaster mitigation. In this study, we utilize SeasFire, a comprehensive global wildfire dataset with climate, vegetation, oceanic indices, and human-related variables, to enable seasonal wildfire forecasting with machine learning. For the predictive analysis, we train deep learning models with different architectures that capture the spatio-temporal context leading to wildfires. Our investigation focuses on assessing the effectiveness of these models in predicting the presence of burned areas at varying forecasting time horizons globally, extending up to six months into the future, and on how different spatial or/and temporal context affects the performance of the models. Our findings demonstrate the great potential of deep learning models in seasonal fire forecasting; longer input time-series leads to more robust predictions across varying forecasting horizons, while integrating spatial information to capture wildfire spatio-temporal dynamics boosts performance. Finally, our results hint that in order to enhance performance at longer forecasting horizons, a larger receptive field spatially needs to be considered.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：pfl-research: simulation framework for accelerating research in Private  Federated Learning</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06430">https://arxiv.org/abs/2404.06430</a></p>
  <p><b>作者</b>：Filip Granqvist,  Congzheng Song,  Áine Cahill,  Rogier van Dalen,  Martin Pelikan,  Yi Sheng Chan,  Xiaojun Feng,  Natarajan Krishnaswami,  Vojta Jina,  Mona Chitnis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging machine learning, Federated learning, machine learning, training paradigm, emerging machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging machine learning (ML) training paradigm where clients own their data and collaborate to train a global model, without revealing any data to the server and other participants. Researchers commonly perform experiments in a simulation environment to quickly iterate on ideas. However, existing open-source tools do not offer the efficiency required to simulate FL on larger and more realistic FL datasets. We introduce pfl-research, a fast, modular, and easy-to-use Python framework for simulating FL. It supports TensorFlow, PyTorch, and non-neural network models, and is tightly integrated with state-of-the-art privacy algorithms. We study the speed of open-source FL frameworks and show that pfl-research is 7-72$\times$ faster than alternative open-source frameworks on common cross-device setups. Such speedup will significantly boost the productivity of the FL research community and enable testing hypotheses on realistic FL datasets that were previously too resource intensive. We release a suite of benchmarks that evaluates an algorithm's overall performance on a diverse set of realistic scenarios. The code is available on GitHub at this https URL.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06429">https://arxiv.org/abs/2404.06429</a></p>
  <p><b>作者</b>：Fan Yang,  Jianfeng Zhang,  Yichun Shi,  Bowen Chen,  Chenxu Zhang,  Huichao Zhang,  Xiaofeng Yang,  Jiashi Feng,  Guosheng Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant progress recently, made significant progress, content creation, progress recently, rapid development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benefiting from the rapid development of 2D diffusion models, 3D content creation has made significant progress recently. One promising solution involves the fine-tuning of pre-trained 2D diffusion models to harness their capacity for producing multi-view images, which are then lifted into accurate 3D models via methods like fast-NeRFs or large reconstruction models. However, as inconsistency still exists and limited generated resolution, the generation results of such methods still lack intricate textures and complex geometries. To solve this problem, we propose Magic-Boost, a multi-view conditioned diffusion model that significantly refines coarse generative results through a brief period of SDS optimization ($\sim15$min). Compared to the previous text or single image based diffusion models, Magic-Boost exhibits a robust capability to generate images with high consistency from pseudo synthesized multi-view images. It provides precise SDS guidance that well aligns with the identity of the input images, enriching the local detail in both geometry and texture of the initial generative results. Extensive experiments show Magic-Boost greatly enhances the coarse inputs and generates high-quality 3D assets with rich geometric and textural details. (Project Page: this https URL)</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：ZeST: Zero-Shot Material Transfer from a Single Image</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06425">https://arxiv.org/abs/2404.06425</a></p>
  <p><b>作者</b>：Ta-Ying Cheng,  Prafull Sharma,  Andrew Markham,  Niki Trigoni,  Varun Jampani</p>
  <p><b>备注</b>：Project Page: this https URL</p>
  <p><b>关键词</b>：exemplar image, input image, material, image, material exemplar image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose ZeST, a method for zero-shot material transfer to an object in the input image given a material exemplar image. ZeST leverages existing diffusion adapters to extract implicit material representation from the exemplar image. This representation is used to transfer the material using pre-trained inpainting diffusion model on the object in the input image using depth estimates as geometry cue and grayscale object shading as illumination cues. The method works on real images without any training resulting a zero-shot approach. Both qualitative and quantitative results on real and synthetic datasets demonstrate that ZeST outputs photorealistic images with transferred materials. We also show the application of ZeST to perform multiple edits and robust material assignment under different illuminations. Project Page: this https URL</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Emergent Dynamics in Neural Cellular Automata</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06406">https://arxiv.org/abs/2404.06406</a></p>
  <p><b>作者</b>：Yitao Xu,  Ehsan Pajouheshgar,  Sabine Süsstrunk</p>
  <p><b>备注</b>：2 pages</p>
  <p><b>关键词</b>：Neural Cellular Automata, traditional Cellular Automata, Cellular Automata, Neural Cellular, traditional Cellular</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Cellular Automata (NCA) models are trainable variations of traditional Cellular Automata (CA). Emergent motion in the patterns created by NCA has been successfully applied to synthesize dynamic textures. However, the conditions required for an NCA to display dynamic patterns remain unexplored. Here, we investigate the relationship between the NCA architecture and the emergent dynamics of the trained models. Specifically, we vary the number of channels in the cell state and the number of hidden neurons in the MultiLayer Perceptron (MLP), and draw a relationship between the combination of these two variables and the motion strength between successive frames. Our analysis reveals that the disparity and proportionality between these two variables have a strong correlation with the emergent dynamics in the NCA output. We thus propose a design principle for creating dynamic NCA.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：VISION2UI: A Real-World Dataset with Layout for Code Generation from UI  Designs</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06369">https://arxiv.org/abs/2404.06369</a></p>
  <p><b>作者</b>：Yi Gui,  Zhen Li,  Yao Wan,  Yemin Shi,  Hongyu Zhang,  Yi Su,  Shaoling Dong,  Xing Zhou,  Wenbin Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：directly generate Web, generate Web pages, enabling beginner developers, generate Web, Web pages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically generating UI code from webpage design visions can significantly alleviate the burden of developers, enabling beginner developers or designers to directly generate Web pages from design diagrams. Currently, prior research has accomplished the objective of generating UI code from rudimentary design visions or sketches through designing deep neural networks. Inspired by the groundbreaking advancements achieved by Multimodal Large Language Models (MLLMs), the automatic generation of UI code from high-fidelity design images is now emerging as a viable possibility. Nevertheless, our investigation reveals that existing MLLMs are hampered by the scarcity of authentic, high-quality, and large-scale datasets, leading to unsatisfactory performance in automated UI code generation. To mitigate this gap, we present a novel dataset, termed VISION2UI, extracted from real-world scenarios, augmented with comprehensive layout information, tailored specifically for finetuning MLLMs in UI code generation. Specifically, this dataset is derived through a series of operations, encompassing collecting, cleaning, and filtering of the open-source Common Crawl dataset. In order to uphold its quality, a neural scorer trained on labeled samples is utilized to refine the data, retaining higher-quality instances. Ultimately, this process yields a dataset comprising 2,000 (Much more is coming soon) parallel samples encompassing design visions and UI code. The dataset is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Dynamic Resolution Guidance for Facial Expression Recognition</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06365">https://arxiv.org/abs/2404.06365</a></p>
  <p><b>作者</b>：Jie Ou,  Xu Li,  Tianxiang Jiang,  Yuanlun Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Facial expression recognition, expression recognition, Expression Recognition Network, Facial expression, images remains challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Facial expression recognition (FER) is vital for human-computer interaction and emotion analysis, yet recognizing expressions in low-resolution images remains challenging. This paper introduces a practical method called Dynamic Resolution Guidance for Facial Expression Recognition (DRGFER) to effectively recognize facial expressions in images with varying resolutions without compromising FER model accuracy. Our framework comprises two main components: the Resolution Recognition Network (RRN) and the Multi-Resolution Adaptation Facial Expression Recognition Network (MRAFER). The RRN determines image resolution, outputs a binary vector, and the MRAFER assigns images to suitable facial expression recognition networks based on resolution. We evaluated DRGFER on widely-used datasets RAFDB and FERPlus, demonstrating that our method retains optimal model performance at each resolution and outperforms alternative resolution approaches. The proposed framework exhibits robustness against resolution variations and facial expressions, offering a promising solution for real-world applications.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06362">https://arxiv.org/abs/2404.06362</a></p>
  <p><b>作者</b>：Sidra Aleem,  Fangyijie Wang,  Mayug Maniparambil,  Eric Arazo,  Julia Dietlmeier,  Kathleen Curran,  Noel E. O'Connor,  Suzanne Little</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vision foundation models, remarkable vision foundation, SAM, foundation models, remarkable vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) and CLIP are remarkable vision foundation models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation tasks across diverse domains, while CLIP is renowned for its zero shot recognition capabilities. However, their unified potential has not yet been explored in medical image segmentation. To adapt SAM to medical imaging, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. This work presents an in depth exploration of integrating SAM and CLIP into a unified framework for medical image segmentation. Specifically, we propose a simple unified framework, SaLIP, for organ segmentation. Initially, SAM is used for part based segmentation within the image, followed by CLIP to retrieve the mask corresponding to the region of interest (ROI) from the pool of SAM generated masks. Finally, SAM is prompted by the retrieved ROI to segment a specific organ. Thus, SaLIP is training and fine tuning free and does not rely on domain expertise or labeled data for prompt engineering. Our method shows substantial enhancements in zero shot segmentation, showcasing notable improvements in DICE scores across diverse segmentation tasks like brain (63.46%), lung (50.11%), and fetal head (30.82%), when compared to un prompted SAM. Code and text prompts will be available online.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：High Noise Scheduling is a Must</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06353">https://arxiv.org/abs/2404.06353</a></p>
  <p><b>作者</b>：Mahmut S. Gokmen,  Cody Bumgardner,  Jie Zhang,  Ge Wang,  Jin Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noise distribution, advancing sampling steps, possess high capabilities, noise, polynomial noise distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Consistency models possess high capabilities for image generation, advancing sampling steps to a single step through their advanced techniques. Current advancements move one step forward consistency training techniques and eliminates the limitation of distillation training. Even though the proposed curriculum and noise scheduling in improved training techniques yield better results than basic consistency models, it lacks well balanced noise distribution and its consistency between curriculum. In this study, it is investigated the balance between high and low noise levels in noise distribution and offered polynomial noise distribution to maintain the stability. This proposed polynomial noise distribution is also supported with a predefined Karras noises to prevent unique noise levels arises with Karras noise generation algorithm. Furthermore, by elimination of learned noisy steps with a curriculum based on sinusoidal function increase the performance of the model in denoising. To make a fair comparison with the latest released consistency model training techniques, experiments are conducted with same hyper-parameters except curriculum and noise distribution. The models utilized during experiments are determined with low depth to prove the robustness of our proposed technique. The results show that the polynomial noise distribution outperforms the model trained with log-normal noise distribution, yielding a 33.54 FID score after 100,000 training steps with constant discretization steps. Additionally, the implementation of a sinusoidal-based curriculum enhances denoising performance, resulting in a FID score of 30.48.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：DaF-BEVSeg: Distortion-aware Fisheye Camera based Bird's Eye View  Segmentation with Occlusion Reasoning</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06352">https://arxiv.org/abs/2404.06352</a></p>
  <p><b>作者</b>：Senthil Yogamani,  David Unger,  Venkatraman Narayanan,  Varun Ravi Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perform scene understanding, Bird Eye View, scene understanding, Bird Eye, Eye View</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic segmentation is an effective way to perform scene understanding. Recently, segmentation in 3D Bird's Eye View (BEV) space has become popular as its directly used by drive policy. However, there is limited work on BEV segmentation for surround-view fisheye cameras, commonly used in commercial vehicles. As this task has no real-world public dataset and existing synthetic datasets do not handle amodal regions due to occlusion, we create a synthetic dataset using the Cognata simulator comprising diverse road types, weather, and lighting conditions. We generalize the BEV segmentation to work with any camera model; this is useful for mixing diverse cameras. We implement a baseline by applying cylindrical rectification on the fisheye images and using a standard LSS-based BEV segmentation model. We demonstrate that we can achieve better performance without undistortion, which has the adverse effects of increased runtime due to pre-processing, reduced field-of-view, and resampling artifacts. Further, we introduce a distortion-aware learnable BEV pooling strategy that is more effective for the fisheye cameras. We extend the model with an occlusion reasoning module, which is critical for estimating in BEV space. Qualitative performance of DaF-BEVSeg is showcased in the video at this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：HPNet: Dynamic Trajectory Forecasting with Historical Prediction  Attention</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06351">https://arxiv.org/abs/2404.06351</a></p>
  <p><b>作者</b>：Xiaolong Tang,  Meina Kan,  Shiguang Shan,  Zhilong Ji,  Jinfeng Bai,  Xilin Chen</p>
  <p><b>备注</b>：accepted by CVPR2024</p>
  <p><b>关键词</b>：autonomous driving systems, Historical Prediction Attention, driving systems, essential for autonomous, autonomous driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting the trajectories of road agents is essential for autonomous driving systems. The recent mainstream methods follow a static paradigm, which predicts the future trajectory by using a fixed duration of historical frames. These methods make the predictions independently even at adjacent time steps, which leads to potential instability and temporal inconsistency. As successive time steps have largely overlapping historical frames, their forecasting should have intrinsic correlation, such as overlapping predicted trajectories should be consistent, or be different but share the same motion goal depending on the road situation. Motivated by this, in this work, we introduce HPNet, a novel dynamic trajectory forecasting method. Aiming for stable and accurate trajectory forecasting, our method leverages not only historical frames including maps and agent states, but also historical predictions. Specifically, we newly design a Historical Prediction Attention module to automatically encode the dynamic relationship between successive predictions. Besides, it also extends the attention range beyond the currently visible window benefitting from the use of historical predictions. The proposed Historical Prediction Attention together with the Agent Attention and Mode Attention is further formulated as the Triple Factorized Attention module, serving as the core design of HPNet.Experiments on the Argoverse and INTERACTION datasets show that HPNet achieves state-of-the-art performance, and generates accurate and stable future trajectories. Our code are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Rolling Shutter Correction with Intermediate Distortion Flow Estimation</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06350">https://arxiv.org/abs/2404.06350</a></p>
  <p><b>作者</b>：Mingdeng Cao,  Sidi Yang,  Yujiu Yang,  Yinqiang Zheng</p>
  <p><b>备注</b>：CVPR2024</p>
  <p><b>关键词</b>：rolling shutter, flow, correct the rolling, distortion flow, shutter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes to correct the rolling shutter (RS) distorted images by estimating the distortion flow from the global shutter (GS) to RS directly. Existing methods usually perform correction using the undistortion flow from the RS to GS. They initially predict the flow from consecutive RS frames, subsequently rescaling it as the displacement fields from the RS frame to the underlying GS image using time-dependent scaling factors. Following this, RS-aware forward warping is employed to convert the RS image into its GS counterpart. Nevertheless, this strategy is prone to two shortcomings. First, the undistortion flow estimation is rendered inaccurate by merely linear scaling the flow, due to the complex non-linear motion nature. Second, RS-aware forward warping often results in unavoidable artifacts. To address these limitations, we introduce a new framework that directly estimates the distortion flow and rectifies the RS image with the backward warping operation. More specifically, we first propose a global correlation-based flow attention mechanism to estimate the initial distortion flow and GS feature jointly, which are then refined by the following coarse-to-fine decoder layers. Additionally, a multi-distortion flow prediction strategy is integrated to mitigate the issue of inaccurate flow estimation further. Experimental results validate the effectiveness of the proposed method, which outperforms state-of-the-art approaches on various benchmarks while maintaining high efficiency. The project is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Matching 2D Images in 3D: Metric Relative Pose from Metric  Correspondences</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06337">https://arxiv.org/abs/2404.06337</a></p>
  <p><b>作者</b>：Axel Barroso-Laguna,  Sowmya Munukutla,  Victor Adrian Prisacariu,  Eric Brachmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pose, correspondences, establishing, relative, depth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given two images, we can estimate the relative camera pose between them by establishing image-to-image correspondences. Usually, correspondences are 2D-to-2D and the pose we estimate is defined only up to scale. Some applications, aiming at instant augmented reality anywhere, require scale-metric pose estimates, and hence, they rely on external depth estimators to recover the scale. We present MicKey, a keypoint matching pipeline that is able to predict metric correspondences in 3D camera space. By learning to match 3D coordinates across images, we are able to infer the metric relative pose without depth measurements. Depth measurements are also not required for training, nor are scene reconstructions or image overlap information. MicKey is supervised only by pairs of images and their relative poses. MicKey achieves state-of-the-art performance on the Map-Free Relocalisation benchmark while requiring less supervision than competing approaches.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：X-VARS: Introducing Explainability in Football Refereeing with  Multi-Modal Large Language Model</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06332">https://arxiv.org/abs/2404.06332</a></p>
  <p><b>作者</b>：Jan Held,  Hani Itani,  Anthony Cioppa,  Silvio Giancola,  Bernard Ghanem,  Marc Van Droogenbroeck</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rapid advancement, advancement of artificial, artificial intelligence, intelligence has led, led to significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid advancement of artificial intelligence has led to significant improvements in automated decision-making. However, the increased performance of models often comes at the cost of explainability and transparency of their decision-making processes. In this paper, we investigate the capabilities of large language models to explain decisions, using football refereeing as a testing ground, given its decision complexity and subjectivity. We introduce the Explainable Video Assistant Referee System, X-VARS, a multi-modal large language model designed for understanding football videos from the point of view of a referee. X-VARS can perform a multitude of tasks, including video description, question answering, action recognition, and conducting meaningful conversations based on video content and in accordance with the Laws of the Game for football referees. We validate X-VARS on our novel dataset, SoccerNet-XFoul, which consists of more than 22k video-question-answer triplets annotated by over 70 experienced football referees. Our experiments and human study illustrate the impressive capabilities of X-VARS in interpreting complex football clips. Furthermore, we highlight the potential of X-VARS to reach human performance and support football referees in the future.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Audio-Visual Generalized Zero-Shot Learning using Pre-Trained Large  Multi-Modal Models</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06309">https://arxiv.org/abs/2404.06309</a></p>
  <p><b>作者</b>：David Kurzendörfer,  Otniel-Bogdan Mercea,  A. Sophia Koepke,  Zeynep Akata</p>
  <p><b>备注</b>：CVPRw 2024 (L3D-IVU)</p>
  <p><b>关键词</b>：Audio-visual zero-shot learning, zero-shot learning methods, learning methods commonly, methods commonly build, Audio-visual zero-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Audio-visual zero-shot learning methods commonly build on features extracted from pre-trained models, e.g. video or audio classification models. However, existing benchmarks predate the popularization of large multi-modal models, such as CLIP and CLAP. In this work, we explore such large pre-trained models to obtain features, i.e. CLIP for visual features, and CLAP for audio features. Furthermore, the CLIP and CLAP text encoders provide class label embeddings which are combined to boost the performance of the system. We propose a simple yet effective model that only relies on feed-forward neural networks, exploiting the strong generalization capabilities of the new audio, visual and textual features. Our framework achieves state-of-the-art performance on VGGSound-GZSL, UCF-GZSL, and ActivityNet-GZSL with our new features. Code and data available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Counterfactual Reasoning for Multi-Label Image Classification via  Patching-Based Training</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06287">https://arxiv.org/abs/2404.06287</a></p>
  <p><b>作者</b>：Ming-Kun Xie,  Jia-Hao Xiao,  Pei Peng,  Gang Niu,  Masashi Sugiyama,  Sheng-Jun Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging label correlations, multi-label image classification, target object, improve model performance, label correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The key to multi-label image classification (MLC) is to improve model performance by leveraging label correlations. Unfortunately, it has been shown that overemphasizing co-occurrence relationships can cause the overfitting issue of the model, ultimately leading to performance degradation. In this paper, we provide a causal inference framework to show that the correlative features caused by the target object and its co-occurring objects can be regarded as a mediator, which has both positive and negative impacts on model predictions. On the positive side, the mediator enhances the recognition performance of the model by capturing co-occurrence relationships; on the negative side, it has the harmful causal effect that causes the model to make an incorrect prediction for the target object, even when only co-occurring objects are present in an image. To address this problem, we propose a counterfactual reasoning method to measure the total direct effect, achieved by enhancing the direct effect caused only by the target object. Due to the unknown location of the target object, we propose patching-based training and inference to accomplish this goal, which divides an image into multiple patches and identifies the pivot patch that contains the target object. Experimental results on multiple benchmark datasets with diverse configurations validate that the proposed method can achieve state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural  Cellular Automata</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06279">https://arxiv.org/abs/2404.06279</a></p>
  <p><b>作者</b>：Ehsan Pajouheshgar,  Yitao Xu,  Sabine Süsstrunk</p>
  <p><b>备注</b>：9 pages, 12 figures</p>
  <p><b>关键词</b>：Neural Cellular Automata, Cellular Automata, Neural Cellular, NCA models, NCA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Cellular Automata (NCA) is a class of Cellular Automata where the update rule is parameterized by a neural network that can be trained using gradient descent. In this paper, we focus on NCA models used for texture synthesis, where the update rule is inspired by partial differential equations (PDEs) describing reaction-diffusion systems. To train the NCA model, the spatio-termporal domain is discretized, and Euler integration is used to numerically simulate the PDE. However, whether a trained NCA truly learns the continuous dynamic described by the corresponding PDE or merely overfits the discretization used in training remains an open question. We study NCA models at the limit where space-time discretization approaches continuity. We find that existing NCA models tend to overfit the training discretization, especially in the proximity of the initial condition, also called "seed". To address this, we propose a solution that utilizes uniform noise as the initial condition. We demonstrate the effectiveness of our approach in preserving the consistency of NCA dynamics across a wide range of spatio-temporal granularities. Our improved NCA model enables two new test-time interactions by allowing continuous control over the speed of pattern formation and the scale of the synthesized patterns. We demonstrate this new NCA feature in our interactive online demo. Our work reveals that NCA models can learn continuous dynamics and opens new venues for NCA research from a dynamical systems' perspective.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Learning Embeddings with Centroid Triplet Loss for Object Identification  in Robotic Grasping</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06277">https://arxiv.org/abs/2404.06277</a></p>
  <p><b>作者</b>：Anas Gouda,  Max Schwarz,  Christopher Reining,  Sven Behnke,  Alice Kirchheim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：object identification, computer vision, object, strong trend, trend in deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Foundation models are a strong trend in deep learning and computer vision. These models serve as a base for applications as they require minor or no further fine-tuning by developers to integrate into their applications. Foundation models for zero-shot object segmentation such as Segment Anything (SAM) output segmentation masks from images without any further object information. When they are followed in a pipeline by an object identification model, they can perform object detection without training. Here, we focus on training such an object identification model. A crucial practical aspect for an object identification model is to be flexible in input size. As object identification is an image retrieval problem, a suitable method should handle multi-query multi-gallery situations without constraining the number of input images (e.g. by having fixed-size aggregation layers). The key solution to train such a model is the centroid triplet loss (CTL), which aggregates image features to their centroids. CTL yields high accuracy, avoids misleading training signals and keeps the model input size flexible. In our experiments, we establish a new state of the art on the ArmBench object identification task, which shows general applicability of our model. We furthermore demonstrate an integrated unseen object detection pipeline on the challenging HOPE dataset, which requires fine-grained detection. There, our pipeline matches and surpasses related methods which have been trained on dataset-specific data.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Robust Confidence Intervals in Stereo Matching using Possibility Theory</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06273">https://arxiv.org/abs/2404.06273</a></p>
  <p><b>作者</b>：Roman Malinowski,  Emmanuelle Sarrazin,  Loïc Dumas,  Emmanuel Dubois,  Sébastien Destercke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stereo matching problems, disparity confidence intervals, estimating disparity confidence, confidence intervals, matching problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for estimating disparity confidence intervals in stereo matching problems. Confidence intervals provide complementary information to usual confidence measures. To the best of our knowledge, this is the first method creating disparity confidence intervals based on the cost volume. This method relies on possibility distributions to interpret the epistemic uncertainty of the cost volume. Our method has the benefit of having a white-box nature, differing in this respect from current state-of-the-art deep neural networks approaches. The accuracy and size of confidence intervals are validated using the Middlebury stereo datasets as well as a dataset of satellite images. This contribution is freely available on GitHub.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：3D Geometry-aware Deformable Gaussian Splatting for Dynamic View  Synthesis</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06270">https://arxiv.org/abs/2404.06270</a></p>
  <p><b>作者</b>：Zhicheng Lu,  Xiang Guo,  Le Hui,  Tianrui Chen,  Min Yang,  Xiao Tang,  Feng Zhu,  Yuchao Dai</p>
  <p><b>备注</b>：Accepted by CVPR 2024. Project page: this https URL</p>
  <p><b>关键词</b>：Gaussian Splatting method, deformable Gaussian Splatting, dynamic view synthesis, Gaussian Splatting, geometry-aware deformable Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a 3D geometry-aware deformable Gaussian Splatting method for dynamic view synthesis. Existing neural radiance fields (NeRF) based solutions learn the deformation in an implicit manner, which cannot incorporate 3D scene geometry. Therefore, the learned deformation is not necessarily geometrically coherent, which results in unsatisfactory dynamic view synthesis and 3D dynamic reconstruction. Recently, 3D Gaussian Splatting provides a new representation of the 3D scene, building upon which the 3D geometry could be exploited in learning the complex 3D deformation. Specifically, the scenes are represented as a collection of 3D Gaussian, where each 3D Gaussian is optimized to move and rotate over time to model the deformation. To enforce the 3D scene geometry constraint during deformation, we explicitly extract 3D geometry features and integrate them in learning the 3D deformation. In this way, our solution achieves 3D geometry-aware deformation modeling, which enables improved dynamic view synthesis and 3D dynamic reconstruction. Extensive experimental results on both synthetic and real datasets prove the superiority of our solution, which achieves new state-of-the-art performance.
The project is available at this https URL</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Spatial-Temporal Multi-level Association for Video Object Segmentation</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06265">https://arxiv.org/abs/2404.06265</a></p>
  <p><b>作者</b>：Deshui Miao,  Xin Li,  Zhenyu He,  Huchuan Lu,  Ming-Hsuan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Existing semi-supervised video, video object segmentation, spatial-temporal feature modeling, Existing semi-supervised, semi-supervised video object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing semi-supervised video object segmentation methods either focus on temporal feature matching or spatial-temporal feature modeling. However, they do not address the issues of sufficient target interaction and efficient parallel processing simultaneously, thereby constraining the learning of dynamic, target-aware features. To tackle these limitations, this paper proposes a spatial-temporal multi-level association framework, which jointly associates reference frame, test frame, and object features to achieve sufficient interaction and parallel target ID association with a spatial-temporal memory bank for efficient video object segmentation. Specifically, we construct a spatial-temporal multi-level feature association module to learn better target-aware features, which formulates feature extraction and interaction as the efficient operations of object self-attention, reference object enhancement, and test reference correlation. In addition, we propose a spatial-temporal memory to assist feature association and temporal ID assignment and correlation. We evaluate the proposed method by conducting extensive experiments on numerous video object segmentation datasets, including DAVIS 2016/2017 val, DAVIS 2017 test-dev, and YouTube-VOS 2018/2019 val. The favorable performance against the state-of-the-art methods demonstrates the effectiveness of our approach. All source code and trained models will be made publicly available.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Playing to Vision Foundation Model's Strengths in Stereo Matching</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06261">https://arxiv.org/abs/2404.06261</a></p>
  <p><b>作者</b>：Chuang-Wei Liu,  Qijun Chen,  Rui Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：environment perception, intelligent vehicles, key technique, perception in intelligent, Stereo matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stereo matching has become a key technique for 3D environment perception in intelligent vehicles. For a considerable time, convolutional neural networks (CNNs) have remained the mainstream choice for feature extraction in this domain. Nonetheless, there is a growing consensus that the existing paradigm should evolve towards vision foundation models (VFM), particularly those developed based on vision Transformers (ViTs) and pre-trained through self-supervision on extensive, unlabeled datasets. While VFMs are adept at extracting informative, general-purpose visual features, specifically for dense prediction tasks, their performance often lacks in geometric vision tasks. This study serves as the first exploration of a viable approach for adapting VFMs to stereo matching. Our ViT adapter, referred to as ViTAS, is constructed upon three types of modules: spatial differentiation, patch attention fusion, and cross-attention. The first module initializes feature pyramids, while the latter two aggregate stereo and multi-scale contextual information into fine-grained features, respectively. ViTAStereo, which combines ViTAS with cost volume-based stereo matching back-end processes, achieves the top rank on the KITTI Stereo 2012 dataset and outperforms the second-best network StereoBase by approximately 7.9% in terms of the percentage of error pixels, with a tolerance of 3 pixels. Additional experiments across diverse scenarios further demonstrate its superior generalizability compared to all other state-of-the-art approaches. We believe this new paradigm will pave the way for the next generation of stereo matching networks.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Robust feature knowledge distillation for enhanced performance of  lightweight crack segmentation models</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06258">https://arxiv.org/abs/2404.06258</a></p>
  <p><b>作者</b>：Zhaohui Chen,  Elyas Asadi Shamsabadi,  Sheng Jiang,  Luming Shen,  Daniel Dias-da-Costa</p>
  <p><b>备注</b>：24 pages, 13 figures</p>
  <p><b>关键词</b>：edge device limitations, detection faces deployment, faces deployment challenges, deployment challenges due, Vision-based crack detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-based crack detection faces deployment challenges due to the size of robust models and edge device limitations. These can be addressed with lightweight models trained with knowledge distillation (KD). However, state-of-the-art (SOTA) KD methods compromise anti-noise robustness. This paper develops Robust Feature Knowledge Distillation (RFKD), a framework to improve robustness while retaining the precision of light models for crack segmentation. RFKD distils knowledge from a teacher model's logit layers and intermediate feature maps while leveraging mixed clean and noisy images to transfer robust patterns to the student model, improving its precision, generalisation, and anti-noise performance. To validate the proposed RFKD, a lightweight crack segmentation model, PoolingCrack Tiny (PCT), with only 0.5 M parameters, is also designed and used as the student to run the framework. The results show a significant enhancement in noisy images, with RFKD reaching a 62% enhanced mean Dice score (mDS) compared to SOTA KD methods.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Label-Efficient 3D Object Detection For Road-Side Units</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06256">https://arxiv.org/abs/2404.06256</a></p>
  <p><b>作者</b>：Minh-Quan Dao,  Holger Caesar,  Julie Stephany Berrio,  Mao Shan,  Stewart Worrall,  Vincent Frémont,  Ezio Malis</p>
  <p><b>备注</b>：IV 2024</p>
  <p><b>关键词</b>：safety-critical applications, autonomous driving, Occlusion presents, RSU data, RSU</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Occlusion presents a significant challenge for safety-critical applications such as autonomous driving. Collaborative perception has recently attracted a large research interest thanks to the ability to enhance the perception of autonomous vehicles via deep information fusion with intelligent roadside units (RSU), thus minimizing the impact of occlusion. While significant advancement has been made, the data-hungry nature of these methods creates a major hurdle for their real-world deployment, particularly due to the need for annotated RSU data. Manually annotating the vast amount of RSU data required for training is prohibitively expensive, given the sheer number of intersections and the effort involved in annotating point clouds. We address this challenge by devising a label-efficient object detection method for RSU based on unsupervised object discovery. Our paper introduces two new modules: one for object discovery based on a spatial-temporal aggregation of point clouds, and another for refinement. Furthermore, we demonstrate that fine-tuning on a small portion of annotated data allows our object discovery models to narrow the performance gap with, or even surpass, fully supervised models. Extensive experiments are carried out in simulated and real-world datasets to evaluate our method.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：From Barlow Twins to Triplet Training: Differentiating Dementia with  Limited Data</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06253">https://arxiv.org/abs/2404.06253</a></p>
  <p><b>作者</b>：Yitong Li,  Tom Nuno Wolf,  Sebastian Pölsterl,  Igor Yakushev,  Dennis M. Hedderich,  Christian Wachinger</p>
  <p><b>备注</b>：Accepted for presentation at MIDL 2024</p>
  <p><b>关键词</b>：magnetic resonance imaging, structural magnetic resonance, Differential diagnosis, overlapping symptoms, resonance imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differential diagnosis of dementia is challenging due to overlapping symptoms, with structural magnetic resonance imaging (MRI) being the primary method for diagnosis. Despite the clinical value of computer-aided differential diagnosis, research has been limited, mainly due to the absence of public datasets that contain diverse types of dementia. This leaves researchers with small in-house datasets that are insufficient for training deep neural networks (DNNs). Self-supervised learning shows promise for utilizing unlabeled MRI scans in training, but small batch sizes for volumetric brain scans make its application challenging. To address these issues, we propose Triplet Training for differential diagnosis with limited target data. It consists of three key stages: (i) self-supervised pre-training on unlabeled data with Barlow Twins, (ii) self-distillation on task-related data, and (iii) fine-tuning on the target dataset. Our approach significantly outperforms traditional training strategies, achieving a balanced accuracy of 75.6%. We further provide insights into the training process by visualizing changes in the latent space after each step. Finally, we validate the robustness of Triplet Training in terms of its individual components in a comprehensive ablation study. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：ColorMNet: A Memory-based Deep Spatial-Temporal Feature Propagation  Network for Video Colorization</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06251">https://arxiv.org/abs/2404.06251</a></p>
  <p><b>作者</b>：Yixin Yang,  Jiangxin Dong,  Jinhui Tang,  Jinshan Pan</p>
  <p><b>备注</b>：Project website: \url{this https URL}</p>
  <p><b>关键词</b>：feature propagation module, features, memory-based feature propagation, feature propagation, estimated features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How to effectively explore spatial-temporal features is important for video colorization. Instead of stacking multiple frames along the temporal dimension or recurrently propagating estimated features that will accumulate errors or cannot explore information from far-apart frames, we develop a memory-based feature propagation module that can establish reliable connections with features from far-apart frames and alleviate the influence of inaccurately estimated features. To extract better features from each frame for the above-mentioned feature propagation, we explore the features from large-pretrained visual models to guide the feature estimation of each frame so that the estimated features can model complex scenarios. In addition, we note that adjacent frames usually contain similar contents. To explore this property for better spatial and temporal feature utilization, we develop a local attention module to aggregate the features from adjacent frames in a spatial-temporal neighborhood. We formulate our memory-based feature propagation module, large-pretrained visual model guided feature estimation module, and local attention module into an end-to-end trainable network (named ColorMNet) and show that it performs favorably against state-of-the-art methods on both the benchmark datasets and real-world scenarios. The source code and pre-trained models will be available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：LRR: Language-Driven Resamplable Continuous Representation against  Adversarial Tracking Attacks</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06247">https://arxiv.org/abs/2404.06247</a></p>
  <p><b>作者</b>：Jianlang Chen,  Xuhong Ren,  Qing Guo,  Felix Juefei-Xu,  Di Lin,  Wei Feng,  Lei Ma,  Jianjun Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual-based autonomous systems, autonomous systems, live video, plays a critical, critical role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual object tracking plays a critical role in visual-based autonomous systems, as it aims to estimate the position and size of the object of interest within a live video. Despite significant progress made in this field, state-of-the-art (SOTA) trackers often fail when faced with adversarial perturbations in the incoming frames. This can lead to significant robustness and security issues when these trackers are deployed in the real world. To achieve high accuracy on both clean and adversarial data, we propose building a spatial-temporal continuous representation using the semantic text guidance of the object of interest. This novel continuous representation enables us to reconstruct incoming frames to maintain semantic and appearance consistency with the object of interest and its clean counterparts. As a result, our proposed method successfully defends against different SOTA adversarial tracking attacks while maintaining high accuracy on clean data. In particular, our method significantly increases tracking accuracy under adversarial attacks with around 90% relative improvement on UAV123, which is even higher than the accuracy on clean data.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：GHNeRF: Learning Generalizable Human Features with Efficient Neural  Radiance Fields</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06246">https://arxiv.org/abs/2404.06246</a></p>
  <p><b>作者</b>：Arnab Dey,  Di Yang,  Rohith Agaram,  Antitza Dantcheva,  Andrew I. Comport,  Srinath Sridhar,  Jean Martinet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, advances in Neural, demonstrated promising results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in Neural Radiance Fields (NeRF) have demonstrated promising results in 3D scene representations, including 3D human representations. However, these representations often lack crucial information on the underlying human pose and structure, which is crucial for AR/VR applications and games. In this paper, we introduce a novel approach, termed GHNeRF, designed to address these limitations by learning 2D/3D joint locations of human subjects with NeRF representation. GHNeRF uses a pre-trained 2D encoder streamlined to extract essential human features from 2D images, which are then incorporated into the NeRF framework in order to encode human biomechanic features. This allows our network to simultaneously learn biomechanic features, such as joint locations, along with human geometry and texture. To assess the effectiveness of our method, we conduct a comprehensive comparison with state-of-the-art human NeRF techniques and joint estimation algorithms. Our results show that GHNeRF can achieve state-of-the-art results in near real-time.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Anchor-based Robust Finetuning of Vision-Language Models</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06244">https://arxiv.org/abs/2404.06244</a></p>
  <p><b>作者</b>：Jinwei Han,  Zhiwen Lin,  Zhongyisun Sun,  Yingguo Gao,  Ke Yan,  Shouhong Ding,  Yuan Gao,  Gui-Song Xia</p>
  <p><b>备注</b>：CVPR2024</p>
  <p><b>关键词</b>：OOD generalization, diminished OOD generalization, OOD, rich semantic information, OOD generalization capabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We aim at finetuning a vision-language model without hurting its out-of-distribution (OOD) generalization. We address two types of OOD generalization, i.e., i) domain shift such as natural to sketch images, and ii) zero-shot capability to recognize the category that was not contained in the finetune data. Arguably, the diminished OOD generalization after finetuning stems from the excessively simplified finetuning target, which only provides the class information, such as ``a photo of a [CLASS]''. This is distinct from the process in that CLIP was pretrained, where there is abundant text supervision with rich semantic information. Therefore, we propose to compensate for the finetune process using auxiliary supervision with rich semantic information, which acts as anchors to preserve the OOD generalization. Specifically, two types of anchors are elaborated in our method, including i) text-compensated anchor which uses the images from the finetune set but enriches the text supervision from a pretrained captioner, ii) image-text-pair anchor which is retrieved from the dataset similar to pretraining data of CLIP according to the downstream task, associating with the original CLIP text with rich semantics. Those anchors are utilized as auxiliary semantic information to maintain the original feature space of CLIP, thereby preserving the OOD generalization capabilities. Comprehensive experiments demonstrate that our method achieves in-distribution performance akin to conventional finetuning while attaining new state-of-the-art results on domain shift and zero-shot learning benchmarks.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised  Action Recognition in Videos</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06243">https://arxiv.org/abs/2404.06243</a></p>
  <p><b>作者</b>：Sharana Dharshikgan Suresh Dass,  Hrishav Bakul Barua,  Ganesh Krishnasamy,  Raveendran Paramesran,  Raphael C.-W. Phan</p>
  <p><b>备注</b>：Submitted for peer review</p>
  <p><b>关键词</b>：self-driving cars, sports analytics, surveillance and monitoring, human-robot interaction, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human action or activity recognition in videos is a fundamental task in computer vision with applications in surveillance and monitoring, self-driving cars, sports analytics, human-robot interaction and many more. Traditional supervised methods require large annotated datasets for training, which are expensive and time-consuming to acquire. This work proposes a novel approach using Cross-Architecture Pseudo-Labeling with contrastive learning for semi-supervised action recognition. Our framework leverages both labeled and unlabelled data to robustly learn action representations in videos, combining pseudo-labeling with contrastive learning for effective learning from both types of samples. We introduce a novel cross-architecture approach where 3D Convolutional Neural Networks (3D CNNs) and video transformers (VIT) are utilised to capture different aspects of action representations; hence we call it ActNetFormer. The 3D CNNs excel at capturing spatial features and local dependencies in the temporal domain, while VIT excels at capturing long-range dependencies across frames. By integrating these complementary architectures within the ActNetFormer framework, our approach can effectively capture both local and global contextual information of an action. This comprehensive representation learning enables the model to achieve better performance in semi-supervised action recognition tasks by leveraging the strengths of each of these architectures. Experimental results on standard action recognition datasets demonstrate that our approach performs better than the existing methods, achieving state-of-the-art performance with only a fraction of labeled data. The official website of this work is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Hyperparameter-Free Medical Image Synthesis for Sharing Data and  Improving Site-Specific Segmentation</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06240">https://arxiv.org/abs/2404.06240</a></p>
  <p><b>作者</b>：Alexander Chebykin,  Peter A. N. Bosman,  Tanja Alderliesten</p>
  <p><b>备注</b>：Accepted at MIDL 2024</p>
  <p><b>关键词</b>：improve patient privacy, medical image synthesis, synthetic medical images, sharing real images, Sharing synthetic medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sharing synthetic medical images is a promising alternative to sharing real images that can improve patient privacy and data security. To get good results, existing methods for medical image synthesis must be manually adjusted when they are applied to unseen data. To remove this manual burden, we introduce a Hyperparameter-Free distributed learning method for automatic medical image Synthesis, Sharing, and Segmentation called HyFree-S3. For three diverse segmentation settings (pelvic MRIs, lung X-rays, polyp photos), the use of HyFree-S3 results in improved performance over training only with site-specific data (in the majority of cases). The hyperparameter-free nature of the method should make data synthesis and sharing easier, potentially leading to an increase in the quantity of available data and consequently the quality of the models trained that may ultimately be applied in the clinic. Our code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Automatic Defect Detection in Sewer Network Using Deep Learning Based  Object Detector</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06219">https://arxiv.org/abs/2404.06219</a></p>
  <p><b>作者</b>：Bach Ha,  Birgit Schalter,  Laura White,  Joachim Koehler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Maintaining sewer systems, effort consuming, systems in large, large cities, time and effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Maintaining sewer systems in large cities is important, but also time and effort consuming, because visual inspections are currently done manually. To reduce the amount of aforementioned manual work, defects within sewer pipes should be located and classified automatically. In the past, multiple works have attempted solving this problem using classical image processing, machine learning, or a combination of those. However, each provided solution only focus on detecting a limited set of defect/structure types, such as fissure, root, and/or connection. Furthermore, due to the use of hand-crafted features and small training datasets, generalization is also problematic. In order to overcome these deficits, a sizable dataset with 14.7 km of various sewer pipes were annotated by sewer maintenance experts in the scope of this work. On top of that, an object detector (EfficientDet-D0) was trained for automatic defect detection. From the result of several expermients, peculiar natures of defects in the context of object detection, which greatly effect annotation and training process, are found and discussed. At the end, the final detector was able to detect 83% of defects in the test set; out of the missing 17%, only 0.77% are very severe defects. This work provides an example of applying deep learning-based object detection into an important but quiet engineering field. It also gives some practical pointers on how to annotate peculiar "object", such as defects.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：OmniFusion Technical Report</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06212">https://arxiv.org/abs/2404.06212</a></p>
  <p><b>作者</b>：Elizaveta Goncharova,  Anton Razzhigaev,  Matvey Mikhalchuk,  Maxim Kurkin,  Irina Abdullaeva,  Matvey Skripkin,  Ivan Oseledets,  Denis Dimitrov,  Andrey Kuznetsov</p>
  <p><b>备注</b>：17 pages, 4 figures, 9 tables, 2 appendices</p>
  <p><b>关键词</b>：multimodal architectures served, large language models, extending the capabilities, revolution in AI-based, AI-based approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Last year, multimodal architectures served up a revolution in AI-based approaches and solutions, extending the capabilities of large language models (LLM). We propose an \textit{OmniFusion} model based on a pretrained LLM and adapters for visual modality. We evaluated and compared several architecture design principles for better text and visual data coupling: MLP and transformer adapters, various CLIP ViT-based encoders (SigLIP, InternVIT, etc.), and their fusing approach, image encoding method (whole image or tiles encoding) and two 7B LLMs (the proprietary one and open-source Mistral). Experiments on 8 visual-language benchmarks show the top score for the best OmniFusion setup in terms of different VQA tasks in comparison with open-source LLaVA-like solutions: VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU. We also propose a variety of situations, where OmniFusion provides highly-detailed answers in different domains: housekeeping, sightseeing, culture, medicine, handwritten and scanned equations recognition, etc. Mistral-based OmniFusion model is an open-source solution with weights, training and inference scripts available at this https URL.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Unified Physical-Digital Attack Detection Challenge</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06211">https://arxiv.org/abs/2404.06211</a></p>
  <p><b>作者</b>：Haocheng Yuan,  Ajian Liu,  Junze Zheng,  Jun Wan,  Jiankang Deng,  Sergio Escalera,  Hugo Jair Escalante,  Isabelle Guyon,  Zhen Lei</p>
  <p><b>备注</b>：11 pages, 10 figures</p>
  <p><b>关键词</b>：safeguard Face Recognition, Unified Attack Detection, Attack Detection, Face Recognition, Face Attack Detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face Anti-Spoofing (FAS) is crucial to safeguard Face Recognition (FR) Systems. In real-world scenarios, FRs are confronted with both physical and digital attacks. However, existing algorithms often address only one type of attack at a time, which poses significant limitations in real-world scenarios where FR systems face hybrid physical-digital threats. To facilitate the research of Unified Attack Detection (UAD) algorithms, a large-scale UniAttackData dataset has been collected. UniAttackData is the largest public dataset for Unified Attack Detection, with a total of 28,706 videos, where each unique identity encompasses all advanced attack types. Based on this dataset, we organized a Unified Physical-Digital Face Attack Detection Challenge to boost the research in Unified Attack Detections. It attracted 136 teams for the development phase, with 13 qualifying for the final round. The results re-verified by the organizing team were used for the final ranking. This paper comprehensively reviews the challenge, detailing the dataset introduction, protocol definition, evaluation criteria, and a summary of published results. Finally, we focus on the detailed analysis of the highest-performing algorithms and offer potential directions for unified physical-digital attack detection inspired by this competition. Challenge Website: this https URL.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Leveraging edge detection and neural networks for better UAV  localization</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06207">https://arxiv.org/abs/2404.06207</a></p>
  <p><b>作者</b>：Theo Di Piazza,  Enric Meinhardt-Llopis,  Gabriele Facciolo,  Benedicte Bascle,  Corentin Abgrall,  Jean-Clement Devaux</p>
  <p><b>备注</b>：Accepted for publication in IGARSS2024. 4 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：Unmanned Aerial Vehicles, Navigation Satellite Systems, Global Navigation Satellite, geolocalizing Unmanned Aerial, lacking Global Navigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel method for geolocalizing Unmanned Aerial Vehicles (UAVs) in environments lacking Global Navigation Satellite Systems (GNSS). Current state-of-the-art techniques employ an offline-trained encoder to generate a vector representation (embedding) of the UAV's current view, which is then compared with pre-computed embeddings of geo-referenced images to determine the UAV's position. Here, we demonstrate that the performance of these methods can be significantly enhanced by preprocessing the images to extract their edges, which exhibit robustness to seasonal and illumination variations. Furthermore, we establish that utilizing edges enhances resilience to orientation and altitude inaccuracies. Additionally, we introduce a confidence criterion for localization. Our findings are substantiated through synthetic experiments.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Automated National Urban Map Extraction</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06202">https://arxiv.org/abs/2404.06202</a></p>
  <p><b>作者</b>：Hasan Nasrallah,  Abed Ellatif Samhat,  Cristiano Nattero,  Ali J. Ghandour</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate and regularly, regularly update, national rooftop map, rooftop map, buildings' instance segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Developing countries usually lack the proper governance means to generate and regularly update a national rooftop map. Using traditional photogrammetry and surveying methods to produce a building map at the federal level is costly and time consuming. Using earth observation and deep learning methods, we can bridge this gap and propose an automated pipeline to fetch such national urban maps. This paper aims to exploit the power of fully convolutional neural networks for multi-class buildings' instance segmentation to leverage high object-wise accuracy results. Buildings' instance segmentation from sub-meter high-resolution satellite images can be achieved with relatively high pixel-wise metric scores. We detail all engineering steps to replicate this work and ensure highly accurate results in dense and slum areas witnessed in regions that lack proper urban planning in the Global South. We applied a case study of the proposed pipeline to Lebanon and successfully produced the first comprehensive national building footprint map with approximately 1 Million units with an 84% accuracy. The proposed architecture relies on advanced augmentation techniques to overcome dataset scarcity, which is often the case in developing countries.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Exploring the Potential of Large Foundation Models for Open-Vocabulary  HOI Detection</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06194">https://arxiv.org/abs/2404.06194</a></p>
  <p><b>作者</b>：Ting Lei,  Shaofeng Yin,  Yang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding human-centric scenes, open vocabulary HOI, vocabulary HOI detection, problem of detecting, guided by natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-vocabulary human-object interaction (HOI) detection, which is concerned with the problem of detecting novel HOIs guided by natural language, is crucial for understanding human-centric scenes. However, prior zero-shot HOI detectors often employ the same levels of feature maps to model HOIs with varying distances, leading to suboptimal performance in scenes containing human-object pairs with a wide range of distances. In addition, these detectors primarily rely on category names and overlook the rich contextual information that language can provide, which is essential for capturing open vocabulary concepts that are typically rare and not well-represented by category names alone. In this paper, we introduce a novel end-to-end open vocabulary HOI detection framework with conditional multi-level decoding and fine-grained semantic enhancement (CMD-SE), harnessing the potential of Visual-Language Models (VLMs). Specifically, we propose to model human-object pairs with different distances with different levels of feature maps by incorporating a soft constraint during the bipartite matching process. Furthermore, by leveraging large language models (LLMs) such as GPT models, we exploit their extensive world knowledge to generate descriptions of human body part states for various interactions. Then we integrate the generalizable and fine-grained semantics of human body parts to improve interaction recognition. Experimental results on two datasets, SWIG-HOI and HICO-DET, demonstrate that our proposed method achieves state-of-the-art results in open vocabulary HOI detection. The code and models are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：EPL: Evidential Prototype Learning for Semi-supervised Medical Image  Segmentation</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06181">https://arxiv.org/abs/2404.06181</a></p>
  <p><b>作者</b>：Yuanpeng He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：current semi-supervised medical, semi-supervised medical segmentation, medical segmentation methods, achieve decent performance, Evidential Prototype Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although current semi-supervised medical segmentation methods can achieve decent performance, they are still affected by the uncertainty in unlabeled data and model predictions, and there is currently a lack of effective strategies that can explore the uncertain aspects of both simultaneously. To address the aforementioned issues, we propose Evidential Prototype Learning (EPL), which utilizes an extended probabilistic framework to effectively fuse voxel probability predictions from different sources and achieves prototype fusion utilization of labeled and unlabeled data under a generalized evidential framework, leveraging voxel-level dual uncertainty masking. The uncertainty not only enables the model to self-correct predictions but also improves the guided learning process with pseudo-labels and is able to feed back into the construction of hidden features. The method proposed in this paper has been experimented on LA, Pancreas-CT and TBAD datasets, achieving the state-of-the-art performance in three different labeled ratios, which strongly demonstrates the effectiveness of our strategy.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：YOLC: You Only Look Clusters for Tiny Object Detection in Aerial Images</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06180">https://arxiv.org/abs/2404.06180</a></p>
  <p><b>作者</b>：Chenguang Liu,  Guangshuai Gao,  Ziyue Huang,  Zhenghui Hu,  Qingjie Liu,  Yunhong Wang</p>
  <p><b>备注</b>：accepted to TITS</p>
  <p><b>关键词</b>：significant challenges due, poses significant challenges, images poses significant, poses significant, aerial images poses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting objects from aerial images poses significant challenges due to the following factors: 1) Aerial images typically have very large sizes, generally with millions or even hundreds of millions of pixels, while computational resources are limited. 2) Small object size leads to insufficient information for effective detection. 3) Non-uniform object distribution leads to computational resource wastage. To address these issues, we propose YOLC (You Only Look Clusters), an efficient and effective framework that builds on an anchor-free object detector, CenterNet. To overcome the challenges posed by large-scale images and non-uniform object distribution, we introduce a Local Scale Module (LSM) that adaptively searches cluster regions for zooming in for accurate detection. Additionally, we modify the regression loss using Gaussian Wasserstein distance (GWD) to obtain high-quality bounding boxes. Deformable convolution and refinement methods are employed in the detection head to enhance the detection of small objects. We perform extensive experiments on two aerial image datasets, including Visdrone2019 and UAVDT, to demonstrate the effectiveness and superiority of our proposed approach.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06177">https://arxiv.org/abs/2404.06177</a></p>
  <p><b>作者</b>：Yuanpeng He,  Lijian Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uncertainty-based semi-supervised medical, semi-supervised medical segmentation, single uncertainty evaluation, existing uncertainty-based semi-supervised, medical segmentation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the existing uncertainty-based semi-supervised medical segmentation methods have achieved excellent performance, they usually only consider a single uncertainty evaluation, which often fails to solve the problem related to credibility completely. Therefore, based on the framework of evidential deep learning, this paper integrates the evidential predictive results in the cross-region of mixed and original samples to reallocate the confidence degree and uncertainty measure of each voxel, which is realized by emphasizing uncertain information of probability assignments fusion rule of traditional evidence theory. Furthermore, we design a voxel-level asymptotic learning strategy by introducing information entropy to combine with the fused uncertainty measure to estimate voxel prediction more precisely. The model will gradually pay attention to the prediction results with high uncertainty in the learning process, to learn the features that are difficult to master. The experimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the superior performance of our proposed method in comparison with the existing state of the arts.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Improving Interpretable Embeddings for Ad-hoc Video Search with  Generative Captions and Multi-word Concept Bank</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06173">https://arxiv.org/abs/2404.06173</a></p>
  <p><b>作者</b>：Jiaxin Wu,  Chong-Wah Ngo,  Wing-Kwong Chan</p>
  <p><b>备注</b>：Accepted in ICMR2024</p>
  <p><b>关键词</b>：cross-modal latent space, ad-hoc video search, multi-word concept bank, Aligning a user, clips in cross-modal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aligning a user query and video clips in cross-modal latent space and that with semantic concepts are two mainstream approaches for ad-hoc video search (AVS). However, the effectiveness of existing approaches is bottlenecked by the small sizes of available video-text datasets and the low quality of concept banks, which results in the failures of unseen queries and the out-of-vocabulary problem. This paper addresses these two problems by constructing a new dataset and developing a multi-word concept bank. Specifically, capitalizing on a generative model, we construct a new dataset consisting of 7 million generated text and video pairs for pre-training. To tackle the out-of-vocabulary problem, we develop a multi-word concept bank based on syntax analysis to enhance the capability of a state-of-the-art interpretable AVS method in modeling relationships between query words. We also study the impact of current advanced features on the method. Experimental results show that the integration of the above-proposed elements doubles the R@1 performance of the AVS method on the MSRVTT dataset and improves the xinfAP on the TRECVid AVS query sets for 2016-2023 (eight years) by a margin from 2% to 77%, with an average about 20%.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Enhanced Radar Perception via Multi-Task Learning: Towards Refined Data  for Sensor Fusion Applications</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06165">https://arxiv.org/abs/2404.06165</a></p>
  <p><b>作者</b>：Huawei Sun,  Hao Feng,  Gianfranco Mauro,  Julius Ott,  Georg Stettinger,  Lorenzo Servadei,  Robert Wille</p>
  <p><b>备注</b>：Accepted by IEEE Intelligent Vehicles Symposium (IV 2024)</p>
  <p><b>关键词</b>：fusion yields robustness, yields robustness, leveraging the strength, camera fusion yields, Radar</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Radar and camera fusion yields robustness in perception tasks by leveraging the strength of both sensors. The typical extracted radar point cloud is 2D without height information due to insufficient antennas along the elevation axis, which challenges the network performance. This work introduces a learning-based approach to infer the height of radar points associated with 3D objects. A novel robust regression loss is introduced to address the sparse target challenge. In addition, a multi-task training strategy is employed, emphasizing important features. The average radar absolute height error decreases from 1.69 to 0.25 meters compared to the state-of-the-art height extension method. The estimated target height values are used to preprocess and enrich radar data for downstream perception tasks. Integrating this refined radar information further enhances the performance of existing radar camera fusion models for object detection and depth estimation tasks.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Efficient and Robust Point Cloud Registration via Heuristics-guided  Parameter Search</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06155">https://arxiv.org/abs/2404.06155</a></p>
  <p><b>作者</b>：Tianyu Huang,  Haoang Li,  Liangzu Peng,  Yinlong Liu,  Yun-Hui Liu</p>
  <p><b>备注</b>：21 pages, 16 figures. Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024</p>
  <p><b>关键词</b>：point cloud registration, Estimating the rigid, degrees of freedom, rigid transformation, freedom based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating the rigid transformation with 6 degrees of freedom based on a putative 3D correspondence set is a crucial procedure in point cloud registration. Existing correspondence identification methods usually lead to large outlier ratios ($>$ 95 $\%$ is common), underscoring the significance of robust registration methods. Many researchers turn to parameter search-based strategies (e.g., Branch-and-Bround) for robust registration. Although related methods show high robustness, their efficiency is limited to the high-dimensional search space. This paper proposes a heuristics-guided parameter search strategy to accelerate the search while maintaining high robustness. We first sample some correspondences (i.e., heuristics) and then just need to sequentially search the feasible regions that make each sample an inlier. Our strategy largely reduces the search space and can guarantee accuracy with only a few inlier samples, therefore enjoying an excellent trade-off between efficiency and robustness. Since directly parameterizing the 6-dimensional nonlinear feasible region for efficient search is intractable, we construct a three-stage decomposition pipeline to reparameterize the feasible region, resulting in three lower-dimensional sub-problems that are easily solvable via our strategy. Besides reducing the searching dimension, our decomposition enables the leverage of 1-dimensional interval stabbing at all three stages for searching acceleration. Moreover, we propose a valid sampling strategy to guarantee our sampling effectiveness, and a compatibility verification setup to further accelerate our search. Extensive experiments on both simulated and real-world datasets demonstrate that our approach exhibits comparable robustness with state-of-the-art methods while achieving a significant efficiency boost.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Concise Plane Arrangements for Low-Poly Surface and Volume Modelling</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06154">https://arxiv.org/abs/2404.06154</a></p>
  <p><b>作者</b>：Raphael Sulzer,  Florent Lafarge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：volume modelling, Plane arrangements, Plane, modelling, construction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Plane arrangements are a useful tool for surface and volume modelling. However, their main drawback is poor scalability. We introduce two key novelties that enable the construction of plane arrangements for complex objects and entire scenes: an ordering scheme for the plane insertion and the direct use of input points during arrangement construction. Both ingredients reduce the number of unwanted splits, resulting in improved scalability of the construction mechanism by up to two orders of magnitude compared to existing algorithms. We further introduce a remeshing and simplification technique that allows us to extract low-polygon surface meshes and lightweight convex decompositions of volumes from the arrangement. We show that our approach leads to state-of-the-art results for the aforementioned tasks by comparing it to learning-based and traditional approaches on various different datasets. Our implementation is available at this https URL .</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：HFNeRF: Learning Human Biomechanic Features with Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06152">https://arxiv.org/abs/2404.06152</a></p>
  <p><b>作者</b>：Arnab Dey,  Di Yang,  Antitza Dantcheva,  Jean Martinet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, generalizable Neural Radiance, Neural Radiance, based methods applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent advancements in novel view synthesis, generalizable Neural Radiance Fields (NeRF) based methods applied to human subjects have shown remarkable results in generating novel views from few images. However, this generalization ability cannot capture the underlying structural features of the skeleton shared across all instances. Building upon this, we introduce HFNeRF: a novel generalizable human feature NeRF aimed at generating human biomechanic features using a pre-trained image encoder. While previous human NeRF methods have shown promising results in the generation of photorealistic virtual avatars, such methods lack underlying human structure or biomechanic features such as skeleton or joint information that are crucial for downstream applications including Augmented Reality (AR)/Virtual Reality (VR). HFNeRF leverages 2D pre-trained foundation models toward learning human features in 3D using neural rendering, and then volume rendering towards generating 2D feature maps. We evaluate HFNeRF in the skeleton estimation task by predicting heatmaps as features. The proposed method is fully differentiable, allowing to successfully learn color, geometry, and human skeleton in a simultaneous manner. This paper presents preliminary results of HFNeRF, illustrating its potential in generating realistic virtual avatars with biomechanic features using NeRF.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：DiffHarmony: Latent Diffusion Model Meets Image Harmonization</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06139">https://arxiv.org/abs/2404.06139</a></p>
  <p><b>作者</b>：Pengfei Zhou,  Fangxiang Feng,  Xiaojie Wang</p>
  <p><b>备注</b>：Accepted by ICMR 2024</p>
  <p><b>关键词</b>：unified visual consistency, pre-trained latent diffusion, Diffusion models, adjusting the foreground, attain a unified</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image harmonization, which involves adjusting the foreground of a composite image to attain a unified visual consistency with the background, can be conceptualized as an image-to-image translation task. Diffusion models have recently promoted the rapid development of image-to-image translation tasks . However, training diffusion models from scratch is computationally intensive. Fine-tuning pre-trained latent diffusion models entails dealing with the reconstruction error induced by the image compression autoencoder, making it unsuitable for image generation tasks that involve pixel-level evaluation metrics. To deal with these issues, in this paper, we first adapt a pre-trained latent diffusion model to the image harmonization task to generate the harmonious but potentially blurry initial images. Then we implement two strategies: utilizing higher-resolution images during inference and incorporating an additional refinement stage, to further enhance the clarity of the initially harmonized images. Extensive experiments on iHarmony4 datasets demonstrate the superiority of our proposed method. The code and model will be made publicly available at this https URL .</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Mansformer: Efficient Transformer of Mixed Attention for Image  Deblurring and Beyond</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06135">https://arxiv.org/abs/2404.06135</a></p>
  <p><b>作者</b>：Pin-Hung Kuo,  Jinshan Pan,  Shao-Yi Chien,  Ming-Hsuan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, past few years, enormous success, success in natural, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer has made an enormous success in natural language processing and high-level vision over the past few years. However, the complexity of self-attention is quadratic to the image size, which makes it infeasible for high-resolution vision tasks. In this paper, we propose the Mansformer, a Transformer of mixed attention that combines multiple self-attentions, gate, and multi-layer perceptions (MLPs), to explore and employ more possibilities of self-attention. Taking efficiency into account, we design four kinds of self-attention, whose complexities are all linear. By elaborate adjustment of the tensor shapes and dimensions for the dot product, we split the typical self-attention of quadratic complexity into four operations of linear complexity. To adaptively merge these different kinds of self-attention, we take advantage of an architecture similar to Squeeze-and-Excitation Networks. Furthermore, we make it to merge the two-staged Transformer design into one stage by the proposed gated-dconv MLP. Image deblurring is our main target, while extensive quantitative and qualitative evaluations show that this method performs favorably against the state-of-the-art methods far more than simply deblurring. The source codes and trained models will be made available to the public.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Gaussian Pancakes: Geometrically-Regularized 3D Gaussian Splatting for  Realistic Endoscopic Reconstruction</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06128">https://arxiv.org/abs/2404.06128</a></p>
  <p><b>作者</b>：Sierra Bonilla,  Shuai Zhang,  Dimitrios Psychogyios,  Danail Stoyanov,  Francisco Vasconcelos,  Sophia Bano</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：conventional colonoscopy techniques, face critical limitations, colonoscopy techniques face, techniques face critical, conventional colonoscopy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within colorectal cancer diagnostics, conventional colonoscopy techniques face critical limitations, including a limited field of view and a lack of depth information, which can impede the detection of precancerous lesions. Current methods struggle to provide comprehensive and accurate 3D reconstructions of the colonic surface which can help minimize the missing regions and reinspection for pre-cancerous polyps. Addressing this, we introduce 'Gaussian Pancakes', a method that leverages 3D Gaussian Splatting (3D GS) combined with a Recurrent Neural Network-based Simultaneous Localization and Mapping (RNNSLAM) system. By introducing geometric and depth regularization into the 3D GS framework, our approach ensures more accurate alignment of Gaussians with the colon surface, resulting in smoother 3D reconstructions with novel viewing of detailed textures and structures. Evaluations across three diverse datasets show that Gaussian Pancakes enhances novel view synthesis quality, surpassing current leading methods with a 18% boost in PSNR and a 16% improvement in SSIM. It also delivers over 100X faster rendering and more than 10X shorter training times, making it a practical tool for real-time applications. Hence, this holds promise for achieving clinical translation for better detection and diagnosis of colorectal cancer.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Hierarchical Insights: Exploiting Structural Similarities for Reliable  3D Semantic Segmentation</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06124">https://arxiv.org/abs/2404.06124</a></p>
  <p><b>作者</b>：Mariella Dreissig,  Florian Piewak,  Joschka Boedecker</p>
  <p><b>备注</b>：submitted to IROS 2024</p>
  <p><b>关键词</b>：autonomous driving call, withstand highly diverse, environment perception algorithms, Safety-critical applications, call for robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Safety-critical applications like autonomous driving call for robust 3D environment perception algorithms which can withstand highly diverse and ambiguous surroundings. The predictive performance of any classification model strongly depends on the underlying dataset and the prior knowledge conveyed by the annotated labels. While the labels provide a basis for the learning process, they usually fail to represent inherent relations between the classes - representations, which are a natural element of the human perception system. We propose a training strategy which enables a 3D LiDAR semantic segmentation model to learn structural relationships between the different classes through abstraction. We achieve this by implicitly modeling those relationships through a learning rule for hierarchical multi-label classification (HMC). With a detailed analysis we show, how this training strategy not only improves the model's confidence calibration, but also preserves additional information for downstream tasks like fusion, prediction and planning.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：DreamView: Injecting View-specific Text Guidance into Text-to-3D  Generation</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06119">https://arxiv.org/abs/2404.06119</a></p>
  <p><b>作者</b>：Junkai Yan,  Yipeng Gao,  Qize Yang,  Xihan Wei,  Xuansong Xie,  Ancong Wu,  Wei-Shi Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly progressed, text guidance, text, text description, guidance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-3D generation, which synthesizes 3D assets according to an overall text description, has significantly progressed. However, a challenge arises when the specific appearances need customizing at designated viewpoints but referring solely to the overall description for generating 3D objects. For instance, ambiguity easily occurs when producing a T-shirt with distinct patterns on its front and back using a single overall text guidance. In this work, we propose DreamView, a text-to-image approach enabling multi-view customization while maintaining overall consistency by adaptively injecting the view-specific and overall text guidance through a collaborative text guidance injection module, which can also be lifted to 3D generation via score distillation sampling. DreamView is trained with large-scale rendered multi-view images and their corresponding view-specific texts to learn to balance the separate content manipulation in each view and the global consistency of the overall object, resulting in a dual achievement of customization and consistency. Consequently, DreamView empowers artists to design 3D objects creatively, fostering the creation of more innovative and diverse 3D assets. Code and model will be released at this https URL.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Revising Densification in Gaussian Splatting</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06109">https://arxiv.org/abs/2404.06109</a></p>
  <p><b>作者</b>：Samuel Rota Bulò,  Lorenzo Porzi,  Peter Kontschieder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Gaussian Splatting, Adaptive Density Control, method achieving high-quality, Adaptive Density, representation method achieving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we address the limitations of Adaptive Density Control (ADC) in 3D Gaussian Splatting (3DGS), a scene representation method achieving high-quality, photorealistic results for novel view synthesis. ADC has been introduced for automatic 3D point primitive management, controlling densification and pruning, however, with certain limitations in the densification logic. Our main contribution is a more principled, pixel-error driven formulation for density control in 3DGS, leveraging an auxiliary, per-pixel error function as the criterion for densification. We further introduce a mechanism to control the total number of primitives generated per scene and correct a bias in the current opacity handling strategy of ADC during cloning operations. Our approach leads to consistent quality improvements across a variety of benchmark scenes, without sacrificing the method's efficiency.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Hash3D: Training-free Acceleration for 3D Generation</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06091">https://arxiv.org/abs/2404.06091</a></p>
  <p><b>作者</b>：Xingyi Yang,  Xinchao Wang</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：generative modeling, notably propelled, diffusion, model, generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The evolution of 3D generative modeling has been notably propelled by the adoption of 2D diffusion models. Despite this progress, the cumbersome optimization process per se presents a critical hurdle to efficiency. In this paper, we introduce Hash3D, a universal acceleration for 3D generation without model training. Central to Hash3D is the insight that feature-map redundancy is prevalent in images rendered from camera positions and diffusion time-steps in close proximity. By effectively hashing and reusing these feature maps across neighboring timesteps and camera angles, Hash3D substantially prevents redundant calculations, thus accelerating the diffusion model's inference in 3D generation tasks. We achieve this through an adaptive grid-based hashing. Surprisingly, this feature-sharing mechanism not only speed up the generation but also enhances the smoothness and view consistency of the synthesized 3D objects. Our experiments covering 5 text-to-3D and 3 image-to-3D models, demonstrate Hash3D's versatility to speed up optimization, enhancing efficiency by 1.3 to 4 times. Additionally, Hash3D's integration with 3D Gaussian splatting largely speeds up 3D model creation, reducing text-to-3D processing to about 10 minutes and image-to-3D conversion to roughly 30 seconds. The project page is at this https URL.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：LIPT: Latency-aware Image Processing Transformer</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06075">https://arxiv.org/abs/2404.06075</a></p>
  <p><b>作者</b>：Junbo Qiao,  Wei Li,  Haizhen Xie,  Hanting Chen,  Yunshuai Zhou,  Zhijun Tu,  Jie Hu,  Shaohui Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image processing, leading a trend, image processing transformers, image, LIPT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer is leading a trend in the field of image processing. Despite the great success that existing lightweight image processing transformers have achieved, they are tailored to FLOPs or parameters reduction, rather than practical inference acceleration. In this paper, we present a latency-aware image processing transformer, termed LIPT. We devise the low-latency proportion LIPT block that substitutes memory-intensive operators with the combination of self-attention and convolutions to achieve practical speedup. Specifically, we propose a novel non-volatile sparse masking self-attention (NVSM-SA) that utilizes a pre-computing sparse mask to capture contextual information from a larger window with no extra computation overload. Besides, a high-frequency reparameterization module (HRM) is proposed to make LIPT block reparameterization friendly, which improves the model's detail reconstruction capability. Extensive experiments on multiple image processing tasks (e.g., image super-resolution (SR), JPEG artifact reduction, and image denoising) demonstrate the superiority of LIPT on both latency and PSNR. LIPT achieves real-time GPU inference with state-of-the-art performance on multiple image SR benchmarks.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Unified Entropy Optimization for Open-Set Test-Time Adaptation</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06065">https://arxiv.org/abs/2404.06065</a></p>
  <p><b>作者</b>：Zhengqing Gao,  Xu-Yao Zhang,  Cheng-Lin Liu</p>
  <p><b>备注</b>：CVPR 2024</p>
  <p><b>关键词</b>：labeled source domain, unlabeled target domain, Test-time adaptation, labeled source, TTA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Test-time adaptation (TTA) aims at adapting a model pre-trained on the labeled source domain to the unlabeled target domain. Existing methods usually focus on improving TTA performance under covariate shifts, while neglecting semantic shifts. In this paper, we delve into a realistic open-set TTA setting where the target domain may contain samples from unknown classes. Many state-of-the-art closed-set TTA methods perform poorly when applied to open-set scenarios, which can be attributed to the inaccurate estimation of data distribution and model confidence. To address these issues, we propose a simple but effective framework called unified entropy optimization (UniEnt), which is capable of simultaneously adapting to covariate-shifted in-distribution (csID) data and detecting covariate-shifted out-of-distribution (csOOD) data. Specifically, UniEnt first mines pseudo-csID and pseudo-csOOD samples from test data, followed by entropy minimization on the pseudo-csID data and entropy maximization on the pseudo-csOOD data. Furthermore, we introduce UniEnt+ to alleviate the noise caused by hard data partition leveraging sample-level confidence. Extensive experiments on CIFAR benchmarks and Tiny-ImageNet-C show the superiority of our framework. The code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Unified Multi-modal Diagnostic Framework with Reconstruction  Pre-training and Heterogeneity-combat Tuning</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06057">https://arxiv.org/abs/2404.06057</a></p>
  <p><b>作者</b>：Yupei Zhang,  Li Pan,  Qiushi Yang,  Tan Li,  Zhen Chen</p>
  <p><b>备注</b>：to be published in IEEE JBHI; Code available at this https URL</p>
  <p><b>关键词</b>：leveraging large-scale unlabeled, large-scale unlabeled datasets, Medical Multi-modal Diagnostic, Unified Medical Multi-modal, Medical multi-modal pre-training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical multi-modal pre-training has revealed promise in computer-aided diagnosis by leveraging large-scale unlabeled datasets. However, existing methods based on masked autoencoders mainly rely on data-level reconstruction tasks, but lack high-level semantic information. Furthermore, two significant heterogeneity challenges hinder the transfer of pre-trained knowledge to downstream tasks, \textit{i.e.}, the distribution heterogeneity between pre-training data and downstream data, and the modality heterogeneity within downstream data. To address these challenges, we propose a Unified Medical Multi-modal Diagnostic (UMD) framework with tailored pre-training and downstream tuning strategies. Specifically, to enhance the representation abilities of vision and language encoders, we propose the Multi-level Reconstruction Pre-training (MR-Pretrain) strategy, including a feature-level and data-level reconstruction, which guides models to capture the semantic information from masked inputs of different modalities. Moreover, to tackle two kinds of heterogeneities during the downstream tuning, we present the heterogeneity-combat downstream tuning strategy, which consists of a Task-oriented Distribution Calibration (TD-Calib) and a Gradient-guided Modality Coordination (GM-Coord). In particular, TD-Calib fine-tunes the pre-trained model regarding the distribution of downstream datasets, and GM-Coord adjusts the gradient weights according to the dynamic optimization status of different modalities. Extensive experiments on five public medical datasets demonstrate the effectiveness of our UMD framework, which remarkably outperforms existing approaches on three kinds of downstream tasks.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Incremental Joint Learning of Depth, Pose and Implicit Scene  Representation on Monocular Camera in Large-scale Scenes</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06050">https://arxiv.org/abs/2404.06050</a></p>
  <p><b>作者</b>：Tianchen Deng,  Nailin Wang,  Chongdi Wang,  Shenghai Yuan,  Jingchuan Wang,  Danwei Wang,  Weidong Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：photo-realistic view synthesis, large-scale scenes, scene, autonomous vehicles, large-scale scene reconstruction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dense scene reconstruction for photo-realistic view synthesis has various applications, such as VR/AR, autonomous vehicles. However, most existing methods have difficulties in large-scale scenes due to three core challenges: \textit{(a) inaccurate depth input.} Accurate depth input is impossible to get in real-world large-scale scenes. \textit{(b) inaccurate pose estimation.} Most existing approaches rely on accurate pre-estimated camera poses. \textit{(c) insufficient scene representation capability.} A single global radiance field lacks the capacity to effectively scale to large-scale scenes. To this end, we propose an incremental joint learning framework, which can achieve accurate depth, pose estimation, and large-scale scene reconstruction. A vision transformer-based network is adopted as the backbone to enhance performance in scale information estimation. For pose estimation, a feature-metric bundle adjustment (FBA) method is designed for accurate and robust camera tracking in large-scale scenes. In terms of implicit scene representation, we propose an incremental scene representation method to construct the entire large-scale scene as multiple local radiance fields to enhance the scalability of 3D scene representation. Extended experiments have been conducted to demonstrate the effectiveness and accuracy of our method in depth estimation, pose estimation, and large-scale scene reconstruction.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Object Dynamics Modeling with Hierarchical Point Cloud-based  Representations</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06044">https://arxiv.org/abs/2404.06044</a></p>
  <p><b>作者</b>：Chanho Kim,  Li Fuxin</p>
  <p><b>备注</b>：CVPR 2024</p>
  <p><b>关键词</b>：Modeling object dynamics, numerous applications, object dynamics, problem with numerous, graph neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling object dynamics with a neural network is an important problem with numerous applications. Most recent work has been based on graph neural networks. However, physics happens in 3D space, where geometric information potentially plays an important role in modeling physical phenomena. In this work, we propose a novel U-net architecture based on continuous point convolution which naturally embeds information from 3D coordinates and allows for multi-scale feature representations with established downsampling and upsampling procedures. Bottleneck layers in the downsampled point clouds lead to better long-range interaction modeling. Besides, the flexibility of point convolutions allows our approach to generalize to sparsely sampled points from mesh vertices and dynamically generate features on important interaction points on mesh faces. Experimental results demonstrate that our approach significantly improves the state-of-the-art, especially in scenarios that require accurate gravity or collision reasoning.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Space-Time Video Super-resolution with Neural Operator</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06036">https://arxiv.org/abs/2404.06036</a></p>
  <p><b>作者</b>：Yuantong Zhang,  Hanyou Zheng,  Daiqin Yang,  Zhenzhong Chen,  Haichuan Ma,  Wenpeng Ding</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper addresses, continuous function space, continuous function, space-time video super-resolution, MEMC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the task of space-time video super-resolution (ST-VSR). Existing methods generally suffer from inaccurate motion estimation and motion compensation (MEMC) problems for large motions. Inspired by recent progress in physics-informed neural networks, we model the challenges of MEMC in ST-VSR as a mapping between two continuous function spaces. Specifically, our approach transforms independent low-resolution representations in the coarse-grained continuous function space into refined representations with enriched spatiotemporal details in the fine-grained continuous function space. To achieve efficient and accurate MEMC, we design a Galerkin-type attention function to perform frame alignment and temporal interpolation. Due to the linear complexity of the Galerkin-type attention mechanism, our model avoids patch partitioning and offers global receptive fields, enabling precise estimation of large motions. The experimental results show that the proposed method surpasses state-of-the-art techniques in both fixed-size and continuous space-time video super-resolution tasks.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Little Strokes Fell Great Oaks: Boosting the Hierarchical Features for  Multi-exposure Image Fusion</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06033">https://arxiv.org/abs/2404.06033</a></p>
  <p><b>作者</b>：Pan Mu,  Zhiying Du,  Jinyuan Liu,  Cong Bai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made remarkable strides, deep learning networks, recent years, deep learning, made remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, deep learning networks have made remarkable strides in the domain of multi-exposure image fusion. Nonetheless, prevailing approaches often involve directly feeding over-exposed and under-exposed images into the network, which leads to the under-utilization of inherent information present in the source images. Additionally, unsupervised techniques predominantly employ rudimentary weighted summation for color channel processing, culminating in an overall desaturated final image tone. To partially mitigate these issues, this study proposes a gamma correction module specifically designed to fully leverage latent information embedded within source images. Furthermore, a modified transformer block, embracing with self-attention mechanisms, is introduced to optimize the fusion process. Ultimately, a novel color enhancement algorithm is presented to augment image saturation while preserving intricate details. The source code is available at this <a href="this https URL rel=" external noopener nofollow" class="link-external link-https">this https URL url.</a></p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Improving Facial Landmark Detection Accuracy and Efficiency with  Knowledge Distillation</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06029">https://arxiv.org/abs/2404.06029</a></p>
  <p><b>作者</b>：Zong-Wei Hong,  Yu-Chen Lin</p>
  <p><b>备注</b>：technical report. 6th/165 in IEEE ICME 2024 PAIR competition</p>
  <p><b>关键词</b>：experienced significant advancements, augmented reality, emotion analysis, domain of computer, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The domain of computer vision has experienced significant advancements in facial-landmark detection, becoming increasingly essential across various applications such as augmented reality, facial recognition, and emotion analysis. Unlike object detection or semantic segmentation, which focus on identifying objects and outlining boundaries, faciallandmark detection aims to precisely locate and track critical facial features. However, deploying deep learning-based facial-landmark detection models on embedded systems with limited computational resources poses challenges due to the complexity of facial features, especially in dynamic settings. Additionally, ensuring robustness across diverse ethnicities and expressions presents further obstacles. Existing datasets often lack comprehensive representation of facial nuances, particularly within populations like those in Taiwan. This paper introduces a novel approach to address these challenges through the development of a knowledge distillation method. By transferring knowledge from larger models to smaller ones, we aim to create lightweight yet powerful deep learning models tailored specifically for facial-landmark detection tasks. Our goal is to design models capable of accurately locating facial landmarks under varying conditions, including diverse expressions, orientations, and lighting environments. The ultimate objective is to achieve high accuracy and real-time performance suitable for deployment on embedded systems. This method was successfully implemented and achieved a top 6th place finish out of 165 participants in the IEEE ICME 2024 PAIR competition.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Greedy-DiM: Greedy Algorithms for Unreasonably Effective Face Morphs</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06025">https://arxiv.org/abs/2404.06025</a></p>
  <p><b>作者</b>：Zander W. Blasingame,  Chen Liu</p>
  <p><b>备注</b>：Initial preprint. Under review</p>
  <p><b>关键词</b>：Face Recognition, Generative Adversarial Network, multiple identities, emerging threat, aim to create</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Morphing attacks are an emerging threat to state-of-the-art Face Recognition (FR) systems, which aim to create a single image that contains the biometric information of multiple identities. Diffusion Morphs (DiM) are a recently proposed morphing attack that has achieved state-of-the-art performance for representation-based morphing attacks. However, none of the existing research on DiMs have leveraged the iterative nature of DiMs and left the DiM model as a black box, treating it no differently than one would a Generative Adversarial Network (GAN) or Varational AutoEncoder (VAE). We propose a greedy strategy on the iterative sampling process of DiM models which searches for an optimal step guided by an identity-based heuristic function. We compare our proposed algorithm against ten other state-of-the-art morphing algorithms using the open-source SYN-MAD 2022 competition dataset. We find that our proposed algorithm is unreasonably effective, fooling all of the tested FR systems with an MMPMR of 100%, outperforming all other morphing algorithms compared.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Band-Attention Modulated RetNet for Face Forgery Detection</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06022">https://arxiv.org/abs/2404.06022</a></p>
  <p><b>作者</b>：Zhida Zhang,  Jie Cao,  Wenkui Yang,  Qihang Fan,  Kai Zhou,  Ran He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：http URL mitigate, efficiently process extensive, process extensive visual, avoiding catastrophic forgetting.Our, catastrophic forgetting.Our approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The transformer networks are extensively utilized in face forgery detection due to their scalability across large datasets.Despite their success, transformers face challenges in balancing the capture of global context, which is crucial for unveiling forgery clues, with computational this http URL mitigate this issue, we introduce Band-Attention modulated RetNet (BAR-Net), a lightweight network designed to efficiently process extensive visual contexts while avoiding catastrophic forgetting.Our approach empowers the target token to perceive global information by assigning differential attention levels to tokens at varying distances. We implement self-attention along both spatial axes, thereby maintaining spatial priors and easing the computational burden.Moreover, we present the adaptive frequency Band-Attention Modulation mechanism, which treats the entire Discrete Cosine Transform spectrogram as a series of frequency bands with learnable weights.Together, BAR-Net achieves favorable performance on several face forgery datasets, outperforming current state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Diffusion-Based Point Cloud Super-Resolution for mmWave Radar Data</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06012">https://arxiv.org/abs/2404.06012</a></p>
  <p><b>作者</b>：Kai Luan,  Chenghao Shi,  Neng Wang,  Yuwei Cheng,  Huimin Lu,  Xieyuanli Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adverse environmental conditions, outdoor mobile robotics, sensor maintains stable, maintains stable performance, all-weather perception tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The millimeter-wave radar sensor maintains stable performance under adverse environmental conditions, making it a promising solution for all-weather perception tasks, such as outdoor mobile robotics. However, the radar point clouds are relatively sparse and contain massive ghost points, which greatly limits the development of mmWave radar technology. In this paper, we propose a novel point cloud super-resolution approach for 3D mmWave radar data, named Radar-diffusion. Our approach employs the diffusion model defined by mean-reverting stochastic differential equations(SDE). Using our proposed new objective function with supervision from corresponding LiDAR point clouds, our approach efficiently handles radar ghost points and enhances the sparse mmWave radar point clouds to dense LiDAR-like point clouds. We evaluate our approach on two different datasets, and the experimental results show that our method outperforms the state-of-the-art baseline methods in 3D radar super-resolution tasks. Furthermore, we demonstrate that our enhanced radar point cloud is capable of downstream radar point-based registration tasks.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Concept-Attention Whitening for Interpretable Skin Lesion Diagnosis</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05997">https://arxiv.org/abs/2404.05997</a></p>
  <p><b>作者</b>：Junlin Hou,  Jilan Xu,  Hao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-world clinical applications, deep learning models, eXplainable Artificial Intelligence, clinical applications, Artificial Intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The black-box nature of deep learning models has raised concerns about their interpretability for successful deployment in real-world clinical applications. To address the concerns, eXplainable Artificial Intelligence (XAI) aims to provide clear and understandable explanations of the decision-making process. In the medical domain, concepts such as attributes of lesions or abnormalities serve as key evidence for deriving diagnostic results. However, existing concept-based models mainly depend on concepts that appear independently and require fine-grained concept annotations such as bounding boxes. A medical image usually contains multiple concepts and the fine-grained concept annotations are difficult to acquire. In this paper, we propose a novel Concept-Attention Whitening (CAW) framework for interpretable skin lesion diagnosis. CAW is comprised of a disease diagnosis branch and a concept alignment branch. In the former branch, we train the CNN with a CAW layer inserted to perform skin lesion diagnosis. The CAW layer decorrelates features and aligns image features to conceptual meanings via an orthogonal matrix. In the latter branch, we calculate the orthogonal matrix under the guidance of the concept attention mask. We particularly introduce a weakly-supervised concept mask generator that only leverages coarse concept labels for filtering local regions that are relevant to certain concepts, improving the optimization of the orthogonal matrix. Extensive experiments on two public skin lesion diagnosis datasets demonstrated that CAW not only enhanced interpretability but also maintained a state-of-the-art diagnostic performance.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：A Lightweight Measure of Classification Difficulty from Application  Dataset Characteristics</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05981">https://arxiv.org/abs/2404.05981</a></p>
  <p><b>作者</b>：Bryan Bo Cao,  Abhinav Sharma,  Lawrence O'Gorman,  Michael Coss,  Shubham Jain</p>
  <p><b>备注</b>：13 pages, 3 figures</p>
  <p><b>关键词</b>：neural network models, accuracy and computation, computation benchmarks, benchmarks being widely, choose among neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite accuracy and computation benchmarks being widely available to help choose among neural network models, these are usually trained on datasets with many classes, and do not give a precise idea of performance for applications of few (< 10) classes. The conventional procedure to predict performance is to train and test repeatedly on the different models and dataset variations of interest. However, this is computationally expensive. We propose an efficient classification difficulty measure that is calculated from the number of classes and intra- and inter-class similarity metrics of the dataset. After a single stage of training and testing per model family, relative performance for different datasets and models of the same family can be predicted by comparing difficulty measures - without further training and testing. We show how this measure can help a practitioner select a computationally efficient model for a small dataset 6 to 29x faster than through repeated training and testing. We give an example of use of the measure for an industrial application in which options are identified to select a model 42% smaller than the baseline YOLOv5-nano model, and if class merging from 3 to 2 classes meets requirements, 85% smaller.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Tackling Structural Hallucination in Image Translation with Local  Diffusion</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05980">https://arxiv.org/abs/2404.05980</a></p>
  <p><b>作者</b>：Seunghoi Kim,  Chen Jin,  Tom Diethe,  Matteo Figini,  Henry F. J. Tregidgo,  Asher Mullokandov,  Philip Teare,  Daniel C. Alexander</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced conditioned image, OOD, Recent developments, struggle with reconstructing, local OOD regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent developments in diffusion models have advanced conditioned image generation, yet they struggle with reconstructing out-of-distribution (OOD) images, such as unseen tumors in medical images, causing ``image hallucination'' and risking misdiagnosis. We hypothesize such hallucinations result from local OOD regions in the conditional images. We verify that partitioning the OOD region and conducting separate image generations alleviates hallucinations in several applications. From this, we propose a training-free diffusion framework that reduces hallucination with multiple Local Diffusion processes. Our approach involves OOD estimation followed by two modules: a ``branching'' module generates locally both within and outside OOD regions, and a ``fusion'' module integrates these predictions into one. Our evaluation shows our method mitigates hallucination over baseline models quantitatively and qualitatively, reducing misdiagnosis by 40% and 25% in the real-world medical and natural image datasets, respectively. It also demonstrates compatibility with various pre-trained diffusion models.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：StoryImager: A Unified and Efficient Framework for Coherent Story  Visualization and Completion</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05979">https://arxiv.org/abs/2404.05979</a></p>
  <p><b>作者</b>：Ming Tao,  Bing-Kun Bao,  Hao Tang,  Yaowei Wang,  Changsheng Xu</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：coherent images based, aims to generate, generate a series, series of realistic, realistic and coherent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Story visualization aims to generate a series of realistic and coherent images based on a storyline. Current models adopt a frame-by-frame architecture by transforming the pre-trained text-to-image model into an auto-regressive manner. Although these models have shown notable progress, there are still three flaws. 1) The unidirectional generation of auto-regressive manner restricts the usability in many scenarios. 2) The additional introduced story history encoders bring an extremely high computational cost. 3) The story visualization and continuation models are trained and inferred independently, which is not user-friendly. To these ends, we propose a bidirectional, unified, and efficient framework, namely StoryImager. The StoryImager enhances the storyboard generative ability inherited from the pre-trained text-to-image model for a bidirectional generation. Specifically, we introduce a Target Frame Masking Strategy to extend and unify different story image generation tasks. Furthermore, we propose a Frame-Story Cross Attention Module that decomposes the cross attention for local fidelity and global coherence. Moreover, we design a Contextual Feature Extractor to extract contextual information from the whole storyline. The extensive experimental results demonstrate the excellent performance of our StoryImager. The code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：JSTR: Judgment Improves Scene Text Recognition</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05967">https://arxiv.org/abs/2404.05967</a></p>
  <p><b>作者</b>：Masato Fujitake</p>
  <p><b>备注</b>：IntelliSys 2024</p>
  <p><b>关键词</b>：text recognition tasks, scene text recognition, text recognition, text recognition accuracy, tasks by judging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a method for enhancing the accuracy of scene text recognition tasks by judging whether the image and text match each other. While previous studies focused on generating the recognition results from input images, our approach also considers the model's misrecognition results to understand its error tendencies, thus improving the text recognition pipeline. This method boosts text recognition accuracy by providing explicit feedback on the data that the model is likely to misrecognize by predicting correct or incorrect between the image and text. The experimental results on publicly available datasets demonstrate that our proposed method outperforms the baseline and state-of-the-art methods in scene text recognition.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：EasyTrack: Efficient and Compact One-stream 3D Point Clouds Tracker</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05960">https://arxiv.org/abs/2404.05960</a></p>
  <p><b>作者</b>：Baojie Fan,  Wuyang Zhou,  Kai Wang,  Shijun Zhou,  Fengyu Xu,  Jiandong Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：single object trackers, point clouds tracking, point cloud backbones, search area point, Siamese or motion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most of 3D single object trackers (SOT) in point clouds follow the two-stream multi-stage 3D Siamese or motion tracking paradigms, which process the template and search area point clouds with two parallel branches, built on supervised point cloud backbones. In this work, beyond typical 3D Siamese or motion tracking, we propose a neat and compact one-stream transformer 3D SOT paradigm from the novel perspective, termed as \textbf{EasyTrack}, which consists of three special designs: 1) A 3D point clouds tracking feature pre-training module is developed to exploit the masked autoencoding for learning 3D point clouds tracking representations. 2) A unified 3D tracking feature learning and fusion network is proposed to simultaneously learns target-aware 3D features, and extensively captures mutual correlation through the flexible self-attention mechanism. 3) A target location network in the dense bird's eye view (BEV) feature space is constructed for target classification and regression. Moreover, we develop an enhanced version named EasyTrack++, which designs the center points interaction (CPI) strategy to reduce the ambiguous targets caused by the noise point cloud background information. The proposed EasyTrack and EasyTrack++ set a new state-of-the-art performance ($\textbf{18\%}$, $\textbf{40\%}$ and $\textbf{3\%}$ success gains) in KITTI, NuScenes, and Waymo while runing at \textbf{52.6fps} with few parameters (\textbf{1.3M}). The code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Prompt-driven Universal Model for View-Agnostic Echocardiography  Analysis</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05916">https://arxiv.org/abs/2404.05916</a></p>
  <p><b>作者</b>：Sekeun Kim,  Hui Ren,  Peng Guo,  Abder-Rahman Ali,  Patrick Zhang,  Kyungsang Kim,  Xiang Li,  Quanzheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming and resource-intensive, resource-intensive due, variability in image, image quality, necessity to process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Echocardiography segmentation for cardiac analysis is time-consuming and resource-intensive due to the variability in image quality and the necessity to process scans from various standard views. While current automated segmentation methods in echocardiography show promising performance, they are trained on specific scan views to analyze corresponding data. However, this solution has a limitation as the number of required models increases with the number of standard views. To address this, in this paper, we present a prompt-driven universal method for view-agnostic echocardiography analysis. Considering the domain shift between standard views, we first introduce a method called prompt matching, aimed at learning prompts specific to different views by matching prompts and querying input embeddings using a pre-trained vision model. Then, we utilized a pre-trained medical language model to align textual information with pixel data for accurate segmentation. Extensive experiments on three standard views showed that our approach significantly outperforms the state-of-the-art universal methods and achieves comparable or even better performances over the segmentation model trained and tested on same views.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：TabConv: Low-Computation CNN Inference via Table Lookups</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05872">https://arxiv.org/abs/2404.05872</a></p>
  <p><b>作者</b>：Neelesh Gupta,  Narayanan Kannan,  Pengmiao Zhang,  Viktor Prasanna</p>
  <p><b>备注</b>：8 pages, Accepted at CF '24</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, demonstrated remarkable ability, Convolutional Neural, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) have demonstrated remarkable ability throughout the field of computer vision. However, CNN inference requires a large number of arithmetic operations, making them expensive to deploy in hardware. Current approaches alleviate this issue by developing hardware-supported, algorithmic processes to simplify spatial convolution functions. However, these methods still heavily rely on matrix multiplication, leading to significant computational overhead. To bridge the gap between hardware, algorithmic acceleration, and approximate matrix multiplication, we propose TabConv, a novel, table-based approximation for convolution to significantly reduce arithmetic operations during inference. Additionally, we introduce a priority masking technique based on cosine similarity to select layers for table-based approximation, thereby maintaining the model performance. We evaluate our approach on popular CNNs: ResNet-18, ResNet-34, and NetworkInNetwork (NIN). TabConv preserves over 93% of the original model's performance while reducing arithmetic operations by 36.5%, 25.8%, and 99.4% for ResNet-18 on CIFAR-10, CIFAR-100, and MNIST, respectively, 35.6% and 99.3% for ResNet-34 on CIFAR-10 and MNIST, and 98.9% for NIN on MNIST, achieving low-computation inference.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Towards Improved Semiconductor Defect Inspection for high-NA EUVL based  on SEMI-SuperYOLO-NAS</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05862">https://arxiv.org/abs/2404.05862</a></p>
  <p><b>作者</b>：Ying-Lin Chen,  Jacob Deforce,  Vic De Ridder,  Bappaditya Dey,  Victor Blanco,  Sandip Halder,  Philippe Leray</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：High-NA EUVL technology, adopting High-NA EUVL, High Volume Manufacturing, EUVL technology, High-NA EUVL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to potential pitch reduction, the semiconductor industry is adopting High-NA EUVL technology. However, its low depth of focus presents challenges for High Volume Manufacturing. To address this, suppliers are exploring thinner photoresists and new underlayers/hardmasks. These may suffer from poor SNR, complicating defect detection. Vision-based ML algorithms offer a promising solution for semiconductor defect inspection. However, developing a robust ML model across various image resolutions without explicit training remains a challenge for nano-scale defect inspection. This research's goal is to propose a scale-invariant ADCD framework capable to upscale images, addressing this issue. We propose an improvised ADCD framework as SEMI-SuperYOLO-NAS, which builds upon the baseline YOLO-NAS architecture. This framework integrates a SR assisted branch to aid in learning HR features by the defect detection backbone, particularly for detecting nano-scale defect instances from LR images. Additionally, the SR-assisted branch can recursively generate upscaled images from their corresponding downscaled counterparts, enabling defect detection inference across various image resolutions without requiring explicit training. Moreover, we investigate improved data augmentation strategy aimed at generating diverse and realistic training datasets to enhance model performance. We have evaluated our proposed approach using two original FAB datasets obtained from two distinct processes and captured using two different imaging tools. Finally, we demonstrate zero-shot inference for our model on a new, originating from a process condition distinct from the training dataset and possessing different Pitch characteristics. Experimental validation demonstrates that our proposed ADCD framework aids in increasing the throughput of imaging tools for defect inspection by reducing the required image pixel resolutions.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Localizing Moments of Actions in Untrimmed Videos of Infants with Autism  Spectrum Disorder</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05849">https://arxiv.org/abs/2404.05849</a></p>
  <p><b>作者</b>：Halil Ismail Helvaci,  Sen-ching Samson Cheung,  Chen-Nee Chuah,  Sally Ozonoff</p>
  <p><b>备注</b>：7 pages, 2 figures, 3 tables</p>
  <p><b>关键词</b>：Autism Spectrum Disorder, Spectrum Disorder, Autism Spectrum, presents significant challenges, presents significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autism Spectrum Disorder (ASD) presents significant challenges in early diagnosis and intervention, impacting children and their families. With prevalence rates rising, there is a critical need for accessible and efficient screening tools. Leveraging machine learning (ML) techniques, in particular Temporal Action Localization (TAL), holds promise for automating ASD screening. This paper introduces a self-attention based TAL model designed to identify ASD-related behaviors in infant videos. Unlike existing methods, our approach simplifies complex modeling and emphasizes efficiency, which is essential for practical deployment in real-world scenarios. Importantly, this work underscores the importance of developing computer vision methods capable of operating in naturilistic environments with little equipment control, addressing key challenges in ASD screening. This study is the first to conduct end-to-end temporal action localization in untrimmed videos of infants with ASD, offering promising avenues for early intervention and support. We report baseline results of behavior detection using our TAL model. We achieve 70% accuracy for look face, 79% accuracy for look object, 72% for smile and 65% for vocalization.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Privacy-Preserving Deep Learning Using Deformable Operators for Secure  Task Learning</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05828">https://arxiv.org/abs/2404.05828</a></p>
  <p><b>作者</b>：Fabian Perez,  Jhon Lopez,  Henry Arguello</p>
  <p><b>备注</b>：copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p>
  <p><b>关键词</b>：protect sensitive information, ensuring truly reliable, era of cloud, cloud computing, computing and data-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of cloud computing and data-driven applications, it is crucial to protect sensitive information to maintain data privacy, ensuring truly reliable systems. As a result, preserving privacy in deep learning systems has become a critical concern. Existing methods for privacy preservation rely on image encryption or perceptual transformation approaches. However, they often suffer from reduced task performance and high computational costs. To address these challenges, we propose a novel Privacy-Preserving framework that uses a set of deformable operators for secure task learning. Our method involves shuffling pixels during the analog-to-digital conversion process to generate visually protected data. Those are then fed into a well-known network enhanced with deformable operators. Using our approach, users can achieve equivalent performance to original images without additional training using a secret key. Moreover, our method enables access control against unauthorized users. Experimental results demonstrate the efficacy of our approach, showcasing its potential in cloud-based scenarios and privacy-sensitive applications.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Towards Explainable Automated Neuroanatomy</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05814">https://arxiv.org/abs/2404.05814</a></p>
  <p><b>作者</b>：Kui Qian,  Litao Qiao,  Beth Friedman,  Edward O'Donnell,  David Kleinfeld,  Yoav Freund</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantifying the microscopic, interpretable features obtained, Convolutional Neural Networks, brain tissue, features obtained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel method for quantifying the microscopic structure of brain tissue. It is based on the automated recognition of interpretable features obtained by analyzing the shapes of cells. This contrasts with prevailing methods of brain anatomical analysis in two ways. First, contemporary methods use gray-scale values derived from smoothed version of the anatomical images, which dissipated valuable information from the texture of the images. Second, contemporary analysis uses the output of black-box Convolutional Neural Networks, while our system makes decisions based on interpretable features obtained by analyzing the shapes of individual cells. An important benefit of this open-box approach is that the anatomist can understand and correct the decisions made by the computer. Our proposed system can accurately localize and identify existing brain structures. This can be used to align and coregistar brains and will facilitate connectomic studies for reverse engineering of brain circuitry.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：BatSort: Enhanced Battery Classification with Transfer Learning for  Battery Sorting and Recycling</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05802">https://arxiv.org/abs/2404.05802</a></p>
  <p><b>作者</b>：Yunyi Zhao,  Wei Zhang,  Erhai Hu,  Qingyu Yan,  Cheng Xiang,  King Jet Tseng,  Dusit Niyato</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimizing environmental harm, critical process, process for minimizing, minimizing environmental, environmental harm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Battery recycling is a critical process for minimizing environmental harm and resource waste for used batteries. However, it is challenging, largely because sorting batteries is costly and hardly automated to group batteries based on battery types. In this paper, we introduce a machine learning-based approach for battery-type classification and address the daunting problem of data scarcity for the application. We propose BatSort which applies transfer learning to utilize the existing knowledge optimized with large-scale datasets and customizes ResNet to be specialized for classifying battery types. We collected our in-house battery-type dataset of small-scale to guide the knowledge transfer as a case study and evaluate the system performance. We conducted an experimental study and the results show that BatSort can achieve outstanding accuracy of 92.1% on average and up to 96.2% and the performance is stable for battery-type classification. Our solution helps realize fast and automated battery sorting with minimized cost and can be transferred to related industry applications with insufficient data.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Responsible Generative AI: What to Generate and What Not</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05783">https://arxiv.org/abs/2404.05783</a></p>
  <p><b>作者</b>：Jindong Gu</p>
  <p><b>备注</b>：74 pages, 10 figures</p>
  <p><b>关键词</b>：received significant attention, large language models, large language, received significant, significant attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, generative AI (GenAI), like large language models and text-to-image models, has received significant attention across various domains. However, ensuring the responsible generation of content by these models is crucial for their real-world applicability. This raises an interesting question: \textit{What should responsible GenAI generate, and what should it not?} To answer the question, this paper investigates the practical responsible requirements of both textual and visual generative models, outlining five key considerations: generating truthful content, avoiding toxic content, refusing harmful instruction, leaking no training data-related content, and ensuring generated content identifiable. Specifically, we review recent advancements and challenges in addressing these requirements. Besides, we discuss and emphasize the importance of responsible GenAI across healthcare, education, finance, and artificial general intelligence domains. Through a unified perspective on both textual and visual generative models, this paper aims to provide insights into practical safety-related issues and further benefit the community in building responsible GenAI.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Forecasting Electric Vehicle Battery Output Voltage: A Predictive  Modeling Approach</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05776">https://arxiv.org/abs/2404.05776</a></p>
  <p><b>作者</b>：Narayana Darapaneni,  Ashish K,  Ullas M S,  Anwesh Reddy Paduri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hybrid vehicles, management system plays, plays a vital, vital role, role in ensuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The battery management system plays a vital role in ensuring the safety and dependability of electric and hybrid vehicles. It is responsible for various functions, including state evaluation, monitoring, charge control, and cell balancing, all integrated within the BMS. Nonetheless, due to the uncertainties surrounding battery performance, implementing these functionalities poses significant challenges. In this study, we explore the latest approaches for assessing battery states, highlight notable advancements in battery management systems (BMS), address existing issues with current BMS technology, and put forth possible solutions for predicting battery charging voltage.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：A comparative analysis of deep learning models for lung segmentation on  X-ray images</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06455">https://arxiv.org/abs/2404.06455</a></p>
  <p><b>作者</b>：Weronika Hryniewska-Guzik,  Jakub Bilski,  Bartosz Chrostowski,  Jakub Drak Sbahi,  Przemysław Biecek</p>
  <p><b>备注</b>：published at the Polish Conference on Artificial Intelligence (PP-RAI), 2024</p>
  <p><b>关键词</b>：highly accurate lung, accurate lung segmentation, segmentation in X-rays, X-rays is crucial, Robust and highly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust and highly accurate lung segmentation in X-rays is crucial in medical imaging. This study evaluates deep learning solutions for this task, ranking existing methods and analyzing their performance under diverse image modifications. Out of 61 analyzed papers, only nine offered implementation or pre-trained models, enabling assessment of three prominent methods: Lung VAE, TransResUNet, and CE-Net. The analysis revealed that CE-Net performs best, demonstrating the highest values in dice similarity coefficient and intersection over union metric.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Raster Forge: Interactive Raster Manipulation Library and GUI for Python</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06389">https://arxiv.org/abs/2404.06389</a></p>
  <p><b>作者</b>：Afonso Oliveira,  Nuno Fachada,  João P. Matos-Carvalho</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Python library, graphical user interface, library and graphical, raster data manipulation, Raster Forge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Raster Forge is a Python library and graphical user interface for raster data manipulation and analysis. The tool is focused on remote sensing applications, particularly in wildfire management. It allows users to import, visualize, and process raster layers for tasks such as image compositing or topographical analysis. For wildfire management, it generates fuel maps using predefined models. Its impact extends from disaster management to hydrological modeling, agriculture, and environmental monitoring. Raster Forge can be a valuable asset for geoscientists and researchers who rely on raster data analysis, enhancing geospatial data processing and visualization across various disciplines.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Fortifying Fully Convolutional Generative Adversarial Networks for Image  Super-Resolution Using Divergence Measures</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06294">https://arxiv.org/abs/2404.06294</a></p>
  <p><b>作者</b>：Arkaprabha Basu,  Kushal Bose,  Sankha Subhra Mullick,  Anish Chakrabarty,  Swagatam Das</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-hallowed image processing, image processing problem, Generative Adversarial Network, fully-convolutional Generative Adversarial, time-hallowed image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Super-Resolution (SR) is a time-hallowed image processing problem that aims to improve the quality of a Low-Resolution (LR) sample up to the standard of its High-Resolution (HR) counterpart. We aim to address this by introducing Super-Resolution Generator (SuRGe), a fully-convolutional Generative Adversarial Network (GAN)-based architecture for SR. We show that distinct convolutional features obtained at increasing depths of a GAN generator can be optimally combined by a set of learnable convex weights to improve the quality of generated SR samples. In the process, we employ the Jensen-Shannon and the Gromov-Wasserstein losses respectively between the SR-HR and LR-SR pairs of distributions to further aid the generator of SuRGe to better exploit the available information in an attempt to improve SR. Moreover, we train the discriminator of SuRGe with the Wasserstein loss with gradient penalty, to primarily prevent mode collapse. The proposed SuRGe, as an end-to-end GAN workflow tailor-made for super-resolution, offers improved performance while maintaining low inference time. The efficacy of SuRGe is substantiated by its superior performance compared to 18 state-of-the-art contenders on 10 benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Using Few-Shot Learning to Classify Primary Lung Cancer and Other  Malignancy with Lung Metastasis in Cytological Imaging via Endobronchial  Ultrasound Procedures</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06080">https://arxiv.org/abs/2404.06080</a></p>
  <p><b>作者</b>：Ching-Kai Lin,  Di-Chun Wei,  Yun-Chien Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer-aided diagnosis system, metastatic cancer, computer-aided diagnosis, diagnosis system, preliminary diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study aims to establish a computer-aided diagnosis system for endobronchial ultrasound (EBUS) surgery to assist physicians in the preliminary diagnosis of metastatic cancer. This involves arranging immediate examinations for other sites of metastatic cancer after EBUS surgery, eliminating the need to wait for reports, thereby shortening the waiting time by more than half and enabling patients to detect other cancers earlier, allowing for early planning and implementation of treatment plans. Unlike previous studies on cell image classification, which have abundant datasets for training, this study must also be able to make effective classifications despite the limited amount of case data for lung metastatic cancer. In the realm of small data set classification methods, Few-shot learning (FSL) has become mainstream in recent years. Through its ability to train on small datasets and its strong generalization capabilities, FSL shows potential in this task of lung metastatic cell image classification. This study will adopt the approach of Few-shot learning, referencing existing proposed models, and designing a model architecture for classifying lung metastases cell images. Batch Spectral Regularization (BSR) will be incorporated as a loss update parameter, and the Finetune method of PMF will be modified. In terms of test results, the addition of BSR and the modified Finetune method further increases the accuracy by 8.89% to 65.60%, outperforming other FSL methods. This study confirms that FSL is superior to supervised and transfer learning in classifying metastatic cancer and demonstrates that using BSR as a loss function and modifying Finetune can enhance the model's capabilities.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：LATUP-Net: A Lightweight 3D Attention U-Net with Parallel Convolutions  for Brain Tumor Segmentation</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05911">https://arxiv.org/abs/2404.05911</a></p>
  <p><b>作者</b>：Ebtihal J. Alwadee,  Xianfang Sun,  Yipeng Qin,  Frank C. Langbein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：magnetic resonance imaging, scans is crucial, effective treatment, magnetic resonance, crucial for prompt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early-stage 3D brain tumor segmentation from magnetic resonance imaging (MRI) scans is crucial for prompt and effective treatment. However, this process faces the challenge of precise delineation due to the tumors' complex heterogeneity. Moreover, energy sustainability targets and resource limitations, especially in developing countries, require efficient and accessible medical imaging solutions. The proposed architecture, a Lightweight 3D ATtention U-Net with Parallel convolutions, LATUP-Net, addresses these issues. It is specifically designed to reduce computational requirements significantly while maintaining high segmentation performance. By incorporating parallel convolutions, it enhances feature representation by capturing multi-scale information. It further integrates an attention mechanism to refine segmentation through selective feature recalibration. LATUP-Net achieves promising segmentation performance: the average Dice scores for the whole tumor, tumor core, and enhancing tumor on the BraTS2020 dataset are 88.41%, 83.82%, and 73.67%, and on the BraTS2021 dataset, they are 90.29%, 89.54%, and 83.92%, respectively. Hausdorff distance metrics further indicate its improved ability to delineate tumor boundaries. With its significantly reduced computational demand using only 3.07 M parameters, about 59 times fewer than other state-of-the-art models, and running on a single V100 GPU, LATUP-Net stands out as a promising solution for real-world clinical applications, particularly in settings with limited resources. Investigations into the model's interpretability, utilizing gradient-weighted class activation mapping and confusion matrices, reveal that while attention mechanisms enhance the segmentation of small regions, their impact is nuanced. Achieving the most accurate tumor delineation requires carefully balancing local and global features.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Study of the effect of Sharpness on Blind Video Quality Assessment</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05764">https://arxiv.org/abs/2404.05764</a></p>
  <p><b>作者</b>：Anantha Prabhu,  David Pratap,  Narayana Darapeni,  Anwesh P R</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Video Quality Assessment, Convolutional Neural Networks, Deep Neural Networks, Video Quality, Neural Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Introduction: Video Quality Assessment (VQA) is one of the important areas of study in this modern era, where video is a crucial component of communication with applications in every field. Rapid technology developments in mobile technology enabled anyone to create videos resulting in a varied range of video quality scenarios. Objectives: Though VQA was present for some time with the classical metrices like SSIM and PSNR, the advent of machine learning has brought in new techniques of VQAs which are built upon Convolutional Neural Networks (CNNs) or Deep Neural Networks (DNNs). Methods: Over the past years various research studies such as the BVQA which performed video quality assessment of nature-based videos using DNNs exposed the powerful capabilities of machine learning algorithms. BVQA using DNNs explored human visual system effects such as content dependency and time-related factors normally known as temporal effects. Results: This study explores the sharpness effect on models like BVQA. Sharpness is the measure of the clarity and details of the video image. Sharpness typically involves analyzing the edges and contrast of the image to determine the overall level of detail and sharpness. Conclusion: This study uses the existing video quality databases such as CVD2014. A comparative study of the various machine learning parameters such as SRCC and PLCC during the training and testing are presented along with the conclusion.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Deep Learning-Based Brain Image Segmentation for Automated Tumour  Detection</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05763">https://arxiv.org/abs/2404.05763</a></p>
  <p><b>作者</b>：Suman Sourabh,  Murugappan Valliappan,  Narayana Darapaneni,  Anwesh R P</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automated brain tumor, brain tumor segmentation, segmentation technique based, tumor segmentation technique, development and evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Introduction: The present study on the development and evaluation of an automated brain tumor segmentation technique based on deep learning using the 3D U-Net model. Objectives: The objective is to leverage state-of-the-art convolutional neural networks (CNNs) on a large dataset of brain MRI scans for segmentation. Methods: The proposed methodology applies pre-processing techniques for enhanced performance and generalizability. Results: Extensive validation on an independent dataset confirms the model's robustness and potential for integration into clinical workflows. The study emphasizes the importance of data pre-processing and explores various hyperparameters to optimize the model's performance. The 3D U-Net, has given IoUs for training and validation dataset have been 0.8181 and 0.66 respectively. Conclusion: Ultimately, this comprehensive framework showcases the efficacy of deep learning in automating brain tumour detection, offering valuable support in clinical practice.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Implicit Assimilation of Sparse In Situ Data for Dense & Global Storm  Surge Forecasting</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05758">https://arxiv.org/abs/2404.05758</a></p>
  <p><b>作者</b>：Patrick Ebel,  Brandon Victor,  Peter Naylor,  Gabriele Meoni,  Federico Serva,  Rochelle Schneider</p>
  <p><b>备注</b>：Accepted at CVPR EarthVision 2024</p>
  <p><b>关键词</b>：disastrous natural hazards, Hurricanes and coastal, natural hazards, coastal floods, disastrous natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hurricanes and coastal floods are among the most disastrous natural hazards. Both are intimately related to storm surges, as their causes and effects, respectively. However, the short-term forecasting of storm surges has proven challenging, especially when targeting previously unseen locations or sites without tidal gauges. Furthermore, recent work improved short and medium-term weather forecasting but the handling of raw unassimilated data remains non-trivial. In this paper, we tackle both challenges and demonstrate that neural networks can implicitly assimilate sparse in situ tide gauge data with coarse ocean state reanalysis in order to forecast storm surges. We curate a global dataset to learn and validate the dense prediction of storm surges, building on preceding efforts. Other than prior work limited to known gauges, our approach extends to ungauged sites, paving the way for global storm surge forecasting.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：MoReVQA: Exploring Modular Reasoning Models for Video Question Answering</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06511">https://arxiv.org/abs/2404.06511</a></p>
  <p><b>作者</b>：Juhong Min,  Shyamal Buch,  Arsha Nagrani,  Minsu Cho,  Cordelia Schmid</p>
  <p><b>备注</b>：CVPR 2024</p>
  <p><b>关键词</b>：video question answering, modular reasoning framework, question answering, paper addresses, video question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the task of video question answering (videoQA) via a decomposed multi-stage, modular reasoning framework. Previous modular methods have shown promise with a single planning stage ungrounded in visual content. However, through a simple and effective baseline, we find that such systems can lead to brittle behavior in practice for challenging videoQA settings. Thus, unlike traditional single-stage planning methods, we propose a multi-stage system consisting of an event parser, a grounding stage, and a final reasoning stage in conjunction with an external memory. All stages are training-free, and performed using few-shot prompting of large models, creating interpretable intermediate outputs at each stage. By decomposing the underlying planning and task complexity, our method, MoReVQA, improves over prior work on standard videoQA benchmarks (NExT-QA, iVQA, EgoSchema, ActivityNet-QA) with state-of-the-art results, and extensions to related tasks (grounded videoQA, paragraph captioning).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：On the Effect of (Near) Duplicate Subwords in Language Modelling</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06508">https://arxiv.org/abs/2404.06508</a></p>
  <p><b>作者</b>：Anton Schäfer,  Thomas Hofmann,  Imanol Schlag,  Tiago Pimentel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：core part, part of language, subwords, duplicates, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tokenisation is a core part of language models (LMs). It involves splitting a character sequence into subwords which are assigned arbitrary indices before being served to the LM. While typically lossless, however, this process may lead to less sample efficient LM training: as it removes character-level information, it could make it harder for LMs to generalise across similar subwords, such as now and Now. We refer to such subwords as near duplicates. In this paper, we study the impact of near duplicate subwords on LM training efficiency. First, we design an experiment that gives us an upper bound to how much we should expect a model to improve if we could perfectly generalise across near duplicates. We do this by duplicating each subword in our LM's vocabulary, creating perfectly equivalent classes of subwords. Experimentally, we find that LMs need roughly 17% more data when trained in a fully duplicated setting. Second, we investigate the impact of naturally occurring near duplicates on LMs. Here, we see that merging them considerably hurts LM performance. Therefore, although subword duplication negatively impacts LM training efficiency, naturally occurring near duplicates may not be as similar as anticipated, limiting the potential for performance improvements.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Simultaneous linear connectivity of neural networks modulo permutation</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06498">https://arxiv.org/abs/2404.06498</a></p>
  <p><b>作者</b>：Ekansh Sharma,  Devin Kwok,  Tom Denton,  Daniel M. Roy,  David Rolnick,  Gintare Karolina Dziugaite</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：Neural networks typically, encounter a high, networks, permutation, permutation symmetries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks typically exhibit permutation symmetries which contribute to the non-convexity of the networks' loss landscapes, since linearly interpolating between two permuted versions of a trained network tends to encounter a high loss barrier. Recent work has argued that permutation symmetries are the only sources of non-convexity, meaning there are essentially no such barriers between trained networks if they are permuted appropriately. In this work, we refine these arguments into three distinct claims of increasing strength. We show that existing evidence only supports "weak linear connectivity"-that for each pair of networks belonging to a set of SGD solutions, there exist (multiple) permutations that linearly connect it with the other networks. In contrast, the claim "strong linear connectivity"-that for each network, there exists one permutation that simultaneously connects it with the other networks-is both intuitively and practically more desirable. This stronger claim would imply that the loss landscape is convex after accounting for permutation, and enable linear interpolation between three or more independently trained models without increased loss. In this work, we introduce an intermediate claim-that for certain sequences of networks, there exists one permutation that simultaneously aligns matching pairs of networks from these sequences. Specifically, we discover that a single permutation aligns sequences of iteratively trained as well as iteratively pruned networks, meaning that two networks exhibit low loss barriers at each step of their optimization and sparsification trajectories respectively. Finally, we provide the first evidence that strong linear connectivity may be possible under certain conditions, by showing that barriers decrease with increasing network width when interpolating among three networks.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Graph Reinforcement Learning for Combinatorial Optimization: A Survey  and Unifying Perspective</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06492">https://arxiv.org/abs/2404.06492</a></p>
  <p><b>作者</b>：Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Reinforcement Learning, Graph Reinforcement Learning, connected entities, natural representation, representation for systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphs are a natural representation for systems based on relations between connected entities. Combinatorial optimization problems, which arise when considering an objective function related to a process of interest on discrete structures, are often challenging due to the rapid growth of the solution space. The trial-and-error paradigm of Reinforcement Learning has recently emerged as a promising alternative to traditional methods, such as exact algorithms and (meta)heuristics, for discovering better decision-making strategies in a variety of disciplines including chemistry, computer science, and statistics. Despite the fact that they arose in markedly different fields, these techniques share significant commonalities. Therefore, we set out to synthesize this work in a unifying perspective that we term Graph Reinforcement Learning, interpreting it as a constructive decision-making method for graph problems. After covering the relevant technical background, we review works along the dividing line of whether the goal is to optimize graph structure given a process of interest, or to optimize the outcome of the process itself under fixed graph structure. Finally, we discuss the common challenges facing the field and open research questions. In contrast with other surveys, the present work focuses on non-canonical graph problems for which performant algorithms are typically not known and Reinforcement Learning is able to provide efficient and effective solutions.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：GO4Align: Group Optimization for Multi-Task Alignment</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06486">https://arxiv.org/abs/2404.06486</a></p>
  <p><b>作者</b>：Jiayi Shen,  Cheems Wang,  Zehao Xiao,  Nanne Van Noord,  Marcel Worring</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-task optimization approach, tackles task imbalance, paper proposes, approach that tackles, imbalance by explicitly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes \textit{GO4Align}, a multi-task optimization approach that tackles task imbalance by explicitly aligning the optimization across tasks. To achieve this, we design an adaptive group risk minimization strategy, compromising two crucial techniques in implementation: (i) dynamical group assignment, which clusters similar tasks based on task interactions; (ii) risk-guided group indicators, which exploit consistent task correlations with risk information from previous iterations. Comprehensive experimental results on diverse typical benchmarks demonstrate our method's performance superiority with even lower computational costs.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Public-private funding models in open source software development: A  case study on scikit-learn</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06484">https://arxiv.org/abs/2404.06484</a></p>
  <p><b>作者</b>：Cailean Osborne</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：domestic software markets, address concerns related, OSS, software security, software markets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Governments are increasingly allocating funding for open source software (OSS) development in order to address concerns related to software security, digital sovereignty, and the competitiveness of domestic software markets, amongst others. While such funding is generally welcomed by OSS practitioners, how OSS developers perceive the relative benefits and drawbacks of governmental funding remains an open question. This paper explores this question through a case study on scikit-learn, a Python library for machine learning, whose funding model combines research grants, commercial sponsorship, community donations, and a 32 million EUR grant from the French government's artificial intelligence strategy. Through 25 interviews with scikit-learn maintainers and funders, this study makes two key contributions with implications for research and practice. First, it provides novel insights into the role of a public-private funding model in a successful, community-led OSS project and how maintainers evaluate their funding model. Furthermore, it highlights the governance mechanisms employed by maintainers to safeguard the community ethos of the project. Second, it offers practical implications for OSS developer communities, companies, and governments. For OSS communities, the study illustrates the benefits of a diversified funding model in balancing the merits and drawbacks of different funding sources. For companies, it serves as a reminder that sponsoring developers or directly funding OSS projects can significantly support OSS maintainers, who often struggle with limited resources and towering workloads. For governments, the findings emphasise the importance of funding the maintenance of existing OSS projects in addition to or exclusively funding new innovations. The paper concludes with suggestions for future research on OSS funding models.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Learning State-Invariant Representations of Objects from Image  Collections with State, Pose, and Viewpoint Changes</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06470">https://arxiv.org/abs/2404.06470</a></p>
  <p><b>作者</b>：Rohan Sarkar,  Avinash Kak</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：state, state invariance, learning object representations, invariance, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We add one more invariance - state invariance - to the more commonly used other invariances for learning object representations for recognition and retrieval. By state invariance, we mean robust with respect to changes in the structural form of the object, such as when an umbrella is folded, or when an item of clothing is tossed on the floor. Since humans generally have no difficulty in recognizing objects despite such state changes, we are naturally faced with the question of whether it is possible to devise a neural architecture with similar abilities. To that end, we present a novel dataset, ObjectsWithStateChange, that captures state and pose variations in the object images recorded from arbitrary viewpoints. We believe that this dataset will facilitate research in fine-grained object recognition and retrieval of objects that are capable of state changes. The goal of such research would be to train models capable of generating object embeddings that remain invariant to state changes while also staying invariant to transformations induced by changes in viewpoint, pose, illumination, etc. To demonstrate the usefulness of the ObjectsWithStateChange dataset, we also propose a curriculum learning strategy that uses the similarity relationships in the learned embedding space after each epoch to guide the training process. The model learns discriminative features by comparing visually similar objects within and across different categories, encouraging it to differentiate between objects that may be challenging to distinguish due to changes in their state. We believe that this strategy enhances the model's ability to capture discriminative features for fine-grained tasks that may involve objects with state changes, leading to performance improvements on object-level tasks not only on our new dataset, but also on two other challenging multi-view datasets such as ModelNet40 and ObjectPI.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Hyperparameter Selection in Continual Learning</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06466">https://arxiv.org/abs/2404.06466</a></p>
  <p><b>作者</b>：Thomas L. Lee,  Sigrid Passano Hellan,  Linus Ericsson,  Elliot J. Crowley,  Amos Storkey</p>
  <p><b>备注</b>：Preprint, 9 pages</p>
  <p><b>关键词</b>：standard hyperparameter optimisation, HPO, HPO frameworks, continual learning, CL-specific HPO frameworks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In continual learning (CL) -- where a learner trains on a stream of data -- standard hyperparameter optimisation (HPO) cannot be applied, as a learner does not have access to all of the data at the same time. This has prompted the development of CL-specific HPO frameworks. The most popular way to tune hyperparameters in CL is to repeatedly train over the whole data stream with different hyperparameter settings. However, this end-of-training HPO is unrealistic as in practice a learner can only see the stream once. Hence, there is an open question: what HPO framework should a practitioner use for a CL problem in reality? This paper answers this question by evaluating several realistic HPO frameworks. We find that all the HPO frameworks considered, including end-of-training HPO, perform similarly. We therefore advocate using the realistic and most computationally efficient method: fitting the hyperparameters on the first task and then fixing them throughout training.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Learning Locally Interacting Discrete Dynamical Systems: Towards  Data-Efficient and Scalable Prediction</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06460">https://arxiv.org/abs/2404.06460</a></p>
  <p><b>作者</b>：Beomseok Kang,  Harshit Kumar,  Minah Lee,  Biswadeep Chakraborty,  Saibal Mukhopadhyay</p>
  <p><b>备注</b>：Accepted in Learning for Dynamics and Control Conference (L4DC) 2024</p>
  <p><b>关键词</b>：Locally interacting dynamical, complex global dynamics, global dynamics originated, interacting dynamical systems, exhibit complex global</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Locally interacting dynamical systems, such as epidemic spread, rumor propagation through crowd, and forest fire, exhibit complex global dynamics originated from local, relatively simple, and often stochastic interactions between dynamic elements. Their temporal evolution is often driven by transitions between a finite number of discrete states. Despite significant advancements in predictive modeling through deep learning, such interactions among many elements have rarely explored as a specific domain for predictive modeling. We present Attentive Recurrent Neural Cellular Automata (AR-NCA), to effectively discover unknown local state transition rules by associating the temporal information between neighboring cells in a permutation-invariant manner. AR-NCA exhibits the superior generalizability across various system configurations (i.e., spatial distribution of states), data efficiency and robustness in extremely data-limited scenarios even in the presence of stochastic interactions, and scalability through spatial dimension-independent prediction.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：PURE: Turning Polysemantic Neurons Into Pure Features by Identifying  Relevant Circuits</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06453">https://arxiv.org/abs/2404.06453</a></p>
  <p><b>作者</b>：Maximilian Dreyer,  Erblina Purelku,  Johanna Vielhaben,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：14 pages (4 pages manuscript, 2 pages references, 8 pages appendix)</p>
  <p><b>关键词</b>：Deep Neural Networks, mechanistic interpretability aims, Deep Neural, Neural Networks, field of mechanistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of mechanistic interpretability aims to study the role of individual neurons in Deep Neural Networks. Single neurons, however, have the capability to act polysemantically and encode for multiple (unrelated) features, which renders their interpretation difficult. We present a method for disentangling polysemanticity of any Deep Neural Network by decomposing a polysemantic neuron into multiple monosemantic "virtual" neurons. This is achieved by identifying the relevant sub-graph ("circuit") for each "pure" feature. We demonstrate how our approach allows us to find and disentangle various polysemantic units of ResNet models trained on ImageNet. While evaluating feature visualizations using CLIP, our method effectively disentangles representations, improving upon methods based on neuron activations. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of  Large Language Models</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06448">https://arxiv.org/abs/2404.06448</a></p>
  <p><b>作者</b>：Zihan Fang,  Zheng Lin,  Zhe Chen,  Xianhao Chen,  Yue Gao,  Yuguang Fang</p>
  <p><b>备注</b>：15 pages, 16 figures</p>
  <p><b>关键词</b>：intelligent generative content, advanced intelligent generative, large language models, generative content, development of advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there has been a surge in the development of advanced intelligent generative content (AIGC), especially large language models (LLMs). However, for many downstream tasks, it is necessary to fine-tune LLMs using private data. While federated learning offers a promising privacy-preserving solution to LLM fine-tuning, the substantial size of an LLM, combined with high computational and communication demands, makes it hard to apply to downstream tasks. More importantly, private edge servers often possess varying computing and network resources in real-world scenarios, introducing additional complexities to LLM fine-tuning. To tackle these problems, we design and implement an automated federated pipeline, named FedPipe, to fine-tune LLMs with minimal training cost but without adding any inference latency. FedPipe firstly identifies the weights to be fine-tuned based on their contributions to the LLM training. It then configures a low-rank adapter for each selected weight to train local low-rank adapters on an edge server, and aggregate local adapters of all edge servers to fine-tune the whole LLM. Finally, it appropriately quantizes the parameters of LLM to reduce memory space according to the requirements of edge servers. Extensive experiments demonstrate that FedPipe expedites the model training and achieves higher accuracy than state-of-the-art benchmarks.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Seasonal Fire Prediction using Spatio-Temporal Deep Neural Networks</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06437">https://arxiv.org/abs/2404.06437</a></p>
  <p><b>作者</b>：Dimitrios Michail,  Lefki-Ioanna Panagiotou,  Charalampos Davalas,  Ioannis Prapas,  Spyros Kondylatos,  Nikolaos Ioannis Bountos,  Ioannis Papoutsis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：climate change expected, fire weather conditions, exacerbate fire weather, weather conditions, disaster mitigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With climate change expected to exacerbate fire weather conditions, the accurate anticipation of wildfires on a global scale becomes increasingly crucial for disaster mitigation. In this study, we utilize SeasFire, a comprehensive global wildfire dataset with climate, vegetation, oceanic indices, and human-related variables, to enable seasonal wildfire forecasting with machine learning. For the predictive analysis, we train deep learning models with different architectures that capture the spatio-temporal context leading to wildfires. Our investigation focuses on assessing the effectiveness of these models in predicting the presence of burned areas at varying forecasting time horizons globally, extending up to six months into the future, and on how different spatial or/and temporal context affects the performance of the models. Our findings demonstrate the great potential of deep learning models in seasonal fire forecasting; longer input time-series leads to more robust predictions across varying forecasting horizons, while integrating spatial information to capture wildfire spatio-temporal dynamics boosts performance. Finally, our results hint that in order to enhance performance at longer forecasting horizons, a larger receptive field spatially needs to be considered.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：pfl-research: simulation framework for accelerating research in Private  Federated Learning</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06430">https://arxiv.org/abs/2404.06430</a></p>
  <p><b>作者</b>：Filip Granqvist,  Congzheng Song,  Áine Cahill,  Rogier van Dalen,  Martin Pelikan,  Yi Sheng Chan,  Xiaojun Feng,  Natarajan Krishnaswami,  Vojta Jina,  Mona Chitnis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging machine learning, Federated learning, machine learning, training paradigm, emerging machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging machine learning (ML) training paradigm where clients own their data and collaborate to train a global model, without revealing any data to the server and other participants. Researchers commonly perform experiments in a simulation environment to quickly iterate on ideas. However, existing open-source tools do not offer the efficiency required to simulate FL on larger and more realistic FL datasets. We introduce pfl-research, a fast, modular, and easy-to-use Python framework for simulating FL. It supports TensorFlow, PyTorch, and non-neural network models, and is tightly integrated with state-of-the-art privacy algorithms. We study the speed of open-source FL frameworks and show that pfl-research is 7-72$\times$ faster than alternative open-source frameworks on common cross-device setups. Such speedup will significantly boost the productivity of the FL research community and enable testing hypotheses on realistic FL datasets that were previously too resource intensive. We release a suite of benchmarks that evaluates an algorithm's overall performance on a diverse set of realistic scenarios. The code is available on GitHub at this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Deep Reinforcement Learning-Based Approach for a Single Vehicle  Persistent Surveillance Problem with Fuel Constraints</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06423">https://arxiv.org/abs/2404.06423</a></p>
  <p><b>作者</b>：Hritik Bana,  Manav Mishra,  Saswata Sarkar,  Sujeevraja Sanjeevi,  Sujit PB,  Kaarthik Sundar</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：persistent surveillance mission, surveillance mission requiring, single unmanned aerial, aerial vehicle initially, vehicle initially stationed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article presents a deep reinforcement learning-based approach to tackle a persistent surveillance mission requiring a single unmanned aerial vehicle initially stationed at a depot with fuel or time-of-flight constraints to repeatedly visit a set of targets with equal priority. Owing to the vehicle's fuel or time-of-flight constraints, the vehicle must be regularly refueled, or its battery must be recharged at the depot. The objective of the problem is to determine an optimal sequence of visits to the targets that minimizes the maximum time elapsed between successive visits to any target while ensuring that the vehicle never runs out of fuel or charge. We present a deep reinforcement learning algorithm to solve this problem and present the results of numerical experiments that corroborate the effectiveness of this approach in comparison with common-sense greedy heuristics.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Bayesian Survival Analysis by Approximate Inference of Neural Networks</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06421">https://arxiv.org/abs/2404.06421</a></p>
  <p><b>作者</b>：Christian Marius Lillelund,  Martin Magris,  Christian Fischer Pedersen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Predicting future events, future events, explain the confidence, Bayesian methods applied, Bayesian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting future events always comes with uncertainty, but traditional non-Bayesian methods cannot distinguish certain from uncertain predictions or explain the confidence in their predictions. In survival analysis, Bayesian methods applied to state-of-the-art solutions in the healthcare and biomedical field are still novel, and their implications have not been fully evaluated. In this paper, we study the benefits of modeling uncertainty in deep neural networks for survival analysis with a focus on prediction and calibration performance. For this, we present a Bayesian deep learning framework that consists of three Bayesian network architectures, which we train by optimizing the Cox partial likelihood and combining input-dependent aleatoric uncertainty with model-specific epistemic uncertainty. This enables us to provide uncertainty estimates as credible intervals when predicting the survival curve or as a probability density function over the predicted median survival times. For our empirical analyses, we evaluated our proposed method on four benchmark datasets and found that our method demonstrates prediction performance comparable to the state-of-the-art based on the concordance index and outperforms all other Cox-based approaches in terms of the mean absolute error. Our work explicitly compares the extent to which different Bayesian approximation techniques differ from each other and improves the prediction over traditional non-Bayesian alternatives.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Studying the Impact of Latent Representations in Implicit Neural  Networks for Scientific Continuous Field Reconstruction</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06418">https://arxiv.org/abs/2404.06418</a></p>
  <p><b>作者</b>：Wei Xu,  Derek Freeman DeSantis,  Xihaier Luo,  Avish Parmar,  Klaus Tan,  Balu Nadiga,  Yihui Ren,  Shinjae Yoo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse scientific disciplines, affects diverse scientific, Modulated Gabor Network, Learning a continuous, scientific disciplines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning a continuous and reliable representation of physical fields from sparse sampling is challenging and it affects diverse scientific disciplines. In a recent work, we present a novel model called MMGN (Multiplicative and Modulated Gabor Network) with implicit neural networks. In this work, we design additional studies leveraging explainability methods to complement the previous experiments and further enhance the understanding of latent representations generated by the model. The adopted methods are general enough to be leveraged for any latent space inspection. Preliminary results demonstrate the contextual information incorporated in the latent representations and their impact on the model performance. As a work in progress, we will continue to verify our findings and develop novel explainability approaches.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Take a Look at it! Rethinking How to Evaluate Language Model Jailbreak</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06407">https://arxiv.org/abs/2404.06407</a></p>
  <p><b>作者</b>：Hongyu Cai,  Arjun Arunasalam,  Leo Y. Lin,  Antonio Bianchi,  Z. Berkay Celik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly integrated, jailbreak, evaluation, Large language models, evaluation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have become increasingly integrated with various applications. To ensure that LLMs do not generate unsafe responses, they are aligned with safeguards that specify what content is restricted. However, such alignment can be bypassed to produce prohibited content using a technique commonly referred to as jailbreak. Different systems have been proposed to perform the jailbreak automatically. These systems rely on evaluation methods to determine whether a jailbreak attempt is successful. However, our analysis reveals that current jailbreak evaluation methods have two limitations. (1) Their objectives lack clarity and do not align with the goal of identifying unsafe responses. (2) They oversimplify the jailbreak result as a binary outcome, successful or not.
In this paper, we propose three metrics, safeguard violation, informativeness, and relative truthfulness, to evaluate language model jailbreak. Additionally, we demonstrate how these metrics correlate with the goal of different malicious actors. To compute these metrics, we introduce a multifaceted approach that extends the natural language generation evaluation method after preprocessing the response. We evaluate our metrics on a benchmark dataset produced from three malicious intent datasets and three jailbreak systems. The benchmark dataset is labeled by three annotators. We compare our multifaceted approach with three existing jailbreak evaluation methods. Experiments demonstrate that our multifaceted evaluation outperforms existing methods, with F1 scores improving on average by 17% compared to existing baselines. Our findings motivate the need to move away from the binary view of the jailbreak problem and incorporate a more comprehensive evaluation to ensure the safety of the language model.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Wu's Method can Boost Symbolic AI to Rival Silver Medalists and  AlphaGeometry to Outperform Gold Medalists at IMO Geometry</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06405">https://arxiv.org/abs/2404.06405</a></p>
  <p><b>作者</b>：Shiven Sinha,  Ameya Prabhu,  Ponnurangam Kumaraguru,  Siddharth Bhat,  Matthias Bethge</p>
  <p><b>备注</b>：Work in Progress. Released for wider feedback</p>
  <p><b>关键词</b>：geometric theorems constitutes, Proving geometric theorems, automated theorem proving, International Mathematical Olympiad, visual reasoning combining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Proving geometric theorems constitutes a hallmark of visual reasoning combining both intuitive and logical skills. Therefore, automated theorem proving of Olympiad-level geometry problems is considered a notable milestone in human-level automated reasoning. The introduction of AlphaGeometry, a neuro-symbolic model trained with 100 million synthetic samples, marked a major breakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO) problems whereas the reported baseline based on Wu's method solved only ten. In this note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry, and find that Wu's method is surprisingly strong. Wu's method alone can solve 15 problems, and some of them are not solved by any of the other methods. This leads to two key findings: (i) Combining Wu's method with the classic synthetic methods of deductive databases and angle, ratio, and distance chasing solves 21 out of 30 methods by just using a CPU-only laptop with a time limit of 5 minutes per problem. Essentially, this classic method solves just 4 problems less than AlphaGeometry and establishes the first fully symbolic baseline strong enough to rival the performance of an IMO silver medalist. (ii) Wu's method even solves 2 of the 5 problems that AlphaGeometry failed to solve. Thus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art for automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the first AI method which outperforms an IMO gold medalist.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Apprentices to Research Assistants: Advancing Research with Large  Language Models</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06404">https://arxiv.org/abs/2404.06404</a></p>
  <p><b>作者</b>：M. Namvarpour,  A. Razi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, emerged as powerful, powerful tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have emerged as powerful tools in various research domains. This article examines their potential through a literature review and firsthand experimentation. While LLMs offer benefits like cost-effectiveness and efficiency, challenges such as prompt tuning, biases, and subjectivity must be addressed. The study presents insights from experiments utilizing LLMs for qualitative analysis, highlighting successes and limitations. Additionally, it discusses strategies for mitigating challenges, such as prompt optimization techniques and leveraging human expertise. This study aligns with the 'LLMs as Research Tools' workshop's focus on integrating LLMs into HCI data work critically and ethically. By addressing both opportunities and challenges, our work contributes to the ongoing dialogue on their responsible application in research.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Online Learning of Decision Trees with Thompson Sampling</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06403">https://arxiv.org/abs/2404.06403</a></p>
  <p><b>作者</b>：Ayman Chaouki,  Jesse Read,  Albert Bifet</p>
  <p><b>备注</b>：To be published in the Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024, Valencia, Spain. PMLR: Volume 238</p>
  <p><b>关键词</b>：interpretable Machine Learning, Machine Learning, prominent prediction models, interpretable Machine, Decision Trees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decision Trees are prominent prediction models for interpretable Machine Learning. They have been thoroughly researched, mostly in the batch setting with a fixed labelled dataset, leading to popular algorithms such as C4.5, ID3 and CART. Unfortunately, these methods are of heuristic nature, they rely on greedy splits offering no guarantees of global optimality and often leading to unnecessarily complex and hard-to-interpret Decision Trees. Recent breakthroughs addressed this suboptimality issue in the batch setting, but no such work has considered the online setting with data arriving in a stream. To this end, we devise a new Monte Carlo Tree Search algorithm, Thompson Sampling Decision Trees (TSDT), able to produce optimal Decision Trees in an online setting. We analyse our algorithm and prove its almost sure convergence to the optimal tree. Furthermore, we conduct extensive experiments to validate our findings empirically. The proposed TSDT outperforms existing algorithms on several benchmarks, all while presenting the practical advantage of being tailored to the online setting.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Dynamic Deep Learning Based Super-Resolution For The Shallow Water  Equations</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06400">https://arxiv.org/abs/2404.06400</a></p>
  <p><b>作者</b>：Maximilian Witte,  Fabricio Rodrigues Lapolli,  Philip Freese,  Sebastian Götschel,  Daniel Ruprecht,  Peter Korn,  Christopher Kadow</p>
  <p><b>备注</b>：17 pages, 12 figures</p>
  <p><b>关键词</b>：nonlinear shallow water, shallow water equations, ICON-O ocean model, achieve discretization errors, equations as benchmark</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using the nonlinear shallow water equations as benchmark, we demonstrate that a simulation with the ICON-O ocean model with a 20km resolution that is frequently corrected by a U-net-type neural network can achieve discretization errors of a simulation with 10km resolution. The network, originally developed for image-based super-resolution in post-processing, is trained to compute the difference between solutions on both meshes and is used to correct the coarse mesh every 12h. Our setup is the Galewsky test case, modeling transition of a barotropic instability into turbulent flow. We show that the ML-corrected coarse resolution run correctly maintains a balance flow and captures the transition to turbulence in line with the higher resolution simulation. After 8 day of simulation, the $L_2$-error of the corrected run is similar to a simulation run on the finer mesh. While mass is conserved in the corrected runs, we observe some spurious generation of kinetic energy.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：MiniCPM: Unveiling the Potential of Small Language Models with Scalable  Training Strategies</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06395">https://arxiv.org/abs/2404.06395</a></p>
  <p><b>作者</b>：Shengding Hu,  Yuge Tu,  Xu Han,  Chaoqun He,  Ganqu Cui,  Xiang Long,  Zhi Zheng,  Yewei Fang,  Yuxiang Huang,  Weilin Zhao,  Xinrong Zhang,  Zheng Leng Thai,  Kaihuo Zhang,  Chongyi Wang,  Yuan Yao,  Chenyang Zhao,  Jie Zhou,  Jie Cai,  Zhongwu Zhai,  Ning Ding,  Chao Jia,  Guoyang Zeng,  Dahai Li,  Zhiyuan Liu,  Maosong Sun</p>
  <p><b>备注</b>：17 pages paper, 7 pages Appendix</p>
  <p><b>关键词</b>：developing Large Language, Large Language Models, Large Language, Small Language Models, developing Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The burgeoning interest in developing Large Language Models (LLMs) with up to trillion parameters has been met with concerns regarding resource efficiency and practical expense, particularly given the immense cost of experimentation. This scenario underscores the importance of exploring the potential of Small Language Models (SLMs) as a resource-efficient alternative. In this context, we introduce MiniCPM, specifically the 1.2B and 2.4B non-embedding parameter variants, not only excel in their respective categories but also demonstrate capabilities on par with 7B-13B LLMs. While focusing on SLMs, our approach exhibits scalability in both model and data dimensions for future LLM research. Regarding model scaling, we employ extensive model wind tunnel experiments for stable and optimal scaling. For data scaling, we introduce a Warmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to continuous training and domain adaptation. We present an in-depth analysis of the intriguing training dynamics that occurred in the WSD LRS. With WSD LRS, we are now able to efficiently study data-model scaling law without extensive retraining experiments on both axes of model and data, from which we derive the much higher compute optimal data-model ratio than Chinchilla Optimal. Additionally, we introduce MiniCPM family, including MiniCPM-DPO, MiniCPM-MoE and MiniCPM-128K, whose excellent performance further cementing MiniCPM's foundation in diverse SLM applications. MiniCPM models are available publicly at this https URL .</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Exploring Neural Network Landscapes: Star-Shaped and Geodesic  Connectivity</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06391">https://arxiv.org/abs/2404.06391</a></p>
  <p><b>作者</b>：Zhanran Lin,  Puheng Li,  Lei Wu</p>
  <p><b>备注</b>：The first two authors contributed equally</p>
  <p><b>关键词</b>：structure of neural, mode connectivity, neural network landscape, typical global minima, connectivity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most intriguing findings in the structure of neural network landscape is the phenomenon of mode connectivity: For two typical global minima, there exists a path connecting them without barrier. This concept of mode connectivity has played a crucial role in understanding important phenomena in deep learning.
In this paper, we conduct a fine-grained analysis of this connectivity phenomenon. First, we demonstrate that in the overparameterized case, the connecting path can be as simple as a two-piece linear path, and the path length can be nearly equal to the Euclidean distance. This finding suggests that the landscape should be nearly convex in a certain sense. Second, we uncover a surprising star-shaped connectivity: For a finite number of typical minima, there exists a center on minima manifold that connects all of them simultaneously via linear paths. These results are provably valid for linear networks and two-layer ReLU networks under a teacher-student setup, and are empirically supported by models trained on MNIST and CIFAR-10.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Model Generation from Requirements with LLMs: an Exploratory Study</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06371">https://arxiv.org/abs/2404.06371</a></p>
  <p><b>作者</b>：Alessio Ferrari,  Sallam Abualhaija,  Chetan Arora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improve stakeholders' communication, Complementing natural language, Complementing natural, system design, improve stakeholders'</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Complementing natural language (NL) requirements with graphical models can improve stakeholders' communication and provide directions for system design. However, creating models from requirements involves manual effort. The advent of generative large language models (LLMs), ChatGPT being a notable example, offers promising avenues for automated assistance in model generation. This paper investigates the capability of ChatGPT to generate a specific type of model, i.e., UML sequence diagrams, from NL requirements. We conduct a qualitative study in which we examine the sequence diagrams generated by ChatGPT for 28 requirements documents of various types and from different domains. Observations from the analysis of the generated diagrams have systematically been captured through evaluation logs, and categorized through thematic analysis. Our results indicate that, although the models generally conform to the standard and exhibit a reasonable level of understandability, their completeness and correctness with respect to the specified requirements often present challenges. This issue is particularly pronounced in the presence of requirements smells, such as ambiguity and inconsistency. The insights derived from this study can influence the practical utilization of LLMs in the RE process, and open the door to novel RE-specific prompting strategies targeting effective model generation.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Policy-Guided Diffusion</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06356">https://arxiv.org/abs/2404.06356</a></p>
  <p><b>作者</b>：Matthew Thomas Jackson,  Michael Tryfan Matthews,  Cong Lu,  Benjamin Ellis,  Shimon Whiteson,  Jakob Foerster</p>
  <p><b>备注</b>：Previously at the NeurIPS 2023 Workshop on Robot Learning</p>
  <p><b>关键词</b>：offline dataset gathered, agents must learn, dataset gathered, prior behavior policy, policy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many real-world settings, agents must learn from an offline dataset gathered by some prior behavior policy. Such a setting naturally leads to distribution shift between the behavior policy and the target policy being trained - requiring policy conservatism to avoid instability and overestimation bias. Autoregressive world models offer a different solution to this by generating synthetic, on-policy experience. However, in practice, model rollouts must be severely truncated to avoid compounding error. As an alternative, we propose policy-guided diffusion. Our method uses diffusion models to generate entire trajectories under the behavior distribution, applying guidance from the target policy to move synthetic experience further on-policy. We show that policy-guided diffusion models a regularized form of the target distribution that balances action likelihood under both the target and behavior policies, leading to plausible trajectories with high target policy probability, while retaining a lower dynamics error than an offline world model baseline. Using synthetic experience from policy-guided diffusion as a drop-in substitute for real data, we demonstrate significant improvements in performance across a range of standard offline reinforcement learning algorithms and environments. Our approach provides an effective alternative to autoregressive offline world models, opening the door to the controllable generation of synthetic training data.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：High Noise Scheduling is a Must</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06353">https://arxiv.org/abs/2404.06353</a></p>
  <p><b>作者</b>：Mahmut S. Gokmen,  Cody Bumgardner,  Jie Zhang,  Ge Wang,  Jin Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noise distribution, advancing sampling steps, possess high capabilities, noise, polynomial noise distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Consistency models possess high capabilities for image generation, advancing sampling steps to a single step through their advanced techniques. Current advancements move one step forward consistency training techniques and eliminates the limitation of distillation training. Even though the proposed curriculum and noise scheduling in improved training techniques yield better results than basic consistency models, it lacks well balanced noise distribution and its consistency between curriculum. In this study, it is investigated the balance between high and low noise levels in noise distribution and offered polynomial noise distribution to maintain the stability. This proposed polynomial noise distribution is also supported with a predefined Karras noises to prevent unique noise levels arises with Karras noise generation algorithm. Furthermore, by elimination of learned noisy steps with a curriculum based on sinusoidal function increase the performance of the model in denoising. To make a fair comparison with the latest released consistency model training techniques, experiments are conducted with same hyper-parameters except curriculum and noise distribution. The models utilized during experiments are determined with low depth to prove the robustness of our proposed technique. The results show that the polynomial noise distribution outperforms the model trained with log-normal noise distribution, yielding a 33.54 FID score after 100,000 training steps with constant discretization steps. Additionally, the implementation of a sinusoidal-based curriculum enhances denoising performance, resulting in a FID score of 30.48.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：CausalBench: A Comprehensive Benchmark for Causal Learning Capability of  Large Language Models</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06349">https://arxiv.org/abs/2404.06349</a></p>
  <p><b>作者</b>：Yu Zhou,  Xingyu Wu,  Beicheng Huang,  Jibin Wu,  Liang Feng,  Kay Chen Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, reveals fundamental principles, Causality reveals fundamental, understand causality directly, causality directly impacts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causality reveals fundamental principles behind data distributions in real-world scenarios, and the capability of large language models (LLMs) to understand causality directly impacts their efficacy across explaining outputs, adapting to new evidence, and generating counterfactuals. With the proliferation of LLMs, the evaluation of this capacity is increasingly garnering attention. However, the absence of a comprehensive benchmark has rendered existing evaluation studies being straightforward, undiversified, and homogeneous. To address these challenges, this paper proposes a comprehensive benchmark, namely CausalBench, to evaluate the causality understanding capabilities of LLMs. Originating from the causal research community, CausalBench encompasses three causal learning-related tasks, which facilitate a convenient comparison of LLMs' performance with classic causal learning algorithms. Meanwhile, causal networks of varying scales and densities are integrated in CausalBench, to explore the upper limits of LLMs' capabilities across task scenarios of varying difficulty. Notably, background knowledge and structured data are also incorporated into CausalBench to thoroughly unlock the underlying potential of LLMs for long-text comprehension and prior information utilization. Based on CausalBench, this paper evaluates nineteen leading LLMs and unveils insightful conclusions in diverse aspects. Firstly, we present the strengths and weaknesses of LLMs and quantitatively explore the upper limits of their capabilities across various scenarios. Meanwhile, we further discern the adaptability and abilities of LLMs to specific structural networks and complex chain of thought structures. Moreover, this paper quantitatively presents the differences across diverse information sources and uncovers the gap between LLMs' capabilities in causal understanding within textual contexts and numerical domains.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Finding fake reviews in e-commerce platforms by using hybrid algorithms</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06339">https://arxiv.org/abs/2404.06339</a></p>
  <p><b>作者</b>：Mathivanan Periasamy,  Rohith Mahadevan,  Bagiya Lakshmi S,  Raja CSP Raman,  Hasan Kumar S,  Jasper Jessiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, Support Vector Machine, Decision Tree classifiers, language processing, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sentiment analysis, a vital component in natural language processing, plays a crucial role in understanding the underlying emotions and opinions expressed in textual data. In this paper, we propose an innovative ensemble approach for sentiment analysis for finding fake reviews that amalgamate the predictive capabilities of Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Decision Tree classifiers. Our ensemble architecture strategically combines these diverse models to capitalize on their strengths while mitigating inherent weaknesses, thereby achieving superior accuracy and robustness in fake review prediction. By combining all the models of our classifiers, the predictive performance is boosted and it also fosters adaptability to varied linguistic patterns and nuances present in real-world datasets. The metrics accounted for on fake reviews demonstrate the efficacy and competitiveness of the proposed ensemble method against traditional single-model approaches. Our findings underscore the potential of ensemble techniques in advancing the state-of-the-art in finding fake reviews using hybrid algorithms, with implications for various applications in different social media and e-platforms to find the best reviews and neglect the fake ones, eliminating puffery and bluffs.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Generative Pre-Trained Transformer for Symbolic Regression Base  In-Context Reinforcement Learning</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06330">https://arxiv.org/abs/2404.06330</a></p>
  <p><b>作者</b>：Yanjie Li,  Weijun Li,  Lina Yu,  Min Wu,  Jingyi Liu,  Wenqiang Li,  Meilan Hao,  Shu Wei,  Yusong Deng</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：scientific research, Finding mathematical formulas, human language, language to describe, describe nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The mathematical formula is the human language to describe nature and is the essence of scientific research. Finding mathematical formulas from observational data is a major demand of scientific research and a major challenge of artificial intelligence. This area is called symbolic regression. Originally symbolic regression was often formulated as a combinatorial optimization problem and solved using GP or reinforcement learning algorithms. These two kinds of algorithms have strong noise robustness ability and good Versatility. However, inference time usually takes a long time, so the search efficiency is relatively low. Later, based on large-scale pre-training data proposed, such methods use a large number of synthetic data points and expression pairs to train a Generative Pre-Trained Transformer(GPT). Then this GPT can only need to perform one forward propagation to obtain the results, the advantage is that the inference speed is very fast. However, its performance is very dependent on the training data and performs poorly on data outside the training set, which leads to poor noise robustness and Versatility of such methods. So, can we combine the advantages of the above two categories of SR algorithms? In this paper, we propose \textbf{FormulaGPT}, which trains a GPT using massive sparse reward learning histories of reinforcement learning-based SR algorithms as training data. After training, the SR algorithm based on reinforcement learning is distilled into a Transformer. When new test data comes, FormulaGPT can directly generate a "reinforcement learning process" and automatically update the learning policy in context. Tested on more than ten datasets including SRBench, formulaGPT achieves the state-of-the-art performance in fitting ability compared with four baselines. In addition, it achieves satisfactory results in noise robustness, versatility, and inference efficiency.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：What is the $\textit{intrinsic}$ dimension of your binary data? -- and  how to compute it quickly</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06326">https://arxiv.org/abs/2404.06326</a></p>
  <p><b>作者</b>：Tom Hanika,  Tobias Hille</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：analyzing and understanding, ICDM paper Tatti, important aspect, aspect for analyzing, ICDM paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality is an important aspect for analyzing and understanding (high-dimensional) data. In their 2006 ICDM paper Tatti et al. answered the question for a (interpretable) dimension of binary data tables by introducing a normalized correlation dimension. In the present work we revisit their results and contrast them with a concept based notion of intrinsic dimension (ID) recently introduced for geometric data sets. To do this, we present a novel approximation for this ID that is based on computing concepts only up to a certain support value. We demonstrate and evaluate our approximation using all available datasets from Tatti et al., which have between 469 and 41271 extrinsic dimensions.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Dynamic D2D-Assisted Federated Learning over O-RAN: Performance  Analysis, MAC Scheduler, and Asymmetric User Selection</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06324">https://arxiv.org/abs/2404.06324</a></p>
  <p><b>作者</b>：Payam Abdisarabshali,  Kwang Taik Kim,  Michael Langberg,  Weifeng Su,  Seyyedali Hosseinalipour</p>
  <p><b>备注</b>：120 pages, 13 figures</p>
  <p><b>关键词</b>：making static control, static snapshots, making static, wireless channel capacity, Existing studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing studies on federated learning (FL) are mostly focused on system orchestration for static snapshots of the network and making static control decisions (e.g., spectrum allocation). However, real-world wireless networks are susceptible to temporal variations of wireless channel capacity and users' datasets. In this paper, we incorporate multi-granular system dynamics (MSDs) into FL, including (M1) dynamic wireless channel capacity, captured by a set of discrete-time events, called $\mathscr{D}$-Events, and (M2) dynamic datasets of users. The latter is characterized by (M2-a) modeling the dynamics of user's dataset size via an ordinary differential equation and (M2-b) introducing dynamic model drift}, formulated via a partial differential inequality} drawing concrete analytical connections between the dynamics of users' datasets and FL accuracy. We then conduct FL orchestration under MSDs by introducing dynamic cooperative FL with dedicated MAC schedulers (DCLM), exploiting the unique features of open radio access network (O-RAN). DCLM proposes (i) a hierarchical device-to-device (D2D)-assisted model training, (ii) dynamic control decisions through dedicated O-RAN MAC schedulers, and (iii) asymmetric user selection. We provide extensive theoretical analysis to study the convergence of DCLM. We then optimize the degrees of freedom (e.g., user selection and spectrum allocation) in DCLM through a highly non-convex optimization problem. We develop a systematic approach to obtain the solution for this problem, opening the door to solving a broad variety of network-aware FL optimization problems. We show the efficiency of DCLM via numerical simulations and provide a series of future directions.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：On adversarial training and the 1 Nearest Neighbor classifier</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06313">https://arxiv.org/abs/2404.06313</a></p>
  <p><b>作者</b>：Amir Hagai,  Yair Weiss</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fool deep learning, deep learning classifiers, adversarial training, adversarial, training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to fool deep learning classifiers with tiny perturbations of the input has lead to the development of adversarial training in which the loss with respect to adversarial examples is minimized in addition to the training examples. While adversarial training improves the robustness of the learned classifiers, the procedure is computationally expensive, sensitive to hyperparameters and may still leave the classifier vulnerable to other types of small perturbations. In this paper we analyze the adversarial robustness of the 1 Nearest Neighbor (1NN) classifier and compare its performance to adversarial training. We prove that under reasonable assumptions, the 1 NN classifier will be robust to {\em any} small image perturbation of the training images and will give high adversarial accuracy on test images as the number of training examples goes to infinity. In experiments with 45 different binary image classification problems taken from CIFAR10, we find that 1NN outperform TRADES (a powerful adversarial training algorithm) in terms of average adversarial accuracy. In additional experiments with 69 pretrained robust models for CIFAR10, we find that 1NN outperforms almost all of them in terms of robustness to perturbations that are only slightly different from those seen during training. Taken together, our results suggest that modern adversarial training methods still fall short of the robustness of the simple 1NN classifier. our code can be found at this https URL</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Counterfactual Reasoning for Multi-Label Image Classification via  Patching-Based Training</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06287">https://arxiv.org/abs/2404.06287</a></p>
  <p><b>作者</b>：Ming-Kun Xie,  Jia-Hao Xiao,  Pei Peng,  Gang Niu,  Masashi Sugiyama,  Sheng-Jun Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging label correlations, multi-label image classification, target object, improve model performance, label correlations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The key to multi-label image classification (MLC) is to improve model performance by leveraging label correlations. Unfortunately, it has been shown that overemphasizing co-occurrence relationships can cause the overfitting issue of the model, ultimately leading to performance degradation. In this paper, we provide a causal inference framework to show that the correlative features caused by the target object and its co-occurring objects can be regarded as a mediator, which has both positive and negative impacts on model predictions. On the positive side, the mediator enhances the recognition performance of the model by capturing co-occurrence relationships; on the negative side, it has the harmful causal effect that causes the model to make an incorrect prediction for the target object, even when only co-occurring objects are present in an image. To address this problem, we propose a counterfactual reasoning method to measure the total direct effect, achieved by enhancing the direct effect caused only by the target object. Due to the unknown location of the target object, we propose patching-based training and inference to accomplish this goal, which divides an image into multiple patches and identifies the pivot patch that contains the target object. Experimental results on multiple benchmark datasets with diverse configurations validate that the proposed method can achieve state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Algorithms for Caching and MTS with reduced number of predictions</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06280">https://arxiv.org/abs/2404.06280</a></p>
  <p><b>作者</b>：Karim Abdel Sadek,  Marek Elias</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ML-augmented algorithms utilize, worst-case bounds, predictions, ML-augmented algorithms, algorithms utilize predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>ML-augmented algorithms utilize predictions to achieve performance beyond their worst-case bounds. Producing these predictions might be a costly operation -- this motivated Im et al. '22 to introduce the study of algorithms which use predictions parsimoniously. We design parsimonious algorithms for caching and MTS with action predictions, proposed by Antoniadis et al. '20, focusing on the parameters of consistency (performance with perfect predictions) and smoothness (dependence of their performance on the prediction error). Our algorithm for caching is 1-consistent, robust, and its smoothness deteriorates with the decreasing number of available predictions. We propose an algorithm for general MTS whose consistency and smoothness both scale linearly with the decreasing number of predictions. Without the restriction on the number of available predictions, both algorithms match the earlier guarantees achieved by Antoniadis et al. '20.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Dimensionality Reduction in Sentence Transformer Vector Databases with  Fast Fourier Transform</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06278">https://arxiv.org/abs/2404.06278</a></p>
  <p><b>作者</b>：Vitaly Bulgakov,  Alec Segal</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：enabling efficient storage, Fast Fourier Transform, faster computation, enabling efficient, efficient storage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality reduction in vector databases is pivotal for streamlining AI data management, enabling efficient storage, faster computation, and improved model performance. This paper explores the benefits of reducing vector database dimensions, with a focus on computational efficiency and overcoming the curse of dimensionality. We introduce a novel application of Fast Fourier Transform (FFT) to dimensionality reduction, a method previously underexploited in this context. By demonstrating its utility across various AI domains, including Retrieval-Augmented Generation (RAG) models and image processing, this FFT-based approach promises to improve data retrieval processes and enhance the efficiency and scalability of AI solutions. The incorporation of FFT may not only optimize operations in real-time processing and recommendation systems but also extend to advanced image processing techniques, where dimensionality reduction can significantly improve performance and analysis efficiency. This paper advocates for the broader adoption of FFT in vector database management, marking a significant stride towards addressing the challenges of data volume and complexity in AI research and applications. Unlike many existing approaches, we directly handle the embedding vectors produced by the model after processing a test input.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：PGTNet: A Process Graph Transformer Network for Remaining Time  Prediction of Business Process Instances</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06267">https://arxiv.org/abs/2404.06267</a></p>
  <p><b>作者</b>：Keyvan Amiri Elyasi,  Han van der Aa,  Heiner Stuckenschmidt</p>
  <p><b>备注</b>：16 pages, 4 figures, To be published in: Advanced Information Systems Engineering - 36th International Conference, CAiSE 2024, Limassol, Cyprus, June 03-07, 2024, Proceedings</p>
  <p><b>关键词</b>：Graph Transformer Networks, Process Graph Transformer, Transformer Networks, leverages graph-oriented data, Graph Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present PGTNet, an approach that transforms event logs into graph datasets and leverages graph-oriented data for training Process Graph Transformer Networks to predict the remaining time of business process instances. PGTNet consistently outperforms state-of-the-art deep learning approaches across a diverse range of 20 publicly available real-world event logs. Notably, our approach is most promising for highly complex processes, where existing deep learning approaches encounter difficulties stemming from their limited ability to learn control-flow relationships among process activities and capture long-range dependencies. PGTNet addresses these challenges, while also being able to consider multiple process perspectives during the learning process.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised  Action Recognition in Videos</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06243">https://arxiv.org/abs/2404.06243</a></p>
  <p><b>作者</b>：Sharana Dharshikgan Suresh Dass,  Hrishav Bakul Barua,  Ganesh Krishnasamy,  Raveendran Paramesran,  Raphael C.-W. Phan</p>
  <p><b>备注</b>：Submitted for peer review</p>
  <p><b>关键词</b>：self-driving cars, sports analytics, surveillance and monitoring, human-robot interaction, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human action or activity recognition in videos is a fundamental task in computer vision with applications in surveillance and monitoring, self-driving cars, sports analytics, human-robot interaction and many more. Traditional supervised methods require large annotated datasets for training, which are expensive and time-consuming to acquire. This work proposes a novel approach using Cross-Architecture Pseudo-Labeling with contrastive learning for semi-supervised action recognition. Our framework leverages both labeled and unlabelled data to robustly learn action representations in videos, combining pseudo-labeling with contrastive learning for effective learning from both types of samples. We introduce a novel cross-architecture approach where 3D Convolutional Neural Networks (3D CNNs) and video transformers (VIT) are utilised to capture different aspects of action representations; hence we call it ActNetFormer. The 3D CNNs excel at capturing spatial features and local dependencies in the temporal domain, while VIT excels at capturing long-range dependencies across frames. By integrating these complementary architectures within the ActNetFormer framework, our approach can effectively capture both local and global contextual information of an action. This comprehensive representation learning enables the model to achieve better performance in semi-supervised action recognition tasks by leveraging the strengths of each of these architectures. Experimental results on standard action recognition datasets demonstrate that our approach performs better than the existing methods, achieving state-of-the-art performance with only a fraction of labeled data. The official website of this work is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Towards Robust Domain Generation Algorithm Classification</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06236">https://arxiv.org/abs/2404.06236</a></p>
  <p><b>作者</b>：Arthur Drichel,  Marc Meyer,  Ulrike Meyer</p>
  <p><b>备注</b>：Accepted at ACM Asia Conference on Computer and Communications Security (ASIA CCS 2024)</p>
  <p><b>关键词</b>：domain generation algorithm, generation algorithm, conduct a comprehensive, domain generation, classifiers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we conduct a comprehensive study on the robustness of domain generation algorithm (DGA) classifiers. We implement 32 white-box attacks, 19 of which are very effective and induce a false-negative rate (FNR) of $\approx$ 100\% on unhardened classifiers. To defend the classifiers, we evaluate different hardening approaches and propose a novel training scheme that leverages adversarial latent space vectors and discretized adversarial domains to significantly improve robustness. In our study, we highlight a pitfall to avoid when hardening classifiers and uncover training biases that can be easily exploited by attackers to bypass detection, but which can be mitigated by adversarial training (AT). In our study, we do not observe any trade-off between robustness and performance, on the contrary, hardening improves a classifier's detection performance for known and unknown DGAs. We implement all attacks and defenses discussed in this paper as a standalone library, which we make publicly available to facilitate hardening of DGA classifiers: this https URL</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Aggressive or Imperceptible, or Both: Network Pruning Assisted Hybrid  Byzantines in Federated Learning</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06230">https://arxiv.org/abs/2404.06230</a></p>
  <p><b>作者</b>：Emre Ozfatura,  Kerem Ozfatura,  Alptekin Kupcu,  Deniz Gunduz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generalized machine learning, possibly mobile devices, machine learning model, large number, Federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) has been introduced to enable a large number of clients, possibly mobile devices, to collaborate on generating a generalized machine learning model thanks to utilizing a larger number of local samples without sharing to offer certain privacy to collaborating clients. However, due to the participation of a large number of clients, it is often difficult to profile and verify each client, which leads to a security threat that malicious participants may hamper the accuracy of the trained model by conveying poisoned models during the training. Hence, the aggregation framework at the parameter server also needs to minimize the detrimental effects of these malicious clients. A plethora of attack and defence strategies have been analyzed in the literature. However, often the Byzantine problem is analyzed solely from the outlier detection perspective, being oblivious to the topology of neural networks (NNs).
In the scope of this work, we argue that by extracting certain side information specific to the NN topology, one can design stronger attacks. Hence, inspired by the sparse neural networks, we introduce a hybrid sparse Byzantine attack that is composed of two parts: one exhibiting a sparse nature and attacking only certain NN locations with higher sensitivity, and the other being more silent but accumulating over time, where each ideally targets a different type of defence mechanism, and together they form a strong but imperceptible attack. Finally, we show through extensive simulations that the proposed hybrid Byzantine attack is effective against 8 different defence methods.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Low-Cost Generation and Evaluation of Dictionary Example Sentences</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06224">https://arxiv.org/abs/2404.06224</a></p>
  <p><b>作者</b>：Bill Cai,  Clarence Boon Liang Ng,  Daniel Tan,  Shelvia Hotama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：manually creating quality, illustrating word definitions, definitions and usage, play an important, important role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dictionary example sentences play an important role in illustrating word definitions and usage, but manually creating quality sentences is challenging. Prior works have demonstrated that language models can be trained to generate example sentences. However, they relied on costly customized models and word sense datasets for generation and evaluation of their work. Rapid advancements in foundational models present the opportunity to create low-cost, zero-shot methods for the generation and evaluation of dictionary example sentences. We introduce a new automatic evaluation metric called OxfordEval that measures the win-rate of generated sentences against existing Oxford Dictionary sentences. OxfordEval shows high alignment with human judgments, enabling large-scale automated quality evaluation. We experiment with various LLMs and configurations to generate dictionary sentences across word classes. We complement this with a novel approach of using masked language models to identify and select sentences that best exemplify word meaning. The eventual model, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences according to OxfordEval, compared to 39.8% win rate for prior model-generated sentences.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Zero-Shot Relational Learning for Multimodal Knowledge Graphs</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06220">https://arxiv.org/abs/2404.06220</a></p>
  <p><b>作者</b>：Rui Cai,  Shichao Pei,  Xiangliang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：KGC context presents, traditional single-modal settings, context presents distinct, presents distinct challenges, multimodal KGC context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relational learning is an essential task in the domain of knowledge representation, particularly in knowledge graph completion (KGC).While relational learning in traditional single-modal settings has been extensively studied, exploring it within a multimodal KGC context presents distinct challenges and opportunities. One of the major challenges is inference on newly discovered relations without any associated training data. This zero-shot relational learning scenario poses unique requirements for multimodal KGC, i.e., utilizing multimodality to facilitate relational learning. However, existing works fail to support the leverage of multimodal information and leave the problem unexplored. In this paper, we propose a novel end-to-end framework, consisting of three components, i.e., multimodal learner, structure consolidator, and relation embedding generator, to integrate diverse multimodal information and knowledge graph structures to facilitate the zero-shot relational learning. Evaluation results on two multimodal knowledge graphs demonstrate the superior performance of our proposed method.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Quantum Circuit $C^*$-algebra Net</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06218">https://arxiv.org/abs/2404.06218</a></p>
  <p><b>作者</b>：Yuka Hashimoto,  Ryuichiro Hataya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper introduces quantum, algebra nets proposed, algebra net, quantum, algebra</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces quantum circuit $C^*$-algebra net, which provides a connection between $C^*$-algebra nets proposed in classical machine learning and quantum circuits. Using $C^*$-algebra, a generalization of the space of complex numbers, we can represent quantum gates as weight parameters of a neural network. By introducing additional parameters, we can induce interaction among multiple circuits constructed by quantum gates. This interaction enables the circuits to share information among them, which contributes to improved generalization performance in machine learning tasks. As an application, we propose to use the quantum circuit $C^*$-algebra net to encode classical data into quantum states, which enables us to integrate classical data into quantum algorithms. Numerical results demonstrate that the interaction among circuits improves performance significantly in image classification, and encoded data by the quantum circuit $C^*$-algebra net are useful for downstream quantum machine learning tasks.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：OmniFusion Technical Report</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06212">https://arxiv.org/abs/2404.06212</a></p>
  <p><b>作者</b>：Elizaveta Goncharova,  Anton Razzhigaev,  Matvey Mikhalchuk,  Maxim Kurkin,  Irina Abdullaeva,  Matvey Skripkin,  Ivan Oseledets,  Denis Dimitrov,  Andrey Kuznetsov</p>
  <p><b>备注</b>：17 pages, 4 figures, 9 tables, 2 appendices</p>
  <p><b>关键词</b>：multimodal architectures served, large language models, extending the capabilities, revolution in AI-based, AI-based approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Last year, multimodal architectures served up a revolution in AI-based approaches and solutions, extending the capabilities of large language models (LLM). We propose an \textit{OmniFusion} model based on a pretrained LLM and adapters for visual modality. We evaluated and compared several architecture design principles for better text and visual data coupling: MLP and transformer adapters, various CLIP ViT-based encoders (SigLIP, InternVIT, etc.), and their fusing approach, image encoding method (whole image or tiles encoding) and two 7B LLMs (the proprietary one and open-source Mistral). Experiments on 8 visual-language benchmarks show the top score for the best OmniFusion setup in terms of different VQA tasks in comparison with open-source LLaVA-like solutions: VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU. We also propose a variety of situations, where OmniFusion provides highly-detailed answers in different domains: housekeeping, sightseeing, culture, medicine, handwritten and scanned equations recognition, etc. Mistral-based OmniFusion model is an open-source solution with weights, training and inference scripts available at this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Elephants Never Forget: Memorization and Learning of Tabular Data in  Large Language Models</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06209">https://arxiv.org/abs/2404.06209</a></p>
  <p><b>作者</b>：Sebastian Bordt,  Harsha Nori,  Vanessa Rodrigues,  Besmira Nushi,  Rich Caruana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown how Large, Large Language, set of tasks, diverse set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Specifically, we introduce a variety of different techniques to assess whether a language model has seen a tabular dataset during training. This investigation reveals that LLMs have memorized many popular tabular datasets verbatim. We then compare the few-shot learning performance of LLMs on datasets that were seen during training to the performance on datasets released after training. We find that LLMs perform better on datasets seen during training, indicating that memorization leads to overfitting. At the same time, LLMs show non-trivial performance on novel datasets and are surprisingly robust to data transformations. We then investigate the in-context statistical learning abilities of LLMs. Without fine-tuning, we find them to be limited. This suggests that much of the few-shot performance on novel datasets is due to the LLM's world knowledge. Overall, our results highlight the importance of testing whether an LLM has seen an evaluation dataset during pre-training. We make the exposure tests we developed available as the tabmemcheck Python package at this https URL</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：The impact of data set similarity and diversity on transfer learning  success in time series forecasting</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06198">https://arxiv.org/abs/2404.06198</a></p>
  <p><b>作者</b>：Claudia Ehrig,  Catherine Cleophas,  Germain Forestier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：target data sets, leveraging transfer learning, target data, time series forecasting, diverse source data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Models, pre-trained on a similar or diverse source data set, have become pivotal in enhancing the efficiency and accuracy of time series forecasting on target data sets by leveraging transfer learning. While benchmarks validate the performance of model generalization on various target data sets, there is no structured research providing similarity and diversity measures explaining which characteristics of source and target data lead to transfer learning success. Our study pioneers in systematically evaluating the impact of source-target similarity and source diversity on zero-shot and fine-tuned forecasting outcomes in terms of accuracy, bias, and uncertainty estimation. We investigate these dynamics using pre-trained neural networks across five public source datasets, applied in forecasting five target data sets, including real-world wholesales data. We identify two feature-based similarity and diversity measures showing: Source-target similarity enhances forecasting accuracy and reduces bias, while source diversity enhances forecasting accuracy and uncertainty estimation and increases the bias.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Diverse Randomized Value Functions: A Provably Pessimistic Approach for  Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06188">https://arxiv.org/abs/2404.06188</a></p>
  <p><b>作者</b>：Xudong Yu,  Chenjia Bai,  Hongyi Guo,  Changhong Wang,  Zhen Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：faces distributional shift, Offline Reinforcement Learning, Reinforcement Learning, faces distributional, distributional shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline Reinforcement Learning (RL) faces distributional shift and unreliable value estimation, especially for out-of-distribution (OOD) actions. To address this, existing uncertainty-based methods penalize the value function with uncertainty quantification and demand numerous ensemble networks, posing computational challenges and suboptimal outcomes. In this paper, we introduce a novel strategy employing diverse randomized value functions to estimate the posterior distribution of $Q$-values. It provides robust uncertainty quantification and estimates lower confidence bounds (LCB) of $Q$-values. By applying moderate value penalties for OOD actions, our method fosters a provably pessimistic approach. We also emphasize on diversity within randomized value functions and enhance efficiency by introducing a diversity regularization method, reducing the requisite number of networks. These modules lead to reliable value estimation and efficient policy learning from offline data. Theoretical analysis shows that our method recovers the provably efficient LCB-penalty under linear MDP assumptions. Extensive empirical results also demonstrate that our proposed method significantly outperforms baseline methods in terms of performance and parametric efficiency.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：CLIP-Embed-KD: Computationally Efficient Knowledge Distillation Using  Embeddings as Teachers</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06170">https://arxiv.org/abs/2404.06170</a></p>
  <p><b>作者</b>：Lakshmi Nair</p>
  <p><b>备注</b>：Short paper - 5 pages; 5 figures</p>
  <p><b>关键词</b>：Contrastive Language-Image Pre-training, improve zero-shot generalization, zero-shot generalization capabilities, Language-Image Pre-training, Contrastive Language-Image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive Language-Image Pre-training (CLIP) has been shown to improve zero-shot generalization capabilities of language and vision models. In this paper, we extend CLIP for efficient knowledge distillation, by utilizing embeddings as teachers. Typical knowledge distillation frameworks require running forward passes through a teacher model, which is often prohibitive in the case of billion or trillion parameter teachers. In these cases, using only the embeddings of the teacher models to guide the distillation can yield significant computational savings. Our preliminary findings show that CLIP-based knowledge distillation with embeddings can outperform full scale knowledge distillation using $9\times$ less memory and $8\times$ less training time. Code available at: this https URL</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：scCDCG: Efficient Deep Structural Clustering for single-cell RNA-seq via  Deep Cut-informed Graph Embedding</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06167">https://arxiv.org/abs/2404.06167</a></p>
  <p><b>作者</b>：Ping Xu,  Zhiyuan Ning,  Meng Xiao,  Guihai Feng,  Xin Li,  Yuanchun Zhou,  Pengfei Wang</p>
  <p><b>备注</b>：Accepted as a long paper for the research track at DASFAA 2024</p>
  <p><b>关键词</b>：Single-cell RNA sequencing, offering invaluable insights, RNA sequencing, unraveling cellular heterogeneity, scRNA-seq data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single-cell RNA sequencing (scRNA-seq) is essential for unraveling cellular heterogeneity and diversity, offering invaluable insights for bioinformatics advancements. Despite its potential, traditional clustering methods in scRNA-seq data analysis often neglect the structural information embedded in gene expression profiles, crucial for understanding cellular correlations and dependencies. Existing strategies, including graph neural networks, face challenges in handling the inefficiency due to scRNA-seq data's intrinsic high-dimension and high-sparsity. Addressing these limitations, we introduce scCDCG (single-cell RNA-seq Clustering via Deep Cut-informed Graph), a novel framework designed for efficient and accurate clustering of scRNA-seq data that simultaneously utilizes intercellular high-order structural information. scCDCG comprises three main components: (i) A graph embedding module utilizing deep cut-informed techniques, which effectively captures intercellular high-order structural information, overcoming the over-smoothing and inefficiency issues prevalent in prior graph neural network methods. (ii) A self-supervised learning module guided by optimal transport, tailored to accommodate the unique complexities of scRNA-seq data, specifically its high-dimension and high-sparsity. (iii) An autoencoder-based feature learning module that simplifies model complexity through effective dimension reduction and feature extraction. Our extensive experiments on 6 datasets demonstrate scCDCG's superior performance and efficiency compared to 7 established models, underscoring scCDCG's potential as a transformative tool in scRNA-seq data analysis. Our code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Characterizing Multimodal Long-form Summarization: A Case Study on  Financial Reports</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06162">https://arxiv.org/abs/2404.06162</a></p>
  <p><b>作者</b>：Tianyu Cao,  Natraj Raman,  Danial Dervovic,  Chenhao Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, natural language processing, language models, large language, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models (LLMs) expand the power of natural language processing to handle long inputs, rigorous and systematic analyses are necessary to understand their abilities and behavior. A salient application is summarization, due to its ubiquity and controversy (e.g., researchers have declared the death of summarization). In this paper, we use financial report summarization as a case study because financial reports not only are long but also use numbers and tables extensively. We propose a computational framework for characterizing multimodal long-form summarization and investigate the behavior of Claude 2.0/2.1, GPT-4/3.5, and Command. We find that GPT-3.5 and Command fail to perform this summarization task meaningfully. For Claude 2 and GPT-4, we analyze the extractiveness of the summary and identify a position bias in LLMs. This position bias disappears after shuffling the input for Claude, which suggests that Claude has the ability to recognize important information. We also conduct a comprehensive investigation on the use of numeric data in LLM-generated summaries and offer a taxonomy of numeric hallucination. We employ prompt engineering to improve GPT-4's use of numbers with limited success. Overall, our analyses highlight the strong capability of Claude 2 in handling long multimodal inputs compared to GPT-4.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：scRDiT: Generating single-cell RNA-seq data by diffusion transformers  and accelerating sampling</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06153">https://arxiv.org/abs/2404.06153</a></p>
  <p><b>作者</b>：Shengze Dong,  Zhuorui Cui,  Ding Liu,  Jinzhi Lei</p>
  <p><b>备注</b>：11 pages, 4 figures,</p>
  <p><b>关键词</b>：Single-cell RNA sequencing, Single-cell RNA, groundbreaking technology extensively, technology extensively utilized, individual cell level</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivation: Single-cell RNA sequencing (scRNA-seq) is a groundbreaking technology extensively utilized in biological research, facilitating the examination of gene expression at the individual cell level within a given tissue sample. While numerous tools have been developed for scRNA-seq data analysis, the challenge persists in capturing the distinct features of such data and replicating virtual datasets that share analogous statistical properties. Results: Our study introduces a generative approach termed scRNA-seq Diffusion Transformer (scRDiT). This method generates virtual scRNA-seq data by leveraging a real dataset. The method is a neural network constructed based on Denoising Diffusion Probabilistic Models (DDPMs) and Diffusion Transformers (DiTs). This involves subjecting Gaussian noises to the real dataset through iterative noise-adding steps and ultimately restoring the noises to form scRNA-seq samples. This scheme allows us to learn data features from actual scRNA-seq samples during model training. Our experiments, conducted on two distinct scRNA-seq datasets, demonstrate superior performance. Additionally, the model sampling process is expedited by incorporating Denoising Diffusion Implicit Models (DDIM). scRDiT presents a unified methodology empowering users to train neural network models with their unique scRNA-seq datasets, enabling the generation of numerous high-quality scRNA-seq samples. Availability and implementation: this https URL</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Differential Privacy for Anomaly Detection: Analyzing the Trade-off  Between Privacy and Explainability</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06144">https://arxiv.org/abs/2404.06144</a></p>
  <p><b>作者</b>：Fatima Ezzeddine,  Mirna Saad,  Omran Ayoub,  Davide Andreoletti,  Martin Gjoreski,  Ihab Sbeity,  Marc Langheinrich,  Silvia Giordano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical process aimed, aimed at identifying, identifying observations, significantly deviate, expected pattern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD), also referred to as outlier detection, is a statistical process aimed at identifying observations within a dataset that significantly deviate from the expected pattern of the majority of the data. Such a process finds wide application in various fields, such as finance and healthcare. While the primary objective of AD is to yield high detection accuracy, the requirements of explainability and privacy are also paramount. The first ensures the transparency of the AD process, while the second guarantees that no sensitive information is leaked to untrusted parties. In this work, we exploit the trade-off of applying Explainable AI (XAI) through SHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform AD with different models and on various datasets, and we thoroughly evaluate the cost of privacy in terms of decreased accuracy and explainability. Our results show that the enforcement of privacy through DP has a significant impact on detection accuracy and explainability, which depends on both the dataset and the considered AD model. We further show that the visual interpretation of explanations is also influenced by the choice of the AD algorithm.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Adaptable Recovery Behaviors in Robotics: A Behavior Trees and Motion  Generators(BTMG) Approach for Failure Management</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06129">https://arxiv.org/abs/2404.06129</a></p>
  <p><b>作者</b>：Faseeh Ahmad,  Matthias Mayr,  Sulthan Suresh-Fazeela,  Volker Kreuger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：failures necessitates robust, dynamic operational environments, adaptable recovery strategies, recovery strategies, necessitates robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In dynamic operational environments, particularly in collaborative robotics, the inevitability of failures necessitates robust and adaptable recovery strategies. Traditional automated recovery strategies, while effective for predefined scenarios, often lack the flexibility required for on-the-fly task management and adaptation to expected failures. Addressing this gap, we propose a novel approach that models recovery behaviors as adaptable robotic skills, leveraging the Behavior Trees and Motion Generators~(BTMG) framework for policy representation. This approach distinguishes itself by employing reinforcement learning~(RL) to dynamically refine recovery behavior parameters, enabling a tailored response to a wide array of failure scenarios with minimal human intervention. We assess our methodology through a series of progressively challenging scenarios within a peg-in-a-hole task, demonstrating the approach's effectiveness in enhancing operational efficiency and task success rates in collaborative robotics settings. We validate our approach using a dual-arm KUKA robot.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Learning Model Predictive Control Parameters via Bayesian Optimization  for Battery Fast Charging</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06125">https://arxiv.org/abs/2404.06125</a></p>
  <p><b>作者</b>：Sebastian Hirt,  Andreas Höhl,  Joachim Schaeffer,  Johannes Pohlodek,  Richard D. Braatz,  Rolf Findeisen</p>
  <p><b>备注</b>：6 pages, 5 figures, accepted for ADCHEM 2024</p>
  <p><b>关键词</b>：presents significant challenges, presents significant, significant challenges, model predictive control, MPC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tuning parameters in model predictive control (MPC) presents significant challenges, particularly when there is a notable discrepancy between the controller's predictions and the actual behavior of the closed-loop plant. This mismatch may stem from factors like substantial model-plant differences, limited prediction horizons that do not cover the entire time of interest, or unforeseen system disturbances. Such mismatches can jeopardize both performance and safety, including constraint satisfaction. Traditional methods address this issue by modifying the finite horizon cost function to better reflect the overall operational cost, learning parts of the prediction model from data, or implementing robust MPC strategies, which might be either computationally intensive or overly cautious. As an alternative, directly optimizing or learning the controller parameters to enhance closed-loop performance has been proposed. We apply Bayesian optimization for efficient learning of unknown model parameters and parameterized constraint backoff terms, aiming to improve closed-loop performance of battery fast charging. This approach establishes a hierarchical control framework where Bayesian optimization directly fine-tunes closed-loop behavior towards a global and long-term objective, while MPC handles lower-level, short-term control tasks. For lithium-ion battery fast charging, we show that the learning approach not only ensures safe operation but also maximizes closed-loop performance. This includes maintaining the battery's operation below its maximum terminal voltage and reducing charging times, all achieved using a standard nominal MPC model with a short horizon and notable initial model-plant mismatch.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Unifying Low Dimensional Observations in Deep Learning Through the Deep  Linear Unconstrained Feature Model</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06106">https://arxiv.org/abs/2404.06106</a></p>
  <p><b>作者</b>：Connall Garrod,  Jonathan P. Keating</p>
  <p><b>备注</b>：35 pages, 14 figures</p>
  <p><b>关键词</b>：achieved high performance, Modern deep neural, Deep Neural Collapse, Neural Collapse, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern deep neural networks have achieved high performance across various tasks. Recently, researchers have noted occurrences of low-dimensional structure in the weights, Hessian's, gradients, and feature vectors of these networks, spanning different datasets and architectures when trained to convergence. In this analysis, we theoretically demonstrate these observations arising, and show how they can be unified within a generalized unconstrained feature model that can be considered analytically. Specifically, we consider a previously described structure called Neural Collapse, and its multi-layer counterpart, Deep Neural Collapse, which emerges when the network approaches global optima. This phenomenon explains the other observed low-dimensional behaviours on a layer-wise level, such as the bulk and outlier structure seen in Hessian spectra, and the alignment of gradient descent with the outlier eigenspace of the Hessian. Empirical results in both the deep linear unconstrained feature model and its non-linear equivalent support these predicted observations.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Fair Graph Neural Network with Supervised Contrastive Regularization</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06090">https://arxiv.org/abs/2404.06090</a></p>
  <p><b>作者</b>：Mahdi Tavassoli Kejani (UT3),  Fadi Dornaika,  Jean-Michel Loubes (IMT)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made significant advancements, graph neural network, Neural Network Framework, Graph Neural, link prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, Graph Neural Networks (GNNs) have made significant advancements, particularly in tasks such as node classification, link prediction, and graph representation. However, challenges arise from biases that can be hidden not only in the node attributes but also in the connections between entities. Therefore, ensuring fairness in graph neural network learning has become a critical problem. To address this issue, we propose a novel model for training fairness-aware GNN, which enhances the Counterfactual Augmented Fair Graph Neural Network Framework (CAF). Our approach integrates Supervised Contrastive Loss and Environmental Loss to enhance both accuracy and fairness. Experimental validation on three real datasets demonstrates the superiority of our proposed model over CAF and several other existing graph-based learning methods.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：All in One: An Empirical Study of GPT for Few-Shot Aspect-Based  Sentiment Anlaysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06063">https://arxiv.org/abs/2404.06063</a></p>
  <p><b>作者</b>：Baoxing Jiang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：natural language processing, Aspect-Based Sentiment Analysis, highly challenging task, Sentiment Analysis, Generative Pre-trained Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aspect-Based Sentiment Analysis (ABSA) is an indispensable and highly challenging task in natural language processing. Current efforts have focused on specific sub-tasks, making it difficult to comprehensively cover all sub-tasks within the ABSA domain. With the development of Generative Pre-trained Transformers (GPTs), there came inspiration for a one-stop solution to sentiment analysis. In this study, we used GPTs for all sub-tasks of few-shot ABSA while defining a general learning paradigm for this application. We propose the All in One (AiO) model, a simple yet effective two-stage model for all ABSA sub-tasks. In the first stage, a specific backbone network learns the semantic information of the review and generates heuristically enhanced candidates. In the second stage, AiO leverages GPT contextual learning capabilities to generate predictions. The study conducted comprehensive comparative and ablation experiments on five benchmark datasets, and the results show that AiO can effectively handle all ABSA sub-tasks, even with few-shot data.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Feel-Good Thompson Sampling for Contextual Dueling Bandits</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06013">https://arxiv.org/abs/2404.06013</a></p>
  <p><b>作者</b>：Xuheng Li,  Heyang Zhao,  Quanquan Gu</p>
  <p><b>备注</b>：30 pages, 6 figures</p>
  <p><b>关键词</b>：receives feedback indicating, extends classic dueling, Contextual dueling bandits, incorporating contextual information, dueling bandits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contextual dueling bandits, where a learner compares two options based on context and receives feedback indicating which was preferred, extends classic dueling bandits by incorporating contextual information for decision-making and preference learning. Several algorithms based on the upper confidence bound (UCB) have been proposed for linear contextual dueling bandits. However, no algorithm based on posterior sampling has been developed in this setting, despite the empirical success observed in traditional contextual bandits. In this paper, we propose a Thompson sampling algorithm, named FGTS.CDB, for linear contextual dueling bandits. At the core of our algorithm is a new Feel-Good exploration term specifically tailored for dueling bandits. This term leverages the independence of the two selected arms, thereby avoiding a cross term in the analysis. We show that our algorithm achieves nearly minimax-optimal regret, i.e., $\tilde{\mathcal{O}}(d\sqrt T)$, where $d$ is the model dimension and $T$ is the time horizon. Finally, we evaluate our algorithm on synthetic data and observe that FGTS.CDB outperforms existing algorithms by a large margin.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Collaborative Edge AI Inference over Cloud-RAN</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06007">https://arxiv.org/abs/2404.06007</a></p>
  <p><b>作者</b>：Pengfei Zhang,  Dingzhu Wen,  Guangxu Zhu,  Qimei Chen,  Kaifeng Han,  Yuanming Shi</p>
  <p><b>备注</b>：This paper is accepted by IEEE Transactions on Communications on 08-Apr-2024</p>
  <p><b>关键词</b>：based collaborative edge, radio access network, cloud radio access, local feature vectors, access network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a cloud radio access network (Cloud-RAN) based collaborative edge AI inference architecture is proposed. Specifically, geographically distributed devices capture real-time noise-corrupted sensory data samples and extract the noisy local feature vectors, which are then aggregated at each remote radio head (RRH) to suppress sensing noise. To realize efficient uplink feature aggregation, we allow each RRH receives local feature vectors from all devices over the same resource blocks simultaneously by leveraging an over-the-air computation (AirComp) technique. Thereafter, these aggregated feature vectors are quantized and transmitted to a central processor (CP) for further aggregation and downstream inference tasks. Our aim in this work is to maximize the inference accuracy via a surrogate accuracy metric called discriminant gain, which measures the discernibility of different classes in the feature space. The key challenges lie on simultaneously suppressing the coupled sensing noise, AirComp distortion caused by hostile wireless channels, and the quantization error resulting from the limited capacity of fronthaul links. To address these challenges, this work proposes a joint transmit precoding, receive beamforming, and quantization error control scheme to enhance the inference accuracy. Extensive numerical experiments demonstrate the effectiveness and superiority of our proposed optimization algorithm compared to various baselines.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM  Experts</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05993">https://arxiv.org/abs/2404.05993</a></p>
  <p><b>作者</b>：Shaona Ghosh,  Prasoon Varshney,  Erick Galinkin,  Christopher Parisien</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, content safety, safety</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As Large Language Models (LLMs) and generative AI become more widespread, the content safety risks associated with their use also increase. We find a notable deficiency in high-quality content safety datasets and benchmarks that comprehensively cover a wide range of critical safety areas. To address this, we define a broad content safety risk taxonomy, comprising 13 critical risk and 9 sparse risk categories. Additionally, we curate AEGISSAFETYDATASET, a new dataset of approximately 26, 000 human-LLM interaction instances, complete with human annotations adhering to the taxonomy. We plan to release this dataset to the community to further research and to help benchmark LLM models for safety. To demonstrate the effectiveness of the dataset, we instruction-tune multiple LLM-based safety models. We show that our models (named AEGISSAFETYEXPERTS), not only surpass or perform competitively with the state-of-the-art LLM-based safety models and general purpose LLMs, but also exhibit robustness across multiple jail-break attack categories. We also show how using AEGISSAFETYDATASET during the LLM alignment phase does not negatively impact the performance of the aligned models on MT Bench scores. Furthermore, we propose AEGIS, a novel application of a no-regret online adaptation framework with strong theoretical guarantees, to perform content moderation with an ensemble of LLM content safety experts in deployment</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Boosting Digital Safeguards: Blending Cryptography and Steganography</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05985">https://arxiv.org/abs/2404.05985</a></p>
  <p><b>作者</b>：Anamitra Maiti,  Subham Laha,  Rishav Upadhaya,  Soumyajit Biswas,  Vikas Choudhary,  Biplab Kar,  Nikhil Kumar,  Jaydip Sen</p>
  <p><b>备注</b>：This report pertains to the Capstone Project done by Group 3 of the Fall batch of 2023 students at Praxis Tech School, Kolkata, India. The reports consists of 36 pages and it includes 11 figures and 5 tables</p>
  <p><b>关键词</b>：today digital age, sophisticated data security, data security measures, prevent unauthorized access, creating a critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In today's digital age, the internet is essential for communication and the sharing of information, creating a critical need for sophisticated data security measures to prevent unauthorized access and exploitation. Cryptography encrypts messages into a cipher text that is incomprehensible to unauthorized readers, thus safeguarding data during its transmission. Steganography, on the other hand, originates from the Greek term for "covered writing" and involves the art of hiding data within another medium, thereby facilitating covert communication by making the message invisible. This proposed approach takes advantage of the latest advancements in Artificial Intelligence (AI) and Deep Learning (DL), especially through the application of Generative Adversarial Networks (GANs), to improve upon traditional steganographic methods. By embedding encrypted data within another medium, our method ensures that the communication remains hidden from prying eyes. The application of GANs enables a smart, secure system that utilizes the inherent sensitivity of neural networks to slight alterations in data, enhancing the protection against detection. By merging the encryption techniques of cryptography with the hiding capabilities of steganography, and augmenting these with the strengths of AI, we introduce a comprehensive security system designed to maintain both the privacy and integrity of information. This system is crafted not just to prevent unauthorized access or modification of data, but also to keep the existence of the data hidden. This fusion of technologies tackles the core challenges of data security in the current era of open digital communication, presenting an advanced solution with the potential to transform the landscape of information security.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：A Lightweight Measure of Classification Difficulty from Application  Dataset Characteristics</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05981">https://arxiv.org/abs/2404.05981</a></p>
  <p><b>作者</b>：Bryan Bo Cao,  Abhinav Sharma,  Lawrence O'Gorman,  Michael Coss,  Shubham Jain</p>
  <p><b>备注</b>：13 pages, 3 figures</p>
  <p><b>关键词</b>：neural network models, accuracy and computation, computation benchmarks, benchmarks being widely, choose among neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite accuracy and computation benchmarks being widely available to help choose among neural network models, these are usually trained on datasets with many classes, and do not give a precise idea of performance for applications of few (< 10) classes. The conventional procedure to predict performance is to train and test repeatedly on the different models and dataset variations of interest. However, this is computationally expensive. We propose an efficient classification difficulty measure that is calculated from the number of classes and intra- and inter-class similarity metrics of the dataset. After a single stage of training and testing per model family, relative performance for different datasets and models of the same family can be predicted by comparing difficulty measures - without further training and testing. We show how this measure can help a practitioner select a computationally efficient model for a small dataset 6 to 29x faster than through repeated training and testing. We give an example of use of the measure for an industrial application in which options are identified to select a model 42% smaller than the baseline YOLOv5-nano model, and if class merging from 3 to 2 classes meets requirements, 85% smaller.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Tackling Structural Hallucination in Image Translation with Local  Diffusion</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05980">https://arxiv.org/abs/2404.05980</a></p>
  <p><b>作者</b>：Seunghoi Kim,  Chen Jin,  Tom Diethe,  Matteo Figini,  Henry F. J. Tregidgo,  Asher Mullokandov,  Philip Teare,  Daniel C. Alexander</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced conditioned image, OOD, Recent developments, struggle with reconstructing, local OOD regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent developments in diffusion models have advanced conditioned image generation, yet they struggle with reconstructing out-of-distribution (OOD) images, such as unseen tumors in medical images, causing ``image hallucination'' and risking misdiagnosis. We hypothesize such hallucinations result from local OOD regions in the conditional images. We verify that partitioning the OOD region and conducting separate image generations alleviates hallucinations in several applications. From this, we propose a training-free diffusion framework that reduces hallucination with multiple Local Diffusion processes. Our approach involves OOD estimation followed by two modules: a ``branching'' module generates locally both within and outside OOD regions, and a ``fusion'' module integrates these predictions into one. Our evaluation shows our method mitigates hallucination over baseline models quantitatively and qualitatively, reducing misdiagnosis by 40% and 25% in the real-world medical and natural image datasets, respectively. It also demonstrates compatibility with various pre-trained diffusion models.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：A Cyber Manufacturing IoT System for Adaptive Machine Learning Model  Deployment by Interactive Causality Enabled Self-Labeling</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05976">https://arxiv.org/abs/2404.05976</a></p>
  <p><b>作者</b>：Yutian Ren,  Yuqi He,  Xuyin Zhang,  Aaron Yen,  G. P. Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine Learning, demonstrated to improve, improve productivity, Internet of Things, Industrial Internet</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning (ML) has been demonstrated to improve productivity in many manufacturing applications. To host these ML applications, several software and Industrial Internet of Things (IIoT) systems have been proposed for manufacturing applications to deploy ML applications and provide real-time intelligence. Recently, an interactive causality enabled self-labeling method has been proposed to advance adaptive ML applications in cyber-physical systems, especially manufacturing, by automatically adapting and personalizing ML models after deployment to counter data distribution shifts. The unique features of the self-labeling method require a novel software system to support dynamism at various levels.
This paper proposes the AdaptIoT system, comprised of an end-to-end data streaming pipeline, ML service integration, and an automated self-labeling service. The self-labeling service consists of causal knowledge bases and automated full-cycle self-labeling workflows to adapt multiple ML models simultaneously. AdaptIoT employs a containerized microservice architecture to deliver a scalable and portable solution for small and medium-sized manufacturers. A field demonstration of a self-labeling adaptive ML application is conducted with a makerspace and shows reliable performance.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Does Transformer Interpretability Transfer to RNNs?</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05971">https://arxiv.org/abs/2404.05971</a></p>
  <p><b>作者</b>：Gonçalo Paulo,  Thomas Marshall,  Nora Belrose</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Mamba and RWKV, neural network architectures, recurrent neural network, language modeling perplexity, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in recurrent neural network architectures, such as Mamba and RWKV, have enabled RNNs to match or exceed the performance of equal-size transformers in terms of language modeling perplexity and downstream evaluations, suggesting that future systems may be built on completely new architectures. In this paper, we examine if selected interpretability methods originally designed for transformer language models will transfer to these up-and-coming recurrent architectures. Specifically, we focus on steering model outputs via contrastive activation addition, on eliciting latent predictions via the tuned lens, and eliciting latent knowledge from models fine-tuned to produce false outputs under certain conditions. Our results show that most of these techniques are effective when applied to RNNs, and we show that it is possible to improve some of them by taking advantage of RNNs' compressed state.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：JSTR: Judgment Improves Scene Text Recognition</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05967">https://arxiv.org/abs/2404.05967</a></p>
  <p><b>作者</b>：Masato Fujitake</p>
  <p><b>备注</b>：IntelliSys 2024</p>
  <p><b>关键词</b>：text recognition tasks, scene text recognition, text recognition, text recognition accuracy, tasks by judging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a method for enhancing the accuracy of scene text recognition tasks by judging whether the image and text match each other. While previous studies focused on generating the recognition results from input images, our approach also considers the model's misrecognition results to understand its error tendencies, thus improving the text recognition pipeline. This method boosts text recognition accuracy by providing explicit feedback on the data that the model is likely to misrecognize by predicting correct or incorrect between the image and text. The experimental results on publicly available datasets demonstrate that our proposed method outperforms the baseline and state-of-the-art methods in scene text recognition.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Efficient Multi-Task Reinforcement Learning via Task-Specific Action  Correction</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05950">https://arxiv.org/abs/2404.05950</a></p>
  <p><b>作者</b>：Jinyuan Feng,  Min Chen,  Zhiqiang Pu,  Tenghai Qiu,  Jianqiang Yi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-task reinforcement learning, multiple tasks concurrently, perform multiple tasks, Multi-task reinforcement, potential for enhancing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-task reinforcement learning (MTRL) demonstrate potential for enhancing the generalization of a robot, enabling it to perform multiple tasks concurrently. However, the performance of MTRL may still be susceptible to conflicts between tasks and negative interference. To facilitate efficient MTRL, we propose Task-Specific Action Correction (TSAC), a general and complementary approach designed for simultaneous learning of multiple tasks. TSAC decomposes policy learning into two separate policies: a shared policy (SP) and an action correction policy (ACP). To alleviate conflicts resulting from excessive focus on specific tasks' details in SP, ACP incorporates goal-oriented sparse rewards, enabling an agent to adopt a long-term perspective and achieve generalization across tasks. Additional rewards transform the original problem into a multi-objective MTRL problem. Furthermore, to convert the multi-objective MTRL into a single-objective formulation, TSAC assigns a virtual expected budget to the sparse rewards and employs Lagrangian method to transform a constrained single-objective optimization into an unconstrained one. Experimental evaluations conducted on Meta-World's MT10 and MT50 benchmarks demonstrate that TSAC outperforms existing state-of-the-art methods, achieving significant improvements in both sample efficiency and effective action execution.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Neural networks can be FLOP-efficient integrators of 1D oscillatory  integrands</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05938">https://arxiv.org/abs/2404.05938</a></p>
  <p><b>作者</b>：Anshuman Sinha,  Spencer H. Bryngelson</p>
  <p><b>备注</b>：11 pages, 7 figures, 3 tables. Published in TMLR 03/2024. Code at this https URL</p>
  <p><b>关键词</b>：one-dimensional oscillatory integrands, oscillatory, oscillatory integrands, neural network, one-dimensional oscillatory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We demonstrate that neural networks can be FLOP-efficient integrators of one-dimensional oscillatory integrands. We train a feed-forward neural network to compute integrals of highly oscillatory 1D functions. The training set is a parametric combination of functions with varying characters and oscillatory behavior degrees. Numerical examples show that these networks are FLOP-efficient for sufficiently oscillatory integrands with an average FLOP gain of 1000 FLOPs. The network calculates oscillatory integrals better than traditional quadrature methods under the same computational budget or number of floating point operations. We find that feed-forward networks of 5 hidden layers are satisfactory for a relative accuracy of 0.001. The computational burden of inference of the neural network is relatively small, even compared to inner-product pattern quadrature rules. We postulate that our result follows from learning latent patterns in the oscillatory integrands that are otherwise opaque to traditional numerical integrators.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：AdaGossip: Adaptive Consensus Step-size for Decentralized Deep Learning  with Communication Compression</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05919">https://arxiv.org/abs/2404.05919</a></p>
  <p><b>作者</b>：Sai Aparna Aketi,  Abolfazl Hashemi,  Kaushik Roy</p>
  <p><b>备注</b>：11 pages, 3 figures, 8 tables. arXiv admin note: text overlap with arXiv:2305.04792, arXiv:2310.15890</p>
  <p><b>关键词</b>：large distributed datasets, supporting on-device learning, central server, crucial in supporting, supporting on-device</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized learning is crucial in supporting on-device learning over large distributed datasets, eliminating the need for a central server. However, the communication overhead remains a major bottleneck for the practical realization of such decentralized setups. To tackle this issue, several algorithms for decentralized training with compressed communication have been proposed in the literature. Most of these algorithms introduce an additional hyper-parameter referred to as consensus step-size which is tuned based on the compression ratio at the beginning of the training. In this work, we propose AdaGossip, a novel technique that adaptively adjusts the consensus step-size based on the compressed model differences between neighboring agents. We demonstrate the effectiveness of the proposed method through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance ($0-2\%$ improvement in test accuracy) compared to the current state-of-the-art method for decentralized learning with communication compression.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Deep Reinforcement Learning for Personalized Diagnostic Decision  Pathways Using Electronic Health Records: A Comparative Study on Anemia and  Systemic Lupus Erythematosus</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05913">https://arxiv.org/abs/2404.05913</a></p>
  <p><b>作者</b>：Lillian Muyama,  Antoine Neuraz,  Adrien Coulet</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2305.06295</p>
  <p><b>关键词</b>：colleges of experts, typically reached, series of steps, steps recommended, authored by colleges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background: Clinical diagnosis is typically reached by following a series of steps recommended by guidelines authored by colleges of experts. Accordingly, guidelines play a crucial role in rationalizing clinical decisions but suffer from limitations as they are built to cover the majority of the population and fail at covering patients with uncommon conditions. Moreover, their updates are long and expensive, making them unsuitable for emerging diseases and practices.
Methods: Inspired by guidelines, we formulate the task of diagnosis as a sequential decision-making problem and study the use of Deep Reinforcement Learning (DRL) algorithms to learn the optimal sequence of actions to perform in order to obtain a correct diagnosis from Electronic Health Records (EHRs). We apply DRL on synthetic, but realistic EHRs and develop two clinical use cases: Anemia diagnosis, where the decision pathways follow the schema of a decision tree; and Systemic Lupus Erythematosus (SLE) diagnosis, which follows a weighted criteria score. We particularly evaluate the robustness of our approaches to noisy and missing data since these frequently occur in EHRs.
Results: In both use cases, and in the presence of imperfect data, our best DRL algorithms exhibit competitive performance when compared to the traditional classifiers, with the added advantage that they enable the progressive generation of a pathway to the suggested diagnosis which can both guide and explain the decision-making process.
Conclusion: DRL offers the opportunity to learn personalized decision pathways to diagnosis. We illustrate with our two use cases their advantages: they generate step-by-step pathways that are self-explanatory; and their correctness is competitive when compared to state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Interpretability in Symbolic Regression: a benchmark of Explanatory  Methods using the Feynman data set</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05908">https://arxiv.org/abs/2404.05908</a></p>
  <p><b>作者</b>：Guilherme Seidyo Imai Aldeia,  Fabricio Olivetti de Franca (Federal University of ABC)</p>
  <p><b>备注</b>：47 pages, 10 figures. This is a post peer-review, pre-copyedit version of an article published in Genetic Programming and Evolvable Machines Volume 23, pages 309-349, (2022). The final version is available on this https URL</p>
  <p><b>关键词</b>：machine learning models, learning models plays, models, symbolic regression models, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In some situations, the interpretability of the machine learning models plays a role as important as the model accuracy. Interpretability comes from the need to trust the prediction model, verify some of its properties, or even enforce them to improve fairness. Many model-agnostic explanatory methods exists to provide explanations for black-box models. In the regression task, the practitioner can use white-boxes or gray-boxes models to achieve more interpretable results, which is the case of symbolic regression. When using an explanatory method, and since interpretability lacks a rigorous definition, there is a need to evaluate and compare the quality and different explainers. This paper proposes a benchmark scheme to evaluate explanatory methods to explain regression models, mainly symbolic regression models. Experiments were performed using 100 physics equations with different interpretable and non-interpretable regression methods and popular explanation methods, evaluating the performance of the explainers performance with several explanation measures. In addition, we further analyzed four benchmarks from the GP community. The results have shown that Symbolic Regression models can be an interesting alternative to white-box and black-box models that is capable of returning accurate models with appropriate explanations. Regarding the explainers, we observed that Partial Effects and SHAP were the most robust explanation models, with Integrated Gradients being unstable only with tree-based models. This benchmark is publicly available for further experiments.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Natural Learning</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05903">https://arxiv.org/abs/2404.05903</a></p>
  <p><b>作者</b>：Hadi Fanaee-T</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：introduce Natural Learning, Natural Learning, introduce Natural, extreme level, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Natural Learning (NL), a novel algorithm that elevates the explainability and interpretability of machine learning to an extreme level. NL simplifies decisions into intuitive rules, like "We rejected your loan because your income, employment status, and age collectively resemble a rejected prototype more than an accepted prototype." When applied to real-life datasets, NL produces impressive results. For example, in a colon cancer dataset with 1545 patients and 10935 genes, NL achieves 98.1% accuracy, comparable to DNNs and RF, by analyzing just 3 genes of test samples against 2 discovered prototypes. Similarly, in the UCI's WDBC dataset, NL achieves 98.3% accuracy using only 7 features and 2 prototypes. Even on the MNIST dataset (0 vs. 1), NL achieves 99.5% accuracy with only 3 pixels from 2 prototype images. NL is inspired by prototype theory, an old concept in cognitive psychology suggesting that people learn single sparse prototypes to categorize objects. Leveraging this relaxed assumption, we redesign Support Vector Machines (SVM), replacing its mathematical formulation with a fully nearest-neighbor-based solution, and to address the curse of dimensionality, we utilize locality-sensitive hashing. Following theory's generalizability principle, we propose a recursive method to prune non-core features. As a result, NL efficiently discovers the sparsest prototypes in O(n^2pL) with high parallelization capacity in terms of n. Evaluation of NL with 17 benchmark datasets shows its significant outperformance compared to decision trees and logistic regression, two methods widely favored in healthcare for their interpretability. Moreover, NL achieves performance comparable to finetuned black-box models such as deep neural networks and random forests in 40% of cases, with only a 1-2% lower average accuracy. The code is available via this http URL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Inexact Simplification of Symbolic Regression Expressions with  Locality-sensitive Hashing</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05898">https://arxiv.org/abs/2404.05898</a></p>
  <p><b>作者</b>：Guilherme Seidyo Imai Aldeia (1),  Fabricio Olivetti de Franca (1),  William G. La Cava (2 and 3) ((1) Federal University of ABC, (2) Boston Children's Hospital, (3) Harvard Medical School)</p>
  <p><b>备注</b>：9 pages, 10 figures, accepted to GECCO-24</p>
  <p><b>关键词</b>：Symbolic regression, searches for parametric, fit a dataset, prioritizing simplicity, simplicity and interpretability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Symbolic regression (SR) searches for parametric models that accurately fit a dataset, prioritizing simplicity and interpretability. Despite this secondary objective, studies point out that the models are often overly complex due to redundant operations, introns, and bloat that arise during the iterative process, and can hinder the search with repeated exploration of bloated segments. Applying a fast heuristic algebraic simplification may not fully simplify the expression and exact methods can be infeasible depending on size or complexity of the expressions. We propose a novel agnostic simplification and bloat control for SR employing an efficient memoization with locality-sensitive hashing (LHS). The idea is that expressions and their sub-expressions traversed during the iterative simplification process are stored in a dictionary using LHS, enabling efficient retrieval of similar structures. We iterate through the expression, replacing subtrees with others of same hash if they result in a smaller expression. Empirical results shows that applying this simplification during evolution performs equal or better than without simplification in minimization of error, significantly reducing the number of nonlinear functions. This technique can learn simplification rules that work in general or for a specific problem, and improves convergence while reducing model complexity.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Learning Heuristics for Transit Network Design and Improvement with Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05894">https://arxiv.org/abs/2404.05894</a></p>
  <p><b>作者</b>：Andrew Holliday,  Ahmed El-Geneidy,  Gregory Dudek</p>
  <p><b>备注</b>：In preparation for submission to the journal "Transportation Research Part C"</p>
  <p><b>关键词</b>：face tightening budgets, agencies world-wide face, world-wide face tightening, Transit agencies world-wide, tightening budgets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transit agencies world-wide face tightening budgets. To maintain quality of service while cutting costs, efficient transit network design is essential. But planning a network of public transit routes is a challenging optimization problem. The most successful approaches to date use metaheuristic algorithms to search through the space of solutions by applying low-level heuristics that randomly alter routes in a network. The design of these low-level heuristics has a major impact on the quality of the result. In this paper we use deep reinforcement learning with graph neural nets to learn low-level heuristics for an evolutionary algorithm, instead of designing them manually. These learned heuristics improve the algorithm's results on benchmark synthetic cities with 70 nodes or more, and obtain state-of-the-art results when optimizing operating costs. They also improve upon a simulation of the real transit network in the city of Laval, Canada, by as much as 54% and 18% on two key metrics, and offer cost savings of up to 12% over the city's existing transit network.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Rapid and Precise Topological Comparison with Merge Tree Neural Networks</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05879">https://arxiv.org/abs/2404.05879</a></p>
  <p><b>作者</b>：Yu Qin,  Brittany Terese Fasy,  Carola Wenk,  Brian Summa</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：merge tree, scalar fields, current methods, computationally expensive, primarily due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Merge trees are a valuable tool in scientific visualization of scalar fields; however, current methods for merge tree comparisons are computationally expensive, primarily due to the exhaustive matching between tree nodes. To address this challenge, we introduce the merge tree neural networks (MTNN), a learned neural network model designed for merge tree comparison. The MTNN enables rapid and high-quality similarity computation. We first demonstrate how graph neural networks (GNNs), which emerged as an effective encoder for graphs, can be trained to produce embeddings of merge trees in vector spaces that enable efficient similarity comparison. Next, we formulate the novel MTNN model that further improves the similarity comparisons by integrating the tree and node embeddings with a new topological attention mechanism. We demonstrate the effectiveness of our model on real-world data in different domains and examine our model's generalizability across various datasets. Our experimental analysis demonstrates our approach's superiority in accuracy and efficiency. In particular, we speed up the prior state-of-the-art by more than 100x on the benchmark datasets while maintaining an error rate below 0.1%.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：CodecLM: Aligning Language Models with Tailored Synthetic Data</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05875">https://arxiv.org/abs/2404.05875</a></p>
  <p><b>作者</b>：Zifeng Wang,  Chun-Liang Li,  Vincent Perot,  Long T. Le,  Jin Miao,  Zizhao Zhang,  Chen-Yu Lee,  Tomas Pfister</p>
  <p><b>备注</b>：Accepted to Findings of NAACL 2024</p>
  <p><b>关键词</b>：large language models, users' actual goals, aligning large language, next-token prediction objective, specific task instructions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users' actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data. Recent works focus on generating diverse instructions and applying LLM to increase instruction complexity, often neglecting downstream use cases. It remains unclear how to tailor high-quality data to elicit better instruction-following abilities in different target instruction distributions and LLMs. To this end, we introduce CodecLM, a general framework for adaptively generating high-quality synthetic data for LLM alignment with different downstream instruction distributions and LLMs. Drawing on the Encode-Decode principles, we use LLMs as codecs to guide the data generation process. We first encode seed instructions into metadata, which are concise keywords generated on-the-fly to capture the target instruction distribution, and then decode metadata to create tailored instructions. We also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain instruction following benchmarks validate the effectiveness of CodecLM over the current state-of-the-arts.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：TabConv: Low-Computation CNN Inference via Table Lookups</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05872">https://arxiv.org/abs/2404.05872</a></p>
  <p><b>作者</b>：Neelesh Gupta,  Narayanan Kannan,  Pengmiao Zhang,  Viktor Prasanna</p>
  <p><b>备注</b>：8 pages, Accepted at CF '24</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, demonstrated remarkable ability, Convolutional Neural, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) have demonstrated remarkable ability throughout the field of computer vision. However, CNN inference requires a large number of arithmetic operations, making them expensive to deploy in hardware. Current approaches alleviate this issue by developing hardware-supported, algorithmic processes to simplify spatial convolution functions. However, these methods still heavily rely on matrix multiplication, leading to significant computational overhead. To bridge the gap between hardware, algorithmic acceleration, and approximate matrix multiplication, we propose TabConv, a novel, table-based approximation for convolution to significantly reduce arithmetic operations during inference. Additionally, we introduce a priority masking technique based on cosine similarity to select layers for table-based approximation, thereby maintaining the model performance. We evaluate our approach on popular CNNs: ResNet-18, ResNet-34, and NetworkInNetwork (NIN). TabConv preserves over 93% of the original model's performance while reducing arithmetic operations by 36.5%, 25.8%, and 99.4% for ResNet-18 on CIFAR-10, CIFAR-100, and MNIST, respectively, 35.6% and 99.3% for ResNet-34 on CIFAR-10 and MNIST, and 98.9% for NIN on MNIST, achieving low-computation inference.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Negative Preference Optimization: From Catastrophic Collapse to  Effective Unlearning</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05868">https://arxiv.org/abs/2404.05868</a></p>
  <p><b>作者</b>：Ruiqi Zhang,  Licong Lin,  Yu Bai,  Song Mei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, model utilities, LLM unlearning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) often memorize sensitive, private, or copyrighted data during pre-training. LLM unlearning aims to eliminate the influence of undesirable data from the pre-trained model while preserving the model's utilities on other tasks. Several practical methods have recently been proposed for LLM unlearning, mostly based on gradient ascent (GA) on the loss of undesirable data. However, on certain unlearning tasks, these methods either fail to effectively unlearn the target data or suffer from catastrophic collapse -- a drastic degradation of the model's utilities.
In this paper, we propose Negative Preference Optimization (NPO), a simple alignment-inspired method that could efficiently and effectively unlearn a target dataset. We theoretically show that the progression toward catastrophic collapse by minimizing the NPO loss is exponentially slower than GA. Through experiments on synthetic data and the benchmark TOFU dataset, we demonstrate that NPO-based methods achieve a better balance between unlearning the undesirable data and maintaining the model's utilities. We also observe that NPO-based methods generate more sensible outputs than GA-based methods, whose outputs are often gibberish. Remarkably, on TOFU, NPO-based methods are the first to achieve reasonable unlearning results in forgetting 50% (or more) of the training data, whereas existing methods already struggle with forgetting 10% of training data.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：A Neuromorphic Approach to Obstacle Avoidance in Robot Manipulation</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05858">https://arxiv.org/abs/2404.05858</a></p>
  <p><b>作者</b>：Ahmed Faisal Abdelrahman,  Matias Valdenegro-Toro,  Maren Bennewitz,  Paul G. Plöger</p>
  <p><b>备注</b>：35 pages, accepted at IJRR, authors' version</p>
  <p><b>关键词</b>：computing mimics computational, mimics computational principles, Neuromorphic computing mimics, spiking neural networks, computing mimics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neuromorphic computing mimics computational principles of the brain in $\textit{silico}$ and motivates research into event-based vision and spiking neural networks (SNNs). Event cameras (ECs) exclusively capture local intensity changes and offer superior power consumption, response latencies, and dynamic ranges. SNNs replicate biological neuronal dynamics and have demonstrated potential as alternatives to conventional artificial neural networks (ANNs), such as in reducing energy expenditure and inference time in visual classification. Nevertheless, these novel paradigms remain scarcely explored outside the domain of aerial robots.
To investigate the utility of brain-inspired sensing and data processing, we developed a neuromorphic approach to obstacle avoidance on a camera-equipped manipulator. Our approach adapts high-level trajectory plans with reactive maneuvers by processing emulated event data in a convolutional SNN, decoding neural activations into avoidance motions, and adjusting plans using a dynamic motion primitive. We conducted experiments with a Kinova Gen3 arm performing simple reaching tasks that involve obstacles in sets of distinct task scenarios and in comparison to a non-adaptive baseline.
Our neuromorphic approach facilitated reliable avoidance of imminent collisions in simulated and real-world experiments, where the baseline consistently failed. Trajectory adaptations had low impacts on safety and predictability criteria. Among the notable SNN properties were the correlation of computations with the magnitude of perceived motions and a robustness to different event emulation methods. Tests with a DAVIS346 EC showed similar performance, validating our experimental event emulation. Our results motivate incorporating SNN learning, utilizing neuromorphic processors, and further exploring the potential of neuromorphic methods.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Localizing Moments of Actions in Untrimmed Videos of Infants with Autism  Spectrum Disorder</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05849">https://arxiv.org/abs/2404.05849</a></p>
  <p><b>作者</b>：Halil Ismail Helvaci,  Sen-ching Samson Cheung,  Chen-Nee Chuah,  Sally Ozonoff</p>
  <p><b>备注</b>：7 pages, 2 figures, 3 tables</p>
  <p><b>关键词</b>：Autism Spectrum Disorder, Spectrum Disorder, Autism Spectrum, presents significant challenges, presents significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autism Spectrum Disorder (ASD) presents significant challenges in early diagnosis and intervention, impacting children and their families. With prevalence rates rising, there is a critical need for accessible and efficient screening tools. Leveraging machine learning (ML) techniques, in particular Temporal Action Localization (TAL), holds promise for automating ASD screening. This paper introduces a self-attention based TAL model designed to identify ASD-related behaviors in infant videos. Unlike existing methods, our approach simplifies complex modeling and emphasizes efficiency, which is essential for practical deployment in real-world scenarios. Importantly, this work underscores the importance of developing computer vision methods capable of operating in naturilistic environments with little equipment control, addressing key challenges in ASD screening. This study is the first to conduct end-to-end temporal action localization in untrimmed videos of infants with ASD, offering promising avenues for early intervention and support. We report baseline results of behavior detection using our TAL model. We achieve 70% accuracy for look face, 79% accuracy for look object, 72% for smile and 65% for vocalization.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Softmax Attention with Constant Cost per Token</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05843">https://arxiv.org/abs/2404.05843</a></p>
  <p><b>作者</b>：Franz A. Heinsen</p>
  <p><b>备注</b>：Source code and instructions for replicating our results are online at this https URL</p>
  <p><b>关键词</b>：quantifying pairwise query-key, pairwise query-key similarity, attention mechanism applied, scaled dot-products, applied by Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a simple modification to the conventional attention mechanism applied by Transformers: Instead of quantifying pairwise query-key similarity with scaled dot-products, we quantify it with the logarithms of scaled dot-products of exponentials. Attention becomes expressible as a composition of log-sums of exponentials that is linearizable, with a latent space of constant size, enabling sequential application with constant time and space complexity per token. We implement our modification, verify that it works in practice, and conclude that it is a promising alternative to conventional attention.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions  with Expertise-Informed Tasks</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05840">https://arxiv.org/abs/2404.05840</a></p>
  <p><b>作者</b>：Andre R Kuroswiski,  Annie S Wu,  Angelo Passaro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enhancing Multi-Agent Reinforcement, Multi-Agent Reinforcement Learning, Multi-Agent Reinforcement, Reinforcement Learning, introduce an alternative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce an alternative approach to enhancing Multi-Agent Reinforcement Learning (MARL) through the integration of domain knowledge and attention-based policy mechanisms. Our methodology focuses on the incorporation of domain-specific expertise into the learning process, which simplifies the development of collaborative behaviors. This approach aims to reduce the complexity and learning overhead typically associated with MARL by enabling agents to concentrate on essential aspects of complex tasks, thus optimizing the learning curve. The utilization of attention mechanisms plays a key role in our model. It allows for the effective processing of dynamic context data and nuanced agent interactions, leading to more refined decision-making. Applied in standard MARL scenarios, such as the Stanford Intelligent Systems Laboratory (SISL) Pursuit and Multi-Particle Environments (MPE) Simple Spread, our method has been shown to improve both learning efficiency and the effectiveness of collaborative behaviors. The results indicate that our attention-based approach can be a viable approach for improving the efficiency of MARL training process, integrating domain-specific knowledge at the action level.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Parameter-Adaptive Approximate MPC: Tuning Neural-Network Controllers  without Re-Training</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05835">https://arxiv.org/abs/2404.05835</a></p>
  <p><b>作者</b>：Henrik Hose,  Alexander Gräfe,  Sebastian Trimpe</p>
  <p><b>备注</b>：Accepted to L4DC 2024</p>
  <p><b>关键词</b>：Model Predictive Control, Predictive Control, high computation times, control nonlinear systems, Model Predictive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model Predictive Control (MPC) is a method to control nonlinear systems with guaranteed stability and constraint satisfaction but suffers from high computation times. Approximate MPC (AMPC) with neural networks (NNs) has emerged to address this limitation, enabling deployment on resource-constrained embedded systems. However, when tuning AMPCs for real-world systems, large datasets need to be regenerated and the NN needs to be retrained at every tuning step. This work introduces a novel, parameter-adaptive AMPC architecture capable of online tuning without recomputing large datasets and retraining. By incorporating local sensitivities of nonlinear programs, the proposed method not only mimics optimal MPC inputs but also adjusts to changes in physical parameters of the model using linear predictions while still guaranteeing stability. We showcase the effectiveness of parameter-adaptive AMPC by controlling the swing-ups of two different real cartpole systems with a severely resource-constrained microcontroller (MCU). We use the same NN across both system instances that have different parameters. This work not only represents the first experimental demonstration of AMPC for fast-moving systems on low-cost MCUs to the best of our knowledge, but also showcases generalization across system instances and variations through our parameter-adaptation method. Taken together, these contributions represent a marked step toward the practical application of AMPC in real-world systems.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：SambaLingo: Teaching Large Language Models New Languages</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05829">https://arxiv.org/abs/2404.05829</a></p>
  <p><b>作者</b>：Zoltan Csaki,  Bo Li,  Jonathan Li,  Qiantong Xu,  Pian Pawakapan,  Leon Zhang,  Yun Du,  Hengyu Zhao,  Changran Hu,  Urmish Thakker</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：widespread availability, remains a substantial, substantial gap, availability across diverse, capabilities and availability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the widespread availability of LLMs, there remains a substantial gap in their capabilities and availability across diverse languages. One approach to address these issues has been to take an existing pre-trained LLM and continue to train it on new languages. While prior works have experimented with language adaptation, many questions around best practices and methodology have not been covered. In this paper, we present a comprehensive investigation into the adaptation of LLMs to new languages. Our study covers the key components in this process, including vocabulary extension, direct preference optimization and the data scarcity problem for human alignment in low-resource languages. We scale these experiments across 9 languages and 2 parameter scales (7B and 70B). We compare our models against Llama 2, Aya-101, XGLM, BLOOM and existing language experts, outperforming all prior published baselines. Additionally, all evaluation code and checkpoints are made public to facilitate future research.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Label Propagation Training Schemes for Physics-Informed Neural Networks  and Gaussian Processes</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05817">https://arxiv.org/abs/2404.05817</a></p>
  <p><b>作者</b>：Ming Zhong,  Dehao Liu,  Raymundo Arroyave,  Ulisses Braga-Neto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training physics-informed machine, physics-informed machine learning, paper proposes, proposes a semi-supervised, semi-supervised methodology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a semi-supervised methodology for training physics-informed machine learning methods. This includes self-training of physics-informed neural networks and physics-informed Gaussian processes in isolation, and the integration of the two via co-training. We demonstrate via extensive numerical experiments how these methods can ameliorate the issue of propagating information forward in time, which is a common failure mode of physics-informed machine learning.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Self-Labeling in Multivariate Causality and Quantification for Adaptive  Machine Learning</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05809">https://arxiv.org/abs/2404.05809</a></p>
  <p><b>作者</b>：Yutian Ren,  Aaron Haohua Yen,  G. P. Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential concept drift, Adaptive machine learning, adapt to ever-changing, ever-changing environments, environments with potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive machine learning (ML) aims to allow ML models to adapt to ever-changing environments with potential concept drift after model deployment. Traditionally, adaptive ML requires a new dataset to be manually labeled to tailor deployed models to altered data distributions. Recently, an interactive causality based self-labeling method was proposed to autonomously associate causally related data streams for domain adaptation, showing promising results compared to traditional feature similarity-based semi-supervised learning. Several unanswered research questions remain, including self-labeling's compatibility with multivariate causality and the quantitative analysis of the auxiliary models used in the self-labeling. The auxiliary models, the interaction time model (ITM) and the effect state detector (ESD), are vital to the success of self-labeling. This paper further develops the self-labeling framework and its theoretical foundations to address these research questions. A framework for the application of self-labeling to multivariate causal graphs is proposed using four basic causal relationships, and the impact of non-ideal ITM and ESD performance is analyzed. A simulated experiment is conducted based on a multivariate causal graph, validating the proposed theory.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Dynamical stability and chaos in artificial neural network trajectories  along training</b></summary>
  <p><b>编号</b>：[331]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05782">https://arxiv.org/abs/2404.05782</a></p>
  <p><b>作者</b>：Kaloyan Danovski,  Miguel C. Soriano,  Lucas Lacasa</p>
  <p><b>备注</b>：29 pages, 18 figures</p>
  <p><b>关键词</b>：involves iteratively adapting, network involves iteratively, artificial neural network, neural network involves, involves iteratively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The process of training an artificial neural network involves iteratively adapting its parameters so as to minimize the error of the network's prediction, when confronted with a learning task. This iterative change can be naturally interpreted as a trajectory in network space -- a time series of networks -- and thus the training algorithm (e.g. gradient descent optimization of a suitable loss function) can be interpreted as a dynamical system in graph space. In order to illustrate this interpretation, here we study the dynamical properties of this process by analyzing through this lens the network trajectories of a shallow neural network, and its evolution through learning a simple classification task. We systematically consider different ranges of the learning rate and explore both the dynamical and orbital stability of the resulting network trajectories, finding hints of regular and chaotic behavior depending on the learning rate regime. Our findings are put in contrast to common wisdom on convergence properties of neural networks and dynamical systems theory. This work also contributes to the cross-fertilization of ideas between dynamical systems theory, network theory and machine learning</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Data Readiness for AI: A 360-Degree Survey</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05779">https://arxiv.org/abs/2404.05779</a></p>
  <p><b>作者</b>：Kaveen Hiniduma,  Suren Byna,  Jean Luca Bez</p>
  <p><b>备注</b>：35 pages, 3 figures, 3 tables, submitted to ACM Computing Surveys</p>
  <p><b>关键词</b>：Artificial Intelligence, fuel for Artificial, critical fuel, data readiness, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data are the critical fuel for Artificial Intelligence (AI) models. Poor quality data produces inaccurate and ineffective AI models that may lead to incorrect or unsafe use. Checking for data readiness is a crucial step in improving data quality. Numerous R&D efforts have been spent on improving data quality. However, standardized metrics for evaluating data readiness for use in AI training are still evolving. In this study, we perform a comprehensive survey of metrics used for verifying AI's data readiness. This survey examines more than 120 papers that are published by ACM Digital Library, IEEE Xplore, other reputable journals, and articles published on the web by prominent AI experts. This survey aims to propose a taxonomy of data readiness for AI (DRAI) metrics for structured and unstructured datasets. We anticipate that this taxonomy can lead to new standards for DRAI metrics that would be used for enhancing the quality and accuracy of AI training and inference.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：STMGF: An Effective Spatial-Temporal Multi-Granularity Framework for  Traffic Forecasting</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05774">https://arxiv.org/abs/2404.05774</a></p>
  <p><b>作者</b>：Zhengyang Zhao,  Haitao Yuan,  Nan Jiang,  Minxiao Chen,  Ning Liu,  Zengxiang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligent transportation due, Accurate Traffic Prediction, road networks, challenging task, task in intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate Traffic Prediction is a challenging task in intelligent transportation due to the spatial-temporal aspects of road networks. The traffic of a road network can be affected by long-distance or long-term dependencies where existing methods fall short in modeling them. In this paper, we introduce a novel framework known as Spatial-Temporal Multi-Granularity Framework (STMGF) to enhance the capture of long-distance and long-term information of the road networks. STMGF makes full use of different granularity information of road networks and models the long-distance and long-term information by gathering information in a hierarchical interactive way. Further, it leverages the inherent periodicity in traffic sequences to refine prediction results by matching with recent traffic data. We conduct experiments on two real-world datasets, and the results demonstrate that STMGF outperforms all baseline models and achieves state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Streamlining Ocean Dynamics Modeling with Fourier Neural Operators: A  Multiobjective Hyperparameter and Architecture Optimization Approach</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05768">https://arxiv.org/abs/2404.05768</a></p>
  <p><b>作者</b>：Yixuan Sun,  Ololade Sowunmi,  Romain Egele,  Sri Hari Krishna Narayanan,  Luke Van Roekel,  Prasanna Balaprakash</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective deep learning, processes involves careful, involves careful choices, learn ocean processes, ocean processes involves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training an effective deep learning model to learn ocean processes involves careful choices of various hyperparameters. We leverage DeepHyper's advanced search algorithms for multiobjective optimization, streamlining the development of neural networks tailored for ocean modeling. The focus is on optimizing Fourier neural operators (FNOs), a data-driven model capable of simulating complex ocean behaviors. Selecting the correct model and tuning the hyperparameters are challenging tasks, requiring much effort to ensure model accuracy. DeepHyper allows efficient exploration of hyperparameters associated with data preprocessing, FNO architecture-related hyperparameters, and various model training strategies. We aim to obtain an optimal set of hyperparameters leading to the most performant model. Moreover, on top of the commonly used mean squared error for model training, we propose adopting the negative anomaly correlation coefficient as the additional loss term to improve model performance and investigate the potential trade-off between the two terms. The experimental results show that the optimal set of hyperparameters enhanced model performance in single timestepping forecasting and greatly exceeded the baseline configuration in the autoregressive rollout for long-horizon forecasting up to 30 days. Utilizing DeepHyper, we demonstrate an approach to enhance the use of FNOs in ocean dynamics forecasting, offering a scalable solution with improved precision.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Enhancing Inference Efficiency of Large Language Models: Investigating  Optimization Strategies and Architectural Innovations</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05741">https://arxiv.org/abs/2404.05741</a></p>
  <p><b>作者</b>：Georgy Tyukin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, models train quicker, Language Models, train quicker</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models are growing in size, and we expect them to continue to do so, as larger models train quicker. However, this increase in size will severely impact inference costs. Therefore model compression is important, to retain the performance of larger models, but with a reduced cost of running them. In this thesis we explore the methods of model compression, and we empirically demonstrate that the simple method of skipping latter attention sublayers in Transformer LLMs is an effective method of model compression, as these layers prove to be redundant, whilst also being incredibly computationally expensive. We observed a 21% speed increase in one-token generation for Llama 2 7B, whilst surprisingly and unexpectedly improving performance over several common benchmarks.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Soil respiration signals in response to sustainable soil management  practices enhance soil organic carbon stocks</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05737">https://arxiv.org/abs/2404.05737</a></p>
  <p><b>作者</b>：Mario Guevara</p>
  <p><b>备注</b>：13 pages, 3 figures</p>
  <p><b>关键词</b>：global scale based, yearly soil moisture, soil organic carbon, soil respiration, spatial-temporal and data-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Development of a spatial-temporal and data-driven model of soil respiration at the global scale based on soil temperature, yearly soil moisture, and soil organic carbon (C) estimates. Prediction of soil respiration on an annual basis (1991-2018) with relatively high accuracy (NSE 0.69, CCC 0.82). Lower soil respiration trends, higher soil respiration magnitudes, and higher soil organic C stocks across areas experiencing the presence of sustainable soil management practices.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：GeoDirDock: Guiding Docking Along Geodesic Paths</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06481">https://arxiv.org/abs/2404.06481</a></p>
  <p><b>作者</b>：Raúl Miñán,  Javier Gallardo,  Álvaro Ciudad,  Alexis Molina</p>
  <p><b>备注</b>：Generative and Experimental Perspectives for Biomolecular Design Workshop at ICLR 2024</p>
  <p><b>关键词</b>：work introduces GeoDirDock, introduces GeoDirDock, work introduces, approach to molecular, physical plausibility</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work introduces GeoDirDock (GDD), a novel approach to molecular docking that enhances the accuracy and physical plausibility of ligand docking predictions. GDD guides the denoising process of a diffusion model along geodesic paths within multiple spaces representing translational, rotational, and torsional degrees of freedom. Our method leverages expert knowledge to direct the generative modeling process, specifically targeting desired protein-ligand interaction regions. We demonstrate that GDD significantly outperforms existing blind docking methods in terms of RMSD accuracy and physicochemical pose realism. Our results indicate that incorporating domain expertise into the diffusion process leads to more biologically relevant docking predictions. Additionally, we explore the potential of GDD for lead optimization in drug discovery through angle transfer in maximal common substructure (MCS) docking, showcasing its capability to predict ligand orientations for chemically similar compounds accurately.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A comparative analysis of deep learning models for lung segmentation on  X-ray images</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06455">https://arxiv.org/abs/2404.06455</a></p>
  <p><b>作者</b>：Weronika Hryniewska-Guzik,  Jakub Bilski,  Bartosz Chrostowski,  Jakub Drak Sbahi,  Przemysław Biecek</p>
  <p><b>备注</b>：published at the Polish Conference on Artificial Intelligence (PP-RAI), 2024</p>
  <p><b>关键词</b>：highly accurate lung, accurate lung segmentation, segmentation in X-rays, X-rays is crucial, Robust and highly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust and highly accurate lung segmentation in X-rays is crucial in medical imaging. This study evaluates deep learning solutions for this task, ranking existing methods and analyzing their performance under diverse image modifications. Out of 61 analyzed papers, only nine offered implementation or pre-trained models, enabling assessment of three prominent methods: Lung VAE, TransResUNet, and CE-Net. The analysis revealed that CE-Net performs best, demonstrating the highest values in dice similarity coefficient and intersection over union metric.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Quantum State Generation with Structure-Preserving Diffusion Model</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06336">https://arxiv.org/abs/2404.06336</a></p>
  <p><b>作者</b>：Yuchen Zhu,  Tianrong Chen,  Evangelos A. Theodorou,  Xie Chen,  Molei Tao</p>
  <p><b>备注</b>：15 pages, 6 figures</p>
  <p><b>关键词</b>：denoising diffusion model, approach based, based on denoising, quantum systems, quantum states</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article considers the generative modeling of the states of quantum systems, and an approach based on denoising diffusion model is proposed. The key contribution is an algorithmic innovation that respects the physical nature of quantum states. More precisely, the commonly used density matrix representation of mixed-state has to be complex-valued Hermitian, positive semi-definite, and trace one. Generic diffusion models, or other generative methods, may not be able to generate data that strictly satisfy these structural constraints, even if all training data do. To develop a machine learning algorithm that has physics hard-wired in, we leverage the recent development of Mirror Diffusion Model and design a previously unconsidered mirror map, to enable strict structure-preserving generation. Both unconditional generation and conditional generation via classifier-free guidance are experimentally demonstrated efficacious, the latter even enabling the design of new quantum states when generated on unseen labels.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Qiskit-Torch-Module: Fast Prototyping of Quantum Neural Networks</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06314">https://arxiv.org/abs/2404.06314</a></p>
  <p><b>作者</b>：Nico Meyer,  Christian Ufrecht,  Maniraman Periyasamy,  Axel Plinge,  Christopher Mutschler,  Daniel D. Scherer,  Andreas Maier</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 7 pages, 4 figures, 3 tables</p>
  <p><b>关键词</b>：quantum computing community, Quantum computer simulation, computer simulation software, computing community, computer simulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantum computer simulation software is an integral tool for the research efforts in the quantum computing community. An important aspect is the efficiency of respective frameworks, especially for training variational quantum algorithms. Focusing on the widely used Qiskit software environment, we develop the qiskit-torch-module. It improves runtime performance by two orders of magnitude over comparable libraries, while facilitating low-overhead integration with existing codebases. Moreover, the framework provides advanced tools for integrating quantum neural networks with PyTorch. The pipeline is tailored for single-machine compute systems, which constitute a widely employed setup in day-to-day research efforts.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Fortifying Fully Convolutional Generative Adversarial Networks for Image  Super-Resolution Using Divergence Measures</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06294">https://arxiv.org/abs/2404.06294</a></p>
  <p><b>作者</b>：Arkaprabha Basu,  Kushal Bose,  Sankha Subhra Mullick,  Anish Chakrabarty,  Swagatam Das</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-hallowed image processing, image processing problem, Generative Adversarial Network, fully-convolutional Generative Adversarial, time-hallowed image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Super-Resolution (SR) is a time-hallowed image processing problem that aims to improve the quality of a Low-Resolution (LR) sample up to the standard of its High-Resolution (HR) counterpart. We aim to address this by introducing Super-Resolution Generator (SuRGe), a fully-convolutional Generative Adversarial Network (GAN)-based architecture for SR. We show that distinct convolutional features obtained at increasing depths of a GAN generator can be optimally combined by a set of learnable convex weights to improve the quality of generated SR samples. In the process, we employ the Jensen-Shannon and the Gromov-Wasserstein losses respectively between the SR-HR and LR-SR pairs of distributions to further aid the generator of SuRGe to better exploit the available information in an attempt to improve SR. Moreover, we train the discriminator of SuRGe with the Wasserstein loss with gradient penalty, to primarily prevent mode collapse. The proposed SuRGe, as an end-to-end GAN workflow tailor-made for super-resolution, offers improved performance while maintaining low inference time. The efficacy of SuRGe is substantiated by its superior performance compared to 18 state-of-the-art contenders on 10 benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Simple algorithms to test and learn local Hamiltonians</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06282">https://arxiv.org/abs/2404.06282</a></p>
  <p><b>作者</b>：Francisco Escudero Gutiérrez</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：normalized Frobenius norm, Pauli spectrum, Frobenius norm, normalized Frobenius, epsilon</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problems of testing and learning an $n$-qubit $k$-local Hamiltonian from queries to its evolution operator with respect the 2-norm of the Pauli spectrum, or equivalently, the normalized Frobenius norm. For testing whether a Hamiltonian is $\epsilon_1$-close to $k$-local or $\epsilon_2$-far from $k$-local, we show that $O(1/(\epsilon_2-\epsilon_1)^{8})$ queries suffice. This solves two questions posed in a recent work by Bluhm, Caro and Oufkir. For learning up to error $\epsilon$, we show that $\exp(O(k^2+k\log(1/\epsilon)))$ queries suffice. Our proofs are simple, concise and based on Pauli-analytic techniques.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Message Passing Variational Autoregressive Network for Solving  Intractable Ising Models</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06225">https://arxiv.org/abs/2404.06225</a></p>
  <p><b>作者</b>：Qunlong Ma,  Zhi Ma,  Jinlong Xu,  Hairui Zhang,  Ming Gao</p>
  <p><b>备注</b>：18 pages, 14 figures</p>
  <p><b>关键词</b>：connected Ising model, solve Ising models, neural networks, fully connected Ising, convolutional neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many deep neural networks have been used to solve Ising models, including autoregressive neural networks, convolutional neural networks, recurrent neural networks, and graph neural networks. Learning a probability distribution of energy configuration or finding the ground states of a disordered, fully connected Ising model is essential for statistical mechanics and NP-hard problems. Despite tremendous efforts, a neural network architecture with the ability to high-accurately solve these fully connected and extremely intractable problems on larger systems is still lacking. Here we propose a variational autoregressive architecture with a message passing mechanism, which can effectively utilize the interactions between spin variables. The new network trained under an annealing framework outperforms existing methods in solving several prototypical Ising spin Hamiltonians, especially for larger spin systems at low temperatures. The advantages also come from the great mitigation of mode collapse during the training process of deep neural networks. Considering these extremely difficult problems to be solved, our method extends the current computational limits of unsupervised neural networks to solve combinatorial optimization problems.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Deep Learning Method for Computing Committor Functions with Adaptive  Sampling</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06206">https://arxiv.org/abs/2404.06206</a></p>
  <p><b>作者</b>：Bo Lin,  Weiqing Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：committor function, central object, object for quantifying, metastable states, states of dynamical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The committor function is a central object for quantifying the transitions between metastable states of dynamical systems. Recently, a number of computational methods based on deep neural networks have been developed for computing the high-dimensional committor function. The success of the methods relies on sampling adequate data for the transition, which still is a challenging task for complex systems at low temperatures. In this work, we propose a deep learning method with two novel adaptive sampling schemes (I and II). In the two schemes, the data are generated actively with a modified potential where the bias potential is constructed from the learned committor function. We theoretically demonstrate the advantages of the sampling schemes and show that the data in sampling scheme II are uniformly distributed along the transition tube. This makes a promising method for studying the transition of complex systems. The efficiency of the method is illustrated in high-dimensional systems including the alanine dipeptide and a solvated dimer system.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：A singular Riemannian Geometry Approach to Deep Neural Networks III.  Piecewise Differentiable Layers and Random Walks on $n$-dimensional Classes</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06104">https://arxiv.org/abs/2404.06104</a></p>
  <p><b>作者</b>：Alessandro Benfenati,  Alessio Marta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern generative models, achieve impressive results, everyday life, playing a crucial, crucial role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are playing a crucial role in everyday life, with the most modern generative models able to achieve impressive results. Nonetheless, their functioning is still not very clear, and several strategies have been adopted to study how and why these model reach their outputs. A common approach is to consider the data in an Euclidean settings: recent years has witnessed instead a shift from this paradigm, moving thus to more general framework, namely Riemannian Geometry. Two recent works introduced a geometric framework to study neural networks making use of singular Riemannian metrics. In this paper we extend these results to convolutional, residual and recursive neural networks, studying also the case of non-differentiable activation functions, such as ReLU. We illustrate our findings with some numerical experiments on classification of images and thermodynamic problems.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Prelimit Coupling and Steady-State Convergence of Constant-stepsize  Nonsmooth Contractive SA</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06023">https://arxiv.org/abs/2404.06023</a></p>
  <p><b>作者</b>：Yixuan Zhang,  Dongyan Huo,  Yudong Chen,  Qiaomin Xie</p>
  <p><b>备注</b>：71 pages, 3 figures</p>
  <p><b>关键词</b>：contractive stochastic approximation, study nonsmooth contractive, nonsmooth contractive stochastic, stochastic approximation, Motivated by Q-learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivated by Q-learning, we study nonsmooth contractive stochastic approximation (SA) with constant stepsize. We focus on two important classes of dynamics: 1) nonsmooth contractive SA with additive noise, and 2) synchronous and asynchronous Q-learning, which features both additive and multiplicative noise. For both dynamics, we establish weak convergence of the iterates to a stationary limit distribution in Wasserstein distance. Furthermore, we propose a prelimit coupling technique for establishing steady-state convergence and characterize the limit of the stationary distribution as the stepsize goes to zero. Using this result, we derive that the asymptotic bias of nonsmooth SA is proportional to the square root of the stepsize, which stands in sharp contrast to smooth SA. This bias characterization allows for the use of Richardson-Romberg extrapolation for bias reduction in nonsmooth SA.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Computing Transition Pathways for the Study of Rare Events Using Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05905">https://arxiv.org/abs/2404.05905</a></p>
  <p><b>作者</b>：Bo Lin,  Yangzheng Zhong,  Weiqing Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transition pathway, transition pathway plays, chemistry and biology, transition, computational physics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the transition events between metastable states in complex systems is an important subject in the fields of computational physics, chemistry and biology. The transition pathway plays an important role in characterizing the mechanism underlying the transition, for example, in the study of conformational changes of bio-molecules. In fact, computing the transition pathway is a challenging task for complex and high-dimensional systems. In this work, we formulate the path-finding task as a cost minimization problem over a particular path space. The cost function is adapted from the Freidlin-Wentzell action functional so that it is able to deal with rough potential landscapes. The path-finding problem is then solved using a actor-critic method based on the deep deterministic policy gradient algorithm (DDPG). The method incorporates the potential force of the system in the policy for generating episodes and combines physical properties of the system with the learning process for molecular systems. The exploitation and exploration nature of reinforcement learning enables the method to efficiently sample the transition events and compute the globally optimal transition pathway. We illustrate the effectiveness of the proposed method using three benchmark systems including an extended Mueller system and the Lennard-Jones system of seven particles.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Condition Monitoring with Incomplete Data: An Integrated Variational  Autoencoder and Distance Metric Framework</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05891">https://arxiv.org/abs/2404.05891</a></p>
  <p><b>作者</b>：Maryam Ahang,  Mostafa Abbasi,  Todd Charter,  Homayoun Najjaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：notable challenges arise, real-world settings due, systems is crucial, crucial for ensuring, notable challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Condition monitoring of industrial systems is crucial for ensuring safety and maintenance planning, yet notable challenges arise in real-world settings due to the limited or non-existent availability of fault samples. This paper introduces an innovative solution to this problem by proposing a new method for fault detection and condition monitoring for unseen data. Adopting an approach inspired by zero-shot learning, our method can identify faults and assign a relative health index to various operational conditions. Typically, we have plenty of data on normal operations, some data on compromised conditions, and very few (if any) samples of severe faults. We use a variational autoencoder to capture the probabilistic distribution of previously seen and new unseen conditions. The health status is determined by comparing each sample's deviation from a normal operation reference distribution in the latent space. Faults are detected by establishing a threshold for the health indexes, allowing the model to identify severe, unseen faults with high accuracy, even amidst noise. We validate our approach using the run-to-failure IMS-bearing dataset and compare it with other methods. The health indexes generated by our model closely match the established descriptive model of bearing wear, attesting to the robustness and reliability of our method. These findings highlight the potential of our methodology in augmenting fault detection capabilities within industrial domains, thereby contributing to heightened safety protocols and optimized maintenance practices.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Quantum Adversarial Learning for Kernel Methods</b></summary>
  <p><b>编号</b>：[374]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05824">https://arxiv.org/abs/2404.05824</a></p>
  <p><b>作者</b>：Giuseppe Montalbano,  Leonardo Banchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support vector machines, small engineered perturbations, quantum kernel methods, hybrid quantum classifiers, quantum classifiers based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that hybrid quantum classifiers based on quantum kernel methods and support vector machines are vulnerable against adversarial attacks, namely small engineered perturbations of the input data can deceive the classifier into predicting the wrong result. Nonetheless, we also show that simple defence strategies based on data augmentation with a few crafted perturbations can make the classifier robust against new attacks. Our results find applications in security-critical learning problems and in mitigating the effect of some forms of quantum noise, since the attacker can also be understood as part of the surrounding environment.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Just Wing It: Optimal Estimation of Missing Mass in a Markovian Sequence</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05819">https://arxiv.org/abs/2404.05819</a></p>
  <p><b>作者</b>：Ashwin Pananjady,  Vidya Muthukumar,  Andrew Thangaraj</p>
  <p><b>备注</b>：40 pages, 5 figures</p>
  <p><b>关键词</b>：ergodic Markov chain, stationary missing mass, estimating the stationary, ergodic Markov, stationary mass</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of estimating the stationary mass -- also called the unigram mass -- that is missing from a single trajectory of a discrete-time, ergodic Markov chain. This problem has several applications -- for example, estimating the stationary missing mass is critical for accurately smoothing probability estimates in sequence models. While the classical Good--Turing estimator from the 1950s has appealing properties for i.i.d. data, it is known to be biased in the Markov setting, and other heuristic estimators do not come equipped with guarantees. Operating in the general setting in which the size of the state space may be much larger than the length $n$ of the trajectory, we develop a linear-runtime estimator called \emph{Windowed Good--Turing} (\textsc{WingIt}) and show that its risk decays as $\widetilde{\mathcal{O}}(\mathsf{T_{mix}}/n)$, where $\mathsf{T_{mix}}$ denotes the mixing time of the chain in total variation distance. Notably, this rate is independent of the size of the state space and minimax-optimal up to a logarithmic factor in $n / \mathsf{T_{mix}}$. We also present a bound on the variance of the missing mass random variable, which may be of independent interest. We extend our estimator to approximate the stationary mass placed on elements occurring with small frequency in $X^n$. Finally, we demonstrate the efficacy of our estimators both in simulations on canonical chains and on sequences constructed from a popular natural language corpus.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Centrality Estimators for Probability Density Functions</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05816">https://arxiv.org/abs/2404.05816</a></p>
  <p><b>作者</b>：Djemel Ziou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data selection leading, selection leading, nice properties leading, estimators maximizing, Fisher maximum likelihood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this report, we explore the data selection leading to a family of estimators maximizing a centrality. The family allows a nice properties leading to accurate and robust probability density function fitting according to some criteria we define. We establish a link between the centrality estimator and the maximum likelihood, showing that the latter is a particular case. Therefore, a new probability interpretation of Fisher maximum likelihood is provided. We will introduce and study two specific centralities that we have named Hölder and Lehmer estimators. A numerical simulation is provided showing the effectiveness of the proposed families of estimators opening the door to development of new concepts and algorithms in machine learning, data mining, statistics, and data analysis.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Group-specific discriminant analysis reveals statistically validated sex  differences in lateralization of brain functional network</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05781">https://arxiv.org/abs/2404.05781</a></p>
  <p><b>作者</b>：Shuo Zhou,  Junhao Luo,  Yaya Jiang,  Haolin Wang,  Haiping Lu,  Gaolang Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human brain, fundamental feature, sex differences, functional networks, Lateralization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lateralization is a fundamental feature of the human brain, where sex differences have been observed. Conventional studies in neuroscience on sex-specific lateralization are typically conducted on univariate statistical comparisons between male and female groups. However, these analyses often lack effective validation of group specificity. Here, we formulate modeling sex differences in lateralization of functional networks as a dual-classification problem, consisting of first-order classification for left vs. right functional networks and second-order classification for male vs. female models. To capture sex-specific patterns, we develop the Group-Specific Discriminant Analysis (GSDA) for first-order classification. The evaluation on two public neuroimaging datasets demonstrates the efficacy of GSDA in learning sex-specific models from functional networks, achieving a significant improvement in group specificity over baseline methods. The major sex differences are in the strength of lateralization and the interactions within and between lobes. The GSDA-based method is generic in nature and can be adapted to other group-specific analyses such as handedness-specific or disease-specific analyses.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Evaluating the Effectiveness of Artificial Intelligence in Predicting  Adverse Drug Reactions among Cancer Patients: A Systematic Review and  Meta-Analysis</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05762">https://arxiv.org/abs/2404.05762</a></p>
  <p><b>作者</b>：Fatma Zahra Abdeldjouad,  Menaouer Brahami,  Mohammed Sabri</p>
  <p><b>备注</b>：Paper has been accepted at the IEEE Challenges and Innovations on TIC (IEEE I2CIT) International Conference</p>
  <p><b>关键词</b>：Adverse drug reactions, reactions considerably impact, drug reactions considerably, Adverse drug, drug reactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adverse drug reactions considerably impact patient outcomes and healthcare costs in cancer therapy. Using artificial intelligence to predict adverse drug reactions in real time could revolutionize oncology treatment. This study aims to assess the performance of artificial intelligence models in predicting adverse drug reactions in patients with cancer. This is the first systematic review and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library databases were searched for studies in English, French, and Arabic from January 1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed research articles; (2) use of artificial intelligence algorithms (machine learning, deep learning, knowledge graphs); (3) study aimed to predict adverse drug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity); (4) study was on cancer patients. The data were extracted and evaluated by three reviewers for study quality. Of the 332 screened articles, 17 studies (5%) involving 93,248 oncology patients from 17 countries were included in the systematic review, of which ten studies synthesized the meta-analysis. A random-effects model was created to pool the sensitivity, specificity, and AUC of the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84 (95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity, and AUC, respectively, of ADR predictive models. Biomarkers proved their effectiveness in predicting ADRs, yet they were adopted by only half of the reviewed studies. The use of AI in cancer treatment shows great potential, with models demonstrating high specificity and sensitivity in predicting ADRs. However, standardized research and multicenter studies are needed to improve the quality of evidence. AI can enhance cancer patient care by bridging the gap between data-driven insights and clinical expertise.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Implicit Assimilation of Sparse In Situ Data for Dense & Global Storm  Surge Forecasting</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05758">https://arxiv.org/abs/2404.05758</a></p>
  <p><b>作者</b>：Patrick Ebel,  Brandon Victor,  Peter Naylor,  Gabriele Meoni,  Federico Serva,  Rochelle Schneider</p>
  <p><b>备注</b>：Accepted at CVPR EarthVision 2024</p>
  <p><b>关键词</b>：disastrous natural hazards, Hurricanes and coastal, natural hazards, coastal floods, disastrous natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hurricanes and coastal floods are among the most disastrous natural hazards. Both are intimately related to storm surges, as their causes and effects, respectively. However, the short-term forecasting of storm surges has proven challenging, especially when targeting previously unseen locations or sites without tidal gauges. Furthermore, recent work improved short and medium-term weather forecasting but the handling of raw unassimilated data remains non-trivial. In this paper, we tackle both challenges and demonstrate that neural networks can implicitly assimilate sparse in situ tide gauge data with coarse ocean state reanalysis in order to forecast storm surges. We curate a global dataset to learn and validate the dense prediction of storm surges, building on preceding efforts. Other than prior work limited to known gauges, our approach extends to ungauged sites, paving the way for global storm surge forecasting.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Physics Event Classification Using Large Language Models</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05752">https://arxiv.org/abs/2404.05752</a></p>
  <p><b>作者</b>：Cristiano Fanelli,  James Giroux,  Patrick Moran,  Hemalata Nayak,  Karthik Suresh,  Eric Walter</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：University of America, Catholic University, Electron Ion Collider, Large Language Model, Artificial Intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The 2023 AI4EIC hackathon was the culmination of the third annual AI4EIC workshop at The Catholic University of America. This workshop brought together researchers from physics, data science and computer science to discuss the latest developments in Artificial Intelligence (AI) and Machine Learning (ML) for the Electron Ion Collider (EIC), including applications for detectors, accelerators, and experimental control. The hackathon, held on the final day of the workshop, involved using a chatbot powered by a Large Language Model, ChatGPT-3.5, to train a binary classifier neutrons and photons in simulated data from the \textsc{GlueX} Barrel Calorimeter. In total, six teams of up to four participants from all over the world took part in this intense educational and research event. This article highlights the hackathon challenge, the resources and methodology used, and the results and insights gained from analyzing physics data using the most cutting-edge tools in AI/ML.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Analysing heterogeneity in Alzheimer Disease using multimodal normative  modelling on ATN biomarkers</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05748">https://arxiv.org/abs/2404.05748</a></p>
  <p><b>作者</b>：Sayantan Kumara,  Thomas Earnest,  Braden Yang,  Deydeep Kothapalli,  Tammie L. S. Benzinger,  Brian A. Gordon,  Philip Payne,  Aristeidis Sotiras</p>
  <p><b>备注</b>：Submitted to Neurology, 5 figures, 2 tables. 5 figures and 3 tables in Supplementary material</p>
  <p><b>关键词</b>：Alzheimer Disease, modality providing unique, multi-faceted disorder, providing unique, unique and complementary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer Disease (AD) is a multi-faceted disorder, with each modality providing unique and complementary info about AD. In this study, we used a deep-learning based multimodal normative model to assess the heterogeneity in regional brain patterns for ATN (amyloid-tau-neurodegeneration) biomarkers. We selected discovery (n = 665) and replication (n = 430) cohorts with simultaneous availability of ATN biomarkers: Florbetapir amyloid, Flortaucipir tau and T1-weighted MRI (magnetic resonance imaging) imaging. A multimodal variational autoencoder (conditioned on age and sex) was used as a normative model to learn the multimodal regional brain patterns of a cognitively unimpaired (CU) control group. The trained model was applied on individuals on the ADS (AD Spectrum) to estimate their deviations (Z-scores) from the normative distribution, resulting in a Z-score regional deviation map per ADS individual per modality. ADS individuals with moderate or severe dementia showed higher proportion of regional outliers for each modality as well as more dissimilarity in modality-specific regional outlier patterns compared to ADS individuals with early or mild dementia. DSI was associated with the progressive stages of dementia, (ii) showed significant associations with neuropsychological composite scores and (iii) related to the longitudinal risk of CDR progression. Findings were reproducible in both discovery and replication cohorts. Our is the first study to examine the heterogeneity in AD through the lens of multiple neuroimaging modalities (ATN), based on distinct or overlapping patterns of regional outlier deviations. Regional MRI and tau outliers were more heterogenous than regional amyloid outliers. DSI has the potential to be an individual patient metric of neurodegeneration that can help in clinical decision making and monitoring patient response for anti-amyloid treatments.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Causality for Earth Science -- A Review on Time-series and  Spatiotemporal Causality Methods</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05746">https://arxiv.org/abs/2404.05746</a></p>
  <p><b>作者</b>：Sahara Ali,  Uzma Hasan,  Xingyan Li,  Omar Faruque,  Akila Sampath,  Yiyi Huang,  Md Osman Gani,  Jianwu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Earth Science, survey paper covers, Earth Science study, Earth Science datasets, specific Earth Science</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This survey paper covers the breadth and depth of time-series and spatiotemporal causality methods, and their applications in Earth Science. More specifically, the paper presents an overview of causal discovery and causal inference, explains the underlying causal assumptions, and enlists evaluation techniques and key terminologies of the domain area. The paper elicits the various state-of-the-art methods introduced for time-series and spatiotemporal causal analysis along with their strengths and limitations. The paper further describes the existing applications of several methods for answering specific Earth Science questions such as extreme weather events, sea level rise, teleconnections etc. This survey paper can serve as a primer for Data Science researchers interested in data-driven causal study as we share a list of resources, such as Earth Science datasets (synthetic, simulated and observational data) and open source tools for causal analysis. It will equally benefit the Earth Science community interested in taking an AI-driven approach to study the causality of different dynamic and thermodynamic processes as we present the open challenges and opportunities in performing causality-based Earth Science study.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Flexible Fairness Learning via Inverse Conditional Permutation</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05678">https://arxiv.org/abs/2404.05678</a></p>
  <p><b>作者</b>：Yuheng Lai,  Leying Guan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aims to ensure, race and gender, true outcome, equalized odds caused, Equalized odds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Equalized odds, as a popular notion of algorithmic fairness, aims to ensure that sensitive variables, such as race and gender, do not unfairly influence the algorithm prediction when conditioning on the true outcome. Despite rapid advancements, most of the current research focuses on the violation of equalized odds caused by one sensitive attribute, leaving the challenge of simultaneously accounting for multiple attributes under-addressed. We address this gap by introducing a fairness learning approach that integrates adversarial learning with a novel inverse conditional permutation. This approach effectively and flexibly handles multiple sensitive attributes, potentially of mixed data types. The efficacy and flexibility of our method are demonstrated through both simulation studies and empirical analysis of real-world datasets.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：MoReVQA: Exploring Modular Reasoning Models for Video Question Answering</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06511">https://arxiv.org/abs/2404.06511</a></p>
  <p><b>作者</b>：Juhong Min,  Shyamal Buch,  Arsha Nagrani,  Minsu Cho,  Cordelia Schmid</p>
  <p><b>备注</b>：CVPR 2024</p>
  <p><b>关键词</b>：video question answering, modular reasoning framework, question answering, paper addresses, video question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the task of video question answering (videoQA) via a decomposed multi-stage, modular reasoning framework. Previous modular methods have shown promise with a single planning stage ungrounded in visual content. However, through a simple and effective baseline, we find that such systems can lead to brittle behavior in practice for challenging videoQA settings. Thus, unlike traditional single-stage planning methods, we propose a multi-stage system consisting of an event parser, a grounding stage, and a final reasoning stage in conjunction with an external memory. All stages are training-free, and performed using few-shot prompting of large models, creating interpretable intermediate outputs at each stage. By decomposing the underlying planning and task complexity, our method, MoReVQA, improves over prior work on standard videoQA benchmarks (NExT-QA, iVQA, EgoSchema, ActivityNet-QA) with state-of-the-art results, and extensions to related tasks (grounded videoQA, paragraph captioning).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Graph Reinforcement Learning for Combinatorial Optimization: A Survey  and Unifying Perspective</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06492">https://arxiv.org/abs/2404.06492</a></p>
  <p><b>作者</b>：Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Reinforcement Learning, Graph Reinforcement Learning, connected entities, natural representation, representation for systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphs are a natural representation for systems based on relations between connected entities. Combinatorial optimization problems, which arise when considering an objective function related to a process of interest on discrete structures, are often challenging due to the rapid growth of the solution space. The trial-and-error paradigm of Reinforcement Learning has recently emerged as a promising alternative to traditional methods, such as exact algorithms and (meta)heuristics, for discovering better decision-making strategies in a variety of disciplines including chemistry, computer science, and statistics. Despite the fact that they arose in markedly different fields, these techniques share significant commonalities. Therefore, we set out to synthesize this work in a unifying perspective that we term Graph Reinforcement Learning, interpreting it as a constructive decision-making method for graph problems. After covering the relevant technical background, we review works along the dividing line of whether the goal is to optimize graph structure given a process of interest, or to optimize the outcome of the process itself under fixed graph structure. Finally, we discuss the common challenges facing the field and open research questions. In contrast with other surveys, the present work focuses on non-canonical graph problems for which performant algorithms are typically not known and Reinforcement Learning is able to provide efficient and effective solutions.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Pitfalls of Conversational LLMs on News Debiasing</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06488">https://arxiv.org/abs/2404.06488</a></p>
  <p><b>作者</b>：Ipek Baris Schlicht,  Defne Altiok,  Maryanne Taouk,  Lucie Flek</p>
  <p><b>备注</b>：The paper is accepted at the DELITE workshop which is co-located at COLING/LREC</p>
  <p><b>关键词</b>：conversational Large Language, Large Language Models, Large Language, paper addresses debiasing, conversational Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses debiasing in news editing and evaluates the effectiveness of conversational Large Language Models in this task. We designed an evaluation checklist tailored to news editors' perspectives, obtained generated texts from three popular conversational models using a subset of a publicly available dataset in media bias, and evaluated the texts according to the designed checklist. Furthermore, we examined the models as evaluator for checking the quality of debiased model outputs. Our findings indicate that none of the LLMs are perfect in debiasing. Notably, some models, including ChatGPT, introduced unnecessary changes that may impact the author's style and create misinformation. Lastly, we show that the models do not perform as proficiently as domain experts in evaluating the quality of debiased outputs.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Public-private funding models in open source software development: A  case study on scikit-learn</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06484">https://arxiv.org/abs/2404.06484</a></p>
  <p><b>作者</b>：Cailean Osborne</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：domestic software markets, address concerns related, OSS, software security, software markets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Governments are increasingly allocating funding for open source software (OSS) development in order to address concerns related to software security, digital sovereignty, and the competitiveness of domestic software markets, amongst others. While such funding is generally welcomed by OSS practitioners, how OSS developers perceive the relative benefits and drawbacks of governmental funding remains an open question. This paper explores this question through a case study on scikit-learn, a Python library for machine learning, whose funding model combines research grants, commercial sponsorship, community donations, and a 32 million EUR grant from the French government's artificial intelligence strategy. Through 25 interviews with scikit-learn maintainers and funders, this study makes two key contributions with implications for research and practice. First, it provides novel insights into the role of a public-private funding model in a successful, community-led OSS project and how maintainers evaluate their funding model. Furthermore, it highlights the governance mechanisms employed by maintainers to safeguard the community ethos of the project. Second, it offers practical implications for OSS developer communities, companies, and governments. For OSS communities, the study illustrates the benefits of a diversified funding model in balancing the merits and drawbacks of different funding sources. For companies, it serves as a reminder that sponsoring developers or directly funding OSS projects can significantly support OSS maintainers, who often struggle with limited resources and towering workloads. For governments, the findings emphasise the importance of funding the maintenance of existing OSS projects in addition to or exclusively funding new innovations. The paper concludes with suggestions for future research on OSS funding models.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06480">https://arxiv.org/abs/2404.06480</a></p>
  <p><b>作者</b>：Chonghua Wang,  Haodong Duan,  Songyang Zhang,  Dahua Lin,  Kai Chen</p>
  <p><b>备注</b>：NAACL 2024</p>
  <p><b>关键词</b>：shown increasing interest, extremely long documents, large language model, enhancing LLMs' capability, handle extremely long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the large language model (LLM) community has shown increasing interest in enhancing LLMs' capability to handle extremely long documents. As various long-text techniques and model architectures emerge, the precise and detailed evaluation of models' long-text capabilities has become increasingly important. Existing long-text evaluation benchmarks, such as L-Eval and LongBench, construct long-text test sets based on open-source datasets, focusing mainly on QA and summarization tasks. These datasets include test samples of varying lengths (from 2k to 32k+) entangled together, making it challenging to assess model capabilities across different length ranges. Moreover, they do not cover the ultralong settings (100k+ tokens) that the latest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a length-adaptable benchmark for evaluating the long-context understanding of LLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which enable a more reliable evaluation of LLMs' long context capabilities. These benchmarks support intricate manipulation of the length of test cases, and can easily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art closed-source API models and 6 open-source models with Ada-LEval. The evaluation results demonstrate the limitations of current LLMs, especially in ultra-long-context settings. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Text-Based Reasoning About Vector Graphics</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06479">https://arxiv.org/abs/2404.06479</a></p>
  <p><b>作者</b>：Zhenhailong Wang,  Joy Hsu,  Xingyao Wang,  Kuan-Hao Huang,  Manling Li,  Jiajun Wu,  Heng Ji</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：broad vision-language benchmarks, solving simple mazes, comparing line lengths, vector graphics, Scalable Vector Graphics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While large multimodal models excel in broad vision-language benchmarks, they often struggle with tasks requiring precise perception of low-level visual details, such as comparing line lengths or solving simple mazes. In particular, this failure mode persists in question-answering tasks about vector graphics -- images composed purely of 2D objects and shapes. To address this challenge, we propose the Visually Descriptive Language Model (VDLM), which performs text-based reasoning about vector graphics. VDLM leverages Scalable Vector Graphics (SVG) for a more precise visual description and first uses an off-the-shelf raster-to-SVG algorithm for encoding. Since existing language models cannot understand raw SVGs in a zero-shot setting, VDLM then bridges SVG with pretrained language models through a newly introduced intermediate symbolic representation, Primal Visual Description (PVD), comprising primitive attributes (e.g., shape, position, measurement) with their corresponding predicted values. PVD is task-agnostic and represents visual primitives that are universal across all vector graphics. It can be learned with procedurally generated (SVG, PVD) pairs and also enables the direct use of LLMs for generalization to complex reasoning tasks. By casting an image to a text-based representation, we can leverage the power of language models to learn alignment from SVG to visual primitives and generalize to unseen question-answering tasks. Empirical results show that VDLM achieves stronger zero-shot performance compared to state-of-the-art LMMs, such as GPT-4V, in various low-level multimodal perception and reasoning tasks on vector graphics. We additionally present extensive analyses on VDLM's performance, demonstrating that our framework offers better interpretability due to its disentangled perception and reasoning processes. Project page: this https URL</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Autonomous Evaluation and Refinement of Digital Agents</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06474">https://arxiv.org/abs/2404.06474</a></p>
  <p><b>作者</b>：Jiayi Pan,  Yichi Zhang,  Nicholas Tomlin,  Yifei Zhou,  Sergey Levine,  Alane Suhr</p>
  <p><b>备注</b>：Code at this https URL</p>
  <p><b>关键词</b>：domain-general automatic evaluators, device control, show that domain-general, domain-general automatic, web navigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that domain-general automatic evaluators can significantly improve the performance of agents for web navigation and device control. We experiment with multiple evaluation models that trade off between inference cost, modularity of design, and accuracy. We validate the performance of these models in several popular benchmarks for digital agents, finding between 74.4 and 92.9% agreement with oracle evaluation metrics. Finally, we use these evaluators to improve the performance of existing agents via fine-tuning and inference-time guidance. Without any additional supervision, we improve state-of-the-art performance by 29% on the popular benchmark WebArena, and achieve a 75% relative improvement in a challenging domain transfer scenario.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：PURE: Turning Polysemantic Neurons Into Pure Features by Identifying  Relevant Circuits</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06453">https://arxiv.org/abs/2404.06453</a></p>
  <p><b>作者</b>：Maximilian Dreyer,  Erblina Purelku,  Johanna Vielhaben,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：14 pages (4 pages manuscript, 2 pages references, 8 pages appendix)</p>
  <p><b>关键词</b>：Deep Neural Networks, mechanistic interpretability aims, Deep Neural, Neural Networks, field of mechanistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of mechanistic interpretability aims to study the role of individual neurons in Deep Neural Networks. Single neurons, however, have the capability to act polysemantically and encode for multiple (unrelated) features, which renders their interpretation difficult. We present a method for disentangling polysemanticity of any Deep Neural Network by decomposing a polysemantic neuron into multiple monosemantic "virtual" neurons. This is achieved by identifying the relevant sub-graph ("circuit") for each "pure" feature. We demonstrate how our approach allows us to find and disentangle various polysemantic units of ResNet models trained on ImageNet. While evaluating feature visualizations using CLIP, our method effectively disentangles representations, improving upon methods based on neuron activations. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of  Large Language Models</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06448">https://arxiv.org/abs/2404.06448</a></p>
  <p><b>作者</b>：Zihan Fang,  Zheng Lin,  Zhe Chen,  Xianhao Chen,  Yue Gao,  Yuguang Fang</p>
  <p><b>备注</b>：15 pages, 16 figures</p>
  <p><b>关键词</b>：intelligent generative content, advanced intelligent generative, large language models, generative content, development of advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there has been a surge in the development of advanced intelligent generative content (AIGC), especially large language models (LLMs). However, for many downstream tasks, it is necessary to fine-tune LLMs using private data. While federated learning offers a promising privacy-preserving solution to LLM fine-tuning, the substantial size of an LLM, combined with high computational and communication demands, makes it hard to apply to downstream tasks. More importantly, private edge servers often possess varying computing and network resources in real-world scenarios, introducing additional complexities to LLM fine-tuning. To tackle these problems, we design and implement an automated federated pipeline, named FedPipe, to fine-tune LLMs with minimal training cost but without adding any inference latency. FedPipe firstly identifies the weights to be fine-tuned based on their contributions to the LLM training. It then configures a low-rank adapter for each selected weight to train local low-rank adapters on an edge server, and aggregate local adapters of all edge servers to fine-tune the whole LLM. Finally, it appropriately quantizes the parameters of LLM to reduce memory space according to the requirements of edge servers. Extensive experiments demonstrate that FedPipe expedites the model training and achieves higher accuracy than state-of-the-art benchmarks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：pfl-research: simulation framework for accelerating research in Private  Federated Learning</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06430">https://arxiv.org/abs/2404.06430</a></p>
  <p><b>作者</b>：Filip Granqvist,  Congzheng Song,  Áine Cahill,  Rogier van Dalen,  Martin Pelikan,  Yi Sheng Chan,  Xiaojun Feng,  Natarajan Krishnaswami,  Vojta Jina,  Mona Chitnis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging machine learning, Federated learning, machine learning, training paradigm, emerging machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging machine learning (ML) training paradigm where clients own their data and collaborate to train a global model, without revealing any data to the server and other participants. Researchers commonly perform experiments in a simulation environment to quickly iterate on ideas. However, existing open-source tools do not offer the efficiency required to simulate FL on larger and more realistic FL datasets. We introduce pfl-research, a fast, modular, and easy-to-use Python framework for simulating FL. It supports TensorFlow, PyTorch, and non-neural network models, and is tightly integrated with state-of-the-art privacy algorithms. We study the speed of open-source FL frameworks and show that pfl-research is 7-72$\times$ faster than alternative open-source frameworks on common cross-device setups. Such speedup will significantly boost the productivity of the FL research community and enable testing hypotheses on realistic FL datasets that were previously too resource intensive. We release a suite of benchmarks that evaluates an algorithm's overall performance on a diverse set of realistic scenarios. The code is available on GitHub at this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06429">https://arxiv.org/abs/2404.06429</a></p>
  <p><b>作者</b>：Fan Yang,  Jianfeng Zhang,  Yichun Shi,  Bowen Chen,  Chenxu Zhang,  Huichao Zhang,  Xiaofeng Yang,  Jiashi Feng,  Guosheng Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant progress recently, made significant progress, content creation, progress recently, rapid development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benefiting from the rapid development of 2D diffusion models, 3D content creation has made significant progress recently. One promising solution involves the fine-tuning of pre-trained 2D diffusion models to harness their capacity for producing multi-view images, which are then lifted into accurate 3D models via methods like fast-NeRFs or large reconstruction models. However, as inconsistency still exists and limited generated resolution, the generation results of such methods still lack intricate textures and complex geometries. To solve this problem, we propose Magic-Boost, a multi-view conditioned diffusion model that significantly refines coarse generative results through a brief period of SDS optimization ($\sim15$min). Compared to the previous text or single image based diffusion models, Magic-Boost exhibits a robust capability to generate images with high consistency from pseudo synthesized multi-view images. It provides precise SDS guidance that well aligns with the identity of the input images, enriching the local detail in both geometry and texture of the initial generative results. Extensive experiments show Magic-Boost greatly enhances the coarse inputs and generates high-quality 3D assets with rich geometric and textural details. (Project Page: this https URL)</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Deep Reinforcement Learning-Based Approach for a Single Vehicle  Persistent Surveillance Problem with Fuel Constraints</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06423">https://arxiv.org/abs/2404.06423</a></p>
  <p><b>作者</b>：Hritik Bana,  Manav Mishra,  Saswata Sarkar,  Sujeevraja Sanjeevi,  Sujit PB,  Kaarthik Sundar</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：persistent surveillance mission, surveillance mission requiring, single unmanned aerial, aerial vehicle initially, vehicle initially stationed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article presents a deep reinforcement learning-based approach to tackle a persistent surveillance mission requiring a single unmanned aerial vehicle initially stationed at a depot with fuel or time-of-flight constraints to repeatedly visit a set of targets with equal priority. Owing to the vehicle's fuel or time-of-flight constraints, the vehicle must be regularly refueled, or its battery must be recharged at the depot. The objective of the problem is to determine an optimal sequence of visits to the targets that minimizes the maximum time elapsed between successive visits to any target while ensuring that the vehicle never runs out of fuel or charge. We present a deep reinforcement learning algorithm to solve this problem and present the results of numerical experiments that corroborate the effectiveness of this approach in comparison with common-sense greedy heuristics.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Studying the Impact of Latent Representations in Implicit Neural  Networks for Scientific Continuous Field Reconstruction</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06418">https://arxiv.org/abs/2404.06418</a></p>
  <p><b>作者</b>：Wei Xu,  Derek Freeman DeSantis,  Xihaier Luo,  Avish Parmar,  Klaus Tan,  Balu Nadiga,  Yihui Ren,  Shinjae Yoo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse scientific disciplines, affects diverse scientific, Modulated Gabor Network, Learning a continuous, scientific disciplines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning a continuous and reliable representation of physical fields from sparse sampling is challenging and it affects diverse scientific disciplines. In a recent work, we present a novel model called MMGN (Multiplicative and Modulated Gabor Network) with implicit neural networks. In this work, we design additional studies leveraging explainability methods to complement the previous experiments and further enhance the understanding of latent representations generated by the model. The adopted methods are general enough to be leveraged for any latent space inspection. Preliminary results demonstrate the contextual information incorporated in the latent representations and their impact on the model performance. As a work in progress, we will continue to verify our findings and develop novel explainability approaches.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：AgentQuest: A Modular Benchmark Framework to Measure Progress and  Improve LLM Agents</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06411">https://arxiv.org/abs/2404.06411</a></p>
  <p><b>作者</b>：Luca Gioacchini,  Giuseppe Siracusano,  Davide Sanvito,  Kiril Gashteovski,  David Friede,  Roberto Bifulco,  Carolin Lawrence</p>
  <p><b>备注</b>：Accepted at the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2024)</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, multi-step reasoning tasks, made by Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advances made by Large Language Models (LLMs) have led to the pursuit of LLM agents that can solve intricate, multi-step reasoning tasks. As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress. However, existing benchmarks are often narrow and simply compute overall task success. To face these issues, we propose AgentQuest -- a framework where (i) both benchmarks and metrics are modular and easily extensible through well documented and easy-to-use APIs; (ii) we offer two new evaluation metrics that can reliably track LLM agent progress while solving a task. We exemplify the utility of the metrics on two use cases wherein we identify common failure points and refine the agent architecture to obtain a significant performance increase. Together with the research community, we hope to extend AgentQuest further and therefore we make it available under this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Take a Look at it! Rethinking How to Evaluate Language Model Jailbreak</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06407">https://arxiv.org/abs/2404.06407</a></p>
  <p><b>作者</b>：Hongyu Cai,  Arjun Arunasalam,  Leo Y. Lin,  Antonio Bianchi,  Z. Berkay Celik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly integrated, jailbreak, evaluation, Large language models, evaluation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have become increasingly integrated with various applications. To ensure that LLMs do not generate unsafe responses, they are aligned with safeguards that specify what content is restricted. However, such alignment can be bypassed to produce prohibited content using a technique commonly referred to as jailbreak. Different systems have been proposed to perform the jailbreak automatically. These systems rely on evaluation methods to determine whether a jailbreak attempt is successful. However, our analysis reveals that current jailbreak evaluation methods have two limitations. (1) Their objectives lack clarity and do not align with the goal of identifying unsafe responses. (2) They oversimplify the jailbreak result as a binary outcome, successful or not.
In this paper, we propose three metrics, safeguard violation, informativeness, and relative truthfulness, to evaluate language model jailbreak. Additionally, we demonstrate how these metrics correlate with the goal of different malicious actors. To compute these metrics, we introduce a multifaceted approach that extends the natural language generation evaluation method after preprocessing the response. We evaluate our metrics on a benchmark dataset produced from three malicious intent datasets and three jailbreak systems. The benchmark dataset is labeled by three annotators. We compare our multifaceted approach with three existing jailbreak evaluation methods. Experiments demonstrate that our multifaceted evaluation outperforms existing methods, with F1 scores improving on average by 17% compared to existing baselines. Our findings motivate the need to move away from the binary view of the jailbreak problem and incorporate a more comprehensive evaluation to ensure the safety of the language model.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Wu's Method can Boost Symbolic AI to Rival Silver Medalists and  AlphaGeometry to Outperform Gold Medalists at IMO Geometry</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06405">https://arxiv.org/abs/2404.06405</a></p>
  <p><b>作者</b>：Shiven Sinha,  Ameya Prabhu,  Ponnurangam Kumaraguru,  Siddharth Bhat,  Matthias Bethge</p>
  <p><b>备注</b>：Work in Progress. Released for wider feedback</p>
  <p><b>关键词</b>：geometric theorems constitutes, Proving geometric theorems, automated theorem proving, International Mathematical Olympiad, visual reasoning combining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Proving geometric theorems constitutes a hallmark of visual reasoning combining both intuitive and logical skills. Therefore, automated theorem proving of Olympiad-level geometry problems is considered a notable milestone in human-level automated reasoning. The introduction of AlphaGeometry, a neuro-symbolic model trained with 100 million synthetic samples, marked a major breakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO) problems whereas the reported baseline based on Wu's method solved only ten. In this note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry, and find that Wu's method is surprisingly strong. Wu's method alone can solve 15 problems, and some of them are not solved by any of the other methods. This leads to two key findings: (i) Combining Wu's method with the classic synthetic methods of deductive databases and angle, ratio, and distance chasing solves 21 out of 30 methods by just using a CPU-only laptop with a time limit of 5 minutes per problem. Essentially, this classic method solves just 4 problems less than AlphaGeometry and establishes the first fully symbolic baseline strong enough to rival the performance of an IMO silver medalist. (ii) Wu's method even solves 2 of the 5 problems that AlphaGeometry failed to solve. Thus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art for automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the first AI method which outperforms an IMO gold medalist.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Apprentices to Research Assistants: Advancing Research with Large  Language Models</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06404">https://arxiv.org/abs/2404.06404</a></p>
  <p><b>作者</b>：M. Namvarpour,  A. Razi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, emerged as powerful, powerful tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have emerged as powerful tools in various research domains. This article examines their potential through a literature review and firsthand experimentation. While LLMs offer benefits like cost-effectiveness and efficiency, challenges such as prompt tuning, biases, and subjectivity must be addressed. The study presents insights from experiments utilizing LLMs for qualitative analysis, highlighting successes and limitations. Additionally, it discusses strategies for mitigating challenges, such as prompt optimization techniques and leveraging human expertise. This study aligns with the 'LLMs as Research Tools' workshop's focus on integrating LLMs into HCI data work critically and ethically. By addressing both opportunities and challenges, our work contributes to the ongoing dialogue on their responsible application in research.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：MuPT: A Generative Symbolic Music Pretrained Transformer</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06393">https://arxiv.org/abs/2404.06393</a></p>
  <p><b>作者</b>：Xingwei Qu,  Yuelin Bai,  Yinghao Ma,  Ziya Zhou,  Ka Man Lo,  Jiaheng Liu,  Ruibin Yuan,  Lejun Min,  Xueling Liu,  Tianyu Zhang,  Xinrun Du,  Shuyue Guo,  Yiming Liang,  Yizhi Li,  Shangda Wu,  Junting Zhou,  Tianyu Zheng,  Ziyang Ma,  Fengze Han,  Wei Xue,  Gus Xia,  Emmanouil Benetos,  Xiang Yue,  Chenghua Lin,  Xu Tan,  Stephen W. Huang,  Wenhu Chen,  Jie Fu,  Ge Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, application of Large, ABC Notation, rack ABC Notation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are inherently more compatible with ABC Notation, which aligns more closely with their design and strengths, thereby enhancing the model's performance in musical composition. To address the challenges associated with misaligned measures from different tracks during generation, we propose the development of a \underline{S}ynchronized \underline{M}ulti-\underline{T}rack ABC Notation (\textbf{SMT-ABC Notation}), which aims to preserve coherence across multiple musical tracks. Our contributions include a series of models capable of handling up to 8192 tokens, covering 90\% of the symbolic music data in our training set. Furthermore, we explore the implications of the \underline{S}ymbolic \underline{M}usic \underline{S}caling Law (\textbf{SMS Law}) on model performance. The results indicate a promising direction for future research in music generation, offering extensive resources for community-led research through our open-source contributions.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Event Extraction in Basque: Typologically motivated Cross-Lingual  Transfer-Learning Analysis</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06392">https://arxiv.org/abs/2404.06392</a></p>
  <p><b>作者</b>：Mikel Zubillaga,  Oscar Sainz,  Ainara Estarrona,  Oier Lopez de Lacalle,  Eneko Agirre</p>
  <p><b>备注</b>：Accepted at LREC-Coling 2024</p>
  <p><b>关键词</b>：Multilingual Language Model, Event Extraction, Language Model, Multilingual Event Extraction, event extraction dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-lingual transfer-learning is widely used in Event Extraction for low-resource languages and involves a Multilingual Language Model that is trained in a source language and applied to the target language. This paper studies whether the typological similarity between source and target languages impacts the performance of cross-lingual transfer, an under-explored topic. We first focus on Basque as the target language, which is an ideal target language because it is typologically different from surrounding languages. Our experiments on three Event Extraction tasks show that the shared linguistic characteristic between source and target languages does have an impact on transfer quality. Further analysis of 72 language pairs reveals that for tasks that involve token classification such as entity and event trigger identification, common writing script and morphological features produce higher quality cross-lingual transfer. In contrast, for tasks involving structural prediction like argument extraction, common word order is the most relevant feature. In addition, we show that when increasing the training size, not all the languages scale in the same way in the cross-lingual setting. To perform the experiments we introduce EusIE, an event extraction dataset for Basque, which follows the Multilingual Event Extraction dataset (MEE). The dataset and code are publicly available.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Enhancing Decision Analysis with a Large Language Model: pyDecision a  Comprehensive Library of MCDA Methods in Python</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06370">https://arxiv.org/abs/2404.06370</a></p>
  <p><b>作者</b>：Valdecy Pereira,  Marcio Pereira Basilio,  Carlos Henrique Tarjano SantosCarlos Henrique Tarjano Santos</p>
  <p><b>备注</b>：23 pages, 2 figures</p>
  <p><b>关键词</b>：Multicriteria decision analysis, Multicriteria decision, MCDA methods, MCDA, decision analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: Multicriteria decision analysis (MCDA) has become increasingly essential for decision-making in complex environments. In response to this need, the pyDecision library, implemented in Python and available at this https URL, has been developed to provide a comprehensive and accessible collection of MCDA methods. Methods: The pyDecision offers 70 MCDA methods, including AHP, TOPSIS, and the PROMETHEE and ELECTRE families. Beyond offering a vast range of techniques, the library provides visualization tools for more intuitive results interpretation. In addition to these features, pyDecision has integrated ChatGPT, an advanced Large Language Model, where decision-makers can use ChatGPT to discuss and compare the outcomes of different methods, providing a more interactive and intuitive understanding of the solutions. Findings: Large Language Models are undeniably potent but can sometimes be a double-edged sword. Its answers may be misleading without rigorous verification of its outputs, especially for researchers lacking deep domain expertise. It's imperative to approach its insights with a discerning eye and a solid foundation in the relevant field. Originality: With the integration of MCDA methods and ChatGPT, pyDecision is a significant contribution to the scientific community, as it is an invaluable resource for researchers, practitioners, and decision-makers navigating complex decision-making problems and seeking the most appropriate solutions based on MCDA methods.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：VISION2UI: A Real-World Dataset with Layout for Code Generation from UI  Designs</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06369">https://arxiv.org/abs/2404.06369</a></p>
  <p><b>作者</b>：Yi Gui,  Zhen Li,  Yao Wan,  Yemin Shi,  Hongyu Zhang,  Yi Su,  Shaoling Dong,  Xing Zhou,  Wenbin Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：directly generate Web, generate Web pages, enabling beginner developers, generate Web, Web pages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically generating UI code from webpage design visions can significantly alleviate the burden of developers, enabling beginner developers or designers to directly generate Web pages from design diagrams. Currently, prior research has accomplished the objective of generating UI code from rudimentary design visions or sketches through designing deep neural networks. Inspired by the groundbreaking advancements achieved by Multimodal Large Language Models (MLLMs), the automatic generation of UI code from high-fidelity design images is now emerging as a viable possibility. Nevertheless, our investigation reveals that existing MLLMs are hampered by the scarcity of authentic, high-quality, and large-scale datasets, leading to unsatisfactory performance in automated UI code generation. To mitigate this gap, we present a novel dataset, termed VISION2UI, extracted from real-world scenarios, augmented with comprehensive layout information, tailored specifically for finetuning MLLMs in UI code generation. Specifically, this dataset is derived through a series of operations, encompassing collecting, cleaning, and filtering of the open-source Common Crawl dataset. In order to uphold its quality, a neural scorer trained on labeled samples is utilized to refine the data, retaining higher-quality instances. Ultimately, this process yields a dataset comprising 2,000 (Much more is coming soon) parallel samples encompassing design visions and UI code. The dataset is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06362">https://arxiv.org/abs/2404.06362</a></p>
  <p><b>作者</b>：Sidra Aleem,  Fangyijie Wang,  Mayug Maniparambil,  Eric Arazo,  Julia Dietlmeier,  Kathleen Curran,  Noel E. O'Connor,  Suzanne Little</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vision foundation models, remarkable vision foundation, SAM, foundation models, remarkable vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Segment Anything Model (SAM) and CLIP are remarkable vision foundation models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation tasks across diverse domains, while CLIP is renowned for its zero shot recognition capabilities. However, their unified potential has not yet been explored in medical image segmentation. To adapt SAM to medical imaging, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. This work presents an in depth exploration of integrating SAM and CLIP into a unified framework for medical image segmentation. Specifically, we propose a simple unified framework, SaLIP, for organ segmentation. Initially, SAM is used for part based segmentation within the image, followed by CLIP to retrieve the mask corresponding to the region of interest (ROI) from the pool of SAM generated masks. Finally, SAM is prompted by the retrieved ROI to segment a specific organ. Thus, SaLIP is training and fine tuning free and does not rely on domain expertise or labeled data for prompt engineering. Our method shows substantial enhancements in zero shot segmentation, showcasing notable improvements in DICE scores across diverse segmentation tasks like brain (63.46%), lung (50.11%), and fetal head (30.82%), when compared to un prompted SAM. Code and text prompts will be available online.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Policy-Guided Diffusion</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06356">https://arxiv.org/abs/2404.06356</a></p>
  <p><b>作者</b>：Matthew Thomas Jackson,  Michael Tryfan Matthews,  Cong Lu,  Benjamin Ellis,  Shimon Whiteson,  Jakob Foerster</p>
  <p><b>备注</b>：Previously at the NeurIPS 2023 Workshop on Robot Learning</p>
  <p><b>关键词</b>：offline dataset gathered, agents must learn, dataset gathered, prior behavior policy, policy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many real-world settings, agents must learn from an offline dataset gathered by some prior behavior policy. Such a setting naturally leads to distribution shift between the behavior policy and the target policy being trained - requiring policy conservatism to avoid instability and overestimation bias. Autoregressive world models offer a different solution to this by generating synthetic, on-policy experience. However, in practice, model rollouts must be severely truncated to avoid compounding error. As an alternative, we propose policy-guided diffusion. Our method uses diffusion models to generate entire trajectories under the behavior distribution, applying guidance from the target policy to move synthetic experience further on-policy. We show that policy-guided diffusion models a regularized form of the target distribution that balances action likelihood under both the target and behavior policies, leading to plausible trajectories with high target policy probability, while retaining a lower dynamics error than an offline world model baseline. Using synthetic experience from policy-guided diffusion as a drop-in substitute for real data, we demonstrate significant improvements in performance across a range of standard offline reinforcement learning algorithms and environments. Our approach provides an effective alternative to autoregressive offline world models, opening the door to the controllable generation of synthetic training data.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：High Noise Scheduling is a Must</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06353">https://arxiv.org/abs/2404.06353</a></p>
  <p><b>作者</b>：Mahmut S. Gokmen,  Cody Bumgardner,  Jie Zhang,  Ge Wang,  Jin Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noise distribution, advancing sampling steps, possess high capabilities, noise, polynomial noise distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Consistency models possess high capabilities for image generation, advancing sampling steps to a single step through their advanced techniques. Current advancements move one step forward consistency training techniques and eliminates the limitation of distillation training. Even though the proposed curriculum and noise scheduling in improved training techniques yield better results than basic consistency models, it lacks well balanced noise distribution and its consistency between curriculum. In this study, it is investigated the balance between high and low noise levels in noise distribution and offered polynomial noise distribution to maintain the stability. This proposed polynomial noise distribution is also supported with a predefined Karras noises to prevent unique noise levels arises with Karras noise generation algorithm. Furthermore, by elimination of learned noisy steps with a curriculum based on sinusoidal function increase the performance of the model in denoising. To make a fair comparison with the latest released consistency model training techniques, experiments are conducted with same hyper-parameters except curriculum and noise distribution. The models utilized during experiments are determined with low depth to prove the robustness of our proposed technique. The results show that the polynomial noise distribution outperforms the model trained with log-normal noise distribution, yielding a 33.54 FID score after 100,000 training steps with constant discretization steps. Additionally, the implementation of a sinusoidal-based curriculum enhances denoising performance, resulting in a FID score of 30.48.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：AgentsCoDriver: Large Language Model Empowered Collaborative Driving  with Lifelong Learning</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06345">https://arxiv.org/abs/2404.06345</a></p>
  <p><b>作者</b>：Senkang Hu,  Zhengru Fang,  Zihan Fang,  Xianhao Chen,  Yuguang Fang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autonomous driving systems, autonomous driving, driving systems, recent years, current autonomous driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Connected and autonomous driving is developing rapidly in recent years. However, current autonomous driving systems, which are primarily based on data-driven approaches, exhibit deficiencies in interpretability, generalization, and continuing learning capabilities. In addition, the single-vehicle autonomous driving systems lack of the ability of collaboration and negotiation with other vehicles, which is crucial for the safety and efficiency of autonomous driving systems. In order to address these issues, we leverage large language models (LLMs) to develop a novel framework, AgentsCoDriver, to enable multiple vehicles to conduct collaborative driving. AgentsCoDriver consists of five modules: observation module, reasoning engine, cognitive memory module, reinforcement reflection module, and communication module. It can accumulate knowledge, lessons, and experiences over time by continuously interacting with the environment, thereby making itself capable of lifelong learning. In addition, by leveraging the communication module, different agents can exchange information and realize negotiation and collaboration in complex traffic environments. Extensive experiments are conducted and show the superiority of AgentsCoDriver.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Generative Pre-Trained Transformer for Symbolic Regression Base  In-Context Reinforcement Learning</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06330">https://arxiv.org/abs/2404.06330</a></p>
  <p><b>作者</b>：Yanjie Li,  Weijun Li,  Lina Yu,  Min Wu,  Jingyi Liu,  Wenqiang Li,  Meilan Hao,  Shu Wei,  Yusong Deng</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：scientific research, Finding mathematical formulas, human language, language to describe, describe nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The mathematical formula is the human language to describe nature and is the essence of scientific research. Finding mathematical formulas from observational data is a major demand of scientific research and a major challenge of artificial intelligence. This area is called symbolic regression. Originally symbolic regression was often formulated as a combinatorial optimization problem and solved using GP or reinforcement learning algorithms. These two kinds of algorithms have strong noise robustness ability and good Versatility. However, inference time usually takes a long time, so the search efficiency is relatively low. Later, based on large-scale pre-training data proposed, such methods use a large number of synthetic data points and expression pairs to train a Generative Pre-Trained Transformer(GPT). Then this GPT can only need to perform one forward propagation to obtain the results, the advantage is that the inference speed is very fast. However, its performance is very dependent on the training data and performs poorly on data outside the training set, which leads to poor noise robustness and Versatility of such methods. So, can we combine the advantages of the above two categories of SR algorithms? In this paper, we propose \textbf{FormulaGPT}, which trains a GPT using massive sparse reward learning histories of reinforcement learning-based SR algorithms as training data. After training, the SR algorithm based on reinforcement learning is distilled into a Transformer. When new test data comes, FormulaGPT can directly generate a "reinforcement learning process" and automatically update the learning policy in context. Tested on more than ten datasets including SRBench, formulaGPT achieves the state-of-the-art performance in fitting ability compared with four baselines. In addition, it achieves satisfactory results in noise robustness, versatility, and inference efficiency.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：What is the $\textit{intrinsic}$ dimension of your binary data? -- and  how to compute it quickly</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06326">https://arxiv.org/abs/2404.06326</a></p>
  <p><b>作者</b>：Tom Hanika,  Tobias Hille</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：analyzing and understanding, ICDM paper Tatti, important aspect, aspect for analyzing, ICDM paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality is an important aspect for analyzing and understanding (high-dimensional) data. In their 2006 ICDM paper Tatti et al. answered the question for a (interpretable) dimension of binary data tables by introducing a normalized correlation dimension. In the present work we revisit their results and contrast them with a concept based notion of intrinsic dimension (ID) recently introduced for geometric data sets. To do this, we present a novel approximation for this ID that is based on computing concepts only up to a certain support value. We demonstrate and evaluate our approximation using all available datasets from Tatti et al., which have between 469 and 41271 extrinsic dimensions.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Automatically Learning HTN Methods from Landmarks</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06325">https://arxiv.org/abs/2404.06325</a></p>
  <p><b>作者</b>：Ruoxi Li,  Dana Nau,  Mark Roberts,  Morgan Fine-Morris</p>
  <p><b>备注</b>：This work has been submitted to FLAIRS-24</p>
  <p><b>关键词</b>：Hierarchical Task Network, Task Network, domain engineer, planning problem, requires a domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hierarchical Task Network (HTN) planning usually requires a domain engineer to provide manual input about how to decompose a planning problem. Even HTN-MAKER, a well-known method-learning algorithm, requires a domain engineer to annotate the tasks with information about what to learn. We introduce CURRICULAMA, an HTN method learning algorithm that completely automates the learning process. It uses landmark analysis to compose annotated tasks and leverages curriculum learning to order the learning of methods from simpler to more complex. This eliminates the need for manual input, resolving a core issue with HTN-MAKER. We prove CURRICULAMA's soundness, and show experimentally that it has a substantially similar convergence rate in learning a complete set of methods to HTN-MAKER.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Dynamic D2D-Assisted Federated Learning over O-RAN: Performance  Analysis, MAC Scheduler, and Asymmetric User Selection</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06324">https://arxiv.org/abs/2404.06324</a></p>
  <p><b>作者</b>：Payam Abdisarabshali,  Kwang Taik Kim,  Michael Langberg,  Weifeng Su,  Seyyedali Hosseinalipour</p>
  <p><b>备注</b>：120 pages, 13 figures</p>
  <p><b>关键词</b>：making static control, static snapshots, making static, wireless channel capacity, Existing studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing studies on federated learning (FL) are mostly focused on system orchestration for static snapshots of the network and making static control decisions (e.g., spectrum allocation). However, real-world wireless networks are susceptible to temporal variations of wireless channel capacity and users' datasets. In this paper, we incorporate multi-granular system dynamics (MSDs) into FL, including (M1) dynamic wireless channel capacity, captured by a set of discrete-time events, called $\mathscr{D}$-Events, and (M2) dynamic datasets of users. The latter is characterized by (M2-a) modeling the dynamics of user's dataset size via an ordinary differential equation and (M2-b) introducing dynamic model drift}, formulated via a partial differential inequality} drawing concrete analytical connections between the dynamics of users' datasets and FL accuracy. We then conduct FL orchestration under MSDs by introducing dynamic cooperative FL with dedicated MAC schedulers (DCLM), exploiting the unique features of open radio access network (O-RAN). DCLM proposes (i) a hierarchical device-to-device (D2D)-assisted model training, (ii) dynamic control decisions through dedicated O-RAN MAC schedulers, and (iii) asymmetric user selection. We provide extensive theoretical analysis to study the convergence of DCLM. We then optimize the degrees of freedom (e.g., user selection and spectrum allocation) in DCLM through a highly non-convex optimization problem. We develop a systematic approach to obtain the solution for this problem, opening the door to solving a broad variety of network-aware FL optimization problems. We show the efficiency of DCLM via numerical simulations and provide a series of future directions.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural  Cellular Automata</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06279">https://arxiv.org/abs/2404.06279</a></p>
  <p><b>作者</b>：Ehsan Pajouheshgar,  Yitao Xu,  Sabine Süsstrunk</p>
  <p><b>备注</b>：9 pages, 12 figures</p>
  <p><b>关键词</b>：Neural Cellular Automata, Cellular Automata, Neural Cellular, NCA models, NCA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Cellular Automata (NCA) is a class of Cellular Automata where the update rule is parameterized by a neural network that can be trained using gradient descent. In this paper, we focus on NCA models used for texture synthesis, where the update rule is inspired by partial differential equations (PDEs) describing reaction-diffusion systems. To train the NCA model, the spatio-termporal domain is discretized, and Euler integration is used to numerically simulate the PDE. However, whether a trained NCA truly learns the continuous dynamic described by the corresponding PDE or merely overfits the discretization used in training remains an open question. We study NCA models at the limit where space-time discretization approaches continuity. We find that existing NCA models tend to overfit the training discretization, especially in the proximity of the initial condition, also called "seed". To address this, we propose a solution that utilizes uniform noise as the initial condition. We demonstrate the effectiveness of our approach in preserving the consistency of NCA dynamics across a wide range of spatio-temporal granularities. Our improved NCA model enables two new test-time interactions by allowing continuous control over the speed of pattern formation and the scale of the synthesized patterns. We demonstrate this new NCA feature in our interactive online demo. Our work reveals that NCA models can learn continuous dynamics and opens new venues for NCA research from a dynamical systems' perspective.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Dimensionality Reduction in Sentence Transformer Vector Databases with  Fast Fourier Transform</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06278">https://arxiv.org/abs/2404.06278</a></p>
  <p><b>作者</b>：Vitaly Bulgakov,  Alec Segal</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：enabling efficient storage, Fast Fourier Transform, faster computation, enabling efficient, efficient storage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality reduction in vector databases is pivotal for streamlining AI data management, enabling efficient storage, faster computation, and improved model performance. This paper explores the benefits of reducing vector database dimensions, with a focus on computational efficiency and overcoming the curse of dimensionality. We introduce a novel application of Fast Fourier Transform (FFT) to dimensionality reduction, a method previously underexploited in this context. By demonstrating its utility across various AI domains, including Retrieval-Augmented Generation (RAG) models and image processing, this FFT-based approach promises to improve data retrieval processes and enhance the efficiency and scalability of AI solutions. The incorporation of FFT may not only optimize operations in real-time processing and recommendation systems but also extend to advanced image processing techniques, where dimensionality reduction can significantly improve performance and analysis efficiency. This paper advocates for the broader adoption of FFT in vector database management, marking a significant stride towards addressing the challenges of data volume and complexity in AI research and applications. Unlike many existing approaches, we directly handle the embedding vectors produced by the model after processing a test input.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：PGTNet: A Process Graph Transformer Network for Remaining Time  Prediction of Business Process Instances</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06267">https://arxiv.org/abs/2404.06267</a></p>
  <p><b>作者</b>：Keyvan Amiri Elyasi,  Han van der Aa,  Heiner Stuckenschmidt</p>
  <p><b>备注</b>：16 pages, 4 figures, To be published in: Advanced Information Systems Engineering - 36th International Conference, CAiSE 2024, Limassol, Cyprus, June 03-07, 2024, Proceedings</p>
  <p><b>关键词</b>：Graph Transformer Networks, Process Graph Transformer, Transformer Networks, leverages graph-oriented data, Graph Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present PGTNet, an approach that transforms event logs into graph datasets and leverages graph-oriented data for training Process Graph Transformer Networks to predict the remaining time of business process instances. PGTNet consistently outperforms state-of-the-art deep learning approaches across a diverse range of 20 publicly available real-world event logs. Notably, our approach is most promising for highly complex processes, where existing deep learning approaches encounter difficulties stemming from their limited ability to learn control-flow relationships among process activities and capture long-range dependencies. PGTNet addresses these challenges, while also being able to consider multiple process perspectives during the learning process.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Playing to Vision Foundation Model's Strengths in Stereo Matching</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06261">https://arxiv.org/abs/2404.06261</a></p>
  <p><b>作者</b>：Chuang-Wei Liu,  Qijun Chen,  Rui Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：environment perception, intelligent vehicles, key technique, perception in intelligent, Stereo matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stereo matching has become a key technique for 3D environment perception in intelligent vehicles. For a considerable time, convolutional neural networks (CNNs) have remained the mainstream choice for feature extraction in this domain. Nonetheless, there is a growing consensus that the existing paradigm should evolve towards vision foundation models (VFM), particularly those developed based on vision Transformers (ViTs) and pre-trained through self-supervision on extensive, unlabeled datasets. While VFMs are adept at extracting informative, general-purpose visual features, specifically for dense prediction tasks, their performance often lacks in geometric vision tasks. This study serves as the first exploration of a viable approach for adapting VFMs to stereo matching. Our ViT adapter, referred to as ViTAS, is constructed upon three types of modules: spatial differentiation, patch attention fusion, and cross-attention. The first module initializes feature pyramids, while the latter two aggregate stereo and multi-scale contextual information into fine-grained features, respectively. ViTAStereo, which combines ViTAS with cost volume-based stereo matching back-end processes, achieves the top rank on the KITTI Stereo 2012 dataset and outperforms the second-best network StereoBase by approximately 7.9% in terms of the percentage of error pixels, with a tolerance of 3 pixels. Additional experiments across diverse scenarios further demonstrate its superior generalizability compared to all other state-of-the-art approaches. We believe this new paradigm will pave the way for the next generation of stereo matching networks.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：GHNeRF: Learning Generalizable Human Features with Efficient Neural  Radiance Fields</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06246">https://arxiv.org/abs/2404.06246</a></p>
  <p><b>作者</b>：Arnab Dey,  Di Yang,  Rohith Agaram,  Antitza Dantcheva,  Andrew I. Comport,  Srinath Sridhar,  Jean Martinet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, Neural Radiance, advances in Neural, demonstrated promising results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in Neural Radiance Fields (NeRF) have demonstrated promising results in 3D scene representations, including 3D human representations. However, these representations often lack crucial information on the underlying human pose and structure, which is crucial for AR/VR applications and games. In this paper, we introduce a novel approach, termed GHNeRF, designed to address these limitations by learning 2D/3D joint locations of human subjects with NeRF representation. GHNeRF uses a pre-trained 2D encoder streamlined to extract essential human features from 2D images, which are then incorporated into the NeRF framework in order to encode human biomechanic features. This allows our network to simultaneously learn biomechanic features, such as joint locations, along with human geometry and texture. To assess the effectiveness of our method, we conduct a comprehensive comparison with state-of-the-art human NeRF techniques and joint estimation algorithms. Our results show that GHNeRF can achieve state-of-the-art results in near real-time.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised  Action Recognition in Videos</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06243">https://arxiv.org/abs/2404.06243</a></p>
  <p><b>作者</b>：Sharana Dharshikgan Suresh Dass,  Hrishav Bakul Barua,  Ganesh Krishnasamy,  Raveendran Paramesran,  Raphael C.-W. Phan</p>
  <p><b>备注</b>：Submitted for peer review</p>
  <p><b>关键词</b>：self-driving cars, sports analytics, surveillance and monitoring, human-robot interaction, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human action or activity recognition in videos is a fundamental task in computer vision with applications in surveillance and monitoring, self-driving cars, sports analytics, human-robot interaction and many more. Traditional supervised methods require large annotated datasets for training, which are expensive and time-consuming to acquire. This work proposes a novel approach using Cross-Architecture Pseudo-Labeling with contrastive learning for semi-supervised action recognition. Our framework leverages both labeled and unlabelled data to robustly learn action representations in videos, combining pseudo-labeling with contrastive learning for effective learning from both types of samples. We introduce a novel cross-architecture approach where 3D Convolutional Neural Networks (3D CNNs) and video transformers (VIT) are utilised to capture different aspects of action representations; hence we call it ActNetFormer. The 3D CNNs excel at capturing spatial features and local dependencies in the temporal domain, while VIT excels at capturing long-range dependencies across frames. By integrating these complementary architectures within the ActNetFormer framework, our approach can effectively capture both local and global contextual information of an action. This comprehensive representation learning enables the model to achieve better performance in semi-supervised action recognition tasks by leveraging the strengths of each of these architectures. Experimental results on standard action recognition datasets demonstrate that our approach performs better than the existing methods, achieving state-of-the-art performance with only a fraction of labeled data. The official website of this work is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Towards Autonomous Driving with Small-Scale Cars: A Survey of Recent  Development</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06229">https://arxiv.org/abs/2404.06229</a></p>
  <p><b>作者</b>：Dianzhao Li,  Paul Auerbach,  Ostap Okhrin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effectively raise awareness, autonomous driving, transformative trend, unfolding revolution, challenge presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While engaging with the unfolding revolution in autonomous driving, a challenge presents itself, how can we effectively raise awareness within society about this transformative trend? While full-scale autonomous driving vehicles often come with a hefty price tag, the emergence of small-scale car platforms offers a compelling alternative. These platforms not only serve as valuable educational tools for the broader public and young generations but also function as robust research platforms, contributing significantly to the ongoing advancements in autonomous driving technology. This survey outlines various small-scale car platforms, categorizing them and detailing the research advancements accomplished through their usage. The conclusion provides proposals for promising future directions in the field.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Low-Cost Generation and Evaluation of Dictionary Example Sentences</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06224">https://arxiv.org/abs/2404.06224</a></p>
  <p><b>作者</b>：Bill Cai,  Clarence Boon Liang Ng,  Daniel Tan,  Shelvia Hotama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：manually creating quality, illustrating word definitions, definitions and usage, play an important, important role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dictionary example sentences play an important role in illustrating word definitions and usage, but manually creating quality sentences is challenging. Prior works have demonstrated that language models can be trained to generate example sentences. However, they relied on costly customized models and word sense datasets for generation and evaluation of their work. Rapid advancements in foundational models present the opportunity to create low-cost, zero-shot methods for the generation and evaluation of dictionary example sentences. We introduce a new automatic evaluation metric called OxfordEval that measures the win-rate of generated sentences against existing Oxford Dictionary sentences. OxfordEval shows high alignment with human judgments, enabling large-scale automated quality evaluation. We experiment with various LLMs and configurations to generate dictionary sentences across word classes. We complement this with a novel approach of using masked language models to identify and select sentences that best exemplify word meaning. The eventual model, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences according to OxfordEval, compared to 39.8% win rate for prior model-generated sentences.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：OmniFusion Technical Report</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06212">https://arxiv.org/abs/2404.06212</a></p>
  <p><b>作者</b>：Elizaveta Goncharova,  Anton Razzhigaev,  Matvey Mikhalchuk,  Maxim Kurkin,  Irina Abdullaeva,  Matvey Skripkin,  Ivan Oseledets,  Denis Dimitrov,  Andrey Kuznetsov</p>
  <p><b>备注</b>：17 pages, 4 figures, 9 tables, 2 appendices</p>
  <p><b>关键词</b>：multimodal architectures served, large language models, extending the capabilities, revolution in AI-based, AI-based approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Last year, multimodal architectures served up a revolution in AI-based approaches and solutions, extending the capabilities of large language models (LLM). We propose an \textit{OmniFusion} model based on a pretrained LLM and adapters for visual modality. We evaluated and compared several architecture design principles for better text and visual data coupling: MLP and transformer adapters, various CLIP ViT-based encoders (SigLIP, InternVIT, etc.), and their fusing approach, image encoding method (whole image or tiles encoding) and two 7B LLMs (the proprietary one and open-source Mistral). Experiments on 8 visual-language benchmarks show the top score for the best OmniFusion setup in terms of different VQA tasks in comparison with open-source LLaVA-like solutions: VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU. We also propose a variety of situations, where OmniFusion provides highly-detailed answers in different domains: housekeeping, sightseeing, culture, medicine, handwritten and scanned equations recognition, etc. Mistral-based OmniFusion model is an open-source solution with weights, training and inference scripts available at this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Elephants Never Forget: Memorization and Learning of Tabular Data in  Large Language Models</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06209">https://arxiv.org/abs/2404.06209</a></p>
  <p><b>作者</b>：Sebastian Bordt,  Harsha Nori,  Vanessa Rodrigues,  Besmira Nushi,  Rich Caruana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown how Large, Large Language, set of tasks, diverse set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While many have shown how Large Language Models (LLMs) can be applied to a diverse set of tasks, the critical issues of data contamination and memorization are often glossed over. In this work, we address this concern for tabular data. Specifically, we introduce a variety of different techniques to assess whether a language model has seen a tabular dataset during training. This investigation reveals that LLMs have memorized many popular tabular datasets verbatim. We then compare the few-shot learning performance of LLMs on datasets that were seen during training to the performance on datasets released after training. We find that LLMs perform better on datasets seen during training, indicating that memorization leads to overfitting. At the same time, LLMs show non-trivial performance on novel datasets and are surprisingly robust to data transformations. We then investigate the in-context statistical learning abilities of LLMs. Without fine-tuning, we find them to be limited. This suggests that much of the few-shot performance on novel datasets is due to the LLM's world knowledge. Overall, our results highlight the importance of testing whether an LLM has seen an evaluation dataset during pre-training. We make the exposure tests we developed available as the tabmemcheck Python package at this https URL</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Open-Source AI-based SE Tools: Opportunities and Challenges of  Collaborative Software Learning</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06201">https://arxiv.org/abs/2404.06201</a></p>
  <p><b>作者</b>：Zhihao Lin,  Wei Ma,  Tao Lin,  Yaowen Zheng,  Jingquan Ge,  Jun Wang,  Jacques Klein,  Tegawende Bissyande,  Yang Liu,  Li Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, showcasing their efficacy, instrumental in advancing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have become instrumental in advancing software engineering (SE) tasks, showcasing their efficacy in code understanding and beyond. Like traditional SE tools, open-source collaboration is key in realising the excellent products. However, with AI models, the essential need is in data. The collaboration of these AI-based SE models hinges on maximising the sources of high-quality data. However, data especially of high quality, often holds commercial or sensitive value, making it less accessible for open-source AI-based SE projects. This reality presents a significant barrier to the development and enhancement of AI-based SE tools within the software engineering community. Therefore, researchers need to find solutions for enabling open-source AI-based SE models to tap into resources by different organisations. Addressing this challenge, our position paper investigates one solution to facilitate access to diverse organizational resources for open-source AI models, ensuring privacy and commercial sensitivities are respected. We introduce a governance framework centered on federated learning (FL), designed to foster the joint development and maintenance of open-source AI code models while safeguarding data privacy and security. Additionally, we present guidelines for developers on AI-based SE tool collaboration, covering data requirements, model architecture, updating strategies, and version control. Given the significant influence of data characteristics on FL, our research examines the effect of code data heterogeneity on FL performance.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Diverse Randomized Value Functions: A Provably Pessimistic Approach for  Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06188">https://arxiv.org/abs/2404.06188</a></p>
  <p><b>作者</b>：Xudong Yu,  Chenjia Bai,  Hongyi Guo,  Changhong Wang,  Zhen Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：faces distributional shift, Offline Reinforcement Learning, Reinforcement Learning, faces distributional, distributional shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline Reinforcement Learning (RL) faces distributional shift and unreliable value estimation, especially for out-of-distribution (OOD) actions. To address this, existing uncertainty-based methods penalize the value function with uncertainty quantification and demand numerous ensemble networks, posing computational challenges and suboptimal outcomes. In this paper, we introduce a novel strategy employing diverse randomized value functions to estimate the posterior distribution of $Q$-values. It provides robust uncertainty quantification and estimates lower confidence bounds (LCB) of $Q$-values. By applying moderate value penalties for OOD actions, our method fosters a provably pessimistic approach. We also emphasize on diversity within randomized value functions and enhance efficiency by introducing a diversity regularization method, reducing the requisite number of networks. These modules lead to reliable value estimation and efficient policy learning from offline data. Theoretical analysis shows that our method recovers the provably efficient LCB-penalty under linear MDP assumptions. Extensive empirical results also demonstrate that our proposed method significantly outperforms baseline methods in terms of performance and parametric efficiency.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Clue-Instruct: Text-Based Clue Generation for Educational Crossword  Puzzles</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06186">https://arxiv.org/abs/2404.06186</a></p>
  <p><b>作者</b>：Andrea Zugarini,  Kamyar Zeinalipour,  Surya Sai Kadali,  Marco Maggini,  Marco Gori,  Leonardo Rigutini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular linguistic games, Large Language Models, students in learning, Large Language, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crossword puzzles are popular linguistic games often used as tools to engage students in learning. Educational crosswords are characterized by less cryptic and more factual clues that distinguish them from traditional crossword puzzles. Despite there exist several publicly available clue-answer pair databases for traditional crosswords, educational clue-answer pairs datasets are missing. In this article, we propose a methodology to build educational clue generation datasets that can be used to instruct Large Language Models (LLMs). By gathering from Wikipedia pages informative content associated with relevant keywords, we use Large Language Models to automatically generate pedagogical clues related to the given input keyword and its context. With such an approach, we created clue-instruct, a dataset containing 44,075 unique examples with text-keyword pairs associated with three distinct crossword clues. We used clue-instruct to instruct different LLMs to generate educational clues from a given input content and keyword. Both human and automatic evaluations confirmed the quality of the generated clues, thus validating the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：EPL: Evidential Prototype Learning for Semi-supervised Medical Image  Segmentation</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06181">https://arxiv.org/abs/2404.06181</a></p>
  <p><b>作者</b>：Yuanpeng He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：current semi-supervised medical, semi-supervised medical segmentation, medical segmentation methods, achieve decent performance, Evidential Prototype Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although current semi-supervised medical segmentation methods can achieve decent performance, they are still affected by the uncertainty in unlabeled data and model predictions, and there is currently a lack of effective strategies that can explore the uncertain aspects of both simultaneously. To address the aforementioned issues, we propose Evidential Prototype Learning (EPL), which utilizes an extended probabilistic framework to effectively fuse voxel probability predictions from different sources and achieves prototype fusion utilization of labeled and unlabeled data under a generalized evidential framework, leveraging voxel-level dual uncertainty masking. The uncertainty not only enables the model to self-correct predictions but also improves the guided learning process with pseudo-labels and is able to feed back into the construction of hidden features. The method proposed in this paper has been experimented on LA, Pancreas-CT and TBAD datasets, achieving the state-of-the-art performance in three different labeled ratios, which strongly demonstrates the effectiveness of our strategy.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06177">https://arxiv.org/abs/2404.06177</a></p>
  <p><b>作者</b>：Yuanpeng He,  Lijian Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uncertainty-based semi-supervised medical, semi-supervised medical segmentation, single uncertainty evaluation, existing uncertainty-based semi-supervised, medical segmentation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the existing uncertainty-based semi-supervised medical segmentation methods have achieved excellent performance, they usually only consider a single uncertainty evaluation, which often fails to solve the problem related to credibility completely. Therefore, based on the framework of evidential deep learning, this paper integrates the evidential predictive results in the cross-region of mixed and original samples to reallocate the confidence degree and uncertainty measure of each voxel, which is realized by emphasizing uncertain information of probability assignments fusion rule of traditional evidence theory. Furthermore, we design a voxel-level asymptotic learning strategy by introducing information entropy to combine with the fused uncertainty measure to estimate voxel prediction more precisely. The model will gradually pay attention to the prediction results with high uncertainty in the learning process, to learn the features that are difficult to master. The experimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the superior performance of our proposed method in comparison with the existing state of the arts.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：CLIP-Embed-KD: Computationally Efficient Knowledge Distillation Using  Embeddings as Teachers</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06170">https://arxiv.org/abs/2404.06170</a></p>
  <p><b>作者</b>：Lakshmi Nair</p>
  <p><b>备注</b>：Short paper - 5 pages; 5 figures</p>
  <p><b>关键词</b>：Contrastive Language-Image Pre-training, improve zero-shot generalization, zero-shot generalization capabilities, Language-Image Pre-training, Contrastive Language-Image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive Language-Image Pre-training (CLIP) has been shown to improve zero-shot generalization capabilities of language and vision models. In this paper, we extend CLIP for efficient knowledge distillation, by utilizing embeddings as teachers. Typical knowledge distillation frameworks require running forward passes through a teacher model, which is often prohibitive in the case of billion or trillion parameter teachers. In these cases, using only the embeddings of the teacher models to guide the distillation can yield significant computational savings. Our preliminary findings show that CLIP-based knowledge distillation with embeddings can outperform full scale knowledge distillation using $9\times$ less memory and $8\times$ less training time. Code available at: this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：scCDCG: Efficient Deep Structural Clustering for single-cell RNA-seq via  Deep Cut-informed Graph Embedding</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06167">https://arxiv.org/abs/2404.06167</a></p>
  <p><b>作者</b>：Ping Xu,  Zhiyuan Ning,  Meng Xiao,  Guihai Feng,  Xin Li,  Yuanchun Zhou,  Pengfei Wang</p>
  <p><b>备注</b>：Accepted as a long paper for the research track at DASFAA 2024</p>
  <p><b>关键词</b>：Single-cell RNA sequencing, offering invaluable insights, RNA sequencing, unraveling cellular heterogeneity, scRNA-seq data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single-cell RNA sequencing (scRNA-seq) is essential for unraveling cellular heterogeneity and diversity, offering invaluable insights for bioinformatics advancements. Despite its potential, traditional clustering methods in scRNA-seq data analysis often neglect the structural information embedded in gene expression profiles, crucial for understanding cellular correlations and dependencies. Existing strategies, including graph neural networks, face challenges in handling the inefficiency due to scRNA-seq data's intrinsic high-dimension and high-sparsity. Addressing these limitations, we introduce scCDCG (single-cell RNA-seq Clustering via Deep Cut-informed Graph), a novel framework designed for efficient and accurate clustering of scRNA-seq data that simultaneously utilizes intercellular high-order structural information. scCDCG comprises three main components: (i) A graph embedding module utilizing deep cut-informed techniques, which effectively captures intercellular high-order structural information, overcoming the over-smoothing and inefficiency issues prevalent in prior graph neural network methods. (ii) A self-supervised learning module guided by optimal transport, tailored to accommodate the unique complexities of scRNA-seq data, specifically its high-dimension and high-sparsity. (iii) An autoencoder-based feature learning module that simplifies model complexity through effective dimension reduction and feature extraction. Our extensive experiments on 6 datasets demonstrate scCDCG's superior performance and efficiency compared to 7 established models, underscoring scCDCG's potential as a transformative tool in scRNA-seq data analysis. Our code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Characterizing Multimodal Long-form Summarization: A Case Study on  Financial Reports</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06162">https://arxiv.org/abs/2404.06162</a></p>
  <p><b>作者</b>：Tianyu Cao,  Natraj Raman,  Danial Dervovic,  Chenhao Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, natural language processing, language models, large language, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large language models (LLMs) expand the power of natural language processing to handle long inputs, rigorous and systematic analyses are necessary to understand their abilities and behavior. A salient application is summarization, due to its ubiquity and controversy (e.g., researchers have declared the death of summarization). In this paper, we use financial report summarization as a case study because financial reports not only are long but also use numbers and tables extensively. We propose a computational framework for characterizing multimodal long-form summarization and investigate the behavior of Claude 2.0/2.1, GPT-4/3.5, and Command. We find that GPT-3.5 and Command fail to perform this summarization task meaningfully. For Claude 2 and GPT-4, we analyze the extractiveness of the summary and identify a position bias in LLMs. This position bias disappears after shuffling the input for Claude, which suggests that Claude has the ability to recognize important information. We also conduct a comprehensive investigation on the use of numeric data in LLM-generated summaries and offer a taxonomy of numeric hallucination. We employ prompt engineering to improve GPT-4's use of numbers with limited success. Overall, our analyses highlight the strong capability of Claude 2 in handling long multimodal inputs compared to GPT-4.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：HFNeRF: Learning Human Biomechanic Features with Neural Radiance Fields</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06152">https://arxiv.org/abs/2404.06152</a></p>
  <p><b>作者</b>：Arnab Dey,  Di Yang,  Antitza Dantcheva,  Jean Martinet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, generalizable Neural Radiance, Neural Radiance, based methods applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent advancements in novel view synthesis, generalizable Neural Radiance Fields (NeRF) based methods applied to human subjects have shown remarkable results in generating novel views from few images. However, this generalization ability cannot capture the underlying structural features of the skeleton shared across all instances. Building upon this, we introduce HFNeRF: a novel generalizable human feature NeRF aimed at generating human biomechanic features using a pre-trained image encoder. While previous human NeRF methods have shown promising results in the generation of photorealistic virtual avatars, such methods lack underlying human structure or biomechanic features such as skeleton or joint information that are crucial for downstream applications including Augmented Reality (AR)/Virtual Reality (VR). HFNeRF leverages 2D pre-trained foundation models toward learning human features in 3D using neural rendering, and then volume rendering towards generating 2D feature maps. We evaluate HFNeRF in the skeleton estimation task by predicting heatmaps as features. The proposed method is fully differentiable, allowing to successfully learn color, geometry, and human skeleton in a simultaneous manner. This paper presents preliminary results of HFNeRF, illustrating its potential in generating realistic virtual avatars with biomechanic features using NeRF.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Differential Privacy for Anomaly Detection: Analyzing the Trade-off  Between Privacy and Explainability</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06144">https://arxiv.org/abs/2404.06144</a></p>
  <p><b>作者</b>：Fatima Ezzeddine,  Mirna Saad,  Omran Ayoub,  Davide Andreoletti,  Martin Gjoreski,  Ihab Sbeity,  Marc Langheinrich,  Silvia Giordano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical process aimed, aimed at identifying, identifying observations, significantly deviate, expected pattern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD), also referred to as outlier detection, is a statistical process aimed at identifying observations within a dataset that significantly deviate from the expected pattern of the majority of the data. Such a process finds wide application in various fields, such as finance and healthcare. While the primary objective of AD is to yield high detection accuracy, the requirements of explainability and privacy are also paramount. The first ensures the transparency of the AD process, while the second guarantees that no sensitive information is leaked to untrusted parties. In this work, we exploit the trade-off of applying Explainable AI (XAI) through SHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform AD with different models and on various datasets, and we thoroughly evaluate the cost of privacy in terms of decreased accuracy and explainability. Our results show that the enforcement of privacy through DP has a significant impact on detection accuracy and explainability, which depends on both the dataset and the considered AD model. We further show that the visual interpretation of explanations is also influenced by the choice of the AD algorithm.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for  Hallucination Detection</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06137">https://arxiv.org/abs/2404.06137</a></p>
  <p><b>作者</b>：Elisei Rykov,  Yana Shishkina,  Kseniia Petrushina,  Kseniia Titova,  Sergey Petrakov,  Alexander Panchenko</p>
  <p><b>备注</b>：12 pages, 10 tables, 3 figures</p>
  <p><b>关键词</b>：hallucination detection task, hallucination detection, detection task, systems developed, encompassing diverse baselines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present our novel systems developed for the SemEval-2024 hallucination detection task. Our investigation spans a range of strategies to compare model predictions with reference standards, encompassing diverse baselines, the refinement of pre-trained encoders through supervised learning, and an ensemble approaches utilizing several high-performing models. Through these explorations, we introduce three distinct methods that exhibit strong performance metrics. To amplify our training data, we generate additional training samples from unlabelled training subset. Furthermore, we provide a detailed comparative analysis of our approaches. Notably, our premier method achieved a commendable 9th place in the competition's model-agnostic track and 17th place in model-aware track, highlighting its effectiveness and potential.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：FLEX: FLEXible Federated Learning Framework</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06127">https://arxiv.org/abs/2404.06127</a></p>
  <p><b>作者</b>：Francisco Herrera,  Daniel Jiménez-López,  Alberto Argente-Garrido,  Nuria Rodríguez-Barroso,  Cristina Zuheros,  Ignacio Aguilera-Martos,  Beatriz Bello,  Mario García-Márquez,  M. Victoria Luzón</p>
  <p><b>备注</b>：Submitted to Information Fusion</p>
  <p><b>关键词</b>：Artificial Intelligence, realm of Artificial, Federated Learning Framework, Federated Learning, Intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of Artificial Intelligence (AI), the need for privacy and security in data processing has become paramount. As AI applications continue to expand, the collection and handling of sensitive data raise concerns about individual privacy protection. Federated Learning (FL) emerges as a promising solution to address these challenges by enabling decentralized model training on local devices, thus preserving data privacy. This paper introduces FLEX: a FLEXible Federated Learning Framework designed to provide maximum flexibility in FL research experiments. By offering customizable features for data distribution, privacy parameters, and communication strategies, FLEX empowers researchers to innovate and develop novel FL techniques. The framework also includes libraries for specific FL implementations including: (1) anomalies, (2) blockchain, (3) adversarial attacks and defences, (4) natural language processing and (5) decision trees, enhancing its versatility and applicability in various domains. Overall, FLEX represents a significant advancement in FL research, facilitating the development of robust and efficient FL applications.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Hierarchical Insights: Exploiting Structural Similarities for Reliable  3D Semantic Segmentation</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06124">https://arxiv.org/abs/2404.06124</a></p>
  <p><b>作者</b>：Mariella Dreissig,  Florian Piewak,  Joschka Boedecker</p>
  <p><b>备注</b>：submitted to IROS 2024</p>
  <p><b>关键词</b>：autonomous driving call, withstand highly diverse, environment perception algorithms, Safety-critical applications, call for robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Safety-critical applications like autonomous driving call for robust 3D environment perception algorithms which can withstand highly diverse and ambiguous surroundings. The predictive performance of any classification model strongly depends on the underlying dataset and the prior knowledge conveyed by the annotated labels. While the labels provide a basis for the learning process, they usually fail to represent inherent relations between the classes - representations, which are a natural element of the human perception system. We propose a training strategy which enables a 3D LiDAR semantic segmentation model to learn structural relationships between the different classes through abstraction. We achieve this by implicitly modeling those relationships through a learning rule for hierarchical multi-label classification (HMC). With a detailed analysis we show, how this training strategy not only improves the model's confidence calibration, but also preserves additional information for downstream tasks like fusion, prediction and planning.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Communication-Efficient Large-Scale Distributed Deep Learning: A  Comprehensive Survey</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06114">https://arxiv.org/abs/2404.06114</a></p>
  <p><b>作者</b>：Feng Liang,  Zhen Zhang,  Haifeng Lu,  Victor C. M. Leung,  Yanyi Guo,  Xiping Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distributed deep learning, large-scale distributed deep, distributed deep, deep learning, large-scale distributed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid growth in the volume of data sets, models, and devices in the domain of deep learning, there is increasing attention on large-scale distributed deep learning. In contrast to traditional distributed deep learning, the large-scale scenario poses new challenges that include fault tolerance, scalability of algorithms and infrastructures, and heterogeneity in data sets, models, and resources. Due to intensive synchronization of models and sharing of data across GPUs and computing nodes during distributed training and inference processes, communication efficiency becomes the bottleneck for achieving high performance at a large scale. This article surveys the literature over the period of 2018-2023 on algorithms and technologies aimed at achieving efficient communication in large-scale distributed deep learning at various levels, including algorithms, frameworks, and infrastructures. Specifically, we first introduce efficient algorithms for model synchronization and communication data compression in the context of large-scale distributed training. Next, we introduce efficient strategies related to resource allocation and task scheduling for use in distributed training and inference. After that, we present the latest technologies pertaining to modern communication infrastructures used in distributed deep learning with a focus on examining the impact of the communication overhead in a large-scale and heterogeneous setting. Finally, we conduct a case study on the distributed training of large language models at a large scale to illustrate how to apply these technologies in real cases. This article aims to offer researchers a comprehensive understanding of the current landscape of large-scale distributed deep learning and to reveal promising future research directions toward communication-efficient solutions in this scope.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Fair Graph Neural Network with Supervised Contrastive Regularization</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06090">https://arxiv.org/abs/2404.06090</a></p>
  <p><b>作者</b>：Mahdi Tavassoli Kejani (UT3),  Fadi Dornaika,  Jean-Michel Loubes (IMT)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made significant advancements, graph neural network, Neural Network Framework, Graph Neural, link prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, Graph Neural Networks (GNNs) have made significant advancements, particularly in tasks such as node classification, link prediction, and graph representation. However, challenges arise from biases that can be hidden not only in the node attributes but also in the connections between entities. Therefore, ensuring fairness in graph neural network learning has become a critical problem. To address this issue, we propose a novel model for training fairness-aware GNN, which enhances the Counterfactual Augmented Fair Graph Neural Network Framework (CAF). Our approach integrates Supervised Contrastive Loss and Environmental Loss to enhance both accuracy and fairness. Experimental validation on three real datasets demonstrates the superiority of our proposed model over CAF and several other existing graph-based learning methods.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Is Your AI Truly Yours? Leveraging Blockchain for Copyrights,  Provenance, and Lineage</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06077">https://arxiv.org/abs/2404.06077</a></p>
  <p><b>作者</b>：Yilin Sai,  Qin Wang,  Guangsheng Yu,  H.M.N. Dilum Bandara,  Shiping Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, ensuring rightful ownership, textsc, IBis, diverse areas</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As Artificial Intelligence (AI) integrates into diverse areas, particularly in content generation, ensuring rightful ownership and ethical use becomes paramount. AI service providers are expected to prioritize responsibly sourcing training data and obtaining licenses from data owners. However, existing studies primarily center on safeguarding static copyrights, which simply treats metadata/datasets as non-fungible items with transferable/trading capabilities, neglecting the dynamic nature of training procedures that can shape an ongoing trajectory.
In this paper, we present \textsc{IBis}, a blockchain-based framework tailored for AI model training workflows. \textsc{IBis} integrates on-chain registries for datasets, licenses and models, alongside off-chain signing services to facilitate collaboration among multiple participants. Our framework addresses concerns regarding data and model provenance and copyright compliance. \textsc{IBis} enables iterative model retraining and fine-tuning, and offers flexible license checks and renewals. Further, \textsc{IBis} provides APIs designed for seamless integration with existing contract management software, minimizing disruptions to established model training processes. We implement \textsc{IBis} using Daml on the Canton blockchain. Evaluation results showcase the feasibility and scalability of \textsc{IBis} across varying numbers of users, datasets, models, and licenses.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：All in One: An Empirical Study of GPT for Few-Shot Aspect-Based  Sentiment Anlaysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06063">https://arxiv.org/abs/2404.06063</a></p>
  <p><b>作者</b>：Baoxing Jiang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：natural language processing, Aspect-Based Sentiment Analysis, highly challenging task, Sentiment Analysis, Generative Pre-trained Transformers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aspect-Based Sentiment Analysis (ABSA) is an indispensable and highly challenging task in natural language processing. Current efforts have focused on specific sub-tasks, making it difficult to comprehensively cover all sub-tasks within the ABSA domain. With the development of Generative Pre-trained Transformers (GPTs), there came inspiration for a one-stop solution to sentiment analysis. In this study, we used GPTs for all sub-tasks of few-shot ABSA while defining a general learning paradigm for this application. We propose the All in One (AiO) model, a simple yet effective two-stage model for all ABSA sub-tasks. In the first stage, a specific backbone network learns the semantic information of the review and generates heuristically enhanced candidates. In the second stage, AiO leverages GPT contextual learning capabilities to generate predictions. The study conducted comprehensive comparative and ablation experiments on five benchmark datasets, and the results show that AiO can effectively handle all ABSA sub-tasks, even with few-shot data.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Greedy-DiM: Greedy Algorithms for Unreasonably Effective Face Morphs</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06025">https://arxiv.org/abs/2404.06025</a></p>
  <p><b>作者</b>：Zander W. Blasingame,  Chen Liu</p>
  <p><b>备注</b>：Initial preprint. Under review</p>
  <p><b>关键词</b>：Face Recognition, Generative Adversarial Network, multiple identities, emerging threat, aim to create</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Morphing attacks are an emerging threat to state-of-the-art Face Recognition (FR) systems, which aim to create a single image that contains the biometric information of multiple identities. Diffusion Morphs (DiM) are a recently proposed morphing attack that has achieved state-of-the-art performance for representation-based morphing attacks. However, none of the existing research on DiMs have leveraged the iterative nature of DiMs and left the DiM model as a black box, treating it no differently than one would a Generative Adversarial Network (GAN) or Varational AutoEncoder (VAE). We propose a greedy strategy on the iterative sampling process of DiM models which searches for an optimal step guided by an identity-based heuristic function. We compare our proposed algorithm against ten other state-of-the-art morphing algorithms using the open-source SYN-MAD 2022 competition dataset. We find that our proposed algorithm is unreasonably effective, fooling all of the tested FR systems with an MMPMR of 100%, outperforming all other morphing algorithms compared.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Band-Attention Modulated RetNet for Face Forgery Detection</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06022">https://arxiv.org/abs/2404.06022</a></p>
  <p><b>作者</b>：Zhida Zhang,  Jie Cao,  Wenkui Yang,  Qihang Fan,  Kai Zhou,  Ran He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：http URL mitigate, efficiently process extensive, process extensive visual, avoiding catastrophic forgetting.Our, catastrophic forgetting.Our approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The transformer networks are extensively utilized in face forgery detection due to their scalability across large datasets.Despite their success, transformers face challenges in balancing the capture of global context, which is crucial for unveiling forgery clues, with computational this http URL mitigate this issue, we introduce Band-Attention modulated RetNet (BAR-Net), a lightweight network designed to efficiently process extensive visual contexts while avoiding catastrophic forgetting.Our approach empowers the target token to perceive global information by assigning differential attention levels to tokens at varying distances. We implement self-attention along both spatial axes, thereby maintaining spatial priors and easing the computational burden.Moreover, we present the adaptive frequency Band-Attention Modulation mechanism, which treats the entire Discrete Cosine Transform spectrogram as a series of frequency bands with learnable weights.Together, BAR-Net achieves favorable performance on several face forgery datasets, outperforming current state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Using 3-Objective Evolutionary Algorithms for the Dynamic Chance  Constrained Knapsack Problem</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06014">https://arxiv.org/abs/2404.06014</a></p>
  <p><b>作者</b>：Ishara Hewa Pathiranage,  Frank Neumann,  Denis Antipov,  Aneta Neumann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Real-world optimization problems, Evolutionary algorithms, Real-world optimization, constrained knapsack problem, Evolutionary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world optimization problems often involve stochastic and dynamic components. Evolutionary algorithms are particularly effective in these scenarios, as they can easily adapt to uncertain and changing environments but often uncertainty and dynamic changes are studied in isolation. In this paper, we explore the use of 3-objective evolutionary algorithms for the chance constrained knapsack problem with dynamic constraints. In our setting, the weights of the items are stochastic and the knapsack's capacity changes over time. We introduce a 3-objective formulation that is able to deal with the stochastic and dynamic components at the same time and is independent of the confidence level required for the constraint. This new approach is then compared to the 2-objective formulation which is limited to a single confidence level. We evaluate the approach using two different multi-objective evolutionary algorithms (MOEAs), namely the global simple evolutionary multi-objective optimizer (GSEMO) and the multi-objective evolutionary algorithm based on decomposition (MOEA/D), across various benchmark scenarios. Our analysis highlights the advantages of the 3-objective formulation over the 2-objective formulation in addressing the dynamic chance constrained knapsack problem.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Collaborative Edge AI Inference over Cloud-RAN</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06007">https://arxiv.org/abs/2404.06007</a></p>
  <p><b>作者</b>：Pengfei Zhang,  Dingzhu Wen,  Guangxu Zhu,  Qimei Chen,  Kaifeng Han,  Yuanming Shi</p>
  <p><b>备注</b>：This paper is accepted by IEEE Transactions on Communications on 08-Apr-2024</p>
  <p><b>关键词</b>：based collaborative edge, radio access network, cloud radio access, local feature vectors, access network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a cloud radio access network (Cloud-RAN) based collaborative edge AI inference architecture is proposed. Specifically, geographically distributed devices capture real-time noise-corrupted sensory data samples and extract the noisy local feature vectors, which are then aggregated at each remote radio head (RRH) to suppress sensing noise. To realize efficient uplink feature aggregation, we allow each RRH receives local feature vectors from all devices over the same resource blocks simultaneously by leveraging an over-the-air computation (AirComp) technique. Thereafter, these aggregated feature vectors are quantized and transmitted to a central processor (CP) for further aggregation and downstream inference tasks. Our aim in this work is to maximize the inference accuracy via a surrogate accuracy metric called discriminant gain, which measures the discernibility of different classes in the feature space. The key challenges lie on simultaneously suppressing the coupled sensing noise, AirComp distortion caused by hostile wireless channels, and the quantization error resulting from the limited capacity of fronthaul links. To address these challenges, this work proposes a joint transmit precoding, receive beamforming, and quantization error control scheme to enhance the inference accuracy. Extensive numerical experiments demonstrate the effectiveness and superiority of our proposed optimization algorithm compared to various baselines.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation  of Large Language Models</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06003">https://arxiv.org/abs/2404.06003</a></p>
  <p><b>作者</b>：Zhuohao Yu,  Chang Gao,  Wenjin Yao,  Yidong Wang,  Zhengran Zeng,  Wei Ye,  Jindong Wang,  Yue Zhang,  Shikun Zhang</p>
  <p><b>备注</b>：We open-source all our code at: this https URL</p>
  <p><b>关键词</b>：large language model, language model, rapid development, development of large, large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid development of large language model (LLM) evaluation methodologies and datasets has led to a profound challenge: integrating state-of-the-art evaluation techniques cost-effectively while ensuring reliability, reproducibility, and efficiency. Currently, there is a notable absence of a unified and adaptable framework that seamlessly integrates various evaluation approaches. Moreover, the reliability of evaluation findings is often questionable due to potential data contamination, with the evaluation efficiency commonly overlooked when facing the substantial costs associated with LLM inference. In response to these challenges, we introduce FreeEval, a modular and scalable framework crafted to enable trustworthy and efficient automatic evaluations of LLMs. Firstly, FreeEval's unified abstractions simplify the integration and improve the transparency of diverse evaluation methodologies, encompassing dynamic evaluation that demand sophisticated LLM interactions. Secondly, the framework integrates meta-evaluation techniques like human evaluation and data contamination detection, which, along with dynamic evaluation modules in the platform, enhance the fairness of the evaluation outcomes. Lastly, FreeEval is designed with a high-performance infrastructure, including distributed computation and caching strategies, enabling extensive evaluations across multi-node, multi-GPU clusters for open-source and proprietary LLMs.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Automatic Authorities: Power and AI</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05990">https://arxiv.org/abs/2404.05990</a></p>
  <p><b>作者</b>：Seth Lazar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, diminished neoliberal state, potent corporations meet, advances in Artificial, neoliberal state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As rapid advances in Artificial Intelligence and the rise of some of history's most potent corporations meet the diminished neoliberal state, people are increasingly subject to power exercised by means of automated systems. Machine learning and related computational technologies now underpin vital government services. They connect consumers and producers in new algorithmic markets. They determine how we find out about everything from how to vote to where to get vaccinated, and whose speech is amplified, reduced, or restricted. And a new wave of products based on Large Language Models (LLMs) will further transform our economic and political lives. Automatic Authorities are automated computational systems used to exercise power over us by determining what we may know, what we may have, and what our options will be. In response to their rise, scholars working on the societal impacts of AI and related technologies have advocated shifting attention from how to make AI systems beneficial or fair towards a critical analysis of these new power relations. But power is everywhere, and is not necessarily bad. On what basis should we object to new or intensified power relations, and what can be done to justify them? This paper introduces the philosophical materials with which to formulate these questions, and offers preliminary answers. It starts by pinning down the concept of power, focusing on the ability that some agents have to shape others' lives. It then explores how AI enables and intensifies the exercise of power so understood, and sketches three problems with power and three ways to solve those problems. It emphasises, in particular, that justifying power requires more than satisfying substantive justificatory criteria; standards of proper authority and procedural legitimacy must also be met. We need to know not only what power may be used for, but how it may be used, and by whom.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Tackling Structural Hallucination in Image Translation with Local  Diffusion</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05980">https://arxiv.org/abs/2404.05980</a></p>
  <p><b>作者</b>：Seunghoi Kim,  Chen Jin,  Tom Diethe,  Matteo Figini,  Henry F. J. Tregidgo,  Asher Mullokandov,  Philip Teare,  Daniel C. Alexander</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced conditioned image, OOD, Recent developments, struggle with reconstructing, local OOD regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent developments in diffusion models have advanced conditioned image generation, yet they struggle with reconstructing out-of-distribution (OOD) images, such as unseen tumors in medical images, causing ``image hallucination'' and risking misdiagnosis. We hypothesize such hallucinations result from local OOD regions in the conditional images. We verify that partitioning the OOD region and conducting separate image generations alleviates hallucinations in several applications. From this, we propose a training-free diffusion framework that reduces hallucination with multiple Local Diffusion processes. Our approach involves OOD estimation followed by two modules: a ``branching'' module generates locally both within and outside OOD regions, and a ``fusion'' module integrates these predictions into one. Our evaluation shows our method mitigates hallucination over baseline models quantitatively and qualitatively, reducing misdiagnosis by 40% and 25% in the real-world medical and natural image datasets, respectively. It also demonstrates compatibility with various pre-trained diffusion models.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Does Transformer Interpretability Transfer to RNNs?</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05971">https://arxiv.org/abs/2404.05971</a></p>
  <p><b>作者</b>：Gonçalo Paulo,  Thomas Marshall,  Nora Belrose</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Mamba and RWKV, neural network architectures, recurrent neural network, language modeling perplexity, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in recurrent neural network architectures, such as Mamba and RWKV, have enabled RNNs to match or exceed the performance of equal-size transformers in terms of language modeling perplexity and downstream evaluations, suggesting that future systems may be built on completely new architectures. In this paper, we examine if selected interpretability methods originally designed for transformer language models will transfer to these up-and-coming recurrent architectures. Specifically, we focus on steering model outputs via contrastive activation addition, on eliciting latent predictions via the tuned lens, and eliciting latent knowledge from models fine-tuned to produce false outputs under certain conditions. Our results show that most of these techniques are effective when applied to RNNs, and we show that it is possible to improve some of them by taking advantage of RNNs' compressed state.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：JSTR: Judgment Improves Scene Text Recognition</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05967">https://arxiv.org/abs/2404.05967</a></p>
  <p><b>作者</b>：Masato Fujitake</p>
  <p><b>备注</b>：IntelliSys 2024</p>
  <p><b>关键词</b>：text recognition tasks, scene text recognition, text recognition, text recognition accuracy, tasks by judging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a method for enhancing the accuracy of scene text recognition tasks by judging whether the image and text match each other. While previous studies focused on generating the recognition results from input images, our approach also considers the model's misrecognition results to understand its error tendencies, thus improving the text recognition pipeline. This method boosts text recognition accuracy by providing explicit feedback on the data that the model is likely to misrecognize by predicting correct or incorrect between the image and text. The experimental results on publicly available datasets demonstrate that our proposed method outperforms the baseline and state-of-the-art methods in scene text recognition.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：THOUGHTSCULPT: Reasoning with Intermediate Revision and Search</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05966">https://arxiv.org/abs/2404.05966</a></p>
  <p><b>作者</b>：Yizhou Chi,  Kevin Yang,  Dan Klein</p>
  <p><b>备注</b>：Code and data available at this https URL</p>
  <p><b>关键词</b>：Monte Carlo Tree, Carlo Tree Search, decomposed into components, Story Outline Improvement, present THOUGHTSCULPT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present THOUGHTSCULPT, a general reasoning and search method for tasks with outputs that can be decomposed into components. THOUGHTSCULPT explores a search tree of potential solutions using Monte Carlo Tree Search (MCTS), building solutions one action at a time and evaluating according to any domain-specific heuristic, which in practice is often simply an LLM evaluator. Critically, our action space includes revision actions: THOUGHTSCULPT may choose to revise part of its previous output rather than continuing to build the rest of its output. Empirically, THOUGHTSCULPT outperforms state-of-the-art reasoning methods across three challenging tasks: Story Outline Improvement (up to +30% interestingness), Mini-Crosswords Solving (up to +16% word success rate), and Constrained Generation (up to +10% concept coverage).</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05961">https://arxiv.org/abs/2404.05961</a></p>
  <p><b>作者</b>：Parishad BehnamGhader,  Vaibhav Adlakha,  Marius Mosbach,  Dzmitry Bahdanau,  Nicolas Chapados,  Siva Reddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：today NLP tasks, today NLP, NLP tasks, NLP, Text Embeddings Benchmark</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large decoder-only language models (LLMs) are the state-of-the-art models on most of today's NLP tasks and benchmarks. Yet, the community is only slowly adopting these models for text embedding tasks, which require rich contextualized representations. In this work, we introduce LLM2Vec, a simple unsupervised approach that can transform any decoder-only LLM into a strong text encoder. LLM2Vec consists of three simple steps: 1) enabling bidirectional attention, 2) masked next token prediction, and 3) unsupervised contrastive learning. We demonstrate the effectiveness of LLM2Vec by applying it to 3 popular LLMs ranging from 1.3B to 7B parameters and evaluate the transformed models on English word- and sequence-level tasks. We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB). Moreover, when combining LLM2Vec with supervised contrastive learning, we achieve state-of-the-art performance on MTEB among models that train only on publicly available data. Our strong empirical results and extensive analysis demonstrate that LLMs can be effectively transformed into universal text encoders in a parameter-efficient manner without the need for expensive adaptation or synthetic GPT-4 generated data.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page  Understanding and Grounding?</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05955">https://arxiv.org/abs/2404.05955</a></p>
  <p><b>作者</b>：Junpeng Liu,  Yifan Song,  Bill Yuchen Lin,  Wai Lam,  Graham Neubig,  Yuanzhi Li,  Xiang Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language models, Multimodal Large Language, Large Language, Language models, web domain remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal Large Language models (MLLMs) have shown promise in web-related tasks, but evaluating their performance in the web domain remains a challenge due to the lack of comprehensive benchmarks. Existing benchmarks are either designed for general multimodal tasks, failing to capture the unique characteristics of web pages, or focus on end-to-end web agent tasks, unable to measure fine-grained abilities such as OCR, understanding, and grounding. In this paper, we introduce \bench{}, a multimodal benchmark designed to assess the capabilities of MLLMs across a variety of web tasks. \bench{} consists of seven tasks, and comprises 1.5K human-curated instances from 139 real websites, covering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3 series, and GPT-4V(ision) on \bench{}, revealing significant challenges and performance gaps. Further analysis highlights the limitations of current MLLMs, including inadequate grounding in text-rich environments and subpar performance with low-resolution image inputs. We believe \bench{} will serve as a valuable resource for the research community and contribute to the creation of more powerful and versatile MLLMs for web-related applications.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Efficient Multi-Task Reinforcement Learning via Task-Specific Action  Correction</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05950">https://arxiv.org/abs/2404.05950</a></p>
  <p><b>作者</b>：Jinyuan Feng,  Min Chen,  Zhiqiang Pu,  Tenghai Qiu,  Jianqiang Yi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-task reinforcement learning, multiple tasks concurrently, perform multiple tasks, Multi-task reinforcement, potential for enhancing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-task reinforcement learning (MTRL) demonstrate potential for enhancing the generalization of a robot, enabling it to perform multiple tasks concurrently. However, the performance of MTRL may still be susceptible to conflicts between tasks and negative interference. To facilitate efficient MTRL, we propose Task-Specific Action Correction (TSAC), a general and complementary approach designed for simultaneous learning of multiple tasks. TSAC decomposes policy learning into two separate policies: a shared policy (SP) and an action correction policy (ACP). To alleviate conflicts resulting from excessive focus on specific tasks' details in SP, ACP incorporates goal-oriented sparse rewards, enabling an agent to adopt a long-term perspective and achieve generalization across tasks. Additional rewards transform the original problem into a multi-objective MTRL problem. Furthermore, to convert the multi-objective MTRL into a single-objective formulation, TSAC assigns a virtual expected budget to the sparse rewards and employs Lagrangian method to transform a constrained single-objective optimization into an unconstrained one. Experimental evaluations conducted on Meta-World's MT10 and MT50 benchmarks demonstrate that TSAC outperforms existing state-of-the-art methods, achieving significant improvements in both sample efficiency and effective action execution.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Interplay of Machine Translation, Diacritics, and Diacritization</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05943">https://arxiv.org/abs/2404.05943</a></p>
  <p><b>作者</b>：Wei-Rui Chen,  Ife Adebara,  Muhammad Abdul-Mageed</p>
  <p><b>备注</b>：Accepted to NAACL 2024 Main Conference</p>
  <p><b>关键词</b>：multi-task learning setting, machine translation, effect of keeping, multi-task learning, research questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate two research questions: (1) how do machine translation (MT) and diacritization influence the performance of each other in a multi-task learning setting (2) the effect of keeping (vs. removing) diacritics on MT performance. We examine these two questions in both high-resource (HR) and low-resource (LR) settings across 55 different languages (36 African languages and 19 European languages). For (1), results show that diacritization significantly benefits MT in the LR scenario, doubling or even tripling performance for some languages, but harms MT in the HR scenario. We find that MT harms diacritization in LR but benefits significantly in HR for some languages. For (2), MT performance is similar regardless of diacritics being kept or removed. In addition, we propose two classes of metrics to measure the complexity of a diacritical system, finding these metrics to correlate positively with the performance of our diacritization models. Overall, our work provides insights for developing MT and diacritization systems under different data size conditions and may have implications that generalize beyond the 55 languages we investigate.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Inclusive Practices for Child-Centered AI Design and Testing</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05920">https://arxiv.org/abs/2404.05920</a></p>
  <p><b>作者</b>：Emani Dotch,  Vitica Arnold</p>
  <p><b>备注</b>：CHI 2024 Workshop on Child-centred AI Design, May 11, 2024, Honolulu, HI, USA</p>
  <p><b>关键词</b>：artificially intelligent technologies, child-centered artificially intelligent, neurodivergent children, inclusive practices, artificially intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We explore ideas and inclusive practices for designing and testing child-centered artificially intelligent technologies for neurodivergent children. AI is promising for supporting social communication, self-regulation, and sensory processing challenges common for neurodivergent children. The authors, both neurodivergent individuals and related to neurodivergent people, draw from their professional and personal experiences to offer insights on creating AI technologies that are accessible and include input from neurodivergent children. We offer ideas for designing AI technologies for neurodivergent children and considerations for including them in the design process while accounting for their sensory sensitivities. We conclude by emphasizing the importance of adaptable and supportive AI technologies and design processes and call for further conversation to refine child-centered AI design and testing methods.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Deep Reinforcement Learning for Personalized Diagnostic Decision  Pathways Using Electronic Health Records: A Comparative Study on Anemia and  Systemic Lupus Erythematosus</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05913">https://arxiv.org/abs/2404.05913</a></p>
  <p><b>作者</b>：Lillian Muyama,  Antoine Neuraz,  Adrien Coulet</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2305.06295</p>
  <p><b>关键词</b>：colleges of experts, typically reached, series of steps, steps recommended, authored by colleges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background: Clinical diagnosis is typically reached by following a series of steps recommended by guidelines authored by colleges of experts. Accordingly, guidelines play a crucial role in rationalizing clinical decisions but suffer from limitations as they are built to cover the majority of the population and fail at covering patients with uncommon conditions. Moreover, their updates are long and expensive, making them unsuitable for emerging diseases and practices.
Methods: Inspired by guidelines, we formulate the task of diagnosis as a sequential decision-making problem and study the use of Deep Reinforcement Learning (DRL) algorithms to learn the optimal sequence of actions to perform in order to obtain a correct diagnosis from Electronic Health Records (EHRs). We apply DRL on synthetic, but realistic EHRs and develop two clinical use cases: Anemia diagnosis, where the decision pathways follow the schema of a decision tree; and Systemic Lupus Erythematosus (SLE) diagnosis, which follows a weighted criteria score. We particularly evaluate the robustness of our approaches to noisy and missing data since these frequently occur in EHRs.
Results: In both use cases, and in the presence of imperfect data, our best DRL algorithms exhibit competitive performance when compared to the traditional classifiers, with the added advantage that they enable the progressive generation of a pathway to the suggested diagnosis which can both guide and explain the decision-making process.
Conclusion: DRL offers the opportunity to learn personalized decision pathways to diagnosis. We illustrate with our two use cases their advantages: they generate step-by-step pathways that are self-explanatory; and their correctness is competitive when compared to state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Interpretability in Symbolic Regression: a benchmark of Explanatory  Methods using the Feynman data set</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05908">https://arxiv.org/abs/2404.05908</a></p>
  <p><b>作者</b>：Guilherme Seidyo Imai Aldeia,  Fabricio Olivetti de Franca (Federal University of ABC)</p>
  <p><b>备注</b>：47 pages, 10 figures. This is a post peer-review, pre-copyedit version of an article published in Genetic Programming and Evolvable Machines Volume 23, pages 309-349, (2022). The final version is available on this https URL</p>
  <p><b>关键词</b>：machine learning models, learning models plays, models, symbolic regression models, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In some situations, the interpretability of the machine learning models plays a role as important as the model accuracy. Interpretability comes from the need to trust the prediction model, verify some of its properties, or even enforce them to improve fairness. Many model-agnostic explanatory methods exists to provide explanations for black-box models. In the regression task, the practitioner can use white-boxes or gray-boxes models to achieve more interpretable results, which is the case of symbolic regression. When using an explanatory method, and since interpretability lacks a rigorous definition, there is a need to evaluate and compare the quality and different explainers. This paper proposes a benchmark scheme to evaluate explanatory methods to explain regression models, mainly symbolic regression models. Experiments were performed using 100 physics equations with different interpretable and non-interpretable regression methods and popular explanation methods, evaluating the performance of the explainers performance with several explanation measures. In addition, we further analyzed four benchmarks from the GP community. The results have shown that Symbolic Regression models can be an interesting alternative to white-box and black-box models that is capable of returning accurate models with appropriate explanations. Regarding the explainers, we observed that Partial Effects and SHAP were the most robust explanation models, with Integrated Gradients being unstable only with tree-based models. This benchmark is publicly available for further experiments.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Natural Learning</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05903">https://arxiv.org/abs/2404.05903</a></p>
  <p><b>作者</b>：Hadi Fanaee-T</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：introduce Natural Learning, Natural Learning, introduce Natural, extreme level, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Natural Learning (NL), a novel algorithm that elevates the explainability and interpretability of machine learning to an extreme level. NL simplifies decisions into intuitive rules, like "We rejected your loan because your income, employment status, and age collectively resemble a rejected prototype more than an accepted prototype." When applied to real-life datasets, NL produces impressive results. For example, in a colon cancer dataset with 1545 patients and 10935 genes, NL achieves 98.1% accuracy, comparable to DNNs and RF, by analyzing just 3 genes of test samples against 2 discovered prototypes. Similarly, in the UCI's WDBC dataset, NL achieves 98.3% accuracy using only 7 features and 2 prototypes. Even on the MNIST dataset (0 vs. 1), NL achieves 99.5% accuracy with only 3 pixels from 2 prototype images. NL is inspired by prototype theory, an old concept in cognitive psychology suggesting that people learn single sparse prototypes to categorize objects. Leveraging this relaxed assumption, we redesign Support Vector Machines (SVM), replacing its mathematical formulation with a fully nearest-neighbor-based solution, and to address the curse of dimensionality, we utilize locality-sensitive hashing. Following theory's generalizability principle, we propose a recursive method to prune non-core features. As a result, NL efficiently discovers the sparsest prototypes in O(n^2pL) with high parallelization capacity in terms of n. Evaluation of NL with 17 benchmark datasets shows its significant outperformance compared to decision trees and logistic regression, two methods widely favored in healthcare for their interpretability. Moreover, NL achieves performance comparable to finetuned black-box models such as deep neural networks and random forests in 40% of cases, with only a 1-2% lower average accuracy. The code is available via this http URL.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05902">https://arxiv.org/abs/2404.05902</a></p>
  <p><b>作者</b>：Michael Lutz,  Arth Bohra,  Manvel Saroyan,  Artem Harutyunyan,  Giovanni Campagna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieving both generalization, challenging problem, generalization and accuracy, accuracy remains, remains a challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of web agent research, achieving both generalization and accuracy remains a challenging problem. Due to high variance in website structure, existing approaches often fail. Moreover, existing fine-tuning and in-context learning techniques fail to generalize across multiple websites. We introduce Wilbur, an approach that uses a differentiable ranking model and a novel instruction synthesis technique to optimally populate a black-box large language model's prompt with task demonstrations from previous runs. To maximize end-to-end success rates, we also propose an intelligent backtracking mechanism that learns and recovers from its mistakes. Finally, we show that our ranking model can be trained on data from a generative auto-curriculum which samples representative goals from an LLM, runs the agent, and automatically evaluates it, with no manual annotation. Wilbur achieves state-of-the-art results on the WebVoyager benchmark, beating text-only models by 8% overall, and up to 36% on certain websites. On the same benchmark, Wilbur is within 5% of a strong multi-modal model despite only receiving textual inputs, and further analysis reveals a substantial number of failures are due to engineering challenges of operating the web.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Learning Heuristics for Transit Network Design and Improvement with Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05894">https://arxiv.org/abs/2404.05894</a></p>
  <p><b>作者</b>：Andrew Holliday,  Ahmed El-Geneidy,  Gregory Dudek</p>
  <p><b>备注</b>：In preparation for submission to the journal "Transportation Research Part C"</p>
  <p><b>关键词</b>：face tightening budgets, agencies world-wide face, world-wide face tightening, Transit agencies world-wide, tightening budgets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transit agencies world-wide face tightening budgets. To maintain quality of service while cutting costs, efficient transit network design is essential. But planning a network of public transit routes is a challenging optimization problem. The most successful approaches to date use metaheuristic algorithms to search through the space of solutions by applying low-level heuristics that randomly alter routes in a network. The design of these low-level heuristics has a major impact on the quality of the result. In this paper we use deep reinforcement learning with graph neural nets to learn low-level heuristics for an evolutionary algorithm, instead of designing them manually. These learned heuristics improve the algorithm's results on benchmark synthetic cities with 70 nodes or more, and obtain state-of-the-art results when optimizing operating costs. They also improve upon a simulation of the real transit network in the city of Laval, Canada, by as much as 54% and 18% on two key metrics, and offer cost savings of up to 12% over the city's existing transit network.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Use of a Structured Knowledge Base Enhances Metadata Curation by Large  Language Models</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05893">https://arxiv.org/abs/2404.05893</a></p>
  <p><b>作者</b>：Sowmya S. Sundaram,  Benjamin Solomon,  Avani Khatri,  Anisha Laumas,  Purvesh Khatri,  Mark A. Musen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ensuring the findability, reusability of datasets, play a crucial, crucial role, role in ensuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Metadata play a crucial role in ensuring the findability, accessibility, interoperability, and reusability of datasets. This paper investigates the potential of large language models (LLMs), specifically GPT-4, to improve adherence to metadata standards. We conducted experiments on 200 random data records describing human samples relating to lung cancer from the NCBI BioSample repository, evaluating GPT-4's ability to suggest edits for adherence to metadata standards. We computed the adherence accuracy of field name-field value pairs through a peer review process, and we observed a marginal average improvement in adherence to the standard data dictionary from 79% to 80% (p<0.01). we then prompted gpt-4 with domain information in the form of textual descriptions cedar templates and recorded a significant improvement to 97% from 79% (p<0.01). these results indicate that, while llms may not be able correct legacy metadata ensure satisfactory adherence standards when unaided, they do show promise for use automated curation integrated structured knowledge base.< p>
  </0.01).></p></details>
</details>
<details>
  <summary>78. <b>标题：Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05892">https://arxiv.org/abs/2404.05892</a></p>
  <p><b>作者</b>：Bo Peng,  Daniel Goldstein,  Quentin Anthony,  Alon Albalak,  Eric Alcaide,  Stella Biderman,  Eugene Cheah,  Teddy Ferdinan,  Haowen Hou,  Przemysław Kazienko,  Kranthi Kiran GV,  Jan Kocoń,  Bartłomiej Koptyra,  Satyapriya Krishna,  Ronald McClelland Jr.,  Niklas Muennighoff,  Fares Obeid,  Atsushi Saito,  Guangyu Song,  Haoqin Tu,  Stanisław Woźniak,  Ruichong Zhang,  Bingchen Zhao,  Qihang Zhao,  Peng Zhou,  Jian Zhu,  Rui-Jie Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sequence models improving, https URL, present Eagle, RWKV, https URL Time-parallel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of benchmarks. We release all our models on HuggingFace under the Apache 2.0 license. Models at: this https URL Training code at: this https URL Inference code at: this https URL Time-parallel training code at: this https URL</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：CodecLM: Aligning Language Models with Tailored Synthetic Data</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05875">https://arxiv.org/abs/2404.05875</a></p>
  <p><b>作者</b>：Zifeng Wang,  Chun-Liang Li,  Vincent Perot,  Long T. Le,  Jin Miao,  Zizhao Zhang,  Chen-Yu Lee,  Tomas Pfister</p>
  <p><b>备注</b>：Accepted to Findings of NAACL 2024</p>
  <p><b>关键词</b>：large language models, users' actual goals, aligning large language, next-token prediction objective, specific task instructions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning has emerged as the key in aligning large language models (LLMs) with specific task instructions, thereby mitigating the discrepancy between the next-token prediction objective and users' actual goals. To reduce the labor and time cost to collect or annotate data by humans, researchers start to explore the use of LLMs to generate instruction-aligned synthetic data. Recent works focus on generating diverse instructions and applying LLM to increase instruction complexity, often neglecting downstream use cases. It remains unclear how to tailor high-quality data to elicit better instruction-following abilities in different target instruction distributions and LLMs. To this end, we introduce CodecLM, a general framework for adaptively generating high-quality synthetic data for LLM alignment with different downstream instruction distributions and LLMs. Drawing on the Encode-Decode principles, we use LLMs as codecs to guide the data generation process. We first encode seed instructions into metadata, which are concise keywords generated on-the-fly to capture the target instruction distribution, and then decode metadata to create tailored instructions. We also introduce Self-Rubrics and Contrastive Filtering during decoding to tailor data-efficient samples. Extensive experiments on four open-domain instruction following benchmarks validate the effectiveness of CodecLM over the current state-of-the-arts.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Negative Preference Optimization: From Catastrophic Collapse to  Effective Unlearning</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05868">https://arxiv.org/abs/2404.05868</a></p>
  <p><b>作者</b>：Ruiqi Zhang,  Licong Lin,  Yu Bai,  Song Mei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Language Models, model utilities, LLM unlearning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) often memorize sensitive, private, or copyrighted data during pre-training. LLM unlearning aims to eliminate the influence of undesirable data from the pre-trained model while preserving the model's utilities on other tasks. Several practical methods have recently been proposed for LLM unlearning, mostly based on gradient ascent (GA) on the loss of undesirable data. However, on certain unlearning tasks, these methods either fail to effectively unlearn the target data or suffer from catastrophic collapse -- a drastic degradation of the model's utilities.
In this paper, we propose Negative Preference Optimization (NPO), a simple alignment-inspired method that could efficiently and effectively unlearn a target dataset. We theoretically show that the progression toward catastrophic collapse by minimizing the NPO loss is exponentially slower than GA. Through experiments on synthetic data and the benchmark TOFU dataset, we demonstrate that NPO-based methods achieve a better balance between unlearning the undesirable data and maintaining the model's utilities. We also observe that NPO-based methods generate more sensible outputs than GA-based methods, whose outputs are often gibberish. Remarkably, on TOFU, NPO-based methods are the first to achieve reasonable unlearning results in forgetting 50% (or more) of the training data, whereas existing methods already struggle with forgetting 10% of training data.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions  with Expertise-Informed Tasks</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05840">https://arxiv.org/abs/2404.05840</a></p>
  <p><b>作者</b>：Andre R Kuroswiski,  Annie S Wu,  Angelo Passaro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enhancing Multi-Agent Reinforcement, Multi-Agent Reinforcement Learning, Multi-Agent Reinforcement, Reinforcement Learning, introduce an alternative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce an alternative approach to enhancing Multi-Agent Reinforcement Learning (MARL) through the integration of domain knowledge and attention-based policy mechanisms. Our methodology focuses on the incorporation of domain-specific expertise into the learning process, which simplifies the development of collaborative behaviors. This approach aims to reduce the complexity and learning overhead typically associated with MARL by enabling agents to concentrate on essential aspects of complex tasks, thus optimizing the learning curve. The utilization of attention mechanisms plays a key role in our model. It allows for the effective processing of dynamic context data and nuanced agent interactions, leading to more refined decision-making. Applied in standard MARL scenarios, such as the Stanford Intelligent Systems Laboratory (SISL) Pursuit and Multi-Particle Environments (MPE) Simple Spread, our method has been shown to improve both learning efficiency and the effectiveness of collaborative behaviors. The results indicate that our attention-based approach can be a viable approach for improving the efficiency of MARL training process, integrating domain-specific knowledge at the action level.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：SambaLingo: Teaching Large Language Models New Languages</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05829">https://arxiv.org/abs/2404.05829</a></p>
  <p><b>作者</b>：Zoltan Csaki,  Bo Li,  Jonathan Li,  Qiantong Xu,  Pian Pawakapan,  Leon Zhang,  Yun Du,  Hengyu Zhao,  Changran Hu,  Urmish Thakker</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：widespread availability, remains a substantial, substantial gap, availability across diverse, capabilities and availability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the widespread availability of LLMs, there remains a substantial gap in their capabilities and availability across diverse languages. One approach to address these issues has been to take an existing pre-trained LLM and continue to train it on new languages. While prior works have experimented with language adaptation, many questions around best practices and methodology have not been covered. In this paper, we present a comprehensive investigation into the adaptation of LLMs to new languages. Our study covers the key components in this process, including vocabulary extension, direct preference optimization and the data scarcity problem for human alignment in low-resource languages. We scale these experiments across 9 languages and 2 parameter scales (7B and 70B). We compare our models against Llama 2, Aya-101, XGLM, BLOOM and existing language experts, outperforming all prior published baselines. Additionally, all evaluation code and checkpoints are made public to facilitate future research.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language  Models and Doc-Level Embedding</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05825">https://arxiv.org/abs/2404.05825</a></p>
  <p><b>作者</b>：Mingrui Wu,  Sheng Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recently embedding-based retrieval, based approaches, Recently embedding-based, compared with traditional, shown state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently embedding-based retrieval or dense retrieval have shown state of the art results, compared with traditional sparse or bag-of-words based approaches. This paper introduces a model-agnostic doc-level embedding framework through large language model (LLM) augmentation. In addition, it also improves some important components in the retrieval model training process, such as negative sampling, loss function, etc. By implementing this LLM-augmented retrieval framework, we have been able to significantly improve the effectiveness of widely-used retriever models such as Bi-encoders (Contriever, DRAGON) and late-interaction models (ColBERTv2), thereby achieving state-of-the-art results on LoTTE datasets and BEIR datasets.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Self-Labeling in Multivariate Causality and Quantification for Adaptive  Machine Learning</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05809">https://arxiv.org/abs/2404.05809</a></p>
  <p><b>作者</b>：Yutian Ren,  Aaron Haohua Yen,  G. P. Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential concept drift, Adaptive machine learning, adapt to ever-changing, ever-changing environments, environments with potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive machine learning (ML) aims to allow ML models to adapt to ever-changing environments with potential concept drift after model deployment. Traditionally, adaptive ML requires a new dataset to be manually labeled to tailor deployed models to altered data distributions. Recently, an interactive causality based self-labeling method was proposed to autonomously associate causally related data streams for domain adaptation, showing promising results compared to traditional feature similarity-based semi-supervised learning. Several unanswered research questions remain, including self-labeling's compatibility with multivariate causality and the quantitative analysis of the auxiliary models used in the self-labeling. The auxiliary models, the interaction time model (ITM) and the effect state detector (ESD), are vital to the success of self-labeling. This paper further develops the self-labeling framework and its theoretical foundations to address these research questions. A framework for the application of self-labeling to multivariate causal graphs is proposed using four basic causal relationships, and the impact of non-ideal ITM and ESD performance is analyzed. A simulated experiment is conducted based on a multivariate causal graph, validating the proposed theory.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Responsible Generative AI: What to Generate and What Not</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05783">https://arxiv.org/abs/2404.05783</a></p>
  <p><b>作者</b>：Jindong Gu</p>
  <p><b>备注</b>：74 pages, 10 figures</p>
  <p><b>关键词</b>：received significant attention, large language models, large language, received significant, significant attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, generative AI (GenAI), like large language models and text-to-image models, has received significant attention across various domains. However, ensuring the responsible generation of content by these models is crucial for their real-world applicability. This raises an interesting question: \textit{What should responsible GenAI generate, and what should it not?} To answer the question, this paper investigates the practical responsible requirements of both textual and visual generative models, outlining five key considerations: generating truthful content, avoiding toxic content, refusing harmful instruction, leaking no training data-related content, and ensuring generated content identifiable. Specifically, we review recent advancements and challenges in addressing these requirements. Besides, we discuss and emphasize the importance of responsible GenAI across healthcare, education, finance, and artificial general intelligence domains. Through a unified perspective on both textual and visual generative models, this paper aims to provide insights into practical safety-related issues and further benefit the community in building responsible GenAI.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Data Readiness for AI: A 360-Degree Survey</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05779">https://arxiv.org/abs/2404.05779</a></p>
  <p><b>作者</b>：Kaveen Hiniduma,  Suren Byna,  Jean Luca Bez</p>
  <p><b>备注</b>：35 pages, 3 figures, 3 tables, submitted to ACM Computing Surveys</p>
  <p><b>关键词</b>：Artificial Intelligence, fuel for Artificial, critical fuel, data readiness, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data are the critical fuel for Artificial Intelligence (AI) models. Poor quality data produces inaccurate and ineffective AI models that may lead to incorrect or unsafe use. Checking for data readiness is a crucial step in improving data quality. Numerous R&D efforts have been spent on improving data quality. However, standardized metrics for evaluating data readiness for use in AI training are still evolving. In this study, we perform a comprehensive survey of metrics used for verifying AI's data readiness. This survey examines more than 120 papers that are published by ACM Digital Library, IEEE Xplore, other reputable journals, and articles published on the web by prominent AI experts. This survey aims to propose a taxonomy of data readiness for AI (DRAI) metrics for structured and unstructured datasets. We anticipate that this taxonomy can lead to new standards for DRAI metrics that would be used for enhancing the quality and accuracy of AI training and inference.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：IA2: Leveraging Instance-Aware Index Advisor with Reinforcement Learning  for Diverse Workloads</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05777">https://arxiv.org/abs/2404.05777</a></p>
  <p><b>作者</b>：Taiyi Wang,  Eiko Yoneki</p>
  <p><b>备注</b>：EuroMLSys 24, April 22, 2024, Athens, Greece</p>
  <p><b>关键词</b>：deep reinforcement learning, large action spaces, facing large action, Deterministic Policy Gradient, Twin Delayed Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study introduces the Instance-A}ware Index A}dvisor (IA2), a novel deep reinforcement learning (DRL)-based approach for optimizing index selection in databases facing large action spaces of potential candidates. IA2 introduces the Twin Delayed Deep Deterministic Policy Gradient - Temporal Difference State-Wise Action Refinery (TD3-TD-SWAR) model, enabling efficient index selection by understanding workload-index dependencies and employing adaptive action masking. This method includes a comprehensive workload model, enhancing its ability to adapt to unseen workloads and ensuring robust performance across diverse database environments. Evaluation on benchmarks such as TPC-H reveals IA2's suggested indexes' performance in enhancing runtime, securing a 40% reduction in runtime for complex TPC-H workloads compared to scenarios without indexes, and delivering a 20% improvement over existing state-of-the-art DRL-based index advisors.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Forecasting Electric Vehicle Battery Output Voltage: A Predictive  Modeling Approach</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05776">https://arxiv.org/abs/2404.05776</a></p>
  <p><b>作者</b>：Narayana Darapaneni,  Ashish K,  Ullas M S,  Anwesh Reddy Paduri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hybrid vehicles, management system plays, plays a vital, vital role, role in ensuring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The battery management system plays a vital role in ensuring the safety and dependability of electric and hybrid vehicles. It is responsible for various functions, including state evaluation, monitoring, charge control, and cell balancing, all integrated within the BMS. Nonetheless, due to the uncertainties surrounding battery performance, implementing these functionalities poses significant challenges. In this study, we explore the latest approaches for assessing battery states, highlight notable advancements in battery management systems (BMS), address existing issues with current BMS technology, and put forth possible solutions for predicting battery charging voltage.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：STMGF: An Effective Spatial-Temporal Multi-Granularity Framework for  Traffic Forecasting</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05774">https://arxiv.org/abs/2404.05774</a></p>
  <p><b>作者</b>：Zhengyang Zhao,  Haitao Yuan,  Nan Jiang,  Minxiao Chen,  Ning Liu,  Zengxiang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligent transportation due, Accurate Traffic Prediction, road networks, challenging task, task in intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate Traffic Prediction is a challenging task in intelligent transportation due to the spatial-temporal aspects of road networks. The traffic of a road network can be affected by long-distance or long-term dependencies where existing methods fall short in modeling them. In this paper, we introduce a novel framework known as Spatial-Temporal Multi-Granularity Framework (STMGF) to enhance the capture of long-distance and long-term information of the road networks. STMGF makes full use of different granularity information of road networks and models the long-distance and long-term information by gathering information in a hierarchical interactive way. Further, it leverages the inherent periodicity in traffic sequences to refine prediction results by matching with recent traffic data. We conduct experiments on two real-world datasets, and the results demonstrate that STMGF outperforms all baseline models and achieves state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Dynamic Quality-Diversity Search</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05769">https://arxiv.org/abs/2404.05769</a></p>
  <p><b>作者</b>：Roberto Gallotta,  Antonios Liapis,  Georgios N. Yannakakis</p>
  <p><b>备注</b>：Parts of this manuscripts are published at The Genetic and Evolutionary Computation Conference (GECCO) 2024</p>
  <p><b>关键词</b>：showing considerable potential, discover highly performing, complex real-world scenarios, highly performing solutions, evolutionary robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Evolutionary search via the quality-diversity (QD) paradigm can discover highly performing solutions in different behavioural niches, showing considerable potential in complex real-world scenarios such as evolutionary robotics. Yet most QD methods only tackle static tasks that are fixed over time, which is rarely the case in the real world. Unlike noisy environments, where the fitness of an individual changes slightly at every evaluation, dynamic environments simulate tasks where external factors at unknown and irregular intervals alter the performance of the individual with a severity that is unknown a priori. Literature on optimisation in dynamic environments is extensive, yet such environments have not been explored in the context of QD search. This paper introduces a novel and generalisable Dynamic QD methodology that aims to keep the archive of past solutions updated in the case of environment changes. Secondly, we present a novel characterisation of dynamic environments that can be easily applied to well-known benchmarks, with minor interventions to move them from a static task to a dynamic one. Our Dynamic QD intervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms, and we test the dynamic variants on different dynamic tasks.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：CSA-Trans: Code Structure Aware Transformer for AST</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05767">https://arxiv.org/abs/2404.05767</a></p>
  <p><b>作者</b>：Saeyoon Oh,  Shin Yoo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Abstract Syntax Trees, Syntax Trees, Abstract Syntax, Structure Aware Transformer, Code Structure Embedder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When applying the Transformer architecture to source code, designing a good self-attention mechanism is critical as it affects how node relationship is extracted from the Abstract Syntax Trees (ASTs) of the source code. We present Code Structure Aware Transformer (CSA-Trans), which uses Code Structure Embedder (CSE) to generate specific PE for each node in AST. CSE generates node Positional Encoding (PE) using disentangled attention. To further extend the self-attention capability, we adopt Stochastic Block Model (SBM) attention. Our evaluation shows that our PE captures the relationships between AST nodes better than other graph-related PE techniques. We also show through quantitative and qualitative analysis that SBM attention is able to generate more node specific attention coefficients. We demonstrate that CSA-Trans outperforms 14 baselines in code summarization tasks for both Python and Java, while being 41.92% faster and 25.31% memory efficient in Java dataset compared to AST-Trans and SG-Trans respectively.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05765">https://arxiv.org/abs/2404.05765</a></p>
  <p><b>作者</b>：Roopa Mayya,  Vivekanand Venkataraman,  Anwesh P R,  Narayana Darapaneni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classical Indian music, generating classical Indian, Indian music, received significant attention, Music</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Introduction: Music generation is a complex task that has received significant attention in recent years, and deep learning techniques have shown promising results in this field. Objectives: While extensive work has been carried out on generating Piano and other Western music, there is limited research on generating classical Indian music due to the scarcity of Indian music in machine-encoded formats. In this technical paper, methods for generating classical Indian music, specifically tabla music, is proposed. Initially, this paper explores piano music generation using deep learning architectures. Then the fundamentals are extended to generating tabla music. Methods: Tabla music in waveform (.wav) files are pre-processed using the librosa library in Python. A novel Bi-LSTM with an Attention approach and a transformer model are trained on the extracted features and labels. Results: The models are then used to predict the next sequences of tabla music. A loss of 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the transformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla music generation. Conclusion: The resulting music embodies a harmonious fusion of novelty and familiarity, pushing the limits of music composition to new horizons.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Enhancing Inference Efficiency of Large Language Models: Investigating  Optimization Strategies and Architectural Innovations</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05741">https://arxiv.org/abs/2404.05741</a></p>
  <p><b>作者</b>：Georgy Tyukin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, models train quicker, Language Models, train quicker</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models are growing in size, and we expect them to continue to do so, as larger models train quicker. However, this increase in size will severely impact inference costs. Therefore model compression is important, to retain the performance of larger models, but with a reduced cost of running them. In this thesis we explore the methods of model compression, and we empirically demonstrate that the simple method of skipping latter attention sublayers in Transformer LLMs is an effective method of model compression, as these layers prove to be redundant, whilst also being incredibly computationally expensive. We observed a 21% speed increase in one-token generation for Llama 2 7B, whilst surprisingly and unexpectedly improving performance over several common benchmarks.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：A Python Framework for Neutrosophic Sets and Mappings</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05735">https://arxiv.org/abs/2404.05735</a></p>
  <p><b>作者</b>：Giorgio Nordo,  Saeid Jafari,  Arif Mehmood,  Bhimraj Basumatary</p>
  <p><b>备注</b>：38 PAGES</p>
  <p><b>关键词</b>：distinct classes designed, open source framework, source framework developed, developed in Python, Python and consisting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present an open source framework developed in Python and consisting of three distinct classes designed to manipulate in a simple and intuitive way both symbolic representations of neutrosophic sets over universes of various types as well as mappings between them. The capabilities offered by this framework extend and generalize previous attempts to provide software solutions to the manipulation of neutrosophic sets such as those proposed by Salama et al., Saranya et al., El-Ghareeb, Topal et al. and Sleem. The code is described in detail and many examples and use cases are also provided.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：The X-LANCE Technical Report for Interspeech 2024 Speech Processing  Using Discrete Speech Unit Challenge</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06079">https://arxiv.org/abs/2404.06079</a></p>
  <p><b>作者</b>：Yiwei Guo,  Chenrun Wang,  Yifan Yang,  Hankun Wang,  Ziyang Ma,  Chenpeng Du,  Shuai Wang,  Hanzheng Li,  Shuai Fan,  Hui Zhang,  Xie Chen,  Kai Yu</p>
  <p><b>备注</b>：5 pages, 3 figures. Report of a challenge</p>
  <p><b>关键词</b>：singing voice synthesis, speech processing fields, automatic speech recognition, including automatic speech, Discrete speech tokens</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discrete speech tokens have been more and more popular in multiple speech processing fields, including automatic speech recognition (ASR), text-to-speech (TTS) and singing voice synthesis (SVS). In this paper, we describe the systems developed by the SJTU X-LANCE group for the TTS (acoustic + vocoder), SVS, and ASR tracks in the Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge. Notably, we achieved 1st rank on the leaderboard in the TTS track both with the whole training set and only 1h training data, with the highest UTMOS score and lowest bitrate among all submissions.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Efficient Quantum Circuits for Machine Learning Activation Functions  including Constant T-depth ReLU</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06059">https://arxiv.org/abs/2404.06059</a></p>
  <p><b>作者</b>：Wei Zi,  Siyi Wang,  Hyunji Kim,  Xiaoming Sun,  Anupam Chattopadhyay,  Patrick Rebentrost</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：Quantum Machine Learning, recent years, interest of researchers, increasingly captured, captured the interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, Quantum Machine Learning (QML) has increasingly captured the interest of researchers. Among the components in this domain, activation functions hold a fundamental and indispensable role. Our research focuses on the development of activation functions quantum circuits for integration into fault-tolerant quantum computing architectures, with an emphasis on minimizing $T$-depth. Specifically, we present novel implementations of ReLU and leaky ReLU activation functions, achieving constant $T$-depths of 4 and 8, respectively. Leveraging quantum lookup tables, we extend our exploration to other activation functions such as the sigmoid. This approach enables us to customize precision and $T$-depth by adjusting the number of qubits, making our results more adaptable to various application scenarios. This study represents a significant advancement towards enhancing the practicality and application of quantum machine learning.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Map Optical Properties to Subwavelength Structures Directly via a  Diffusion Model</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05959">https://arxiv.org/abs/2404.05959</a></p>
  <p><b>作者</b>：Shijie Rao,  Kaiyu Cui,  Yidong Huang,  Jiawei Yang,  Yali Li,  Shengjin Wang,  Xue Feng,  Fang Liu,  Wei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：metamaterials provide revolutionary, provide revolutionary approaches, Subwavelength photonic structures, inverse design, inverse design methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subwavelength photonic structures and metamaterials provide revolutionary approaches for controlling light. The inverse design methods proposed for these subwavelength structures are vital to the development of new photonic devices. However, most of the existing inverse design methods cannot realize direct mapping from optical properties to photonic structures but instead rely on forward simulation methods to perform iterative optimization. In this work, we exploit the powerful generative abilities of artificial intelligence (AI) and propose a practical inverse design method based on latent diffusion models. Our method maps directly the optical properties to structures without the requirement of forward simulation and iterative optimization. Here, the given optical properties can work as "prompts" and guide the constructed model to correctly "draw" the required photonic structures. Experiments show that our direct mapping-based inverse design method can generate subwavelength photonic structures at high fidelity while following the given optical properties. This may change the method used for optical design and greatly accelerate the research on new photonic devices.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Condition Monitoring with Incomplete Data: An Integrated Variational  Autoencoder and Distance Metric Framework</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05891">https://arxiv.org/abs/2404.05891</a></p>
  <p><b>作者</b>：Maryam Ahang,  Mostafa Abbasi,  Todd Charter,  Homayoun Najjaran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：notable challenges arise, real-world settings due, systems is crucial, crucial for ensuring, notable challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Condition monitoring of industrial systems is crucial for ensuring safety and maintenance planning, yet notable challenges arise in real-world settings due to the limited or non-existent availability of fault samples. This paper introduces an innovative solution to this problem by proposing a new method for fault detection and condition monitoring for unseen data. Adopting an approach inspired by zero-shot learning, our method can identify faults and assign a relative health index to various operational conditions. Typically, we have plenty of data on normal operations, some data on compromised conditions, and very few (if any) samples of severe faults. We use a variational autoencoder to capture the probabilistic distribution of previously seen and new unseen conditions. The health status is determined by comparing each sample's deviation from a normal operation reference distribution in the latent space. Faults are detected by establishing a threshold for the health indexes, allowing the model to identify severe, unseen faults with high accuracy, even amidst noise. We validate our approach using the run-to-failure IMS-bearing dataset and compare it with other methods. The health indexes generated by our model closely match the established descriptive model of bearing wear, attesting to the robustness and reliability of our method. These findings highlight the potential of our methodology in augmenting fault detection capabilities within industrial domains, thereby contributing to heightened safety protocols and optimized maintenance practices.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Evaluating the Effectiveness of Artificial Intelligence in Predicting  Adverse Drug Reactions among Cancer Patients: A Systematic Review and  Meta-Analysis</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05762">https://arxiv.org/abs/2404.05762</a></p>
  <p><b>作者</b>：Fatma Zahra Abdeldjouad,  Menaouer Brahami,  Mohammed Sabri</p>
  <p><b>备注</b>：Paper has been accepted at the IEEE Challenges and Innovations on TIC (IEEE I2CIT) International Conference</p>
  <p><b>关键词</b>：Adverse drug reactions, reactions considerably impact, drug reactions considerably, Adverse drug, drug reactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adverse drug reactions considerably impact patient outcomes and healthcare costs in cancer therapy. Using artificial intelligence to predict adverse drug reactions in real time could revolutionize oncology treatment. This study aims to assess the performance of artificial intelligence models in predicting adverse drug reactions in patients with cancer. This is the first systematic review and meta-analysis. Scopus, PubMed, IEEE Xplore, and ACM Digital Library databases were searched for studies in English, French, and Arabic from January 1, 2018, to August 20, 2023. The inclusion criteria were: (1) peer-reviewed research articles; (2) use of artificial intelligence algorithms (machine learning, deep learning, knowledge graphs); (3) study aimed to predict adverse drug reactions (cardiotoxicity, neutropenia, nephrotoxicity, hepatotoxicity); (4) study was on cancer patients. The data were extracted and evaluated by three reviewers for study quality. Of the 332 screened articles, 17 studies (5%) involving 93,248 oncology patients from 17 countries were included in the systematic review, of which ten studies synthesized the meta-analysis. A random-effects model was created to pool the sensitivity, specificity, and AUC of the included studies. The pooled results were 0.82 (95% CI:0.69, 0.9), 0.84 (95% CI:0.75, 0.9), and 0.83 (95% CI:0.77, 0.87) for sensitivity, specificity, and AUC, respectively, of ADR predictive models. Biomarkers proved their effectiveness in predicting ADRs, yet they were adopted by only half of the reviewed studies. The use of AI in cancer treatment shows great potential, with models demonstrating high specificity and sensitivity in predicting ADRs. However, standardized research and multicenter studies are needed to improve the quality of evidence. AI can enhance cancer patient care by bridging the gap between data-driven insights and clinical expertise.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Implicit Assimilation of Sparse In Situ Data for Dense & Global Storm  Surge Forecasting</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05758">https://arxiv.org/abs/2404.05758</a></p>
  <p><b>作者</b>：Patrick Ebel,  Brandon Victor,  Peter Naylor,  Gabriele Meoni,  Federico Serva,  Rochelle Schneider</p>
  <p><b>备注</b>：Accepted at CVPR EarthVision 2024</p>
  <p><b>关键词</b>：disastrous natural hazards, Hurricanes and coastal, natural hazards, coastal floods, disastrous natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hurricanes and coastal floods are among the most disastrous natural hazards. Both are intimately related to storm surges, as their causes and effects, respectively. However, the short-term forecasting of storm surges has proven challenging, especially when targeting previously unseen locations or sites without tidal gauges. Furthermore, recent work improved short and medium-term weather forecasting but the handling of raw unassimilated data remains non-trivial. In this paper, we tackle both challenges and demonstrate that neural networks can implicitly assimilate sparse in situ tide gauge data with coarse ocean state reanalysis in order to forecast storm surges. We curate a global dataset to learn and validate the dense prediction of storm surges, building on preceding efforts. Other than prior work limited to known gauges, our approach extends to ungauged sites, paving the way for global storm surge forecasting.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Causality for Earth Science -- A Review on Time-series and  Spatiotemporal Causality Methods</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05746">https://arxiv.org/abs/2404.05746</a></p>
  <p><b>作者</b>：Sahara Ali,  Uzma Hasan,  Xingyan Li,  Omar Faruque,  Akila Sampath,  Yiyi Huang,  Md Osman Gani,  Jianwu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Earth Science, survey paper covers, Earth Science study, Earth Science datasets, specific Earth Science</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This survey paper covers the breadth and depth of time-series and spatiotemporal causality methods, and their applications in Earth Science. More specifically, the paper presents an overview of causal discovery and causal inference, explains the underlying causal assumptions, and enlists evaluation techniques and key terminologies of the domain area. The paper elicits the various state-of-the-art methods introduced for time-series and spatiotemporal causal analysis along with their strengths and limitations. The paper further describes the existing applications of several methods for answering specific Earth Science questions such as extreme weather events, sea level rise, teleconnections etc. This survey paper can serve as a primer for Data Science researchers interested in data-driven causal study as we share a list of resources, such as Earth Science datasets (synthetic, simulated and observational data) and open source tools for causal analysis. It will equally benefit the Earth Science community interested in taking an AI-driven approach to study the causality of different dynamic and thermodynamic processes as we present the open challenges and opportunities in performing causality-based Earth Science study.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html"><img class="next-cover" src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">🎨 Stable Diffusion 提示词指南书</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">💭这个人很懒，什么都没有留下</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2024-04-11)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2024-04-11)"/></a><div class="content"><a class="title" href="/2024/04/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2024-04-11)">Arxiv每日速递(2024-04-11)</a><time datetime="2024-04-11T00:36:50.526Z" title="发表于 2024-04-11 08:36:50">2024-04-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html" title="🎨 Stable Diffusion 提示词指南书"><img src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="🎨 Stable Diffusion 提示词指南书"/></a><div class="content"><a class="title" href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html" title="🎨 Stable Diffusion 提示词指南书">🎨 Stable Diffusion 提示词指南书</a><time datetime="2024-02-03T06:57:45.000Z" title="发表于 2024-02-03 14:57:45">2024-02-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/22/Transformer%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E9%95%BF%E5%BA%A6%E5%A4%96%E6%8E%A8.html" title="Transformer语言模型的位置编码与长度外推"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/city.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer语言模型的位置编码与长度外推"/></a><div class="content"><a class="title" href="/2023/10/22/Transformer%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E9%95%BF%E5%BA%A6%E5%A4%96%E6%8E%A8.html" title="Transformer语言模型的位置编码与长度外推">Transformer语言模型的位置编码与长度外推</a><time datetime="2023-10-22T14:55:45.000Z" title="发表于 2023-10-22 22:55:45">2023-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"/></a><div class="content"><a class="title" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><time datetime="2023-09-22T14:55:45.000Z" title="发表于 2023-09-22 22:55:45">2023-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prompt：大语言模型的执行指南"/></a><div class="content"><a class="title" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南">Prompt：大语言模型的执行指南</a><time datetime="2023-09-06T14:45:45.000Z" title="发表于 2023-09-06 22:45:45">2023-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (8)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt=""><img width="48" height="48" src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-05-19</span><a class="blog-slider__title" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/cail2021.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-10-22</span><a class="blog-slider__title" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt=""><img width="48" height="48" src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-17</span><a class="blog-slider__title" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-22</span><a class="blog-slider__title" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/city.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-10-22</span><a class="blog-slider__title" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt="">Transformer语言模型的位置编码与长度外推</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt=""><img width="48" height="48" src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-03</span><a class="blog-slider__title" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt="">🎨 Stable Diffusion 提示词指南书</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-06</span><a class="blog-slider__title" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">Prompt：大语言模型的执行指南</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/26/升级深度学习开发环境全攻略.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-26</span><a class="blog-slider__title" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">升级深度学习开发环境全攻略</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>