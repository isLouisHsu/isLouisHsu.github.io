<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2024-05-06) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。 统计 今日共更新473篇论文，其中：  71篇自然语言处理（cs.CL） 96篇计算机视觉（cs.CV） 163篇机器学习（cs.LG） 116篇人工智能（cs.AI）  自然语言处理    1. 标题：Prometheus 2: An Open Source Langua">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2024-05-06)">
<meta property="og:url" content="http://louishsu.xyz/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。 统计 今日共更新473篇论文，其中：  71篇自然语言处理（cs.CL） 96篇计算机视觉（cs.CV） 163篇机器学习（cs.LG） 116篇人工智能（cs.AI）  自然语言处理    1. 标题：Prometheus 2: An Open Source Langua">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2024-05-06T00:38:55.907Z">
<meta property="article:modified_time" content="2024-05-06T00:40:43.452Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2024-05-06 08:40:43'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zealdocs.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zeal：离线文档浏览器，其灵感来自 OS X平台上的 Dash，目前支持 Window 和 Liunx，基于 QT5</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wise-system-monitor.en.softonic.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Wise System Monitor：监控从系统到本地网络的所有运行情况</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="http://www.uderzo.it/main_products/space_sniffer/index.html"><i class="fa-fw fa-regular fa-star"></i><span> Space Sniffer：磁盘空间分析工具</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://zealdocs.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zeal：离线文档浏览器，其灵感来自 OS X平台上的 Dash，目前支持 Window 和 Liunx，基于 QT5</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://wise-system-monitor.en.softonic.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Wise System Monitor：监控从系统到本地网络的所有运行情况</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="http://www.uderzo.it/main_products/space_sniffer/index.html"><i class="fa-fw fa-regular fa-star"></i><span> Space Sniffer：磁盘空间分析工具</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2024-05-06)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-06T00:38:55.907Z" title="发表于 2024-05-06 08:38:55">2024-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-05-06T00:40:43.452Z" title="更新于 2024-05-06 08:40:43">2024-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">112.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>671分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以自然语言处理、计算机视觉、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新473篇论文，其中：</p>
<ul>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">71篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">96篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">163篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">116篇人工智能（cs.AI）</a></li>
</ul>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Prometheus 2: An Open Source Language Model Specialized in Evaluating  Other Language Models</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01535">https://arxiv.org/abs/2405.01535</a></p>
  <p><b>作者</b>：Seungone Kim,  Juyoung Suk,  Shayne Longpre,  Bill Yuchen Lin,  Jamin Shin,  Sean Welleck,  Graham Neubig,  Moontae Lee,  Kyungjae Lee,  Minjoon Seo</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：employed to assess, assess the quality, quality of responses, open evaluator LMs, direct assessment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Proprietary LMs such as GPT-4 are often employed to assess the quality of responses from various LMs. However, concerns including transparency, controllability, and affordability strongly motivate the development of open-source LMs specialized in evaluations. On the other hand, existing open evaluator LMs exhibit critical shortcomings: 1) they issue scores that significantly diverge from those assigned by humans, and 2) they lack the flexibility to perform both direct assessment and pairwise ranking, the two most prevalent forms of assessment. Additionally, they do not possess the ability to evaluate based on custom evaluation criteria, focusing instead on general attributes like helpfulness and harmlessness. To address these issues, we introduce Prometheus 2, a more powerful evaluator LM than its predecessor that closely mirrors human and GPT-4 judgements. Moreover, it is capable of processing both direct assessment and pair-wise ranking formats grouped with a user-defined evaluation criteria. On four direct assessment benchmarks and four pairwise ranking benchmarks, Prometheus 2 scores the highest correlation and agreement with humans and proprietary LM judges among all tested open evaluator LMs. Our models, code, and data are all publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：FLAME: Factuality-Aware Alignment for Large Language Models</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01525">https://arxiv.org/abs/2405.01525</a></p>
  <p><b>作者</b>：Sheng-Chieh Lin,  Luyu Gao,  Barlas Oguz,  Wenhan Xiong,  Jimmy Lin,  Wen-tau Yih,  Xilun Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, pre-trained large language, follow natural language, fine-tune pre-trained large, natural language instructions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alignment is a standard procedure to fine-tune pre-trained large language models (LLMs) to follow natural language instructions and serve as helpful AI assistants. We have observed, however, that the conventional alignment process fails to enhance the factual accuracy of LLMs, and often leads to the generation of more false facts (i.e. hallucination). In this paper, we study how to make the LLM alignment process more factual, by first identifying factors that lead to hallucination in both alignment steps:\ supervised fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that training the LLM on new knowledge or unfamiliar texts can encourage hallucination. This makes SFT less factual as it trains on human labeled data that may be novel to the LLM. Furthermore, reward functions used in standard RL can also encourage hallucination, because it guides the LLM to provide more helpful responses on a diverse set of instructions, often preferring longer and more detailed responses. Based on these observations, we propose factuality-aware alignment, comprised of factuality-aware SFT and factuality-aware RL through direct preference optimization. Experiments show that our proposed factuality-aware alignment guides LLMs to output more factual responses while maintaining instruction-following capability.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：D2PO: Discriminator-Guided DPO with Response Evaluation Models</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01511">https://arxiv.org/abs/2405.01511</a></p>
  <p><b>作者</b>：Prasann Singhal,  Nathan Lambert,  Scott Niekum,  Tanya Goyal,  Greg Durrett</p>
  <p><b>备注</b>：20 pages, 12 figures</p>
  <p><b>关键词</b>：direct optimization methods, including supervised fine-tuning, aligning language models, Varied approaches, supervised fine-tuning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Varied approaches for aligning language models have been proposed, including supervised fine-tuning, RLHF, and direct optimization methods such as DPO. Although DPO has rapidly gained popularity due to its straightforward training process and competitive results, there is an open question of whether there remain practical advantages of using a discriminator, like a reward model, to evaluate responses. We propose D2PO, discriminator-guided DPO, an approach for the online setting where preferences are being collected throughout learning. As we collect gold preferences, we use these not only to train our policy, but to train a discriminative response evaluation model to silver-label even more synthetic data for policy training. We explore this approach across a set of diverse tasks, including a realistic chat setting, we find that our approach leads to higher-quality outputs compared to DPO with the same data budget, and greater efficiency in terms of preference data requirements. Furthermore, we show conditions under which silver labeling is most helpful: it is most effective when training the policy with DPO, outperforming traditional PPO, and benefits from maintaining a separate discriminator from the policy model.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on  Large Language Models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01509">https://arxiv.org/abs/2405.01509</a></p>
  <p><b>作者</b>：Minhao Bai,  Kaiyi Pang,  Yongfeng Huang</p>
  <p><b>备注</b>：not decided</p>
  <p><b>关键词</b>：Large Language Models, Large Language, rapidly evolving domain, property of Large, model extraction attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the rapidly evolving domain of artificial intelligence, safeguarding the intellectual property of Large Language Models (LLMs) is increasingly crucial. Current watermarking techniques against model extraction attacks, which rely on signal insertion in model logits or post-processing of generated text, remain largely heuristic. We propose a novel method for embedding learnable linguistic watermarks in LLMs, aimed at tracing and preventing model extraction attacks. Our approach subtly modifies the LLM's output distribution by introducing controlled noise into token frequency distributions, embedding an statistically identifiable controllable watermark.We leverage statistical hypothesis testing and information theory, particularly focusing on Kullback-Leibler Divergence, to differentiate between original and modified distributions effectively. Our watermarking method strikes a delicate well balance between robustness and output quality, maintaining low false positive/negative rates and preserving the LLM's original performance.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Analyzing the Role of Semantic Representations in the Era of Large  Language Models</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01502">https://arxiv.org/abs/2405.01502</a></p>
  <p><b>作者</b>：Zhijing Jin,  Yuen Chen,  Fernando Gonzalez,  Jiarui Liu,  Jiayi Zhang,  Julian Michael,  Bernhard Schölkopf,  Mona Diab</p>
  <p><b>备注</b>：NAACL 2024</p>
  <p><b>关键词</b>：natural language processing, linguistic expertise, rich set, set of features, features created</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven chain-of-thought prompting method, which we call AMRCoT, and find that it generally hurts performance more than it helps. To investigate what AMR may have to offer on these tasks, we conduct a series of analysis experiments. We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction. We recommend focusing on these areas for future work in semantic representations for LLMs. Our code: this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Controllable Text Generation in the Instruction-Tuning Era</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01490">https://arxiv.org/abs/2405.01490</a></p>
  <p><b>作者</b>：Dhananjay Ashok,  Barnabas Poczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Instruction-tuned Language Models, base Language Models, steering base Language, Language Models, prompting paradigm offers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While most research on controllable text generation has focused on steering base Language Models, the emerging instruction-tuning and prompting paradigm offers an alternate approach to controllability. We compile and release ConGenBench, a testbed of 17 different controllable generation tasks, using a subset of it to benchmark the performance of 9 different baselines and methods on Instruction-tuned Language Models. To our surprise, we find that prompting-based approaches outperform controllable text generation methods on most datasets and tasks, highlighting a need for research on controllable text generation with Instruction-tuned Language Models in specific. Prompt-based approaches match human performance on most stylistic tasks while lagging on structural tasks, foregrounding a need to study more varied constraints and more challenging stylistic tasks. To facilitate such research, we provide an algorithm that uses only a task dataset and a Large Language Model with in-context capabilities to automatically generate a constraint dataset. This method eliminates the fields dependence on pre-curated constraint datasets, hence vastly expanding the range of constraints that can be studied in the future.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：MANTIS: Interleaved Multi-Image Instruction Tuning</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01483">https://arxiv.org/abs/2405.01483</a></p>
  <p><b>作者</b>：Dongfu Jiang,  Xuan He,  Huaye Zeng,  Cong Wei,  Max Ku,  Qian Liu,  Wenhu Chen</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：vision language tasks, large multimodal models, language tasks, multi-image, single-image vision language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent years have witnessed a great array of large multimodal models (LMMs) to effectively solve single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from web, which is neither efficient nor effective. In this paper, we aim at building strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K instances from 14 multi-image datasets. We design Mantis-Instruct to cover different multi-image skills like co-reference, reasoning, comparing, temporal understanding. We combine Mantis-Instruct with several single-image visual-language datasets to train our model Mantis to handle any interleaved image-text inputs. We evaluate the trained Mantis on five multi-image benchmarks and eight single-image benchmarks. Though only requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B can achieve state-of-the-art performance on all the multi-image benchmarks and beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute points. We observe that Mantis performs equivalently well on the held-in and held-out evaluation benchmarks. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis can maintain a strong single-image performance on par with CogVLM and Emu2. Our results are particularly encouraging as it shows that low-cost instruction tuning is indeed much more effective than intensive pre-training in terms of building multi-image LMMs.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01481">https://arxiv.org/abs/2405.01481</a></p>
  <p><b>作者</b>：Gerald Shen,  Zhilin Wang,  Olivier Delalleau,  Jiaqi Zeng,  Yi Dong,  Daniel Egert,  Shengyang Sun,  Jimmy Zhang,  Sahil Jain,  Ali Taghibakhshi,  Markel Sanz Ausin,  Ashwath Aithal,  Oleksii Kuchaiev</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：Aligning Large Language, Large Language Models, Large Language, Aligning Large, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aligning Large Language Models (LLMs) with human values and preferences is essential for making them helpful and safe. However, building efficient tools to perform alignment can be challenging, especially for the largest and most competent LLMs which often contain tens or hundreds of billions of parameters. We create NeMo-Aligner, a toolkit for model alignment that can efficiently scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly optimized and scalable implementations for major paradigms of model alignment such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally, our toolkit supports running most of the alignment techniques in a Parameter Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for extensibility, allowing support for other alignment techniques with minimal effort. It is open-sourced with Apache 2.0 License and we invite community contributions at this https URL</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：V-FLUTE: Visual Figurative Language Understanding with Textual  Explanations</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01474">https://arxiv.org/abs/2405.01474</a></p>
  <p><b>作者</b>：Arkadiy Saakyan,  Shreyas Kulkarni,  Tuhin Chakrabarty,  Smaranda Muresan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong reasoning, strong reasoning capabilities, Large Vision-Language models, Visual Figurative Language, Figurative Language Understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Vision-Language models (VLMs) have demonstrated strong reasoning capabilities in tasks requiring a fine-grained understanding of literal images and text, such as visual question-answering or visual entailment. However, there has been little exploration of these models' capabilities when presented with images and captions containing figurative phenomena such as metaphors or humor, the meaning of which is often implicit. To close this gap, we propose a new task and a high-quality dataset: Visual Figurative Language Understanding with Textual Explanations (V-FLUTE). We frame the visual figurative language understanding problem as an explainable visual entailment task, where the model has to predict whether the image (premise) entails a claim (hypothesis) and justify the predicted label with a textual explanation. Using a human-AI collaboration framework, we build a high-quality dataset, V-FLUTE, that contains 6,027 <image, claim, label, explanation> instances spanning five diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm, and humor. The figurative phenomena can be present either in the image, the caption, or both. We further conduct both automatic and human evaluations to assess current VLMs' capabilities in understanding figurative phenomena.</image,></p>
  </details>
</details>
<details>
  <summary>10. <b>标题：WildChat: 1M ChatGPT Interaction Logs in the Wild</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01470">https://arxiv.org/abs/2405.01470</a></p>
  <p><b>作者</b>：Wenting Zhao,  Xiang Ren,  Jack Hessel,  Claire Cardie,  Yejin Choi,  Yuntian Deng</p>
  <p><b>备注</b>：accepted by ICLR 2024</p>
  <p><b>关键词</b>：serving millions, users, request headers, chat transcripts, public datasets showcasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite their widespread use, there remains a lack of public datasets showcasing how these tools are used by a population of users in practice. To bridge this gap, we offered free access to ChatGPT for online users in exchange for their affirmative, consensual opt-in to anonymously collect their chat transcripts and request headers. From this, we compiled WildChat, a corpus of 1 million user-ChatGPT conversations, which consists of over 2.5 million interaction turns. We compare WildChat with other popular user-chatbot interaction datasets, and find that our dataset offers the most diverse user prompts, contains the largest number of languages, and presents the richest variety of potentially toxic use-cases for researchers to study. In addition to timestamped chat transcripts, we enrich the dataset with demographic data, including state, country, and hashed IP addresses, alongside request headers. This augmentation allows for more detailed analysis of user behaviors across different geographical regions and temporal dimensions. Finally, because it captures a broad range of use cases, we demonstrate the dataset's potential utility in fine-tuning instruction-following models. WildChat is released at this https URL under AI2 ImpACT Licenses.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：UQA: Corpus for Urdu Question Answering</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01458">https://arxiv.org/abs/2405.01458</a></p>
  <p><b>作者</b>：Samee Arif,  Sualeha Farid,  Awais Athar,  Agha Ali Raza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：million native speakers, Stanford Question Answering, Question Answering Dataset, question answering, paper introduces UQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces UQA, a novel dataset for question answering and text comprehension in Urdu, a low-resource language with over 70 million native speakers. UQA is generated by translating the Stanford Question Answering Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in the translated context paragraphs. The paper describes the process of selecting and evaluating the best translation model among two candidates: Google Translator and Seamless M4T. The paper also benchmarks several state-of-the-art multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and 74.56 EM. UQA is a valuable resource for developing and testing multilingual NLP systems for Urdu and for enhancing the cross-lingual transferability of existing models. Further, the paper demonstrates the effectiveness of EATS for creating high-quality datasets for other languages and domains. The UQA dataset and the code are publicly available at this http URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01413">https://arxiv.org/abs/2405.01413</a></p>
  <p><b>作者</b>：Yuan Tang,  Xu Han,  Xianzhi Li,  Qiao Yu,  Yixue Hao,  Long Hu,  Min Chen</p>
  <p><b>备注</b>：17 pages, 9 figures</p>
  <p><b>关键词</b>：Large Language Models, bridging Large Language, gained significant attention, Language Models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Unsupervised Flow Discovery from Task-oriented Dialogues</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01403">https://arxiv.org/abs/2405.01403</a></p>
  <p><b>作者</b>：Patrícia Ferreira,  Daniel Martins,  Ana Alves,  Catarina Silva,  Hugo Gonçalo Oliveira</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：critical but time-consuming, time-consuming task, task when developing, developing task-oriented dialogue, flows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design of dialogue flows is a critical but time-consuming task when developing task-oriented dialogue (TOD) systems. We propose an approach for the unsupervised discovery of flows from dialogue history, thus making the process applicable to any domain for which such an history is available. Briefly, utterances are represented in a vector space and clustered according to their semantic similarity. Clusters, which can be seen as dialogue states, are then used as the vertices of a transition graph for representing the flows visually. We present concrete examples of flows, discovered from MultiWOZ, a public TOD dataset. We further elaborate on their significance and relevance for the underlying conversations and introduce an automatic validation metric for their assessment. Experimental results demonstrate the potential of the proposed approach for extracting meaningful flows from task-oriented conversations.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Verification and Refinement of Natural Language Explanations through  LLM-Symbolic Theorem Proving</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01379">https://arxiv.org/abs/2405.01379</a></p>
  <p><b>作者</b>：Xin Quan,  Marco Valentino,  Louise A. Dennis,  André Freitas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-step Natural Language, Natural language explanations, Large Language Models, Natural Language Inference, Natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language explanations have become a proxy for evaluating explainable and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is time-consuming and prone to logical errors. To address existing limitations, this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically, we present a neuro-symbolic framework, named Explanation-Refiner, that augments a TP with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn, the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation-Refiner can be jointly used to evaluate explanatory reasoning, autoformalisation, and error correction mechanisms of state-of-the-art LLMs as well as to automatically enhance the quality of human-annotated explanations of variable complexity in different domains.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Topics in the Study of the Pragmatic Functions of Phonetic Reduction in  Dialog</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01376">https://arxiv.org/abs/2405.01376</a></p>
  <p><b>作者</b>：Nigel G. Ward,  Carlos A. Ortega</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Reduced articulatory precision, Reduced articulatory, articulatory precision, precision is common, acoustic properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reduced articulatory precision is common in speech, but for dialog its acoustic properties and pragmatic functions have been little studied. We here try to remedy this gap. This technical report contains content that was omitted from the journal article (Ward et al. 2024, submitted). Specifically, we here report 1) lessons learned about annotating for perceived reduction, 2) the finding that, unlike in read speech, the correlates of reduction in dialog include high pitch, wide pitch range, and intensity, and 3) a baseline model for predicting reduction in dialog, using simple acoustic/prosodic features, that achieves correlations with human perceptions of 0.24 for English, and 0.17 for Spanish. We also provide examples of additional possible pragmatic functions of reduction in English, and various discussion, observations and speculations</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：GAIA: A General AI Assistant for Intelligent Accelerator Operations</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01359">https://arxiv.org/abs/2405.01359</a></p>
  <p><b>作者</b>：Frank Mayet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine, particle accelerators, Large-scale machines, operators, particle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale machines like particle accelerators are usually run by a team of experienced operators. In case of a particle accelerator, these operators possess suitable background knowledge on both accelerator physics and the technology comprising the machine. Due to the complexity of the machine, particular subsystems of the machine are taken care of by experts, who the operators can turn to. In this work the reasoning and action (ReAct) prompting paradigm is used to couple an open-weights large language model (LLM) with a high-level machine control system framework and other tools, e.g. the electronic logbook or machine design documentation. By doing so, a multi-expert retrieval augmented generation (RAG) system is implemented, which assists operators in knowledge retrieval tasks, interacts with the machine directly if needed, or writes high level control system scripts. This consolidation of expert knowledge and machine interaction can simplify and speed up machine operation tasks for both new and experienced human operators.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：The Power of Question Translation Training in Multilingual Reasoning:  Broadened Scope and Deepened Insights</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01345">https://arxiv.org/abs/2405.01345</a></p>
  <p><b>作者</b>：Wenhao Zhu,  Shujian Huang,  Fei Yuan,  Cheng Chen,  Jiajun Chen,  Alexandra Birch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-English performance presents, model English, Bridging the significant, great challenge, language model English</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bridging the significant gap between large language model's English and non-English performance presents a great challenge. While some previous studies attempt to mitigate this gap with translated training data, the recently proposed question alignment approach leverages the model's English expertise to improve multilingual performance with minimum usage of expensive, error-prone translation. In this paper, we explore how broadly this method can be applied by examining its effects in reasoning with executable code and reasoning with common sense. We also explore how to apply this approach efficiently to extremely large language models using proxy-tuning. Experiment results on multilingual reasoning benchmarks mGSM, mSVAMP and xCSQA demonstrate that the question alignment approach can be used to boost multilingual performance across diverse reasoning scenarios, model families, and sizes. For instance, when applied to the LLaMA2 models, our method brings an average accuracy improvements of 12.2% on mGSM even with the 70B model. To understand the mechanism of its success, we analyze representation space, chain-of-thought and translation data scales, which reveals how question translation training strengthens language alignment within LLMs and shapes their working patterns.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf  Disease Remediation</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01310">https://arxiv.org/abs/2405.01310</a></p>
  <p><b>作者</b>：Dr. Selva Kumar S,  Afifah Khan Mohammed Ajmal Khan,  Imadh Ajaz Banday,  Manikantha Gada,  Vibha Venkatesh Shanbhag</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：Retrieval Augmented Generation, Augmented Generation, Retrieval Augmented, innovative AI-driven precision, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research introduces an innovative AI-driven precision agriculture system, leveraging YOLOv8 for disease identification and Retrieval Augmented Generation (RAG) for context-aware diagnosis. Focused on addressing the challenges of diseases affecting the coffee production sector in Karnataka, The system integrates sophisticated object detection techniques with language models to address the inherent constraints associated with Large Language Models (LLMs). Our methodology not only tackles the issue of hallucinations in LLMs, but also introduces dynamic disease identification and remediation strategies. Real-time monitoring, collaborative dataset expansion, and organizational involvement ensure the system's adaptability in diverse agricultural settings. The effect of the suggested system extends beyond automation, aiming to secure food supplies, protect livelihoods, and promote eco-friendly farming practices. By facilitating precise disease identification, the system contributes to sustainable and environmentally conscious agriculture, reducing reliance on pesticides. Looking to the future, the project envisions continuous development in RAG-integrated object detection systems, emphasizing scalability, reliability, and usability. This research strives to be a beacon for positive change in agriculture, aligning with global efforts toward sustainable and technologically enhanced food production.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：The Effectiveness of LLMs as Annotators: A Comparative Overview and  Empirical Analysis of Direct Representation</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01299">https://arxiv.org/abs/2405.01299</a></p>
  <p><b>作者</b>：Maja Pavlovic,  Massimo Poesio</p>
  <p><b>备注</b>：LREC-COLING NLPerspectives workshop</p>
  <p><b>关键词</b>：Large Language Models, powerful support tools, application domains, emerged as powerful, range of application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Low-resource speech recognition and dialect identification of Irish in a  multi-task framework</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01293">https://arxiv.org/abs/2405.01293</a></p>
  <p><b>作者</b>：Liam Lonergan,  Mengjie Qian,  Neasa Ní Chiaráin,  Christer Gobl,  Ailbhe Ní Chasaide</p>
  <p><b>备注</b>：7 pages. Accepted to Odyssey 2024 - The Speaker and Language Recognition Workshop</p>
  <p><b>关键词</b>：Hybrid CTC, Intermediate CTC, Attention encoder-decoder models, Attention encoder-decoder, CTC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the use of Hybrid CTC/Attention encoder-decoder models trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech recognition (ASR) and dialect identification (DID). Results are compared to the current best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN). An optimal InterCTC setting is initially established using a Conformer encoder. This setting is then used to train a model with an E-branchformer encoder and the performance of both architectures are compared. A multi-task fine-tuning approach is adopted for language model (LM) shallow fusion. The experiments yielded an improvement in DID accuracy of 10.8% relative to a baseline ECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task approach emerges as a promising strategy for Irish low-resource ASR and DID.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine  Translation</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01280">https://arxiv.org/abs/2405.01280</a></p>
  <p><b>作者</b>：Hao Wang,  Tetsuro Morimura,  Ukyo Honda,  Daisuke Kawahara</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural machine translation, NAR, machine translation, low latency, latency in neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-autoregressive (NAR) language models are known for their low latency in neural machine translation (NMT). However, a performance gap exists between NAR and autoregressive models due to the large decoding space and difficulty in capturing dependency between target words accurately. Compounding this, preparing appropriate training data for NAR models is a non-trivial task, often exacerbating exposure bias. To address these challenges, we apply reinforcement learning (RL) to Levenshtein Transformer, a representative edit-based NAR model, demonstrating that RL with self-generated data can enhance the performance of edit-based NAR models. We explore two RL approaches: stepwise reward maximization and episodic reward maximization. We discuss the respective pros and cons of these two approaches and empirically verify them. Moreover, we experimentally investigate the impact of temperature setting on performance, confirming the importance of proper temperature setting for NAR models' training.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Identification of Entailment and Contradiction Relations between Natural  Language Sentences: A Neurosymbolic Approach</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01259">https://arxiv.org/abs/2405.01259</a></p>
  <p><b>作者</b>：Xuyao Feng,  Anthony Hunter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recognizing Textual Entailment, Natural language inference, natural language understanding, Recognizing Textual, Natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language inference (NLI), also known as Recognizing Textual Entailment (RTE), is an important aspect of natural language understanding. Most research now uses machine learning and deep learning to perform this task on specific datasets, meaning their solution is not explainable nor explicit. To address the need for an explainable approach to RTE, we propose a novel pipeline that is based on translating text into an Abstract Meaning Representation (AMR) graph. For this we use a pre-trained AMR parser. We then translate the AMR graph into propositional logic and use a SAT solver for automated reasoning. In text, often commonsense suggests that an entailment (or contradiction) relationship holds between a premise and a claim, but because different wordings are used, this is not identified from their logical representations. To address this, we introduce relaxation methods to allow replacement or forgetting of some propositions. Our experimental results show this pipeline performs well on four RTE datasets.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Prompt engineering paradigms for medical applications: scoping review  and recommendations for better practices</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01249">https://arxiv.org/abs/2405.01249</a></p>
  <p><b>作者</b>：Jamil Zaghir,  Marco Naguib,  Mina Bjelogrlic,  Aurélie Névéol,  Xavier Tannier,  Christian Lovis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, Prompt engineering, medical domain, language models, medical domain remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt engineering is crucial for harnessing the potential of large language models (LLMs), especially in the medical domain where specialized terminology and phrasing is used. However, the efficacy of prompt engineering in the medical domain remains to be explored. In this work, 114 recent studies (2022-2024) applying prompt engineering in medicine, covering prompt learning (PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used interchangeably. ChatGPT is the most commonly used LLM, with seven papers using it for processing sensitive clinical data. Chain-of-Thought emerges as the most common prompt engineering technique. While PL and PT articles typically provide a baseline for evaluating prompt-based approaches, 64% of PD studies lack non-prompt-related baselines. We provide tables and figures summarizing existing work, and reporting recommendations to guide future research contributions.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Boosting Jailbreak Attack with Momentum</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01229">https://arxiv.org/abs/2405.01229</a></p>
  <p><b>作者</b>：Yihao Zhang,  Zeming Wei</p>
  <p><b>备注</b>：ICLR 2024 Workshop on Reliable and Responsible Foundation Models</p>
  <p><b>关键词</b>：Large Language Models, achieved remarkable success, Greedy Coordinate Gradient, notably the well-documented, diverse tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-documented \textit{jailbreak} attack. Recently, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous iterations. Specifically, we introduce the \textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) attack, which incorporates a momentum term into the gradient heuristic. Experimental results showcase the notable enhancement achieved by MAP in gradient-based attacks on aligned language models. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：DMON: A Simple yet Effective Approach for Argument Structure Learning</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01216">https://arxiv.org/abs/2405.01216</a></p>
  <p><b>作者</b>：Wei Sun,  Mingxiao Li,  Jingyuan Sun,  Jesse Davis,  Marie-Francine Moens</p>
  <p><b>备注</b>：COLING 2024</p>
  <p><b>关键词</b>：entails predicting relations, entails predicting, Argument structure learning, structure learning, ASL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Argument structure learning~(ASL) entails predicting relations between arguments. Because it can structure a document to facilitate its understanding, it has been widely applied in many fields~(medical, commercial, and scientific domains). Despite its broad utilization, ASL remains a challenging task because it involves examining the complex relationships between the sentences in a potentially unstructured discourse. To resolve this problem, we have developed a simple yet effective approach called Dual-tower Multi-scale cOnvolution neural Network~(DMON) for the ASL task. Specifically, we organize arguments into a relationship matrix that together with the argument embeddings forms a relationship tensor and design a mechanism to capture relations with contextual arguments. Experimental results on three different-domain argument mining datasets demonstrate that our framework outperforms state-of-the-art models. The code is available at this https URL .</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：TartuNLP at EvaLatin 2024: Emotion Polarity Detection</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01159">https://arxiv.org/abs/2405.01159</a></p>
  <p><b>作者</b>：Aleksei Dorkin,  Kairit Sirts</p>
  <p><b>备注</b>：Accepted to The Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA 2024)</p>
  <p><b>关键词</b>：TartuNLP team submission, emotion polarity detection, historical Latin texts, paper presents, presents the TartuNLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the TartuNLP team submission to EvaLatin 2024 shared task of the emotion polarity detection for historical Latin texts. Our system relies on two distinct approaches to annotating training data for supervised learning: 1) creating heuristics-based labels by adopting the polarity lexicon provided by the organizers and 2) generating labels with GPT4. We employed parameter efficient fine-tuning using the adapters framework and experimented with both monolingual and cross-lingual knowledge transfer for training language and task adapters. Our submission with the LLM-generated labels achieved the overall first place in the emotion polarity detection task. Our results show that LLM-based annotations show promising results on texts in Latin.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：It Couldn't Help But Overhear: On the Limits of Modelling  Meta-Communicative Grounding Acts with Supervised Learning</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01139">https://arxiv.org/abs/2405.01139</a></p>
  <p><b>作者</b>：Brielen Madureira,  David Schlangen</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：building common ground, Active participation, common ground, producers and recipients, conversation is key</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active participation in a conversation is key to building common ground, since understanding is jointly tailored by producers and recipients. Overhearers are deprived of the privilege of performing grounding acts and can only conjecture about intended meanings. Still, data generation and annotation, modelling, training and evaluation of NLP dialogue models place reliance on the overhearing paradigm. How much of the underlying grounding processes are thereby forfeited? As we show, there is evidence pointing to the impossibility of properly modelling human meta-communicative acts with data-driven learning models. In this paper, we discuss this issue and provide a preliminary analysis on the variability of human decisions for requesting clarification. Most importantly, we wish to bring this topic back to the community's table, encouraging discussion on the consequences of having models designed to only "listen in".</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Efficient Data Generation for Source-grounded Information-seeking  Dialogs: A Use Case for Meeting Transcripts</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01121">https://arxiv.org/abs/2405.01121</a></p>
  <p><b>作者</b>：Lotem Golany,  Filippo Galgani,  Maya Mamo,  Nimrod Parasol,  Omer Vandsburger,  Nadav Bar,  Ido Dagan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：creating source-grounded information-seeking, creating source-grounded, costly and hard, hard to implement, implement due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing methods for creating source-grounded information-seeking dialog datasets are often costly and hard to implement due to their sole reliance on human annotators. We propose combining large language models (LLMs) prompting with human expertise for more efficient and reliable data generation. Instead of the labor-intensive Wizard-of-Oz (WOZ) method, where two annotators generate a dialog from scratch, role-playing agent and user, we use LLM generation to simulate the two roles. Annotators then verify the output and augment it with attribution data. We demonstrate our method by constructing MISeD -- Meeting Information Seeking Dialogs dataset -- the first information-seeking dialog dataset focused on meeting transcripts. Models finetuned with MISeD demonstrate superior performance on our test set, as well as on a novel fully-manual WOZ test set and an existing query-based summarization benchmark, suggesting the utility of our approach.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization  Tool for Mitigating the Risk of Whistleblower Re-Identification</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01097">https://arxiv.org/abs/2405.01097</a></p>
  <p><b>作者</b>：Dimitri Staufer,  Frank Pallas,  Bettina Berendt</p>
  <p><b>备注</b>：Accepted for publication at the ACM Conference on Fairness, Accountability, and Transparency 2024 (ACM FAccT'24). This is a preprint manuscript (authors' own version before final copy-editing)</p>
  <p><b>关键词</b>：private sectors, essential for ensuring, ensuring transparency, transparency and accountability, public and private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU WBD, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other NE labels) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a LLM that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool's effectiveness using court cases from the ECHR and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution (AA) attacks and utility loss statistically using the popular IMDb62 movie reviews dataset. Our method can significantly reduce AA accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original content's semantics.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Few Shot Class Incremental Learning using Vision-Language models</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01040">https://arxiv.org/abs/2405.01040</a></p>
  <p><b>作者</b>：Anurag Kumar,  Chinmay Bharti,  Saikat Dutta,  Srikrishna Karanam,  Biplab Banerjee</p>
  <p><b>备注</b>：under review at Pattern Recognition Letters</p>
  <p><b>关键词</b>：computer vision tasks, supervised computer vision, demonstrated remarkable performance, remarkable performance comparable, Recent advancements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in deep learning have demonstrated remarkable performance comparable to human capabilities across various supervised computer vision tasks. However, the prevalent assumption of having an extensive pool of training data encompassing all classes prior to model training often diverges from real-world scenarios, where limited data availability for novel classes is the norm. The challenge emerges in seamlessly integrating new classes with few samples into the training data, demanding the model to adeptly accommodate these additions without compromising its performance on base classes. To address this exigency, the research community has introduced several solutions under the realm of few-shot class incremental learning (FSCIL).
In this study, we introduce an innovative FSCIL framework that utilizes language regularizer and subspace regularizer. During base training, the language regularizer helps incorporate semantic information extracted from a Vision-Language model. The subspace regularizer helps in facilitating the model's acquisition of nuanced connections between image and text semantics inherent to base classes during incremental training. Our proposed framework not only empowers the model to embrace novel classes with limited data, but also ensures the preservation of performance on base classes. To substantiate the efficacy of our approach, we conduct comprehensive experiments on three distinct FSCIL benchmarks, where our framework attains state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：UniGen: Universal Domain Generalization for Sentiment Classification via  Zero-shot Dataset Generation</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01022">https://arxiv.org/abs/2405.01022</a></p>
  <p><b>作者</b>：Juhwan Choi,  Yeonghwa Kim,  Seunguk Yu,  JungMin Yun,  YoungBin Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prompt-based few-shot learning, exhibited great flexibility, pre-trained language models, extensive parameter size, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although pre-trained language models have exhibited great flexibility and versatility with prompt-based few-shot learning, they suffer from the extensive parameter size and limited applicability for inference. Recent studies have suggested that PLMs be used as dataset generators and a tiny task-specific model be trained to achieve efficient inference. However, their applicability to various domains is limited because they tend to generate domain-specific datasets. In this work, we propose a novel approach to universal domain generalization that generates a dataset regardless of the target domain. This allows for generalization of the tiny task model to any domain that shares the label space, thus enhancing the real-world applicability of the dataset generation paradigm. Our experiments indicate that the proposed method accomplishes generalizability across various domains while using a parameter set that is orders of magnitude smaller than PLMs.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：The IgboAPI Dataset: Empowering Igbo Language Technologies through  Multi-dialectal Enrichment</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00997">https://arxiv.org/abs/2405.00997</a></p>
  <p><b>作者</b>：Chris Chinenye Emezue,  Ifeoma Okoh,  Chinedu Mbonu,  Chiamaka Chukwuneke,  Daisy Lal,  Ignatius Ezeani,  Paul Rayson,  Ijemma Onwuzulike,  Chukwuma Okeke,  Gerald Nweya,  Bright Ogbonna,  Chukwuebuka Oraegbunam,  Esther Chidinma Awo-Ndubuisi,  Akudo Amarachukwu Osuagwu,  Obioha Nmezi</p>
  <p><b>备注</b>：Accepted to the LREC-COLING 2024 conference</p>
  <p><b>关键词</b>：Igbo semantic lexicon, Igbo semantic, Igbo, UNESCO study, language technologies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Igbo language is facing a risk of becoming endangered, as indicated by a 2025 UNESCO study. This highlights the need to develop language technologies for Igbo to foster communication, learning and preservation. To create robust, impactful, and widely adopted language technologies for Igbo, it is essential to incorporate the multi-dialectal nature of the language. The primary obstacle in achieving dialectal-aware language technologies is the lack of comprehensive dialectal datasets. In response, we present the IgboAPI dataset, a multi-dialectal Igbo-English dictionary dataset, developed with the aim of enhancing the representation of Igbo dialects. Furthermore, we illustrate the practicality of the IgboAPI dataset through two distinct studies: one focusing on Igbo semantic lexicon and the other on machine translation. In the semantic lexicon project, we successfully establish an initial Igbo semantic lexicon for the Igbo semantic tagger, while in the machine translation study, we demonstrate that by finetuning existing machine translation systems using the IgboAPI dataset, we significantly improve their ability to handle dialectal variations in sentences.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Context-Aware Clustering using Large Language Models</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00988">https://arxiv.org/abs/2405.00988</a></p>
  <p><b>作者</b>：Sindhu Tipirneni,  Ravinarayana Adkathimar,  Nurendra Choudhary,  Gaurush Hiranandani,  Rana Ali Amjad,  Vassilis N. Ioannidis,  Changhe Yuan,  Chandan K. Reddy</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：Large Language Models, success of Large, Large Language, tasks remains underexplored, clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable success of Large Language Models (LLMs) in text understanding and generation, their potential for text clustering tasks remains underexplored. We observed that powerful closed-source LLMs provide good quality clusterings of entity sets but are not scalable due to the massive compute power required and the associated costs. Thus, we propose CACTUS (Context-Aware ClusTering with aUgmented triplet losS), a systematic approach that leverages open-source LLMs for efficient and effective supervised clustering of entity subsets, particularly focusing on text-based entities. Existing text clustering methods fail to effectively capture the context provided by the entity subset. Moreover, though there are several language modeling based approaches for clustering, very few are designed for the task of supervised clustering. This paper introduces a novel approach towards clustering entity subsets using LLMs by capturing context via a scalable inter-entity attention mechanism. We propose a novel augmented triplet loss function tailored for supervised clustering, which addresses the inherent challenges of directly applying the triplet loss to this problem. Furthermore, we introduce a self-supervised clustering task based on text augmentation techniques to improve the generalization of our model. For evaluation, we collect ground truth clusterings from a closed-source LLM and transfer this knowledge to an open-source LLM under the supervised clustering framework, allowing a faster and cheaper open-source model to perform the same task. Experiments on various e-commerce query and product clustering datasets demonstrate that our proposed approach significantly outperforms existing unsupervised and supervised baselines under various external clustering evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：On the Evaluation of Machine-Generated Reports</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00982">https://arxiv.org/abs/2405.00982</a></p>
  <p><b>作者</b>：James Mayfield,  Eugene Yang,  Dawn Lawrie,  Sean MacAvaney,  Paul McNamee,  Douglas W. Oard,  Luca Soldaini,  Ian Soboroff,  Orion Weller,  Efsun Kayi,  Kate Sanders,  Marc Mason,  Noah Hibbler</p>
  <p><b>备注</b>：12 pages, 4 figures, accepted at SIGIR 2024 as perspective paper</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, Models, Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have enabled new ways to satisfy information needs. Although great strides have been made in applying them to settings like document ranking and short-form text generation, they still struggle to compose complete, accurate, and verifiable long-form reports. Reports with these qualities are necessary to satisfy the complex, nuanced, or multi-faceted information needs of users. In this perspective paper, we draw together opinions from industry and academia, and from a variety of related research areas, to present our vision for automatic report generation, and -- critically -- a flexible framework by which such reports can be evaluated. In contrast with other summarization tasks, automatic report generation starts with a detailed description of an information need, stating the necessary background, requirements, and scope of the report. Further, the generated reports should be complete, accurate, and verifiable. These qualities, which are desirable -- if not required -- in many analytic report-writing settings, require rethinking how to build and evaluate systems that exhibit these qualities. To foster new efforts in building these systems, we present an evaluation framework that draws on ideas found in various evaluations. To test completeness and accuracy, the framework uses nuggets of information, expressed as questions and answers, that need to be part of any high-quality generated report. Additionally, evaluation of citations that map claims made in the report to their source documents ensures verifiability.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Bayesian Optimization with LLM-Based Acquisition Functions for Natural  Language Preference Elicitation</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00981">https://arxiv.org/abs/2405.00981</a></p>
  <p><b>作者</b>：David Eric Austin,  Anton Korikov,  Armin Toroghi,  Scott Sanner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Designing preference elicitation, personalized conversational recommendation, user top item, top item preferences, quickly ascertain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing preference elicitation (PE) methodologies that can quickly ascertain a user's top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to generate NL queries which actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00980">https://arxiv.org/abs/2405.00980</a></p>
  <p><b>作者</b>：Zhe Niu,  Ronglai Zuo,  Brian Mak,  Fangyun Wei</p>
  <p><b>备注</b>：Accepted by LREC-COLING 2024</p>
  <p><b>关键词</b>：Hong Kong sign, Hong Kong, Kong sign language, Kong sign, sign language recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL) dataset collected from a TV news program over a period of 7 months. The dataset is collected to enrich resources for HKSL and support research in large-vocabulary continuous sign language recognition (SLR) and translation (SLT). It consists of 16.07 hours of sign videos of two signers with a vocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K Chinese words (for SLT). One signer has 11.66 hours of sign videos and the other has 4.41 hours. One objective in building the dataset is to support the investigation of how well large-vocabulary continuous sign language recognition/translation can be done for a single signer given a (relatively) large amount of his/her training data, which could potentially lead to the development of new modeling methods. Besides, most parts of the data collection pipeline are automated with little human intervention; we believe that our collection method can be scaled up to collect more sign language data easily for SLT in the future for any sign languages if such sign-interpreted videos are available. We also run a SOTA SLR/SLT model on the dataset and get a baseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58 for benchmarking future research on the dataset.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Language Fairness in Multilingual Information Retrieval</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00978">https://arxiv.org/abs/2405.00978</a></p>
  <p><b>作者</b>：Eugene Yang,  Thomas Jänich,  James Mayfield,  Dawn Lawrie</p>
  <p><b>备注</b>：5 pages, 1 figure, accepted at SIGIR 2024 as short paper</p>
  <p><b>关键词</b>：Multilingual information retrieval, information retrieval, problem of ranking, query expressed, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilingual information retrieval (MLIR) considers the problem of ranking documents in several languages for a query expressed in a language that may differ from any of those languages. Recent work has observed that approaches such as combining ranked lists representing a single document language each or using multilingual pretrained language models demonstrate a preference for one language over others. This results in systematic unfair treatment of documents in different languages. This work proposes a language fairness metric to evaluate whether documents across different languages are fairly ranked through statistical equivalence testing using the Kruskal-Wallis test. In contrast to most prior work in group fairness, we do not consider any language to be an unprotected group. Thus our proposed measure, PEER (Probability of EqualExpected Rank), is the first fairness metric specifically designed to capture the language fairness of MLIR systems. We demonstrate the behavior of PEER on artificial ranked lists. We also evaluate real MLIR systems on two publicly available benchmarks and show that the PEER scores align with prior analytical findings on MLIR fairness. Our implementation is compatible with ir-measures and is available at this http URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Distillation for Multilingual Information Retrieval</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00977">https://arxiv.org/abs/2405.00977</a></p>
  <p><b>作者</b>：Eugene Yang,  Dawn Lawrie,  James Mayfield</p>
  <p><b>备注</b>：6 pages, 1 figure, accepted at SIGIR 2024 as short paper</p>
  <p><b>关键词</b>：cross-language neural dual-encoder, cross-language information retrieval, neural dual-encoder model, translation and distillation, cross-language neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work in cross-language information retrieval (CLIR), where queries and documents are in different languages, has shown the benefit of the Translate-Distill framework that trains a cross-language neural dual-encoder model using translation and distillation. However, Translate-Distill only supports a single document language. Multilingual information retrieval (MLIR), which ranks a multilingual document collection, is harder to train than CLIR because the model must assign comparable relevance scores to documents in different languages. This work extends Translate-Distill and propose Multilingual Translate-Distill (MTD) for MLIR. We show that ColBERT-X models trained with MTD outperform their counterparts trained ith Multilingual Translate-Train, which is the previous state-of-the-art training approach, by 5% to 25% in nDCG@20 and 15% to 45% in MAP. We also show that the model is robust to the way languages are mixed in training batches. Our implementation is available on GitHub.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：PLAID SHIRTTT for Large-Scale Streaming Dense Retrieval</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00975">https://arxiv.org/abs/2405.00975</a></p>
  <p><b>作者</b>：Dawn Lawrie,  Efsun Kayi,  Eugene Yang,  James Mayfield,  Douglas W. Oard</p>
  <p><b>备注</b>：5 pages, 1 figure, accepted at SIGIR 2024 as short paper</p>
  <p><b>关键词</b>：late interaction bi-encoder, pretrained language models, ColBERT late interaction, consistently achieves, models for ranking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>PLAID, an efficient implementation of the ColBERT late interaction bi-encoder using pretrained language models for ranking, consistently achieves state-of-the-art performance in monolingual, cross-language, and multilingual retrieval. PLAID differs from ColBERT by assigning terms to clusters and representing those terms as cluster centroids plus compressed residual vectors. While PLAID is effective in batch experiments, its performance degrades in streaming settings where documents arrive over time because representations of new tokens may be poorly modeled by the earlier tokens used to select cluster centroids. PLAID Streaming Hierarchical Indexing that Runs on Terabytes of Temporal Text (PLAID SHIRTTT) addresses this concern using multi-phase incremental indexing based on hierarchical sharding. Experiments on ClueWeb09 and the multilingual NeuCLIR collection demonstrate the effectiveness of this approach both for the largest collection indexed to date by the ColBERT architecture and in the multilingual setting, respectively.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：CACTUS: Chemistry Agent Connecting Tool-Usage to Science</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00972">https://arxiv.org/abs/2405.00972</a></p>
  <p><b>作者</b>：Andrew D. McNaughton,  Gautham Ramalaxmi,  Agustin Kruel,  Carter R. Knutson,  Rohith A. Varikoti,  Neeraj Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Chemistry Agent Connecting, Large language models, shown remarkable potential, Agent Connecting Tool-Usage, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee  Responses</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00970">https://arxiv.org/abs/2405.00970</a></p>
  <p><b>作者</b>：Jionghao Lin,  Zifei Han,  Danielle R. Thomas,  Ashish Gurung,  Shivang Gupta,  Vincent Aleven,  Kenneth R. Koedinger</p>
  <p><b>备注</b>：International Journal of Artificial Intelligence in Education</p>
  <p><b>关键词</b>：effective instructional method, qualified tutors, instructional method, qualified tutors remains, widely acknowledged</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One-on-one tutoring is widely acknowledged as an effective instructional method, conditioned on qualified tutors. However, the high demand for qualified tutors remains a challenge, often necessitating the training of novice tutors (i.e., trainees) to ensure effective tutoring. Research suggests that providing timely explanatory feedback can facilitate the training process for trainees. However, it presents challenges due to the time-consuming nature of assessing trainee performance by human experts. Inspired by the recent advancements of large language models (LLMs), our study employed the GPT-4 model to build an explanatory feedback system. This system identifies trainees' responses in binary form (i.e., correct/incorrect) and automatically provides template-based feedback with responses appropriately rephrased by the GPT-4 model. We conducted our study on 410 responses from trainees across three training lessons: Giving Effective Praise, Reacting to Errors, and Determining What Students Know. Our findings indicate that: 1) using a few-shot approach, the GPT-4 model effectively identifies correct/incorrect trainees' responses from three training lessons with an average F1 score of 0.84 and an AUC score of 0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases incorrect trainees' responses into desired responses, achieving performance comparable to that of human experts.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Efficient Compression of Multitask Multilingual Speech Models</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00966">https://arxiv.org/abs/2405.00966</a></p>
  <p><b>作者</b>：Thomas Palmeira Ferraz</p>
  <p><b>备注</b>：Master Thesis</p>
  <p><b>关键词</b>：speech model covering, model covering, ASR, languages, multilingual speech model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we examine its limitations, demonstrating the presence of speaker-related (gender, age) and model-related (resourcefulness and model size) bias. Despite that, we show that only model-related bias are amplified by quantization, impacting more low-resource languages and smaller models. Searching for a better compression approach, we propose DistilWhisper, an approach that is able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：The Role of Model Architecture and Scale in Predicting Molecular  Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00949">https://arxiv.org/abs/2405.00949</a></p>
  <p><b>作者</b>：Lee Youngmin,  Lang S.I.D. Andrew,  Cai Duoduo,  Wheat R. Stephen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Line Entry System, Input Line Entry, efficacy of Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study introduces a systematic framework to compare the efficacy of Large Language Models (LLMs) for fine-tuning across various cheminformatics tasks. Employing a uniform training methodology, we assessed three well-known models-RoBERTa, BART, and LLaMA-on their ability to predict molecular properties using the Simplified Molecular Input Line Entry System (SMILES) as a universal molecular representation format. Our comparative analysis involved pre-training 18 configurations of these models, with varying parameter sizes and dataset scales, followed by fine-tuning them on six benchmarking tasks from DeepChem. We maintained consistent training environments across models to ensure reliable comparisons. This approach allowed us to assess the influence of model type, size, and training dataset size on model performance. Specifically, we found that LLaMA-based models generally offered the lowest validation loss, suggesting their superior adaptability across tasks and scales. However, we observed that absolute validation loss is not a definitive indicator of model performance - contradicts previous research - at least for fine-tuning tasks: instead, model size plays a crucial role. Through rigorous replication and validation, involving multiple training and fine-tuning cycles, our study not only delineates the strengths and limitations of each model type but also provides a robust methodology for selecting the most suitable LLM for specific cheminformatics applications. This research underscores the importance of considering model architecture and dataset characteristics in deploying AI for molecular property prediction, paving the way for more informed and effective utilization of AI in drug discovery and related fields.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Modeling Empathetic Alignment in Conversation</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00948">https://arxiv.org/abs/2405.00948</a></p>
  <p><b>作者</b>：Jiamin Yang,  David Jurgens</p>
  <p><b>备注</b>：Camera-ready version for NAACL 2024</p>
  <p><b>关键词</b>：Empathy requires perspective-taking, requires perspective-taking, understanding in language, experienced and communicate, communicate that understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Empathy requires perspective-taking: empathetic responses require a person to reason about what another has experienced and communicate that understanding in language. However, most NLP approaches to empathy do not explicitly model this alignment process. Here, we introduce a new approach to recognizing alignment in empathetic speech, grounded in Appraisal Theory. We introduce a new dataset of over 9.2K span-level annotations of different types of appraisals of a person's experience and over 3K empathetic alignments between a speaker's and observer's speech. Through computational experiments, we show that these appraisals and alignments can be accurately recognized. In experiments in over 9.2M Reddit conversations, we find that appraisals capture meaningful groupings of behavior but that most responses have minimal alignment. However, we find that mental health professionals engage with substantially more empathetic alignment.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content  Understanding Abilities Of LLMs</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00942">https://arxiv.org/abs/2405.00942</a></p>
  <p><b>作者</b>：Somesh Singh,  Harini S I,  Yaman K Singla,  Veeky Baths,  Rajiv Ratn Shah,  Changyou Chen,  Balaji Krishnamurthy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：communicator generates downstream, Communication is defined, Receiver behavior, generates downstream receiver, communicator generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication is defined as ``Who says what to whom with what effect.'' A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior data is often ignored while training large language models. We show that training LLMs on receiver behavior can actually help improve their content-understanding abilities. Specifically, we show that training LLMs to predict the receiver behavior of likes and comments improves the LLM's performance on a wide variety of downstream content understanding tasks. We show this performance increase over 40 video and image understanding tasks over 23 benchmark datasets across both 0-shot and fine-tuning settings, outperforming many supervised baselines. Moreover, since receiver behavior, such as likes and comments, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free-lunch. We release the receiver behavior cleaned comments and likes of 750k images and videos collected from multiple platforms along with our instruction-tuning data.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：A Named Entity Recognition and Topic Modeling-based Solution for  Locating and Better Assessment of Natural Disasters in Social Media</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00903">https://arxiv.org/abs/2405.00903</a></p>
  <p><b>作者</b>：Ayaz Mehmood,  Muhammad Tayyab Zamir,  Muhammad Asif Ayub,  Nasir Ahmad,  Kashif Ahmad</p>
  <p><b>备注</b>：15 pages; 4 tables; 4 figures</p>
  <p><b>关键词</b>：social media content, social media, social media posts, media content, application domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last decade, similar to other application domains, social media content has been proven very effective in disaster informatics. However, due to the unstructured nature of the data, several challenges are associated with disaster analysis in social media content. To fully explore the potential of social media content in disaster informatics, access to relevant content and the correct geo-location information is very critical. In this paper, we propose a three-step solution to tackling these challenges. Firstly, the proposed solution aims to classify social media posts into relevant and irrelevant posts followed by the automatic extraction of location information from the posts' text through Named Entity Recognition (NER) analysis. Finally, to quickly analyze the topics covered in large volumes of social media posts, we perform topic modeling resulting in a list of top keywords, that highlight the issues discussed in the tweet. For the Relevant Classification of Twitter Posts (RCTP), we proposed a merit-based fusion framework combining the capabilities of four different models namely BERT, RoBERTa, Distil BERT, and ALBERT obtaining the highest F1-score of 0.933 on a benchmark dataset. For the Location Extraction from Twitter Text (LETT), we evaluated four models namely BERT, RoBERTa, Distil BERTA, and Electra in an NER framework obtaining the highest F1-score of 0.960. For topic modeling, we used the BERTopic library to discover the hidden topic patterns in the relevant tweets. The experimental results of all the components of the proposed end-to-end solution are very encouraging and hint at the potential of social media content and NLP in disaster management.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Characterising the Creative Process in Humans and Large Language Models</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00899">https://arxiv.org/abs/2405.00899</a></p>
  <p><b>作者</b>：Surabhi S. Nath,  Peter Dayan,  Claire Stevenson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, Large language, Verbal Fluency Task, performing on par, creativity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models appear quite creative, often performing on par with the average human on creative tasks. However, research on LLM creativity has focused solely on \textit{products}, with little attention on the creative \textit{process}. Process analyses of human creativity often require hand-coded categories or exploit response times, which do not apply to LLMs. We provide an automated method to characterise how humans and LLMs explore semantic spaces on the Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task. We use sentence embeddings to identify response categories and compute semantic similarities, which we use to generate jump profiles. Our results corroborate earlier work in humans reporting both persistent (deep search in few semantic spaces) and flexible (broad search across multiple semantic spaces) pathways to creativity, where both pathways lead to similar creativity scores. LLMs were found to be biased towards either persistent or flexible paths, that varied across tasks. Though LLMs as a population match human profiles, their relationship with creativity is different, where the more flexible models score higher on creativity. Our dataset and scripts are available on \href{this https URL}{GitHub}.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：DynaMo: Accelerating Language Model Inference with Dynamic Multi-Token  Sampling</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00888">https://arxiv.org/abs/2405.00888</a></p>
  <p><b>作者</b>：Shikhar Tuli,  Chi-Heng Lin,  Yen-Chang Hsu,  Niraj K. Jha,  Yilin Shen,  Hongxia Jin</p>
  <p><b>备注</b>：Accepted at NAACL 2024</p>
  <p><b>关键词</b>：models operate autoregressively, operate autoregressively, language models operate, models, inference times</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional language models operate autoregressively, i.e., they predict one token at a time. Rapid explosion in model sizes has resulted in high inference times. In this work, we propose DynaMo, a suite of multi-token prediction language models that reduce net inference times. Our models $\textit{dynamically}$ predict multiple tokens based on their confidence in the predicted joint probability distribution. We propose a lightweight technique to train these models, leveraging the weights of traditional autoregressive counterparts. Moreover, we propose novel ways to enhance the estimated joint probability to improve text generation quality, namely co-occurrence weighted masking and adaptive thresholding. We also propose systematic qualitative and quantitative methods to rigorously test the quality of generated text for non-autoregressive generation. One of the models in our suite, DynaMo-7.3B-T3, achieves same-quality generated text as the baseline (Pythia-6.9B) while achieving 2.57$\times$ speed-up with only 5.87% and 2.67% parameter and training time overheads, respectively.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Math Multiple Choice Question Generation via Human-Large Language Model  Collaboration</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00864">https://arxiv.org/abs/2405.00864</a></p>
  <p><b>作者</b>：Jaewook Lee,  Digory Smith,  Simon Woodhead,  Andrew Lan</p>
  <p><b>备注</b>：17th International Conference on Educational Data Mining (EDM 2024)</p>
  <p><b>关键词</b>：evaluating students' knowledge, students' knowledge due, Multiple choice questions, Multiple choice, administration and grading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple choice questions (MCQs) are a popular method for evaluating students' knowledge due to their efficiency in administration and grading. Crafting high-quality math MCQs is a labor-intensive process that requires educators to formulate precise stems and plausible distractors. Recent advances in large language models (LLMs) have sparked interest in automating MCQ creation, but challenges persist in ensuring mathematical accuracy and addressing student errors. This paper introduces a prototype tool designed to facilitate collaboration between LLMs and educators for streamlining the math MCQ generation process. We conduct a pilot study involving math educators to investigate how the tool can help them simplify the process of crafting high-quality math MCQs. We found that while LLMs can generate well-formulated question stems, their ability to generate distractors that capture common student errors and misconceptions is limited. Nevertheless, a human-AI collaboration has the potential to enhance the efficiency and effectiveness of MCQ generation.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00828">https://arxiv.org/abs/2405.00828</a></p>
  <p><b>作者</b>：Arman Irani,  Ju Yeon Park,  Kevin Esterling,  Michalis Faloutsos</p>
  <p><b>备注</b>：8 pages, 2 figures, submitted to The 16th International Conference on Advances in Social Networks Analysis and Mining (ASONAM) '24</p>
  <p><b>关键词</b>：Argument Detection model, Argument Stance Classification, Large Language Models, comprehensive understanding, propose WIBA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose WIBA, a novel framework and suite of methods that enable the comprehensive understanding of "What Is Being Argued" across contexts. Our approach develops a comprehensive framework that detects: (a) the existence, (b) the topic, and (c) the stance of an argument, correctly accounting for the logical dependence among the three tasks. Our algorithm leverages the fine-tuning and prompt-engineering of Large Language Models. We evaluate our approach and show that it performs well in all the three capabilities. First, we develop and release an Argument Detection model that can classify a piece of text as an argument with an F1 score between 79% and 86% on three different benchmark datasets. Second, we release a language model that can identify the topic being argued in a sentence, be it implicit or explicit, with an average similarity score of 71%, outperforming current naive methods by nearly 40%. Finally, we develop a method for Argument Stance Classification, and evaluate the capability of our approach, showing it achieves a classification F1 score between 71% and 78% across three diverse benchmark datasets. Our evaluation demonstrates that WIBA allows the comprehensive understanding of What Is Being Argued in large corpora across diverse contexts, which is of core interest to many applications in linguistics, communication, and social and computer science. To facilitate accessibility to the advancements outlined in this work, we release WIBA as a free open access platform (wiba.dev).</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace  Setting</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00823">https://arxiv.org/abs/2405.00823</a></p>
  <p><b>作者</b>：Olly Styles,  Sam Miller,  Patricio Cerda-Mardini,  Tanaya Guha,  Victor Sanchez,  Bertie Vidgen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmark dataset, dataset for evaluating, WorkBench, tasks, evaluating agents' ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce WorkBench: a benchmark dataset for evaluating agents' ability to execute tasks in a workplace setting. WorkBench contains a sandbox environment with five databases, 26 tools, and 690 tasks. These tasks represent common business activities, such as sending emails and scheduling meetings. The tasks in WorkBench are challenging as they require planning, tool selection, and often multiple actions. If a task has been successfully executed, one (or more) of the database values may change. The correct outcome for each task is unique and unambiguous, which allows for robust, automated evaluation. We call this key contribution outcome-centric evaluation. We evaluate five existing ReAct agents on WorkBench, finding they successfully complete as few as 3% of tasks (Llama2-70B), and just 43% for the best-performing (GPT-4). We further find that agents' errors can result in the wrong action being taken, such as an email being sent to the wrong person. WorkBench reveals weaknesses in agents' ability to undertake common business activities, raising questions about their use in high-stakes workplace settings. WorkBench is publicly available as a free resource at this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Uncovering Agendas: A Novel French & English Dataset for Agenda  Detection on Social Media</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00821">https://arxiv.org/abs/2405.00821</a></p>
  <p><b>作者</b>：Gregorios Katsios,  Ning Sa,  Ankita Bhaumik,  Tomek Strzalkowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：call for action, behavior and decision, decision making, making of groups, groups or communities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The behavior and decision making of groups or communities can be dramatically influenced by individuals pushing particular agendas, e.g., to promote or disparage a person or an activity, to call for action, etc.. In the examination of online influence campaigns, particularly those related to important political and social events, scholars often concentrate on identifying the sources responsible for setting and controlling the agenda (e.g., public media). In this article we present a methodology for detecting specific instances of agenda control through social media where annotated data is limited or non-existent. By using a modest corpus of Twitter messages centered on the 2022 French Presidential Elections, we carry out a comprehensive evaluation of various approaches and techniques that can be applied to this problem. Our findings demonstrate that by treating the task as a textual entailment problem, it is possible to overcome the requirement for a large annotated training dataset.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题："Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00801">https://arxiv.org/abs/2405.00801</a></p>
  <p><b>作者</b>：Scott Rome,  Tianwen Chen,  Raphael Tang,  Luwei Zhou,  Ferhan Ture</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Customer, Customer service, AMA, service, agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or "chat bots". On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment.
This raises the bar for customer service agents. They need to accurately understand the customer's question or concern, identify a solution that is acceptable yet feasible (and within the company's policy), all while handling multiple conversations at once.
In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations -- the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating its usefulness as an AI-assisted feature for customer care.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Modeling Caption Diversity in Contrastive Vision-Language Pretraining</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00740">https://arxiv.org/abs/2405.00740</a></p>
  <p><b>作者</b>：Samuel Lavoie,  Polina Kirichenko,  Mark Ibrahim,  Mahmoud Assran,  Andrew Gordon Wildon,  Aaron Courville,  Nicolas Ballas</p>
  <p><b>备注</b>：14 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：Language Image Pretraining, Latent Language Image, Contrastive Language Pretraining, Language Pretraining, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are a thousand ways to caption an image. Contrastive Language Pretraining (CLIP) on the other hand, works by mapping an image and its caption to a single vector -- limiting how well CLIP-like models can represent the diverse ways to describe an image. In this work, we introduce Llip, Latent Language Image Pretraining, which models the diversity of captions that could match an image. Llip's vision encoder outputs a set of visual features that are mixed into a final representation by conditioning on information derived from the text. We show that Llip outperforms non-contextualized baselines like CLIP and SigLIP on a variety of tasks even with large-scale encoders. Llip improves zero-shot classification by an average of 2.9% zero-shot classification benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by 1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by 6.0%. We provide a comprehensive analysis of the components introduced by the method and demonstrate that Llip leads to richer visual representations.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00732">https://arxiv.org/abs/2405.00732</a></p>
  <p><b>作者</b>：Justin Zhao,  Timothy Wang,  Wael Abid,  Geoffrey Angus,  Arnav Garg,  Jeffery Kinnison,  Alex Sherstinsky,  Piero Molino,  Travis Addair,  Devvret Rishi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Parameter Efficient Fine-Tuning, Low Rank Adaptation, widely adopted methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted methods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models (LLMs). LoRA reduces the number of trainable parameters and memory usage while achieving comparable performance to full fine-tuning. We aim to assess the viability of training and serving LLMs fine-tuned with LoRA in real-world applications. First, we measure the quality of LLMs fine-tuned with quantized low rank adapters across 10 base models and 31 tasks for a total of 310 models. We find that 4-bit LoRA fine-tuned models outperform base models by 34 points and GPT-4 by 10 points on average. Second, we investigate the most effective base models for fine-tuning and assess the correlative and predictive capacities of task complexity heuristics in forecasting the outcomes of fine-tuning. Finally, we evaluate the latency and concurrency capabilities of LoRAX, an open-source Multi-LoRA inference server that facilitates the deployment of multiple LoRA fine-tuned models on a single GPU using shared base model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA A100 GPU with 80GB memory. LoRA Land highlights the quality and cost-effectiveness of employing multiple specialized LLMs over a single, general-purpose LLM.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A  Comparative Study</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00728">https://arxiv.org/abs/2405.00728</a></p>
  <p><b>作者</b>：Dou Liu,  Ying Han,  Xiandi Wang,  Xiaomei Tan,  Di Liu,  Guangwu Qian,  Kang Li,  Dan Pu,  Rong Yin</p>
  <p><b>备注</b>：8 pages, 1 figure, conference(International Ergonomics Association)</p>
  <p><b>关键词</b>：Artificial Intelligence, Large Language Models, health outcomes, presents a transformative, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of Artificial Intelligence (AI) in healthcare presents a transformative potential for enhancing operational efficiency and health outcomes. Large Language Models (LLMs), such as ChatGPT, have shown their capabilities in supporting medical decision-making. Embedding LLMs in medical systems is becoming a promising trend in healthcare development. The potential of ChatGPT to address the triage problem in emergency departments has been examined, while few studies have explored its application in outpatient departments. With a focus on streamlining workflows and enhancing efficiency for outpatient triage, this study specifically aims to evaluate the consistency of responses provided by ChatGPT in outpatient guidance, including both within-version response analysis and between-version comparisons. For within-version, the results indicate that the internal response consistency for ChatGPT-4.0 is significantly higher than ChatGPT-3.5 (p=0.03) and both have a moderate consistency (71.2% for 4.0 and 59.6% for 3.5) in their top recommendation. However, the between-version consistency is relatively low (mean consistency score=1.43/3, median=1), indicating few recommendations match between the two versions. Also, only 50% top recommendations match perfectly in the comparisons. Interestingly, ChatGPT-3.5 responses are more likely to be complete than those from ChatGPT-4.0 (p=0.02), suggesting possible differences in information processing and response generation between the two versions. The findings offer insights into AI-assisted outpatient operations, while also facilitating the exploration of potentials and limitations of LLMs in healthcare utilization. Future research may focus on carefully optimizing LLMs and AI integration in healthcare systems based on ergonomic and human factors principles, precisely aligning with the specific needs of effective outpatient triage.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：LLMs for Generating and Evaluating Counterfactuals: A Comprehensive  Study</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00722">https://arxiv.org/abs/2405.00722</a></p>
  <p><b>作者</b>：Van Bach Nguyen,  Paul Youssef,  Jörg Schlötterer,  Christin Seifert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding their decisions, CFs, Large Language Models, NLP models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As NLP models become more complex, understanding their decisions becomes more crucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's prediction, offer a way to explain these models. While Large Language Models (LLMs) have shown remarkable performance in NLP tasks, their efficacy in generating high-quality CFs remains uncertain. This work fills this gap by investigating how well LLMs generate CFs for two NLU tasks. We conduct a comprehensive comparison of several common LLMs, and evaluate their CFs, assessing both intrinsic metrics, and the impact of these CFs on data augmentation. Moreover, we analyze differences between human and LLM-generated CFs, providing insights for future research directions. Our results show that LLMs generate fluent CFs, but struggle to keep the induced changes minimal. Generating CFs for Sentiment Analysis (SA) is less challenging than NLI where LLMs show weaknesses in generating CFs that flip the original label. This also reflects on the data augmentation performance, where we observe a large gap between augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs' ability to assess CFs in a mislabelled data setting, and show that they have a strong bias towards agreeing with the provided labels. GPT4 is more robust against this bias and its scores correlate well with automatic metrics. Our findings reveal several limitations and point to potential future work directions.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Can't say cant? Measuring and Reasoning of Dark Jargons in Large  Language Models</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00718">https://arxiv.org/abs/2405.00718</a></p>
  <p><b>作者</b>：Xu Ji,  Jianyi Zhang,  Ziyin Zhou,  Zhangchi Zhao,  Qianqian Qiao,  Kaiying Han,  Md Imran Hossen,  Xiali Hei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, mitigating offensive responses, Large Language, resilience of Large, Ensuring the resilience</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensuring the resilience of Large Language Models (LLMs) against malicious exploitation is paramount, with recent focus on mitigating offensive responses. Yet, the understanding of cant or dark jargon remains unexplored. This paper introduces a domain-specific Cant dataset and CantCounter evaluation framework, employing Fine-Tuning, Co-Tuning, Data-Diffusion, and Data-Analysis stages. Experiments reveal LLMs, including ChatGPT, are susceptible to cant bypassing filters, with varying recognition accuracy influenced by question types, setups, and prompt clues. Updated models exhibit higher acceptance rates for cant queries. Moreover, LLM reactions differ across domains, e.g., reluctance to engage in racism versus LGBT topics. These findings underscore LLMs' understanding of cant and reflect training data characteristics and vendor approaches to sensitive topics. Additionally, we assess LLMs' ability to demonstrate reasoning capabilities. Access to our datasets and code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Exploring News Summarization and Enrichment in a Highly Resource-Scarce  Indian Language: A Case Study of Mizo</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00717">https://arxiv.org/abs/2405.00717</a></p>
  <p><b>作者</b>：Abhinaba Bala,  Ashok Urlana,  Rahul Mishra,  Parameswari Krishnamurthy</p>
  <p><b>备注</b>：Accepted at LREC-COLING2024 WILDRE Workshop</p>
  <p><b>关键词</b>：Obtaining sufficient information, Obtaining sufficient, mother tongue, tongue is crucial, crucial for satisfying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obtaining sufficient information in one's mother tongue is crucial for satisfying the information needs of the users. While high-resource languages have abundant online resources, the situation is less than ideal for very low-resource languages. Moreover, the insufficient reporting of vital national and international events continues to be a worry, especially in languages with scarce resources, like \textbf{Mizo}. In this paper, we conduct a study to investigate the effectiveness of a simple methodology designed to generate a holistic summary for Mizo news articles, which leverages English-language news to supplement and enhance the information related to the corresponding news events. Furthermore, we make available 500 Mizo news articles and corresponding enriched holistic summaries. Human evaluation confirms that our approach significantly enhances the information coverage of Mizo news articles. The mizo dataset and code can be accessed at \url{this https URL</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Large Language Models in Healthcare: A Comprehensive Benchmark</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00716">https://arxiv.org/abs/2405.00716</a></p>
  <p><b>作者</b>：Andrew Liu,  Hongjian Zhou,  Yining Hua,  Omid Rohanian,  Lei Clifton,  David A. Clifton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted remarkable attention, remarkable attention, adoption of large, assist clinicians, clinicians has attracted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the close-ended question-answering task with answer options for evaluation. However, in real clinical settings, many clinical decisions, such as treatment recommendations, involve answering open-ended questions without pre-set options. Meanwhile, existing studies mainly use accuracy to assess model performance. In this paper, we comprehensively benchmark diverse LLMs in healthcare, to clearly understand their strengths and weaknesses. Our benchmark contains seven tasks and thirteen datasets across medical language generation, understanding, and reasoning. We conduct a detailed evaluation of the existing sixteen LLMs in healthcare under both zero-shot and few-shot (i.e., 1,3,5-shot) learning settings. We report the results on five metrics (i.e. matching, faithfulness, comprehensiveness, generalizability, and robustness) that are critical in achieving trust from clinical users. We further invite medical experts to conduct human evaluation.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Towards Adapting Open-Source Large Language Models for Expert-Level  Clinical Note Generation</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00715">https://arxiv.org/abs/2405.00715</a></p>
  <p><b>作者</b>：Hanyin Wang,  Chufan Gao,  Bolun Liu,  Qiping Xu,  Guleid Hussein,  Mohamad El Labban,  Kingsley Iheasirim,  Hariprasad Korsapati,  Jimeng Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown promising capabilities, Large Language, Language Models, text summarization tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have shown promising capabilities in handling clinical text summarization tasks. In this study, we demonstrate that a small open-source LLM can be effectively trained to generate high-quality clinical notes from outpatient patient-doctor dialogues. We achieve this through a comprehensive domain- and task-specific adaptation process for the LLaMA-2 13 billion parameter model. This process incorporates continued pre-training, supervised fine-tuning, and reinforcement learning from both AI and human feedback. We introduced an enhanced approach, termed DistillDirect, for performing on-policy reinforcement learning with Gemini Pro serving as the teacher model. Our resulting model, LLaMA-Clinic, is capable of generating clinical notes that are comparable in quality to those authored by physicians. In a blinded physician reader study, the majority (90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as "acceptable" or higher across all three criteria: real-world readiness, completeness, and accuracy. Notably, in the more challenging "Assessment and Plan" section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness compared to physician-authored notes (4.1/5). Additionally, we identified caveats in public clinical note datasets, such as ACI-BENCH. We highlight key considerations for future clinical note-generation tasks, emphasizing the importance of pre-defining a best-practice note format. Overall, our research demonstrates the potential and feasibility of training smaller, open-source LLMs to assist with clinical documentation, capitalizing on healthcare institutions' access to patient records and domain expertise. We have made our newly created synthetic clinic dialogue-note dataset and the physician feedback dataset publicly available to foster future research in this field.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of  Theories, Detection Methods, and Opportunities</b></summary>
  <p><b>编号</b>：[392]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00711">https://arxiv.org/abs/2405.00711</a></p>
  <p><b>作者</b>：Xiaomin Yu,  Yezhaohui Wang,  Yanfang Chen,  Zhen Tao,  Dinghao Xi,  Shichao Song,  Simin Niu,  Zhiyu Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Diffusion Models, artificial intelligence models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, generative artificial intelligence models, represented by Large Language Models (LLMs) and Diffusion Models (DMs), have revolutionized content production methods. These artificial intelligence-generated content (AIGC) have become deeply embedded in various aspects of daily life and work, spanning texts, images, videos, and audio. The authenticity of AI-generated content is progressively enhancing, approaching human-level creative standards. However, these technologies have also led to the emergence of Fake Artificial Intelligence Generated Content (FAIGC), posing new challenges in distinguishing genuine information. It is crucial to recognize that AIGC technology is akin to a double-edged sword; its potent generative capabilities, while beneficial, also pose risks for the creation and dissemination of FAIGC. In this survey, We propose a new taxonomy that provides a more comprehensive breakdown of the space of FAIGC methods today. Next, we explore the modalities and generative technologies of FAIGC, categorized under AI-generated disinformation and AI-generated misinformation. From various perspectives, we then introduce FAIGC detection methods, including Deceptive FAIGC Detection, Deepfake Detection, and Hallucination-based FAIGC Detection. Finally, we discuss outstanding challenges and promising areas for future research.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Homonym Sense Disambiguation in the Georgian Language</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00710">https://arxiv.org/abs/2405.00710</a></p>
  <p><b>作者</b>：Davit Melikidze,  Alexander Gamkrelidze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Common Crawls corpus, Georgian Common Crawls, Large Language Model, Common Crawls, pre-trained Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research proposes a novel approach to the Word Sense Disambiguation (WSD) task in the Georgian language, based on supervised fine-tuning of a pre-trained Large Language Model (LLM) on a dataset formed by filtering the Georgian Common Crawls corpus. The dataset is used to train a classifier for words with multiple senses. Additionally, we present experimental results of using LSTM for WSD. Accurately disambiguating homonyms is crucial in natural language processing. Georgian, an agglutinative language belonging to the Kartvelian language family, presents unique challenges in this context. The aim of this paper is to highlight the specific problems concerning homonym disambiguation in the Georgian language and to present our approach to solving them. The techniques discussed in the article achieve 95% accuracy for predicting lexical meanings of homonyms using a hand-classified dataset of over 7500 sentences.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Evaluating Tool-Augmented Agents in Remote Sensing Platforms</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00709">https://arxiv.org/abs/2405.00709</a></p>
  <p><b>作者</b>：Simranjit Singh,  Michael Fore,  Dimitrios Stamoulis</p>
  <p><b>备注</b>：ICLR 2024 Machine Learning for Remote Sensing (ML4RS) Workshop</p>
  <p><b>关键词</b>：Large Language Models, Tool-augmented Large Language, Language Models, shown impressive capabilities, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user-grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask "Detect all objects here". Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., the live map positioning? To bridge this gap, we present GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights towards stronger agents for RS applications.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Interactive Analysis of LLMs using Meaningful Counterfactuals</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00708">https://arxiv.org/abs/2405.00708</a></p>
  <p><b>作者</b>：Furui Cheng,  Vilém Zouhar,  Robin Shing Moon Chan,  Daniel Fürst,  Hendrik Strobelt,  Mennatallah El-Assady</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determining feature attributions, machine learning models, feature attributions, exploring the decision, decision boundaries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Counterfactual examples are useful for exploring the decision boundaries of machine learning models and determining feature attributions. How can we apply counterfactual-based methods to analyze and explain LLMs? We identify the following key challenges. First, the generated textual counterfactuals should be meaningful and readable to users and thus can be mentally compared to draw conclusions. Second, to make the solution scalable to long-form text, users should be equipped with tools to create batches of counterfactuals from perturbations at various granularity levels and interactively analyze the results. In this paper, we tackle the above challenges and contribute 1) a novel algorithm for generating batches of complete and meaningful textual counterfactuals by removing and replacing text segments in different granularities, and 2) LLM Analyzer, an interactive visualization tool to help users understand an LLM's behaviors by interactively inspecting and aggregating meaningful counterfactuals. We evaluate the proposed algorithm by the grammatical correctness of its generated counterfactuals using 1,000 samples from medical, legal, finance, education, and news datasets. In our experiments, 97.2% of the counterfactuals are grammatically correct. Through a use case, user studies, and feedback from experts, we demonstrate the usefulness and usability of the proposed interactive visualization tool.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Science Written by Generative AI is Perceived as Less Intelligent, but  More Credible and Trustworthy than Science Written by Humans</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00706">https://arxiv.org/abs/2405.00706</a></p>
  <p><b>作者</b>：David M. Markowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simplify science communication, enhance public trust, simplify science, science communication, evaluated the effectiveness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper evaluated the effectiveness of using generative AI to simplify science communication and enhance public trust in science. By comparing lay summaries of journal articles from PNAS, yoked to those generated by AI, this work assessed linguistic simplicity across such summaries and public perceptions. Study 1a analyzed simplicity features of PNAS abstracts (scientific summaries) and significance statements (lay summaries), observing that lay summaries were indeed linguistically simpler, but effect size differences were small. Study 1b used GPT-4 to create significance statements based on paper abstracts and this more than doubled the average effect size without fine-tuning. Finally, Study 2 experimentally demonstrated that simply-written GPT summaries facilitated more favorable public perceptions of scientists (their credibility, trustworthiness) than more complexly-written human PNAS summaries. AI has the potential to engage scientific communities and the public via a simple language heuristic, advocating for its integration into scientific dissemination for a more informed society.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：SHED: Shapley-Based Automated Dataset Refinement for Instruction  Fine-Tuning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00705">https://arxiv.org/abs/2405.00705</a></p>
  <p><b>作者</b>：Yexiao He,  Ziyao Wang,  Zheyu Shen,  Guoheng Sun,  Yucong Dai,  Yongkai Wu,  Hongyi Wang,  Ang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, pre-trained Large Language, Language Models, Large Language, pre-trained Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The pre-trained Large Language Models (LLMs) can be adapted for many downstream tasks and tailored to align with human preferences through fine-tuning. Recent studies have discovered that LLMs can achieve desirable performance with only a small amount of high-quality data, suggesting that a large amount of the data in these extensive datasets is redundant or even harmful. Identifying high-quality data from vast datasets to curate small yet effective datasets has emerged as a critical challenge. In this paper, we introduce SHED, an automated dataset refinement framework based on Shapley value for instruction fine-tuning. SHED eliminates the need for human intervention or the use of commercial LLMs. Moreover, the datasets curated through SHED exhibit transferability, indicating they can be reused across different LLMs with consistently high performance. We conduct extensive experiments to evaluate the datasets curated by SHED. The results demonstrate SHED's superiority over state-of-the-art methods across various tasks and LLMs; notably, datasets comprising only 10% of the original data selected by SHED achieve performance comparable to or surpassing that of the full datasets.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：A Survey on the Real Power of ChatGPT</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00704">https://arxiv.org/abs/2405.00704</a></p>
  <p><b>作者</b>：Ming Liu,  Ran Liu,  Hua Wang,  Wray Buntine</p>
  <p><b>备注</b>：9 pages, 2 tables</p>
  <p><b>关键词</b>：active research line, active research, research line, ChatGPT, emphasize key challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>ChatGPT has changed the AI community and an active research line is the performance evaluation of ChatGPT. A key challenge for the evaluation is that ChatGPT is still closed-source and traditional benchmark datasets may have been used by ChatGPT as the training data. In this paper, (i) we survey recent studies which uncover the real performance levels of ChatGPT in seven categories of NLP tasks, (ii) review the social implications and safety issues of ChatGPT, and (iii) emphasize key challenges and opportunities for its evaluation. We hope our survey can shed some light on its blackbox manner, so that researchers are not misleaded by its surface generation.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Large Language Models for Human-Robot Interaction: Opportunities and  Risks</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00693">https://arxiv.org/abs/2405.00693</a></p>
  <p><b>作者</b>：Jesse Atuhurra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yielded research results, large language models, social robots, language models, wave of innovations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The tremendous development in large language models (LLM) has led to a new wave of innovations and applications and yielded research results that were initially forecast to take longer. In this work, we tap into these recent developments and present a meta-study about the potential of large language models if deployed in social robots. We place particular emphasis on the applications of social robots: education, healthcare, and entertainment. Before being deployed in social robots, we also study how these language models could be safely trained to ``understand'' societal norms and issues, such as trust, bias, ethics, cognition, and teamwork. We hope this study provides a resourceful guide to other robotics researchers interested in incorporating language models in their robots.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Understanding Social Perception, Interactions, and Safety Aspects of  Sidewalk Delivery Robots Using Sentiment Analysis</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00688">https://arxiv.org/abs/2405.00688</a></p>
  <p><b>作者</b>：Yuchen Du,  Tho V. Le</p>
  <p><b>备注</b>：34 pages, 7 figures, 2 tables</p>
  <p><b>关键词</b>：Sidewalk Delivery Robots, Delivery Robots, Sidewalk Delivery, YouTube videos related, comprehensive sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article presents a comprehensive sentiment analysis (SA) of comments on YouTube videos related to Sidewalk Delivery Robots (SDRs). We manually annotated the collected YouTube comments with three sentiment labels: negative (0), positive (1), and neutral (2). We then constructed models for text sentiment classification and tested the models' performance on both binary and ternary classification tasks in terms of accuracy, precision, recall, and F1 score. Our results indicate that, in binary classification tasks, the Support Vector Machine (SVM) model using Term Frequency-Inverse Document Frequency (TF-IDF) and N-gram get the highest accuracy. In ternary classification tasks, the model using Bidirectional Encoder Representations from Transformers (BERT), Long Short-Term Memory Networks (LSTM) and Gated Recurrent Unit (GRU) significantly outperforms other machine learning models, achieving an accuracy, precision, recall, and F1 score of 0.78. Additionally, we employ the Latent Dirichlet Allocation model to generate 10 topics from the comments to explore the public's underlying views on SDRs. Drawing from these findings, we propose targeted recommendations for shaping future policies concerning SDRs. This work provides valuable insights for stakeholders in the SDR sector regarding social perception, interaction, and safety.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries  Cryptocurrency Trend Forecasting</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00522">https://arxiv.org/abs/2405.00522</a></p>
  <p><b>作者</b>：Yihang Fu,  Mingyu Zhou,  Luyao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant investment opportunities, Dual Attention Mechanism, merging enhanced security, rise of cryptocurrencies, investment opportunities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the distributed systems landscape, Blockchain has catalyzed the rise of cryptocurrencies, merging enhanced security and decentralization with significant investment opportunities. Despite their potential, current research on cryptocurrency trend forecasting often falls short by simplistically merging sentiment data without fully considering the nuanced interplay between financial market dynamics and external sentiment influences. This paper presents a novel Dual Attention Mechanism (DAM) for forecasting cryptocurrency trends using multimodal time-series data. Our approach, which integrates critical cryptocurrency metrics with sentiment data from news and social media analyzed through CryptoBERT, addresses the inherent volatility and prediction challenges in cryptocurrency markets. By combining elements of distributed systems, natural language processing, and financial forecasting, our method outperforms conventional models like LSTM and Transformer by up to 20\% in prediction accuracy. This advancement deepens the understanding of distributed systems and has practical implications in financial markets, benefiting stakeholders in cryptocurrency and blockchain technologies. Moreover, our enhanced forecasting approach can significantly support decentralized science (DeSci) by facilitating strategic planning and the efficient adoption of blockchain technologies, improving operational efficiency and financial risk management in the rapidly evolving digital asset domain, thus ensuring optimal resource allocation.</p>
  </details>
</details>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Multi-Space Alignments Towards Universal LiDAR Segmentation</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01538">https://arxiv.org/abs/2405.01538</a></p>
  <p><b>作者</b>：Youquan Liu,  Lingdong Kong,  Xiaoyang Wu,  Runnan Chen,  Xin Li,  Liang Pan,  Ziwei Liu,  Yuexin Ma</p>
  <p><b>备注</b>：CVPR 2024; 33 pages, 14 figures, 14 tables; Code at this https URL</p>
  <p><b>关键词</b>：autonomous driving perception, safe autonomous driving, versatile LiDAR segmentation, LiDAR segmentation, unified and versatile</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A unified and versatile LiDAR segmentation model with strong robustness and generalizability is desirable for safe autonomous driving perception. This work presents M3Net, a one-of-a-kind framework for fulfilling multi-task, multi-dataset, multi-modality LiDAR segmentation in a universal manner using just a single set of parameters. To better exploit data volume and diversity, we first combine large-scale driving datasets acquired by different types of sensors from diverse scenes and then conduct alignments in three spaces, namely data, feature, and label spaces, during the training. As a result, M3Net is capable of taming heterogeneous data for training state-of-the-art LiDAR segmentation models. Extensive experiments on twelve LiDAR segmentation datasets verify our effectiveness. Notably, using a shared set of parameters, M3Net achieves 75.1%, 83.1%, and 72.4% mIoU scores, respectively, on the official benchmarks of SemanticKITTI, nuScenes, and Waymo Open.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Customizing Text-to-Image Models with a Single Image Pair</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01536">https://arxiv.org/abs/2405.01536</a></p>
  <p><b>作者</b>：Maxwell Jones,  Sheng-Yu Wang,  Nupur Kumari,  David Bau,  Jun-Yan Zhu</p>
  <p><b>备注</b>：project page: this https URL</p>
  <p><b>关键词</b>：single image pair, Art reinterpretation, reference work, image pair, stylistic difference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Art reinterpretation is the practice of creating a variation of a reference work, making a paired artwork that exhibits a distinct artistic style. We ask if such an image pair can be used to customize a generative model to capture the demonstrated stylistic difference. We propose Pair Customization, a new customization method that learns stylistic difference from a single image pair and then applies the acquired style to the generation process. Unlike existing methods that learn to mimic a single concept from a collection of images, our method captures the stylistic difference between paired images. This allows us to apply a stylistic change without overfitting to the specific image content in the examples. To address this new task, we employ a joint optimization method that explicitly separates the style and content into distinct LoRA weight spaces. We optimize these style and content weights to reproduce the style and content images while encouraging their orthogonality. During inference, we modify the diffusion process via a new style guidance based on our learned weights. Both qualitative and quantitative experiments show that our method can effectively learn style while avoiding overfitting to image content, highlighting the potential of modeling such stylistic differences from a single image pair.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon  Robotics Tasks</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01534">https://arxiv.org/abs/2405.01534</a></p>
  <p><b>作者</b>：Murtaza Dalal,  Tarun Chiruvolu,  Devendra Chaplot,  Ruslan Salakhutdinov</p>
  <p><b>备注</b>：Published at ICLR 2024. Website at this https URL 9 pages, 3 figures, 3 tables; 14 pages appendix (7 additional figures)</p>
  <p><b>关键词</b>：Large Language Models, existing methods require, methods require access, pre-defined skill library, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have been shown to be capable of performing high-level planning for long-horizon robotics tasks, yet existing methods require access to a pre-defined skill library (e.g. picking, placing, pulling, pushing, navigating). However, LLM planning does not address how to design or learn those behaviors, which remains challenging particularly in long-horizon settings. Furthermore, for many tasks of interest, the robot needs to be able to adjust its behavior in a fine-grained manner, requiring the agent to be capable of modifying low-level control actions. Can we instead use the internet-scale knowledge from LLMs for high-level policies, guiding reinforcement learning (RL) policies to efficiently solve robotic control tasks online without requiring a pre-determined set of skills? In this paper, we propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to bridge the gap between abstract language and learned low-level control for solving long-horizon robotics tasks from scratch. We demonstrate that PSL achieves state-of-the-art results on over 25 challenging robotics tasks with up to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four benchmarks at success rates of over 85%, out-performing language-based, classical, and end-to-end approaches. Video results and code at this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D  Perception, Reasoning and Planning</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01533">https://arxiv.org/abs/2405.01533</a></p>
  <p><b>作者</b>：Shihao Wang,  Zhiding Yu,  Xiaohui Jiang,  Shiyi Lan,  Min Shi,  Nadine Chang,  Jan Kautz,  Ying Li,  Jose M. Alvarez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multimodal large language, LLM-based autonomous driving, large language models, strong reasoning capabilities, autonomous driving agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advances in multimodal large language models (MLLMs) have led to growing interests in LLM-based autonomous driving agents to leverage their strong reasoning capabilities. However, capitalizing on MLLMs' strong reasoning capabilities for improved planning behavior is challenging since planning requires full 3D situational awareness beyond 2D reasoning. To address this challenge, our work proposes a holistic framework for strong alignment between agent models and 3D driving tasks. Our framework starts with a novel 3D MLLM architecture that uses sparse queries to lift and compress visual representations into 3D before feeding them into an LLM. This query-based representation allows us to jointly encode dynamic objects and static map elements (e.g., traffic lanes), providing a condensed world model for perception-action alignment in 3D. We further propose OmniDrive-nuScenes, a new visual question-answering dataset challenging the true 3D situational awareness of a model with comprehensive visual question-answering (VQA) tasks, including scene description, traffic regulation, 3D grounding, counterfactual reasoning, decision making and planning. Extensive studies show the effectiveness of the proposed architecture as well as the importance of the VQA tasks for reasoning and planning in complex 3D scenes.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Improving Intervention Efficacy via Concept Realignment in Concept  Bottleneck Models</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01531">https://arxiv.org/abs/2405.01531</a></p>
  <p><b>作者</b>：Nishad Singhi,  Jae Myung Kim,  Karsten Roth,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Concept Bottleneck Models, Bottleneck Models, Concept Bottleneck, interpretable model decisions, ground image classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept Bottleneck Models (CBMs) ground image classification on human-understandable concepts to allow for interpretable model decisions. Crucially, the CBM design inherently allows for human interventions, in which expert users are given the ability to modify potentially misaligned concept choices to influence the decision behavior of the model in an interpretable fashion. However, existing approaches often require numerous human interventions per image to achieve strong performances, posing practical challenges in scenarios where obtaining human feedback is expensive. In this paper, we find that this is noticeably driven by an independent treatment of concepts during intervention, wherein a change of one concept does not influence the use of other ones in the model's final decision. To address this issue, we introduce a trainable concept intervention realignment module, which leverages concept relations to realign concept assignments post-intervention. Across standard, real-world benchmarks, we find that concept realignment can significantly improve intervention efficacy; significantly reducing the number of interventions needed to reach a target classification performance or concept prediction accuracy. In addition, it easily integrates into existing concept-based architectures without requiring changes to the models themselves. This reduced cost of human-model collaboration is crucial to enhancing the feasibility of CBMs in resource-constrained environments.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Track2Act: Predicting Point Tracks from Internet Videos enables Diverse  Zero-shot Robot Manipulation</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01527">https://arxiv.org/abs/2405.01527</a></p>
  <p><b>作者</b>：Homanga Bharadhwaj,  Roozbeh Mottaghi,  Abhinav Gupta,  Shubham Tulsiani</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：generalizable goal-conditioned policy, test-time adaptation, generalizable goal-conditioned, zero-shot robot manipulation, enables zero-shot robot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We seek to learn a generalizable goal-conditioned policy that enables zero-shot robot manipulation: interacting with unseen objects in novel scenes without test-time adaptation. While typical approaches rely on a large amount of demonstration data for such generalization, we propose an approach that leverages web videos to predict plausible interaction plans and learns a task-agnostic transformation to obtain robot actions in the real world. Our framework,Track2Act predicts tracks of how points in an image should move in future time-steps based on a goal, and can be trained with diverse videos on the web including those of humans and robots manipulating everyday objects. We use these 2D track predictions to infer a sequence of rigid transforms of the object to be manipulated, and obtain robot end-effector poses that can be executed in an open-loop manner. We then refine this open-loop plan by predicting residual actions through a closed loop policy trained with a few embodiment-specific demonstrations. We show that this approach of combining scalably learned track prediction with a residual policy requiring minimal in-domain robot-specific data enables zero-shot robot manipulation, and present a wide array of real-world robot manipulation results across unseen tasks, objects, and scenes. this https URL</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A separability-based approach to quantifying generalization: which layer  is best?</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01524">https://arxiv.org/abs/2405.01524</a></p>
  <p><b>作者</b>：Luciano Dyballa,  Evan Gerritz,  Steven W. Zucker</p>
  <p><b>备注</b>：6, pages, 5 figures</p>
  <p><b>关键词</b>：remains poorly understood, data remains poorly, deep learning classification, remains poorly, poorly understood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization to unseen data remains poorly understood for deep learning classification and foundation models. How can one assess the ability of networks to adapt to new or extended versions of their input space in the spirit of few-shot learning, out-of-distribution generalization, and domain adaptation? Which layers of a network are likely to generalize best? We provide a new method for evaluating the capacity of networks to represent a sampled domain, regardless of whether the network has been trained on all classes in the domain. Our approach is the following: after fine-tuning state-of-the-art pre-trained models for visual classification on a particular domain, we assess their performance on data from related but distinct variations in that domain. Generalization power is quantified as a function of the latent embeddings of unseen data from intermediate layers for both unsupervised and supervised settings. Working throughout all stages of the network, we find that (i) high classification accuracy does not imply high generalizability; and (ii) deeper layers in a model do not always generalize the best, which has implications for pruning. Since the trends observed across datasets are largely consistent, we conclude that our approach reveals (a function of) the intrinsic capacity of the different layers of a model to generalize.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Transformer-Aided Semantic Communications</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01521">https://arxiv.org/abs/2405.01521</a></p>
  <p><b>作者</b>：Matin Mortaheb,  Erciyes Karakaya,  Mohammad A. Amir Khojastepour,  Sennur Ulukus</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, deep neural networks, transformer structure employed, featuring attention mechanisms, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The transformer structure employed in large language models (LLMs), as a specialized category of deep neural networks (DNNs) featuring attention mechanisms, stands out for their ability to identify and highlight the most relevant aspects of input data. Such a capability is particularly beneficial in addressing a variety of communication challenges, notably in the realm of semantic communication where proper encoding of the relevant data is critical especially in systems with limited bandwidth. In this work, we employ vision transformers specifically for the purpose of compression and compact representation of the input image, with the goal of preserving semantic information throughout the transmission process. Through the use of the attention mechanism inherent in transformers, we create an attention mask. This mask effectively prioritizes critical segments of images for transmission, ensuring that the reconstruction phase focuses on key objects highlighted by the mask. Our methodology significantly improves the quality of semantic communication and optimizes bandwidth usage by encoding different parts of the data in accordance with their semantic information content, thus enhancing overall efficiency. We evaluate the effectiveness of our proposed framework using the TinyImageNet dataset, focusing on both reconstruction quality and accuracy. Our evaluation results demonstrate that our framework successfully preserves semantic information, even when only a fraction of the encoded data is transmitted, according to the intended compression rates.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：LocInv: Localization-aware Inversion for Text-Guided Image Editing</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01496">https://arxiv.org/abs/2405.01496</a></p>
  <p><b>作者</b>：Chuanming Tang,  Kai Wang,  Fei Yang,  Joost van de Weijer</p>
  <p><b>备注</b>：Accepted by CVPR 2024 Workshop AI4CC</p>
  <p><b>关键词</b>：demonstrate significant generation, significant generation capabilities, models demonstrate significant, generation capabilities based, diffusion models demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale Text-to-Image (T2I) diffusion models demonstrate significant generation capabilities based on textual prompts. Based on the T2I diffusion models, text-guided image editing research aims to empower users to manipulate generated images by altering the text prompts. However, existing image editing techniques are prone to editing over unintentional regions that are beyond the intended target area, primarily due to inaccuracies in cross-attention maps. To address this problem, we propose Localization-aware Inversion (LocInv), which exploits segmentation maps or bounding boxes as extra localization priors to refine the cross-attention maps in the denoising phases of the diffusion process. Through the dynamic updating of tokens corresponding to noun words in the textual input, we are compelling the cross-attention maps to closely align with the correct noun and adjective words in the text prompt. Based on this technique, we achieve fine-grained image editing over particular objects while preventing undesired changes to other regions. Our method LocInv, based on the publicly available Stable Diffusion, is extensively evaluated on a subset of the COCO dataset, and consistently obtains superior results both quantitatively and qualitatively.The code will be released at this https URL</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Navigating Heterogeneity and Privacy in One-Shot Federated Learning with  Diffusion Models</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01494">https://arxiv.org/abs/2405.01494</a></p>
  <p><b>作者</b>：Matias Mendieta,  Guangyu Sun,  Chen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enables multiple clients, enables multiple, train models collectively, multiple clients, clients to train</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) enables multiple clients to train models collectively while preserving data privacy. However, FL faces challenges in terms of communication cost and data heterogeneity. One-shot federated learning has emerged as a solution by reducing communication rounds, improving efficiency, and providing better security against eavesdropping attacks. Nevertheless, data heterogeneity remains a significant challenge, impacting performance. This work explores the effectiveness of diffusion models in one-shot FL, demonstrating their applicability in addressing data heterogeneity and improving FL performance. Additionally, we investigate the utility of our diffusion model approach, FedDiff, compared to other one-shot FL methods under differential privacy (DP). Furthermore, to improve generated sample quality under DP settings, we propose a pragmatic Fourier Magnitude Filtering (FMF) method, enhancing the effectiveness of generated data for global model training.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：MANTIS: Interleaved Multi-Image Instruction Tuning</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01483">https://arxiv.org/abs/2405.01483</a></p>
  <p><b>作者</b>：Dongfu Jiang,  Xuan He,  Huaye Zeng,  Cong Wei,  Max Ku,  Qian Liu,  Wenhu Chen</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：vision language tasks, large multimodal models, language tasks, multi-image, single-image vision language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent years have witnessed a great array of large multimodal models (LMMs) to effectively solve single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from web, which is neither efficient nor effective. In this paper, we aim at building strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K instances from 14 multi-image datasets. We design Mantis-Instruct to cover different multi-image skills like co-reference, reasoning, comparing, temporal understanding. We combine Mantis-Instruct with several single-image visual-language datasets to train our model Mantis to handle any interleaved image-text inputs. We evaluate the trained Mantis on five multi-image benchmarks and eight single-image benchmarks. Though only requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B can achieve state-of-the-art performance on all the multi-image benchmarks and beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute points. We observe that Mantis performs equivalently well on the held-in and held-out evaluation benchmarks. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis can maintain a strong single-image performance on par with CogVLM and Emu2. Our results are particularly encouraging as it shows that low-cost instruction tuning is indeed much more effective than intensive pre-training in terms of building multi-image LMMs.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：V-FLUTE: Visual Figurative Language Understanding with Textual  Explanations</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01474">https://arxiv.org/abs/2405.01474</a></p>
  <p><b>作者</b>：Arkadiy Saakyan,  Shreyas Kulkarni,  Tuhin Chakrabarty,  Smaranda Muresan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong reasoning, strong reasoning capabilities, Large Vision-Language models, Visual Figurative Language, Figurative Language Understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Vision-Language models (VLMs) have demonstrated strong reasoning capabilities in tasks requiring a fine-grained understanding of literal images and text, such as visual question-answering or visual entailment. However, there has been little exploration of these models' capabilities when presented with images and captions containing figurative phenomena such as metaphors or humor, the meaning of which is often implicit. To close this gap, we propose a new task and a high-quality dataset: Visual Figurative Language Understanding with Textual Explanations (V-FLUTE). We frame the visual figurative language understanding problem as an explainable visual entailment task, where the model has to predict whether the image (premise) entails a claim (hypothesis) and justify the predicted label with a textual explanation. Using a human-AI collaboration framework, we build a high-quality dataset, V-FLUTE, that contains 6,027 <image, claim, label, explanation> instances spanning five diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm, and humor. The figurative phenomena can be present either in the image, the caption, or both. We further conduct both automatic and human evaluations to assess current VLMs' capabilities in understanding figurative phenomena.</image,></p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Advancing human-centric AI for robust X-ray analysis through holistic  self-supervised learning</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01469">https://arxiv.org/abs/2405.01469</a></p>
  <p><b>作者</b>：Théo Moutakanni,  Piotr Bojanowski,  Guillaume Chassagnon,  Céline Hudelot,  Armand Joulin,  Yann LeCun,  Matthew Muckley,  Maxime Oquab,  Marie-Pierre Revel,  Maria Vakalopoulou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including medical fields, medical foundation models, Foundation models, gaining traction, including medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI Foundation models are gaining traction in various applications, including medical fields like radiology. However, medical foundation models are often tested on limited tasks, leaving their generalisability and biases unexplored. We present RayDINO, a large visual encoder trained by self-supervision on 873k chest X-rays. We compare RayDINO to previous state-of-the-art models across nine radiology tasks, from classification and dense segmentation to text generation, and provide an in depth analysis of population, age and sex biases of our model. Our findings suggest that self-supervision allows patient-centric AI proving useful in clinical workflows and interpreting X-rays holistically. With RayDINO and small task-specific adapters, we reach state-of-the-art results and improve generalization to unseen populations while mitigating bias, illustrating the true promise of foundation models: versatility and robustness.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Understanding Retrieval-Augmented Task Adaptation for Vision-Language  Models</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01468">https://arxiv.org/abs/2405.01468</a></p>
  <p><b>作者</b>：Yifei Ming,  Yixuan Li</p>
  <p><b>备注</b>：The paper is accepted at ICML 2024</p>
  <p><b>关键词</b>：demonstrated remarkable performance, Pre-trained contrastive vision-language, Pre-trained contrastive, range of tasks, demonstrated remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained contrastive vision-language models have demonstrated remarkable performance across a wide range of tasks. However, they often struggle on fine-trained datasets with categories not adequately represented during pre-training, which makes adaptation necessary. Recent works have shown promising results by utilizing samples from web-scale databases for retrieval-augmented adaptation, especially in low-data regimes. Despite the empirical success, understanding how retrieval impacts the adaptation of vision-language models remains an open research question. In this work, we adopt a reflective perspective by presenting a systematic study to understand the roles of key components in retrieval-augmented adaptation. We unveil new insights on uni-modal and cross-modal retrieval and highlight the critical role of logit ensemble for effective adaptation. We further present theoretical underpinnings that directly support our empirical observations.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：SATO: Stable Text-to-Motion Framework</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01461">https://arxiv.org/abs/2405.01461</a></p>
  <p><b>作者</b>：Wenshuo Chen,  Hongru Xiao,  Erhang Zhang,  Lijie Hu,  Lei Wang,  Mengyuan Liu,  Chen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Motion model robust, Motion models primarily, Text to Motion, Motion model, Text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Is the Text to Motion model robust? Recent advancements in Text to Motion models primarily stem from more accurate predictions of specific actions. However, the text modality typically relies solely on pre-trained Contrastive Language-Image Pretraining (CLIP) models. Our research has uncovered a significant issue with the text-to-motion model: its predictions often exhibit inconsistent outputs, resulting in vastly different or even incorrect poses when presented with semantically similar or identical text inputs. In this paper, we undertake an analysis to elucidate the underlying causes of this instability, establishing a clear link between the unpredictability of model outputs and the erratic attention patterns of the text encoder module. Consequently, we introduce a formal framework aimed at addressing this issue, which we term the Stable Text-to-Motion Framework (SATO). SATO consists of three modules, each dedicated to stable attention, stable prediction, and maintaining a balance between accuracy and robustness trade-off. We present a methodology for constructing an SATO that satisfies the stability of attention and prediction. To verify the stability of the model, we introduced a new textual synonym perturbation dataset based on HumanML3D and KIT-ML. Results show that SATO is significantly more stable against synonyms and other slight perturbations while keeping its high accuracy performance.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Purify Unlearnable Examples via Rate-Constrained Variational  Autoencoders</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01460">https://arxiv.org/abs/2405.01460</a></p>
  <p><b>作者</b>：Yi Yu,  Yufei Wang,  Song Xia,  Wenhan Yang,  Shijian Lu,  Yap-Peng Tan,  Alex C. Kot</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：maximize testing error, making subtle modifications, seek to maximize, correctly labeled, maximize testing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlearnable examples (UEs) seek to maximize testing error by making subtle modifications to training examples that are correctly labeled. Defenses against these poisoning attacks can be categorized based on whether specific interventions are adopted during training. The first approach is training-time defense, such as adversarial training, which can mitigate poisoning effects but is computationally intensive. The other approach is pre-training purification, e.g., image short squeezing, which consists of several simple compressions but often encounters challenges in dealing with various UEs. Our work provides a novel disentanglement mechanism to build an efficient pre-training purification method. Firstly, we uncover rate-constrained variational autoencoders (VAEs), demonstrating a clear tendency to suppress the perturbations in UEs. We subsequently conduct a theoretical analysis for this phenomenon. Building upon these insights, we introduce a disentangle variational autoencoder (D-VAE), capable of disentangling the perturbations with learnable class-wise embeddings. Based on this network, a two-stage purification approach is naturally developed. The first stage focuses on roughly eliminating perturbations, while the second stage produces refined, poison-free results, ensuring effectiveness and robustness across various scenarios. Extensive experiments demonstrate the remarkable performance of our method across CIFAR-10, CIFAR-100, and a 100-class ImageNet-subset. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Improving Domain Generalization on Gaze Estimation via Branch-out  Auxiliary Regularization</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01439">https://arxiv.org/abs/2405.01439</a></p>
  <p><b>作者</b>：Ruijie Zhao,  Pinyan Tang,  Sihui Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：individual facial attributes, uncontrolled environments due, remarkable advancements, facial attributes, mainstream gaze estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite remarkable advancements, mainstream gaze estimation techniques, particularly appearance-based methods, often suffer from performance degradation in uncontrolled environments due to variations in illumination and individual facial attributes. Existing domain adaptation strategies, limited by their need for target domain samples, may fall short in real-world applications. This letter introduces Branch-out Auxiliary Regularization (BAR), an innovative method designed to boost gaze estimation's generalization capabilities without requiring direct access to target domain data. Specifically, BAR integrates two auxiliary consistency regularization branches: one that uses augmented samples to counteract environmental variations, and another that aligns gaze directions with positive source domain samples to encourage the learning of consistent gaze features. These auxiliary pathways strengthen the core network and are integrated in a smooth, plug-and-play manner, facilitating easy adaptation to various other models. Comprehensive experimental evaluations on four cross-dataset tasks demonstrate the superiority of our approach.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video  Generation</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01434">https://arxiv.org/abs/2405.01434</a></p>
  <p><b>作者</b>：Yupeng Zhou,  Daquan Zhou,  Ming-Ming Cheng,  Jiashi Feng,  Qibin Hou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent diffusion-based generative, diffusion-based generative models, complex details, presents a significant, significant challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For recent diffusion-based generative models, maintaining consistent content across a series of generated images, especially those containing subjects and complex details, presents a significant challenge. In this paper, we propose a new way of self-attention calculation, termed Consistent Self-Attention, that significantly boosts the consistency between the generated images and augments prevalent pretrained diffusion-based text-to-image models in a zero-shot manner. To extend our method to long-range video generation, we further introduce a novel semantic space temporal motion prediction module, named Semantic Motion Predictor. It is trained to estimate the motion conditions between two provided images in the semantic spaces. This module converts the generated sequence of images into videos with smooth transitions and consistent subjects that are significantly more stable than the modules based on latent spaces only, especially in the context of long video generation. By merging these two novel components, our framework, referred to as StoryDiffusion, can describe a text-based story with consistent images or videos encompassing a rich variety of contents. The proposed StoryDiffusion encompasses pioneering explorations in visual story generation with the presentation of images and videos, which we hope could inspire more research from the aspect of architectural modifications. Our code is made publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01413">https://arxiv.org/abs/2405.01413</a></p>
  <p><b>作者</b>：Yuan Tang,  Xu Han,  Xianzhi Li,  Qiao Yu,  Yixue Hao,  Long Hu,  Min Chen</p>
  <p><b>备注</b>：17 pages, 9 figures</p>
  <p><b>关键词</b>：Large Language Models, bridging Large Language, gained significant attention, Language Models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Goal-conditioned reinforcement learning for ultrasound navigation  guidance</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01409">https://arxiv.org/abs/2405.01409</a></p>
  <p><b>作者</b>：Abdoul Aziz Amadou,  Vivek Singh,  Florin C. Ghesu,  Young-Ho Kim,  Laura Stanciulescu,  Harshitha P. Sai,  Puneet Sharma,  Alistair Young,  Ronak Rajani,  Kawal Rhode</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：plays a pivotal, pivotal role, role in cardiology, TEE, interventional procedures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transesophageal echocardiography (TEE) plays a pivotal role in cardiology for diagnostic and interventional procedures. However, using it effectively requires extensive training due to the intricate nature of image acquisition and interpretation. To enhance the efficiency of novice sonographers and reduce variability in scan acquisitions, we propose a novel ultrasound (US) navigation assistance method based on contrastive learning as goal-conditioned reinforcement learning (GCRL). We augment the previous framework using a novel contrastive patient batching method (CPB) and a data-augmented contrastive loss, both of which we demonstrate are essential to ensure generalization to anatomical variations across patients. The proposed framework enables navigation to both standard diagnostic as well as intricate interventional views with a single model. Our method was developed with a large dataset of 789 patients and obtained an average error of 6.56 mm in position and 9.36 degrees in angle on a testing dataset of 140 patients, which is competitive or superior to models trained on individual views. Furthermore, we quantitatively validate our method's ability to navigate to interventional views such as the Left Atrial Appendage (LAA) view used in LAA closure. Our approach holds promise in providing valuable guidance during transesophageal ultrasound examinations, contributing to the advancement of skill acquisition for cardiac ultrasound practitioners.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：ATOM: Attention Mixer for Efficient Dataset Distillation</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01373">https://arxiv.org/abs/2405.01373</a></p>
  <p><b>作者</b>：Samir Khaki,  Ahmad Sajedi,  Kai Wang,  Lucy Z. Liu,  Yuri A. Lawryshyn,  Konstantinos N. Plataniotis</p>
  <p><b>备注</b>：Accepted for an oral presentation in CVPR-DD 2024</p>
  <p><b>关键词</b>：larger real dataset, minimize training expenses, Recent works, dataset distillation seek, seek to minimize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works in dataset distillation seek to minimize training expenses by generating a condensed synthetic dataset that encapsulates the information present in a larger real dataset. These approaches ultimately aim to attain test accuracy levels akin to those achieved by models trained on the entirety of the original dataset. Previous studies in feature and distribution matching have achieved significant results without incurring the costs of bi-level optimization in the distillation process. Despite their convincing efficiency, many of these methods suffer from marginal downstream performance improvements, limited distillation of contextual information, and subpar cross-architecture generalization. To address these challenges in dataset distillation, we propose the ATtentiOn Mixer (ATOM) module to efficiently distill large datasets using a mixture of channel and spatial-wise attention in the feature matching process. Spatial-wise attention helps guide the learning process based on consistent localization of classes in their respective images, allowing for distillation from a broader receptive field. Meanwhile, channel-wise attention captures the contextual information associated with the class itself, thus making the synthetic image more informative for training. By integrating both types of attention, our ATOM module demonstrates superior performance across various computer vision datasets, including CIFAR10/100 and TinyImagenet. Notably, our method significantly improves performance in scenarios with a low number of images per class, thereby enhancing its potential. Furthermore, we maintain the improvement in cross-architectures and applications such as neural architecture search.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Improving Subject-Driven Image Synthesis with Subject-Agnostic Guidance</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01356">https://arxiv.org/abs/2405.01356</a></p>
  <p><b>作者</b>：Kelvin C.K. Chan,  Yang Zhao,  Xuhui Jia,  Ming-Hsuan Yang,  Huisheng Wang</p>
  <p><b>备注</b>：Accepted to CVPR 2024</p>
  <p><b>关键词</b>：reference images provided, overlooking crucial attributes, crucial attributes detailed, synthesis process, heavily influenced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In subject-driven text-to-image synthesis, the synthesis process tends to be heavily influenced by the reference images provided by users, often overlooking crucial attributes detailed in the text prompt. In this work, we propose Subject-Agnostic Guidance (SAG), a simple yet effective solution to remedy the problem. We show that through constructing a subject-agnostic condition and applying our proposed dual classifier-free guidance, one could obtain outputs consistent with both the given subject and input text prompts. We validate the efficacy of our approach through both optimization-based and encoder-based methods. Additionally, we demonstrate its applicability in second-order customization methods, where an encoder-based model is fine-tuned with DreamBooth. Our approach is conceptually simple and requires only minimal code modifications, but leads to substantial quality improvements, as evidenced by our evaluations and user studies.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Sparse multi-view hand-object reconstruction for unseen environments</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01353">https://arxiv.org/abs/2405.01353</a></p>
  <p><b>作者</b>：Yik Lung Pang,  Changjae Oh,  Andrea Cavallaro</p>
  <p><b>备注</b>：Camera-ready version. Paper accepted to CVPRW 2024. 8 pages, 7 figures, 1 table</p>
  <p><b>关键词</b>：dense multi-view methods, multi-view methods, Recent works, dense multi-view, unseen objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works in hand-object reconstruction mainly focus on the single-view and dense multi-view settings. On the one hand, single-view methods can leverage learned shape priors to generalise to unseen objects but are prone to inaccuracies due to occlusions. On the other hand, dense multi-view methods are very accurate but cannot easily adapt to unseen objects without further data collection. In contrast, sparse multi-view methods can take advantage of the additional views to tackle occlusion, while keeping the computational cost low compared to dense multi-view methods. In this paper, we consider the problem of hand-object reconstruction with unseen objects in the sparse multi-view setting. Given multiple RGB images of the hand and object captured at the same time, our model SVHO combines the predictions from each view into a unified reconstruction without optimisation across views. We train our model on a synthetic hand-object dataset and evaluate directly on a real world recorded hand-object dataset with unseen objects. We show that while reconstruction of unseen hands and objects from RGB is challenging, additional views can help improve the reconstruction quality.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Multi-view Action Recognition via Directed Gromov-Wasserstein  Discrepancy</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01337">https://arxiv.org/abs/2405.01337</a></p>
  <p><b>作者</b>：Hoang-Quan Nguyen,  Thanh-Dat Truong,  Khoa Luu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular research topics, Action recognition, Directed Gromov-Wasserstein Discrepancy, Action, action recognition model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Action recognition has become one of the popular research topics in computer vision. There are various methods based on Convolutional Networks and self-attention mechanisms as Transformers to solve both spatial and temporal dimensions problems of action recognition tasks that achieve competitive performances. However, these methods lack a guarantee of the correctness of the action subject that the models give attention to, i.e., how to ensure an action recognition model focuses on the proper action subject to make a reasonable action prediction. In this paper, we propose a multi-view attention consistency method that computes the similarity between two attentions from two different views of the action videos using Directed Gromov-Wasserstein Discrepancy. Furthermore, our approach applies the idea of Neural Radiance Field to implicitly render the features from novel views when training on single-view datasets. Therefore, the contributions in this work are three-fold. Firstly, we introduce the multi-view attention consistency to solve the problem of reasonable prediction in action recognition. Secondly, we define a new metric for multi-view consistent attention using Directed Gromov-Wasserstein Discrepancy. Thirdly, we built an action recognition model based on Video Transformers and Neural Radiance Fields. Compared to the recent action recognition methods, the proposed approach achieves state-of-the-art results on three large-scale datasets, i.e., Jester, Something-Something V2, and Kinetics-400.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：NeRF in Robotics: A Survey</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01333">https://arxiv.org/abs/2405.01333</a></p>
  <p><b>作者</b>：Guangming Wang,  Lei Pan,  Songyou Peng,  Shaohui Liu,  Chenfeng Xu,  Yanzi Miao,  Wei Zhan,  Masayoshi Tomizuka,  Marc Pollefeys,  Hesheng Wang</p>
  <p><b>备注</b>：21 pages, 19 figures</p>
  <p><b>关键词</b>：Neural Radiance Field, field, NeRF, neural implicit representations, field of robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meticulous 3D environment representations have been a longstanding goal in computer vision and robotics fields. The recent emergence of neural implicit representations has introduced radical innovation to this field as implicit representations enable numerous capabilities. Among these, the Neural Radiance Field (NeRF) has sparked a trend because of the huge representational advantages, such as simplified mathematical models, compact environment storage, and continuous scene representations. Apart from computer vision, NeRF has also shown tremendous potential in the field of robotics. Thus, we create this survey to provide a comprehensive understanding of NeRF in the field of robotics. By exploring the advantages and limitations of NeRF, as well as its current applications and future potential, we hope to shed light on this promising area of research. Our survey is divided into two main sections: \textit{The Application of NeRF in Robotics} and \textit{The Advance of NeRF in Robotics}, from the perspective of how NeRF enters the field of robotics. In the first section, we introduce and analyze some works that have been or could be used in the field of robotics from the perception and interaction perspectives. In the second section, we show some works related to improving NeRF's own properties, which are essential for deploying NeRF in the field of robotics. In the discussion section of the review, we summarize the existing challenges and provide some valuable future research directions for reference.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Multi-modal Learnable Queries for Image Aesthetics Assessment</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01326">https://arxiv.org/abs/2405.01326</a></p>
  <p><b>作者</b>：Zhiwei Xiong,  Yunfan Zhang,  Zhiqi Shen,  Peiran Ren,  Han Yu</p>
  <p><b>备注</b>：Accepted by ICME2024</p>
  <p><b>关键词</b>：attracting wide interest, social media, Image aesthetics assessment, attracting wide, wide interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image aesthetics assessment (IAA) is attracting wide interest with the prevalence of social media. The problem is challenging due to its subjective and ambiguous nature. Instead of directly extracting aesthetic features solely from the image, user comments associated with an image could potentially provide complementary knowledge that is useful for IAA. With existing large-scale pre-trained models demonstrating strong capabilities in extracting high-quality transferable visual and textual features, learnable queries are shown to be effective in extracting useful features from the pre-trained visual features. Therefore, in this paper, we propose MMLQ, which utilizes multi-modal learnable queries to extract aesthetics-related features from multi-modal pre-trained features. Extensive experimental results demonstrate that MMLQ achieves new state-of-the-art performance on multi-modal IAA, beating previous methods by 7.7% and 8.3% in terms of SRCC and PLCC, respectively.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Imagine the Unseen: Occluded Pedestrian Detection via Adversarial  Feature Completion</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01311">https://arxiv.org/abs/2405.01311</a></p>
  <p><b>作者</b>：Shanshan Zhang,  Mingqian Ji,  Yang Li,  Jian Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, development of DNNs, significantly progressed, progressed in recent, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pedestrian detection has significantly progressed in recent years, thanks to the development of DNNs. However, detection performance at occluded scenes is still far from satisfactory, as occlusion increases the intra-class variance of pedestrians, hindering the model from finding an accurate classification boundary between pedestrians and background clutters. From the perspective of reducing intra-class variance, we propose to complete features for occluded regions so as to align the features of pedestrians across different occlusion patterns. An important premise for feature completion is to locate occluded regions. From our analysis, channel features of different pedestrian proposals only show high correlation values at visible parts and thus feature correlations can be used to model occlusion patterns. In order to narrow down the gap between completed features and real fully visible ones, we propose an adversarial learning method, which completes occluded features with a generator such that they can hardly be distinguished by the discriminator from real fully visible features. We report experimental results on the CityPersons, Caltech and CrowdHuman datasets. On CityPersons, we show significant improvements over five different baseline detectors, especially on the heavy occlusion subset. Furthermore, we show that our proposed method FeatComp++ achieves state-of-the-art results on all the above three datasets without relying on extra cues.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Towards Inclusive Face Recognition Through Synthetic Ethnicity  Alteration</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01273">https://arxiv.org/abs/2405.01273</a></p>
  <p><b>作者</b>：Praveen Kumar Chandaliya,  Kiran Raja,  Raghavendra Ramachandra,  Zahid Akhtar,  Christoph Busch</p>
  <p><b>备注</b>：8 Pages</p>
  <p><b>关键词</b>：Face Recognition Systems, existing Face Recognition, Face Recognition, Recognition Systems, face image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous studies have shown that existing Face Recognition Systems (FRS), including commercial ones, often exhibit biases toward certain ethnicities due to under-represented data. In this work, we explore ethnicity alteration and skin tone modification using synthetic face image generation methods to increase the diversity of datasets. We conduct a detailed analysis by first constructing a balanced face image dataset representing three ethnicities: Asian, Black, and Indian. We then make use of existing Generative Adversarial Network-based (GAN) image-to-image translation and manifold learning models to alter the ethnicity from one to another. A systematic analysis is further conducted to assess the suitability of such datasets for FRS by studying the realistic skin-tone representation using Individual Typology Angle (ITA). Further, we also analyze the quality characteristics using existing Face image quality assessment (FIQA) approaches. We then provide a holistic FRS performance analysis using four different systems. Our findings pave the way for future research works in (i) developing both specific ethnicity and general (any to any) ethnicity alteration models, (ii) expanding such approaches to create databases with diverse skin tones, (iii) creating datasets representing various ethnicities which further can help in mitigating bias while addressing privacy concerns.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Towards Consistent Object Detection via LiDAR-Camera Synergy</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01258">https://arxiv.org/abs/2405.01258</a></p>
  <p><b>作者</b>：Kai Luo,  Hao Wu,  Kefu Yi,  Kailun Yang,  Wei Hao,  Rongdong Hu</p>
  <p><b>备注</b>：The source code will be made publicly available at this https URL</p>
  <p><b>关键词</b>：point clouds, continues to evolve, increasingly crucial, human-machine interaction continues, capacity for environmental</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As human-machine interaction continues to evolve, the capacity for environmental perception is becoming increasingly crucial. Integrating the two most common types of sensory data, images, and point clouds, can enhance detection accuracy. However, currently, no model exists that can simultaneously detect an object's position in both point clouds and images and ascertain their corresponding relationship. This information is invaluable for human-machine interactions, offering new possibilities for their enhancement. In light of this, this paper introduces an end-to-end Consistency Object Detection (COD) algorithm framework that requires only a single forward inference to simultaneously obtain an object's position in both point clouds and images and establish their correlation. Furthermore, to assess the accuracy of the object correlation between point clouds and images, this paper proposes a new evaluation metric, Consistency Precision (CP). To verify the effectiveness of the proposed framework, an extensive set of experiments has been conducted on the KITTI and DAIR-V2X datasets. The study also explored how the proposed consistency detection method performs on images when the calibration parameters between images and point clouds are disturbed, compared to existing post-processing methods. The experimental results demonstrate that the proposed method exhibits excellent detection performance and robustness, achieving end-to-end consistency detection. The source code will be made publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Evaluation of Video-Based rPPG in Challenging Environments: Artifact  Mitigation and Network Resilience</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01230">https://arxiv.org/abs/2405.01230</a></p>
  <p><b>作者</b>：Nhi Nguyen,  Le Nguyen,  Honghan Li,  Miguel Bordallo López,  Constantino Álvarez Casado</p>
  <p><b>备注</b>：22 main article pages with 3 supplementary pages, journal</p>
  <p><b>关键词</b>：non-contact vital sign, vital sign monitoring, controlled conditions, promising technology, technology for non-contact</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video-based remote photoplethysmography (rPPG) has emerged as a promising technology for non-contact vital sign monitoring, especially under controlled conditions. However, the accurate measurement of vital signs in real-world scenarios faces several challenges, including artifacts induced by videocodecs, low-light noise, degradation, low dynamic range, occlusions, and hardware and network constraints. In this article, we systematically investigate comprehensive investigate these issues, measuring their detrimental effects on the quality of rPPG measurements. Additionally, we propose practical strategies for mitigating these challenges to improve the dependability and resilience of video-based rPPG systems. We detail methods for effective biosignal recovery in the presence of network limitations and present denoising and inpainting techniques aimed at preserving video frame integrity. Through extensive evaluations and direct comparisons, we demonstrate the effectiveness of the approaches in enhancing rPPG measurements under challenging environments, contributing to the development of more reliable and effective remote vital sign monitoring technologies.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：RaffeSDG: Random Frequency Filtering enabled Single-source Domain  Generalization for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01228">https://arxiv.org/abs/2405.01228</a></p>
  <p><b>作者</b>：Heng Li,  Haojin Li,  Jianyu Chen,  Zhongxi Qiu,  Huazhu Fu,  Lidai Wang,  Yan Hu,  Jiang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep learning models, making accurate inferences, clinical settings due, Deep learning, encounter challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models often encounter challenges in making accurate inferences when there are domain shifts between the source and target data. This issue is particularly pronounced in clinical settings due to the scarcity of annotated data resulting from the professional and private nature of medical data. Despite the existence of decent solutions, many of them are hindered in clinical settings due to limitations in data collection and computational complexity. To tackle domain shifts in data-scarce medical scenarios, we propose a Random frequency filtering enabled Single-source Domain Generalization algorithm (RaffeSDG), which promises robust out-of-domain inference with segmentation models trained on a single-source domain. A filter-based data augmentation strategy is first proposed to promote domain variability within a single-source domain by introducing variations in frequency space and blending homologous samples. Then Gaussian filter-based structural saliency is also leveraged to learn robust representations across augmented samples, further facilitating the training of generalizable segmentation models. To validate the effectiveness of RaffeSDG, we conducted extensive experiments involving out-of-domain inference on segmentation tasks for three human tissues imaged by four diverse modalities. Through thorough investigations and comparisons, compelling evidence was observed in these experiments, demonstrating the potential and generalizability of RaffeSDG. The code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：CromSS: Cross-modal pre-training with noisy labels for remote sensing  image segmentation</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01217">https://arxiv.org/abs/2405.01217</a></p>
  <p><b>作者</b>：Chenying Liu,  Conrad Albrecht,  Yi Wang,  Xiao Xiang Zhu</p>
  <p><b>备注</b>：Accepted as an oral presentation by ICLR 2024 ML4RS workshop</p>
  <p><b>关键词</b>：Cross-modal Sample Selection, pretrain semantic segmentation, semantic segmentation models, multi-modal learning framework, Sample Selection method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the potential of noisy labels y to pretrain semantic segmentation models in a multi-modal learning framework for geospatial applications. Specifically, we propose a novel Cross-modal Sample Selection method (CromSS) that utilizes the class distributions P^{(d)}(x,c) over pixels x and classes c modelled by multiple sensors/modalities d of a given geospatial scene. Consistency of predictions across sensors $d$ is jointly informed by the entropy of P^{(d)}(x,c). Noisy label sampling we determine by the confidence of each sensor d in the noisy class label, P^{(d)}(x,c=y(x)). To verify the performance of our approach, we conduct experiments with Sentinel-1 (radar) and Sentinel-2 (optical) satellite imagery from the globally-sampled SSL4EO-S12 dataset. We pair those scenes with 9-class noisy labels sourced from the Google Dynamic World project for pretraining. Transfer learning evaluations (downstream task) on the DFC2020 dataset confirm the effectiveness of the proposed method for remote sensing image segmentation.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Error-Driven Uncertainty Aware Training</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01205">https://arxiv.org/abs/2405.01205</a></p>
  <p><b>作者</b>：Pedro Mendes,  Paolo Romano,  David Garlan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reliability and trustworthiness, undermines their reliability, Uncertainty Aware Training, Error-Driven Uncertainty Aware, Neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are often overconfident about their predictions, which undermines their reliability and trustworthiness. In this work, we present a novel technique, named Error-Driven Uncertainty Aware Training (EUAT), which aims to enhance the ability of neural models to estimate their uncertainty correctly, namely to be highly uncertain when they output inaccurate predictions and low uncertain when their output is accurate. The EUAT approach operates during the model's training phase by selectively employing two loss functions depending on whether the training examples are correctly or incorrectly predicted by the model. This allows for pursuing the twofold goal of i) minimizing model uncertainty for correctly predicted inputs and ii) maximizing uncertainty for mispredicted inputs, while preserving the model's misprediction rate. We evaluate EUAT using diverse neural models and datasets in the image recognition domains considering both non-adversarial and adversarial settings. The results show that EUAT outperforms existing approaches for uncertainty estimation (including other uncertainty-aware training techniques, calibration, ensembles, and DEUP) by providing uncertainty estimates that not only have higher quality when evaluated via statistical metrics (e.g., correlation with residuals) but also when employed to build binary classifiers that decide whether the model's output can be trusted or not and under distributional data shifts.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Towards Cross-Scale Attention and Surface Supervision for Fractured Bone  Segmentation in CT</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01204">https://arxiv.org/abs/2405.01204</a></p>
  <p><b>作者</b>：Yu Zhou,  Xiahao Zou,  Yi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fracture trauma surgery, trauma surgery, essential step, preoperative planning, fractured bone segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bone segmentation is an essential step for the preoperative planning of fracture trauma surgery. The automated segmentation of fractured bone from computed tomography (CT) scans remains challenging, due to the large differences of fractures in position and morphology, and also the inherent anatomical characteristics of different bone structures. To alleviate these issues, we propose a cross-scale attention mechanism as well as a surface supervision strategy for fractured bone segmentation in CT. Specifically, a cross-scale attention mechanism is introduced to effectively aggregate the features among different scales to provide more powerful fracture representation. Moreover, a surface supervision strategy is employed, which explicitly constrains the network to pay more attention to the bone boundary. The efficacy of the proposed method is evaluated on a public dataset containing CT scans with hip fractures. The evaluation metrics are Dice similarity coefficient (DSC), average symmetric surface distance (ASSD), and Hausdorff distance (95HD). The proposed method achieves an average DSC of 93.36%, ASSD of 0.85mm, 95HD of 7.51mm. Our method offers an effective fracture segmentation approach for the pelvic CT examinations, and has the potential to be used for improving the segmentation performance of other types of fractures.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Latent Fingerprint Matching via Dense Minutia Descriptor</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01199">https://arxiv.org/abs/2405.01199</a></p>
  <p><b>作者</b>：Zhiyu Pan,  Yongjie Duan,  Xiongjun Guan,  Jianjiang Feng,  Jie Zhou</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：Latent fingerprint matching, Latent fingerprint, daunting task, primarily due, poor quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Latent fingerprint matching is a daunting task, primarily due to the poor quality of latent fingerprints. In this study, we propose a deep-learning based dense minutia descriptor (DMD) for latent fingerprint matching. A DMD is obtained by extracting the fingerprint patch aligned by its central minutia, capturing detailed minutia information and texture information. Our dense descriptor takes the form of a three-dimensional representation, with two dimensions associated with the original image plane and the other dimension representing the abstract features. Additionally, the extraction process outputs the fingerprint segmentation map, ensuring that the descriptor is only valid in the foreground region. The matching between two descriptors occurs in their overlapping regions, with a score normalization strategy to reduce the impact brought by the differences outside the valid area. Our descriptor achieves state-of-the-art performance on several latent fingerprint datasets. Overall, our DMD is more representative and interpretable compared to previous methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Imagine2touch: Predictive Tactile Sensing for Robotic Manipulation using  Efficient Low-Dimensional Signals</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01192">https://arxiv.org/abs/2405.01192</a></p>
  <p><b>作者</b>：Abdallah Ayad,  Adrian Röfer,  Nick Heppert,  Abhinav Valada</p>
  <p><b>备注</b>：3 pages, 3 figures, 2 tables, accepted at ViTac2024 ICRA2024 Workshop. arXiv admin note: substantial text overlap with arXiv:2403.15107</p>
  <p><b>关键词</b>：Humans seemingly incorporate, seemingly incorporate potential, incorporate potential touch, Humans seemingly, seemingly incorporate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans seemingly incorporate potential touch signals in their perception. Our goal is to equip robots with a similar capability, which we term Imagine2touch. Imagine2touch aims to predict the expected touch signal based on a visual patch representing the area to be touched. We use ReSkin, an inexpensive and compact touch sensor to collect the required dataset through random touching of five basic geometric shapes, and one tool. We train Imagine2touch on two out of those shapes and validate it on the ood. tool. We demonstrate the efficacy of Imagine2touch through its application to the downstream task of object recognition. In this task, we evaluate Imagine2touch performance in two experiments, together comprising 5 out of training distribution objects. Imagine2touch achieves an object recognition accuracy of 58% after ten touches per object, surpassing a proprioception baseline.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Uncertainty-aware self-training with expectation maximization basis  transformation</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01175">https://arxiv.org/abs/2405.01175</a></p>
  <p><b>作者</b>：Zijia Wang,  Wenbin Yang,  Zhisong Liu,  Zhen Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning, powerful approach, approach to deep, uncertainty information, uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-training is a powerful approach to deep learning. The key process is to find a pseudo-label for modeling. However, previous self-training algorithms suffer from the over-confidence issue brought by the hard labels, even some confidence-related regularizers cannot comprehensively catch the uncertainty. Therefore, we propose a new self-training framework to combine uncertainty information of both model and dataset. Specifically, we propose to use Expectation-Maximization (EM) to smooth the labels and comprehensively estimate the uncertainty information. We further design a basis extraction network to estimate the initial basis from the dataset. The obtained basis with uncertainty can be filtered based on uncertainty information. It can then be transformed into the real hard label to iteratively update the model and basis in the retraining process. Experiments on image classification and semantic segmentation show the advantages of our methods among confidence-aware self-training algorithms with 1-3 percentage improvement on different datasets.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：GroupedMixer: An Entropy Model with Group-wise Token-Mixers for Learned  Image Compression</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01170">https://arxiv.org/abs/2405.01170</a></p>
  <p><b>作者</b>：Daxin Li,  Yuanchao Bai,  Kai Wang,  Junjun Jiang,  Xianming Liu,  Wen Gao</p>
  <p><b>备注</b>：Accepted by IEEE TCSVT</p>
  <p><b>关键词</b>：capture long-range dependencies, probability distribution estimation, distribution estimation compared, recent years due, Transformer-based entropy models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer-based entropy models have gained prominence in recent years due to their superior ability to capture long-range dependencies in probability distribution estimation compared to convolution-based methods. However, previous transformer-based entropy models suffer from a sluggish coding process due to pixel-wise autoregression or duplicated computation during inference. In this paper, we propose a novel transformer-based entropy model called GroupedMixer, which enjoys both faster coding speed and better compression performance than previous transformer-based methods. Specifically, our approach builds upon group-wise autoregression by first partitioning the latent variables into groups along spatial-channel dimensions, and then entropy coding the groups with the proposed transformer-based entropy model. The global causal self-attention is decomposed into more efficient group-wise interactions, implemented using inner-group and cross-group token-mixers. The inner-group token-mixer incorporates contextual elements within a group while the cross-group token-mixer interacts with previously decoded groups. Alternate arrangement of two token-mixers enables global contextual reference. To further expedite the network inference, we introduce context cache optimization to GroupedMixer, which caches attention activation values in cross-group token-mixers and avoids complex and duplicated computation. Experimental results demonstrate that the proposed GroupedMixer yields the state-of-the-art rate-distortion performance with fast compression speed.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Self-Supervised Learning for Interventional Image Analytics: Towards  Robust Device Trackers</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01156">https://arxiv.org/abs/2405.01156</a></p>
  <p><b>作者</b>：Saahil Islam,  Venkatesh N. Murthy,  Dominik Neumann,  Badhan Kumar Das,  Puneet Sharma,  Andreas Maier,  Dorin Comaniciu,  Florin C. Ghesu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：endovascular cardiac interventions, live X-ray image, accurate detection, guiding catheters, catheters in live</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An accurate detection and tracking of devices such as guiding catheters in live X-ray image acquisitions is an essential prerequisite for endovascular cardiac interventions. This information is leveraged for procedural guidance, e.g., directing stent placements. To ensure procedural safety and efficacy, there is a need for high robustness no failures during tracking. To achieve that, one needs to efficiently tackle challenges, such as: device obscuration by contrast agent or other external devices or wires, changes in field-of-view or acquisition angle, as well as the continuous movement due to cardiac and respiratory motion. To overcome the aforementioned challenges, we propose a novel approach to learn spatio-temporal features from a very large data cohort of over 16 million interventional X-ray frames using self-supervision for image sequence data. Our approach is based on a masked image modeling technique that leverages frame interpolation based reconstruction to learn fine inter-frame temporal correspondences. The features encoded in the resulting model are fine-tuned downstream. Our approach achieves state-of-the-art performance and in particular robustness compared to ultra optimized reference solutions (that use multi-stage feature fusion, multi-task and flow regularization). The experiments show that our method achieves 66.31% reduction in maximum tracking error against reference solutions (23.20% when flow regularization is used); achieving a success score of 97.95% at a 3x faster inference speed of 42 frames-per-second (on GPU). The results encourage the use of our approach in various other tasks within interventional image analytics that require effective understanding of spatio-temporal semantics.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Automated Virtual Product Placement and Assessment in Images using  Diffusion Models</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01130">https://arxiv.org/abs/2405.01130</a></p>
  <p><b>作者</b>：Mohammad Mahmudul Alam,  Negin Sokhandan,  Emmett Goodman</p>
  <p><b>备注</b>：Accepted at the 6th AI for Content Creation (AI4CC) workshop at CVPR 2024</p>
  <p><b>关键词</b>：Virtual Product Placement, specific brand products, Product Placement, VPP system, important task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Virtual Product Placement (VPP) applications, the discrete integration of specific brand products into images or videos has emerged as a challenging yet important task. This paper introduces a novel three-stage fully automated VPP system. In the first stage, a language-guided image segmentation model identifies optimal regions within images for product inpainting. In the second stage, Stable Diffusion (SD), fine-tuned with a few example product images, is used to inpaint the product into the previously identified candidate regions. The final stage introduces an "Alignment Module", which is designed to effectively sieve out low-quality images. Comprehensive experiments demonstrate that the Alignment Module ensures the presence of the intended product in every generated image and enhances the average quality of images by 35%. The results presented in this paper demonstrate the effectiveness of the proposed VPP system, which holds significant potential for transforming the landscape of virtual advertising and marketing strategies.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Detecting and clustering swallow events in esophageal long-term  high-resolution manometry</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01126">https://arxiv.org/abs/2405.01126</a></p>
  <p><b>作者</b>：Alexander Geiger,  Lars Wagner,  Daniel Rueckert,  Dirk Wilhelm,  Alissa Jell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：High-resolution manometry, esophageal motility disorders, diagnosing esophageal motility, gold standard, standard in diagnosing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-resolution manometry (HRM) is the gold standard in diagnosing esophageal motility disorders. As HRM is typically conducted under short-term laboratory settings, intermittently occurring disorders are likely to be missed. Therefore, long-term (up to 24h) HRM (LTHRM) is used to gain detailed insights into the swallowing behavior. However, analyzing the extensive data from LTHRM is challenging and time consuming as medical experts have to analyze the data manually, which is slow and prone to errors. To address this challenge, we propose a Deep Learning based swallowing detection method to accurately identify swallowing events and secondary non-deglutitive-induced esophageal motility disorders in LTHRM data. We then proceed with clustering the identified swallows into distinct classes, which are analyzed by highly experienced clinicians to validate the different swallowing patterns. We evaluate our computational pipeline on a total of 25 LTHRMs, which were meticulously annotated by medical experts. By detecting more than 94% of all relevant swallow events and providing all relevant clusters for a more reliable diagnostic process among experienced clinicians, we are able to demonstrate the effectiveness as well as positive clinical impact of our approach to make LTHRM feasible in clinical care.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Domain-Transferred Synthetic Data Generation for Improving Monocular  Depth Estimation</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01113">https://arxiv.org/abs/2405.01113</a></p>
  <p><b>作者</b>：Seungyeop Lee,  Knut Peterson,  Solmaz Arezoomandan,  Bill Cai,  Peihan Li,  Lifeng Zhou,  David Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collected RGB images, obtaining high-quality depth, collected RGB, RGB images, major obstacle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A major obstacle to the development of effective monocular depth estimation algorithms is the difficulty in obtaining high-quality depth data that corresponds to collected RGB images. Collecting this data is time-consuming and costly, and even data collected by modern sensors has limited range or resolution, and is subject to inconsistencies and noise. To combat this, we propose a method of data generation in simulation using 3D synthetic environments and CycleGAN domain transfer. We compare this method of data generation to the popular NYUDepth V2 dataset by training a depth estimation model based on the DenseDepth structure using different training sets of real and simulated data. We evaluate the performance of the models on newly collected images and LiDAR depth data from a Husky robot to verify the generalizability of the approach and show that GAN-transformed data can serve as an effective alternative to real-world data, particularly in depth estimation.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Sports Analysis and VR Viewing System Based on Player Tracking and Pose  Estimation with Multimodal and Multiview Sensors</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01112">https://arxiv.org/abs/2405.01112</a></p>
  <p><b>作者</b>：Wenxuan Guo,  Zhiyu Pan,  Ziheng Xi,  Alapati Tuerxun,  Jianjiang Feng,  Jie Zhou</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2312.06409</p>
  <p><b>关键词</b>：offering significant, play a pivotal, pivotal role, coaches and athletes, current sports domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sports analysis and viewing play a pivotal role in the current sports domain, offering significant value not only to coaches and athletes but also to fans and the media. In recent years, the rapid development of virtual reality (VR) and augmented reality (AR) technologies have introduced a new platform for watching games. Visualization of sports competitions in VR/AR represents a revolutionary technology, providing audiences with a novel immersive viewing experience. However, there is still a lack of related research in this area. In this work, we present for the first time a comprehensive system for sports competition analysis and real-time visualization on VR/AR platforms. First, we utilize multiview LiDARs and cameras to collect multimodal game data. Subsequently, we propose a framework for multi-player tracking and pose estimation based on a limited amount of supervised data, which extracts precise player positions and movements from point clouds and images. Moreover, we perform avatar modeling of players to obtain their 3D models. Ultimately, using these 3D player data, we conduct competition analysis and real-time visualization on VR/AR. Extensive quantitative experiments demonstrate the accuracy and robustness of our multi-player tracking and pose estimation framework. The visualization results showcase the immense potential of our sports visualization system on the domain of watching games on VR/AR devices. The multimodal competition dataset we collected and all related code will be released soon.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Federated Learning with Heterogeneous Data Handling for Robust Vehicular  Object Detection</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01108">https://arxiv.org/abs/2405.01108</a></p>
  <p><b>作者</b>：Ahmad Khalil,  Tizian Dege,  Pegah Golchin,  Rostyslav Olshevskyi,  Antonio Fernandez Anta,  Tobias Meuser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully autonomous driving, refining precise perception, precise perception models, autonomous driving, model training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the pursuit of refining precise perception models for fully autonomous driving, continual online model training becomes essential. Federated Learning (FL) within vehicular networks offers an efficient mechanism for model training while preserving raw sensory data integrity. Yet, FL struggles with non-identically distributed data (e.g., quantity skew), leading to suboptimal convergence rates during model training. In previous work, we introduced FedLA, an innovative Label-Aware aggregation method addressing data heterogeneity in FL for generic scenarios.
In this paper, we introduce FedProx+LA, a novel FL method building upon the state-of-the-art FedProx and FedLA to tackle data heterogeneity, which is specifically tailored for vehicular networks. We evaluate the efficacy of FedProx+LA in continuous online object detection model training. Through a comparative analysis against conventional and state-of-the-art methods, our findings reveal the superior convergence rate of FedProx+LA. Notably, if the label distribution is very heterogeneous, our FedProx+LA approach shows substantial improvements in detection performance compared to baseline methods, also outperforming our previous FedLA approach. Moreover, both FedLA and FedProx+LA increase convergence speed by 30% compared to baseline methods.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Image segmentation of treated and untreated tumor spheroids by Fully  Convolutional Networks</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01105">https://arxiv.org/abs/2405.01105</a></p>
  <p><b>作者</b>：Matthias Streller,  Soňa Michlíková,  Willy Ciecior,  Katharina Lönnecke,  Leoni A. Kunz-Schughart,  Steffen Lange,  Anja Voss-Böhme</p>
  <p><b>备注</b>：28 pages, 21 figures</p>
  <p><b>关键词</b>：advanced cell culture, cell culture systems, combinatorial radio, culture systems, systems for assessing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multicellular tumor spheroids (MCTS) are advanced cell culture systems for assessing the impact of combinatorial radio(chemo)therapy. They exhibit therapeutically relevant in-vivo-like characteristics from 3D cell-cell and cell-matrix interactions to radial pathophysiological gradients related to proliferative activity and nutrient/oxygen supply, altering cellular radioresponse. State-of-the-art assays quantify long-term curative endpoints based on collected brightfield image time series from large treated spheroid populations per irradiation dose and treatment arm. Here, spheroid control probabilities are documented analogous to in-vivo tumor control probabilities based on Kaplan-Meier curves. This analyses require laborious spheroid segmentation of up to 100.000 images per treatment arm to extract relevant structural information from the images, e.g., diameter, area, volume and circularity. While several image analysis algorithms are available for spheroid segmentation, they all focus on compact MCTS with clearly distinguishable outer rim throughout growth. However, treated MCTS may partly be detached and destroyed and are usually obscured by dead cell debris. We successfully train two Fully Convolutional Networks, UNet and HRNet, and optimize their hyperparameters to develop an automatic segmentation for both untreated and treated MCTS. We systematically validate the automatic segmentation on larger, independent data sets of spheroids derived from two human head-and-neck cancer cell lines. We find an excellent overlap between manual and automatic segmentation for most images, quantified by Jaccard indices at around 90%. For images with smaller overlap of the segmentations, we demonstrate that this error is comparable to the variations across segmentations from different biological experts, suggesting that these images represent biologically unclear or ambiguous cases.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Enhancing Person Re-Identification via Uncertainty Feature Fusion and  Wise Distance Aggregation</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01101">https://arxiv.org/abs/2405.01101</a></p>
  <p><b>作者</b>：Quang-Huy Che,  Le-Chuong Nguyen,  Vinh-Tiep Nguyen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robust Person re-identification, diverse scenarios remains, enhances Person Re-Identification, Wise Distance Aggregation, Person re-identification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The quest for robust Person re-identification (Re-ID) systems capable of accurately identifying subjects across diverse scenarios remains a formidable challenge in surveillance and security applications. This study presents a novel methodology that significantly enhances Person Re-Identification (Re-ID) by integrating Uncertainty Feature Fusion (UFFM) with Wise Distance Aggregation (WDA). Tested on benchmark datasets - Market-1501, DukeMTMC-ReID, and MSMT17 - our approach demonstrates substantial improvements in Rank-1 accuracy and mean Average Precision (mAP). Specifically, UFFM capitalizes on the power of feature synthesis from multiple images to overcome the limitations imposed by the variability of subject appearances across different views. WDA further refines the process by intelligently aggregating similarity metrics, thereby enhancing the system's ability to discern subtle but critical differences between subjects. The empirical results affirm the superiority of our method over existing approaches, achieving new performance benchmarks across all evaluated datasets. Code is available on Github.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Transformers Fusion across Disjoint Samples for Hyperspectral Image  Classification</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01095">https://arxiv.org/abs/2405.01095</a></p>
  <p><b>作者</b>：Muhammad Ahmad,  Manuel Mazzara,  Salvatore Distifano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：capturing intricate spatial, intricate spatial relationships, Swin Transformer, window-based processing, excels in capturing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D Swin Transformer (3D-ST) known for its hierarchical attention and window-based processing, excels in capturing intricate spatial relationships within images. Spatial-spectral Transformer (SST), meanwhile, specializes in modeling long-range dependencies through self-attention mechanisms. Therefore, this paper introduces a novel method: an attentional fusion of these two transformers to significantly enhance the classification performance of Hyperspectral Images (HSIs). What sets this approach apart is its emphasis on the integration of attentional mechanisms from both architectures. This integration not only refines the modeling of spatial and spectral information but also contributes to achieving more precise and accurate classification results. The experimentation and evaluation of benchmark HSI datasets underscore the importance of employing disjoint training, validation, and test samples. The results demonstrate the effectiveness of the fusion approach, showcasing its superiority over traditional methods and individual transformers. Incorporating disjoint samples enhances the robustness and reliability of the proposed methodology, emphasizing its potential for advancing hyperspectral image classification.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning Object States from Actions via Large Language Models</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01090">https://arxiv.org/abs/2405.01090</a></p>
  <p><b>作者</b>：Masatoshi Tateno,  Takuma Yagi,  Ryosuke Furuta,  Yoichi Sato</p>
  <p><b>备注</b>：19 pages of main content, 24 pages of supplementary material</p>
  <p><b>关键词</b>：understanding human activities, object states, object, Temporally localizing, crucial in understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporally localizing the presence of object states in videos is crucial in understanding human activities beyond actions and objects. This task has suffered from a lack of training data due to object states' inherent ambiguity and variety. To avoid exhaustive annotation, learning from transcribed narrations in instructional videos would be intriguing. However, object states are less described in narrations compared to actions, making them less effective. In this work, we propose to extract the object state information from action information included in narrations, using large language models (LLMs). Our observation is that LLMs include world knowledge on the relationship between actions and their resulting object states, and can infer the presence of object states from past action sequences. The proposed LLM-based framework offers flexibility to generate plausible pseudo-object state labels against arbitrary categories. We evaluate our method with our newly collected Multiple Object States Transition (MOST) dataset including dense temporal annotation of 60 object state categories. Our model trained by the generated pseudo-labels demonstrates significant improvement of over 29% in mAP against strong zero-shot vision-language models, showing the effectiveness of explicitly extracting object state information from actions through LLMs.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Type2Branch: Keystroke Biometrics based on a Dual-branch Architecture  with Attention Mechanisms and Set2set Loss</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01088">https://arxiv.org/abs/2405.01088</a></p>
  <p><b>作者</b>：Nahuel González,  Giuseppe Stragapede,  Rubén Vera-Rodriguez,  Rubén Tolosana</p>
  <p><b>备注</b>：13 pages, 3 figures</p>
  <p><b>关键词</b>：keystroke dynamics verification, minimal performance degradation, evaluating keystroke dynamics, dynamics verification systems, keystroke dynamics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In 2021, the pioneering work on TypeNet showed that keystroke dynamics verification could scale to hundreds of thousands of users with minimal performance degradation. Recently, the KVC-onGoing competition has provided an open and robust experimental protocol for evaluating keystroke dynamics verification systems of such scale, including considerations of algorithmic fairness. This article describes Type2Branch, the model and techniques that achieved the lowest error rates at the KVC-onGoing, in both desktop and mobile scenarios. The novelty aspects of the proposed Type2Branch include: i) synthesized timing features emphasizing user behavior deviation from the general population, ii) a dual-branch architecture combining recurrent and convolutional paths with various attention mechanisms, iii) a new loss function named Set2set that captures the global structure of the embedding space, and iv) a training curriculum of increasing difficulty. Considering five enrollment samples per subject of approximately 50 characters typed, the proposed Type2Branch achieves state-of-the-art performance with mean per-subject EERs of 0.77% and 1.03% on evaluation sets of respectively 15,000 and 5,000 subjects for desktop and mobile scenarios. With a uniform global threshold for all subjects, the EERs are 3.25% for desktop and 3.61% for mobile, outperforming previous approaches by a significant margin.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Single Image Super-Resolution Based on Global-Local Information Synergy</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01085">https://arxiv.org/abs/2405.01085</a></p>
  <p><b>作者</b>：Nianzu Qiao,  Lamei Di,  Changyin Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Information Extraction Module, Global-Local Information Extraction, super-resolution solutions exist, Extraction Module, Basic Block Module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although several image super-resolution solutions exist, they still face many challenges. CNN-based algorithms, despite the reduction in computational complexity, still need to improve their accuracy. While Transformer-based algorithms have higher accuracy, their ultra-high computational complexity makes them difficult to be accepted in practical applications. To overcome the existing challenges, a novel super-resolution reconstruction algorithm is proposed in this paper. The algorithm achieves a significant increase in accuracy through a unique design while maintaining a low complexity. The core of the algorithm lies in its cleverly designed Global-Local Information Extraction Module and Basic Block Module. By combining global and local information, the Global-Local Information Extraction Module aims to understand the image content more comprehensively so as to recover the global structure and local details in the image more accurately, which provides rich information support for the subsequent reconstruction process. Experimental results show that the comprehensive performance of the algorithm proposed in this paper is optimal, providing an efficient and practical new solution in the field of super-resolution reconstruction.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：MCMS: Multi-Category Information and Multi-Scale Stripe Attention for  Blind Motion Deblurring</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01083">https://arxiv.org/abs/2405.01083</a></p>
  <p><b>作者</b>：Nianzu Qiao,  Lamei Di,  Changyin Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-frequency component, low-frequency component, component, blurry images, recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning-based motion deblurring techniques have advanced significantly in recent years. This class of techniques, however, does not carefully examine the inherent flaws in blurry images. For instance, low edge and structural information are traits of blurry images. The high-frequency component of blurry images is edge information, and the low-frequency component is structure information. A blind motion deblurring network (MCMS) based on multi-category information and multi-scale stripe attention mechanism is proposed. Given the respective characteristics of the high-frequency and low-frequency components, a three-stage encoder-decoder model is designed. Specifically, the first stage focuses on extracting the features of the high-frequency component, the second stage concentrates on extracting the features of the low-frequency component, and the third stage integrates the extracted low-frequency component features, the extracted high-frequency component features, and the original blurred image in order to recover the final clear image. As a result, the model effectively improves motion deblurring by fusing the edge information of the high-frequency component and the structural information of the low-frequency component. In addition, a grouped feature fusion technique is developed so as to achieve richer, more three-dimensional and comprehensive utilization of various types of features at a deep level. Next, a multi-scale stripe attention mechanism (MSSA) is designed, which effectively combines the anisotropy and multi-scale information of the image, a move that significantly enhances the capability of the deep model in feature representation. Large-scale comparative studies on various datasets show that the strategy in this paper works better than the recently published measures.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Poisoning Attacks on Federated Learning for Autonomous Driving</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01073">https://arxiv.org/abs/2405.01073</a></p>
  <p><b>作者</b>：Sonakshi Garg,  Hugo Jönsson,  Gustav Kalander,  Axel Nilsson,  Bhhaanu Pirange,  Viktor Valadi,  Johan Östman</p>
  <p><b>备注</b>：Accepted to SCAI2024</p>
  <p><b>关键词</b>：decentralized learning paradigm, collaboratively train models, Federated Learning, learning paradigm, enabling parties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a decentralized learning paradigm, enabling parties to collaboratively train models while keeping their data confidential. Within autonomous driving, it brings the potential of reducing data storage costs, reducing bandwidth requirements, and to accelerate the learning. FL is, however, susceptible to poisoning attacks. In this paper, we introduce two novel poisoning attacks on FL tailored to regression tasks within autonomous driving: FLStealth and Off-Track Attack (OTA). FLStealth, an untargeted attack, aims at providing model updates that deteriorate the global model performance while appearing benign. OTA, on the other hand, is a targeted attack with the objective to change the global model's behavior when exposed to a certain trigger. We demonstrate the effectiveness of our attacks by conducting comprehensive experiments pertaining to the task of vehicle trajectory prediction. In particular, we show that, among five different untargeted attacks, FLStealth is the most successful at bypassing the considered defenses employed by the server. For OTA, we demonstrate the inability of common defense strategies to mitigate the attack, highlighting the critical need for new defensive mechanisms against targeted attacks within FL for autonomous driving.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Callico: a Versatile Open-Source Document Image Annotation Platform</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01071">https://arxiv.org/abs/2405.01071</a></p>
  <p><b>作者</b>：Christopher Kermorvant,  Eva Bardou,  Manon Blanco,  Bastien Abadie</p>
  <p><b>备注</b>：Accepted to ICDAR 2024</p>
  <p><b>关键词</b>：paper presents Callico, web-based open source, paper presents, designed to simplify, source platform designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents Callico, a web-based open source platform designed to simplify the annotation process in document recognition projects. The move towards data-centric AI in machine learning and deep learning underscores the importance of high-quality data, and the need for specialised tools that increase the efficiency and effectiveness of generating such data. For document image annotation, Callico offers dual-display annotation for digitised documents, enabling simultaneous visualisation and annotation of scanned images and text. This capability is critical for OCR and HTR model training, document layout analysis, named entity recognition, form-based key value annotation or hierarchical structure annotation with element grouping. The platform supports collaborative annotation with versatile features backed by a commitment to open source development, high-quality code standards and easy deployment via Docker. Illustrative use cases - including the transcription of the Belfort municipal registers, the indexing of French World War II prisoners for the ICRC, and the extraction of personal information from the Socface project's census lists - demonstrate Callico's applicability and utility.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：HandSSCA: 3D Hand Mesh Reconstruction with State Space Channel Attention  from RGB images</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01066">https://arxiv.org/abs/2405.01066</a></p>
  <p><b>作者</b>：Zixun Jiao,  Xihan Wang,  Quanli Gao</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：single RGB image, single RGB, RGB image, occluded by objects, RGB</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing a hand mesh from a single RGB image is a challenging task because hands are often occluded by objects. Most previous works attempted to introduce more additional information and adopt attention mechanisms to improve 3D reconstruction results, but it would increased computational complexity. This observation prompts us to propose a new and concise architecture while improving computational efficiency. In this work, we propose a simple and effective 3D hand mesh reconstruction network HandSSCA, which is the first to incorporate state space modeling into the field of hand pose estimation. In the network, we have designed a novel state space channel attention module that extends the effective sensory field, extracts hand features in the spatial dimension, and enhances hand regional features in the channel dimension. This design helps to reconstruct a complete and detailed hand mesh. Extensive experiments conducted on well-known datasets featuring challenging hand-object occlusions (such as FREIHAND, DEXYCB, and HO3D) demonstrate that our proposed HandSSCA achieves state-of-the-art performance while maintaining a minimal parameter count.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：MFDS-Net: Multi-Scale Feature Depth-Supervised Network for Remote  Sensing Change Detection with Global Semantic and Detail Information</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01065">https://arxiv.org/abs/2405.01065</a></p>
  <p><b>作者</b>：Zhenyang Huang,  Zhaojin Fu,  Song Jintao,  Genji Yuan,  Jinjiang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：receiving extensive attention, Remote Sensing Change, Sensing Change Detection, Change detection, remote sensing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Change detection as an interdisciplinary discipline in the field of computer vision and remote sensing at present has been receiving extensive attention and research. Due to the rapid development of society, the geographic information captured by remote sensing satellites is changing faster and more complex, which undoubtedly poses a higher challenge and highlights the value of change detection tasks. We propose MFDS-Net: Multi-Scale Feature Depth-Supervised Network for Remote Sensing Change Detection with Global Semantic and Detail Information (MFDS-Net) with the aim of achieving a more refined description of changing buildings as well as geographic information, enhancing the localisation of changing targets and the acquisition of weak features. To achieve the research objectives, we use a modified ResNet_34 as backbone network to perform feature extraction and DO-Conv as an alternative to traditional convolution to better focus on the association between feature information and to obtain better training results. We propose the Global Semantic Enhancement Module (GSEM) to enhance the processing of high-level semantic information from a global perspective. The Differential Feature Integration Module (DFIM) is proposed to strengthen the fusion of different depth feature information, achieving learning and extraction of differential features. The entire network is trained and optimized using a deep supervision mechanism.
The experimental outcomes of MFDS-Net surpass those of current mainstream change detection networks. On the LEVIR dataset, it achieved an F1 score of 91.589 and IoU of 84.483, on the WHU dataset, the scores were F1: 92.384 and IoU: 86.807, and on the GZ-CD dataset, the scores were F1: 86.377 and IoU: 76.021. The code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A text-based, generative deep learning model for soil reflectance  spectrum simulation in the VIS-NIR (400-2499 nm) bands</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01060">https://arxiv.org/abs/2405.01060</a></p>
  <p><b>作者</b>：Tong Lei,  Brian N. Bailey</p>
  <p><b>备注</b>：The paper has been submitted to Remote sensing of Environment and revised</p>
  <p><b>关键词</b>：soil reflectance spectra, reflectance spectra, soil reflectance, reflectance spectra based, Simulating soil reflectance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulating soil reflectance spectra is invaluable for soil-plant radiative modeling and training machine learning models, yet it is difficult as the intricate relationships between soil structure and its constituents. To address this, a fully data-driven soil optics generative model (SOGM) for simulation of soil reflectance spectra based on soil property inputs was developed. The model is trained on an extensive dataset comprising nearly 180,000 soil spectra-property pairs from 17 datasets. It generates soil reflectance spectra from text-based inputs describing soil properties and their values rather than only numerical values and labels in binary vector format. The generative model can simulate output spectra based on an incomplete set of input properties. SOGM is based on the denoising diffusion probabilistic model (DDPM). Two additional sub-models were also built to complement the SOGM: a spectral padding model that can fill in the gaps for spectra shorter than the full visible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra model that can estimate the effects of water content on soil reflectance spectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by coupling with the Helios 3D plant modeling software, which allowed for generation of synthetic aerial images of simulated soil and plant scenes. It can also be easily integrated with soil-plant radiation model used for remote sensin research like PROSAIL. The testing results of the SOGM on new datasets that not included in model training proved that the model can generate reasonable soil reflectance spectra based on available property inputs. The presented models are openly accessible on: this https URL.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Continual Learning for Robust Gate Detection under Dynamic Lighting in  Autonomous Drone Racing</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01054">https://arxiv.org/abs/2405.01054</a></p>
  <p><b>作者</b>：Zhongzheng Qiao,  Xuan Huy Pham,  Savitha Ramasamy,  Xudong Jiang,  Erdal Kayacan,  Andriy Sarabakha</p>
  <p><b>备注</b>：8 pages, 6 figures, in 2024 International Joint Conference on Neural Networks (IJCNN)</p>
  <p><b>关键词</b>：resilient real-time environmental, real-time environmental perception, autonomous drone racing, mobile robotics, dynamic elements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In autonomous and mobile robotics, a principal challenge is resilient real-time environmental perception, particularly in situations characterized by unknown and dynamic elements, as exemplified in the context of autonomous drone racing. This study introduces a perception technique for detecting drone racing gates under illumination variations, which is common during high-speed drone flights. The proposed technique relies upon a lightweight neural network backbone augmented with capabilities for continual learning. The envisaged approach amalgamates predictions of the gates' positional coordinates, distance, and orientation, encapsulating them into a cohesive pose tuple. A comprehensive number of tests serve to underscore the efficacy of this approach in confronting diverse and challenging scenarios, specifically those involving variable lighting conditions. The proposed methodology exhibits notable robustness in the face of illumination variations, thereby substantiating its effectiveness.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Few Shot Class Incremental Learning using Vision-Language models</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01040">https://arxiv.org/abs/2405.01040</a></p>
  <p><b>作者</b>：Anurag Kumar,  Chinmay Bharti,  Saikat Dutta,  Srikrishna Karanam,  Biplab Banerjee</p>
  <p><b>备注</b>：under review at Pattern Recognition Letters</p>
  <p><b>关键词</b>：computer vision tasks, supervised computer vision, demonstrated remarkable performance, remarkable performance comparable, Recent advancements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in deep learning have demonstrated remarkable performance comparable to human capabilities across various supervised computer vision tasks. However, the prevalent assumption of having an extensive pool of training data encompassing all classes prior to model training often diverges from real-world scenarios, where limited data availability for novel classes is the norm. The challenge emerges in seamlessly integrating new classes with few samples into the training data, demanding the model to adeptly accommodate these additions without compromising its performance on base classes. To address this exigency, the research community has introduced several solutions under the realm of few-shot class incremental learning (FSCIL).
In this study, we introduce an innovative FSCIL framework that utilizes language regularizer and subspace regularizer. During base training, the language regularizer helps incorporate semantic information extracted from a Vision-Language model. The subspace regularizer helps in facilitating the model's acquisition of nuanced connections between image and text semantics inherent to base classes during incremental training. Our proposed framework not only empowers the model to embrace novel classes with limited data, but also ensures the preservation of performance on base classes. To substantiate the efficacy of our approach, we conduct comprehensive experiments on three distinct FSCIL benchmarks, where our framework attains state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Technical Report of NICE Challenge at CVPR 2024: Caption Re-ranking  Evaluation Using Ensembled CLIP and Consensus Scores</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01028">https://arxiv.org/abs/2405.01028</a></p>
  <p><b>作者</b>：Kiyoon Jeong,  Woojun Lee,  Woongchan Nam,  Minjeong Ma,  Pilsung Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：team DSBA LAB, DSBA LAB, Ensembled Clip score, team DSBA, Ensembled Clip</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report presents the ECO (Ensembled Clip score and cOnsensus score) pipeline from team DSBA LAB, which is a new framework used to evaluate and rank captions for a given image. ECO selects the most accurate caption describing image. It is made possible by combining an Ensembled CLIP score, which considers the semantic alignment between the image and captions, with a Consensus score that accounts for the essentialness of the captions. Using this framework, we achieved notable success in the CVPR 2024 Workshop Challenge on Caption Re-ranking Evaluation at the New Frontiers for Zero-Shot Image Captioning Evaluation (NICE). Specifically, we secured third place based on the CIDEr metric, second in both the SPICE and METEOR metrics, and first in the ROUGE-L and all BLEU Score metrics. The code and configuration for the ECO framework are available at this https URL DSBA-Lab/ECO .</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Addressing Diverging Training Costs using Local Restoration for Precise  Bird's Eye View Map Construction</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01016">https://arxiv.org/abs/2405.01016</a></p>
  <p><b>作者</b>：Minsu Kim,  Giseop Kim,  Sunwook Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bird Eye View, Eye View, Bird Eye, demonstrated remarkable mapping, advancements in Bird</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Bird's Eye View (BEV) fusion for map construction have demonstrated remarkable mapping of urban environments. However, their deep and bulky architecture incurs substantial amounts of backpropagation memory and computing latency. Consequently, the problem poses an unavoidable bottleneck in constructing high-resolution (HR) BEV maps, as their large-sized features cause significant increases in costs including GPU memory consumption and computing latency, named diverging training costs issue. Affected by the problem, most existing methods adopt low-resolution (LR) BEV and struggle to estimate the precise locations of urban scene components like road lanes, and sidewalks. As the imprecision leads to risky self-driving, the diverging training costs issue has to be resolved. In this paper, we address the issue with our novel Trumpet Neural Network (TNN) mechanism. The framework utilizes LR BEV space and outputs an up-sampled semantic BEV map to create a memory-efficient pipeline. To this end, we introduce Local Restoration of BEV representation. Specifically, the up-sampled BEV representation has severely aliased, blocky signals, and thick semantic labels. Our proposed Local Restoration restores the signals and thins (or narrows down) the width of the labels. Our extensive experiments show that the TNN mechanism provides a plug-and-play memory-efficient pipeline, thereby enabling the effective estimation of real-sized (or precise) semantic labels for BEV map construction.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：On Mechanistic Knowledge Localization in Text-to-Image Generative Models</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01008">https://arxiv.org/abs/2405.01008</a></p>
  <p><b>作者</b>：Samyadeep Basu,  Keivan Rezaei,  Ryan Rossi,  Cherry Zhao,  Vlad Morariu,  Varun Manjunatha,  Soheil Feizi</p>
  <p><b>备注</b>：Appearing in ICML 2024</p>
  <p><b>关键词</b>：model editing, efficient model editing, facilitate efficient model, control visual attributes, Mechanistic Localization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying layers within text-to-image models which control visual attributes can facilitate efficient model editing through closed-form updates. Recent work, leveraging causal tracing show that early Stable-Diffusion variants confine knowledge primarily to the first layer of the CLIP text-encoder, while it diffuses throughout the UNet.Extending this framework, we observe that for recent models (e.g., SD-XL, DeepFloyd), causal tracing fails in pinpointing localized knowledge, highlighting challenges in model editing. To address this issue, we introduce the concept of Mechanistic Localization in text-to-image models, where knowledge about various visual attributes (e.g., ``style", ``objects", ``facts") can be mechanistically localized to a small fraction of layers in the UNet, thus facilitating efficient model editing. We localize knowledge using our method LocoGen which measures the direct effect of intermediate layers to output generation by performing interventions in the cross-attention layers of the UNet. We then employ LocoEdit, a fast closed-form editing method across popular open-source text-to-image models (including the latest SD-XL)and explore the possibilities of neuron-level model editing. Using Mechanistic Localization, our work offers a better view of successes and failures in localization-based text-to-image model editing. Code will be available at \href{this https URL}{this https URL}.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Deep Learning Models in Speech Recognition: Measuring GPU Energy  Consumption, Impact of Noise and Model Quantization for Edge Deployment</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01004">https://arxiv.org/abs/2405.01004</a></p>
  <p><b>作者</b>：Aditya Chakravarty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved word-error rates, surpassing human annotator, extensive server resources, significant carbon footprints, Recent transformer-based ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent transformer-based ASR models have achieved word-error rates (WER) below 4%, surpassing human annotator accuracy, yet they demand extensive server resources, contributing to significant carbon footprints. The traditional server-based architecture of ASR also presents privacy concerns, alongside reliability and latency issues due to network dependencies. In contrast, on-device (edge) ASR enhances privacy, boosts performance, and promotes sustainability by effectively balancing energy use and accuracy for specific applications. This study examines the effects of quantization, memory demands, and energy consumption on the performance of various ASR model inference on the NVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models using FP32, FP16, and INT8 quantization on clean and noisy datasets, we highlight the crucial trade-offs between accuracy, speeds, quantization, energy efficiency, and memory needs. We found that changing precision from fp32 to fp16 halves the energy consumption for audio transcription across different models, with minimal performance degradation. A larger model size and number of parameters neither guarantees better resilience to noise, nor predicts the energy consumption for a given transcription load. These, along with several other findings offer novel insights for optimizing ASR systems within energy- and memory-limited environments, crucial for the development of efficient on-device ASR solutions. The code and input data needed to reproduce the results in this article are open sourced are available on [this https URL].</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Spider: A Unified Framework for Context-dependent Concept Understanding</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01002">https://arxiv.org/abs/2405.01002</a></p>
  <p><b>作者</b>：Xiaoqi Zhao,  Youwei Pang,  Wei Ji,  Baicheng Sheng,  Jiaming Zuo,  Lihe Zhang,  Huchuan Lu</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：visual understanding ability, higher visual understanding, require higher visual, concepts require higher, higher visual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Different from the context-independent (CI) concepts such as human, car, and airplane, context-dependent (CD) concepts require higher visual understanding ability, such as camouflaged object and medical lesion. Despite the rapid advance of many CD understanding tasks in respective branches, the isolated evolution leads to their limited cross-domain generalisation and repetitive technique innovation. Since there is a strong coupling relationship between foreground and background context in CD tasks, existing methods require to train separate models in their focused domains. This restricts their real-world CD concept understanding towards artificial general intelligence (AGI). We propose a unified model with a single set of parameters, Spider, which only needs to be trained once. With the help of the proposed concept filter driven by the image-mask group prompt, Spider is able to understand and distinguish diverse strong context-dependent concepts to accurately capture the Prompter's intention. Without bells and whistles, Spider significantly outperforms the state-of-the-art specialized models in 8 different context-dependent segmentation tasks, including 4 natural scenes (salient, camouflaged, and transparent objects and shadow) and 4 medical lesions (COVID-19, polyp, breast, and skin lesion with color colonoscopy, CT, ultrasound, and dermoscopy modalities). Besides, Spider shows obvious advantages in continuous learning. It can easily complete the training of new tasks by fine-tuning parameters less than 1\% and bring a tolerable performance degradation of less than 5\% for all old tasks. The source code will be publicly available at \href{this https URL}{Spider-UniCDSeg}.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Part-aware Shape Generation with Latent 3D Diffusion of Neural Voxel  Fields</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00998">https://arxiv.org/abs/2405.00998</a></p>
  <p><b>作者</b>：Yuhang Huang,  SHilong Zou,  Xinwang Liu,  Kai Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural voxel fields, voxel fields, accurate part-aware structures, aiming to achieve, achieve accurate part-aware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel latent 3D diffusion model for the generation of neural voxel fields, aiming to achieve accurate part-aware structures. Compared to existing methods, there are two key designs to ensure high-quality and accurate part-aware generation. On one hand, we introduce a latent 3D diffusion process for neural voxel fields, enabling generation at significantly higher resolutions that can accurately capture rich textural and geometric details. On the other hand, a part-aware shape decoder is introduced to integrate the part codes into the neural voxel fields, guiding the accurate part decomposition and producing high-quality rendering results. Through extensive experimentation and comparisons with state-of-the-art methods, we evaluate our approach across four different classes of data. The results demonstrate the superior generative capabilities of our proposed method in part-aware shape generation, outperforming existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Estimate the building height at a 10-meter resolution based on Sentinel  data</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00989">https://arxiv.org/abs/2405.00989</a></p>
  <p><b>作者</b>：Xin Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Building height, Building, Shapley Additive Explanations, high-resolution building height, height</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building height is an important indicator for scientific research and practical application. However, building height products with a high spatial resolution (10m) are still very scarce. To meet the needs of high-resolution building height estimation models, this study established a set of spatial-spectral-temporal feature databases, combining SAR data provided by Sentinel-1, optical data provided by Sentinel-2, and shape data provided by building footprints. The statistical indicators on the time scale are extracted to form a rich database of 160 features. This study combined with permutation feature importance, Shapley Additive Explanations, and Random Forest variable importance, and the final stable features are obtained through an expert scoring system. This study took 12 large, medium, and small cities in the United States as the training data. It used moving windows to aggregate the pixels to solve the impact of SAR image displacement and building shadows. This study built a building height model based on a random forest model and compared three model ensemble methods of bagging, boosting, and stacking. To evaluate the accuracy of the prediction results, this study collected Lidar data in the test area, and the evaluation results showed that its R-Square reached 0.78, which can prove that the building height can be obtained effectively. The fast production of high-resolution building height data can support large-scale scientific research and application in many fields.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：FREE: Faster and Better Data-Free Meta-Learning</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00984">https://arxiv.org/abs/2405.00984</a></p>
  <p><b>作者</b>：Yongxian Wei,  Zixuan Hu,  Zhenyi Wang,  Li Shen,  Chun Yuan,  Dacheng Tao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：presenting practical benefits, data privacy concerns, pre-trained models, aims to extract, presenting practical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-Free Meta-Learning (DFML) aims to extract knowledge from a collection of pre-trained models without requiring the original data, presenting practical benefits in contexts constrained by data privacy concerns. Current DFML methods primarily focus on the data recovery from these pre-trained models. However, they suffer from slow recovery speed and overlook gaps inherent in heterogeneous pre-trained models. In response to these challenges, we introduce the Faster and Better Data-Free Meta-Learning (FREE) framework, which contains: (i) a meta-generator for rapidly recovering training tasks from pre-trained models; and (ii) a meta-learner for generalizing to new unseen tasks. Specifically, within the module Faster Inversion via Meta-Generator, each pre-trained model is perceived as a distinct task. The meta-generator can rapidly adapt to a specific task in just five steps, significantly accelerating the data recovery. Furthermore, we propose Better Generalization via Meta-Learner and introduce an implicit gradient alignment algorithm to optimize the meta-learner. This is achieved as aligned gradient directions alleviate potential conflicts among tasks from heterogeneous pre-trained models. Empirical experiments on multiple benchmarks affirm the superiority of our approach, marking a notable speed-up (20$\times$) and performance enhancement (1.42\% $\sim$ 4.78\%) in comparison to the state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：LLM-AD: Large Language Model based Audio Description System</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00983">https://arxiv.org/abs/2405.00983</a></p>
  <p><b>作者</b>：Peng Chu,  Jiang Wang,  Andre Abrantes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Audio Description, pivotal step forward, making video content, development of Audio, accessible and inclusive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of Audio Description (AD) has been a pivotal step forward in making video content more accessible and inclusive. Traditionally, AD production has demanded a considerable amount of skilled labor, while existing automated approaches still necessitate extensive training to integrate multimodal inputs and tailor the output from a captioning style to an AD style. In this paper, we introduce an automated AD generation pipeline that harnesses the potent multimodal and instruction-following capacities of GPT-4V(ision). Notably, our methodology employs readily available components, eliminating the need for additional training. It produces ADs that not only comply with established natural language AD production standards but also maintain contextually consistent character information across frames, courtesy of a tracking-based character recognition module. A thorough analysis on the MAD dataset reveals that our approach achieves a performance on par with learning-based methods in automated AD production, as substantiated by a CIDEr score of 20.5.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00980">https://arxiv.org/abs/2405.00980</a></p>
  <p><b>作者</b>：Zhe Niu,  Ronglai Zuo,  Brian Mak,  Fangyun Wei</p>
  <p><b>备注</b>：Accepted by LREC-COLING 2024</p>
  <p><b>关键词</b>：Hong Kong sign, Hong Kong, Kong sign language, Kong sign, sign language recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL) dataset collected from a TV news program over a period of 7 months. The dataset is collected to enrich resources for HKSL and support research in large-vocabulary continuous sign language recognition (SLR) and translation (SLT). It consists of 16.07 hours of sign videos of two signers with a vocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K Chinese words (for SLT). One signer has 11.66 hours of sign videos and the other has 4.41 hours. One objective in building the dataset is to support the investigation of how well large-vocabulary continuous sign language recognition/translation can be done for a single signer given a (relatively) large amount of his/her training data, which could potentially lead to the development of new modeling methods. Besides, most parts of the data collection pipeline are automated with little human intervention; we believe that our collection method can be scaled up to collect more sign language data easily for SLT in the future for any sign languages if such sign-interpreted videos are available. We also run a SOTA SLR/SLT model on the dataset and get a baseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58 for benchmarking future research on the dataset.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：FITA: Fine-grained Image-Text Aligner for Radiology Report Generation</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00962">https://arxiv.org/abs/2405.00962</a></p>
  <p><b>作者</b>：Honglong Yang,  Hui Tang,  Xiaomeng Li</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：Radiology report generation, reports alongside radiology, coherent descriptive reports, descriptive reports alongside, automatically generate detailed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Radiology report generation aims to automatically generate detailed and coherent descriptive reports alongside radiology images. Previous work mainly focused on refining fine-grained image features or leveraging external knowledge. However, the precise alignment of fine-grained image features with corresponding text descriptions has not been considered. This paper presents a novel method called Fine-grained Image-Text Aligner (FITA) to construct fine-grained alignment for image and text features. It has three novel designs: Image Feature Refiner (IFR), Text Feature Refiner (TFR) and Contrastive Aligner (CA). IFR and TFR aim to learn fine-grained image and text features, respectively. We achieve this by leveraging saliency maps to effectively fuse symptoms with corresponding abnormal visual regions, and by utilizing a meticulously constructed triplet set for training. Finally, CA module aligns fine-grained image and text features using contrastive loss for precise alignment. Results show that our method surpasses existing methods on the widely used benchmark</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Efficient Data-driven Scene Simulation using Robotic Surgery Videos via  Physics-embedded 3D Gaussians</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00956">https://arxiv.org/abs/2405.00956</a></p>
  <p><b>作者</b>：Zhenya Yang,  Kai Chen,  Yonghao Long,  Qi Dou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Surgical, plays a crucial, crucial role, scene simulation plays, Surgical scene</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surgical scene simulation plays a crucial role in surgical education and simulator-based robot learning. Traditional approaches for creating these environments with surgical scene involve a labor-intensive process where designers hand-craft tissues models with textures and geometries for soft body simulations. This manual approach is not only time-consuming but also limited in the scalability and realism. In contrast, data-driven simulation offers a compelling alternative. It has the potential to automatically reconstruct 3D surgical scenes from real-world surgical video data, followed by the application of soft body physics. This area, however, is relatively uncharted. In our research, we introduce 3D Gaussian as a learnable representation for surgical scene, which is learned from stereo endoscopic video. To prevent over-fitting and ensure the geometrical correctness of these scenes, we incorporate depth supervision and anisotropy regularization into the Gaussian learning process. Furthermore, we apply the Material Point Method, which is integrated with physical properties, to the 3D Gaussians to achieve realistic scene deformations. Our method was evaluated on our collected in-house and public surgical videos datasets. Results show that it can reconstruct and simulate surgical scenes from endoscopic videos efficiently-taking only a few minutes to reconstruct the surgical scene-and produce both visually and physically plausible deformations at a speed approaching real-time. The results demonstrate great potential of our proposed method to enhance the efficiency and variety of simulations available for surgical education and robot learning.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：X-Oscar: A Progressive Framework for High-quality Text-guided 3D  Animatable Avatar Generation</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00954">https://arxiv.org/abs/2405.00954</a></p>
  <p><b>作者</b>：Yiwei Ma,  Zhekai Lin,  Jiayi Ji,  Yijun Fan,  Xiaoshuai Sun,  Rongrong Ji</p>
  <p><b>备注</b>：ICML2024</p>
  <p><b>关键词</b>：made significant progress, Recent advancements, advancements in automatic, significant progress, made significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in automatic 3D avatar generation guided by text have made significant progress. However, existing methods have limitations such as oversaturation and low-quality output. To address these challenges, we propose X-Oscar, a progressive framework for generating high-quality animatable avatars from text prompts. It follows a sequential Geometry->Texture->Animation paradigm, simplifying optimization through step-by-step generation. To tackle oversaturation, we introduce Adaptive Variational Parameter (AVP), representing avatars as an adaptive distribution during training. Additionally, we present Avatar-aware Score Distillation Sampling (ASDS), a novel technique that incorporates avatar-aware noise into rendered images for improved generation quality during optimization. Extensive evaluations confirm the superiority of X-Oscar over existing text-to-3D and text-to-avatar approaches. Our anonymous project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Hyperspectral Band Selection based on Generalized 3DTV and Tensor CUR  Decomposition</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00951">https://arxiv.org/abs/2405.00951</a></p>
  <p><b>作者</b>：Katherine Henneberger,  Jing Qin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remote sensing, Hyperspectral Imaging, HSI, Imaging, Band selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral Imaging (HSI) serves as an important technique in remote sensing. However, high dimensionality and data volume typically pose significant computational challenges. Band selection is essential for reducing spectral redundancy in hyperspectral imagery while retaining intrinsic critical information. In this work, we propose a novel hyperspectral band selection model by decomposing the data into a low-rank and smooth component and a sparse one. In particular, we develop a generalized 3D total variation (G3DTV) by applying the $\ell_1^p$-norm to derivatives to preserve spatial-spectral smoothness. By employing the alternating direction method of multipliers (ADMM), we derive an efficient algorithm, where the tensor low-rankness is implied by the tensor CUR decomposition. We demonstrate the effectiveness of the proposed approach through comparisons with various other state-of-the-art band selection techniques using two benchmark real-world datasets. In addition, we provide practical guidelines for parameter selection in both noise-free and noisy scenarios.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content  Understanding Abilities Of LLMs</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00942">https://arxiv.org/abs/2405.00942</a></p>
  <p><b>作者</b>：Somesh Singh,  Harini S I,  Yaman K Singla,  Veeky Baths,  Rajiv Ratn Shah,  Changyou Chen,  Balaji Krishnamurthy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：communicator generates downstream, Communication is defined, Receiver behavior, generates downstream receiver, communicator generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication is defined as ``Who says what to whom with what effect.'' A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior data is often ignored while training large language models. We show that training LLMs on receiver behavior can actually help improve their content-understanding abilities. Specifically, we show that training LLMs to predict the receiver behavior of likes and comments improves the LLM's performance on a wide variety of downstream content understanding tasks. We show this performance increase over 40 video and image understanding tasks over 23 benchmark datasets across both 0-shot and fine-tuning settings, outperforming many supervised baselines. Moreover, since receiver behavior, such as likes and comments, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free-lunch. We release the receiver behavior cleaned comments and likes of 750k images and videos collected from multiple platforms along with our instruction-tuning data.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：EchoScene: Indoor Scene Generation via Information Echo over Scene Graph  Diffusion</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00915">https://arxiv.org/abs/2405.00915</a></p>
  <p><b>作者</b>：Guangyao Zhai,  Evin Pınar Örnek,  Dave Zhenyu Chen,  Ruotong Liao,  Yan Di,  Nassir Navab,  Federico Tombari,  Benjamin Busam</p>
  <p><b>备注</b>：25 pages. 10 figures</p>
  <p><b>关键词</b>：controllable generative model, scene, present EchoScene, scene graphs, controllable generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present EchoScene, an interactive and controllable generative model that generates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch diffusion model that dynamically adapts to scene graphs. Existing methods struggle to handle scene graphs due to varying numbers of nodes, multiple edge combinations, and manipulator-induced node-edge operations. EchoScene overcomes this by associating each node with a denoising process and enables collaborative information exchange, enhancing controllable and consistent generation aware of global constraints. This is achieved through an information echo scheme in both shape and layout branches. At every denoising step, all processes share their denoising data with an information exchange unit that combines these updates using graph convolution. The scheme ensures that the denoising processes are influenced by a holistic understanding of the scene graph, facilitating the generation of globally coherent scenes. The resulting scenes can be manipulated during inference by editing the input scene graph and sampling the noise in the diffusion model. Extensive experiments validate our approach, which maintains scene controllability and surpasses previous methods in generation fidelity. Moreover, the generated scenes are of high quality and thus directly compatible with off-the-shelf texture generation. Code and trained models are open-sourced.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Transformer-Based Self-Supervised Learning for Histopathological  Classification of Ischemic Stroke Clot Origin</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00908">https://arxiv.org/abs/2405.00908</a></p>
  <p><b>作者</b>：K. Yeh,  M. S. Jabal,  V. Gupta,  D. F. Kallmes,  W. Brinjikji,  B. S. Erdal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Background and Purpose, ischemic stroke, ischemic stroke clot, thromboembolism source, crucial for treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background and Purpose: Identifying the thromboembolism source in ischemic stroke is crucial for treatment and secondary prevention yet is often undetermined. This study describes a self-supervised deep learning approach in digital pathology of emboli for classifying ischemic stroke clot origin from histopathological images. Methods: The dataset included whole slide images (WSI) from the STRIP AI Kaggle challenge, consisting of retrieved clots from ischemic stroke patients following mechanical thrombectomy. Transformer-based deep learning models were developed using transfer learning and self-supervised pretraining for classifying WSI. Customizations included an attention pooling layer, weighted loss function, and threshold optimization. Various model architectures were tested and compared, and model performances were primarily evaluated using weighted logarithmic loss. Results: The model achieved a logloss score of 0.662 in cross-validation and 0.659 on the test set. Different model backbones were compared, with the swin_large_patch4_window12_384 showed higher performance. Thresholding techniques for clot origin classification were employed to balance false positives and negatives. Conclusion: The study demonstrates the extent of efficacy of transformer-based deep learning models in identifying ischemic stroke clot origins from histopathological images and emphasizes the need for refined modeling techniques specifically adapted to thrombi WSI. Further research is needed to improve model performance, interpretability, validate its effectiveness. Future enhancement could include integrating larger patient cohorts, advanced preprocessing strategies, and exploring ensemble multimodal methods for enhanced diagnostic accuracy.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data  Lottery Tickets</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00906">https://arxiv.org/abs/2405.00906</a></p>
  <p><b>作者</b>：Ojasw Upadhyay</p>
  <p><b>备注</b>：3 pages, 5 figures</p>
  <p><b>关键词</b>：demands present challenges, revolutionized computer vision, vision transformer training, computational demands present, vision transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformers have revolutionized computer vision, but their computational demands present challenges for training and deployment. This paper introduces LOTUS (LOttery Transformers with Ultra Sparsity), a novel method that leverages data lottery ticket selection and sparsity pruning to accelerate vision transformer training while maintaining accuracy. Our approach focuses on identifying and utilizing the most informative data subsets and eliminating redundant model parameters to optimize the training process. Through extensive experiments, we demonstrate the effectiveness of LOTUS in achieving rapid convergence and high accuracy with significantly reduced computational requirements. This work highlights the potential of combining data selection and sparsity techniques for efficient vision transformer training, opening doors for further research and development in this area.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：DiL-NeRF: Delving into Lidar for Neural Radiance Field on Street Scenes</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00900">https://arxiv.org/abs/2405.00900</a></p>
  <p><b>作者</b>：Shanlin Sun,  Bingbing Zhuang,  Ziyu Jiang,  Buyu Liu,  Xiaohui Xie,  Manmohan Chandraker</p>
  <p><b>备注</b>：CVPR2024 Highlights</p>
  <p><b>关键词</b>：Photorealistic simulation plays, neural radiance fields, Photorealistic simulation, creation of digital, simulation plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Photorealistic simulation plays a crucial role in applications such as autonomous driving, where advances in neural radiance fields (NeRFs) may allow better scalability through the automatic creation of digital 3D assets. However, reconstruction quality suffers on street scenes due to largely collinear camera motions and sparser samplings at higher speeds. On the other hand, the application often demands rendering from camera views that deviate from the inputs to accurately simulate behaviors like lane changes. In this paper, we propose several insights that allow a better utilization of Lidar data to improve NeRF quality on street scenes. First, our framework learns a geometric scene representation from Lidar, which is fused with the implicit grid-based representation for radiance decoding, thereby supplying stronger geometric information offered by explicit point cloud. Second, we put forth a robust occlusion-aware depth supervision scheme, which allows utilizing densified Lidar points by accumulation. Third, we generate augmented training views from Lidar points for further improvement. Our insights translate to largely improved novel view synthesis under real driving scenes.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Wake Vision: A Large-scale, Diverse Dataset and Benchmark Suite for  TinyML Person Detection</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00892">https://arxiv.org/abs/2405.00892</a></p>
  <p><b>作者</b>：Colby Banbury,  Emil Njor,  Matthew Stewart,  Pete Warden,  Manjunath Kudlur,  Nat Jeffries,  Xenofon Fafoutis,  Vijay Janapa Reddi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine learning applications, tiny machine learning, extremely low-power devices, Machine learning, Wake Vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning applications on extremely low-power devices, commonly referred to as tiny machine learning (TinyML), promises a smarter and more connected world. However, the advancement of current TinyML research is hindered by the limited size and quality of pertinent datasets. To address this challenge, we introduce Wake Vision, a large-scale, diverse dataset tailored for person detection -- the canonical task for TinyML visual sensing. Wake Vision comprises over 6 million images, which is a hundredfold increase compared to the previous standard, and has undergone thorough quality filtering. Using Wake Vision for training results in a 2.41\% increase in accuracy compared to the established benchmark. Alongside the dataset, we provide a collection of five detailed benchmark sets that assess model performance on specific segments of the test data, such as varying lighting conditions, distances from the camera, and demographic characteristics of subjects. These novel fine-grained benchmarks facilitate the evaluation of model quality in challenging real-world scenarios that are often ignored when focusing solely on overall accuracy. Through an evaluation of a MobileNetV2 TinyML model on the benchmarks, we show that the input resolution plays a more crucial role than the model width in detecting distant subjects and that the impact of quantization on model robustness is minimal, thanks to the dataset quality. These findings underscore the importance of a detailed evaluation to identify essential factors for model development. The dataset, benchmark suite, code, and models are publicly available under the CC-BY 4.0 license, enabling their use for commercial use cases.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：SonicDiffusion: Audio-Driven Image Generation and Editing with  Pretrained Diffusion Models</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00878">https://arxiv.org/abs/2405.00878</a></p>
  <p><b>作者</b>：Burak Can Biner,  Farrin Marouf Sofian,  Umur Berkay Karakaş,  Duygu Ceylan,  Erkut Erdem,  Aykut Erdem</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conditional image synthesis, witnessing a revolution, revolution in conditional, image, audio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are witnessing a revolution in conditional image synthesis with the recent success of large scale text-to-image generation methods. This success also opens up new opportunities in controlling the generation and editing process using multi-modal input. While spatial control using cues such as depth, sketch, and other images has attracted a lot of research, we argue that another equally effective modality is audio since sound and sight are two main components of human perception. Hence, we propose a method to enable audio-conditioning in large scale image diffusion models. Our method first maps features obtained from audio clips to tokens that can be injected into the diffusion model in a fashion similar to text tokens. We introduce additional audio-image cross attention layers which we finetune while freezing the weights of the original layers of the diffusion model. In addition to audio conditioned image generation, our method can also be utilized in conjuction with diffusion based editing methods to enable audio conditioned image editing. We demonstrate our method on a wide range of audio and image datasets. We perform extensive comparisons with recent methods and show favorable performance.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Beyond Human Vision: The Role of Large Vision Language Models in  Microscope Image Analysis</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00876">https://arxiv.org/abs/2405.00876</a></p>
  <p><b>作者</b>：Prateek Verma,  Minh-Hao Van,  Xintao Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vision language models, Vision language, emerged and gained, gained the spotlight, dual modality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision language models (VLMs) have recently emerged and gained the spotlight for their ability to comprehend the dual modality of image and textual data. VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive performance on tasks such as natural image captioning, visual question answering (VQA), and spatial reasoning. Additionally, a universal segmentation model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance at isolating objects from unforeseen images. Since medical experts, biologists, and materials scientists routinely examine microscopy or medical images in conjunction with textual information in the form of captions, literature, or reports, and draw conclusions of great importance and merit, it is indubitably essential to test the performance of VLMs and foundation models such as SAM, on these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with classification, segmentation, counting, and VQA tasks on a variety of microscopy images. We observe that ChatGPT and Gemini are impressively able to comprehend the visual features in microscopy images, while SAM is quite capable at isolating artefacts in a general sense. However, the performance is not close to that of a domain expert - the models are readily encumbered by the introduction of impurities, defects, artefact overlaps and diversity present in the images.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Guided Conditional Diffusion Classifier (ConDiff) for Enhanced  Prediction of Infection in Diabetic Foot Ulcers</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00858">https://arxiv.org/abs/2405.00858</a></p>
  <p><b>作者</b>：Palawat Busaranuvong,  Emmanuel Agu,  Deepak Kumar,  Shefalika Gautam,  Reza Saadati Fard,  Bengisu Tulu,  Diane Strong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Diabetic Foot Ulcers, Foot Ulcers, Diabetic Foot, preventing severe complications, detect infected wounds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To detect infected wounds in Diabetic Foot Ulcers (DFUs) from photographs, preventing severe complications and amputations. Methods: This paper proposes the Guided Conditional Diffusion Classifier (ConDiff), a novel deep-learning infection detection model that combines guided image synthesis with a denoising diffusion model and distance-based classification. The process involves (1) generating guided conditional synthetic images by injecting Gaussian noise to a guide image, followed by denoising the noise-perturbed image through a reverse diffusion process, conditioned on infection status and (2) classifying infections based on the minimum Euclidean distance between synthesized images and the original guide image in embedding space. Results: ConDiff demonstrated superior performance with an accuracy of 83% and an F1-score of 0.858, outperforming state-of-the-art models by at least 3%. The use of a triplet loss function reduces overfitting in the distance-based classifier. Conclusions: ConDiff not only enhances diagnostic accuracy for DFU infections but also pioneers the use of generative discriminative models for detailed medical image analysis, offering a promising approach for improving patient outcomes.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Brighteye: Glaucoma Screening with Color Fundus Photographs based on  Vision Transformer</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00857">https://arxiv.org/abs/2405.00857</a></p>
  <p><b>作者</b>：Hui Lin,  Charilaos Apostolidis,  Aggelos K. Katsaggelos</p>
  <p><b>备注</b>：ISBI 2024, JustRAIGS challenge, glaucoma detection</p>
  <p><b>关键词</b>：patient demographics pose, color fundus photography, automated glaucoma detection, demographics pose challenges, lighting conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differences in image quality, lighting conditions, and patient demographics pose challenges to automated glaucoma detection from color fundus photography. Brighteye, a method based on Vision Transformer, is proposed for glaucoma detection and glaucomatous feature classification. Brighteye learns long-range relationships among pixels within large fundus images using a self-attention mechanism. Prior to being input into Brighteye, the optic disc is localized using YOLOv8, and the region of interest (ROI) around the disc center is cropped to ensure alignment with clinical practice. Optic disc detection improves the sensitivity at 95% specificity from 79.20% to 85.70% for glaucoma detection and the Hamming distance from 0.2470 to 0.1250 for glaucomatous feature classification. In the developmental stage of the Justified Referral in AI Glaucoma Screening (JustRAIGS) challenge, the overall outcome secured the fifth position out of 226 entries.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：ADM: Accelerated Diffusion Model via Estimated Priors for Robust Motion  Prediction under Uncertainties</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00797">https://arxiv.org/abs/2405.00797</a></p>
  <p><b>作者</b>：Jiahui Li,  Tianle Shen,  Zekai Gu,  Jiawei Sun,  Chengran Yuan,  Yuhang Han,  Shuo Sun,  Marcelo H. Ang Jr</p>
  <p><b>备注</b>：7 pages, 4 figures</p>
  <p><b>关键词</b>：comprehend stochastic dynamics, real-world agent interactions, challenging problem, demands the system, system to comprehend</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motion prediction is a challenging problem in autonomous driving as it demands the system to comprehend stochastic dynamics and the multi-modal nature of real-world agent interactions. Diffusion models have recently risen to prominence, and have proven particularly effective in pedestrian motion prediction tasks. However, the significant time consumption and sensitivity to noise have limited the real-time predictive capability of diffusion models. In response to these impediments, we propose a novel diffusion-based, acceleratable framework that adeptly predicts future trajectories of agents with enhanced resistance to noise. The core idea of our model is to learn a coarse-grained prior distribution of trajectory, which can skip a large number of denoise steps. This advancement not only boosts sampling efficiency but also maintains the fidelity of prediction accuracy. Our method meets the rigorous real-time operational standards essential for autonomous vehicles, enabling prompt trajectory generation that is vital for secure and efficient navigation. Through extensive experiments, our method speeds up the inference time to 136ms compared to standard diffusion model, and achieves significant improvement in multi-agent motion prediction on the Argoverse 1 motion forecasting dataset.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Coherent 3D Portrait Video Reconstruction via Triplane Fusion</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00794">https://arxiv.org/abs/2405.00794</a></p>
  <p><b>作者</b>：Shengze Wang,  Xueting Li,  Chao Liu,  Matthew Chan,  Michael Stengel,  Josef Spjut,  Henry Fuchs,  Shalini De Mello,  Koki Nagano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potentially democratizing telepresence, enabled telepresence systems, enabled telepresence, telepresence systems, democratizing telepresence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent breakthroughs in single-image 3D portrait reconstruction have enabled telepresence systems to stream 3D portrait videos from a single camera in real-time, potentially democratizing telepresence. However, per-frame 3D reconstruction exhibits temporal inconsistency and forgets the user's appearance. On the other hand, self-reenactment methods can render coherent 3D portraits by driving a personalized 3D prior, but fail to faithfully reconstruct the user's per-frame appearance (e.g., facial expressions and lighting). In this work, we recognize the need to maintain both coherent identity and dynamic per-frame appearance to enable the best possible realism. To this end, we propose a new fusion-based method that fuses a personalized 3D subject prior with per-frame information, producing temporally stable 3D videos with faithful reconstruction of the user's per-frame appearances. Trained only using synthetic data produced by an expression-conditioned 3D GAN, our encoder-based method achieves both state-of-the-art 3D reconstruction accuracy and temporal consistency on in-studio and in-the-wild datasets.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Obtaining Favorable Layouts for Multiple Object Generation</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00791">https://arxiv.org/abs/2405.00791</a></p>
  <p><b>作者</b>：Barak Battash,  Amit Rozner,  Lior Wolf,  Ofir Lindenbaum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown remarkable success, remarkable success, generate high-quality, high-quality and diverse, shown remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale text-to-image models that can generate high-quality and diverse images based on textual prompts have shown remarkable success. These models aim ultimately to create complex scenes, and addressing the challenge of multi-subject generation is a critical step towards this goal. However, the existing state-of-the-art diffusion models face difficulty when generating images that involve multiple subjects. When presented with a prompt containing more than one subject, these models may omit some subjects or merge them together. To address this challenge, we propose a novel approach based on a guiding principle. We allow the diffusion model to initially propose a layout, and then we rearrange the layout grid. This is achieved by enforcing cross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels from latent maps to new locations determined by us. We introduce new loss terms aimed at reducing XAM entropy for clearer spatial definition of subjects, reduce the overlap between XAMs, and ensure that XAMs align with their respective masks. We contrast our approach with several alternative methods and show that it more faithfully captures the desired concepts across a variety of text prompts.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00760">https://arxiv.org/abs/2405.00760</a></p>
  <p><b>作者</b>：Xiaoshi Wu,  Yiming Hao,  Manyuan Zhang,  Keqiang Sun,  Zhaoyang Huang,  Guanglu Song,  Yu Liu,  Hongsheng Li</p>
  <p><b>备注</b>：N/A</p>
  <p><b>关键词</b>：underexplored research area, Deep Reward Tuning, research area, important but underexplored, underexplored research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimizing a text-to-image diffusion model with a given reward function is an important but underexplored research area. In this study, we propose Deep Reward Tuning (DRTune), an algorithm that directly supervises the final output image of a text-to-image diffusion model and back-propagates through the iterative sampling process to the input noise. We find that training earlier steps in the sampling process is crucial for low-level rewards, and deep supervision can be achieved efficiently and effectively by stopping the gradient of the denoising network input. DRTune is extensively evaluated on various reward models. It consistently outperforms other algorithms, particularly for low-level control signals, where all shallow supervision methods fail. Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0) model via DRTune to optimize Human Preference Score v2.1, resulting in the Favorable Diffusion XL 1.0 (FDXL 1.0) model. FDXL 1.0 significantly enhances image quality compared to SDXL 1.0 and reaches comparable quality compared with Midjourney v5.2.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：CLIPArTT: Light-weight Adaptation of CLIP to New Domains at Test Time</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00754">https://arxiv.org/abs/2405.00754</a></p>
  <p><b>作者</b>：Gustavo Adolfo Vargas Hakim,  David Osowiechi,  Mehrdad Noori,  Milad Cheraghalikhani,  Ali Bahri,  Moslem Yazdanpanah,  Ismail Ben Ayed,  Christian Desrosiers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Pre-trained vision-language models, zero-shot classification tasks, Pre-trained vision-language, vision-language models, zero-shot classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained vision-language models (VLMs), exemplified by CLIP, demonstrate remarkable adaptability across zero-shot classification tasks without additional training. However, their performance diminishes in the presence of domain shifts. In this study, we introduce CLIP Adaptation duRing Test-Time (CLIPArTT), a fully test-time adaptation (TTA) approach for CLIP, which involves automatic text prompts construction during inference for their use as text supervision. Our method employs a unique, minimally invasive text prompt tuning process, wherein multiple predicted classes are aggregated into a single new text prompt, used as pseudo label to re-classify inputs in a transductive manner. Additionally, we pioneer the standardization of TTA benchmarks (e.g., TENT) in the realm of VLMs. Our findings demonstrate that, without requiring additional transformations nor new trainable modules, CLIPArTT enhances performance dynamically across non-corrupted datasets such as CIFAR-10, corrupted datasets like CIFAR-10-C and CIFAR-10.1, alongside synthetic datasets such as VisDA-C. This research underscores the potential for improving VLMs' adaptability through novel test-time strategies, offering insights for robust performance across varied datasets and environments. The code can be found at: this https URL</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：More is Better: Deep Domain Adaptation with Multiple Sources</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00749">https://arxiv.org/abs/2405.00749</a></p>
  <p><b>作者</b>：Sicheng Zhao,  Hui Chen,  Hu Huang,  Pengfei Xu,  Guiguang Ding</p>
  <p><b>备注</b>：Accepted by IJCAI 2024. arXiv admin note: text overlap with arXiv:2002.12169</p>
  <p><b>关键词</b>：obtain large-scale labeled, deep neural networks, neural networks, difficult and expensive, expensive to obtain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many practical applications, it is often difficult and expensive to obtain large-scale labeled data to train state-of-the-art deep neural networks. Therefore, transferring the learned knowledge from a separate, labeled source domain to an unlabeled or sparsely labeled target domain becomes an appealing alternative. However, direct transfer often results in significant performance decay due to domain shift. Domain adaptation (DA) aims to address this problem by aligning the distributions between the source and target domains. Multi-source domain adaptation (MDA) is a powerful and practical extension in which the labeled data may be collected from multiple sources with different distributions. In this survey, we first define various MDA strategies. Then we systematically summarize and compare modern MDA methods in the deep learning era from different perspectives, followed by commonly used datasets and a brief benchmark. Finally, we discuss future research directions for MDA that are worth investigating.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Modeling Caption Diversity in Contrastive Vision-Language Pretraining</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00740">https://arxiv.org/abs/2405.00740</a></p>
  <p><b>作者</b>：Samuel Lavoie,  Polina Kirichenko,  Mark Ibrahim,  Mahmoud Assran,  Andrew Gordon Wildon,  Aaron Courville,  Nicolas Ballas</p>
  <p><b>备注</b>：14 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：Language Image Pretraining, Latent Language Image, Contrastive Language Pretraining, Language Pretraining, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are a thousand ways to caption an image. Contrastive Language Pretraining (CLIP) on the other hand, works by mapping an image and its caption to a single vector -- limiting how well CLIP-like models can represent the diverse ways to describe an image. In this work, we introduce Llip, Latent Language Image Pretraining, which models the diversity of captions that could match an image. Llip's vision encoder outputs a set of visual features that are mixed into a final representation by conditioning on information derived from the text. We show that Llip outperforms non-contextualized baselines like CLIP and SigLIP on a variety of tasks even with large-scale encoders. Llip improves zero-shot classification by an average of 2.9% zero-shot classification benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by 1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by 6.0%. We provide a comprehensive analysis of the components introduced by the method and demonstrate that Llip leads to richer visual representations.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Why does Knowledge Distillation Work? Rethink its Attention and Fidelity  Mechanism</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00739">https://arxiv.org/abs/2405.00739</a></p>
  <p><b>作者</b>：Chenqi Guo,  Shiwei Zhong,  Xiaofeng Liu,  Qianli Feng,  Yinglong Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge Distillation, Distillation, knowledge transfer procedure, student, Knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Does Knowledge Distillation (KD) really work? Conventional wisdom viewed it as a knowledge transfer procedure where a perfect mimicry of the student to its teacher is desired. However, paradoxical studies indicate that closely replicating the teacher's behavior does not consistently improve student generalization, posing questions on its possible causes. Confronted with this gap, we hypothesize that diverse attentions in teachers contribute to better student generalization at the expense of reduced fidelity in ensemble KD setups. By increasing data augmentation strengths, our key findings reveal a decrease in the Intersection over Union (IoU) of attentions between teacher models, leading to reduced student overfitting and decreased fidelity. We propose this low-fidelity phenomenon as an underlying characteristic rather than a pathology when training KD. This suggests that stronger data augmentation fosters a broader perspective provided by the divergent teacher ensemble and lower student-teacher mutual information, benefiting generalization performance. These insights clarify the mechanism on low-fidelity phenomenon in KD. Thus, we offer new perspectives on optimizing student model performance, by emphasizing increased diversity in teacher attentions and reduced mimicry behavior between teachers and student.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Technical Report on BaumEvA Evolutionary Optimization Python-Library  Testing</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00686">https://arxiv.org/abs/2405.00686</a></p>
  <p><b>作者</b>：Vadim Tynchenko,  Aleksei Kudryavtsev,  Vladimir Nelyub,  Aleksei Borodulin,  Andrei Gantimurov</p>
  <p><b>备注</b>：The paper consists of 30 pages, 37 figures, 5 tables</p>
  <p><b>关键词</b>：Python library BaumEvA, including computer vision, optimal model architectures, test results Python, results Python library</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report presents the test results Python library BaumEvA, which implements evolutionary algorithms for optimizing various types of problems, including computer vision tasks accompanied by the search for optimal model architectures. Testing was carried out to evaluate the effectiveness and reliability of the pro-posed methods, as well as to determine their applicability in various fields. Dur-ing testing, various test functions and parameters of evolutionary algorithms were used, which made it possible to evaluate their performance in a wide range of conditions. Test results showed that the library provides effective and reliable methods for solving optimization problems. However, some limitations were identified related to computational resources and execution time of algorithms on problems with large dimensions. The report includes a detailed description of the tests performed, the results obtained and conclusions about the applicability of the genetic algorithm in various tasks. Recommendations for choosing algorithm pa-rameters and using the library to achieve the best results are also provided. The report may be useful to developers involved in the optimization of complex com-puting systems, as well as to researchers studying the possibilities of using evo-lutionary algorithms in various fields of science and technology.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：The active visual sensing methods for robotic welding: review, tutorial  and prospect</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00685">https://arxiv.org/abs/2405.00685</a></p>
  <p><b>作者</b>：ZhenZhou Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：active visual sensing, visual sensing methods, visual sensing, active visual, sensing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The visual sensing system is one of the most important parts of the welding robots to realize intelligent and autonomous welding. The active visual sensing methods have been widely adopted in robotic welding because of their higher accuracies compared to the passive visual sensing methods. In this paper, we give a comprehensive review of the active visual sensing methods for robotic welding. According to their uses, we divide the state-of-the-art active visual sensing methods into four categories: seam tracking, weld bead defect detection, 3D weld pool geometry measurement and welding path planning. Firstly, we review the principles of these active visual sensing methods. Then, we give a tutorial of the 3D calibration methods for the active visual sensing systems used in intelligent welding robots to fill the gaps in the related fields. At last, we compare the reviewed active visual sensing methods and give the prospects based on their advantages and disadvantages.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：PAM-UNet: Shifting Attention on Region of Interest in Medical Images</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01503">https://arxiv.org/abs/2405.01503</a></p>
  <p><b>作者</b>：Abhijit Das,  Debesh Jha,  Vandan Gorade,  Koushik Biswas,  Hongyi Pan,  Zheyuan Zhang,  Daniela P. Ladner,  Yury Velichko,  Amir Borhani,  Ulas Bagci</p>
  <p><b>备注</b>：Accepted at 2024 IEEE EMBC</p>
  <p><b>关键词</b>：improving diagnostic outcomes, assist medical personnel, Computer-aided segmentation methods, diagnostic outcomes, underline</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computer-aided segmentation methods can assist medical personnel in improving diagnostic outcomes. While recent advancements like UNet and its variants have shown promise, they face a critical challenge: balancing accuracy with computational efficiency. Shallow encoder architectures in UNets often struggle to capture crucial spatial features, leading in inaccurate and sparse segmentation. To address this limitation, we propose a novel \underline{P}rogressive \underline{A}ttention based \underline{M}obile \underline{UNet} (\underline{PAM-UNet}) architecture. The inverted residual (IR) blocks in PAM-UNet help maintain a lightweight framework, while layerwise \textit{Progressive Luong Attention} ($\mathcal{PLA}$) promotes precise segmentation by directing attention toward regions of interest during synthesis. Our approach prioritizes both accuracy and speed, achieving a commendable balance with a mean IoU of 74.65 and a dice score of 82.87, while requiring only 1.32 floating-point operations per second (FLOPS) on the Liver Tumor Segmentation Benchmark (LiTS) 2017 dataset. These results highlight the importance of developing efficient segmentation models to accelerate the adoption of AI in clinical practice.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Investigating Self-Supervised Image Denoising with Denaturation</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01124">https://arxiv.org/abs/2405.01124</a></p>
  <p><b>作者</b>：Hiroki Waida,  Kimihiro Yamazaki,  Atsushi Tokuhisa,  Mutsuyo Wada,  Yuichiro Wada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, denatured data, noisy data, crucial approach, Self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning for image denoising problems in the presence of denaturation for noisy data is a crucial approach in machine learning. However, theoretical understanding of the performance of the approach that uses denatured data is lacking. To provide better understanding of the approach, in this paper, we analyze a self-supervised denoising algorithm that uses denatured data in depth through theoretical analysis and numerical experiments. Through the theoretical analysis, we discuss that the algorithm finds desired solutions to the optimization problem with the population risk, while the guarantee for the empirical risk depends on the hardness of the denoising task in terms of denaturation levels. We also conduct several experiments to investigate the performance of an extended algorithm in practice. The results indicate that the algorithm training with denatured images works, and the empirical performance aligns with the theoretical results. These results suggest several insights for further improvement of self-supervised image denoising that uses denatured data in future directions.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Correcting Biased Centered Kernel Alignment Measures in Biological and  Artificial Neural Networks</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01012">https://arxiv.org/abs/2405.01012</a></p>
  <p><b>作者</b>：Alex Murphy,  Joel Zylberberg,  Alona Fyshe</p>
  <p><b>备注</b>：ICLR 2024 Re-Align Workshop</p>
  <p><b>关键词</b>：Centred Kernel Alignment, Centred Kernel, artificial neural networks, biased CKA, CKA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Centred Kernel Alignment (CKA) has recently emerged as a popular metric to compare activations from biological and artificial neural networks (ANNs) in order to quantify the alignment between internal representations derived from stimuli sets (e.g. images, text, video) that are presented to both systems. In this paper we highlight issues that the community should take into account if using CKA as an alignment metric with neural data. Neural data are in the low-data high-dimensionality domain, which is one of the cases where (biased) CKA results in high similarity scores even for pairs of random matrices. Using fMRI and MEG data from the THINGS project, we show that if biased CKA is applied to representations of different sizes in the low-data high-dimensionality domain, they are not directly comparable due to biased CKA's sensitivity to differing feature-sample ratios and not stimuli-driven responses. This situation can arise both when comparing a pre-selected area of interest (e.g. ROI) to multiple ANN layers, as well as when determining to which ANN layer multiple regions of interest (ROIs) / sensor groups of different dimensionality are most similar. We show that biased CKA can be artificially driven to its maximum value when using independent random data of different sample-feature ratios. We further show that shuffling sample-feature pairs of real neural data does not drastically alter biased CKA similarity in comparison to unshuffled data, indicating an undesirable lack of sensitivity to stimuli-driven neural responses. Positive alignment of true stimuli-driven responses is only achieved by using debiased CKA. Lastly, we report findings that suggest biased CKA is sensitive to the inherent structure of neural data, only differing from shuffled data when debiased CKA detects stimuli-driven alignment.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：SynthBrainGrow: Synthetic Diffusion Brain Aging for Longitudinal MRI  Data Generation in Young People</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00682">https://arxiv.org/abs/2405.00682</a></p>
  <p><b>作者</b>：Anna Zapaishchykova,  Benjamin H. Kann,  Divyanshu Tak,  Zezhong Ye,  Daphne A. Haas-Kogan,  Hugo J.W.L. Aerts</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：neurodegenerative conditions, efficient research, research on neurodevelopmental, neurodevelopmental and neurodegenerative, brain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthetic longitudinal brain MRI simulates brain aging and would enable more efficient research on neurodevelopmental and neurodegenerative conditions. Synthetically generated, age-adjusted brain images could serve as valuable alternatives to costly longitudinal imaging acquisitions, serve as internal controls for studies looking at the effects of environmental or therapeutic modifiers on brain development, and allow data augmentation for diverse populations. In this paper, we present a diffusion-based approach called SynthBrainGrow for synthetic brain aging with a two-year step. To validate the feasibility of using synthetically-generated data on downstream tasks, we compared structural volumetrics of two-year-aged brains against synthetically-aged brain MRI. Results show that SynthBrainGrow can accurately capture substructure volumetrics and simulate structural changes such as ventricle enlargement and cortical thinning. Our approach provides a novel way to generate longitudinal brain datasets from cross-sectional data to enable augmented training and benchmarking of computational tools for analyzing lifespan trajectories. This work signifies an important advance in generative modeling to synthesize realistic longitudinal data with limited lifelong MRI scans. The code is available at XXX.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Multi-Space Alignments Towards Universal LiDAR Segmentation</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01538">https://arxiv.org/abs/2405.01538</a></p>
  <p><b>作者</b>：Youquan Liu,  Lingdong Kong,  Xiaoyang Wu,  Runnan Chen,  Xin Li,  Liang Pan,  Ziwei Liu,  Yuexin Ma</p>
  <p><b>备注</b>：CVPR 2024; 33 pages, 14 figures, 14 tables; Code at this https URL</p>
  <p><b>关键词</b>：autonomous driving perception, safe autonomous driving, versatile LiDAR segmentation, LiDAR segmentation, unified and versatile</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A unified and versatile LiDAR segmentation model with strong robustness and generalizability is desirable for safe autonomous driving perception. This work presents M3Net, a one-of-a-kind framework for fulfilling multi-task, multi-dataset, multi-modality LiDAR segmentation in a universal manner using just a single set of parameters. To better exploit data volume and diversity, we first combine large-scale driving datasets acquired by different types of sensors from diverse scenes and then conduct alignments in three spaces, namely data, feature, and label spaces, during the training. As a result, M3Net is capable of taming heterogeneous data for training state-of-the-art LiDAR segmentation models. Extensive experiments on twelve LiDAR segmentation datasets verify our effectiveness. Notably, using a shared set of parameters, M3Net achieves 75.1%, 83.1%, and 72.4% mIoU scores, respectively, on the official benchmarks of SemanticKITTI, nuScenes, and Waymo Open.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Customizing Text-to-Image Models with a Single Image Pair</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01536">https://arxiv.org/abs/2405.01536</a></p>
  <p><b>作者</b>：Maxwell Jones,  Sheng-Yu Wang,  Nupur Kumari,  David Bau,  Jun-Yan Zhu</p>
  <p><b>备注</b>：project page: this https URL</p>
  <p><b>关键词</b>：single image pair, Art reinterpretation, reference work, image pair, stylistic difference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Art reinterpretation is the practice of creating a variation of a reference work, making a paired artwork that exhibits a distinct artistic style. We ask if such an image pair can be used to customize a generative model to capture the demonstrated stylistic difference. We propose Pair Customization, a new customization method that learns stylistic difference from a single image pair and then applies the acquired style to the generation process. Unlike existing methods that learn to mimic a single concept from a collection of images, our method captures the stylistic difference between paired images. This allows us to apply a stylistic change without overfitting to the specific image content in the examples. To address this new task, we employ a joint optimization method that explicitly separates the style and content into distinct LoRA weight spaces. We optimize these style and content weights to reproduce the style and content images while encouraging their orthogonality. During inference, we modify the diffusion process via a new style guidance based on our learned weights. Both qualitative and quantitative experiments show that our method can effectively learn style while avoiding overfitting to image content, highlighting the potential of modeling such stylistic differences from a single image pair.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon  Robotics Tasks</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01534">https://arxiv.org/abs/2405.01534</a></p>
  <p><b>作者</b>：Murtaza Dalal,  Tarun Chiruvolu,  Devendra Chaplot,  Ruslan Salakhutdinov</p>
  <p><b>备注</b>：Published at ICLR 2024. Website at this https URL 9 pages, 3 figures, 3 tables; 14 pages appendix (7 additional figures)</p>
  <p><b>关键词</b>：Large Language Models, existing methods require, methods require access, pre-defined skill library, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have been shown to be capable of performing high-level planning for long-horizon robotics tasks, yet existing methods require access to a pre-defined skill library (e.g. picking, placing, pulling, pushing, navigating). However, LLM planning does not address how to design or learn those behaviors, which remains challenging particularly in long-horizon settings. Furthermore, for many tasks of interest, the robot needs to be able to adjust its behavior in a fine-grained manner, requiring the agent to be capable of modifying low-level control actions. Can we instead use the internet-scale knowledge from LLMs for high-level policies, guiding reinforcement learning (RL) policies to efficiently solve robotic control tasks online without requiring a pre-determined set of skills? In this paper, we propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to bridge the gap between abstract language and learned low-level control for solving long-horizon robotics tasks from scratch. We demonstrate that PSL achieves state-of-the-art results on over 25 challenging robotics tasks with up to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four benchmarks at success rates of over 85%, out-performing language-based, classical, and end-to-end approaches. Video results and code at this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Improving Intervention Efficacy via Concept Realignment in Concept  Bottleneck Models</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01531">https://arxiv.org/abs/2405.01531</a></p>
  <p><b>作者</b>：Nishad Singhi,  Jae Myung Kim,  Karsten Roth,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Concept Bottleneck Models, Bottleneck Models, Concept Bottleneck, interpretable model decisions, ground image classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept Bottleneck Models (CBMs) ground image classification on human-understandable concepts to allow for interpretable model decisions. Crucially, the CBM design inherently allows for human interventions, in which expert users are given the ability to modify potentially misaligned concept choices to influence the decision behavior of the model in an interpretable fashion. However, existing approaches often require numerous human interventions per image to achieve strong performances, posing practical challenges in scenarios where obtaining human feedback is expensive. In this paper, we find that this is noticeably driven by an independent treatment of concepts during intervention, wherein a change of one concept does not influence the use of other ones in the model's final decision. To address this issue, we introduce a trainable concept intervention realignment module, which leverages concept relations to realign concept assignments post-intervention. Across standard, real-world benchmarks, we find that concept realignment can significantly improve intervention efficacy; significantly reducing the number of interventions needed to reach a target classification performance or concept prediction accuracy. In addition, it easily integrates into existing concept-based architectures without requiring changes to the models themselves. This reduced cost of human-model collaboration is crucial to enhancing the feasibility of CBMs in resource-constrained environments.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A separability-based approach to quantifying generalization: which layer  is best?</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01524">https://arxiv.org/abs/2405.01524</a></p>
  <p><b>作者</b>：Luciano Dyballa,  Evan Gerritz,  Steven W. Zucker</p>
  <p><b>备注</b>：6, pages, 5 figures</p>
  <p><b>关键词</b>：remains poorly understood, data remains poorly, deep learning classification, remains poorly, poorly understood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization to unseen data remains poorly understood for deep learning classification and foundation models. How can one assess the ability of networks to adapt to new or extended versions of their input space in the spirit of few-shot learning, out-of-distribution generalization, and domain adaptation? Which layers of a network are likely to generalize best? We provide a new method for evaluating the capacity of networks to represent a sampled domain, regardless of whether the network has been trained on all classes in the domain. Our approach is the following: after fine-tuning state-of-the-art pre-trained models for visual classification on a particular domain, we assess their performance on data from related but distinct variations in that domain. Generalization power is quantified as a function of the latent embeddings of unseen data from intermediate layers for both unsupervised and supervised settings. Working throughout all stages of the network, we find that (i) high classification accuracy does not imply high generalizability; and (ii) deeper layers in a model do not always generalize the best, which has implications for pruning. Since the trends observed across datasets are largely consistent, we conclude that our approach reveals (a function of) the intrinsic capacity of the different layers of a model to generalize.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Transformer-Aided Semantic Communications</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01521">https://arxiv.org/abs/2405.01521</a></p>
  <p><b>作者</b>：Matin Mortaheb,  Erciyes Karakaya,  Mohammad A. Amir Khojastepour,  Sennur Ulukus</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, deep neural networks, transformer structure employed, featuring attention mechanisms, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The transformer structure employed in large language models (LLMs), as a specialized category of deep neural networks (DNNs) featuring attention mechanisms, stands out for their ability to identify and highlight the most relevant aspects of input data. Such a capability is particularly beneficial in addressing a variety of communication challenges, notably in the realm of semantic communication where proper encoding of the relevant data is critical especially in systems with limited bandwidth. In this work, we employ vision transformers specifically for the purpose of compression and compact representation of the input image, with the goal of preserving semantic information throughout the transmission process. Through the use of the attention mechanism inherent in transformers, we create an attention mask. This mask effectively prioritizes critical segments of images for transmission, ensuring that the reconstruction phase focuses on key objects highlighted by the mask. Our methodology significantly improves the quality of semantic communication and optimizes bandwidth usage by encoding different parts of the data in accordance with their semantic information content, thus enhancing overall efficiency. We evaluate the effectiveness of our proposed framework using the TinyImageNet dataset, focusing on both reconstruction quality and accuracy. Our evaluation results demonstrate that our framework successfully preserves semantic information, even when only a fraction of the encoded data is transmitted, according to the intended compression rates.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Accelerating Convergence in Bayesian Few-Shot Classification</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01507">https://arxiv.org/abs/2405.01507</a></p>
  <p><b>作者</b>：Tianjun Ke,  Haoqun Cao,  Feng Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian few-shot classification, Gaussian process-based few-shot, focal point, Bayesian few-shot, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian few-shot classification has been a focal point in the field of few-shot learning. This paper seamlessly integrates mirror descent-based variational inference into Gaussian process-based few-shot classification, addressing the challenge of non-conjugate inference. By leveraging non-Euclidean geometry, mirror descent achieves accelerated convergence by providing the steepest descent direction along the corresponding manifold. It also exhibits the parameterization invariance property concerning the variational distribution. Experimental results demonstrate competitive classification accuracy, improved uncertainty quantification, and faster convergence compared to baseline models. Additionally, we investigate the impact of hyperparameters and components. Code is publicly available at this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Analyzing the Role of Semantic Representations in the Era of Large  Language Models</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01502">https://arxiv.org/abs/2405.01502</a></p>
  <p><b>作者</b>：Zhijing Jin,  Yuen Chen,  Fernando Gonzalez,  Jiarui Liu,  Jiayi Zhang,  Julian Michael,  Bernhard Schölkopf,  Mona Diab</p>
  <p><b>备注</b>：NAACL 2024</p>
  <p><b>关键词</b>：natural language processing, linguistic expertise, rich set, set of features, features created</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven chain-of-thought prompting method, which we call AMRCoT, and find that it generally hurts performance more than it helps. To investigate what AMR may have to offer on these tasks, we conduct a series of analysis experiments. We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction. We recommend focusing on these areas for future work in semantic representations for LLMs. Our code: this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Navigating Heterogeneity and Privacy in One-Shot Federated Learning with  Diffusion Models</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01494">https://arxiv.org/abs/2405.01494</a></p>
  <p><b>作者</b>：Matias Mendieta,  Guangyu Sun,  Chen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enables multiple clients, enables multiple, train models collectively, multiple clients, clients to train</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) enables multiple clients to train models collectively while preserving data privacy. However, FL faces challenges in terms of communication cost and data heterogeneity. One-shot federated learning has emerged as a solution by reducing communication rounds, improving efficiency, and providing better security against eavesdropping attacks. Nevertheless, data heterogeneity remains a significant challenge, impacting performance. This work explores the effectiveness of diffusion models in one-shot FL, demonstrating their applicability in addressing data heterogeneity and improving FL performance. Additionally, we investigate the utility of our diffusion model approach, FedDiff, compared to other one-shot FL methods under differential privacy (DP). Furthermore, to improve generated sample quality under DP settings, we propose a pragmatic Fourier Magnitude Filtering (FMF) method, enhancing the effectiveness of generated data for global model training.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Digital Twin Generators for Disease Modeling</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01488">https://arxiv.org/abs/2405.01488</a></p>
  <p><b>作者</b>：Nameyeh Alam,  Jake Basilico,  Daniele Bertolini,  Satish Casie Chetty,  Heather D'Angelo,  Ryan Douglas,  Charles K. Fisher,  Franklin Fuller,  Melissa Gomes,  Rishabh Gupta,  Alex Lang,  Anton Loukianov,  Rachel Mak-McCully,  Cary Murray,  Hanalei Pham,  Susanna Qiao,  Elena Ryapolova-Webb,  Aaron Smith,  Dimitri Theoharatos,  Anil Tolwani,  Eric W. Tramel,  Anna Vidovszky,  Judy Viduya,  Jonathan R. Walsh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Digital twins, Digital Twin Generators, digital, patient digital twin, patients' digital twins</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A patient's digital twin is a computational model that describes the evolution of their health over time. Digital twins have the potential to revolutionize medicine by enabling individual-level computer simulations of human health, which can be used to conduct more efficient clinical trials or to recommend personalized treatment options. Due to the overwhelming complexity of human biology, machine learning approaches that leverage large datasets of historical patients' longitudinal health records to generate patients' digital twins are more tractable than potential mechanistic models. In this manuscript, we describe a neural network architecture that can learn conditional generative models of clinical trajectories, which we call Digital Twin Generators (DTGs), that can create digital twins of individual patients. We show that the same neural network architecture can be trained to generate accurate digital twins for patients across 13 different indications simply by changing the training set and tuning hyperparameters. By introducing a general purpose architecture, we aim to unlock the ability to scale machine learning approaches to larger datasets and across more indications so that a digital twin could be created for any patient in the world.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Designing Algorithmic Recommendations to Achieve Human-AI  Complementarity</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01484">https://arxiv.org/abs/2405.01484</a></p>
  <p><b>作者</b>：Bryce McLaughlin,  Jann Spiess</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human, Algorithms frequently assist, human decisions, human decision-makers, design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Algorithms frequently assist, rather than replace, human decision-makers. However, the design and analysis of algorithms often focus on predicting outcomes and do not explicitly model their effect on human decisions. This discrepancy between the design and role of algorithmic assistants becomes of particular concern in light of empirical evidence that suggests that algorithmic assistants again and again fail to improve human decisions. In this article, we formalize the design of recommendation algorithms that assist human decision-makers without making restrictive ex-ante assumptions about how recommendations affect decisions. We formulate an algorithmic-design problem that leverages the potential-outcomes framework from causal inference to model the effect of recommendations on a human decision-maker's binary treatment choice. Within this model, we introduce a monotonicity assumption that leads to an intuitive classification of human responses to the algorithm. Under this monotonicity assumption, we can express the human's response to algorithmic recommendations in terms of their compliance with the algorithm and the decision they would take if the algorithm sends no recommendation. We showcase the utility of our framework using an online experiment that simulates a hiring task. We argue that our approach explains the relative performance of different recommendation algorithms in the experiment, and can help design solutions that realize human-AI complementarity.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01481">https://arxiv.org/abs/2405.01481</a></p>
  <p><b>作者</b>：Gerald Shen,  Zhilin Wang,  Olivier Delalleau,  Jiaqi Zeng,  Yi Dong,  Daniel Egert,  Shengyang Sun,  Jimmy Zhang,  Sahil Jain,  Ali Taghibakhshi,  Markel Sanz Ausin,  Ashwath Aithal,  Oleksii Kuchaiev</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：Aligning Large Language, Large Language Models, Large Language, Aligning Large, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aligning Large Language Models (LLMs) with human values and preferences is essential for making them helpful and safe. However, building efficient tools to perform alignment can be challenging, especially for the largest and most competent LLMs which often contain tens or hundreds of billions of parameters. We create NeMo-Aligner, a toolkit for model alignment that can efficiently scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly optimized and scalable implementations for major paradigms of model alignment such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally, our toolkit supports running most of the alignment techniques in a Parameter Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for extensibility, allowing support for other alignment techniques with minimal effort. It is open-sourced with Apache 2.0 License and we invite community contributions at this https URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Common pitfalls to avoid while using multiobjective optimization in  machine learning</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01480">https://arxiv.org/abs/2405.01480</a></p>
  <p><b>作者</b>：Junaid Akhter,  Paul David Fährmann,  Konstantin Sonntag,  Sebastian Peitz</p>
  <p><b>备注</b>：21 pages, 12 figures</p>
  <p><b>关键词</b>：MOO, increasing interest, machine learning, multiobjective optimization, interest in exploring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there has been an increasing interest in exploring the application of multiobjective optimization (MOO) in machine learning (ML). The interest is driven by the numerous situations in real-life applications where multiple objectives need to be optimized simultaneously. A key aspect of MOO is the existence of a Pareto set, rather than a single optimal solution, which illustrates the inherent trade-offs between objectives. Despite its potential, there is a noticeable lack of satisfactory literature that could serve as an entry-level guide for ML practitioners who want to use MOO. Hence, our goal in this paper is to produce such a resource. We critically review previous studies, particularly those involving MOO in deep learning (using Physics-Informed Neural Networks (PINNs) as a guiding example), and identify misconceptions that highlight the need for a better grasp of MOO principles in ML. Using MOO of PINNs as a case study, we demonstrate the interplay between the data loss and the physics loss terms. We highlight the most common pitfalls one should avoid while using MOO techniques in ML. We begin by establishing the groundwork for MOO, focusing on well-known approaches such as the weighted sum (WS) method, alongside more complex techniques like the multiobjective gradient descent algorithm (MGDA). Additionally, we compare the results obtained from the WS and MGDA with one of the most common evolutionary algorithms, NSGA-II. We emphasize the importance of understanding the specific problem, the objective space, and the selected MOO method, while also noting that neglecting factors such as convergence can result in inaccurate outcomes and, consequently, a non-optimal solution. Our goal is to offer a clear and practical guide for ML practitioners to effectively apply MOO, particularly in the context of DL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Understanding Retrieval-Augmented Task Adaptation for Vision-Language  Models</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01468">https://arxiv.org/abs/2405.01468</a></p>
  <p><b>作者</b>：Yifei Ming,  Yixuan Li</p>
  <p><b>备注</b>：The paper is accepted at ICML 2024</p>
  <p><b>关键词</b>：demonstrated remarkable performance, Pre-trained contrastive vision-language, Pre-trained contrastive, range of tasks, demonstrated remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained contrastive vision-language models have demonstrated remarkable performance across a wide range of tasks. However, they often struggle on fine-trained datasets with categories not adequately represented during pre-training, which makes adaptation necessary. Recent works have shown promising results by utilizing samples from web-scale databases for retrieval-augmented adaptation, especially in low-data regimes. Despite the empirical success, understanding how retrieval impacts the adaptation of vision-language models remains an open research question. In this work, we adopt a reflective perspective by presenting a systematic study to understand the roles of key components in retrieval-augmented adaptation. We unveil new insights on uni-modal and cross-modal retrieval and highlight the critical role of logit ensemble for effective adaptation. We further present theoretical underpinnings that directly support our empirical observations.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Uncertainty for Active Learning on Graphs</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01462">https://arxiv.org/abs/2405.01462</a></p>
  <p><b>作者</b>：Dominik Fuchsgruber,  Tom Wollschläger,  Bertrand Charpentier,  Antonio Oroz,  Stephan Günnemann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Active Learning strategy, iteratively acquiring labels, machine learning models, Active Learning, Uncertainty Sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty Sampling is an Active Learning strategy that aims to improve the data efficiency of machine learning models by iteratively acquiring labels of data points with the highest uncertainty. While it has proven effective for independent data its applicability to graphs remains under-explored. We propose the first extensive study of Uncertainty Sampling for node classification: (1) We benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a significant performance gap to other Active Learning strategies. (2) We develop ground-truth Bayesian uncertainty estimates in terms of the data generating process and prove their effectiveness in guiding Uncertainty Sampling toward optimal queries. We confirm our results on synthetic data and design an approximate approach that consistently outperforms other uncertainty estimators on real datasets. (3) Based on this analysis, we relate pitfalls in modeling uncertainty to existing methods. Our analysis enables and informs the development of principled uncertainty estimation on graphs.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Purify Unlearnable Examples via Rate-Constrained Variational  Autoencoders</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01460">https://arxiv.org/abs/2405.01460</a></p>
  <p><b>作者</b>：Yi Yu,  Yufei Wang,  Song Xia,  Wenhan Yang,  Shijian Lu,  Yap-Peng Tan,  Alex C. Kot</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：maximize testing error, making subtle modifications, seek to maximize, correctly labeled, maximize testing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlearnable examples (UEs) seek to maximize testing error by making subtle modifications to training examples that are correctly labeled. Defenses against these poisoning attacks can be categorized based on whether specific interventions are adopted during training. The first approach is training-time defense, such as adversarial training, which can mitigate poisoning effects but is computationally intensive. The other approach is pre-training purification, e.g., image short squeezing, which consists of several simple compressions but often encounters challenges in dealing with various UEs. Our work provides a novel disentanglement mechanism to build an efficient pre-training purification method. Firstly, we uncover rate-constrained variational autoencoders (VAEs), demonstrating a clear tendency to suppress the perturbations in UEs. We subsequently conduct a theoretical analysis for this phenomenon. Building upon these insights, we introduce a disentangle variational autoencoder (D-VAE), capable of disentangling the perturbations with learnable class-wise embeddings. Based on this network, a two-stage purification approach is naturally developed. The first stage focuses on roughly eliminating perturbations, while the second stage produces refined, poison-free results, ensuring effectiveness and robustness across various scenarios. Extensive experiments demonstrate the remarkable performance of our method across CIFAR-10, CIFAR-100, and a 100-class ImageNet-subset. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：UQA: Corpus for Urdu Question Answering</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01458">https://arxiv.org/abs/2405.01458</a></p>
  <p><b>作者</b>：Samee Arif,  Sualeha Farid,  Awais Athar,  Agha Ali Raza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：million native speakers, Stanford Question Answering, Question Answering Dataset, question answering, paper introduces UQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces UQA, a novel dataset for question answering and text comprehension in Urdu, a low-resource language with over 70 million native speakers. UQA is generated by translating the Stanford Question Answering Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in the translated context paragraphs. The paper describes the process of selecting and evaluating the best translation model among two candidates: Google Translator and Seamless M4T. The paper also benchmarks several state-of-the-art multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and 74.56 EM. UQA is a valuable resource for developing and testing multilingual NLP systems for Urdu and for enhancing the cross-lingual transferability of existing models. Further, the paper demonstrates the effectiveness of EATS for creating high-quality datasets for other languages and domains. The UQA dataset and the code are publicly available at this http URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Creative Problem Solving in Large Language and Vision Models -- What  Would it Take?</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01453">https://arxiv.org/abs/2405.01453</a></p>
  <p><b>作者</b>：Lakshmi Nair,  Evana Gizzi,  Jivko Sinapov</p>
  <p><b>备注</b>：9 pages, 7 figures, 2 tables</p>
  <p><b>关键词</b>：integrating Computational Creativity, Computational Creativity, vision models, creative problem solving, discuss approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we discuss approaches for integrating Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this limitation through augmented prompting. With this work, we hope to foster discussions of Computational Creativity in the context of ML algorithms for creative problem solving in LLVMs. Our code is at: this https URL</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Test-time Assessment of a Model's Performance on Unseen Domains via  Optimal Transport</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01451">https://arxiv.org/abs/2405.01451</a></p>
  <p><b>作者</b>：Akshay Mehra,  Yunbei Zhang,  Jihun Hamm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model performance, unseen domains, performance, data, challenging problem due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gauging the performance of ML models on data from unseen domains at test-time is essential yet a challenging problem due to the lack of labels in this setting. Moreover, the performance of these models on in-distribution data is a poor indicator of their performance on data from unseen domains. Thus, it is essential to develop metrics that can provide insights into the model's performance at test time and can be computed only with the information available at test time (such as their model parameters, the training data or its statistics, and the unlabeled test data). To this end, we propose a metric based on Optimal Transport that is highly correlated with the model's performance on unseen domains and is efficiently computable only using information available at test time. Concretely, our metric characterizes the model's performance on unseen domains using only a small amount of unlabeled data from these domains and data or statistics from the training (source) domain(s). Through extensive empirical evaluation using standard benchmark datasets, and their corruptions, we demonstrate the utility of our metric in estimating the model's performance in various practical applications. These include the problems of selecting the source data and architecture that leads to the best performance on data from an unseen domain and the problem of predicting a deployed model's performance at test time on unseen domains. Our empirical results show that our metric, which uses information from both the source and the unseen domain, is highly correlated with the model's performance, achieving a significantly better correlation than that obtained via the popular prediction entropy-based metric, which is computed solely using the data from the unseen domain.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：A Review of Reward Functions for Reinforcement Learning in the context  of Autonomous Driving</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01440">https://arxiv.org/abs/2405.01440</a></p>
  <p><b>作者</b>：Ahmed Abouelazm,  Jonas Michel,  J. Marius Zoellner</p>
  <p><b>备注</b>：Accepted at "Interaction-driven Behavior Prediction and Planning for Autonomous Vehicles" workshop in 35th IEEE Intelligent Vehicles Symposium (IV 2024)</p>
  <p><b>关键词</b>：Reinforcement learning, important approach, autonomous driving, reward, Traffic Rules compliance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has emerged as an important approach for autonomous driving. A reward function is used in reinforcement learning to establish the learned skill objectives and guide the agent toward the optimal policy. Since autonomous driving is a complex domain with partly conflicting objectives with varying degrees of priority, developing a suitable reward function represents a fundamental challenge. This paper aims to highlight the gap in such function design by assessing different proposed formulations in the literature and dividing individual objectives into Safety, Comfort, Progress, and Traffic Rules compliance categories. Additionally, the limitations of the reviewed reward functions are discussed, such as objectives aggregation and indifference to driving context. Furthermore, the reward categories are frequently inadequately formulated and lack standardization. This paper concludes by proposing future research that potentially addresses the observed shortcomings in rewards, including a reward validation framework and structured rewards that are context-aware and able to resolve conflicts.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Closed-form congestion control via deep symbolic regression</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01435">https://arxiv.org/abs/2405.01435</a></p>
  <p><b>作者</b>：Jean Martins,  Igor Almeida,  Ricardo Souza,  Silvia Lins</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：throughput scenarios increases, high throughput scenarios, mobile networks embrace, adopting Reinforcement Learning, scenarios increases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As mobile networks embrace the 5G era, the interest in adopting Reinforcement Learning (RL) algorithms to handle challenges in ultra-low-latency and high throughput scenarios increases. Simultaneously, the advent of packetized fronthaul networks imposes demanding requirements that traditional congestion control mechanisms cannot accomplish, highlighting the potential of RL-based congestion control algorithms. Although learning RL policies optimized for satisfying the stringent fronthaul requirements is feasible, the adoption of neural network models in real deployments still poses some challenges regarding real-time inference and interpretability. This paper proposes a methodology to deal with such challenges while maintaining the performance and generalization capabilities provided by a baseline RL policy. The method consists of (1) training a congestion control policy specialized in fronthaul-like networks via reinforcement learning, (2) collecting state-action experiences from the baseline, and (3) performing deep symbolic regression on the collected dataset. The proposed process overcomes the challenges related to inference-time limitations through closed-form expressions that approximate the baseline performance (link utilization, delay, and fairness) and which can be directly implemented in any programming language. Finally, we analyze the inner workings of the closed-form expressions.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01425">https://arxiv.org/abs/2405.01425</a></p>
  <p><b>作者</b>：Yunbum Kook,  Santosh S. Vempala,  Matthew S. Zhang</p>
  <p><b>备注</b>：32 pages</p>
  <p><b>关键词</b>：high-dimensional convex bodies, uniformly sampling high-dimensional, sampling high-dimensional convex, convex bodies, random walk</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a new random walk for uniformly sampling high-dimensional convex bodies. It achieves state-of-the-art runtime complexity with stronger guarantees on the output than previously known, namely in Rényi divergence (which implies TV, $\mathcal{W}_2$, KL, $\chi^2$). The proof departs from known approaches for polytime algorithms for the problem -- we utilize a stochastic diffusion perspective to show contraction to the target distribution with the rate of convergence determined by functional isoperimetric constants of the stationary density.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01413">https://arxiv.org/abs/2405.01413</a></p>
  <p><b>作者</b>：Yuan Tang,  Xu Han,  Xianzhi Li,  Qiao Yu,  Yixue Hao,  Long Hu,  Min Chen</p>
  <p><b>备注</b>：17 pages, 9 figures</p>
  <p><b>关键词</b>：Large Language Models, bridging Large Language, gained significant attention, Language Models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Learning Force Control for Legged Manipulation</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01402">https://arxiv.org/abs/2405.01402</a></p>
  <p><b>作者</b>：Tifanny Portela,  Gabriel B. Margolis,  Yandong Ji,  Pulkit Agrawal</p>
  <p><b>备注</b>：This work has been accepted to ICRA24, as well as the Loco-manipulation workshop at ICRA24</p>
  <p><b>关键词</b>：Controlling contact forces, Controlling contact, critical for locomotion, force, control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlling contact forces during interactions is critical for locomotion and manipulation tasks. While sim-to-real reinforcement learning (RL) has succeeded in many contact-rich problems, current RL methods achieve forceful interactions implicitly without explicitly regulating forces. We propose a method for training RL policies for direct force control without requiring access to force sensing. We showcase our method on a whole-body control platform of a quadruped robot with an arm. Such force control enables us to perform gravity compensation and impedance control, unlocking compliant whole-body manipulation. The learned whole-body controller with variable compliance makes it intuitive for humans to teleoperate the robot by only commanding the manipulator, and the robot's body adjusts automatically to achieve the desired position and force. Consequently, a human teleoperator can easily demonstrate a wide variety of loco-manipulation tasks. To the best of our knowledge, we provide the first deployment of learned whole-body force control in legged manipulators, paving the way for more versatile and adaptable legged robots.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous  Space Exploration</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01392">https://arxiv.org/abs/2405.01392</a></p>
  <p><b>作者</b>：David Maranto</p>
  <p><b>备注</b>：B.A.Sc thesis</p>
  <p><b>关键词</b>：onboard intelligence, spacecraft, systems, complex missions, Earth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for. Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration. Recent work has explored AI-based goal-oriented systems to increase the level of autonomy in mission execution. These systems make use of symbolic reasoning managers to make inferences from the state of a spacecraft and a handcrafted knowledge base, enabling autonomous generation of tasks and re-planning. Such systems have proven to be successful in controlled cases, but they are difficult to implement as they require human-crafted ontological models to allow the spacecraft to understand the world. Reinforcement learning has been applied to train robotic agents to pursue a goal. A new architecture for autonomy is called for. This work explores the application of Large Language Models (LLMs) as the high-level control system of a spacecraft. Using a systems engineering approach, this work presents the design and development of an agentic spacecraft controller by leveraging an LLM as a reasoning engine, to evaluate the utility of such an architecture in achieving higher levels of spacecraft autonomy. A series of deep space mission scenarios simulated within the popular game engine Kerbal Space Program (KSP) are used as case studies to evaluate the implementation against the requirements. It is shown the reasoning and planning abilities of present-day LLMs do not scale well as the complexity of a mission increases, but this can be alleviated with adequate prompting frameworks and strategic selection of the agent's level of authority over the host spacecraft. This research evaluates the potential of LLMs in augmenting autonomous decision-making systems for future robotic space applications.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Invariant Risk Minimization Is A Total Variation Model</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01389">https://arxiv.org/abs/2405.01389</a></p>
  <p><b>作者</b>：Zhao-Rong Lai,  Wei-Wen Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Invariant risk minimization, arising approach, approach to generalize, IRM, generalize invariant features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Invariant risk minimization (IRM) is an arising approach to generalize invariant features to different environments in machine learning. While most related works focus on new IRM settings or new application scenarios, the mathematical essence of IRM remains to be properly explained. We verify that IRM is essentially a total variation based on $L^2$ norm (TV-$\ell_2$) of the learning risk with respect to the classifier variable. Moreover, we propose a novel IRM framework based on the TV-$\ell_1$ model. It not only expands the classes of functions that can be used as the learning risk, but also has robust performance in denoising and invariant feature preservation based on the coarea formula. We also illustrate some requirements for IRM-TV-$\ell_1$ to achieve out-of-distribution generalization. Experimental results show that the proposed framework achieves competitive performance in several benchmark machine learning scenarios.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Dynamic Online Ensembles of Basis Expansions</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01365">https://arxiv.org/abs/2405.01365</a></p>
  <p><b>作者</b>：Daniel Waxman,  Petar M. Djurić</p>
  <p><b>备注</b>：34 pages, 14 figures. Accepted to Transactions on Machine Learning Research (TMLR)</p>
  <p><b>关键词</b>：Practical Bayesian learning, Practical Bayesian, Bayesian learning, learning often requires, online inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Practical Bayesian learning often requires (1) online inference, (2) dynamic models, and (3) ensembling over multiple different models. Recent advances have shown how to use random feature approximations to achieve scalable, online ensembling of Gaussian processes with desirable theoretical properties and fruitful applications. One key to these methods' success is the inclusion of a random walk on the model parameters, which makes models dynamic. We show that these methods can be generalized easily to any basis expansion model and that using alternative basis expansions, such as Hilbert space Gaussian processes, often results in better performance. To simplify the process of choosing a specific basis expansion, our method's generality also allows the ensembling of several entirely different models, for example, a Gaussian process and polynomial regression. Finally, we propose a novel method to ensemble static and dynamic models together.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Community-Invariant Graph Contrastive Learning</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01350">https://arxiv.org/abs/2405.01350</a></p>
  <p><b>作者</b>：Shiyin Tan,  Dongyuan Li,  Renhe Jiang,  Ying Zhang,  Manabu Okumura</p>
  <p><b>备注</b>：This paper is accepted by ICML-2024</p>
  <p><b>关键词</b>：received great attention, graph contrastive learning, learn well-generalized node, Graph augmentation, Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph augmentation has received great attention in recent years for graph contrastive learning (GCL) to learn well-generalized node/graph representations. However, mainstream GCL methods often favor randomly disrupting graphs for augmentation, which shows limited generalization and inevitably leads to the corruption of high-level graph information, i.e., the graph community. Moreover, current knowledge-based graph augmentation methods can only focus on either topology or node features, causing the model to lack robustness against various types of noise. To address these limitations, this research investigated the role of the graph community in graph augmentation and figured out its crucial advantage for learnable graph augmentation. Based on our observations, we propose a community-invariant GCL framework to maintain graph community structure during learnable graph augmentation. By maximizing the spectral changes, this framework unifies the constraints of both topology and feature augmentation, enhancing the model's robustness. Empirical evidence on 21 benchmark datasets demonstrates the exclusive merits of our framework. Code is released on Github (this https URL).</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Position Paper: Beyond Robustness Against Single Attack Types</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01349">https://arxiv.org/abs/2405.01349</a></p>
  <p><b>作者</b>：Sihui Dai,  Chong Xiang,  Tong Wu,  Prateek Mittal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：single attack type, single attack, ell, defending against adversarial, adversarial examples focuses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current research on defending against adversarial examples focuses primarily on achieving robustness against a single attack type such as $\ell_2$ or $\ell_{\infty}$-bounded attacks. However, the space of possible perturbations is much larger and currently cannot be modeled by a single attack type. The discrepancy between the focus of current defenses and the space of attacks of interest calls to question the practicality of existing defenses and the reliability of their evaluation. In this position paper, we argue that the research community should look beyond single attack robustness, and we draw attention to three potential directions involving robustness against multiple attacks: simultaneous multiattack robustness, unforeseen attack robustness, and a newly defined problem setting which we call continual adaptive robustness. We provide a unified framework which rigorously defines these problem settings, synthesize existing research in these fields, and outline open directions. We hope that our position paper inspires more research in simultaneous multiattack, unforeseen attack, and continual adaptive robustness.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Constrained Reinforcement Learning Under Model Mismatch</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01327">https://arxiv.org/abs/2405.01327</a></p>
  <p><b>作者</b>：Zhongchang Sun,  Sihong He,  Fei Miao,  Shaofeng Zou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constrained reinforcement learning, Existing studies, reinforcement learning, obtain a well-performing, Constrained Policy Optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing studies on constrained reinforcement learning (RL) may obtain a well-performing policy in the training environment. However, when deployed in a real environment, it may easily violate constraints that were originally satisfied during training because there might be model mismatch between the training and real environments. To address the above challenge, we formulate the problem as constrained RL under model uncertainty, where the goal is to learn a good policy that optimizes the reward and at the same time satisfy the constraint under model mismatch. We develop a Robust Constrained Policy Optimization (RCPO) algorithm, which is the first algorithm that applies to large/continuous state space and has theoretical guarantees on worst-case reward improvement and constraint violation at each iteration during the training. We demonstrate the effectiveness of our algorithm on a set of RL tasks with constraints.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Data Scoping: Effectively Learning the Evolution of Generic Transport  PDEs</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01319">https://arxiv.org/abs/2405.01319</a></p>
  <p><b>作者</b>：Jiangce Chen,  Wenzhuo Xu,  Zeda Xu,  Noelia Grande Gutiérrez,  Sneha Prabha Narra,  Christopher McComb</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：partial differential equations, time-dependent partial differential, fluid flows, describing mass, differential equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transport phenomena (e.g., fluid flows) are governed by time-dependent partial differential equations (PDEs) describing mass, momentum, and energy conservation, and are ubiquitous in many engineering applications. However, deep learning architectures are fundamentally incompatible with the simulation of these PDEs. This paper clearly articulates and then solves this incompatibility. The local-dependency of generic transport PDEs implies that it only involves local information to predict the physical properties at a location in the next time step. However, the deep learning architecture will inevitably increase the scope of information to make such predictions as the number of layers increases, which can cause sluggish convergence and compromise generalizability. This paper aims to solve this problem by proposing a distributed data scoping method with linear time complexity to strictly limit the scope of information to predict the local properties. The numerical experiments over multiple physics show that our data scoping method significantly accelerates training convergence and improves the generalizability of benchmark models on large-scale engineering simulations. Specifically, over the geometries not included in the training data for heat transferring simulation, it can increase the accuracy of Convolutional Neural Networks (CNNs) by 21.7 \% and that of Fourier Neural Operators (FNOs) by 38.5 \% on average.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Non-iterative Optimization of Trajectory and Radio Resource for Aerial  Network</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01314">https://arxiv.org/abs/2405.01314</a></p>
  <p><b>作者</b>：Hyeonsu Lyu,  Jonggyu Jang,  Harim Lee,  Hyun Jong Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maximize proportional fairness, power control problem, aerial IoT network, coordinate optimization approaches, communication schedules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address a joint trajectory planning, user association, resource allocation, and power control problem to maximize proportional fairness in the aerial IoT network, considering practical end-to-end quality-of-service (QoS) and communication schedules. Though the problem is rather ancient, apart from the fact that the previous approaches have never considered user- and time-specific QoS, we point out a prevalent mistake in coordinate optimization approaches adopted by the majority of the literature. Coordinate optimization approaches, which repetitively optimize radio resources for a fixed trajectory and vice versa, generally converge to local optima when all variables are differentiable. However, these methods often stagnate at a non-stationary point, significantly degrading the network utility in mixed-integer problems such as joint trajectory and radio resource optimization. We detour this problem by converting the formulated problem into the Markov decision process (MDP). Exploiting the beneficial characteristics of the MDP, we design a non-iterative framework that cooperatively optimizes trajectory and radio resources without initial trajectory choice. The proposed framework can incorporate various trajectory planning algorithms such as the genetic algorithm, tree search, and reinforcement learning. Extensive comparisons with diverse baselines verify that the proposed framework significantly outperforms the state-of-the-art method, nearly achieving the global optimum. Our implementation code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Graph is all you need? Lightweight data-agnostic neural architecture  search without training</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01306">https://arxiv.org/abs/2405.01306</a></p>
  <p><b>作者</b>：Zhenhan Huang,  Tejaswini Pedapati,  Pin-Yu Chen,  Chunhen Jiang,  Jianxi Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural network models, enables the automatic, network models, automatic design, Neural architecture search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural architecture search (NAS) enables the automatic design of neural network models. However, training the candidates generated by the search algorithm for performance evaluation incurs considerable computational overhead. Our method, dubbed nasgraph, remarkably reduces the computational costs by converting neural architectures to graphs and using the average degree, a graph measure, as the proxy in lieu of the evaluation metric. Our training-free NAS method is data-agnostic and light-weight. It can find the best architecture among 200 randomly sampled architectures from NAS-Bench201 in 217 CPU seconds. Besides, our method is able to achieve competitive performance on various datasets including NASBench-101, NASBench-201, and NDS search spaces. We also demonstrate that nasgraph generalizes to more challenging tasks on Micro TransNAS-Bench-101.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：The Effectiveness of LLMs as Annotators: A Comparative Overview and  Empirical Analysis of Direct Representation</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01299">https://arxiv.org/abs/2405.01299</a></p>
  <p><b>作者</b>：Maja Pavlovic,  Massimo Poesio</p>
  <p><b>备注</b>：LREC-COLING NLPerspectives workshop</p>
  <p><b>关键词</b>：Large Language Models, powerful support tools, application domains, emerged as powerful, range of application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Behavior Imitation for Manipulator Control and Grasping with Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01284">https://arxiv.org/abs/2405.01284</a></p>
  <p><b>作者</b>：Liu Qiyuan</p>
  <p><b>备注</b>：50 pages, 30 figures, Final Year Project Report at Nanyang Technological University, Singapore This article is an NTU FYP report. The formal paper is still in the preparation process</p>
  <p><b>关键词</b>：necessitating substantial investments, typically require expert, human arm motions, require expert data, expert data obtained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The existing Motion Imitation models typically require expert data obtained through MoCap devices, but the vast amount of training data needed is difficult to acquire, necessitating substantial investments of financial resources, manpower, and time. This project combines 3D human pose estimation with reinforcement learning, proposing a novel model that simplifies Motion Imitation into a prediction problem of joint angle values in reinforcement learning. This significantly reduces the reliance on vast amounts of training data, enabling the agent to learn an imitation policy from just a few seconds of video and exhibit strong generalization capabilities. It can quickly apply the learned policy to imitate human arm motions in unfamiliar videos. The model first extracts skeletal motions of human arms from a given video using 3D human pose estimation. These extracted arm motions are then morphologically retargeted onto a robotic manipulator. Subsequently, the retargeted motions are used to generate reference motions. Finally, these reference motions are used to formulate a reinforcement learning problem, enabling the agent to learn a policy for imitating human arm motions. This project excels at imitation tasks and demonstrates robust transferability, accurately imitating human arm motions from other unfamiliar videos. This project provides a lightweight, convenient, efficient, and accurate Motion Imitation model. While simplifying the complex process of Motion Imitation, it achieves notably outstanding performance.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Quantifying Spatial Domain Explanations in BCI using Earth Mover's  Distance</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01277">https://arxiv.org/abs/2405.01277</a></p>
  <p><b>作者</b>：Param Rajpura,  Hubert Cecotti,  Yogesh Kumar Meena</p>
  <p><b>备注</b>：8 pages, 3 figures, 3 tables, draft of the accepted work at IJCNN, WCCI 2024</p>
  <p><b>关键词</b>：systems facilitate unique, benefiting severely disabled, severely disabled individuals, facilitate unique communication, systems facilitate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain-computer interface (BCI) systems facilitate unique communication between humans and computers, benefiting severely disabled individuals. Despite decades of research, BCIs are not fully integrated into clinical and commercial settings. It's crucial to assess and explain BCI performance, offering clear explanations for potential users to avoid frustration when it doesn't work as expected. This work investigates the efficacy of different deep learning and Riemannian geometry-based classification models in the context of motor imagery (MI) based BCI using electroencephalography (EEG). We then propose an optimal transport theory-based approach using earth mover's distance (EMD) to quantify the comparison of the feature relevance map with the domain knowledge of neuroscience. For this, we utilized explainable AI (XAI) techniques for generating feature relevance in the spatial domain to identify important channels for model outcomes. Three state-of-the-art models are implemented - 1) Riemannian geometry-based classifier, 2) EEGNet, and 3) EEG Conformer, and the observed trend in the model's accuracy across different architectures on the dataset correlates with the proposed feature relevance metrics. The models with diverse architectures perform significantly better when trained on channels relevant to motor imagery than data-driven channel selection. This work focuses attention on the necessity for interpretability and incorporating metrics beyond accuracy, underscores the value of combining domain knowledge and quantifying model interpretations with data-driven approaches in creating reliable and robust Brain-Computer Interfaces (BCIs).</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：The Importance of Model Inspection for Better Understanding Performance  Characteristics of Graph Neural Networks</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01270">https://arxiv.org/abs/2405.01270</a></p>
  <p><b>作者</b>：Nairouz Shehata,  Carolina Piçarra,  Anees Kazi,  Ben Glocker</p>
  <p><b>备注</b>：International Symposium on Biomedical Imaging (ISBI)</p>
  <p><b>关键词</b>：conducting comprehensive model, importance of conducting, conducting comprehensive, comparative performance analyses, comprehensive model inspection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study highlights the importance of conducting comprehensive model inspection as part of comparative performance analyses. Here, we investigate the effect of modelling choices on the feature learning characteristics of graph neural networks applied to a brain shape classification task. Specifically, we analyse the effect of using parameter-efficient, shared graph convolutional submodels compared to structure-specific, non-shared submodels. Further, we assess the effect of mesh registration as part of the data harmonisation pipeline. We find substantial differences in the feature embeddings at different layers of the models. Our results highlight that test accuracy alone is insufficient to identify important model characteristics such as encoded biases related to data source or potentially non-discriminative features learned in submodels. Our model inspection framework offers a valuable tool for practitioners to better understand performance characteristics of deep learning models in medical imaging.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：An Online Gradient-Based Caching Policy with Logarithmic Complexity and  Regret Guarantees</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01263">https://arxiv.org/abs/2405.01263</a></p>
  <p><b>作者</b>：Damiano Carra,  Giovanni Neglia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：LRU or LFU, specific traffic patterns, Machine Learning-based methods, advanced Machine Learning-based, specific traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The commonly used caching policies, such as LRU or LFU, exhibit optimal performance only for specific traffic patterns. Even advanced Machine Learning-based methods, which detect patterns in historical request data, struggle when future requests deviate from past trends. Recently, a new class of policies has emerged that makes no assumptions about the request arrival process. These algorithms solve an online optimization problem, enabling continuous adaptation to the context. They offer theoretical guarantees on the regret metric, which is the gap between the gain of the online policy and the gain of the optimal static cache allocation in hindsight. Nevertheless, the high computational complexity of these solutions hinders their practical adoption. In this study, we introduce a groundbreaking gradient-based online caching policy, the first to achieve logarithmic computational complexity relative to catalog size along with regret guarantees. This means our algorithm can efficiently handle large-scale data while minimizing the performance gap between real-time decisions and optimal hindsight choices. As requests arrive, our policy dynamically adjusts the probabilities of including items in the cache, which drive cache update decisions. Our algorithm's streamlined complexity is a key advantage, enabling its application to real-world traces featuring millions of requests and items. This is a significant achievement, as traces of this scale have been out of reach for existing policies with regret guarantees. To the best of our knowledge, our experimental results show for the first time that the regret guarantees of gradient-based caching policies bring significant benefits in scenarios of practical interest.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Continuously evolving rewards in an open-ended environment</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01261">https://arxiv.org/abs/2405.01261</a></p>
  <p><b>作者</b>：Richard M. Bailey</p>
  <p><b>备注</b>：30 pages, 8 figures</p>
  <p><b>关键词</b>：complex open-ended real-world, open-ended real-world environments, behaviours emerge endogenously, Unambiguous identification, partly because goals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unambiguous identification of the rewards driving behaviours of entities operating in complex open-ended real-world environments is difficult, partly because goals and associated behaviours emerge endogenously and are dynamically updated as environments change. Reproducing such dynamics in models would be useful in many domains, particularly where fixed reward functions limit the adaptive capabilities of agents. Simulation experiments described assess a candidate algorithm for the dynamic updating of rewards, RULE: Reward Updating through Learning and Expectation. The approach is tested in a simplified ecosystem-like setting where experiments challenge entities' survival, calling for significant behavioural change. The population of entities successfully demonstrate the abandonment of an initially rewarded but ultimately detrimental behaviour, amplification of beneficial behaviour, and appropriate responses to novel items added to their environment. These adjustment happen through endogenous modification of the entities' underlying reward function, during continuous learning, without external intervention.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Causal Influence in Federated Edge Inference</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01260">https://arxiv.org/abs/2405.01260</a></p>
  <p><b>作者</b>：Mert Kayaalp,  Yunus Inan,  Visa Koivunen,  Ali H. Sayed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unlabeled streaming data, setting where heterogeneous, connectivity are performing, unlabeled streaming, streaming data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider a setting where heterogeneous agents with connectivity are performing inference using unlabeled streaming data. Observed data are only partially informative about the target variable of interest. In order to overcome the uncertainty, agents cooperate with each other by exchanging their local inferences with and through a fusion center. To evaluate how each agent influences the overall decision, we adopt a causal framework in order to distinguish the actual influence of agents from mere correlations within the decision-making process. Various scenarios reflecting different agent participation patterns and fusion center policies are investigated. We derive expressions to quantify the causal impact of each agent on the joint decision, which could be beneficial for anticipating and addressing atypical scenarios, such as adversarial attacks or system malfunctions. We validate our theoretical results with numerical simulations and a real-world application of multi-camera crowd counting.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Revisiting semi-supervised training objectives for differentiable  particle filters</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01251">https://arxiv.org/abs/2405.01251</a></p>
  <p><b>作者</b>：Jiaxi Li,  John-Joseph Brady,  Xiongjie Chen,  Yunpeng Li</p>
  <p><b>备注</b>：5 pages, 2 figures</p>
  <p><b>关键词</b>：Monte Carlo methods, sequential Monte Carlo, Monte Carlo, Carlo methods, sequential Monte</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable particle filters combine the flexibility of neural networks with the probabilistic nature of sequential Monte Carlo methods. However, traditional approaches rely on the availability of labelled data, i.e., the ground truth latent state information, which is often difficult to obtain in real-world applications. This paper compares the effectiveness of two semi-supervised training objectives for differentiable particle filters. We present results in two simulated environments where labelled data are scarce.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Prompt engineering paradigms for medical applications: scoping review  and recommendations for better practices</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01249">https://arxiv.org/abs/2405.01249</a></p>
  <p><b>作者</b>：Jamil Zaghir,  Marco Naguib,  Mina Bjelogrlic,  Aurélie Névéol,  Xavier Tannier,  Christian Lovis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, Prompt engineering, medical domain, language models, medical domain remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt engineering is crucial for harnessing the potential of large language models (LLMs), especially in the medical domain where specialized terminology and phrasing is used. However, the efficacy of prompt engineering in the medical domain remains to be explored. In this work, 114 recent studies (2022-2024) applying prompt engineering in medicine, covering prompt learning (PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used interchangeably. ChatGPT is the most commonly used LLM, with seven papers using it for processing sensitive clinical data. Chain-of-Thought emerges as the most common prompt engineering technique. While PL and PT articles typically provide a baseline for evaluating prompt-based approaches, 64% of PD studies lack non-prompt-related baselines. We provide tables and figures summarizing existing work, and reporting recommendations to guide future research contributions.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Lying Graph Convolution: Learning to Lie for Node Classification Tasks</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01247">https://arxiv.org/abs/2405.01247</a></p>
  <p><b>作者</b>：Daniele Castellana</p>
  <p><b>备注</b>：Accepted to IJCNN2024</p>
  <p><b>关键词</b>：Deep Graph Networks, Graph Networks, Deep Graph, observed that Deep, graph structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of machine learning for graphs, many researchers have empirically observed that Deep Graph Networks (DGNs) perform favourably on node classification tasks when the graph structure is homophilic (\ie adjacent nodes are similar). In this paper, we introduce Lying-GCN, a new DGN inspired by opinion dynamics that can adaptively work in both the heterophilic and the homophilic setting. At each layer, each agent (node) shares its own opinions (node embeddings) with its neighbours. Instead of sharing its opinion directly as in GCN, we introduce a mechanism which allows agents to lie. Such a mechanism is adaptive, thus the agents learn how and when to lie according to the task that should be solved. We provide a characterisation of our proposal in terms of dynamical systems, by studying the spectral property of the coefficient matrix of the system. While the steady state of the system collapses to zero, we believe the lying mechanism is still usable to solve node classification tasks. We empirically prove our belief on both synthetic and real-world datasets, by showing that the lying mechanism allows to increase the performances in the heterophilic setting without harming the results in the homophilic one.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio  and Bone Conduction Speech Super Resolution and Enhancement on Mobile and  Wearable Platforms</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01242">https://arxiv.org/abs/2405.01242</a></p>
  <p><b>作者</b>：Yueyuan Sui,  Minghui Zhao,  Junxi Xia,  Xiaofan Jiang,  Stephen Xia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conduction speech enhancement, bone conduction speech, transformer and Mamba, Mamba architecture, bone conduction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose TRAMBA, a hybrid transformer and Mamba architecture for acoustic and bone conduction speech enhancement, suitable for mobile and wearable platforms. Bone conduction speech enhancement has been impractical to adopt in mobile and wearable platforms for several reasons: (i) data collection is labor-intensive, resulting in scarcity; (ii) there exists a performance gap between state of-art models with memory footprints of hundreds of MBs and methods better suited for resource-constrained systems. To adapt TRAMBA to vibration-based sensing modalities, we pre-train TRAMBA with audio speech datasets that are widely available. Then, users fine-tune with a small amount of bone conduction data. TRAMBA outperforms state-of-art GANs by up to 7.3% in PESQ and 1.8% in STOI, with an order of magnitude smaller memory footprint and an inference speed up of up to 465 times. We integrate TRAMBA into real systems and show that TRAMBA (i) improves battery life of wearables by up to 160% by requiring less data sampling and transmission; (ii) generates higher quality voice in noisy environments than over-the-air speech; (iii) requires a memory footprint of less than 20.0 MB.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Boosting Jailbreak Attack with Momentum</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01229">https://arxiv.org/abs/2405.01229</a></p>
  <p><b>作者</b>：Yihao Zhang,  Zeming Wei</p>
  <p><b>备注</b>：ICLR 2024 Workshop on Reliable and Responsible Foundation Models</p>
  <p><b>关键词</b>：Large Language Models, achieved remarkable success, Greedy Coordinate Gradient, notably the well-documented, diverse tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-documented \textit{jailbreak} attack. Recently, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous iterations. Specifically, we introduce the \textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) attack, which incorporates a momentum term into the gradient heuristic. Experimental results showcase the notable enhancement achieved by MAP in gradient-based attacks on aligned language models. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Improving Membership Inference in ASR Model Auditing with Perturbed Loss  Features</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01207">https://arxiv.org/abs/2405.01207</a></p>
  <p><b>作者</b>：Francisco Teixeira,  Karla Pizzi,  Raphael Olivier,  Alberto Abad,  Bhiksha Raj,  Isabel Trancoso</p>
  <p><b>备注</b>：Trustworthy Speech Processing, Satellite Workshop at ICASSP 2024</p>
  <p><b>关键词</b>：Automatic Speech Recognition, Speech Recognition, Automatic Speech, substantial privacy threat, Membership Inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Membership Inference (MI) poses a substantial privacy threat to the training data of Automatic Speech Recognition (ASR) systems, while also offering an opportunity to audit these models with regard to user data. This paper explores the effectiveness of loss-based features in combination with Gaussian and adversarial perturbations to perform MI in ASR models. To the best of our knowledge, this approach has not yet been investigated. We compare our proposed features with commonly used error-based features and find that the proposed features greatly enhance performance for sample-level MI. For speaker-level MI, these features improve results, though by a smaller margin, as error-based features already obtained a high performance for this task. Our findings emphasise the importance of considering different feature sets and levels of access to target models for effective MI in ASR systems, providing valuable insights for auditing such models.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Error-Driven Uncertainty Aware Training</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01205">https://arxiv.org/abs/2405.01205</a></p>
  <p><b>作者</b>：Pedro Mendes,  Paolo Romano,  David Garlan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reliability and trustworthiness, undermines their reliability, Uncertainty Aware Training, Error-Driven Uncertainty Aware, Neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are often overconfident about their predictions, which undermines their reliability and trustworthiness. In this work, we present a novel technique, named Error-Driven Uncertainty Aware Training (EUAT), which aims to enhance the ability of neural models to estimate their uncertainty correctly, namely to be highly uncertain when they output inaccurate predictions and low uncertain when their output is accurate. The EUAT approach operates during the model's training phase by selectively employing two loss functions depending on whether the training examples are correctly or incorrectly predicted by the model. This allows for pursuing the twofold goal of i) minimizing model uncertainty for correctly predicted inputs and ii) maximizing uncertainty for mispredicted inputs, while preserving the model's misprediction rate. We evaluate EUAT using diverse neural models and datasets in the image recognition domains considering both non-adversarial and adversarial settings. The results show that EUAT outperforms existing approaches for uncertainty estimation (including other uncertainty-aware training techniques, calibration, ensembles, and DEUP) by providing uncertainty estimates that not only have higher quality when evaluated via statistical metrics (e.g., correlation with residuals) but also when employed to build binary classifiers that decide whether the model's output can be trusted or not and under distributional data shifts.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning-to-solve unit commitment based on few-shot physics-guided  spatial-temporal graph convolution network</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01200">https://arxiv.org/abs/2405.01200</a></p>
  <p><b>作者</b>：Mei Yang,  Gao Qiu andJunyong Liu,  Kai Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph convolutional network, solve unit commitment, spatial temporal graph, temporal graph convolutional, fast solve unit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This letter proposes a few-shot physics-guided spatial temporal graph convolutional network (FPG-STGCN) to fast solve unit commitment (UC). Firstly, STGCN is tailored to parameterize UC. Then, few-shot physics-guided learning scheme is proposed. It exploits few typical UC solutions yielded via commercial optimizer to escape from local minimum, and leverages the augmented Lagrangian method for constraint satisfaction. To further enable both feasibility and continuous relaxation for integers in learning process, straight-through estimator for Tanh-Sign composition is proposed to fully differentiate the mixed integer solution space. Case study on the IEEE benchmark justifies that, our method bests mainstream learning ways on UC feasibility, and surpasses traditional solver on efficiency.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Towards Interpretable Reinforcement Learning with Constrained  Normalizing Flow Policies</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01198">https://arxiv.org/abs/2405.01198</a></p>
  <p><b>作者</b>：Finn Rietz,  Erik Schaffernicht,  Stefan Heinrich,  Johannes A. Stork</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black-box neural networks, neural networks, typically represented, represented by black-box, black-box neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning policies are typically represented by black-box neural networks, which are non-interpretable and not well-suited for safety-critical domains. To address both of these issues, we propose constrained normalizing flow policies as interpretable and safe-by-construction policy models. We achieve safety for reinforcement learning problems with instantaneous safety constraints, for which we can exploit domain knowledge by analytically constructing a normalizing flow that ensures constraint satisfaction. The normalizing flow corresponds to an interpretable sequence of transformations on action samples, each ensuring alignment with respect to a particular constraint. Our experiments reveal benefits beyond interpretability in an easier learning objective and maintained constraint satisfaction throughout the entire learning process. Our approach leverages constraints over reward engineering while offering enhanced interpretability, safety, and direct means of providing domain knowledge to the agent without relying on complex reward functions.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Decoupling Feature Extraction and Classification Layers for Calibrated  Neural Networks</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01196">https://arxiv.org/abs/2405.01196</a></p>
  <p><b>作者</b>：Mikkel Jordahn,  Pablo M. Olmos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Neural Networks, shown great promise, poorly calibrated predictions, Neural Networks, Deep Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Neural Networks (DNN) have shown great promise in many classification applications, yet are widely known to have poorly calibrated predictions when they are over-parametrized. Improving DNN calibration without comprising on model accuracy is of extreme importance and interest in safety critical applications such as in the health-care sector. In this work, we show that decoupling the training of feature extraction layers and classification layers in over-parametrized DNN architectures such as Wide Residual Networks (WRN) and Visual Transformers (ViT) significantly improves model calibration whilst retaining accuracy, and at a low training cost. In addition, we show that placing a Gaussian prior on the last hidden layer outputs of a DNN, and training the model variationally in the classification training stage, even further improves calibration. We illustrate these methods improve calibration across ViT and WRN architectures for several image classification benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Gradient-Congruity Guided Federated Sparse Training</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01189">https://arxiv.org/abs/2405.01189</a></p>
  <p><b>作者</b>：Chris Xing Tian,  Yibing Liu,  Haoliang Li,  Ray C.C. Cheung,  Shiqi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, machine learning, machine learning technique, distributed machine learning, computing allows artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Edge computing allows artificial intelligence and machine learning models to be deployed on edge devices, where they can learn from local data and collaborate to form a global model. Federated learning (FL) is a distributed machine learning technique that facilitates this process while preserving data privacy. However, FL also faces challenges such as high computational and communication costs regarding resource-constrained devices, and poor generalization performance due to the heterogeneity of data across edge clients and the presence of out-of-distribution data. In this paper, we propose the Gradient-Congruity Guided Federated Sparse Training (FedSGC), a novel method that integrates dynamic sparse training and gradient congruity inspection into federated learning framework to address these issues. Our method leverages the idea that the neurons, in which the associated gradients with conflicting directions with respect to the global model contain irrelevant or less generalized information for other clients, and could be pruned during the sparse training process. Conversely, the neurons where the associated gradients with consistent directions could be grown in a higher priority. In this way, FedSGC can greatly reduce the local computation and communication overheads while, at the same time, enhancing the generalization abilities of FL. We evaluate our method on challenging non-i.i.d settings and show that it achieves competitive accuracy with state-of-the-art FL methods across various scenarios while minimizing computation and communication costs.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Potential Energy based Mixture Model for Noisy Label Learning</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01186">https://arxiv.org/abs/2405.01186</a></p>
  <p><b>作者</b>：Zijia Wang,  Wenbin Yang,  Zhisong Liu,  Zhen Jia</p>
  <p><b>备注</b>：36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：Training deep neural, challenging task, important and challenging, potential energy, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training deep neural networks (DNNs) from noisy labels is an important and challenging task. However, most existing approaches focus on the corrupted labels and ignore the importance of inherent data structure. To bridge the gap between noisy labels and data, inspired by the concept of potential energy in physics, we propose a novel Potential Energy based Mixture Model (PEMM) for noise-labels learning. We innovate a distance-based classifier with the potential energy regularization on its class centers. Embedding our proposed classifier with existing deep learning backbones, we can have robust networks with better feature representations. They can preserve intrinsic structures from the data, resulting in a superior noisy tolerance. We conducted extensive experiments to analyze the efficiency of our proposed model on several real-world datasets. Quantitative results show that it can achieve state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Interpretable Data-driven Anomaly Detection in Industrial Processes with  ExIFFI</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01158">https://arxiv.org/abs/2405.01158</a></p>
  <p><b>作者</b>：Davide Frizzo,  Francesco Borsatti,  Alessio Arcudi,  Antonio De Moliner,  Roberto Oboe,  Gian Antonio Susto</p>
  <p><b>备注</b>：6 pages, submitted to IEEE RTSI 2024</p>
  <p><b>关键词</b>：Anomaly detection, Extended Isolation Forest, Anomaly detection method, crucial process, process often required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD) is a crucial process often required in industrial settings. Anomalies can signal underlying issues within a system, prompting further investigation. Industrial processes aim to streamline operations as much as possible, encompassing the production of the final product, making AD an essential mean to reach this goal.Conventional anomaly detection methodologies typically classify observations as either normal or anomalous without providing insight into the reasons behind these classifications.Consequently, in light of the emergence of Industry 5.0, a more desirable approach involves providing interpretable outcomes, enabling users to understand the rationale behind the results.This paper presents the first industrial application of ExIFFI, a recently developed approach focused on the production of fast and efficient explanations for the Extended Isolation Forest (EIF) Anomaly detection method. ExIFFI is tested on two publicly available industrial datasets demonstrating superior effectiveness in explanations and computational efficiency with the respect to other state-of-the-art explainable AD models.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Tabular and Deep Reinforcement Learning for Gittins Index</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01157">https://arxiv.org/abs/2405.01157</a></p>
  <p><b>作者</b>：Harshit Dhankar,  Kshitij Mishra,  Tejas Bodas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expected total discounted, Gittins index policy, Gittins index, total discounted reward, discounted reward obtained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the realm of multi-arm bandit problems, the Gittins index policy is known to be optimal in maximizing the expected total discounted reward obtained from pulling the Markovian arms. In most realistic scenarios however, the Markovian state transition probabilities are unknown and therefore the Gittins indices cannot be computed. One can then resort to reinforcement learning (RL) algorithms that explore the state space to learn these indices while exploiting to maximize the reward collected. In this work, we propose tabular (QGI) and Deep RL (DGN) algorithms for learning the Gittins index that are based on the retirement formulation for the multi-arm bandit problem. When compared with existing RL algorithms that learn the Gittins index, our algorithms have a lower run time, require less storage space (small Q-table size in QGI and smaller replay buffer in DGN), and illustrate better empirical convergence to the Gittins index. This makes our algorithm well suited for problems with large state spaces and is a viable alternative to existing methods. As a key application, we demonstrate the use of our algorithms in minimizing the mean flowtime in a job scheduling problem when jobs are available in batches and have an unknown service time distribution. \</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：SynFlowNet: Towards Molecule Design with Guaranteed Synthesis Pathways</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01155">https://arxiv.org/abs/2405.01155</a></p>
  <p><b>作者</b>：Miruna Cretu,  Charles Harris,  Julien Roy,  Emmanuel Bengio,  Pietro Liò</p>
  <p><b>备注</b>：Presented at ICLR 2024 GEM Workshop</p>
  <p><b>关键词</b>：works proposing molecular, proposing molecular generation, Recent breakthroughs, drug discovery, breakthroughs in generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent breakthroughs in generative modelling have led to a number of works proposing molecular generation models for drug discovery. While these models perform well at capturing drug-like motifs, they are known to often produce synthetically inaccessible molecules. This is because they are trained to compose atoms or fragments in a way that approximates the training distribution, but they are not explicitly aware of the synthesis constraints that come with making molecules in the lab. To address this issue, we introduce SynFlowNet, a GFlowNet model whose action space uses chemically validated reactions and reactants to sequentially build new molecules. We evaluate our approach using synthetic accessibility scores and an independent retrosynthesis tool. SynFlowNet consistently samples synthetically feasible molecules, while still being able to find diverse and high-utility candidates. Furthermore, we compare molecules designed with SynFlowNet to experimentally validated actives, and find that they show comparable properties of interest, such as molecular weight, SA score and predicted protein binding affinity.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Why Tabular Foundation Models Should Be a Research Priority</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01147">https://arxiv.org/abs/2405.01147</a></p>
  <p><b>作者</b>：Boris van Breugel,  Mihaela van der Schaar</p>
  <p><b>备注</b>：Accepted at International Conference on Machine Learning (ICML 2024)</p>
  <p><b>关键词</b>：Recent text, incredibly impressive, image foundation models, text and image, attracting an ever-increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent text and image foundation models are incredibly impressive, and these models are attracting an ever-increasing portion of research resources. In this position piece we aim to shift the ML research community's priorities ever so slightly to a different modality: tabular data. Tabular data is the dominant modality in many fields, yet it is given hardly any research attention and significantly lags behind in terms of scale and power. We believe the time is now to start developing tabular foundation models, or what we coin a Large Tabular Model (LTM). LTMs could revolutionise the way science and ML use tabular data: not as single datasets that are analyzed in a vacuum, but contextualized with respect to related datasets. The potential impact is far-reaching: from few-shot tabular models to automating data science; from out-of-distribution synthetic data to empowering multidisciplinary scientific discovery. We intend to excite reflections on the modalities we study, and convince some researchers to study large tabular models.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Sharp Bounds for Sequential Federated Learning on Heterogeneous Data</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01142">https://arxiv.org/abs/2405.01142</a></p>
  <p><b>作者</b>：Yipeng Li,  Xinchen Lyu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2311.03154</p>
  <p><b>关键词</b>：Federated Learning, manner across clients, models are trained, paradigms in Federated, SFL outperforms PFL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are two paradigms in Federated Learning (FL): parallel FL (PFL), where models are trained in a parallel manner across clients; and sequential FL (SFL), where models are trained in a sequential manner across clients. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. To resolve the theoretical dilemma of SFL, we establish sharp convergence guarantees for SFL on heterogeneous data with both upper and lower bounds. Specifically, we derive the upper bounds for strongly convex, general convex and non-convex objective functions, and construct the matching lower bounds for the strongly convex and general convex objective functions. Then, we compare the upper bounds of SFL with those of PFL, showing that SFL outperforms PFL (at least, when the level of heterogeneity is relatively high). Experimental results on quadratic functions and real data sets validate the counterintuitive comparison result.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Leveraging Procedural Generation for Learning Autonomous Peg-in-Hole  Assembly in Space</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01134">https://arxiv.org/abs/2405.01134</a></p>
  <p><b>作者</b>：Andrej Orsula,  Matthieu Geist,  Miguel Olivares-Mendez,  Carol Martinez</p>
  <p><b>备注</b>：Accepted for publication at the 2024 International Conference on Space Robotics (iSpaRo) | The source code is available at this https URL</p>
  <p><b>关键词</b>：autonomously assemble structures, ability to autonomously, autonomously assemble, assemble structures, structures is crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to autonomously assemble structures is crucial for the development of future space infrastructure. However, the unpredictable conditions of space pose significant challenges for robotic systems, necessitating the development of advanced learning techniques to enable autonomous assembly. In this study, we present a novel approach for learning autonomous peg-in-hole assembly in the context of space robotics. Our focus is on enhancing the generalization and adaptability of autonomous systems through deep reinforcement learning. By integrating procedural generation and domain randomization, we train agents in a highly parallelized simulation environment across a spectrum of diverse scenarios with the aim of acquiring a robust policy. The proposed approach is evaluated using three distinct reinforcement learning algorithms to investigate the trade-offs among various paradigms. We demonstrate the adaptability of our agents to novel scenarios and assembly sequences while emphasizing the potential of leveraging advanced simulation techniques for robot learning in space. Our findings set the stage for future advancements in intelligent robotic systems capable of supporting ambitious space missions and infrastructure development beyond Earth.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Lipschitz constant estimation for general neural network architectures  using control tools</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01125">https://arxiv.org/abs/2405.01125</a></p>
  <p><b>作者</b>：Patricia Pauli,  Dennis Gramlich,  Frank Allgöwer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper is devoted, neural networks, neural, neural network architectures, Lipschitz constant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is devoted to the estimation of the Lipschitz constant of neural networks using semidefinite programming. For this purpose, we interpret neural networks as time-varying dynamical systems, where the $k$-th layer corresponds to the dynamics at time $k$. A key novelty with respect to prior work is that we use this interpretation to exploit the series interconnection structure of neural networks with a dynamic programming recursion. Nonlinearities, such as activation functions and nonlinear pooling layers, are handled with integral quadratic constraints. If the neural network contains signal processing layers (convolutional or state space model layers), we realize them as 1-D/2-D/N-D systems and exploit this structure as well. We distinguish ourselves from related work on Lipschitz constant estimation by more extensive structure exploitation (scalability) and a generalization to a large class of common neural network architectures. To show the versatility and computational advantages of our method, we apply it to different neural network architectures trained on MNIST and CIFAR-10.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Continual Imitation Learning for Prosthetic Limbs</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01114">https://arxiv.org/abs/2405.01114</a></p>
  <p><b>作者</b>：Sharmita Dey,  Benjamin Paassen,  Sarath Ravindran Nair,  Sabri Boughorbel,  Arndt F. Schilling</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：severely restrict mobility, neuromuscular impairments severely, impairments severely restrict, Lower limb amputations, restrict mobility</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lower limb amputations and neuromuscular impairments severely restrict mobility, necessitating advancements beyond conventional prosthetics. Motorized bionic limbs offer promise, but their utility depends on mimicking the evolving synergy of human movement in various settings. In this context, we present a novel model for bionic prostheses' application that leverages camera-based motion capture and wearable sensor data, to learn the synergistic coupling of the lower limbs during human locomotion, empowering it to infer the kinematic behavior of a missing lower limb across varied tasks, such as climbing inclines and stairs. We propose a model that can multitask, adapt continually, anticipate movements, and refine. The core of our method lies in an approach which we call -- multitask prospective rehearsal -- that anticipates and synthesizes future movements based on the previous prediction and employs a corrective mechanism for subsequent predictions. We design an evolving architecture that merges lightweight, task-specific modules on a shared backbone, ensuring both specificity and scalability. We empirically validate our model against various baselines using real-world human gait datasets, including experiments with transtibial amputees, which encompass a broad spectrum of locomotion tasks. The results show that our approach consistently outperforms baseline models, particularly under scenarios affected by distributional shifts, adversarial perturbations, and noise.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Hypergraph $p$-Laplacian regularization on point clouds for data  interpolation</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01109">https://arxiv.org/abs/2405.01109</a></p>
  <p><b>作者</b>：Kehan Shi,  Martin Burger</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：model higher-order relations, Laplacian regularization, Laplacian, point cloud data, Laplacian regularization outperforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a generalization of graphs, hypergraphs are widely used to model higher-order relations in data. This paper explores the benefit of the hypergraph structure for the interpolation of point cloud data that contain no explicit structural information. We define the $\varepsilon_n$-ball hypergraph and the $k_n$-nearest neighbor hypergraph on a point cloud and study the $p$-Laplacian regularization on the hypergraphs. We prove the variational consistency between the hypergraph $p$-Laplacian regularization and the continuum $p$-Laplacian regularization in a semisupervised setting when the number of points $n$ goes to infinity while the number of labeled points remains fixed. A key improvement compared to the graph case is that the results rely on weaker assumptions on the upper bound of $\varepsilon_n$ and $k_n$. To solve the convex but non-differentiable large-scale optimization problem, we utilize the stochastic primal-dual hybrid gradient algorithm. Numerical experiments on data interpolation verify that the hypergraph $p$-Laplacian regularization outperforms the graph $p$-Laplacian regularization in preventing the development of spikes at the labeled points.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Federated Learning with Heterogeneous Data Handling for Robust Vehicular  Object Detection</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01108">https://arxiv.org/abs/2405.01108</a></p>
  <p><b>作者</b>：Ahmad Khalil,  Tizian Dege,  Pegah Golchin,  Rostyslav Olshevskyi,  Antonio Fernandez Anta,  Tobias Meuser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully autonomous driving, refining precise perception, precise perception models, autonomous driving, model training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the pursuit of refining precise perception models for fully autonomous driving, continual online model training becomes essential. Federated Learning (FL) within vehicular networks offers an efficient mechanism for model training while preserving raw sensory data integrity. Yet, FL struggles with non-identically distributed data (e.g., quantity skew), leading to suboptimal convergence rates during model training. In previous work, we introduced FedLA, an innovative Label-Aware aggregation method addressing data heterogeneity in FL for generic scenarios.
In this paper, we introduce FedProx+LA, a novel FL method building upon the state-of-the-art FedProx and FedLA to tackle data heterogeneity, which is specifically tailored for vehicular networks. We evaluate the efficacy of FedProx+LA in continuous online object detection model training. Through a comparative analysis against conventional and state-of-the-art methods, our findings reveal the superior convergence rate of FedProx+LA. Notably, if the label distribution is very heterogeneous, our FedProx+LA approach shows substantial improvements in detection performance compared to baseline methods, also outperforming our previous FedLA approach. Moreover, both FedLA and FedProx+LA increase convergence speed by 30% compared to baseline methods.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Less is More: on the Over-Globalizing Problem in Graph Transformers</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01102">https://arxiv.org/abs/2405.01102</a></p>
  <p><b>作者</b>：Yujie Xing,  Xiao Wang,  Yibo Li,  Hai Huang,  Chuan Shi</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：global attention mechanism, Global Graph Transformer, Graph Transformer, attention mechanism, global attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Transformer, due to its global attention mechanism, has emerged as a new tool in dealing with graph-structured data. It is well recognized that the global attention mechanism considers a wider receptive field in a fully connected graph, leading many to believe that useful information can be extracted from all the nodes. In this paper, we challenge this belief: does the globalizing property always benefit Graph Transformers? We reveal the over-globalizing problem in Graph Transformer by presenting both empirical evidence and theoretical analysis, i.e., the current attention mechanism overly focuses on those distant nodes, while the near nodes, which actually contain most of the useful information, are relatively weakened. Then we propose a novel Bi-Level Global Graph Transformer with Collaborative Training (CoBFormer), including the inter-cluster and intra-cluster Transformers, to prevent the over-globalizing problem while keeping the ability to extract valuable information from distant nodes. Moreover, the collaborative training is proposed to improve the model's generalization ability with a theoretical guarantee. Extensive experiments on various graphs well validate the effectiveness of our proposed CoBFormer.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Poisoning Attacks on Federated Learning for Autonomous Driving</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01073">https://arxiv.org/abs/2405.01073</a></p>
  <p><b>作者</b>：Sonakshi Garg,  Hugo Jönsson,  Gustav Kalander,  Axel Nilsson,  Bhhaanu Pirange,  Viktor Valadi,  Johan Östman</p>
  <p><b>备注</b>：Accepted to SCAI2024</p>
  <p><b>关键词</b>：decentralized learning paradigm, collaboratively train models, Federated Learning, learning paradigm, enabling parties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a decentralized learning paradigm, enabling parties to collaboratively train models while keeping their data confidential. Within autonomous driving, it brings the potential of reducing data storage costs, reducing bandwidth requirements, and to accelerate the learning. FL is, however, susceptible to poisoning attacks. In this paper, we introduce two novel poisoning attacks on FL tailored to regression tasks within autonomous driving: FLStealth and Off-Track Attack (OTA). FLStealth, an untargeted attack, aims at providing model updates that deteriorate the global model performance while appearing benign. OTA, on the other hand, is a targeted attack with the objective to change the global model's behavior when exposed to a certain trigger. We demonstrate the effectiveness of our attacks by conducting comprehensive experiments pertaining to the task of vehicle trajectory prediction. In particular, we show that, among five different untargeted attacks, FLStealth is the most successful at bypassing the considered defenses employed by the server. For OTA, we demonstrate the inability of common defense strategies to mitigate the attack, highlighting the critical need for new defensive mechanisms against targeted attacks within FL for autonomous driving.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：AB-Training: A Communication-Efficient Approach for Distributed Low-Rank  Learning</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01067">https://arxiv.org/abs/2405.01067</a></p>
  <p><b>作者</b>：Daniel Coquelin,  Katherina Flügel,  Marie Weiel,  Nicholas Kiefer,  Muhammed Öz,  Charlotte Debus,  Achim Streit,  Markus Götz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distributed-memory computing clusters, Communication bottlenecks hinder, distributed neural network, computing clusters, bottlenecks hinder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication bottlenecks hinder the scalability of distributed neural network training, particularly on distributed-memory computing clusters. To significantly reduce this communication overhead, we introduce AB-training, a novel data-parallel training method that decomposes weight matrices into low-rank representations and utilizes independent group-based training. This approach consistently reduces network traffic by 50% across multiple scaling scenarios, increasing the training potential on communication-constrained systems. Our method exhibits regularization effects at smaller scales, leading to improved generalization for models like VGG16, while achieving a remarkable 44.14 : 1 compression ratio during training on CIFAR-10 and maintaining competitive accuracy. Albeit promising, our experiments reveal that large batch effects remain a challenge even in low-rank training regimes.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Fair Recommendations with Limited Sensitive Attributes: A  Distributionally Robust Optimization Approach</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01063">https://arxiv.org/abs/2405.01063</a></p>
  <p><b>作者</b>：Tianhao Shi,  Yang Zhang,  Jizhi Zhang,  Fuli Feng,  Xiangnan He</p>
  <p><b>备注</b>：8 pages, 5 figures</p>
  <p><b>关键词</b>：providing equitable recommendations, sensitive attributes, recommender systems, searching and e-commerce, providing equitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As recommender systems are indispensable in various domains such as job searching and e-commerce, providing equitable recommendations to users with different sensitive attributes becomes an imperative requirement. Prior approaches for enhancing fairness in recommender systems presume the availability of all sensitive attributes, which can be difficult to obtain due to privacy concerns or inadequate means of capturing these attributes. In practice, the efficacy of these approaches is limited, pushing us to investigate ways of promoting fairness with limited sensitive attribute information.
Toward this goal, it is important to reconstruct missing sensitive attributes. Nevertheless, reconstruction errors are inevitable due to the complexity of real-world sensitive attribute reconstruction problems and legal regulations. Thus, we pursue fair learning methods that are robust to reconstruction errors. To this end, we propose Distributionally Robust Fair Optimization (DRFO), which minimizes the worst-case unfairness over all potential probability distributions of missing sensitive attributes instead of the reconstructed one to account for the impact of the reconstruction errors. We provide theoretical and empirical evidence to demonstrate that our method can effectively ensure fairness in recommender systems when only limited sensitive attributes are accessible.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：A text-based, generative deep learning model for soil reflectance  spectrum simulation in the VIS-NIR (400-2499 nm) bands</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01060">https://arxiv.org/abs/2405.01060</a></p>
  <p><b>作者</b>：Tong Lei,  Brian N. Bailey</p>
  <p><b>备注</b>：The paper has been submitted to Remote sensing of Environment and revised</p>
  <p><b>关键词</b>：soil reflectance spectra, reflectance spectra, soil reflectance, reflectance spectra based, Simulating soil reflectance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulating soil reflectance spectra is invaluable for soil-plant radiative modeling and training machine learning models, yet it is difficult as the intricate relationships between soil structure and its constituents. To address this, a fully data-driven soil optics generative model (SOGM) for simulation of soil reflectance spectra based on soil property inputs was developed. The model is trained on an extensive dataset comprising nearly 180,000 soil spectra-property pairs from 17 datasets. It generates soil reflectance spectra from text-based inputs describing soil properties and their values rather than only numerical values and labels in binary vector format. The generative model can simulate output spectra based on an incomplete set of input properties. SOGM is based on the denoising diffusion probabilistic model (DDPM). Two additional sub-models were also built to complement the SOGM: a spectral padding model that can fill in the gaps for spectra shorter than the full visible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra model that can estimate the effects of water content on soil reflectance spectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by coupling with the Helios 3D plant modeling software, which allowed for generation of synthetic aerial images of simulated soil and plant scenes. It can also be easily integrated with soil-plant radiation model used for remote sensin research like PROSAIL. The testing results of the SOGM on new datasets that not included in model training proved that the model can generate reasonable soil reflectance spectra based on available property inputs. The presented models are openly accessible on: this https URL.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Leverage Multi-source Traffic Demand Data Fusion with Transformer Model  for Urban Parking Prediction</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01055">https://arxiv.org/abs/2405.01055</a></p>
  <p><b>作者</b>：Yin Huang,  Yongqi Dong,  Youhua Tang,  Li Li</p>
  <p><b>备注</b>：7 pages, 5 figures, under review by the 27th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2024)</p>
  <p><b>关键词</b>：private car ownership, parking availability prediction, necessitating effective parking, spatial-temporal deep learning, urban private car</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The escalation in urban private car ownership has worsened the urban parking predicament, necessitating effective parking availability prediction for urban planning and management. However, the existing prediction methods suffer from low prediction accuracy with the lack of spatial-temporal correlation features related to parking volume, and neglect of flow patterns and correlations between similar parking lots within certain areas. To address these challenges, this study proposes a parking availability prediction framework integrating spatial-temporal deep learning with multi-source data fusion, encompassing traffic demand data from multiple sources (e.g., metro, bus, taxi services), and parking lot data. The framework is based on the Transformer as the spatial-temporal deep learning model and leverages K-means clustering to establish parking cluster zones, extracting and integrating traffic demand characteristics from various transportation modes (i.e., metro, bus, online ride-hailing, and taxi) connected to parking lots. Real-world empirical data was used to verify the effectiveness of the proposed method compared with different machine learning, deep learning, and traditional statistical models for predicting parking availability. Experimental results reveal that, with the proposed pipeline, the developed Transformer model outperforms other models in terms of various metrics, e.g., Mean Squared Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). By fusing multi-source demanding data with spatial-temporal deep learning techniques, this approach offers the potential to develop parking availability prediction systems that furnish more accurate and timely information to both drivers and urban planners, thereby fostering more efficient and sustainable urban mobility.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Continual Learning for Robust Gate Detection under Dynamic Lighting in  Autonomous Drone Racing</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01054">https://arxiv.org/abs/2405.01054</a></p>
  <p><b>作者</b>：Zhongzheng Qiao,  Xuan Huy Pham,  Savitha Ramasamy,  Xudong Jiang,  Erdal Kayacan,  Andriy Sarabakha</p>
  <p><b>备注</b>：8 pages, 6 figures, in 2024 International Joint Conference on Neural Networks (IJCNN)</p>
  <p><b>关键词</b>：resilient real-time environmental, real-time environmental perception, autonomous drone racing, mobile robotics, dynamic elements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In autonomous and mobile robotics, a principal challenge is resilient real-time environmental perception, particularly in situations characterized by unknown and dynamic elements, as exemplified in the context of autonomous drone racing. This study introduces a perception technique for detecting drone racing gates under illumination variations, which is common during high-speed drone flights. The proposed technique relies upon a lightweight neural network backbone augmented with capabilities for continual learning. The envisaged approach amalgamates predictions of the gates' positional coordinates, distance, and orientation, encapsulating them into a cohesive pose tuple. A comprehensive number of tests serve to underscore the efficacy of this approach in confronting diverse and challenging scenarios, specifically those involving variable lighting conditions. The proposed methodology exhibits notable robustness in the face of illumination variations, thereby substantiating its effectiveness.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Explicitly Modeling Generality into Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01053">https://arxiv.org/abs/2405.01053</a></p>
  <p><b>作者</b>：Jingyao Wang,  Wenwen Qiang,  Changwen Zheng</p>
  <p><b>备注</b>：28 pages</p>
  <p><b>关键词</b>：SSL, achieve excellent performance, generality, achieve, achieve excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of generality in machine learning is to achieve excellent performance on various unseen tasks and domains. Recently, self-supervised learning (SSL) has been regarded as an effective method to achieve this goal. It can learn high-quality representations from unlabeled data and achieve promising empirical performance on multiple downstream tasks. Existing SSL methods mainly constrain generality from two aspects: (i) large-scale training data, and (ii) learning task-level shared knowledge. However, these methods lack explicit modeling of the SSL generality in the learning objective, and the theoretical understanding of SSL's generality remains limited. This may cause SSL models to overfit in data-scarce situations and generalize poorly in the real world, making it difficult to achieve true generality. To address these issues, we provide a theoretical definition of generality in SSL and define a $\sigma$-measurement to help quantify it. Based on this insight, we explicitly model generality into self-supervised learning and further propose a novel SSL framework, called GeSSL. It introduces a self-motivated target based on $\sigma$-measurement, which enables the model to find the optimal update direction towards generality. Extensive theoretical and empirical evaluations demonstrate the superior performance of the proposed GeSSL.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Polynomial Chaos Expanded Gaussian Process</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01052">https://arxiv.org/abs/2405.01052</a></p>
  <p><b>作者</b>：Dominik Polke,  Tim Kösters,  Elmar Ahle,  Dirk Söffker</p>
  <p><b>备注</b>：Manuscript: 20 pages, 4 figures, 7 tables</p>
  <p><b>关键词</b>：entire experimental space, local experimental spaces, Expanded Gaussian Process, Chaos Expanded Gaussian, unknown processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In complex and unknown processes, global models are initially generated over the entire experimental space, but they often fail to provide accurate predictions in local areas. Recognizing this limitation, this study addresses the need for models that effectively represent both global and local experimental spaces. It introduces a novel machine learning (ML) approach: Polynomial Chaos Expanded Gaussian Process (PCEGP), leveraging polynomial chaos expansion (PCE) to calculate input-dependent hyperparameters of the Gaussian process (GP). This approach provides a mathematically interpretable method that incorporates non-stationary covariance functions and heteroscedastic noise estimation to generate locally adapted models. The model performance is compared to different algorithms in benchmark tests for regression tasks. The results demonstrate low prediction errors of the PCEGP in these benchmark applications, highlighting model performance that is often competitive with or superior to previous methods. A key advantage of the presented model is the transparency and traceability in the calculation of hyperparameters and model predictions.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Efficient and Flexible Method for Reducing Moderate-size Deep Neural  Networks with Condensation</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01041">https://arxiv.org/abs/2405.01041</a></p>
  <p><b>作者</b>：Tianyi Chen,  Zhi-Qin John Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural networks, Neural, networks, Applying neural networks, neural network sizes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have been extensively applied to a variety of tasks, achieving astounding results. Applying neural networks in the scientific field is an important research direction that is gaining increasing attention. In scientific applications, the scale of neural networks is generally moderate-size, mainly to ensure the speed of inference during application. Additionally, comparing neural networks to traditional algorithms in scientific applications is inevitable. These applications often require rapid computations, making the reduction of neural network sizes increasingly important. Existing work has found that the powerful capabilities of neural networks are primarily due to their non-linearity. Theoretical work has discovered that under strong non-linearity, neurons in the same layer tend to behave similarly, a phenomenon known as condensation. Condensation offers an opportunity to reduce the scale of neural networks to a smaller subnetwork with similar performance. In this article, we propose a condensation reduction algorithm to verify the feasibility of this idea in practical problems. Our reduction method can currently be applied to both fully connected networks and convolutional networks, achieving positive results. In complex combustion acceleration tasks, we reduced the size of the neural network to 41.7% of its original scale while maintaining prediction accuracy. In the CIFAR10 image classification task, we reduced the network size to 11.5% of the original scale, still maintaining a satisfactory validation accuracy. Our method can be applied to most trained neural networks, reducing computational pressure and improving inference speed.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：LOQA: Learning with Opponent Q-Learning Awareness</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01035">https://arxiv.org/abs/2405.01035</a></p>
  <p><b>作者</b>：Milad Aghajohari,  Juan Agustin Duque,  Tim Cooijmans,  Aaron Courville</p>
  <p><b>备注</b>：accepted to ICLR but still not in proceedings this https URL</p>
  <p><b>关键词</b>：resemble the dynamics, dynamics of general-sum, strives to optimize, general-sum games, agent individual utility</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In various real-world scenarios, interactions among agents often resemble the dynamics of general-sum games, where each agent strives to optimize its own utility. Despite the ubiquitous relevance of such settings, decentralized machine learning algorithms have struggled to find equilibria that maximize individual utility while preserving social welfare. In this paper we introduce Learning with Opponent Q-Learning Awareness (LOQA), a novel, decentralized reinforcement learning algorithm tailored to optimizing an agent's individual utility while fostering cooperation among adversaries in partially competitive environments. LOQA assumes the opponent samples actions proportionally to their action-value function Q. Experimental results demonstrate the effectiveness of LOQA at achieving state-of-the-art performance in benchmark scenarios such as the Iterated Prisoner's Dilemma and the Coin Game. LOQA achieves these outcomes with a significantly reduced computational footprint, making it a promising approach for practical multi-agent applications.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：CrossMPT: Cross-attention Message-Passing Transformer for Error  Correcting Codes</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01033">https://arxiv.org/abs/2405.01033</a></p>
  <p><b>作者</b>：Seong-Joon Park,  Hee-Youl Kwak,  Sang-Hyo Kim,  Yongjune Kim,  Jong-Seon No</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：Error correcting codes, Error correcting, communication systems, indispensable for reliable, reliable transmission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Error correcting codes~(ECCs) are indispensable for reliable transmission in communication systems. The recent advancements in deep learning have catalyzed the exploration of ECC decoders based on neural networks. Among these, transformer-based neural decoders have achieved state-of-the-art decoding performance. In this paper, we propose a novel Cross-attention Message-Passing Transformer~(CrossMPT). CrossMPT iteratively updates two types of input vectors (i.e., magnitude and syndrome vectors) using two masked cross-attention blocks. The mask matrices in these cross-attention blocks are determined by the code's parity-check matrix that delineates the relationship between magnitude and syndrome vectors. Our experimental results show that CrossMPT significantly outperforms existing neural network-based decoders, particularly in decoding low-density parity-check codes. Notably, CrossMPT also achieves a significant reduction in computational complexity, achieving over a 50\% decrease in its attention layers compared to the original transformer-based decoder, while retaining the computational complexity of the remaining layers.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：The Privacy Power of Correlated Noise in Decentralized Learning</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01031">https://arxiv.org/abs/2405.01031</a></p>
  <p><b>作者</b>：Youssef Allouah,  Anastasia Koloskova,  Aymane El Firdoussi,  Martin Jaggi,  Rachid Guerraoui</p>
  <p><b>备注</b>：Accepted as conference paper at ICML 2024</p>
  <p><b>关键词</b>：distributed data, learning is appealing, enables the scalable, scalable usage, usage of large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized learning is appealing as it enables the scalable usage of large amounts of distributed data and resources (without resorting to any central entity), while promoting privacy since every user minimizes the direct exposure of their data. Yet, without additional precautions, curious users can still leverage models obtained from their peers to violate privacy. In this paper, we propose Decor, a variant of decentralized SGD with differential privacy (DP) guarantees. Essentially, in Decor, users securely exchange randomness seeds in one communication round to generate pairwise-canceling correlated Gaussian noises, which are injected to protect local models at every communication round. We theoretically and empirically show that, for arbitrary connected graphs, Decor matches the central DP optimal privacy-utility trade-off. We do so under SecLDP, our new relaxation of local DP, which protects all user communications against an external eavesdropper and curious users, assuming that every pair of connected users shares a secret, i.e., an information hidden to all others. The main theoretical challenge is to control the accumulation of non-canceling correlated noise due to network sparsity. We also propose a companion SecLDP privacy accountant for public use.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01029">https://arxiv.org/abs/2405.01029</a></p>
  <p><b>作者</b>：Jianan Zhou,  Zhiguang Cao,  Yaoxin Wu,  Wen Song,  Yining Ma,  Jie Zhang,  Chi Xu</p>
  <p><b>备注</b>：Accepted at ICML 2024</p>
  <p><b>关键词</b>：Learning to solve, garnered much attention, solve vehicle routing, vehicle routing problems, solve vehicle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning to solve vehicle routing problems (VRPs) has garnered much attention. However, most neural solvers are only structured and trained independently on a specific problem, making them less generic and practical. In this paper, we aim to develop a unified neural solver that can cope with a range of VRP variants simultaneously. Specifically, we propose a multi-task vehicle routing solver with mixture-of-experts (MVMoE), which greatly enhances the model capacity without a proportional increase in computation. We further develop a hierarchical gating mechanism for the MVMoE, delivering a good trade-off between empirical performance and computational complexity. Experimentally, our method significantly promotes the zero-shot generalization performance on 10 unseen VRP variants, and showcases decent results on the few-shot setting and real-world benchmark instances. We further provide extensive studies on the effect of MoE configurations in solving VRPs. Surprisingly, the hierarchical gating can achieve much better out-of-distribution generalization performance. The source code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Non-clairvoyant Scheduling with Partial Predictions</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01013">https://arxiv.org/abs/2405.01013</a></p>
  <p><b>作者</b>：Ziyad Benomar,  Vianney Perchet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-clairvoyant scheduling problem, quality guarantees, non-clairvoyant scheduling, scheduling problem, problem has gained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The non-clairvoyant scheduling problem has gained new interest within learning-augmented algorithms, where the decision-maker is equipped with predictions without any quality guarantees. In practical settings, access to predictions may be reduced to specific instances, due to cost or data limitations. Our investigation focuses on scenarios where predictions for only $B$ job sizes out of $n$ are available to the algorithm. We first establish near-optimal lower bounds and algorithms in the case of perfect predictions. Subsequently, we present a learning-augmented algorithm satisfying the robustness, consistency, and smoothness criteria, and revealing a novel tradeoff between consistency and smoothness inherent in the scenario with a restricted number of predictions.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Efficient and Adaptive Posterior Sampling Algorithms for Bandits</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01010">https://arxiv.org/abs/2405.01010</a></p>
  <p><b>作者</b>：Bingshan Hu,  Zhiming Huang,  Tianyue H. Zhang,  Mathias Lécuyer,  Nidhi Hegde</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study Thompson Sampling-based, Thompson Sampling-based algorithms, Thompson Sampling, Thompson Sampling-based, parameterized Thompson Sampling-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study Thompson Sampling-based algorithms for stochastic bandits with bounded rewards. As the existing problem-dependent regret bound for Thompson Sampling with Gaussian priors [Agrawal and Goyal, 2017] is vacuous when $T \le 288 e^{64}$, we derive a more practical bound that tightens the coefficient of the leading term %from $288 e^{64}$ to $1270$. Additionally, motivated by large-scale real-world applications that require scalability, adaptive computational resource allocation, and a balance in utility and computation, we propose two parameterized Thompson Sampling-based algorithms: Thompson Sampling with Model Aggregation (TS-MA-$\alpha$) and Thompson Sampling with Timestamp Duelling (TS-TD-$\alpha$), where $\alpha \in [0,1]$ controls the trade-off between utility and computation. Both algorithms achieve $O \left(K\ln^{\alpha+1}(T)/\Delta \right)$ regret bound, where $K$ is the number of arms, $T$ is the finite learning horizon, and $\Delta$ denotes the single round performance loss when pulling a sub-optimal arm.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Tackling Graph Oversquashing by Global and Local Non-Dissipativity</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01009">https://arxiv.org/abs/2405.01009</a></p>
  <p><b>作者</b>：Alessio Gravina,  Moshe Eliasof,  Claudio Gallicchio,  Davide Bacciu,  Carola-Bibiane Schönlieb</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Message-Passing Neural Networks, Neural Networks, Message-Passing Neural, facilitate effective information, effective information flow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common problem in Message-Passing Neural Networks is oversquashing -- the limited ability to facilitate effective information flow between distant nodes. Oversquashing is attributed to the exponential decay in information transmission as node distances increase. This paper introduces a novel perspective to address oversquashing, leveraging properties of global and local non-dissipativity, that enable the maintenance of a constant information flow rate. Namely, we present SWAN, a uniquely parameterized model GNN with antisymmetry both in space and weight domains, as a means to obtain non-dissipativity. Our theoretical analysis asserts that by achieving these properties, SWAN offers an enhanced ability to transmit information over extended distances. Empirical evaluations on synthetic and real-world benchmarks that emphasize long-range interactions validate the theoretical understanding of SWAN, and its ability to mitigate oversquashing.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Deep Learning Models in Speech Recognition: Measuring GPU Energy  Consumption, Impact of Noise and Model Quantization for Edge Deployment</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01004">https://arxiv.org/abs/2405.01004</a></p>
  <p><b>作者</b>：Aditya Chakravarty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved word-error rates, surpassing human annotator, extensive server resources, significant carbon footprints, Recent transformer-based ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent transformer-based ASR models have achieved word-error rates (WER) below 4%, surpassing human annotator accuracy, yet they demand extensive server resources, contributing to significant carbon footprints. The traditional server-based architecture of ASR also presents privacy concerns, alongside reliability and latency issues due to network dependencies. In contrast, on-device (edge) ASR enhances privacy, boosts performance, and promotes sustainability by effectively balancing energy use and accuracy for specific applications. This study examines the effects of quantization, memory demands, and energy consumption on the performance of various ASR model inference on the NVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models using FP32, FP16, and INT8 quantization on clean and noisy datasets, we highlight the crucial trade-offs between accuracy, speeds, quantization, energy efficiency, and memory needs. We found that changing precision from fp32 to fp16 halves the energy consumption for audio transcription across different models, with minimal performance degradation. A larger model size and number of parameters neither guarantees better resilience to noise, nor predicts the energy consumption for a given transcription load. These, along with several other findings offer novel insights for optimizing ASR systems within energy- and memory-limited environments, crucial for the development of efficient on-device ASR solutions. The code and input data needed to reproduce the results in this article are open sourced are available on [this https URL].</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Spider: A Unified Framework for Context-dependent Concept Understanding</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01002">https://arxiv.org/abs/2405.01002</a></p>
  <p><b>作者</b>：Xiaoqi Zhao,  Youwei Pang,  Wei Ji,  Baicheng Sheng,  Jiaming Zuo,  Lihe Zhang,  Huchuan Lu</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：visual understanding ability, higher visual understanding, require higher visual, concepts require higher, higher visual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Different from the context-independent (CI) concepts such as human, car, and airplane, context-dependent (CD) concepts require higher visual understanding ability, such as camouflaged object and medical lesion. Despite the rapid advance of many CD understanding tasks in respective branches, the isolated evolution leads to their limited cross-domain generalisation and repetitive technique innovation. Since there is a strong coupling relationship between foreground and background context in CD tasks, existing methods require to train separate models in their focused domains. This restricts their real-world CD concept understanding towards artificial general intelligence (AGI). We propose a unified model with a single set of parameters, Spider, which only needs to be trained once. With the help of the proposed concept filter driven by the image-mask group prompt, Spider is able to understand and distinguish diverse strong context-dependent concepts to accurately capture the Prompter's intention. Without bells and whistles, Spider significantly outperforms the state-of-the-art specialized models in 8 different context-dependent segmentation tasks, including 4 natural scenes (salient, camouflaged, and transparent objects and shadow) and 4 medical lesions (COVID-19, polyp, breast, and skin lesion with color colonoscopy, CT, ultrasound, and dermoscopy modalities). Besides, Spider shows obvious advantages in continuous learning. It can easily complete the training of new tasks by fine-tuning parameters less than 1\% and bring a tolerable performance degradation of less than 5\% for all old tasks. The source code will be publicly available at \href{this https URL}{Spider-UniCDSeg}.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Estimate the building height at a 10-meter resolution based on Sentinel  data</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00989">https://arxiv.org/abs/2405.00989</a></p>
  <p><b>作者</b>：Xin Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Building height, Building, Shapley Additive Explanations, high-resolution building height, height</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building height is an important indicator for scientific research and practical application. However, building height products with a high spatial resolution (10m) are still very scarce. To meet the needs of high-resolution building height estimation models, this study established a set of spatial-spectral-temporal feature databases, combining SAR data provided by Sentinel-1, optical data provided by Sentinel-2, and shape data provided by building footprints. The statistical indicators on the time scale are extracted to form a rich database of 160 features. This study combined with permutation feature importance, Shapley Additive Explanations, and Random Forest variable importance, and the final stable features are obtained through an expert scoring system. This study took 12 large, medium, and small cities in the United States as the training data. It used moving windows to aggregate the pixels to solve the impact of SAR image displacement and building shadows. This study built a building height model based on a random forest model and compared three model ensemble methods of bagging, boosting, and stacking. To evaluate the accuracy of the prediction results, this study collected Lidar data in the test area, and the evaluation results showed that its R-Square reached 0.78, which can prove that the building height can be obtained effectively. The fast production of high-resolution building height data can support large-scale scientific research and application in many fields.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Context-Aware Clustering using Large Language Models</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00988">https://arxiv.org/abs/2405.00988</a></p>
  <p><b>作者</b>：Sindhu Tipirneni,  Ravinarayana Adkathimar,  Nurendra Choudhary,  Gaurush Hiranandani,  Rana Ali Amjad,  Vassilis N. Ioannidis,  Changhe Yuan,  Chandan K. Reddy</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：Large Language Models, success of Large, Large Language, tasks remains underexplored, clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the remarkable success of Large Language Models (LLMs) in text understanding and generation, their potential for text clustering tasks remains underexplored. We observed that powerful closed-source LLMs provide good quality clusterings of entity sets but are not scalable due to the massive compute power required and the associated costs. Thus, we propose CACTUS (Context-Aware ClusTering with aUgmented triplet losS), a systematic approach that leverages open-source LLMs for efficient and effective supervised clustering of entity subsets, particularly focusing on text-based entities. Existing text clustering methods fail to effectively capture the context provided by the entity subset. Moreover, though there are several language modeling based approaches for clustering, very few are designed for the task of supervised clustering. This paper introduces a novel approach towards clustering entity subsets using LLMs by capturing context via a scalable inter-entity attention mechanism. We propose a novel augmented triplet loss function tailored for supervised clustering, which addresses the inherent challenges of directly applying the triplet loss to this problem. Furthermore, we introduce a self-supervised clustering task based on text augmentation techniques to improve the generalization of our model. For evaluation, we collect ground truth clusterings from a closed-source LLM and transfer this knowledge to an open-source LLM under the supervised clustering framework, allowing a faster and cheaper open-source model to perform the same task. Experiments on various e-commerce query and product clustering datasets demonstrate that our proposed approach significantly outperforms existing unsupervised and supervised baselines under various external clustering evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：S$^2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor  Critic</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00987">https://arxiv.org/abs/2405.00987</a></p>
  <p><b>作者</b>：Safa Messaoud,  Billel Mokeddem,  Zhenghai Xue,  Linsey Pang,  Bo An,  Haipeng Chen,  Sanjay Chawla</p>
  <p><b>备注</b>：Accepted for publication at ICLR 2024</p>
  <p><b>关键词</b>：Learning expressive stochastic, Entropy Reinforcement Learning, Maximum Entropy Reinforcement, achieve better stability, expressive Energy-Based Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning expressive stochastic policies instead of deterministic ones has been proposed to achieve better stability, sample complexity, and robustness. Notably, in Maximum Entropy Reinforcement Learning (MaxEnt RL), the policy is modeled as an expressive Energy-Based Model (EBM) over the Q-values. However, this formulation requires the estimation of the entropy of such EBMs, which is an open problem. To address this, previous MaxEnt RL methods either implicitly estimate the entropy, resulting in high computational complexity and variance (SQL), or follow a variational inference procedure that fits simplified actor distributions (e.g., Gaussian) for tractability (SAC). We propose Stein Soft Actor-Critic (S$^2$AC), a MaxEnt RL algorithm that learns expressive policies without compromising efficiency. Specifically, S$^2$AC uses parameterized Stein Variational Gradient Descent (SVGD) as the underlying policy. We derive a closed-form expression of the entropy of such policies. Our formula is computationally efficient and only depends on first-order derivatives and vector products. Empirical results show that S$^2$AC yields more optimal solutions to the MaxEnt objective than SQL and SAC in the multi-goal environment, and outperforms SAC and SQL on the MuJoCo benchmark. Our code is available at: this https URL</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Progressive Feedforward Collapse of ResNet Training</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00985">https://arxiv.org/abs/2405.00985</a></p>
  <p><b>作者</b>：Sicong Wang,  Kuo Gai,  Shihua Zhang</p>
  <p><b>备注</b>：14 pages, 5 figures</p>
  <p><b>关键词</b>：deep neural networks, simplex equiangular tight, equiangular tight frame, tight frame aligning, last-layer features collapse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural collapse (NC) is a simple and symmetric phenomenon for deep neural networks (DNNs) at the terminal phase of training, where the last-layer features collapse to their class means and form a simplex equiangular tight frame aligning with the classifier vectors. However, the relationship of the last-layer features to the data and intermediate layers during training remains unexplored. To this end, we characterize the geometry of intermediate layers of ResNet and propose a novel conjecture, progressive feedforward collapse (PFC), claiming the degree of collapse increases during the forward propagation of DNNs. We derive a transparent model for the well-trained ResNet according to that ResNet with weight decay approximates the geodesic curve in Wasserstein space at the terminal phase. The metrics of PFC indeed monotonically decrease across depth on various datasets. We propose a new surrogate model, multilayer unconstrained feature model (MUFM), connecting intermediate layers by an optimal transport regularizer. The optimal solution of MUFM is inconsistent with NC but is more concentrated relative to the input data. Overall, this study extends NC to PFC to model the collapse phenomenon of intermediate layers and its dependence on the input data, shedding light on the theoretical understanding of ResNet in classification problems.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：FREE: Faster and Better Data-Free Meta-Learning</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00984">https://arxiv.org/abs/2405.00984</a></p>
  <p><b>作者</b>：Yongxian Wei,  Zixuan Hu,  Zhenyi Wang,  Li Shen,  Chun Yuan,  Dacheng Tao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：presenting practical benefits, data privacy concerns, pre-trained models, aims to extract, presenting practical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-Free Meta-Learning (DFML) aims to extract knowledge from a collection of pre-trained models without requiring the original data, presenting practical benefits in contexts constrained by data privacy concerns. Current DFML methods primarily focus on the data recovery from these pre-trained models. However, they suffer from slow recovery speed and overlook gaps inherent in heterogeneous pre-trained models. In response to these challenges, we introduce the Faster and Better Data-Free Meta-Learning (FREE) framework, which contains: (i) a meta-generator for rapidly recovering training tasks from pre-trained models; and (ii) a meta-learner for generalizing to new unseen tasks. Specifically, within the module Faster Inversion via Meta-Generator, each pre-trained model is perceived as a distinct task. The meta-generator can rapidly adapt to a specific task in just five steps, significantly accelerating the data recovery. Furthermore, we propose Better Generalization via Meta-Learner and introduce an implicit gradient alignment algorithm to optimize the meta-learner. This is achieved as aligned gradient directions alleviate potential conflicts among tasks from heterogeneous pre-trained models. Empirical experiments on multiple benchmarks affirm the superiority of our approach, marking a notable speed-up (20$\times$) and performance enhancement (1.42\% $\sim$ 4.78\%) in comparison to the state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：CACTUS: Chemistry Agent Connecting Tool-Usage to Science</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00972">https://arxiv.org/abs/2405.00972</a></p>
  <p><b>作者</b>：Andrew D. McNaughton,  Gautham Ramalaxmi,  Agustin Kruel,  Carter R. Knutson,  Rohith A. Varikoti,  Neeraj Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Chemistry Agent Connecting, Large language models, shown remarkable potential, Agent Connecting Tool-Usage, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Robust Decentralized Learning with Local Updates and Gradient Tracking</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00965">https://arxiv.org/abs/2405.00965</a></p>
  <p><b>作者</b>：Sajjad Ghiasvand,  Amirhossein Reisizadeh,  Mahnoosh Alizadeh,  Ramtin Pedarsani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Edge Computing grow, Internet of Things, Edge Computing, Computing grow, distributed learning applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As distributed learning applications such as Federated Learning, the Internet of Things (IoT), and Edge Computing grow, it is critical to address the shortcomings of such technologies from a theoretical perspective. As an abstraction, we consider decentralized learning over a network of communicating clients or nodes and tackle two major challenges: data heterogeneity and adversarial robustness. We propose a decentralized minimax optimization method that employs two important modules: local updates and gradient tracking. Minimax optimization is the key tool to enable adversarial training for ensuring robustness. Having local updates is essential in Federated Learning (FL) applications to mitigate the communication bottleneck, and utilizing gradient tracking is essential to proving convergence in the case of data heterogeneity. We analyze the performance of the proposed algorithm, Dec-FedTrack, in the case of nonconvex-strongly concave minimax optimization, and prove that it converges a stationary point. We also conduct numerical experiments to support our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Generative manufacturing systems using diffusion models and ChatGPT</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00958">https://arxiv.org/abs/2405.00958</a></p>
  <p><b>作者</b>：Xingyu Li,  Fei Tao,  Wei Ye,  Aydin Nassehi,  John W. Sutherland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：coordinate autonomous manufacturing, introduce Generative Manufacturing, autonomous manufacturing assets, Generative Manufacturing Systems, GMS employs generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we introduce Generative Manufacturing Systems (GMS) as a novel approach to effectively manage and coordinate autonomous manufacturing assets, thereby enhancing their responsiveness and flexibility to address a wide array of production objectives and human preferences. Deviating from traditional explicit modeling, GMS employs generative AI, including diffusion models and ChatGPT, for implicit learning from envisioned futures, marking a shift from a model-optimum to a training-sampling decision-making. Through the integration of generative AI, GMS enables complex decision-making through interactive dialogue with humans, allowing manufacturing assets to generate multiple high-quality global decisions that can be iteratively refined based on human feedback. Empirical findings showcase GMS's substantial improvement in system resilience and responsiveness to uncertainties, with decision times reduced from seconds to milliseconds. The study underscores the inherent creativity and diversity in the generated solutions, facilitating human-centric decision-making through seamless and continuous human-machine interactions.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：IntraMix: Intra-Class Mixup Generation for Accurate Labels and Neighbors</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00957">https://arxiv.org/abs/2405.00957</a></p>
  <p><b>作者</b>：Shenghe Zheng,  Hongzhi Wang,  Xianglong Liu</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, aggregating neighborhood information, Insufficient High-Quality Labels, demonstrate excellent performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) demonstrate excellent performance on graphs, with their core idea about aggregating neighborhood information and learning from labels. However, the prevailing challenges in most graph datasets are twofold of Insufficient High-Quality Labels and Lack of Neighborhoods, resulting in weak GNNs. Existing data augmentation methods designed to address these two issues often tackle only one. They may either require extensive training of generators, rely on overly simplistic strategies, or demand substantial prior knowledge, leading to suboptimal generalization abilities. To simultaneously address both of these two challenges, we propose an elegant method called IntraMix. IntraMix innovatively employs Mixup among low-quality labeled data of the same class, generating high-quality labeled data at minimal cost. Additionally, it establishes neighborhoods for the generated data by connecting them with data from the same class with high confidence, thereby enriching the neighborhoods of graphs. IntraMix efficiently tackles both challenges faced by graphs and challenges the prior notion of the limited effectiveness of Mixup in node classification. IntraMix serves as a universal framework that can be readily applied to all GNNs. Extensive experiments demonstrate the effectiveness of IntraMix across various GNNs and datasets.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Recovering Labels from Local Updates in Federated Learning</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00955">https://arxiv.org/abs/2405.00955</a></p>
  <p><b>作者</b>：Huancheng Chen,  Haris Vikalo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Gradient inversion, communicated model updates, federated learning, aiming to enable, enable reconstruction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient inversion (GI) attacks present a threat to the privacy of clients in federated learning (FL) by aiming to enable reconstruction of the clients' data from communicated model updates. A number of such techniques attempts to accelerate data recovery by first reconstructing labels of the samples used in local training. However, existing label extraction methods make strong assumptions that typically do not hold in realistic FL settings. In this paper we present a novel label recovery scheme, Recovering Labels from Local Updates (RLU), which provides near-perfect accuracy when attacking untrained (most vulnerable) models. More significantly, RLU achieves high performance even in realistic real-world settings where the clients in an FL system run multiple local epochs, train on heterogeneous data, and deploy various optimizers to minimize different objective functions. Specifically, RLU estimates labels by solving a least-square problem that emerges from the analysis of the correlation between labels of the data points used in a training round and the resulting update of the output layer. The experimental results on several datasets, architectures, and data heterogeneity scenarios demonstrate that the proposed method consistently outperforms existing baselines, and helps improve quality of the reconstructed images in GI attacks in terms of both PSNR and LPIPS.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Provably Efficient Reinforcement Learning for Adversarial Restless  Multi-Armed Bandits with Unknown Transitions and Bandit Feedback</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00950">https://arxiv.org/abs/2405.00950</a></p>
  <p><b>作者</b>：Guojun Xiong,  Jian Li</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：modeling sequential decision, sequential decision making, decision making problems, Restless multi-armed bandits, play a central</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Restless multi-armed bandits (RMAB) play a central role in modeling sequential decision making problems under an instantaneous activation constraint that at most B arms can be activated at any decision epoch. Each restless arm is endowed with a state that evolves independently according to a Markov decision process regardless of being activated or not. In this paper, we consider the task of learning in episodic RMAB with unknown transition functions and adversarial rewards, which can change arbitrarily across episodes. Further, we consider a challenging but natural bandit feedback setting that only adversarial rewards of activated arms are revealed to the decision maker (DM). The goal of the DM is to maximize its total adversarial rewards during the learning process while the instantaneous activation constraint must be satisfied in each decision epoch. We develop a novel reinforcement learning algorithm with two key contributors: a novel biased adversarial reward estimator to deal with bandit feedback and unknown transitions, and a low-complexity index policy to satisfy the instantaneous activation constraint. We show $\tilde{\mathcal{O}}(H\sqrt{T})$ regret bound for our algorithm, where $T$ is the number of episodes and $H$ is the episode length. To our best knowledge, this is the first algorithm to ensure $\tilde{\mathcal{O}}(\sqrt{T})$ regret for adversarial RMAB in our considered challenging settings.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：The Role of Model Architecture and Scale in Predicting Molecular  Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00949">https://arxiv.org/abs/2405.00949</a></p>
  <p><b>作者</b>：Lee Youngmin,  Lang S.I.D. Andrew,  Cai Duoduo,  Wheat R. Stephen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Line Entry System, Input Line Entry, efficacy of Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study introduces a systematic framework to compare the efficacy of Large Language Models (LLMs) for fine-tuning across various cheminformatics tasks. Employing a uniform training methodology, we assessed three well-known models-RoBERTa, BART, and LLaMA-on their ability to predict molecular properties using the Simplified Molecular Input Line Entry System (SMILES) as a universal molecular representation format. Our comparative analysis involved pre-training 18 configurations of these models, with varying parameter sizes and dataset scales, followed by fine-tuning them on six benchmarking tasks from DeepChem. We maintained consistent training environments across models to ensure reliable comparisons. This approach allowed us to assess the influence of model type, size, and training dataset size on model performance. Specifically, we found that LLaMA-based models generally offered the lowest validation loss, suggesting their superior adaptability across tasks and scales. However, we observed that absolute validation loss is not a definitive indicator of model performance - contradicts previous research - at least for fine-tuning tasks: instead, model size plays a crucial role. Through rigorous replication and validation, involving multiple training and fine-tuning cycles, our study not only delineates the strengths and limitations of each model type but also provides a robust methodology for selecting the most suitable LLM for specific cheminformatics applications. This research underscores the importance of considering model architecture and dataset characteristics in deploying AI for molecular property prediction, paving the way for more informed and effective utilization of AI in drug discovery and related fields.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：SparseTSF: Modeling Long-term Time Series Forecasting with 1k Parameters</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00946">https://arxiv.org/abs/2405.00946</a></p>
  <p><b>作者</b>：Shengsheng Lin,  Weiwei Lin,  Wentai Wu,  Haojun Chen,  Junjie Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Long-term Time Series, Time Series Forecasting, modeling complex temporal, complex temporal dependencies, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces SparseTSF, a novel, extremely lightweight model for Long-term Time Series Forecasting (LTSF), designed to address the challenges of modeling complex temporal dependencies over extended horizons with minimal computational resources. At the heart of SparseTSF lies the Cross-Period Sparse Forecasting technique, which simplifies the forecasting task by decoupling the periodicity and trend in time series data. This technique involves downsampling the original sequences to focus on cross-period trend prediction, effectively extracting periodic features while minimizing the model's complexity and parameter count. Based on this technique, the SparseTSF model uses fewer than 1k parameters to achieve competitive or superior performance compared to state-of-the-art models. Furthermore, SparseTSF showcases remarkable generalization capabilities, making it well-suited for scenarios with limited computational resources, small samples, or low-quality data. The code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：New bounds on the cohesion of complete-link and other linkage methods  for agglomeration clustering</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00937">https://arxiv.org/abs/2405.00937</a></p>
  <p><b>作者</b>：Sanjoy Dasgupta,  Eduardo Laber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithms for hierarchical, hierarchical clustering, Linkage methods, popular algorithms, methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linkage methods are among the most popular algorithms for hierarchical clustering. Despite their relevance the current knowledge regarding the quality of the clustering produced by these methods is limited. Here, we improve the currently available bounds on the maximum diameter of the clustering obtained by complete-link for metric spaces.
One of our new bounds, in contrast to the existing ones, allows us to separate complete-link from single-link in terms of approximation for the diameter, which corroborates the common perception that the former is more suitable than the latter when the goal is producing compact clusters.
We also show that our techniques can be employed to derive upper bounds on the cohesion of a class of linkage methods that includes the quite popular average-link.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：MTDT: A Multi-Task Deep Learning Digital Twin</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00922">https://arxiv.org/abs/2405.00922</a></p>
  <p><b>作者</b>：Nooshin Yousefzadeh,  Rahul Sengupta,  Yashaswi Karnati,  Anand Rangarajan,  Sanjay Ranka</p>
  <p><b>备注</b>：8 pages, 2 figures, 4 tables</p>
  <p><b>关键词</b>：congestion has significant, significant impacts, Learning Digital Twin, MTDT, Traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traffic congestion has significant impacts on both the economy and the environment. Measures of Effectiveness (MOEs) have long been the standard for evaluating the level of service and operational efficiency of traffic intersections. However, the scarcity of traditional high-resolution loop detector data (ATSPM) presents challenges in accurately measuring MOEs or capturing the intricate temporospatial characteristics inherent in urban intersection traffic. In response to this challenge, we have introduced the Multi-Task Deep Learning Digital Twin (MTDT) as a solution for multifaceted and precise intersection traffic flow simulation. MTDT enables accurate, fine-grained estimation of loop detector waveform time series for each lane of movement, alongside successful estimation of several MOEs for each lane group associated with a traffic phase concurrently and for all approaches of an arbitrary urban intersection. Unlike existing deep learning methodologies, MTDT distinguishes itself through its adaptability to local temporal and spatial features, such as signal timing plans, intersection topology, driving behaviors, and turning movement counts. While maintaining a straightforward design, our model emphasizes the advantages of multi-task learning in traffic modeling. By consolidating the learning process across multiple tasks, MTDT demonstrates reduced overfitting, increased efficiency, and enhanced effectiveness by sharing representations learned by different tasks. Furthermore, our approach facilitates sequential computation and lends itself to complete parallelization through GPU implementation. This not only streamlines the computational process but also enhances scalability and performance.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：EchoScene: Indoor Scene Generation via Information Echo over Scene Graph  Diffusion</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00915">https://arxiv.org/abs/2405.00915</a></p>
  <p><b>作者</b>：Guangyao Zhai,  Evin Pınar Örnek,  Dave Zhenyu Chen,  Ruotong Liao,  Yan Di,  Nassir Navab,  Federico Tombari,  Benjamin Busam</p>
  <p><b>备注</b>：25 pages. 10 figures</p>
  <p><b>关键词</b>：controllable generative model, scene, present EchoScene, scene graphs, controllable generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present EchoScene, an interactive and controllable generative model that generates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch diffusion model that dynamically adapts to scene graphs. Existing methods struggle to handle scene graphs due to varying numbers of nodes, multiple edge combinations, and manipulator-induced node-edge operations. EchoScene overcomes this by associating each node with a denoising process and enables collaborative information exchange, enhancing controllable and consistent generation aware of global constraints. This is achieved through an information echo scheme in both shape and layout branches. At every denoising step, all processes share their denoising data with an information exchange unit that combines these updates using graph convolution. The scheme ensures that the denoising processes are influenced by a holistic understanding of the scene graph, facilitating the generation of globally coherent scenes. The resulting scenes can be manipulated during inference by editing the input scene graph and sampling the noise in the diffusion model. Extensive experiments validate our approach, which maintains scene controllability and surpasses previous methods in generation fidelity. Moreover, the generated scenes are of high quality and thus directly compatible with off-the-shelf texture generation. Code and trained models are open-sourced.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：De-Biasing Models of Biased Decisions: A Comparison of Methods Using  Mortgage Application Data</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00910">https://arxiv.org/abs/2405.00910</a></p>
  <p><b>作者</b>：Nicholas Tenev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improve efficiency, efficiency by automating, approval of loan, prohibited variables, loan applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prediction models can improve efficiency by automating decisions such as the approval of loan applications. However, they may inherit bias against protected groups from the data they are trained on. This paper adds counterfactual (simulated) ethnic bias to real data on mortgage application decisions, and shows that this bias is replicated by a machine learning model (XGBoost) even when ethnicity is not used as a predictive variable. Next, several other de-biasing methods are compared: averaging over prohibited variables, taking the most favorable prediction over prohibited variables (a novel method), and jointly minimizing errors as well as the association between predictions and prohibited variables. De-biasing can recover some of the original decisions, but the results are sensitive to whether the bias is effected through a proxy.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Quantum Federated Learning Experiments in the Cloud with Data Encoding</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00909">https://arxiv.org/abs/2405.00909</a></p>
  <p><b>作者</b>：Shiva Raj Pokhrel,  Naman Yash,  Jonathan Kua,  Gang Li,  Lei Pan</p>
  <p><b>备注</b>：SIGCOMM 2024, Quantum Computing, Federated Learning, Qiskit</p>
  <p><b>关键词</b>：unfold federated learning, Quantum Federated Learning, Federated Learning, local data privacy, enabling collaborative quantum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantum Federated Learning (QFL) is an emerging concept that aims to unfold federated learning (FL) over quantum networks, enabling collaborative quantum model training along with local data privacy. We explore the challenges of deploying QFL on cloud platforms, emphasizing quantum intricacies and platform limitations. The proposed data-encoding-driven QFL, with a proof of concept (GitHub Open Source) using genomic data sets on quantum simulators, shows promising results.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Transformer-Based Self-Supervised Learning for Histopathological  Classification of Ischemic Stroke Clot Origin</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00908">https://arxiv.org/abs/2405.00908</a></p>
  <p><b>作者</b>：K. Yeh,  M. S. Jabal,  V. Gupta,  D. F. Kallmes,  W. Brinjikji,  B. S. Erdal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Background and Purpose, ischemic stroke, ischemic stroke clot, thromboembolism source, crucial for treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background and Purpose: Identifying the thromboembolism source in ischemic stroke is crucial for treatment and secondary prevention yet is often undetermined. This study describes a self-supervised deep learning approach in digital pathology of emboli for classifying ischemic stroke clot origin from histopathological images. Methods: The dataset included whole slide images (WSI) from the STRIP AI Kaggle challenge, consisting of retrieved clots from ischemic stroke patients following mechanical thrombectomy. Transformer-based deep learning models were developed using transfer learning and self-supervised pretraining for classifying WSI. Customizations included an attention pooling layer, weighted loss function, and threshold optimization. Various model architectures were tested and compared, and model performances were primarily evaluated using weighted logarithmic loss. Results: The model achieved a logloss score of 0.662 in cross-validation and 0.659 on the test set. Different model backbones were compared, with the swin_large_patch4_window12_384 showed higher performance. Thresholding techniques for clot origin classification were employed to balance false positives and negatives. Conclusion: The study demonstrates the extent of efficacy of transformer-based deep learning models in identifying ischemic stroke clot origins from histopathological images and emphasizes the need for refined modeling techniques specifically adapted to thrombi WSI. Further research is needed to improve model performance, interpretability, validate its effectiveness. Future enhancement could include integrating larger patient cohorts, advanced preprocessing strategies, and exploring ensemble multimodal methods for enhanced diagnostic accuracy.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data  Lottery Tickets</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00906">https://arxiv.org/abs/2405.00906</a></p>
  <p><b>作者</b>：Ojasw Upadhyay</p>
  <p><b>备注</b>：3 pages, 5 figures</p>
  <p><b>关键词</b>：demands present challenges, revolutionized computer vision, vision transformer training, computational demands present, vision transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformers have revolutionized computer vision, but their computational demands present challenges for training and deployment. This paper introduces LOTUS (LOttery Transformers with Ultra Sparsity), a novel method that leverages data lottery ticket selection and sparsity pruning to accelerate vision transformer training while maintaining accuracy. Our approach focuses on identifying and utilizing the most informative data subsets and eliminating redundant model parameters to optimize the training process. Through extensive experiments, we demonstrate the effectiveness of LOTUS in achieving rapid convergence and high accuracy with significantly reduced computational requirements. This work highlights the potential of combining data selection and sparsity techniques for efficient vision transformer training, opening doors for further research and development in this area.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：MESA: Cooperative Meta-Exploration in Multi-Agent Learning through  Exploiting State-Action Space Structure</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00902">https://arxiv.org/abs/2405.00902</a></p>
  <p><b>作者</b>：Zhicheng Zhang,  Yancheng Liang,  Yi Wu,  Fei Fang</p>
  <p><b>备注</b>：Accepted to AAMAS 2024. 15 pages</p>
  <p><b>关键词</b>：optimal Nash Equilibrium, Pareto optimal Nash, Nash Equilibrium, find strategies close, close to Pareto</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent reinforcement learning (MARL) algorithms often struggle to find strategies close to Pareto optimal Nash Equilibrium, owing largely to the lack of efficient exploration. The problem is exacerbated in sparse-reward settings, caused by the larger variance exhibited in policy learning. This paper introduces MESA, a novel meta-exploration method for cooperative multi-agent learning. It learns to explore by first identifying the agents' high-rewarding joint state-action subspace from training tasks and then learning a set of diverse exploration policies to "cover" the subspace. These trained exploration policies can be integrated with any off-policy MARL algorithm for test-time tasks. We first showcase MESA's advantage in a multi-step matrix game. Furthermore, experiments show that with learned exploration policies, MESA achieves significantly better performance in sparse-reward tasks in several multi-agent particle environments and multi-agent MuJoCo environments, and exhibits the ability to generalize to more challenging tasks at test time.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：WHALE-FL: Wireless and Heterogeneity Aware Latency Efficient Federated  Learning over Mobile Devices via Adaptive Subnetwork Scheduling</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00885">https://arxiv.org/abs/2405.00885</a></p>
  <p><b>作者</b>：Huai-an Su,  Jiaxiang Geng,  Liang Li,  Xiaoqi Qin,  Yanzhao Hou,  Xin Fu,  Miao Pan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fosters numerous applications, devices fosters numerous, distributed learning paradigm, local training, popular distributed learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a popular distributed learning paradigm, federated learning (FL) over mobile devices fosters numerous applications, while their practical deployment is hindered by participating devices' computing and communication heterogeneity. Some pioneering research efforts proposed to extract subnetworks from the global model, and assign as large a subnetwork as possible to the device for local training based on its full computing and communications capacity. Although such fixed size subnetwork assignment enables FL training over heterogeneous mobile devices, it is unaware of (i) the dynamic changes of devices' communication and computing conditions and (ii) FL training progress and its dynamic requirements of local training contributions, both of which may cause very long FL training delay. Motivated by those dynamics, in this paper, we develop a wireless and heterogeneity aware latency efficient FL (WHALE-FL) approach to accelerate FL training through adaptive subnetwork scheduling. Instead of sticking to the fixed size subnetwork, WHALE-FL introduces a novel subnetwork selection utility function to capture device and FL training dynamics, and guides the mobile device to adaptively select the subnetwork size for local training based on (a) its computing and communication capacity, (b) its dynamic computing and/or communication conditions, and (c) FL training status and its corresponding requirements for local training contributions. Our evaluation shows that, compared with peer designs, WHALE-FL effectively accelerates FL training without sacrificing learning accuracy.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Machine Learning Techniques for Data Reduction of Climate Applications</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00879">https://arxiv.org/abs/2405.00879</a></p>
  <p><b>作者</b>：Xiao Li,  Qian Gong,  Jaemoon Lee,  Scott Klasky,  Anand Rangarajan,  Sanjay Ranka</p>
  <p><b>备注</b>：7 pages. arXiv admin note: text overlap with arXiv:2404.18063</p>
  <p><b>关键词</b>：Scientists conduct large-scale, conduct large-scale simulations, Scientists conduct, compute derived, conduct large-scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scientists conduct large-scale simulations to compute derived quantities-of-interest (QoI) from primary data. Often, QoI are linked to specific features, regions, or time intervals, such that data can be adaptively reduced without compromising the integrity of QoI. For many spatiotemporal applications, these QoI are binary in nature and represent presence or absence of a physical phenomenon. We present a pipelined compression approach that first uses neural-network-based techniques to derive regions where QoI are highly likely to be present. Then, we employ a Guaranteed Autoencoder (GAE) to compress data with differential error bounds. GAE uses QoI information to apply low-error compression to only these regions. This results in overall high compression ratios while still achieving downstream goals of simulation or data collections. Experimental results are presented for climate data generated from the E3SM Simulation model for downstream quantities such as tropical cyclone and atmospheric river detection and tracking. These results show that our approach is superior to comparable methods in the literature.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Markov flow policy -- deep MC</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00877">https://arxiv.org/abs/2405.00877</a></p>
  <p><b>作者</b>：Nitsan Soffair,  Gilad Katz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impose undesired temporal, undesired temporal discounts, encounter evaluation errors, evaluation errors due, short-term estimations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discounted algorithms often encounter evaluation errors due to their reliance on short-term estimations, which can impede their efficacy in addressing simple, short-term tasks and impose undesired temporal discounts (\(\gamma\)). Interestingly, these algorithms are often tested without applying a discount, a phenomenon we refer as the \textit{train-test bias}. In response to these challenges, we propose the Markov Flow Policy, which utilizes a non-negative neural network flow to enable comprehensive forward-view predictions. Through integration into the TD7 codebase and evaluation using the MuJoCo benchmark, we observe significant performance improvements, positioning MFP as a straightforward, practical, and easily implementable solution within the domain of average rewards algorithms.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Beyond Human Vision: The Role of Large Vision Language Models in  Microscope Image Analysis</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00876">https://arxiv.org/abs/2405.00876</a></p>
  <p><b>作者</b>：Prateek Verma,  Minh-Hao Van,  Xintao Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vision language models, Vision language, emerged and gained, gained the spotlight, dual modality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision language models (VLMs) have recently emerged and gained the spotlight for their ability to comprehend the dual modality of image and textual data. VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive performance on tasks such as natural image captioning, visual question answering (VQA), and spatial reasoning. Additionally, a universal segmentation model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance at isolating objects from unforeseen images. Since medical experts, biologists, and materials scientists routinely examine microscopy or medical images in conjunction with textual information in the form of captions, literature, or reports, and draw conclusions of great importance and merit, it is indubitably essential to test the performance of VLMs and foundation models such as SAM, on these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with classification, segmentation, counting, and VQA tasks on a variety of microscopy images. We observe that ChatGPT and Gemini are impressively able to comprehend the visual features in microscopy images, while SAM is quite capable at isolating artefacts in a general sense. However, the performance is not close to that of a domain expert - the models are readily encumbered by the introduction of impurities, defects, artefact overlaps and diversity present in the images.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Learning to Boost the Performance of Stable Nonlinear Systems</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00871">https://arxiv.org/abs/2405.00871</a></p>
  <p><b>作者</b>：Luca Furieri,  Clara Lucía Galimberti,  Giancarlo Ferrari-Trecate</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unparalleled performances achievable, evolve current control, current control architectures, control architectures aiming, machine learning algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The growing scale and complexity of safety-critical control systems underscore the need to evolve current control architectures aiming for the unparalleled performances achievable through state-of-the-art optimization and machine learning algorithms. However, maintaining closed-loop stability while boosting the performance of nonlinear control systems using data-driven and deep-learning approaches stands as an important unsolved challenge. In this paper, we tackle the performance-boosting problem with closed-loop stability guarantees. Specifically, we establish a synergy between the Internal Model Control (IMC) principle for nonlinear systems and state-of-the-art unconstrained optimization approaches for learning stable dynamics. Our methods enable learning over arbitrarily deep neural network classes of performance-boosting controllers for stable nonlinear systems; crucially, we guarantee Lp closed-loop stability even if optimization is halted prematurely, and even when the ground-truth dynamics are unknown, with vanishing conservatism in the class of stabilizing policies as the model uncertainty is reduced to zero. We discuss the implementation details of the proposed control schemes, including distributed ones, along with the corresponding optimization procedures, demonstrating the potential of freely shaping the cost functions through several numerical experiments.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Efficient Algorithms for Learning Monophonic Halfspaces in Graphs</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00853">https://arxiv.org/abs/2405.00853</a></p>
  <p><b>作者</b>：Marco Bressan,  Emmanuel Esposito,  Maximilian Thiessen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：monophonic halfspaces, binary classifier, monophonic, learning monophonic halfspaces, halfspaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of learning a binary classifier on the vertices of a graph. In particular, we consider classifiers given by monophonic halfspaces, partitions of the vertices that are convex in a certain abstract sense. Monophonic halfspaces, and related notions such as geodesic halfspaces,have recently attracted interest, and several connections have been drawn between their properties(e.g., their VC dimension) and the structure of the underlying graph $G$. We prove several novel results for learning monophonic halfspaces in the supervised, online, and active settings. Our main result is that a monophonic halfspace can be learned with near-optimal passive sample complexity in time polynomial in $n = |V(G)|$. This requires us to devise a polynomial-time algorithm for consistent hypothesis checking, based on several structural insights on monophonic halfspaces and on a reduction to $2$-satisfiability. We prove similar results for the online and active settings. We also show that the concept class can be enumerated with delay $\operatorname{poly}(n)$, and that empirical risk minimization can be performed in time $2^{\omega(G)}\operatorname{poly}(n)$ where $\omega(G)$ is the clique number of $G$. These results answer open questions from the literature (González et al., 2020), and show a contrast with geodesic halfspaces, for which some of the said problems are NP-hard (Seiffarth et al., 2023).</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Gameplay Filters: Safe Robot Walking through Adversarial Imagination</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00846">https://arxiv.org/abs/2405.00846</a></p>
  <p><b>作者</b>：Duy P. Nguyen,  Kai-Chieh Hsu,  Wenhao Yu,  Jie Tan,  Jaime F. Fisac</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Ensuring the safe, widespread adoption, safe operation, environments is crucial, legged robot locomotion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensuring the safe operation of legged robots in uncertain, novel environments is crucial to their widespread adoption. Despite recent advances in safety filters that can keep arbitrary task-driven policies from incurring safety failures, existing solutions for legged robot locomotion still rely on simplified dynamics and may fail when the robot is perturbed away from predefined stable gaits. This paper presents a general approach that leverages offline game-theoretic reinforcement learning to synthesize a highly robust safety filter for high-order nonlinear dynamics. This gameplay filter then maintains runtime safety by continually simulating adversarial futures and precluding task-driven actions that would cause it to lose future games (and thereby violate safety). Validated on a 36-dimensional quadruped robot locomotion task, the gameplay safety filter exhibits inherent robustness to the sim-to-real gap without manual tuning or heuristic designs. Physical experiments demonstrate the effectiveness of the gameplay safety filter under perturbations, such as tugging and unmodeled irregular terrains, while simulation studies shed light on how to trade off computation and conservativeness without compromising safety.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Communication-Efficient Training Workload Balancing for Decentralized  Multi-Agent Learning</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00839">https://arxiv.org/abs/2405.00839</a></p>
  <p><b>作者</b>：Seyed Mahmoud Sajjadi Mohammadabadi,  Lei Yang,  Feng Yan,  Junshan Zhang</p>
  <p><b>备注</b>：This paper has been accepted for presentation at ICDCS (44th IEEE International Conference on Distributed Computing Systems). Keywords: decentralized multi-agent learning, federated learning, edge computing, heterogeneous agents, workload balancing, and communication-efficient training )</p>
  <p><b>关键词</b>：Decentralized Multi-agent Learning, Multi-agent Learning, training time, training, Decentralized Multi-agent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized Multi-agent Learning (DML) enables collaborative model training while preserving data privacy. However, inherent heterogeneity in agents' resources (computation, communication, and task size) may lead to substantial variations in training time. This heterogeneity creates a bottleneck, lengthening the overall training time due to straggler effects and potentially wasting spare resources of faster agents. To minimize training time in heterogeneous environments, we present a Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning (ComDML), which balances the workload among agents through a decentralized approach. Leveraging local-loss split training, ComDML enables parallel updates, where slower agents offload part of their workload to faster agents. To minimize the overall training time, ComDML optimizes the workload balancing by jointly considering the communication and computation capacities of agents, which hinges upon integer programming. A dynamic decentralized pairing scheduler is developed to efficiently pair agents and determine optimal offloading amounts. We prove that in ComDML, both slower and faster agents' models converge, for convex and non-convex functions. Furthermore, extensive experimental results on popular datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-I.I.D. variants, with large models such as ResNet-56 and ResNet-110, demonstrate that ComDML can significantly reduce the overall training time while maintaining model accuracy, compared to state-of-the-art methods. ComDML demonstrates robustness in heterogeneous environments, and privacy measures can be seamlessly integrated for enhanced data protection.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Locality Regularized Reconstruction: Structured Sparsity and Delaunay  Triangulations</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00837">https://arxiv.org/abs/2405.00837</a></p>
  <p><b>作者</b>：Marshall Mueller,  James M. Murphy,  Abiy Tasissa</p>
  <p><b>备注</b>：26 pages, 8 figures</p>
  <p><b>关键词</b>：mathbf, Linear representation learning, widely studied due, Linear representation, feature extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear representation learning is widely studied due to its conceptual simplicity and empirical utility in tasks such as compression, classification, and feature extraction. Given a set of points $[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n] = \mathbf{X} \in \mathbb{R}^{d \times n}$ and a vector $\mathbf{y} \in \mathbb{R}^d$, the goal is to find coefficients $\mathbf{w} \in \mathbb{R}^n$ so that $\mathbf{X} \mathbf{w} \approx \mathbf{y}$, subject to some desired structure on $\mathbf{w}$. In this work we seek $\mathbf{w}$ that forms a local reconstruction of $\mathbf{y}$ by solving a regularized least squares regression problem. We obtain local solutions through a locality function that promotes the use of columns of $\mathbf{X}$ that are close to $\mathbf{y}$ when used as a regularization term. We prove that, for all levels of regularization and under a mild condition that the columns of $\mathbf{X}$ have a unique Delaunay triangulation, the optimal coefficients' number of non-zero entries is upper bounded by $d+1$, thereby providing local sparse solutions when $d \ll n$. Under the same condition we also show that for any $\mathbf{y}$ contained in the convex hull of $\mathbf{X}$ there exists a regime of regularization parameter such that the optimal coefficients are supported on the vertices of the Delaunay simplex containing $\mathbf{y}$. This provides an interpretation of the sparsity as having structure obtained implicitly from the Delaunay triangulation of $\mathbf{X}$. We demonstrate that our locality regularized problem can be solved in comparable time to other methods that identify the containing Delaunay simplex.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：HLSFactory: A Framework Empowering High-Level Synthesis Datasets for  Machine Learning and Beyond</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00820">https://arxiv.org/abs/2405.00820</a></p>
  <p><b>作者</b>：Stefan Abi-Karam,  Rishov Sarkar,  Allison Seigler,  Sean Lowe,  Zhigang Wei,  Hanqiu Chen,  Nanditha Rao,  Lizy John,  Aman Arora,  Cong Hao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：HLS, design space, HLS designs, design, design space exploration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) techniques have been applied to high-level synthesis (HLS) flows for quality-of-result (QoR) prediction and design space exploration (DSE). Nevertheless, the scarcity of accessible high-quality HLS datasets and the complexity of building such datasets present challenges. Existing datasets have limitations in terms of benchmark coverage, design space enumeration, vendor extensibility, or lack of reproducible and extensible software for dataset construction. Many works also lack user-friendly ways to add more designs, limiting wider adoption of such datasets.
In response to these challenges, we introduce HLSFactory, a comprehensive framework designed to facilitate the curation and generation of high-quality HLS design datasets. HLSFactory has three main stages: 1) a design space expansion stage to elaborate single HLS designs into large design spaces using various optimization directives across multiple vendor tools, 2) a design synthesis stage to execute HLS and FPGA tool flows concurrently across designs, and 3) a data aggregation stage for extracting standardized data into packaged datasets for ML usage. This tripartite architecture ensures broad design space coverage via design space expansion and supports multiple vendor tools. Users can contribute to each stage with their own HLS designs and synthesis results and extend the framework itself with custom frontends and tool flows. We also include an initial set of built-in designs from common HLS benchmarks curated open-source HLS designs.
We showcase the versatility and multi-functionality of our framework through six case studies: I) Design space sampling; II) Fine-grained parallelism backend speedup; III) Targeting Intel's HLS flow; IV) Adding new auxiliary designs; V) Integrating published HLS data; VI) HLS tool version regression benchmarking.
Code at this https URL.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：ICU Bloodstream Infection Prediction: A Transformer-Based Approach for  EHR Analysis</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00819">https://arxiv.org/abs/2405.00819</a></p>
  <p><b>作者</b>：Ortal Hirszowicz,  Dvir Aran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：electronic health records, intensive care unit, transformer-based framework designed, EHR data, Graph Convolutional Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce RatchetEHR, a novel transformer-based framework designed for the predictive analysis of electronic health records (EHR) data in intensive care unit (ICU) settings, with a specific focus on bloodstream infection (BSI) prediction. Leveraging the MIMIC-IV dataset, RatchetEHR demonstrates superior predictive performance compared to other methods, including RNN, LSTM, and XGBoost, particularly due to its advanced handling of sequential and temporal EHR data. A key innovation in RatchetEHR is the integration of the Graph Convolutional Transformer (GCT) component, which significantly enhances the ability to identify hidden structural relationships within EHR data, resulting in more accurate clinical predictions. Through SHAP value analysis, we provide insights into influential features for BSI prediction. RatchetEHR integrates multiple advancements in deep learning which together provide accurate predictions even with a relatively small sample size and highly imbalanced dataset. This study contributes to medical informatics by showcasing the application of advanced AI techniques in healthcare and sets a foundation for further research to optimize these capabilities in EHR data analysis.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Sifting out communities in large sparse networks</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00816">https://arxiv.org/abs/2405.00816</a></p>
  <p><b>作者</b>：Sharlee Climer,  Kenneth Smith Jr,  Wei Yang,  Lisa de las Fuentes,  Victor G. Dávila-Román,  C. Charles Gu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Research data sets, extract complex relationships, involved in disease, sets are growing, growing to unprecedented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research data sets are growing to unprecedented sizes and network modeling is commonly used to extract complex relationships in diverse domains, such as genetic interactions involved in disease, logistics, and social communities. As the number of nodes increases in a network, an increasing sparsity of edges is a practical limitation due to memory restrictions. Moreover, many of these sparse networks exhibit very large numbers of nodes with no adjacent edges, as well as disjoint components of nodes with no edges connecting them. A prevalent aim in network modeling is the identification of clusters, or communities, of nodes that are highly interrelated. Several definitions of strong community structure have been introduced to facilitate this task, each with inherent assumptions and biases. We introduce an intuitive objective function for quantifying the quality of clustering results in large sparse networks. We utilize a two-step method for identifying communities which is especially well-suited for this domain as the first step efficiently divides the network into the disjoint components, while the second step optimizes clustering of the produced components based on the new objective. Using simulated networks, optimization based on the new objective function consistently yields significantly higher accuracy than those based on the modularity function, with the widest gaps appearing for the noisiest networks. Additionally, applications to benchmark problems illustrate the intuitive correctness of our approach. Finally, the practicality of our approach is demonstrated in real-world data in which we identify complex genetic interactions in large-scale networks comprised of tens of thousands of nodes. Based on these three different types of trials, our results clearly demonstrate the usefulness of our two-step procedure and the accuracy of our simple objective.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Error Exponent in Agnostic PAC Learning</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00792">https://arxiv.org/abs/2405.00792</a></p>
  <p><b>作者</b>：Adi Hendel,  Meir Feder</p>
  <p><b>备注</b>：paper with appendix to accepted ISIT2024 paper with the same name</p>
  <p><b>关键词</b>：Approximately Correct, Statistical learning theory, mathematical learning theory, common approach, approach to mathematical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Statistical learning theory and the Probably Approximately Correct (PAC) criterion are the common approach to mathematical learning theory. PAC is widely used to analyze learning problems and algorithms, and have been studied thoroughly. Uniform worst case bounds on the convergence rate have been well established using, e.g., VC theory or Radamacher complexity. However, in a typical scenario the performance could be much better. In this paper, we consider PAC learning using a somewhat different tradeoff, the error exponent - a well established analysis method in Information Theory - which describes the exponential behavior of the probability that the risk will exceed a certain threshold as function of the sample size. We focus on binary classification and find, under some stability assumptions, an improved distribution dependent error exponent for a wide range of problems, establishing the exponential behavior of the PAC error probability in agnostic learning. Interestingly, under these assumptions, agnostic learning may have the same error exponent as realizable learning. The error exponent criterion can be applied to analyze knowledge distillation, a problem that so far lacks a theoretical analysis.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet  Module Accelerators</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00790">https://arxiv.org/abs/2405.00790</a></p>
  <p><b>作者</b>：Mohanad Odema,  Luke Chen,  Hyoukjun Kwon,  Mohammad Abdullah Al Faruque</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent large language, large language models, language models significantly, models significantly increased, heterogeneous dataflow MCM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emerging multi-model workloads with heavy models like recent large language models significantly increased the compute and memory demands on hardware. To address such increasing demands, designing a scalable hardware architecture became a key problem. Among recent solutions, the 2.5D silicon interposer multi-chip module (MCM)-based AI accelerator has been actively explored as a promising scalable solution due to their significant benefits in the low engineering cost and composability. However, previous MCM accelerators are based on homogeneous architectures with fixed dataflow, which encounter major challenges from highly heterogeneous multi-model workloads due to their limited workload adaptivity. Therefore, in this work, we explore the opportunity in the heterogeneous dataflow MCM AI accelerators. We identify the scheduling of multi-model workload on heterogeneous dataflow MCM AI accelerator is an important and challenging problem due to its significance and scale, which reaches O(10^18) scale even for a single model case on 6x6 chiplets. We develop a set of heuristics to navigate the huge scheduling space and codify them into a scheduler with advanced techniques such as inter-chiplet pipelining. Our evaluation on ten multi-model workload scenarios for datacenter multitenancy and AR/VR use-cases has shown the efficacy of our approach, achieving on average 35.3% and 31.4% less energy-delay product (EDP) for the respective applications settings compared to homogeneous baselines.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Quantum AI for Alzheimer's disease early screening</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00755">https://arxiv.org/abs/2405.00755</a></p>
  <p><b>作者</b>：Giacomo Cappiello,  Filippo Caruso</p>
  <p><b>备注</b>：18 pages, 6 figures</p>
  <p><b>关键词</b>：research field combining, field combining quantum, combining quantum information, quantum information science, research field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantum machine learning is a new research field combining quantum information science and machine learning. Quantum computing technologies seem to be particularly well suited to solving problems in the health sector in an efficient way, because they may deal with large datasets more efficiently than classical AI.
Alzheimer's disease is a neurodegenerative brain disorder that mostly affects elderly people, causing important cognitive impairments. It is the most common cause of dementia and it has an effect on memory, thought, learning abilities and movement control. This type of disease has no cure, consequently an early diagnosis is fundamental for reducing its impact. The analysis of handwriting can be effective for diagnosing, as many researches have conjectured. The DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset contains handwriting samples from people affected by Alzheimer's disease and a group of healthy people. Here we apply quantum AI to this use-case. In particular, we use this dataset to test kernel methods for classification task and compare their performances with the ones obtained via quantum machine learning methods. We find that quantum and classical algorithms achieve similar performances and in some cases quantum methods perform even better.
Our results pave the way for future new quantum machine learning applications in early-screening diagnostics in the healthcare domain.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：CLIPArTT: Light-weight Adaptation of CLIP to New Domains at Test Time</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00754">https://arxiv.org/abs/2405.00754</a></p>
  <p><b>作者</b>：Gustavo Adolfo Vargas Hakim,  David Osowiechi,  Mehrdad Noori,  Milad Cheraghalikhani,  Ali Bahri,  Moslem Yazdanpanah,  Ismail Ben Ayed,  Christian Desrosiers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Pre-trained vision-language models, zero-shot classification tasks, Pre-trained vision-language, vision-language models, zero-shot classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained vision-language models (VLMs), exemplified by CLIP, demonstrate remarkable adaptability across zero-shot classification tasks without additional training. However, their performance diminishes in the presence of domain shifts. In this study, we introduce CLIP Adaptation duRing Test-Time (CLIPArTT), a fully test-time adaptation (TTA) approach for CLIP, which involves automatic text prompts construction during inference for their use as text supervision. Our method employs a unique, minimally invasive text prompt tuning process, wherein multiple predicted classes are aggregated into a single new text prompt, used as pseudo label to re-classify inputs in a transductive manner. Additionally, we pioneer the standardization of TTA benchmarks (e.g., TENT) in the realm of VLMs. Our findings demonstrate that, without requiring additional transformations nor new trainable modules, CLIPArTT enhances performance dynamically across non-corrupted datasets such as CIFAR-10, corrupted datasets like CIFAR-10-C and CIFAR-10.1, alongside synthetic datasets such as VisDA-C. This research underscores the potential for improving VLMs' adaptability through novel test-time strategies, offering insights for robust performance across varied datasets and environments. The code can be found at: this https URL</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：More is Better: Deep Domain Adaptation with Multiple Sources</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00749">https://arxiv.org/abs/2405.00749</a></p>
  <p><b>作者</b>：Sicheng Zhao,  Hui Chen,  Hu Huang,  Pengfei Xu,  Guiguang Ding</p>
  <p><b>备注</b>：Accepted by IJCAI 2024. arXiv admin note: text overlap with arXiv:2002.12169</p>
  <p><b>关键词</b>：obtain large-scale labeled, deep neural networks, neural networks, difficult and expensive, expensive to obtain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many practical applications, it is often difficult and expensive to obtain large-scale labeled data to train state-of-the-art deep neural networks. Therefore, transferring the learned knowledge from a separate, labeled source domain to an unlabeled or sparsely labeled target domain becomes an appealing alternative. However, direct transfer often results in significant performance decay due to domain shift. Domain adaptation (DA) aims to address this problem by aligning the distributions between the source and target domains. Multi-source domain adaptation (MDA) is a powerful and practical extension in which the labeled data may be collected from multiple sources with different distributions. In this survey, we first define various MDA strategies. Then we systematically summarize and compare modern MDA methods in the deep learning era from different perspectives, followed by commonly used datasets and a brief benchmark. Finally, we discuss future research directions for MDA that are worth investigating.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Soft Preference Optimization: Aligning Language Models to Expert  Distributions</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00747">https://arxiv.org/abs/2405.00747</a></p>
  <p><b>作者</b>：Arsalan Sharifnassab,  Sina Ghiassian,  Saber Salehkaleybar,  Surya Kanoria,  Dale Schuurmans</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Soft Preference Optimization, Large Language Models, propose Soft Preference, Large Language, propose Soft</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Soft Preference Optimization (SPO), a method for aligning generative models, such as Large Language Models (LLMs), with human preferences, without the need for a reward model. SPO optimizes model outputs directly over a preference dataset through a natural loss function that integrates preference loss with a regularization term across the model's entire output distribution rather than limiting it to the preference dataset. Although SPO does not require the assumption of an existing underlying reward model, we demonstrate that, under the Bradley-Terry (BT) model assumption, it converges to a softmax of scaled rewards, with the distribution's "softness" adjustable via the softmax exponent, an algorithm parameter. We showcase SPO's methodology, its theoretical foundation, and its comparative advantages in simplicity, computational efficiency, and alignment precision.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00746">https://arxiv.org/abs/2405.00746</a></p>
  <p><b>作者</b>：Calarina Muslimani,  Matthew E. Taylor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：create useful reinforcement, design a suitable, captures the nuances, reward, suitable reward function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To create useful reinforcement learning (RL) agents, step zero is to design a suitable reward function that captures the nuances of the task. However, reward engineering can be a difficult and time-consuming process. Instead, human-in-the-loop (HitL) RL allows agents to learn reward functions from human feedback. Despite recent successes, many of the HitL RL methods still require numerous human interactions to learn successful reward functions. To improve the feedback efficiency of HitL RL methods (i.e., require less feedback), this paper introduces Sub-optimal Data Pre-training, SDP, an approach that leverages reward-free, sub-optimal data to improve scalar- and preference-based HitL RL algorithms. In SDP, we start by pseudo-labeling all low-quality data with rewards of zero. Through this process, we obtain free reward labels to pre-train our reward model. This pre-training phase provides the reward model a head start in learning, whereby it can identify that low-quality transitions should have a low reward, all without any actual feedback. Through extensive experiments with a simulated teacher, we demonstrate that SDP can significantly improve or achieve competitive performance with state-of-the-art (SOTA) HitL RL algorithms across nine robotic manipulation and locomotion tasks.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：On the weight dynamics of learning networks</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00743">https://arxiv.org/abs/2405.00743</a></p>
  <p><b>作者</b>：Nahal Sharafi,  Christoph Martin,  Sarah Hallerberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely adopted tool, artificial intelligence, widely adopted, adopted tool, tool for tackling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have become a widely adopted tool for tackling a variety of problems in machine learning and artificial intelligence. In this contribution we use the mathematical framework of local stability analysis to gain a deeper understanding of the learning dynamics of feed forward neural networks. Therefore, we derive equations for the tangent operator of the learning dynamics of three-layer networks learning regression tasks. The results are valid for an arbitrary numbers of nodes and arbitrary choices of activation functions. Applying the results to a network learning a regression task, we investigate numerically, how stability indicators relate to the final training-loss. Although the specific results vary with different choices of initial conditions and activation functions, we demonstrate that it is possible to predict the final training loss, by monitoring finite-time Lyapunov exponents or covariant Lyapunov vectors during the training process.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Federated Graph Learning for EV Charging Demand Forecasting with  Personalization Against Cyberattacks</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00742">https://arxiv.org/abs/2405.00742</a></p>
  <p><b>作者</b>：Yi Li,  Renyou Xie,  Chaojie Li,  Yi Wang,  Zhaoyang Dong</p>
  <p><b>备注</b>：11 pages,4 figures</p>
  <p><b>关键词</b>：Mitigating cybersecurity risk, cost-effective infrastructure expansion, demand forecasting plays, Mitigating cybersecurity, electric vehicle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mitigating cybersecurity risk in electric vehicle (EV) charging demand forecasting plays a crucial role in the safe operation of collective EV chargings, the stability of the power grid, and the cost-effective infrastructure expansion. However, existing methods either suffer from the data privacy issue and the susceptibility to cyberattacks or fail to consider the spatial correlation among different stations. To address these challenges, a federated graph learning approach involving multiple charging stations is proposed to collaboratively train a more generalized deep learning model for demand forecasting while capturing spatial correlations among various stations and enhancing robustness against potential attacks. Firstly, for better model performance, a Graph Neural Network (GNN) model is leveraged to characterize the geographic correlation among different charging stations in a federated manner. Secondly, to ensure robustness and deal with the data heterogeneity in a federated setting, a message passing that utilizes a global attention mechanism to aggregate personalized models for each client is proposed. Thirdly, by concerning cyberattacks, a special credit-based function is designed to mitigate potential threats from malicious clients or unwanted attacks. Extensive experiments on a public EV charging dataset are conducted using various deep learning techniques and federated learning methods to demonstrate the prediction accuracy and robustness of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Modeling Caption Diversity in Contrastive Vision-Language Pretraining</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00740">https://arxiv.org/abs/2405.00740</a></p>
  <p><b>作者</b>：Samuel Lavoie,  Polina Kirichenko,  Mark Ibrahim,  Mahmoud Assran,  Andrew Gordon Wildon,  Aaron Courville,  Nicolas Ballas</p>
  <p><b>备注</b>：14 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：Language Image Pretraining, Latent Language Image, Contrastive Language Pretraining, Language Pretraining, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are a thousand ways to caption an image. Contrastive Language Pretraining (CLIP) on the other hand, works by mapping an image and its caption to a single vector -- limiting how well CLIP-like models can represent the diverse ways to describe an image. In this work, we introduce Llip, Latent Language Image Pretraining, which models the diversity of captions that could match an image. Llip's vision encoder outputs a set of visual features that are mixed into a final representation by conditioning on information derived from the text. We show that Llip outperforms non-contextualized baselines like CLIP and SigLIP on a variety of tasks even with large-scale encoders. Llip improves zero-shot classification by an average of 2.9% zero-shot classification benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by 1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by 6.0%. We provide a comprehensive analysis of the components introduced by the method and demonstrate that Llip leads to richer visual representations.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Why does Knowledge Distillation Work? Rethink its Attention and Fidelity  Mechanism</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00739">https://arxiv.org/abs/2405.00739</a></p>
  <p><b>作者</b>：Chenqi Guo,  Shiwei Zhong,  Xiaofeng Liu,  Qianli Feng,  Yinglong Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge Distillation, Distillation, knowledge transfer procedure, student, Knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Does Knowledge Distillation (KD) really work? Conventional wisdom viewed it as a knowledge transfer procedure where a perfect mimicry of the student to its teacher is desired. However, paradoxical studies indicate that closely replicating the teacher's behavior does not consistently improve student generalization, posing questions on its possible causes. Confronted with this gap, we hypothesize that diverse attentions in teachers contribute to better student generalization at the expense of reduced fidelity in ensemble KD setups. By increasing data augmentation strengths, our key findings reveal a decrease in the Intersection over Union (IoU) of attentions between teacher models, leading to reduced student overfitting and decreased fidelity. We propose this low-fidelity phenomenon as an underlying characteristic rather than a pathology when training KD. This suggests that stronger data augmentation fosters a broader perspective provided by the divergent teacher ensemble and lower student-teacher mutual information, benefiting generalization performance. These insights clarify the mechanism on low-fidelity phenomenon in KD. Thus, we offer new perspectives on optimizing student model performance, by emphasizing increased diversity in teacher attentions and reduced mimicry behavior between teachers and student.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level  Synthesis</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00738">https://arxiv.org/abs/2405.00738</a></p>
  <p><b>作者</b>：Andy He,  Darren Key,  Mason Bulling,  Andrew Chang,  Skyler Shapiro,  Everett Lee</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：Graphics Processing Units, Large Language Models, modern Large Language, Processing Units, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphics Processing Units (GPUs) have become the leading hardware accelerator for deep learning applications and are used widely in training and inference of transformers; transformers have achieved state-of-the-art performance in many areas of machine learning and are especially used in most modern Large Language Models (LLMs). However, GPUs require large amounts of energy, which poses environmental concerns, demands high operational costs, and causes GPUs to be unsuitable for edge computing. We develop an accelerator for transformers, namely, Llama 2, an open-source state-of-the-art LLM, using high level synthesis (HLS) on Field Programmable Gate Arrays (FPGAs). HLS allows us to rapidly prototype FPGA designs without writing code at the register-transfer level (RTL). We name our method HLSTransform, and the FPGA designs we synthesize with HLS achieve up to a 12.75x reduction and 8.25x reduction in energy used per token on the Xilinx Virtex UltraScale+ VU9P FPGA compared to an Intel Xeon Broadwell E5-2686 v4 CPU and NVIDIA RTX 3090 GPU respectively, while increasing inference speeds by up to 2.46x compared to CPU and maintaining 0.53x the speed of an RTX 3090 GPU despite the GPU's 4 times higher base clock rate. With the lack of existing open-source FPGA accelerators for transformers, we open-source our code and document our steps for synthesis. We hope this work will serve as a step in democratizing the use of FPGAs in transformer inference and inspire research into energy-efficient inference methods as a whole. The code can be found on this https URL.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00732">https://arxiv.org/abs/2405.00732</a></p>
  <p><b>作者</b>：Justin Zhao,  Timothy Wang,  Wael Abid,  Geoffrey Angus,  Arnav Garg,  Jeffery Kinnison,  Alex Sherstinsky,  Piero Molino,  Travis Addair,  Devvret Rishi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Parameter Efficient Fine-Tuning, Low Rank Adaptation, widely adopted methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted methods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models (LLMs). LoRA reduces the number of trainable parameters and memory usage while achieving comparable performance to full fine-tuning. We aim to assess the viability of training and serving LLMs fine-tuned with LoRA in real-world applications. First, we measure the quality of LLMs fine-tuned with quantized low rank adapters across 10 base models and 31 tasks for a total of 310 models. We find that 4-bit LoRA fine-tuned models outperform base models by 34 points and GPT-4 by 10 points on average. Second, we investigate the most effective base models for fine-tuning and assess the correlative and predictive capacities of task complexity heuristics in forecasting the outcomes of fine-tuning. Finally, we evaluate the latency and concurrency capabilities of LoRAX, an open-source Multi-LoRA inference server that facilitates the deployment of multiple LoRA fine-tuned models on a single GPU using shared base model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA A100 GPU with 80GB memory. LoRA Land highlights the quality and cost-effectiveness of employing multiple specialized LLMs over a single, general-purpose LLM.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Towards Adapting Open-Source Large Language Models for Expert-Level  Clinical Note Generation</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00715">https://arxiv.org/abs/2405.00715</a></p>
  <p><b>作者</b>：Hanyin Wang,  Chufan Gao,  Bolun Liu,  Qiping Xu,  Guleid Hussein,  Mohamad El Labban,  Kingsley Iheasirim,  Hariprasad Korsapati,  Jimeng Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown promising capabilities, Large Language, Language Models, text summarization tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have shown promising capabilities in handling clinical text summarization tasks. In this study, we demonstrate that a small open-source LLM can be effectively trained to generate high-quality clinical notes from outpatient patient-doctor dialogues. We achieve this through a comprehensive domain- and task-specific adaptation process for the LLaMA-2 13 billion parameter model. This process incorporates continued pre-training, supervised fine-tuning, and reinforcement learning from both AI and human feedback. We introduced an enhanced approach, termed DistillDirect, for performing on-policy reinforcement learning with Gemini Pro serving as the teacher model. Our resulting model, LLaMA-Clinic, is capable of generating clinical notes that are comparable in quality to those authored by physicians. In a blinded physician reader study, the majority (90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as "acceptable" or higher across all three criteria: real-world readiness, completeness, and accuracy. Notably, in the more challenging "Assessment and Plan" section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness compared to physician-authored notes (4.1/5). Additionally, we identified caveats in public clinical note datasets, such as ACI-BENCH. We highlight key considerations for future clinical note-generation tasks, emphasizing the importance of pre-defining a best-practice note format. Overall, our research demonstrates the potential and feasibility of training smaller, open-source LLMs to assist with clinical documentation, capitalizing on healthcare institutions' access to patient records and domain expertise. We have made our newly created synthetic clinic dialogue-note dataset and the physician feedback dataset publicly available to foster future research in this field.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Homonym Sense Disambiguation in the Georgian Language</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00710">https://arxiv.org/abs/2405.00710</a></p>
  <p><b>作者</b>：Davit Melikidze,  Alexander Gamkrelidze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Common Crawls corpus, Georgian Common Crawls, Large Language Model, Common Crawls, pre-trained Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research proposes a novel approach to the Word Sense Disambiguation (WSD) task in the Georgian language, based on supervised fine-tuning of a pre-trained Large Language Model (LLM) on a dataset formed by filtering the Georgian Common Crawls corpus. The dataset is used to train a classifier for words with multiple senses. Additionally, we present experimental results of using LSTM for WSD. Accurately disambiguating homonyms is crucial in natural language processing. Georgian, an agglutinative language belonging to the Kartvelian language family, presents unique challenges in this context. The aim of this paper is to highlight the specific problems concerning homonym disambiguation in the Georgian language and to present our approach to solving them. The techniques discussed in the article achieve 95% accuracy for predicting lexical meanings of homonyms using a hand-classified dataset of over 7500 sentences.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Evaluating Tool-Augmented Agents in Remote Sensing Platforms</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00709">https://arxiv.org/abs/2405.00709</a></p>
  <p><b>作者</b>：Simranjit Singh,  Michael Fore,  Dimitrios Stamoulis</p>
  <p><b>备注</b>：ICLR 2024 Machine Learning for Remote Sensing (ML4RS) Workshop</p>
  <p><b>关键词</b>：Large Language Models, Tool-augmented Large Language, Language Models, shown impressive capabilities, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user-grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask "Detect all objects here". Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., the live map positioning? To bridge this gap, we present GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights towards stronger agents for RS applications.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Interactive Analysis of LLMs using Meaningful Counterfactuals</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00708">https://arxiv.org/abs/2405.00708</a></p>
  <p><b>作者</b>：Furui Cheng,  Vilém Zouhar,  Robin Shing Moon Chan,  Daniel Fürst,  Hendrik Strobelt,  Mennatallah El-Assady</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determining feature attributions, machine learning models, feature attributions, exploring the decision, decision boundaries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Counterfactual examples are useful for exploring the decision boundaries of machine learning models and determining feature attributions. How can we apply counterfactual-based methods to analyze and explain LLMs? We identify the following key challenges. First, the generated textual counterfactuals should be meaningful and readable to users and thus can be mentally compared to draw conclusions. Second, to make the solution scalable to long-form text, users should be equipped with tools to create batches of counterfactuals from perturbations at various granularity levels and interactively analyze the results. In this paper, we tackle the above challenges and contribute 1) a novel algorithm for generating batches of complete and meaningful textual counterfactuals by removing and replacing text segments in different granularities, and 2) LLM Analyzer, an interactive visualization tool to help users understand an LLM's behaviors by interactively inspecting and aggregating meaningful counterfactuals. We evaluate the proposed algorithm by the grammatical correctness of its generated counterfactuals using 1,000 samples from medical, legal, finance, education, and news datasets. In our experiments, 97.2% of the counterfactuals are grammatically correct. Through a use case, user studies, and feedback from experts, we demonstrate the usefulness and usability of the proposed interactive visualization tool.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：SHED: Shapley-Based Automated Dataset Refinement for Instruction  Fine-Tuning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00705">https://arxiv.org/abs/2405.00705</a></p>
  <p><b>作者</b>：Yexiao He,  Ziyao Wang,  Zheyu Shen,  Guoheng Sun,  Yucong Dai,  Yongkai Wu,  Hongyi Wang,  Ang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, pre-trained Large Language, Language Models, Large Language, pre-trained Large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The pre-trained Large Language Models (LLMs) can be adapted for many downstream tasks and tailored to align with human preferences through fine-tuning. Recent studies have discovered that LLMs can achieve desirable performance with only a small amount of high-quality data, suggesting that a large amount of the data in these extensive datasets is redundant or even harmful. Identifying high-quality data from vast datasets to curate small yet effective datasets has emerged as a critical challenge. In this paper, we introduce SHED, an automated dataset refinement framework based on Shapley value for instruction fine-tuning. SHED eliminates the need for human intervention or the use of commercial LLMs. Moreover, the datasets curated through SHED exhibit transferability, indicating they can be reused across different LLMs with consistently high performance. We conduct extensive experiments to evaluate the datasets curated by SHED. The results demonstrate SHED's superiority over state-of-the-art methods across various tasks and LLMs; notably, datasets comprising only 10% of the original data selected by SHED achieve performance comparable to or surpassing that of the full datasets.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Direct Training Needs Regularisation: Anytime Optimal Inference Spiking  Neural Network</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00699">https://arxiv.org/abs/2405.00699</a></p>
  <p><b>作者</b>：Dengyu Wu,  Yi Qi,  Kaiwen Cai,  Gaojie Jin,  Xinping Yi,  Xiaowei Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Neural Network, Spiking Neural Network, Neural Network, hold great promise, Artificial Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Network (SNN) is acknowledged as the next generation of Artificial Neural Network (ANN) and hold great promise in effectively processing spatial-temporal information. However, the choice of timestep becomes crucial as it significantly impacts the accuracy of the neural network training. Specifically, a smaller timestep indicates better performance in efficient computing, resulting in reduced latency and operations. While, using a small timestep may lead to low accuracy due to insufficient information presentation with few spikes. This observation motivates us to develop an SNN that is more reliable for adaptive timestep by introducing a novel regularisation technique, namely Spatial-Temporal Regulariser (STR). Our approach regulates the ratio between the strength of spikes and membrane potential at each timestep. This effectively balances spatial and temporal performance during training, ultimately resulting in an Anytime Optimal Inference (AOI) SNN. Through extensive experiments on frame-based and event-based datasets, our method, in combination with cutoff based on softmax output, achieves state-of-the-art performance in terms of both latency and accuracy. Notably, with STR and cutoff, SNN achieves 2.14 to 2.89 faster in inference compared to the pre-configured timestep with near-zero accuracy drop of 0.50% to 0.64% over the event-based datasets. Code available: this https URL</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Joint torques prediction of a robotic arm using neural networks</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00695">https://arxiv.org/abs/2405.00695</a></p>
  <p><b>作者</b>：Giulia d'Addato,  Ruggero Carli,  Eurico Pedrosa,  Artur Pereira,  Luigi Palopoli,  Daniele Fontanelli</p>
  <p><b>备注</b>：6 pages, 5 figures, submitted to CASE 2024</p>
  <p><b>关键词</b>：Accurate dynamic models, Accurate dynamic, robotic applications, dynamic models, Lagrangian or Newtonian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate dynamic models are crucial for many robotic applications. Traditional approaches to deriving these models are based on the application of Lagrangian or Newtonian mechanics. Although these methods provide a good insight into the physical behaviour of the system, they rely on the exact knowledge of parameters such as inertia, friction and joint flexibility. In addition, the system is often affected by uncertain and nonlinear effects, such as saturation and dead zones, which can be difficult to model. A popular alternative is the application of Machine Learning (ML) techniques - e.g., Neural Networks (NNs) - in the context of a "black-box" methodology. This paper reports on our experience with this approach for a real-life 6 degrees of freedom (DoF) manipulator. Specifically, we considered several NN architectures: single NN, multiple NNs, and cascade NN. We compared the performance of the system by using different policies for selecting the NN hyperparameters. Our experiments reveal that the best accuracy and performance are obtained by a cascade NN, in which we encode our prior physical knowledge about the dependencies between joints, complemented by an appropriate optimisation of the hyperparameters.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Understanding Social Perception, Interactions, and Safety Aspects of  Sidewalk Delivery Robots Using Sentiment Analysis</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00688">https://arxiv.org/abs/2405.00688</a></p>
  <p><b>作者</b>：Yuchen Du,  Tho V. Le</p>
  <p><b>备注</b>：34 pages, 7 figures, 2 tables</p>
  <p><b>关键词</b>：Sidewalk Delivery Robots, Delivery Robots, Sidewalk Delivery, YouTube videos related, comprehensive sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article presents a comprehensive sentiment analysis (SA) of comments on YouTube videos related to Sidewalk Delivery Robots (SDRs). We manually annotated the collected YouTube comments with three sentiment labels: negative (0), positive (1), and neutral (2). We then constructed models for text sentiment classification and tested the models' performance on both binary and ternary classification tasks in terms of accuracy, precision, recall, and F1 score. Our results indicate that, in binary classification tasks, the Support Vector Machine (SVM) model using Term Frequency-Inverse Document Frequency (TF-IDF) and N-gram get the highest accuracy. In ternary classification tasks, the model using Bidirectional Encoder Representations from Transformers (BERT), Long Short-Term Memory Networks (LSTM) and Gated Recurrent Unit (GRU) significantly outperforms other machine learning models, achieving an accuracy, precision, recall, and F1 score of 0.78. Additionally, we employ the Latent Dirichlet Allocation model to generate 10 topics from the comments to explore the public's underlying views on SDRs. Drawing from these findings, we propose targeted recommendations for shaping future policies concerning SDRs. This work provides valuable insights for stakeholders in the SDR sector regarding social perception, interaction, and safety.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：FeNNol: an Efficient and Flexible Library for Building  Force-field-enhanced Neural Network Potentials</b></summary>
  <p><b>编号</b>：[416]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01491">https://arxiv.org/abs/2405.01491</a></p>
  <p><b>作者</b>：Thomas Plé,  Olivier Adjoua,  Louis Lagardère,  Jean-Philip Piquemal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high numerical cost, accurately model complex, Neural network interatomic, ab-initio molecular dynamics, network interatomic potentials</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network interatomic potentials (NNPs) have recently proven to be powerful tools to accurately model complex molecular systems while bypassing the high numerical cost of ab-initio molecular dynamics simulations. In recent years, numerous advances in model architectures as well as the development of hybrid models combining machine-learning (ML) with more traditional, physically-motivated, force-field interactions have considerably increased the design space of ML potentials. In this paper, we present FeNNol, a new library for building, training and running force-field-enhanced neural network potentials. It provides a flexible and modular system for building hybrid models, allowing to easily combine state-of-the-art embeddings with ML-parameterized physical interaction terms without the need for explicit programming. Furthermore, FeNNol leverages the automatic differentiation and just-in-time compilation features of the Jax Python library to enable fast evaluation of NNPs, shrinking the performance gap between ML potentials and standard force-fields. This is demonstrated with the popular ANI-2x model reaching simulation speeds nearly on par with the AMOEBA polarizable force-field on commodity GPUs (GPU=Graphics processing unit). We hope that FeNNol will facilitate the development and application of new hybrid NNP architectures for a wide range of molecular simulation problems.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Dynamic Local Average Treatment Effects</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01463">https://arxiv.org/abs/2405.01463</a></p>
  <p><b>作者</b>：Ravi B. Sojitra,  Vasilis Syrgkanis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dynamic Treatment Regimes, adaptive medical trials, Treatment Regimes, Local Average Treatment, Average Treatment Effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider Dynamic Treatment Regimes (DTRs) with one sided non-compliance that arise in applications such as digital recommendations and adaptive medical trials. These are settings where decision makers encourage individuals to take treatments over time, but adapt encouragements based on previous encouragements, treatments, states, and outcomes. Importantly, individuals may choose to (not) comply with a treatment recommendation, whenever it is made available to them, based on unobserved confounding factors. We provide non-parametric identification, estimation, and inference for Dynamic Local Average Treatment Effects, which are expected values of multi-period treatment contrasts among appropriately defined complier subpopulations. Under standard assumptions in the Instrumental Variable and DTR literature, we show that one can identify local average effects of contrasts that correspond to offering treatment at any single time step. Under an additional cross-period effect-compliance independence assumption, which is satisfied in Staggered Adoption settings and a generalization of them, which we define as Staggered Compliance settings, we identify local average treatment effects of treating in multiple time periods.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Random Pareto front surfaces</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01404">https://arxiv.org/abs/2405.01404</a></p>
  <p><b>作者</b>：Ben Tu,  Nikolas Kantas,  Robert M. Lee,  Behrang Shafei</p>
  <p><b>备注</b>：The code is available at: this https URL</p>
  <p><b>关键词</b>：Pareto front surface, Pareto front, Pareto, front surface, front</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Pareto front of a set of vectors is the subset which is comprised solely of all of the best trade-off points. By interpolating this subset, we obtain the optimal trade-off surface. In this work, we prove a very useful result which states that all Pareto front surfaces can be explicitly parametrised using polar coordinates. In particular, our polar parametrisation result tells us that we can fully characterise any Pareto front surface using the length function, which is a scalar-valued function that returns the projected length along any positive radial direction. Consequently, by exploiting this representation, we show how it is possible to generalise many useful concepts from linear algebra, probability and statistics, and decision theory to function over the space of Pareto front surfaces. Notably, we focus our attention on the stochastic setting where the Pareto front surface itself is a stochastic process. Among other things, we showcase how it is possible to define and estimate many statistical quantities of interest such as the expectation, covariance and quantile of any Pareto front surface distribution. As a motivating example, we investigate how these statistics can be used within a design of experiments setting, where the goal is to both infer and use the Pareto front surface distribution in order to make effective decisions. Besides this, we also illustrate how these Pareto front ideas can be used within the context of extreme value theory. Finally, as a numerical example, we applied some of our new methodology on a real-world air pollution data set.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Koopman Data-Driven Predictive Control with Robust Stability and  Recursive Feasibility Guarantees</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01292">https://arxiv.org/abs/2405.01292</a></p>
  <p><b>作者</b>：Thomas de Jong,  Valentina Breschi,  Maarten Schoukens,  Mircea Lazar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：input Koopman lifted, Koopman lifted models, Koopman data-driven predictive, input Koopman, Koopman</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider the design of data-driven predictive controllers for nonlinear systems from input-output data via linear-in-control input Koopman lifted models. Instead of identifying and simulating a Koopman model to predict future outputs, we design a subspace predictive controller in the Koopman space. This allows us to learn the observables minimizing the multi-step output prediction error of the Koopman subspace predictor, preventing the propagation of prediction errors. To avoid losing feasibility of our predictive control scheme due to prediction errors, we compute a terminal cost and terminal set in the Koopman space and we obtain recursive feasibility guarantees through an interpolated initial state. As a third contribution, we introduce a novel regularization cost yielding input-to-state stability guarantees with respect to the prediction error for the resulting closed-loop system. The performance of the developed Koopman data-driven predictive control methodology is illustrated on a nonlinear benchmark example from the literature.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Mathematics of Differential Machine Learning in Derivative Pricing and  Hedging</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01233">https://arxiv.org/abs/2405.01233</a></p>
  <p><b>作者</b>：Pedro Duarte Gomes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：differential machine learning, machine learning algorithm, machine learning, financial machine learning, rigorous mathematical framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article introduces the groundbreaking concept of the financial differential machine learning algorithm through a rigorous mathematical framework. Diverging from existing literature on financial machine learning, the work highlights the profound implications of theoretical assumptions within financial models on the construction of machine learning algorithms.
This endeavour is particularly timely as the finance landscape witnesses a surge in interest towards data-driven models for the valuation and hedging of derivative products. Notably, the predictive capabilities of neural networks have garnered substantial attention in both academic research and practical financial applications.
The approach offers a unified theoretical foundation that facilitates comprehensive comparisons, both at a theoretical level and in experimental outcomes. Importantly, this theoretical grounding lends substantial weight to the experimental results, affirming the differential machine learning method's optimality within the prevailing context.
By anchoring the insights in rigorous mathematics, the article bridges the gap between abstract financial concepts and practical algorithmic implementations.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Investigating Self-Supervised Image Denoising with Denaturation</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01124">https://arxiv.org/abs/2405.01124</a></p>
  <p><b>作者</b>：Hiroki Waida,  Kimihiro Yamazaki,  Atsushi Tokuhisa,  Mutsuyo Wada,  Yuichiro Wada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, denatured data, noisy data, crucial approach, Self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning for image denoising problems in the presence of denaturation for noisy data is a crucial approach in machine learning. However, theoretical understanding of the performance of the approach that uses denatured data is lacking. To provide better understanding of the approach, in this paper, we analyze a self-supervised denoising algorithm that uses denatured data in depth through theoretical analysis and numerical experiments. Through the theoretical analysis, we discuss that the algorithm finds desired solutions to the optimization problem with the population risk, while the guarantee for the empirical risk depends on the hardness of the denoising task in terms of denaturation levels. We also conduct several experiments to investigate the performance of an extended algorithm in practice. The results indicate that the algorithm training with denatured images works, and the empirical performance aligns with the theoretical results. These results suggest several insights for further improvement of self-supervised image denoising that uses denatured data in future directions.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Multivariate trace estimation using quantum state space linear algebra</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01098">https://arxiv.org/abs/2405.01098</a></p>
  <p><b>作者</b>：Liron Mor Yosef,  Shashanka Ubaru,  Lior Horesh,  Haim Avron</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：state preparation circuits, approximating multivariate traces, state preparation, multivariate trace, multivariate trace formula</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a quantum algorithm for approximating multivariate traces, i.e. the traces of matrix products. Our research is motivated by the extensive utility of multivariate traces in elucidating spectral characteristics of matrices, as well as by recent advancements in leveraging quantum computing for faster numerical linear algebra. Central to our approach is a direct translation of a multivariate trace formula into a quantum circuit, achieved through a sequence of low-level circuit construction operations. To facilitate this translation, we introduce \emph{quantum Matrix States Linear Algebra} (qMSLA), a framework tailored for the efficient generation of state preparation circuits via primitive matrix algebra operations. Our algorithm relies on sets of state preparation circuits for input matrices as its primary inputs and yields two state preparation circuits encoding the multivariate trace as output. These circuits are constructed utilizing qMSLA operations, which enact the aforementioned multivariate trace formula. We emphasize that our algorithm's inputs consist solely of state preparation circuits, eschewing harder to synthesize constructs such as Block Encodings. Furthermore, our approach operates independently of the availability of specialized hardware like QRAM, underscoring its versatility and practicality.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Network reconstruction via the minimum description length principle</b></summary>
  <p><b>编号</b>：[439]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01015">https://arxiv.org/abs/2405.01015</a></p>
  <p><b>作者</b>：Tiago P. Peixoto</p>
  <p><b>备注</b>：17 pages, 10 figures</p>
  <p><b>关键词</b>：behavioral data consists, statistically justifiable number, fundamental problem, dynamical or behavioral, consists in determining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A fundamental problem associated with the task of network reconstruction from dynamical or behavioral data consists in determining the most appropriate model complexity in a manner that prevents overfitting, and produces an inferred network with a statistically justifiable number of edges. The status quo in this context is based on $L_{1}$ regularization combined with cross-validation. As we demonstrate, besides its high computational cost, this commonplace approach unnecessarily ties the promotion of sparsity with weight "shrinkage". This combination forces a trade-off between the bias introduced by shrinkage and the network sparsity, which often results in substantial overfitting even after cross-validation. In this work, we propose an alternative nonparametric regularization scheme based on hierarchical Bayesian inference and weight quantization, which does not rely on weight shrinkage to promote sparsity. Our approach follows the minimum description length (MDL) principle, and uncovers the weight distribution that allows for the most compression of the data, thus avoiding overfitting without requiring cross-validation. The latter property renders our approach substantially faster to employ, as it requires a single fit to the complete data. As a result, we have a principled and efficient inference scheme that can be used with a large variety of generative models, without requiring the number of edges to be known in advance. We also demonstrate that our scheme yields systematically increased accuracy in the reconstruction of both artificial and empirical networks. We highlight the use of our method with the reconstruction of interaction networks between microbial communities from large-scale abundance samples involving in the order of $10^{4}$ to $10^{5}$ species, and demonstrate how the inferred model can be used to predict the outcome of interventions in the system.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Deriving Lehmer and Hölder means as maximum weighted likelihood  estimates for the multivariate exponential family</b></summary>
  <p><b>编号</b>：[441]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00964">https://arxiv.org/abs/2405.00964</a></p>
  <p><b>作者</b>：Djemel Ziou,  Issam Fakir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：univariate exponential family, weighted maximum likelihood, maximum likelihood estimator, regular univariate exponential, Lehmer and Hölder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The links between the mean families of Lehmer and Hölder and the weighted maximum likelihood estimator have recently been established in the case of a regular univariate exponential family. In this article, we will extend the outcomes obtained to the multivariate case. This extension provides a probabilistic interpretation of these families of means and could therefore broaden their uses in various applications.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Benchmarking Representations for Speech, Music, and Acoustic Events</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00934">https://arxiv.org/abs/2405.00934</a></p>
  <p><b>作者</b>：Moreno La Quatra,  Alkis Koudounas,  Lorenzo Vaiani,  Elena Baralis,  Luca Cagliero,  Paolo Garza,  Sabato Marco Siniscalchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hinder systematic comparison, audio representation learning, current methods' capabilities, Limited diversity, representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Limited diversity in standardized benchmarks for evaluating audio representation learning (ARL) methods may hinder systematic comparison of current methods' capabilities. We present ARCH, a comprehensive benchmark for evaluating ARL methods on diverse audio classification domains, covering acoustic events, music, and speech. ARCH comprises 12 datasets, that allow us to thoroughly assess pre-trained SSL models of different sizes. ARCH streamlines benchmarking of ARL techniques through its unified access to a wide range of domains and its ability to readily incorporate new datasets and models. To address the current lack of open-source, pre-trained models for non-speech audio, we also release new pre-trained models that demonstrate strong performance on non-speech datasets. We argue that the presented wide-ranging evaluation provides valuable insights into state-of-the-art ARL methods, and is useful to pinpoint promising research directions.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Accelerated Fully First-Order Methods for Bilevel and Minimax  Optimization</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00914">https://arxiv.org/abs/2405.00914</a></p>
  <p><b>作者</b>：Chris Junchi Li</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2307.00126</p>
  <p><b>关键词</b>：Restarted Accelerated Fully, Restarted Accelerated, Accelerated Fully First-order, accelerating first-order methods, Fully First-order methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new algorithm member for accelerating first-order methods for bilevel optimization, namely the \emph{(Perturbed) Restarted Accelerated Fully First-order methods for Bilevel Approximation}, abbreviated as \texttt{(P)RAF${}^2$BA}. The algorithm leverages \emph{fully} first-order oracles and seeks approximate stationary points in nonconvex-strongly-convex bilevel optimization, enhancing oracle complexity for efficient optimization. Theoretical guarantees for finding approximate first-order stationary points and second-order stationary points at the state-of-the-art query complexities are established, showcasing their effectiveness in solving complex optimization tasks. Empirical studies for real-world problems are provided to further validate the outperformance of our proposed algorithms. The significance of \texttt{(P)RAF${}^2$BA} in optimizing nonconvex-strongly-convex bilevel optimization problems is underscored by its state-of-the-art convergence rates and computational efficiency.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Quickest Change Detection with Confusing Change</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00842">https://arxiv.org/abs/2405.00842</a></p>
  <p><b>作者</b>：Yu-Zhen Janice Chen,  Jinhang Zuo,  Venugopal V. Veeravalli,  Don Towsley</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bad change, confusing change, change, confusing change distributions, independent observations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the problem of quickest change detection (QCD), a change occurs at some unknown time in the distribution of a sequence of independent observations. This work studies a QCD problem where the change is either a bad change, which we aim to detect, or a confusing change, which is not of our interest. Our objective is to detect a bad change as quickly as possible while avoiding raising a false alarm for pre-change or a confusing change. We identify a specific set of pre-change, bad change, and confusing change distributions that pose challenges beyond the capabilities of standard Cumulative Sum (CuSum) procedures. Proposing novel CuSum-based detection procedures, S-CuSum and J-CuSum, leveraging two CuSum statistics, we offer solutions applicable across all kinds of pre-change, bad change, and confusing change distributions. For both S-CuSum and J-CuSum, we provide analytical performance guarantees and validate them by numerical results. Furthermore, both procedures are computationally efficient as they only require simple recursive updates.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Rigged Dynamic Mode Decomposition: Data-Driven Generalized Eigenfunction  Decompositions for Koopman Operators</b></summary>
  <p><b>编号</b>：[450]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00782">https://arxiv.org/abs/2405.00782</a></p>
  <p><b>作者</b>：Matthew J. Colbrook,  Catherine Drysdale,  Andrew Horning</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dynamic Mode Decomposition, Dynamic Mode, Rigged DMD, Rigged Dynamic Mode, Extended Dynamic Mode</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the Rigged Dynamic Mode Decomposition (Rigged DMD) algorithm, which computes generalized eigenfunction decompositions of Koopman operators. By considering the evolution of observables, Koopman operators transform complex nonlinear dynamics into a linear framework suitable for spectral analysis. While powerful, traditional Dynamic Mode Decomposition (DMD) techniques often struggle with continuous spectra. Rigged DMD addresses these challenges with a data-driven methodology that approximates the Koopman operator's resolvent and its generalized eigenfunctions using snapshot data from the system's evolution. At its core, Rigged DMD builds wave-packet approximations for generalized Koopman eigenfunctions and modes by integrating Measure-Preserving Extended Dynamic Mode Decomposition with high-order kernels for smoothing. This provides a robust decomposition encompassing both discrete and continuous spectral elements. We derive explicit high-order convergence theorems for generalized eigenfunctions and spectral measures. Additionally, we propose a novel framework for constructing rigged Hilbert spaces using time-delay embedding, significantly extending the algorithm's applicability. We provide examples, including systems with a Lebesgue spectrum, integrable Hamiltonian systems, the Lorenz system, and a high-Reynolds number lid-driven flow in a two-dimensional square cavity, demonstrating Rigged DMD's convergence, efficiency, and versatility. This work paves the way for future research and applications of decompositions with continuous spectra.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：A Review of Barren Plateaus in Variational Quantum Computing</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00781">https://arxiv.org/abs/2405.00781</a></p>
  <p><b>作者</b>：Martin Larocca,  Supanut Thanasilp,  Samson Wang,  Kunal Sharma,  Jacob Biamonte,  Patrick J. Coles,  Lukasz Cincio,  Jarrod R. McClean,  Zoë Holmes,  M. Cerezo</p>
  <p><b>备注</b>：21 pages, 10 boxes</p>
  <p><b>关键词</b>：flexible computational paradigm, Variational quantum computing, quantum computing offers, computing offers, offers a flexible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational quantum computing offers a flexible computational paradigm with applications in diverse areas. However, a key obstacle to realizing their potential is the Barren Plateau (BP) phenomenon. When a model exhibits a BP, its parameter optimization landscape becomes exponentially flat and featureless as the problem size increases. Importantly, all the moving pieces of an algorithm -- choices of ansatz, initial state, observable, loss function and hardware noise -- can lead to BPs when ill-suited. Due to the significant impact of BPs on trainability, researchers have dedicated considerable effort to develop theoretical and heuristic methods to understand and mitigate their effects. As a result, the study of BPs has become a thriving area of research, influencing and cross-fertilizing other fields such as quantum optimal control, tensor networks, and learning theory. This article provides a comprehensive review of the current understanding of the BP phenomenon.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Quantum-Classical Separations in Shallow-Circuit-Based Learning with and  without Noises</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00770">https://arxiv.org/abs/2405.00770</a></p>
  <p><b>作者</b>：Zhihan Zhang,  Weiyuan Gong,  Weikang Li,  Dong-Ling Deng</p>
  <p><b>备注</b>：14 pages, 3 figures</p>
  <p><b>关键词</b>：study quantum-classical separations, quantum supervised learning, quantum, supervised learning models, learning models based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study quantum-classical separations between classical and quantum supervised learning models based on constant depth (i.e., shallow) circuits, in scenarios with and without noises. We construct a classification problem defined by a noiseless shallow quantum circuit and rigorously prove that any classical neural network with bounded connectivity requires logarithmic depth to output correctly with a larger-than-exponentially-small probability. This unconditional near-optimal quantum-classical separation originates from the quantum nonlocality property that distinguishes quantum circuits from their classical counterparts. We further derive the noise thresholds for demonstrating such a separation on near-term quantum devices under the depolarization noise model. We prove that this separation will persist if the noise strength is upper bounded by an inverse polynomial with respect to the system size, and vanish if the noise strength is greater than an inverse polylogarithmic function. In addition, for quantum devices with constant noise strength, we prove that no super-polynomial classical-quantum separation exists for any classification task defined by shallow Clifford circuits, independent of the structures of the circuits that specify the learning models.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：F$^3$low: Frame-to-Frame Coarse-grained Molecular Dynamics with SE(3)  Guided Flow Matching</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00751">https://arxiv.org/abs/2405.00751</a></p>
  <p><b>作者</b>：Shaoning Li,  Yusong Wang,  Mingyu Li,  Jian Zhang,  Bin Shao,  Nanning Zheng,  Jian Tang</p>
  <p><b>备注</b>：Accepted by ICLR 2024 GEM workshop</p>
  <p><b>关键词</b>：simulating biological systems, Molecular dynamics, biological systems, functions and properties, dynamic nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Molecular dynamics (MD) is a crucial technique for simulating biological systems, enabling the exploration of their dynamic nature and fostering an understanding of their functions and properties. To address exploration inefficiency, emerging enhanced sampling approaches like coarse-graining (CG) and generative models have been employed. In this work, we propose a \underline{Frame-to-Frame} generative model with guided \underline{Flow}-matching (F$3$low) for enhanced sampling, which (a) extends the domain of CG modeling to the SE(3) Riemannian manifold; (b) retreating CGMD simulations as autoregressively sampling guided by the former frame via flow-matching models; (c) targets the protein backbone, offering improved insights into secondary structure formation and intricate folding pathways. Compared to previous methods, F$3$low allows for broader exploration of conformational space. The ability to rapidly generate diverse conformations via force-free generative paradigm on SE(3) paves the way toward efficient enhanced sampling methods.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Joint Signal Detection and Automatic Modulation Classification via Deep  Learning</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00736">https://arxiv.org/abs/2405.00736</a></p>
  <p><b>作者</b>：Huijun Xing,  Xuhui Zhang,  Shuo Chang,  Jinke Ren,  Zixun Zhang,  Jie Xu,  Shuguang Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：wireless communication systems, Signal detection, communication systems, crucial tasks, wireless communication</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal detection and modulation classification are two crucial tasks in various wireless communication systems. Different from prior works that investigate them independently, this paper studies the joint signal detection and automatic modulation classification (AMC) by considering a realistic and complex scenario, in which multiple signals with different modulation schemes coexist at different carrier frequencies. We first generate a coexisting RADIOML dataset (CRML23) to facilitate the joint design. Different from the publicly available AMC dataset ignoring the signal detection step and containing only one signal, our synthetic dataset covers the more realistic multiple-signal coexisting scenario. Then, we present a joint framework for detection and classification (JDM) for such a multiple-signal coexisting environment, which consists of two modules for signal detection and AMC, respectively. In particular, these two modules are interconnected using a designated data structure called "proposal". Finally, we conduct extensive simulations over the newly developed dataset, which demonstrate the effectiveness of our designs. Our code and dataset are now available as open-source (this https URL).</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based  Cross-Center Brain Disease Diagnosis under Unreliable Annotations</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00734">https://arxiv.org/abs/2405.00734</a></p>
  <p><b>作者</b>：Zhenxi Song,  Ruihan Qin,  Huixia Ren,  Zhen Liang,  Yi Guo,  Min Zhang,  Zhiguo Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unreliability significantly challenge, annotation unreliability significantly, significantly challenge, challenge the intelligent, intelligent diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-center data heterogeneity and annotation unreliability significantly challenge the intelligent diagnosis of diseases using brain signals. A notable example is the EEG-based diagnosis of neurodegenerative diseases, which features subtler abnormal neural dynamics typically observed in small-group settings. To advance this area, in this work, we introduce a transferable framework employing Manifold Attention and Confidence Stratification (MACS) to diagnose neurodegenerative disorders based on EEG signals sourced from four centers with unreliable annotations. The MACS framework's effectiveness stems from these features: 1) The Augmentor generates various EEG-represented brain variants to enrich the data space; 2) The Switcher enhances the feature space for trusted samples and reduces overfitting on incorrectly labeled samples; 3) The Encoder uses the Riemannian manifold and Euclidean metrics to capture spatiotemporal variations and dynamic synchronization in EEG; 4) The Projector, equipped with dual heads, monitors consistency across multiple brain variants and ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies learned samples by confidence levels throughout the training process; 6) Forward and backpropagation in MACS are constrained by confidence stratification to stabilize the learning system amid unreliable annotations. Our subject-independent experiments, conducted on both neurocognitive and movement disorders using cross-center corpora, have demonstrated superior performance compared to existing related algorithms. This work not only improves EEG-based diagnostics for cross-center and small-setting brain diseases but also offers insights into extending MACS techniques to other data analyses, tackling data heterogeneity and annotation unreliability in multimedia and multimodal content understanding.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Generalised envelope spectrum-based signal-to-noise objectives:  Formulation, optimisation and application for gear fault detection under  time-varying speed conditions</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00727">https://arxiv.org/abs/2405.00727</a></p>
  <p><b>作者</b>：Stephan Schmidt,  Daniel N. Wilke,  Konstantinos C. Gryllias</p>
  <p><b>备注</b>：27 pages, 15 figures, tables 1, submitted MSSP review</p>
  <p><b>关键词</b>：filter design improves, vibration-based condition monitoring, design improves fault, enhancing weak fault, weak fault signatures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In vibration-based condition monitoring, optimal filter design improves fault detection by enhancing weak fault signatures within vibration signals. This process involves optimising a derived objective function from a defined objective. The objectives are often based on proxy health indicators to determine the filter's parameters. However, these indicators can be compromised by irrelevant extraneous signal components and fluctuating operational conditions, affecting the filter's efficacy. Fault detection primarily uses the fault component's prominence in the squared envelope spectrum, quantified by a squared envelope spectrum-based signal-to-noise ratio. New optimal filter objective functions are derived from the proposed generalised envelope spectrum-based signal-to-noise objective for machines operating under variable speed conditions. Instead of optimising proxy health indicators, the optimal filter coefficients of the formulation directly maximise the squared envelope spectrum-based signal-to-noise ratio over targeted frequency bands using standard gradient-based optimisers. Four derived objective functions from the proposed objective effectively outperform five prominent methods in tests on three experimental datasets.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：Federated Learning and Differential Privacy Techniques on Multi-hospital  Population-scale Electrocardiogram Data</b></summary>
  <p><b>编号</b>：[461]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00725">https://arxiv.org/abs/2405.00725</a></p>
  <p><b>作者</b>：Vikhyat Agrawal,  Sunil Vasu Kalmady,  Venkataseetharam Manoj Malipeddi,  Manisimha Varma Manthena,  Weijie Sun,  Saiful Islam,  Abram Hindle,  Padma Kaul,  Russell Greiner</p>
  <p><b>备注</b>：Accepted for ICMHI 2024</p>
  <p><b>关键词</b>：apply Federated Learning, Federated Learning, research paper explores, population-scale Electrocardiogram, apply Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This research paper explores ways to apply Federated Learning (FL) and Differential Privacy (DP) techniques to population-scale Electrocardiogram (ECG) data. The study learns a multi-label ECG classification model using FL and DP based on 1,565,849 ECG tracings from 7 hospitals in Alberta, Canada. The FL approach allowed collaborative model training without sharing raw data between hospitals while building robust ECG classification models for diagnosing various cardiac conditions. These accurate ECG classification models can facilitate the diagnoses while preserving patient confidentiality using FL and DP techniques. Our results show that the performance achieved using our implementation of the FL approach is comparable to that of the pooled approach, where the model is trained over the aggregating data from all hospitals. Furthermore, our findings suggest that hospitals with limited ECGs for training can benefit from adopting the FL model compared to single-site training. In addition, this study showcases the trade-off between model performance and data privacy by employing DP during model training. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Baseline Drift Tolerant Signal Encoding for ECG Classification with Deep  Learning</b></summary>
  <p><b>编号</b>：[462]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00724">https://arxiv.org/abs/2405.00724</a></p>
  <p><b>作者</b>：Robert O Shea,  Prabodh Katti,  Bipin Rajendran</p>
  <p><b>备注</b>：4 pages, 3 figures. Submitted to 46th Annual International Conference of the IEEE Engineering in Medicine and Biology 2024</p>
  <p><b>关键词</b>：noise critically limit, proposes Derived Peak, machine learningbased automated, learningbased automated ECG, automated ECG analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Common artefacts such as baseline drift, rescaling, and noise critically limit the performance of machine learningbased automated ECG analysis and interpretation. This study proposes Derived Peak (DP) encoding, a non-parametric method that generates signed spikes corresponding to zero crossings of the signals first and second-order time derivatives. Notably, DP encoding is invariant to shift and scaling artefacts, and its implementation is further simplified by the absence of userdefined parameters. DP encoding was used to encode the 12-lead ECG data from the PTB-XL dataset (n=18,869 participants) and was fed to 1D-ResNet-18 models trained to identify myocardial infarction, conductive deficits and ST-segment abnormalities. Robustness to artefacts was assessed by corrupting ECG data with sinusoidal baseline drift, shift, rescaling and noise, before encoding. The addition of these artefacts resulted in a significant drop in accuracy for seven other methods from prior art, while DP encoding maintained a baseline AUC of 0.88 under drift, shift and rescaling. DP achieved superior performance to unencoded inputs in the presence of shift (AUC under 1mV shift: 0.91 vs 0.62), and rescaling artefacts (AUC 0.91 vs 0.79). Thus, DP encoding is a simple method by which robustness to common ECG artefacts may be improved for automated ECG analysis and interpretation.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：EEG_RL-Net: Enhancing EEG MI Classification through Reinforcement  Learning-Optimised Graph Neural Networks</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00723">https://arxiv.org/abs/2405.00723</a></p>
  <p><b>作者</b>：Htoo Wai Aung,  Jiao Jiao Li,  Yang An,  Steven W. Su</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Networks, accurately decoding electroencephalography, EEG, Brain-Computer Interfaces, outperform Convolutional Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain-Computer Interfaces (BCIs) rely on accurately decoding electroencephalography (EEG) motor imagery (MI) signals for effective device control. Graph Neural Networks (GNNs) outperform Convolutional Neural Networks (CNNs) in this regard, by leveraging the spatial relationships between EEG electrodes through adjacency matrices. The EEG_GLT-Net framework, featuring the state-of-the-art EEG_GLT adjacency matrix method, has notably enhanced EEG MI signal classification, evidenced by an average accuracy of 83.95% across 20 subjects on the PhysioNet dataset. This significantly exceeds the 76.10% accuracy rate achieved using the Pearson Correlation Coefficient (PCC) method within the same framework.
In this research, we advance the field by applying a Reinforcement Learning (RL) approach to the classification of EEG MI signals. Our innovative method empowers the RL agent, enabling not only the classification of EEG MI data points with higher accuracy, but effective identification of EEG MI data points that are less distinct. We present the EEG_RL-Net, an enhancement of the EEG_GLT-Net framework, which incorporates the trained EEG GCN Block from EEG_GLT-Net at an adjacency matrix density of 13.39% alongside the RL-centric Dueling Deep Q Network (Dueling DQN) block. The EEG_RL-Net model showcases exceptional classification performance, achieving an unprecedented average accuracy of 96.40% across 20 subjects within 25 milliseconds. This model illustrates the transformative effect of the RL in EEG MI time point classification.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Optimizing Brain-Computer Interface Performance: Advancing EEG Signals  Channel Selection through Regularized CSP and SPEA II Multi-Objective  Optimization</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00721">https://arxiv.org/abs/2405.00721</a></p>
  <p><b>作者</b>：M. Moein Esfahani,  Hossein Sadati,  Vince D Calhoun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：garnered significant attention, EEG, Brain-computer interface systems, EEG signal, Brain-computer interface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain-computer interface systems and the recording of brain activity has garnered significant attention across a diverse spectrum of applications. EEG signals have emerged as a modality for recording neural electrical activity. Among the methodologies designed for feature extraction from EEG data, the method of RCSP has proven to be an approach, particularly in the context of MI tasks. RCSP exhibits efficacy in the discrimination and classification of EEG signals. In optimizing the performance of this method, our research extends to a comparative analysis with conventional CSP techniques, as well as optimized methodologies designed for similar applications. Notably, we employ the meta-heuristic multi-objective Strength Pareto Evolutionary Algorithm II (SPEA-II) as a pivotal component of our research paradigm. This is a state-of-the-art approach in the selection of an subset of channels from a multichannel EEG signal with MI tasks. Our main objective is to formulate an optimum channel selection strategy aimed at identifying the most pertinent subset of channels from the multi-dimensional electroencephalogram (EEG) signals. One of the primary objectives inherent to channel selection in the EEG signal analysis pertains to the reduction of the channel count, an approach that enhances user comfort when utilizing gel-based EEG electrodes. Additionally, within this research, we took benefit of ensemble learning models as a component of our decision-making. This technique serves to mitigate the challenges associated with overfitting, especially when confronted with an extensive array of potentially redundant EEG channels and data noise. Our findings not only affirm the performance of RCSP in MI-based BCI systems, but also underscore the significance of channel selection strategies and ensemble learning techniques in optimizing the performance of EEG signal classification.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：A Novel Machine Learning-based Equalizer for a Downstream 100G PAM-4 PON</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00720">https://arxiv.org/abs/2405.00720</a></p>
  <p><b>作者</b>：Chen Shao,  Elias Giacoumidis,  Shi Li,  Jialei Li,  Michael Faerber,  Tobias Kaefer,  Andre Richter</p>
  <p><b>备注</b>：3 pages, 6 figures, accepted by Optical Fiber Communications Conference and Exhibition 2024</p>
  <p><b>关键词</b>：frequency-calibrated SCINet, equalizer is proposed, proposed for down-stream, path loss, PON</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A frequency-calibrated SCINet (FC-SCINet) equalizer is proposed for down-stream 100G PON with 28.7 dB path loss. At 5 km, FC-SCINet improves the BER by 88.87% compared to FFE and a 3-layer DNN with 10.57% lower complexity.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：EEG-Deformer: A Dense Convolutional Transformer for Brain-computer  Interfaces</b></summary>
  <p><b>编号</b>：[466]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00719">https://arxiv.org/abs/2405.00719</a></p>
  <p><b>作者</b>：Yi Ding,  Yong Li,  Hao Sun,  Rui Liu,  Chengxuan Tong,  Cuntai Guan</p>
  <p><b>备注</b>：10 pages, 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：brain-computer interfaces, Dense Information Purification, Fine-grained Temporal Learning, challenging yet essential, activities using brain-computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Effectively learning the temporal dynamics in electroencephalogram (EEG) signals is challenging yet essential for decoding brain activities using brain-computer interfaces (BCIs). Although Transformers are popular for their long-term sequential learning ability in the BCI field, most methods combining Transformers with convolutional neural networks (CNNs) fail to capture the coarse-to-fine temporal dynamics of EEG signals. To overcome this limitation, we introduce EEG-Deformer, which incorporates two main novel components into a CNN-Transformer: (1) a Hierarchical Coarse-to-Fine Transformer (HCT) block that integrates a Fine-grained Temporal Learning (FTL) branch into Transformers, effectively discerning coarse-to-fine temporal patterns; and (2) a Dense Information Purification (DIP) module, which utilizes multi-level, purified temporal information to enhance decoding accuracy. Comprehensive experiments on three representative cognitive tasks consistently verify the generalizability of our proposed EEG-Deformer, demonstrating that it either outperforms existing state-of-the-art methods or is comparable to them. Visualization results show that EEG-Deformer learns from neurophysiologically meaningful brain regions for the corresponding cognitive tasks. The source code can be found at this https URL.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：SoK: Behind the Accuracy of Complex Human Activity Recognition Using  Deep Learning</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00712">https://arxiv.org/abs/2405.00712</a></p>
  <p><b>作者</b>：Duc-Anh Nguyen,  Nhien-An Le-Khac</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Human Activity Recognition, research dating back, well-studied field, dating back, Activity Recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) is a well-studied field with research dating back to the 1980s. Over time, HAR technologies have evolved significantly from manual feature extraction, rule-based algorithms, and simple machine learning models to powerful deep learning models, from one sensor type to a diverse array of sensing modalities. The scope has also expanded from recognising a limited set of activities to encompassing a larger variety of both simple and complex activities. However, there still exist many challenges that hinder advancement in complex activity recognition using modern deep learning methods. In this paper, we comprehensively systematise factors leading to inaccuracy in complex HAR, such as data variety and model capacity. Among many sensor types, we give more attention to wearable and camera due to their prevalence. Through this Systematisation of Knowledge (SoK) paper, readers can gain a solid understanding of the development history and existing challenges of HAR, different categorisations of activities, obstacles in deep learning-based complex HAR that impact accuracy, and potential research directions.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Pricing Catastrophe Bonds -- A Probabilistic Machine Learning Approach</b></summary>
  <p><b>编号</b>：[469]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00697">https://arxiv.org/abs/2405.00697</a></p>
  <p><b>作者</b>：Xiaowei Chen,  Hong Li,  Yufan Lu,  Rui Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CAT bond prices, primary market CAT, market CAT bond, CAT bond, CAT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a probabilistic machine learning method to price catastrophe (CAT) bonds in the primary market. The proposed method combines machine-learning-based predictive models with Conformal Prediction, an innovative algorithm that generates distribution-free probabilistic forecasts for CAT bond prices. Using primary market CAT bond transaction records between January 1999 and March 2021, the proposed method is found to be more robust and yields more accurate predictions of the bond spreads than traditional regression-based methods. Furthermore, the proposed method generates more informative prediction intervals than linear regression and identifies important nonlinear relationships between various risk factors and bond spreads, suggesting that linear regressions could misestimate the bond spreads. Overall, this paper demonstrates the potential of machine learning methods in improving the pricing of CAT bonds.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：Low-cost modular devices for on-road vehicle detection and  characterisation</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00678">https://arxiv.org/abs/2405.00678</a></p>
  <p><b>作者</b>：Jose-Luis Poza-Lujan,  Pedro Uribe-Chavert,  Juan-Luis Posadas-Yagüe</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：Detecting and characterising, purposes of embedded, intelligent environments, characterising vehicles, embedded systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting and characterising vehicles is one of the purposes of embedded systems used in intelligent environments. An analysis of a vehicle characteristics can reveal inappropriate or dangerous behaviour. This detection makes it possible to sanction or notify emergency services to take early and practical actions. Vehicle detection and characterisation systems employ complex sensors such as video cameras, especially in urban environments. These sensors provide high precision and performance, although the price and computational requirements are proportional to their accuracy. These sensors offer high accuracy, but the price and computational requirements are directly proportional to their performance. This article introduces a system based on modular devices that is economical and has a low computational cost. These devices use ultrasonic sensors to detect the speed and length of vehicles. The measurement accuracy is improved through the collaboration of the device modules. The experiments were performed using multiple modules oriented to different angles. This module is coupled with another specifically designed to detect distance using previous modules speed and length data. The collaboration between different modules reduces the speed relative error ranges from 1 to 5, depending on the angle configuration used in the modules.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon  Robotics Tasks</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01534">https://arxiv.org/abs/2405.01534</a></p>
  <p><b>作者</b>：Murtaza Dalal,  Tarun Chiruvolu,  Devendra Chaplot,  Ruslan Salakhutdinov</p>
  <p><b>备注</b>：Published at ICLR 2024. Website at this https URL 9 pages, 3 figures, 3 tables; 14 pages appendix (7 additional figures)</p>
  <p><b>关键词</b>：Large Language Models, existing methods require, methods require access, pre-defined skill library, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have been shown to be capable of performing high-level planning for long-horizon robotics tasks, yet existing methods require access to a pre-defined skill library (e.g. picking, placing, pulling, pushing, navigating). However, LLM planning does not address how to design or learn those behaviors, which remains challenging particularly in long-horizon settings. Furthermore, for many tasks of interest, the robot needs to be able to adjust its behavior in a fine-grained manner, requiring the agent to be capable of modifying low-level control actions. Can we instead use the internet-scale knowledge from LLMs for high-level policies, guiding reinforcement learning (RL) policies to efficiently solve robotic control tasks online without requiring a pre-determined set of skills? In this paper, we propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to bridge the gap between abstract language and learned low-level control for solving long-horizon robotics tasks from scratch. We demonstrate that PSL achieves state-of-the-art results on over 25 challenging robotics tasks with up to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four benchmarks at success rates of over 85%, out-performing language-based, classical, and end-to-end approaches. Video results and code at this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Improving Intervention Efficacy via Concept Realignment in Concept  Bottleneck Models</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01531">https://arxiv.org/abs/2405.01531</a></p>
  <p><b>作者</b>：Nishad Singhi,  Jae Myung Kim,  Karsten Roth,  Zeynep Akata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Concept Bottleneck Models, Bottleneck Models, Concept Bottleneck, interpretable model decisions, ground image classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept Bottleneck Models (CBMs) ground image classification on human-understandable concepts to allow for interpretable model decisions. Crucially, the CBM design inherently allows for human interventions, in which expert users are given the ability to modify potentially misaligned concept choices to influence the decision behavior of the model in an interpretable fashion. However, existing approaches often require numerous human interventions per image to achieve strong performances, posing practical challenges in scenarios where obtaining human feedback is expensive. In this paper, we find that this is noticeably driven by an independent treatment of concepts during intervention, wherein a change of one concept does not influence the use of other ones in the model's final decision. To address this issue, we introduce a trainable concept intervention realignment module, which leverages concept relations to realign concept assignments post-intervention. Across standard, real-world benchmarks, we find that concept realignment can significantly improve intervention efficacy; significantly reducing the number of interventions needed to reach a target classification performance or concept prediction accuracy. In addition, it easily integrates into existing concept-based architectures without requiring changes to the models themselves. This reduced cost of human-model collaboration is crucial to enhancing the feasibility of CBMs in resource-constrained environments.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：FLAME: Factuality-Aware Alignment for Large Language Models</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01525">https://arxiv.org/abs/2405.01525</a></p>
  <p><b>作者</b>：Sheng-Chieh Lin,  Luyu Gao,  Barlas Oguz,  Wenhan Xiong,  Jimmy Lin,  Wen-tau Yih,  Xilun Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, pre-trained large language, follow natural language, fine-tune pre-trained large, natural language instructions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alignment is a standard procedure to fine-tune pre-trained large language models (LLMs) to follow natural language instructions and serve as helpful AI assistants. We have observed, however, that the conventional alignment process fails to enhance the factual accuracy of LLMs, and often leads to the generation of more false facts (i.e. hallucination). In this paper, we study how to make the LLM alignment process more factual, by first identifying factors that lead to hallucination in both alignment steps:\ supervised fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that training the LLM on new knowledge or unfamiliar texts can encourage hallucination. This makes SFT less factual as it trains on human labeled data that may be novel to the LLM. Furthermore, reward functions used in standard RL can also encourage hallucination, because it guides the LLM to provide more helpful responses on a diverse set of instructions, often preferring longer and more detailed responses. Based on these observations, we propose factuality-aware alignment, comprised of factuality-aware SFT and factuality-aware RL through direct preference optimization. Experiments show that our proposed factuality-aware alignment guides LLMs to output more factual responses while maintaining instruction-following capability.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：A separability-based approach to quantifying generalization: which layer  is best?</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01524">https://arxiv.org/abs/2405.01524</a></p>
  <p><b>作者</b>：Luciano Dyballa,  Evan Gerritz,  Steven W. Zucker</p>
  <p><b>备注</b>：6, pages, 5 figures</p>
  <p><b>关键词</b>：remains poorly understood, data remains poorly, deep learning classification, remains poorly, poorly understood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization to unseen data remains poorly understood for deep learning classification and foundation models. How can one assess the ability of networks to adapt to new or extended versions of their input space in the spirit of few-shot learning, out-of-distribution generalization, and domain adaptation? Which layers of a network are likely to generalize best? We provide a new method for evaluating the capacity of networks to represent a sampled domain, regardless of whether the network has been trained on all classes in the domain. Our approach is the following: after fine-tuning state-of-the-art pre-trained models for visual classification on a particular domain, we assess their performance on data from related but distinct variations in that domain. Generalization power is quantified as a function of the latent embeddings of unseen data from intermediate layers for both unsupervised and supervised settings. Working throughout all stages of the network, we find that (i) high classification accuracy does not imply high generalizability; and (ii) deeper layers in a model do not always generalize the best, which has implications for pruning. Since the trends observed across datasets are largely consistent, we conclude that our approach reveals (a function of) the intrinsic capacity of the different layers of a model to generalize.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on  Large Language Models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01509">https://arxiv.org/abs/2405.01509</a></p>
  <p><b>作者</b>：Minhao Bai,  Kaiyi Pang,  Yongfeng Huang</p>
  <p><b>备注</b>：not decided</p>
  <p><b>关键词</b>：Large Language Models, Large Language, rapidly evolving domain, property of Large, model extraction attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the rapidly evolving domain of artificial intelligence, safeguarding the intellectual property of Large Language Models (LLMs) is increasingly crucial. Current watermarking techniques against model extraction attacks, which rely on signal insertion in model logits or post-processing of generated text, remain largely heuristic. We propose a novel method for embedding learnable linguistic watermarks in LLMs, aimed at tracing and preventing model extraction attacks. Our approach subtly modifies the LLM's output distribution by introducing controlled noise into token frequency distributions, embedding an statistically identifiable controllable watermark.We leverage statistical hypothesis testing and information theory, particularly focusing on Kullback-Leibler Divergence, to differentiate between original and modified distributions effectively. Our watermarking method strikes a delicate well balance between robustness and output quality, maintaining low false positive/negative rates and preserving the LLM's original performance.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Analyzing the Role of Semantic Representations in the Era of Large  Language Models</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01502">https://arxiv.org/abs/2405.01502</a></p>
  <p><b>作者</b>：Zhijing Jin,  Yuen Chen,  Fernando Gonzalez,  Jiarui Liu,  Jiayi Zhang,  Julian Michael,  Bernhard Schölkopf,  Mona Diab</p>
  <p><b>备注</b>：NAACL 2024</p>
  <p><b>关键词</b>：natural language processing, linguistic expertise, rich set, set of features, features created</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven chain-of-thought prompting method, which we call AMRCoT, and find that it generally hurts performance more than it helps. To investigate what AMR may have to offer on these tasks, we conduct a series of analysis experiments. We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction. We recommend focusing on these areas for future work in semantic representations for LLMs. Our code: this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Controllable Text Generation in the Instruction-Tuning Era</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01490">https://arxiv.org/abs/2405.01490</a></p>
  <p><b>作者</b>：Dhananjay Ashok,  Barnabas Poczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Instruction-tuned Language Models, base Language Models, steering base Language, Language Models, prompting paradigm offers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While most research on controllable text generation has focused on steering base Language Models, the emerging instruction-tuning and prompting paradigm offers an alternate approach to controllability. We compile and release ConGenBench, a testbed of 17 different controllable generation tasks, using a subset of it to benchmark the performance of 9 different baselines and methods on Instruction-tuned Language Models. To our surprise, we find that prompting-based approaches outperform controllable text generation methods on most datasets and tasks, highlighting a need for research on controllable text generation with Instruction-tuned Language Models in specific. Prompt-based approaches match human performance on most stylistic tasks while lagging on structural tasks, foregrounding a need to study more varied constraints and more challenging stylistic tasks. To facilitate such research, we provide an algorithm that uses only a task dataset and a Large Language Model with in-context capabilities to automatically generate a constraint dataset. This method eliminates the fields dependence on pre-curated constraint datasets, hence vastly expanding the range of constraints that can be studied in the future.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：MANTIS: Interleaved Multi-Image Instruction Tuning</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01483">https://arxiv.org/abs/2405.01483</a></p>
  <p><b>作者</b>：Dongfu Jiang,  Xuan He,  Huaye Zeng,  Cong Wei,  Max Ku,  Qian Liu,  Wenhu Chen</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：vision language tasks, large multimodal models, language tasks, multi-image, single-image vision language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent years have witnessed a great array of large multimodal models (LMMs) to effectively solve single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from web, which is neither efficient nor effective. In this paper, we aim at building strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K instances from 14 multi-image datasets. We design Mantis-Instruct to cover different multi-image skills like co-reference, reasoning, comparing, temporal understanding. We combine Mantis-Instruct with several single-image visual-language datasets to train our model Mantis to handle any interleaved image-text inputs. We evaluate the trained Mantis on five multi-image benchmarks and eight single-image benchmarks. Though only requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B can achieve state-of-the-art performance on all the multi-image benchmarks and beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute points. We observe that Mantis performs equivalently well on the held-in and held-out evaluation benchmarks. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis can maintain a strong single-image performance on par with CogVLM and Emu2. Our results are particularly encouraging as it shows that low-cost instruction tuning is indeed much more effective than intensive pre-training in terms of building multi-image LMMs.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01481">https://arxiv.org/abs/2405.01481</a></p>
  <p><b>作者</b>：Gerald Shen,  Zhilin Wang,  Olivier Delalleau,  Jiaqi Zeng,  Yi Dong,  Daniel Egert,  Shengyang Sun,  Jimmy Zhang,  Sahil Jain,  Ali Taghibakhshi,  Markel Sanz Ausin,  Ashwath Aithal,  Oleksii Kuchaiev</p>
  <p><b>备注</b>：13 pages, 4 figures</p>
  <p><b>关键词</b>：Aligning Large Language, Large Language Models, Large Language, Aligning Large, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aligning Large Language Models (LLMs) with human values and preferences is essential for making them helpful and safe. However, building efficient tools to perform alignment can be challenging, especially for the largest and most competent LLMs which often contain tens or hundreds of billions of parameters. We create NeMo-Aligner, a toolkit for model alignment that can efficiently scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly optimized and scalable implementations for major paradigms of model alignment such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally, our toolkit supports running most of the alignment techniques in a Parameter Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for extensibility, allowing support for other alignment techniques with minimal effort. It is open-sourced with Apache 2.0 License and we invite community contributions at this https URL</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：V-FLUTE: Visual Figurative Language Understanding with Textual  Explanations</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01474">https://arxiv.org/abs/2405.01474</a></p>
  <p><b>作者</b>：Arkadiy Saakyan,  Shreyas Kulkarni,  Tuhin Chakrabarty,  Smaranda Muresan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated strong reasoning, strong reasoning capabilities, Large Vision-Language models, Visual Figurative Language, Figurative Language Understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Vision-Language models (VLMs) have demonstrated strong reasoning capabilities in tasks requiring a fine-grained understanding of literal images and text, such as visual question-answering or visual entailment. However, there has been little exploration of these models' capabilities when presented with images and captions containing figurative phenomena such as metaphors or humor, the meaning of which is often implicit. To close this gap, we propose a new task and a high-quality dataset: Visual Figurative Language Understanding with Textual Explanations (V-FLUTE). We frame the visual figurative language understanding problem as an explainable visual entailment task, where the model has to predict whether the image (premise) entails a claim (hypothesis) and justify the predicted label with a textual explanation. Using a human-AI collaboration framework, we build a high-quality dataset, V-FLUTE, that contains 6,027 <image, claim, label, explanation> instances spanning five diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm, and humor. The figurative phenomena can be present either in the image, the caption, or both. We further conduct both automatic and human evaluations to assess current VLMs' capabilities in understanding figurative phenomena.</image,></p>
  </details>
</details>
<details>
  <summary>11. <b>标题：IntervenGen: Interventional Data Generation for Robust and  Data-Efficient Robot Imitation Learning</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01472">https://arxiv.org/abs/2405.01472</a></p>
  <p><b>作者</b>：Ryan Hoque,  Ajay Mandlekar,  Caelan Garrett,  Ken Goldberg,  Dieter Fox</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training robot control, robot control policies, evaluation time differ, training robot, control policies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation learning is a promising paradigm for training robot control policies, but these policies can suffer from distribution shift, where the conditions at evaluation time differ from those in the training data. A popular approach for increasing policy robustness to distribution shift is interactive imitation learning (i.e., DAgger and variants), where a human operator provides corrective interventions during policy rollouts. However, collecting a sufficient amount of interventions to cover the distribution of policy mistakes can be burdensome for human operators. We propose IntervenGen (I-Gen), a novel data generation system that can autonomously produce a large set of corrective interventions with rich coverage of the state space from a small number of human interventions. We apply I-Gen to 4 simulated environments and 1 physical environment with object pose estimation error and show that it can increase policy robustness by up to 39x with only 10 human interventions. Videos and more results are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Advancing human-centric AI for robust X-ray analysis through holistic  self-supervised learning</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01469">https://arxiv.org/abs/2405.01469</a></p>
  <p><b>作者</b>：Théo Moutakanni,  Piotr Bojanowski,  Guillaume Chassagnon,  Céline Hudelot,  Armand Joulin,  Yann LeCun,  Matthew Muckley,  Maxime Oquab,  Marie-Pierre Revel,  Maria Vakalopoulou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including medical fields, medical foundation models, Foundation models, gaining traction, including medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI Foundation models are gaining traction in various applications, including medical fields like radiology. However, medical foundation models are often tested on limited tasks, leaving their generalisability and biases unexplored. We present RayDINO, a large visual encoder trained by self-supervision on 873k chest X-rays. We compare RayDINO to previous state-of-the-art models across nine radiology tasks, from classification and dense segmentation to text generation, and provide an in depth analysis of population, age and sex biases of our model. Our findings suggest that self-supervision allows patient-centric AI proving useful in clinical workflows and interpreting X-rays holistically. With RayDINO and small task-specific adapters, we reach state-of-the-art results and improve generalization to unseen populations while mitigating bias, illustrating the true promise of foundation models: versatility and robustness.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Understanding Retrieval-Augmented Task Adaptation for Vision-Language  Models</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01468">https://arxiv.org/abs/2405.01468</a></p>
  <p><b>作者</b>：Yifei Ming,  Yixuan Li</p>
  <p><b>备注</b>：The paper is accepted at ICML 2024</p>
  <p><b>关键词</b>：demonstrated remarkable performance, Pre-trained contrastive vision-language, Pre-trained contrastive, range of tasks, demonstrated remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained contrastive vision-language models have demonstrated remarkable performance across a wide range of tasks. However, they often struggle on fine-trained datasets with categories not adequately represented during pre-training, which makes adaptation necessary. Recent works have shown promising results by utilizing samples from web-scale databases for retrieval-augmented adaptation, especially in low-data regimes. Despite the empirical success, understanding how retrieval impacts the adaptation of vision-language models remains an open research question. In this work, we adopt a reflective perspective by presenting a systematic study to understand the roles of key components in retrieval-augmented adaptation. We unveil new insights on uni-modal and cross-modal retrieval and highlight the critical role of logit ensemble for effective adaptation. We further present theoretical underpinnings that directly support our empirical observations.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Purify Unlearnable Examples via Rate-Constrained Variational  Autoencoders</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01460">https://arxiv.org/abs/2405.01460</a></p>
  <p><b>作者</b>：Yi Yu,  Yufei Wang,  Song Xia,  Wenhan Yang,  Shijian Lu,  Yap-Peng Tan,  Alex C. Kot</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：maximize testing error, making subtle modifications, seek to maximize, correctly labeled, maximize testing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlearnable examples (UEs) seek to maximize testing error by making subtle modifications to training examples that are correctly labeled. Defenses against these poisoning attacks can be categorized based on whether specific interventions are adopted during training. The first approach is training-time defense, such as adversarial training, which can mitigate poisoning effects but is computationally intensive. The other approach is pre-training purification, e.g., image short squeezing, which consists of several simple compressions but often encounters challenges in dealing with various UEs. Our work provides a novel disentanglement mechanism to build an efficient pre-training purification method. Firstly, we uncover rate-constrained variational autoencoders (VAEs), demonstrating a clear tendency to suppress the perturbations in UEs. We subsequently conduct a theoretical analysis for this phenomenon. Building upon these insights, we introduce a disentangle variational autoencoder (D-VAE), capable of disentangling the perturbations with learnable class-wise embeddings. Based on this network, a two-stage purification approach is naturally developed. The first stage focuses on roughly eliminating perturbations, while the second stage produces refined, poison-free results, ensuring effectiveness and robustness across various scenarios. Extensive experiments demonstrate the remarkable performance of our method across CIFAR-10, CIFAR-100, and a 100-class ImageNet-subset. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：UQA: Corpus for Urdu Question Answering</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01458">https://arxiv.org/abs/2405.01458</a></p>
  <p><b>作者</b>：Samee Arif,  Sualeha Farid,  Awais Athar,  Agha Ali Raza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：million native speakers, Stanford Question Answering, Question Answering Dataset, question answering, paper introduces UQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces UQA, a novel dataset for question answering and text comprehension in Urdu, a low-resource language with over 70 million native speakers. UQA is generated by translating the Stanford Question Answering Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in the translated context paragraphs. The paper describes the process of selecting and evaluating the best translation model among two candidates: Google Translator and Seamless M4T. The paper also benchmarks several state-of-the-art multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and 74.56 EM. UQA is a valuable resource for developing and testing multilingual NLP systems for Urdu and for enhancing the cross-lingual transferability of existing models. Further, the paper demonstrates the effectiveness of EATS for creating high-quality datasets for other languages and domains. The UQA dataset and the code are publicly available at this http URL.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Creative Problem Solving in Large Language and Vision Models -- What  Would it Take?</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01453">https://arxiv.org/abs/2405.01453</a></p>
  <p><b>作者</b>：Lakshmi Nair,  Evana Gizzi,  Jivko Sinapov</p>
  <p><b>备注</b>：9 pages, 7 figures, 2 tables</p>
  <p><b>关键词</b>：integrating Computational Creativity, Computational Creativity, vision models, creative problem solving, discuss approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we discuss approaches for integrating Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this limitation through augmented prompting. With this work, we hope to foster discussions of Computational Creativity in the context of ML algorithms for creative problem solving in LLVMs. Our code is at: this https URL</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Review of Reward Functions for Reinforcement Learning in the context  of Autonomous Driving</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01440">https://arxiv.org/abs/2405.01440</a></p>
  <p><b>作者</b>：Ahmed Abouelazm,  Jonas Michel,  J. Marius Zoellner</p>
  <p><b>备注</b>：Accepted at "Interaction-driven Behavior Prediction and Planning for Autonomous Vehicles" workshop in 35th IEEE Intelligent Vehicles Symposium (IV 2024)</p>
  <p><b>关键词</b>：Reinforcement learning, important approach, autonomous driving, reward, Traffic Rules compliance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has emerged as an important approach for autonomous driving. A reward function is used in reinforcement learning to establish the learned skill objectives and guide the agent toward the optimal policy. Since autonomous driving is a complex domain with partly conflicting objectives with varying degrees of priority, developing a suitable reward function represents a fundamental challenge. This paper aims to highlight the gap in such function design by assessing different proposed formulations in the literature and dividing individual objectives into Safety, Comfort, Progress, and Traffic Rules compliance categories. Additionally, the limitations of the reviewed reward functions are discussed, such as objectives aggregation and indifference to driving context. Furthermore, the reward categories are frequently inadequately formulated and lack standardization. This paper concludes by proposing future research that potentially addresses the observed shortcomings in rewards, including a reward validation framework and structured rewards that are context-aware and able to resolve conflicts.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Natural Language to Verilog: Design of a Recurrent Spiking Neural  Network using Large Language Models and ChatGPT</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01419">https://arxiv.org/abs/2405.01419</a></p>
  <p><b>作者</b>：Paola Vitolo,  George Psaltakis,  Michael Tomlinson,  Gian Domenico Licciardo,  Andreas G. Andreou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, hardware description code, neuromorphic computing architectures, efficient neuromorphic computing, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates the use of Large Language Models (LLMs) for automating the generation of hardware description code, aiming to explore their potential in supporting and enhancing the development of efficient neuromorphic computing architectures. Building on our prior work, we employ OpenAI's ChatGPT4 and natural language prompts to synthesize a RTL Verilog module of a programmable recurrent spiking neural network, while also generating test benches to assess the system's correctness. The resultant design was validated in three case studies, the exclusive OR,the IRIS flower classification and the MNIST hand-written digit classification, achieving accuracies of up to 96.6%. To verify its synthesizability and implementability, the design was prototyped on a field-programmable gate array and implemented on SkyWater 130 nm technology by using an open-source electronic design automation flow. Additionally, we have submitted it to Tiny Tapeout 6 chip fabrication program to further evaluate the system on-chip performance in the future.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01413">https://arxiv.org/abs/2405.01413</a></p>
  <p><b>作者</b>：Yuan Tang,  Xu Han,  Xianzhi Li,  Qiao Yu,  Yixue Hao,  Long Hu,  Min Chen</p>
  <p><b>备注</b>：17 pages, 9 figures</p>
  <p><b>关键词</b>：Large Language Models, bridging Large Language, gained significant attention, Language Models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Goal-conditioned reinforcement learning for ultrasound navigation  guidance</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01409">https://arxiv.org/abs/2405.01409</a></p>
  <p><b>作者</b>：Abdoul Aziz Amadou,  Vivek Singh,  Florin C. Ghesu,  Young-Ho Kim,  Laura Stanciulescu,  Harshitha P. Sai,  Puneet Sharma,  Alistair Young,  Ronak Rajani,  Kawal Rhode</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：plays a pivotal, pivotal role, role in cardiology, TEE, interventional procedures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transesophageal echocardiography (TEE) plays a pivotal role in cardiology for diagnostic and interventional procedures. However, using it effectively requires extensive training due to the intricate nature of image acquisition and interpretation. To enhance the efficiency of novice sonographers and reduce variability in scan acquisitions, we propose a novel ultrasound (US) navigation assistance method based on contrastive learning as goal-conditioned reinforcement learning (GCRL). We augment the previous framework using a novel contrastive patient batching method (CPB) and a data-augmented contrastive loss, both of which we demonstrate are essential to ensure generalization to anatomical variations across patients. The proposed framework enables navigation to both standard diagnostic as well as intricate interventional views with a single model. Our method was developed with a large dataset of 789 patients and obtained an average error of 6.56 mm in position and 9.36 degrees in angle on a testing dataset of 140 patients, which is competitive or superior to models trained on individual views. Furthermore, we quantitatively validate our method's ability to navigate to interventional views such as the Left Atrial Appendage (LAA) view used in LAA closure. Our approach holds promise in providing valuable guidance during transesophageal ultrasound examinations, contributing to the advancement of skill acquisition for cardiac ultrasound practitioners.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Unsupervised Flow Discovery from Task-oriented Dialogues</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01403">https://arxiv.org/abs/2405.01403</a></p>
  <p><b>作者</b>：Patrícia Ferreira,  Daniel Martins,  Ana Alves,  Catarina Silva,  Hugo Gonçalo Oliveira</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：critical but time-consuming, time-consuming task, task when developing, developing task-oriented dialogue, flows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design of dialogue flows is a critical but time-consuming task when developing task-oriented dialogue (TOD) systems. We propose an approach for the unsupervised discovery of flows from dialogue history, thus making the process applicable to any domain for which such an history is available. Briefly, utterances are represented in a vector space and clustered according to their semantic similarity. Clusters, which can be seen as dialogue states, are then used as the vertices of a transition graph for representing the flows visually. We present concrete examples of flows, discovered from MultiWOZ, a public TOD dataset. We further elaborate on their significance and relevance for the underlying conversations and introduce an automatic validation metric for their assessment. Experimental results demonstrate the potential of the proposed approach for extracting meaningful flows from task-oriented conversations.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Learning Force Control for Legged Manipulation</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01402">https://arxiv.org/abs/2405.01402</a></p>
  <p><b>作者</b>：Tifanny Portela,  Gabriel B. Margolis,  Yandong Ji,  Pulkit Agrawal</p>
  <p><b>备注</b>：This work has been accepted to ICRA24, as well as the Loco-manipulation workshop at ICRA24</p>
  <p><b>关键词</b>：Controlling contact forces, Controlling contact, critical for locomotion, force, control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlling contact forces during interactions is critical for locomotion and manipulation tasks. While sim-to-real reinforcement learning (RL) has succeeded in many contact-rich problems, current RL methods achieve forceful interactions implicitly without explicitly regulating forces. We propose a method for training RL policies for direct force control without requiring access to force sensing. We showcase our method on a whole-body control platform of a quadruped robot with an arm. Such force control enables us to perform gravity compensation and impedance control, unlocking compliant whole-body manipulation. The learned whole-body controller with variable compliance makes it intuitive for humans to teleoperate the robot by only commanding the manipulator, and the robot's body adjusts automatically to achieve the desired position and force. Consequently, a human teleoperator can easily demonstrate a wide variety of loco-manipulation tasks. To the best of our knowledge, we provide the first deployment of learned whole-body force control in legged manipulators, paving the way for more versatile and adaptable legged robots.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Advancing Frontiers in SLAM: A Survey of Symbolic Representation and  Human-Machine Teaming in Environmental Mapping</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01398">https://arxiv.org/abs/2405.01398</a></p>
  <p><b>作者</b>：Brandon Curtis Colelough</p>
  <p><b>备注</b>：8 pages, 1 figure</p>
  <p><b>关键词</b>：Simultaneous Localization, field of Simultaneous, survey paper presents, presents a comprehensive, comprehensive overview</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This survey paper presents a comprehensive overview of the latest advancements in the field of Simultaneous Localization and Mapping (SLAM) with a focus on the integration of symbolic representation of environment features. The paper synthesizes research trends in multi-agent systems (MAS) and human-machine teaming, highlighting their applications in both symbolic and sub-symbolic SLAM tasks. The survey emphasizes the evolution and significance of ontological designs and symbolic reasoning in creating sophisticated 2D and 3D maps of various environments. Central to this review is the exploration of different architectural approaches in SLAM, with a particular interest in the functionalities and applications of edge and control agent architectures in MAS settings. This study acknowledges the growing demand for enhanced human-machine collaboration in mapping tasks and examines how these collaborative efforts improve the accuracy and efficiency of environmental mapping</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Analysis of a Modular Autonomous Driving Architecture: The Top  Submission to CARLA Leaderboard 2.0 Challenge</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01394">https://arxiv.org/abs/2405.01394</a></p>
  <p><b>作者</b>：Weize Zhang,  Mohammed Elmahgiubi,  Kasra Rezaee,  Behzad Khamidehi,  Hamidreza Mirkhani,  Fazel Arasteh,  Chunlin Li,  Muhammad Ahsan Kaleem,  Eduardo R. Corral-Soto,  Dhruv Sharma,  Tongtong Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CARLA Leaderboard, track of CARLA, Autonomous Driving, achieved first place, paper we present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present the architecture of the Kyber-E2E submission to the map track of CARLA Leaderboard 2.0 Autonomous Driving (AD) challenge 2023, which achieved first place. We employed a modular architecture for our solution consists of five main components: sensing, localization, perception, tracking/prediction, and planning/control. Our solution leverages state-of-the-art language-assisted perception models to help our planner perform more reliably in highly challenging traffic scenarios. We use open-source driving datasets in conjunction with Inverse Reinforcement Learning (IRL) to enhance the performance of our motion planner. We provide insight into our design choices and trade-offs made to achieve this solution. We also explore the impact of each component in the overall performance of our solution, with the intent of providing a guideline where allocation of resources can have the greatest impact.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous  Space Exploration</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01392">https://arxiv.org/abs/2405.01392</a></p>
  <p><b>作者</b>：David Maranto</p>
  <p><b>备注</b>：B.A.Sc thesis</p>
  <p><b>关键词</b>：onboard intelligence, spacecraft, systems, complex missions, Earth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for. Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration. Recent work has explored AI-based goal-oriented systems to increase the level of autonomy in mission execution. These systems make use of symbolic reasoning managers to make inferences from the state of a spacecraft and a handcrafted knowledge base, enabling autonomous generation of tasks and re-planning. Such systems have proven to be successful in controlled cases, but they are difficult to implement as they require human-crafted ontological models to allow the spacecraft to understand the world. Reinforcement learning has been applied to train robotic agents to pursue a goal. A new architecture for autonomy is called for. This work explores the application of Large Language Models (LLMs) as the high-level control system of a spacecraft. Using a systems engineering approach, this work presents the design and development of an agentic spacecraft controller by leveraging an LLM as a reasoning engine, to evaluate the utility of such an architecture in achieving higher levels of spacecraft autonomy. A series of deep space mission scenarios simulated within the popular game engine Kerbal Space Program (KSP) are used as case studies to evaluate the implementation against the requirements. It is shown the reasoning and planning abilities of present-day LLMs do not scale well as the complexity of a mission increases, but this can be alleviated with adequate prompting frameworks and strategic selection of the agent's level of authority over the host spacecraft. This research evaluates the potential of LLMs in augmenting autonomous decision-making systems for future robotic space applications.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Distributed Representations Enable Robust Multi-Timescale Computation in  Neuromorphic Hardware</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01305">https://arxiv.org/abs/2405.01305</a></p>
  <p><b>作者</b>：Madison Cotteret,  Hugh Greatorex,  Alpha Renner,  Junren Chen,  Emre Neftci,  Huaqiang Wu,  Giacomo Indiveri,  Martin Ziegler,  Elisabetta Chicca</p>
  <p><b>备注</b>：16 pages, 6 figures. Supplementary material: 7 pages, 6 figures</p>
  <p><b>关键词</b>：spiking neural networks, robustly perform multi-timescale, Programming recurrent spiking, recurrent spiking neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Programming recurrent spiking neural networks (RSNNs) to robustly perform multi-timescale computation remains a difficult challenge. To address this, we show how the distributed approach offered by vector symbolic architectures (VSAs), which uses high-dimensional random vectors as the smallest units of representation, can be leveraged to embed robust multi-timescale dynamics into attractor-based RSNNs. We embed finite state machines into the RSNN dynamics by superimposing a symmetric autoassociative weight matrix and asymmetric transition terms. The transition terms are formed by the VSA binding of an input and heteroassociative outer-products between states. Our approach is validated through simulations with highly non-ideal weights; an experimental closed-loop memristive hardware setup; and on Loihi 2, where it scales seamlessly to large state machines. This work demonstrates the effectiveness of VSA representations for embedding robust computation with recurrent dynamics into neuromorphic hardware, without requiring parameter fine-tuning or significant platform-specific optimisation. This advances VSAs as a high-level representation-invariant abstract language for cognitive algorithms in neuromorphic hardware.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：The Effectiveness of LLMs as Annotators: A Comparative Overview and  Empirical Analysis of Direct Representation</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01299">https://arxiv.org/abs/2405.01299</a></p>
  <p><b>作者</b>：Maja Pavlovic,  Massimo Poesio</p>
  <p><b>备注</b>：LREC-COLING NLPerspectives workshop</p>
  <p><b>关键词</b>：Large Language Models, powerful support tools, application domains, emerged as powerful, range of application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Low-resource speech recognition and dialect identification of Irish in a  multi-task framework</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01293">https://arxiv.org/abs/2405.01293</a></p>
  <p><b>作者</b>：Liam Lonergan,  Mengjie Qian,  Neasa Ní Chiaráin,  Christer Gobl,  Ailbhe Ní Chasaide</p>
  <p><b>备注</b>：7 pages. Accepted to Odyssey 2024 - The Speaker and Language Recognition Workshop</p>
  <p><b>关键词</b>：Hybrid CTC, Intermediate CTC, Attention encoder-decoder models, Attention encoder-decoder, CTC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the use of Hybrid CTC/Attention encoder-decoder models trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech recognition (ASR) and dialect identification (DID). Results are compared to the current best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN). An optimal InterCTC setting is initially established using a Conformer encoder. This setting is then used to train a model with an E-branchformer encoder and the performance of both architectures are compared. A multi-task fine-tuning approach is adopted for language model (LM) shallow fusion. The experiments yielded an improvement in DID accuracy of 10.8% relative to a baseline ECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task approach emerges as a promising strategy for Irish low-resource ASR and DID.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Data Feminism for AI</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01286">https://arxiv.org/abs/2405.01286</a></p>
  <p><b>作者</b>：Lauren Klein,  Catherine D'Ignazio</p>
  <p><b>备注</b>：21 pages, to be published in the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24)</p>
  <p><b>关键词</b>：intersectional feminist principles, set of intersectional, intersectional feminist, Data Feminism, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a set of intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. In Data Feminism (2020), we offered seven principles for examining and challenging unequal power in data science. Here, we present a rationale for why feminism remains deeply relevant for AI research, rearticulate the original principles of data feminism with respect to AI, and introduce two potential new principles related to environmental impact and consent. Together, these principles help to 1) account for the unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment; 2) identify and mitigate predictable harms in advance of unsafe, discriminatory, or otherwise oppressive systems being released into the world; and 3) inspire creative, joyful, and collective ways to work towards a more equitable, sustainable world in which all of us can thrive.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Towards Inclusive Face Recognition Through Synthetic Ethnicity  Alteration</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01273">https://arxiv.org/abs/2405.01273</a></p>
  <p><b>作者</b>：Praveen Kumar Chandaliya,  Kiran Raja,  Raghavendra Ramachandra,  Zahid Akhtar,  Christoph Busch</p>
  <p><b>备注</b>：8 Pages</p>
  <p><b>关键词</b>：Face Recognition Systems, existing Face Recognition, Face Recognition, Recognition Systems, face image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous studies have shown that existing Face Recognition Systems (FRS), including commercial ones, often exhibit biases toward certain ethnicities due to under-represented data. In this work, we explore ethnicity alteration and skin tone modification using synthetic face image generation methods to increase the diversity of datasets. We conduct a detailed analysis by first constructing a balanced face image dataset representing three ethnicities: Asian, Black, and Indian. We then make use of existing Generative Adversarial Network-based (GAN) image-to-image translation and manifold learning models to alter the ethnicity from one to another. A systematic analysis is further conducted to assess the suitability of such datasets for FRS by studying the realistic skin-tone representation using Individual Typology Angle (ITA). Further, we also analyze the quality characteristics using existing Face image quality assessment (FIQA) approaches. We then provide a holistic FRS performance analysis using four different systems. Our findings pave the way for future research works in (i) developing both specific ethnicity and general (any to any) ethnicity alteration models, (ii) expanding such approaches to create databases with diverse skin tones, (iii) creating datasets representing various ethnicities which further can help in mitigating bias while addressing privacy concerns.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：MFTraj: Map-Free, Behavior-Driven Trajectory Prediction for Autonomous  Driving</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01266">https://arxiv.org/abs/2405.01266</a></p>
  <p><b>作者</b>：Haicheng Liao,  Zhenning Li,  Chengyue Wang,  Huanming Shen,  Bonan Wang,  Dongping Liao,  Guofa Li,  Chengzhong Xu</p>
  <p><b>备注</b>：Accepted by IJCAI 2024</p>
  <p><b>关键词</b>：capturing complex interactions, focusing on capturing, paper introduces, capturing complex, complex interactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a trajectory prediction model tailored for autonomous driving, focusing on capturing complex interactions in dynamic traffic scenarios without reliance on high-definition maps. The model, termed MFTraj, harnesses historical trajectory data combined with a novel dynamic geometric graph-based behavior-aware module. At its core, an adaptive structure-aware interactive graph convolutional network captures both positional and behavioral features of road users, preserving spatial-temporal intricacies. Enhanced by a linear attention mechanism, the model achieves computational efficiency and reduced parameter overhead. Evaluations on the Argoverse, NGSIM, HighD, and MoCAD datasets underscore MFTraj's robustness and adaptability, outperforming numerous benchmarks even in data-challenged scenarios without the need for additional information such as HD maps or vectorized maps. Importantly, it maintains competitive performance even in scenarios with substantial missing data, on par with most existing state-of-the-art models. The results and methodology suggest a significant advancement in autonomous driving trajectory prediction, paving the way for safer and more efficient autonomous systems.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Identification of Entailment and Contradiction Relations between Natural  Language Sentences: A Neurosymbolic Approach</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01259">https://arxiv.org/abs/2405.01259</a></p>
  <p><b>作者</b>：Xuyao Feng,  Anthony Hunter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recognizing Textual Entailment, Natural language inference, natural language understanding, Recognizing Textual, Natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language inference (NLI), also known as Recognizing Textual Entailment (RTE), is an important aspect of natural language understanding. Most research now uses machine learning and deep learning to perform this task on specific datasets, meaning their solution is not explainable nor explicit. To address the need for an explainable approach to RTE, we propose a novel pipeline that is based on translating text into an Abstract Meaning Representation (AMR) graph. For this we use a pre-trained AMR parser. We then translate the AMR graph into propositional logic and use a SAT solver for automated reasoning. In text, often commonsense suggests that an entailment (or contradiction) relationship holds between a premise and a claim, but because different wordings are used, this is not identified from their logical representations. To address this, we introduce relaxation methods to allow replacement or forgetting of some propositions. Our experimental results show this pipeline performs well on four RTE datasets.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio  and Bone Conduction Speech Super Resolution and Enhancement on Mobile and  Wearable Platforms</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01242">https://arxiv.org/abs/2405.01242</a></p>
  <p><b>作者</b>：Yueyuan Sui,  Minghui Zhao,  Junxi Xia,  Xiaofan Jiang,  Stephen Xia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conduction speech enhancement, bone conduction speech, transformer and Mamba, Mamba architecture, bone conduction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose TRAMBA, a hybrid transformer and Mamba architecture for acoustic and bone conduction speech enhancement, suitable for mobile and wearable platforms. Bone conduction speech enhancement has been impractical to adopt in mobile and wearable platforms for several reasons: (i) data collection is labor-intensive, resulting in scarcity; (ii) there exists a performance gap between state of-art models with memory footprints of hundreds of MBs and methods better suited for resource-constrained systems. To adapt TRAMBA to vibration-based sensing modalities, we pre-train TRAMBA with audio speech datasets that are widely available. Then, users fine-tune with a small amount of bone conduction data. TRAMBA outperforms state-of-art GANs by up to 7.3% in PESQ and 1.8% in STOI, with an order of magnitude smaller memory footprint and an inference speed up of up to 465 times. We integrate TRAMBA into real systems and show that TRAMBA (i) improves battery life of wearables by up to 160% by requiring less data sampling and transmission; (ii) generates higher quality voice in noisy environments than over-the-air speech; (iii) requires a memory footprint of less than 20.0 MB.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Boosting Jailbreak Attack with Momentum</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01229">https://arxiv.org/abs/2405.01229</a></p>
  <p><b>作者</b>：Yihao Zhang,  Zeming Wei</p>
  <p><b>备注</b>：ICLR 2024 Workshop on Reliable and Responsible Foundation Models</p>
  <p><b>关键词</b>：Large Language Models, achieved remarkable success, Greedy Coordinate Gradient, notably the well-documented, diverse tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-documented \textit{jailbreak} attack. Recently, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous iterations. Specifically, we introduce the \textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) attack, which incorporates a momentum term into the gradient heuristic. Experimental results showcase the notable enhancement achieved by MAP in gradient-based attacks on aligned language models. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：DMON: A Simple yet Effective Approach for Argument Structure Learning</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01216">https://arxiv.org/abs/2405.01216</a></p>
  <p><b>作者</b>：Wei Sun,  Mingxiao Li,  Jingyuan Sun,  Jesse Davis,  Marie-Francine Moens</p>
  <p><b>备注</b>：COLING 2024</p>
  <p><b>关键词</b>：entails predicting relations, entails predicting, Argument structure learning, structure learning, ASL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Argument structure learning~(ASL) entails predicting relations between arguments. Because it can structure a document to facilitate its understanding, it has been widely applied in many fields~(medical, commercial, and scientific domains). Despite its broad utilization, ASL remains a challenging task because it involves examining the complex relationships between the sentences in a potentially unstructured discourse. To resolve this problem, we have developed a simple yet effective approach called Dual-tower Multi-scale cOnvolution neural Network~(DMON) for the ASL task. Specifically, we organize arguments into a relationship matrix that together with the argument embeddings forms a relationship tensor and design a mechanism to capture relations with contextual arguments. Experimental results on three different-domain argument mining datasets demonstrate that our framework outperforms state-of-the-art models. The code is available at this https URL .</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Towards Cross-Scale Attention and Surface Supervision for Fractured Bone  Segmentation in CT</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01204">https://arxiv.org/abs/2405.01204</a></p>
  <p><b>作者</b>：Yu Zhou,  Xiahao Zou,  Yi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fracture trauma surgery, trauma surgery, essential step, preoperative planning, fractured bone segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bone segmentation is an essential step for the preoperative planning of fracture trauma surgery. The automated segmentation of fractured bone from computed tomography (CT) scans remains challenging, due to the large differences of fractures in position and morphology, and also the inherent anatomical characteristics of different bone structures. To alleviate these issues, we propose a cross-scale attention mechanism as well as a surface supervision strategy for fractured bone segmentation in CT. Specifically, a cross-scale attention mechanism is introduced to effectively aggregate the features among different scales to provide more powerful fracture representation. Moreover, a surface supervision strategy is employed, which explicitly constrains the network to pay more attention to the bone boundary. The efficacy of the proposed method is evaluated on a public dataset containing CT scans with hip fractures. The evaluation metrics are Dice similarity coefficient (DSC), average symmetric surface distance (ASSD), and Hausdorff distance (95HD). The proposed method achieves an average DSC of 93.36%, ASSD of 0.85mm, 95HD of 7.51mm. Our method offers an effective fracture segmentation approach for the pelvic CT examinations, and has the potential to be used for improving the segmentation performance of other types of fractures.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Towards Interpretable Reinforcement Learning with Constrained  Normalizing Flow Policies</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01198">https://arxiv.org/abs/2405.01198</a></p>
  <p><b>作者</b>：Finn Rietz,  Erik Schaffernicht,  Stefan Heinrich,  Johannes A. Stork</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black-box neural networks, neural networks, typically represented, represented by black-box, black-box neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning policies are typically represented by black-box neural networks, which are non-interpretable and not well-suited for safety-critical domains. To address both of these issues, we propose constrained normalizing flow policies as interpretable and safe-by-construction policy models. We achieve safety for reinforcement learning problems with instantaneous safety constraints, for which we can exploit domain knowledge by analytically constructing a normalizing flow that ensures constraint satisfaction. The normalizing flow corresponds to an interpretable sequence of transformations on action samples, each ensuring alignment with respect to a particular constraint. Our experiments reveal benefits beyond interpretability in an easier learning objective and maintained constraint satisfaction throughout the entire learning process. Our approach leverages constraints over reward engineering while offering enhanced interpretability, safety, and direct means of providing domain knowledge to the agent without relying on complex reward functions.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Gradient-Congruity Guided Federated Sparse Training</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01189">https://arxiv.org/abs/2405.01189</a></p>
  <p><b>作者</b>：Chris Xing Tian,  Yibing Liu,  Haoliang Li,  Ray C.C. Cheung,  Shiqi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, machine learning, machine learning technique, distributed machine learning, computing allows artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Edge computing allows artificial intelligence and machine learning models to be deployed on edge devices, where they can learn from local data and collaborate to form a global model. Federated learning (FL) is a distributed machine learning technique that facilitates this process while preserving data privacy. However, FL also faces challenges such as high computational and communication costs regarding resource-constrained devices, and poor generalization performance due to the heterogeneity of data across edge clients and the presence of out-of-distribution data. In this paper, we propose the Gradient-Congruity Guided Federated Sparse Training (FedSGC), a novel method that integrates dynamic sparse training and gradient congruity inspection into federated learning framework to address these issues. Our method leverages the idea that the neurons, in which the associated gradients with conflicting directions with respect to the global model contain irrelevant or less generalized information for other clients, and could be pruned during the sparse training process. Conversely, the neurons where the associated gradients with consistent directions could be grown in a higher priority. In this way, FedSGC can greatly reduce the local computation and communication overheads while, at the same time, enhancing the generalization abilities of FL. We evaluate our method on challenging non-i.i.d settings and show that it achieves competitive accuracy with state-of-the-art FL methods across various scenarios while minimizing computation and communication costs.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Potential Energy based Mixture Model for Noisy Label Learning</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01186">https://arxiv.org/abs/2405.01186</a></p>
  <p><b>作者</b>：Zijia Wang,  Wenbin Yang,  Zhisong Liu,  Zhen Jia</p>
  <p><b>备注</b>：36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：Training deep neural, challenging task, important and challenging, potential energy, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training deep neural networks (DNNs) from noisy labels is an important and challenging task. However, most existing approaches focus on the corrupted labels and ignore the importance of inherent data structure. To bridge the gap between noisy labels and data, inspired by the concept of potential energy in physics, we propose a novel Potential Energy based Mixture Model (PEMM) for noise-labels learning. We innovate a distance-based classifier with the potential energy regularization on its class centers. Embedding our proposed classifier with existing deep learning backbones, we can have robust networks with better feature representations. They can preserve intrinsic structures from the data, resulting in a superior noisy tolerance. We conducted extensive experiments to analyze the efficiency of our proposed model on several real-world datasets. Quantitative results show that it can achieve state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Uncertainty-aware self-training with expectation maximization basis  transformation</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01175">https://arxiv.org/abs/2405.01175</a></p>
  <p><b>作者</b>：Zijia Wang,  Wenbin Yang,  Zhisong Liu,  Zhen Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning, powerful approach, approach to deep, uncertainty information, uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-training is a powerful approach to deep learning. The key process is to find a pseudo-label for modeling. However, previous self-training algorithms suffer from the over-confidence issue brought by the hard labels, even some confidence-related regularizers cannot comprehensively catch the uncertainty. Therefore, we propose a new self-training framework to combine uncertainty information of both model and dataset. Specifically, we propose to use Expectation-Maximization (EM) to smooth the labels and comprehensively estimate the uncertainty information. We further design a basis extraction network to estimate the initial basis from the dataset. The obtained basis with uncertainty can be filtered based on uncertainty information. It can then be transformed into the real hard label to iteratively update the model and basis in the retraining process. Experiments on image classification and semantic segmentation show the advantages of our methods among confidence-aware self-training algorithms with 1-3 percentage improvement on different datasets.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Interpretable Data-driven Anomaly Detection in Industrial Processes with  ExIFFI</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01158">https://arxiv.org/abs/2405.01158</a></p>
  <p><b>作者</b>：Davide Frizzo,  Francesco Borsatti,  Alessio Arcudi,  Antonio De Moliner,  Roberto Oboe,  Gian Antonio Susto</p>
  <p><b>备注</b>：6 pages, submitted to IEEE RTSI 2024</p>
  <p><b>关键词</b>：Anomaly detection, Extended Isolation Forest, Anomaly detection method, crucial process, process often required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection (AD) is a crucial process often required in industrial settings. Anomalies can signal underlying issues within a system, prompting further investigation. Industrial processes aim to streamline operations as much as possible, encompassing the production of the final product, making AD an essential mean to reach this goal.Conventional anomaly detection methodologies typically classify observations as either normal or anomalous without providing insight into the reasons behind these classifications.Consequently, in light of the emergence of Industry 5.0, a more desirable approach involves providing interpretable outcomes, enabling users to understand the rationale behind the results.This paper presents the first industrial application of ExIFFI, a recently developed approach focused on the production of fast and efficient explanations for the Extended Isolation Forest (EIF) Anomaly detection method. ExIFFI is tested on two publicly available industrial datasets demonstrating superior effectiveness in explanations and computational efficiency with the respect to other state-of-the-art explainable AD models.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Self-Supervised Learning for Interventional Image Analytics: Towards  Robust Device Trackers</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01156">https://arxiv.org/abs/2405.01156</a></p>
  <p><b>作者</b>：Saahil Islam,  Venkatesh N. Murthy,  Dominik Neumann,  Badhan Kumar Das,  Puneet Sharma,  Andreas Maier,  Dorin Comaniciu,  Florin C. Ghesu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：endovascular cardiac interventions, live X-ray image, accurate detection, guiding catheters, catheters in live</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An accurate detection and tracking of devices such as guiding catheters in live X-ray image acquisitions is an essential prerequisite for endovascular cardiac interventions. This information is leveraged for procedural guidance, e.g., directing stent placements. To ensure procedural safety and efficacy, there is a need for high robustness no failures during tracking. To achieve that, one needs to efficiently tackle challenges, such as: device obscuration by contrast agent or other external devices or wires, changes in field-of-view or acquisition angle, as well as the continuous movement due to cardiac and respiratory motion. To overcome the aforementioned challenges, we propose a novel approach to learn spatio-temporal features from a very large data cohort of over 16 million interventional X-ray frames using self-supervision for image sequence data. Our approach is based on a masked image modeling technique that leverages frame interpolation based reconstruction to learn fine inter-frame temporal correspondences. The features encoded in the resulting model are fine-tuned downstream. Our approach achieves state-of-the-art performance and in particular robustness compared to ultra optimized reference solutions (that use multi-stage feature fusion, multi-task and flow regularization). The experiments show that our method achieves 66.31% reduction in maximum tracking error against reference solutions (23.20% when flow regularization is used); achieving a success score of 97.95% at a 3x faster inference speed of 42 frames-per-second (on GPU). The results encourage the use of our approach in various other tasks within interventional image analytics that require effective understanding of spatio-temporal semantics.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Leveraging Procedural Generation for Learning Autonomous Peg-in-Hole  Assembly in Space</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01134">https://arxiv.org/abs/2405.01134</a></p>
  <p><b>作者</b>：Andrej Orsula,  Matthieu Geist,  Miguel Olivares-Mendez,  Carol Martinez</p>
  <p><b>备注</b>：Accepted for publication at the 2024 International Conference on Space Robotics (iSpaRo) | The source code is available at this https URL</p>
  <p><b>关键词</b>：autonomously assemble structures, ability to autonomously, autonomously assemble, assemble structures, structures is crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to autonomously assemble structures is crucial for the development of future space infrastructure. However, the unpredictable conditions of space pose significant challenges for robotic systems, necessitating the development of advanced learning techniques to enable autonomous assembly. In this study, we present a novel approach for learning autonomous peg-in-hole assembly in the context of space robotics. Our focus is on enhancing the generalization and adaptability of autonomous systems through deep reinforcement learning. By integrating procedural generation and domain randomization, we train agents in a highly parallelized simulation environment across a spectrum of diverse scenarios with the aim of acquiring a robust policy. The proposed approach is evaluated using three distinct reinforcement learning algorithms to investigate the trade-offs among various paradigms. We demonstrate the adaptability of our agents to novel scenarios and assembly sequences while emphasizing the potential of leveraging advanced simulation techniques for robot learning in space. Our findings set the stage for future advancements in intelligent robotic systems capable of supporting ambitious space missions and infrastructure development beyond Earth.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Efficient Data Generation for Source-grounded Information-seeking  Dialogs: A Use Case for Meeting Transcripts</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01121">https://arxiv.org/abs/2405.01121</a></p>
  <p><b>作者</b>：Lotem Golany,  Filippo Galgani,  Maya Mamo,  Nimrod Parasol,  Omer Vandsburger,  Nadav Bar,  Ido Dagan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：creating source-grounded information-seeking, creating source-grounded, costly and hard, hard to implement, implement due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing methods for creating source-grounded information-seeking dialog datasets are often costly and hard to implement due to their sole reliance on human annotators. We propose combining large language models (LLMs) prompting with human expertise for more efficient and reliable data generation. Instead of the labor-intensive Wizard-of-Oz (WOZ) method, where two annotators generate a dialog from scratch, role-playing agent and user, we use LLM generation to simulate the two roles. Annotators then verify the output and augment it with attribution data. We demonstrate our method by constructing MISeD -- Meeting Information Seeking Dialogs dataset -- the first information-seeking dialog dataset focused on meeting transcripts. Models finetuned with MISeD demonstrate superior performance on our test set, as well as on a novel fully-manual WOZ test set and an existing query-based summarization benchmark, suggesting the utility of our approach.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Domain-Transferred Synthetic Data Generation for Improving Monocular  Depth Estimation</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01113">https://arxiv.org/abs/2405.01113</a></p>
  <p><b>作者</b>：Seungyeop Lee,  Knut Peterson,  Solmaz Arezoomandan,  Bill Cai,  Peihan Li,  Lifeng Zhou,  David Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collected RGB images, obtaining high-quality depth, collected RGB, RGB images, major obstacle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A major obstacle to the development of effective monocular depth estimation algorithms is the difficulty in obtaining high-quality depth data that corresponds to collected RGB images. Collecting this data is time-consuming and costly, and even data collected by modern sensors has limited range or resolution, and is subject to inconsistencies and noise. To combat this, we propose a method of data generation in simulation using 3D synthetic environments and CycleGAN domain transfer. We compare this method of data generation to the popular NYUDepth V2 dataset by training a depth estimation model based on the DenseDepth structure using different training sets of real and simulated data. We evaluate the performance of the models on newly collected images and LiDAR depth data from a Husky robot to verify the generalizability of the approach and show that GAN-transformed data can serve as an effective alternative to real-world data, particularly in depth estimation.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Federated Learning with Heterogeneous Data Handling for Robust Vehicular  Object Detection</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01108">https://arxiv.org/abs/2405.01108</a></p>
  <p><b>作者</b>：Ahmad Khalil,  Tizian Dege,  Pegah Golchin,  Rostyslav Olshevskyi,  Antonio Fernandez Anta,  Tobias Meuser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully autonomous driving, refining precise perception, precise perception models, autonomous driving, model training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the pursuit of refining precise perception models for fully autonomous driving, continual online model training becomes essential. Federated Learning (FL) within vehicular networks offers an efficient mechanism for model training while preserving raw sensory data integrity. Yet, FL struggles with non-identically distributed data (e.g., quantity skew), leading to suboptimal convergence rates during model training. In previous work, we introduced FedLA, an innovative Label-Aware aggregation method addressing data heterogeneity in FL for generic scenarios.
In this paper, we introduce FedProx+LA, a novel FL method building upon the state-of-the-art FedProx and FedLA to tackle data heterogeneity, which is specifically tailored for vehicular networks. We evaluate the efficacy of FedProx+LA in continuous online object detection model training. Through a comparative analysis against conventional and state-of-the-art methods, our findings reveal the superior convergence rate of FedProx+LA. Notably, if the label distribution is very heterogeneous, our FedProx+LA approach shows substantial improvements in detection performance compared to baseline methods, also outperforming our previous FedLA approach. Moreover, both FedLA and FedProx+LA increase convergence speed by 30% compared to baseline methods.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Less is More: on the Over-Globalizing Problem in Graph Transformers</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01102">https://arxiv.org/abs/2405.01102</a></p>
  <p><b>作者</b>：Yujie Xing,  Xiao Wang,  Yibo Li,  Hai Huang,  Chuan Shi</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：global attention mechanism, Global Graph Transformer, Graph Transformer, attention mechanism, global attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Transformer, due to its global attention mechanism, has emerged as a new tool in dealing with graph-structured data. It is well recognized that the global attention mechanism considers a wider receptive field in a fully connected graph, leading many to believe that useful information can be extracted from all the nodes. In this paper, we challenge this belief: does the globalizing property always benefit Graph Transformers? We reveal the over-globalizing problem in Graph Transformer by presenting both empirical evidence and theoretical analysis, i.e., the current attention mechanism overly focuses on those distant nodes, while the near nodes, which actually contain most of the useful information, are relatively weakened. Then we propose a novel Bi-Level Global Graph Transformer with Collaborative Training (CoBFormer), including the inter-cluster and intra-cluster Transformers, to prevent the over-globalizing problem while keeping the ability to extract valuable information from distant nodes. Moreover, the collaborative training is proposed to improve the model's generalization ability with a theoretical guarantee. Extensive experiments on various graphs well validate the effectiveness of our proposed CoBFormer.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Poisoning Attacks on Federated Learning for Autonomous Driving</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01073">https://arxiv.org/abs/2405.01073</a></p>
  <p><b>作者</b>：Sonakshi Garg,  Hugo Jönsson,  Gustav Kalander,  Axel Nilsson,  Bhhaanu Pirange,  Viktor Valadi,  Johan Östman</p>
  <p><b>备注</b>：Accepted to SCAI2024</p>
  <p><b>关键词</b>：decentralized learning paradigm, collaboratively train models, Federated Learning, learning paradigm, enabling parties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a decentralized learning paradigm, enabling parties to collaboratively train models while keeping their data confidential. Within autonomous driving, it brings the potential of reducing data storage costs, reducing bandwidth requirements, and to accelerate the learning. FL is, however, susceptible to poisoning attacks. In this paper, we introduce two novel poisoning attacks on FL tailored to regression tasks within autonomous driving: FLStealth and Off-Track Attack (OTA). FLStealth, an untargeted attack, aims at providing model updates that deteriorate the global model performance while appearing benign. OTA, on the other hand, is a targeted attack with the objective to change the global model's behavior when exposed to a certain trigger. We demonstrate the effectiveness of our attacks by conducting comprehensive experiments pertaining to the task of vehicle trajectory prediction. In particular, we show that, among five different untargeted attacks, FLStealth is the most successful at bypassing the considered defenses employed by the server. For OTA, we demonstrate the inability of common defense strategies to mitigate the attack, highlighting the critical need for new defensive mechanisms against targeted attacks within FL for autonomous driving.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：AB-Training: A Communication-Efficient Approach for Distributed Low-Rank  Learning</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01067">https://arxiv.org/abs/2405.01067</a></p>
  <p><b>作者</b>：Daniel Coquelin,  Katherina Flügel,  Marie Weiel,  Nicholas Kiefer,  Muhammed Öz,  Charlotte Debus,  Achim Streit,  Markus Götz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distributed-memory computing clusters, Communication bottlenecks hinder, distributed neural network, computing clusters, bottlenecks hinder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication bottlenecks hinder the scalability of distributed neural network training, particularly on distributed-memory computing clusters. To significantly reduce this communication overhead, we introduce AB-training, a novel data-parallel training method that decomposes weight matrices into low-rank representations and utilizes independent group-based training. This approach consistently reduces network traffic by 50% across multiple scaling scenarios, increasing the training potential on communication-constrained systems. Our method exhibits regularization effects at smaller scales, leading to improved generalization for models like VGG16, while achieving a remarkable 44.14 : 1 compression ratio during training on CIFAR-10 and maintaining competitive accuracy. Albeit promising, our experiments reveal that large batch effects remain a challenge even in low-rank training regimes.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：HandSSCA: 3D Hand Mesh Reconstruction with State Space Channel Attention  from RGB images</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01066">https://arxiv.org/abs/2405.01066</a></p>
  <p><b>作者</b>：Zixun Jiao,  Xihan Wang,  Quanli Gao</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：single RGB image, single RGB, RGB image, occluded by objects, RGB</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing a hand mesh from a single RGB image is a challenging task because hands are often occluded by objects. Most previous works attempted to introduce more additional information and adopt attention mechanisms to improve 3D reconstruction results, but it would increased computational complexity. This observation prompts us to propose a new and concise architecture while improving computational efficiency. In this work, we propose a simple and effective 3D hand mesh reconstruction network HandSSCA, which is the first to incorporate state space modeling into the field of hand pose estimation. In the network, we have designed a novel state space channel attention module that extends the effective sensory field, extracts hand features in the spatial dimension, and enhances hand regional features in the channel dimension. This design helps to reconstruct a complete and detailed hand mesh. Extensive experiments conducted on well-known datasets featuring challenging hand-object occlusions (such as FREIHAND, DEXYCB, and HO3D) demonstrate that our proposed HandSSCA achieves state-of-the-art performance while maintaining a minimal parameter count.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：A text-based, generative deep learning model for soil reflectance  spectrum simulation in the VIS-NIR (400-2499 nm) bands</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01060">https://arxiv.org/abs/2405.01060</a></p>
  <p><b>作者</b>：Tong Lei,  Brian N. Bailey</p>
  <p><b>备注</b>：The paper has been submitted to Remote sensing of Environment and revised</p>
  <p><b>关键词</b>：soil reflectance spectra, reflectance spectra, soil reflectance, reflectance spectra based, Simulating soil reflectance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulating soil reflectance spectra is invaluable for soil-plant radiative modeling and training machine learning models, yet it is difficult as the intricate relationships between soil structure and its constituents. To address this, a fully data-driven soil optics generative model (SOGM) for simulation of soil reflectance spectra based on soil property inputs was developed. The model is trained on an extensive dataset comprising nearly 180,000 soil spectra-property pairs from 17 datasets. It generates soil reflectance spectra from text-based inputs describing soil properties and their values rather than only numerical values and labels in binary vector format. The generative model can simulate output spectra based on an incomplete set of input properties. SOGM is based on the denoising diffusion probabilistic model (DDPM). Two additional sub-models were also built to complement the SOGM: a spectral padding model that can fill in the gaps for spectra shorter than the full visible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra model that can estimate the effects of water content on soil reflectance spectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by coupling with the Helios 3D plant modeling software, which allowed for generation of synthetic aerial images of simulated soil and plant scenes. It can also be easily integrated with soil-plant radiation model used for remote sensin research like PROSAIL. The testing results of the SOGM on new datasets that not included in model training proved that the model can generate reasonable soil reflectance spectra based on available property inputs. The presented models are openly accessible on: this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Leverage Multi-source Traffic Demand Data Fusion with Transformer Model  for Urban Parking Prediction</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01055">https://arxiv.org/abs/2405.01055</a></p>
  <p><b>作者</b>：Yin Huang,  Yongqi Dong,  Youhua Tang,  Li Li</p>
  <p><b>备注</b>：7 pages, 5 figures, under review by the 27th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2024)</p>
  <p><b>关键词</b>：private car ownership, parking availability prediction, necessitating effective parking, spatial-temporal deep learning, urban private car</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The escalation in urban private car ownership has worsened the urban parking predicament, necessitating effective parking availability prediction for urban planning and management. However, the existing prediction methods suffer from low prediction accuracy with the lack of spatial-temporal correlation features related to parking volume, and neglect of flow patterns and correlations between similar parking lots within certain areas. To address these challenges, this study proposes a parking availability prediction framework integrating spatial-temporal deep learning with multi-source data fusion, encompassing traffic demand data from multiple sources (e.g., metro, bus, taxi services), and parking lot data. The framework is based on the Transformer as the spatial-temporal deep learning model and leverages K-means clustering to establish parking cluster zones, extracting and integrating traffic demand characteristics from various transportation modes (i.e., metro, bus, online ride-hailing, and taxi) connected to parking lots. Real-world empirical data was used to verify the effectiveness of the proposed method compared with different machine learning, deep learning, and traditional statistical models for predicting parking availability. Experimental results reveal that, with the proposed pipeline, the developed Transformer model outperforms other models in terms of various metrics, e.g., Mean Squared Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). By fusing multi-source demanding data with spatial-temporal deep learning techniques, this approach offers the potential to develop parking availability prediction systems that furnish more accurate and timely information to both drivers and urban planners, thereby fostering more efficient and sustainable urban mobility.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Explicitly Modeling Generality into Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01053">https://arxiv.org/abs/2405.01053</a></p>
  <p><b>作者</b>：Jingyao Wang,  Wenwen Qiang,  Changwen Zheng</p>
  <p><b>备注</b>：28 pages</p>
  <p><b>关键词</b>：SSL, achieve excellent performance, generality, achieve, achieve excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of generality in machine learning is to achieve excellent performance on various unseen tasks and domains. Recently, self-supervised learning (SSL) has been regarded as an effective method to achieve this goal. It can learn high-quality representations from unlabeled data and achieve promising empirical performance on multiple downstream tasks. Existing SSL methods mainly constrain generality from two aspects: (i) large-scale training data, and (ii) learning task-level shared knowledge. However, these methods lack explicit modeling of the SSL generality in the learning objective, and the theoretical understanding of SSL's generality remains limited. This may cause SSL models to overfit in data-scarce situations and generalize poorly in the real world, making it difficult to achieve true generality. To address these issues, we provide a theoretical definition of generality in SSL and define a $\sigma$-measurement to help quantify it. Based on this insight, we explicitly model generality into self-supervised learning and further propose a novel SSL framework, called GeSSL. It introduces a self-motivated target based on $\sigma$-measurement, which enables the model to find the optimal update direction towards generality. Extensive theoretical and empirical evaluations demonstrate the superior performance of the proposed GeSSL.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：LOQA: Learning with Opponent Q-Learning Awareness</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01035">https://arxiv.org/abs/2405.01035</a></p>
  <p><b>作者</b>：Milad Aghajohari,  Juan Agustin Duque,  Tim Cooijmans,  Aaron Courville</p>
  <p><b>备注</b>：accepted to ICLR but still not in proceedings this https URL</p>
  <p><b>关键词</b>：resemble the dynamics, dynamics of general-sum, strives to optimize, general-sum games, agent individual utility</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In various real-world scenarios, interactions among agents often resemble the dynamics of general-sum games, where each agent strives to optimize its own utility. Despite the ubiquitous relevance of such settings, decentralized machine learning algorithms have struggled to find equilibria that maximize individual utility while preserving social welfare. In this paper we introduce Learning with Opponent Q-Learning Awareness (LOQA), a novel, decentralized reinforcement learning algorithm tailored to optimizing an agent's individual utility while fostering cooperation among adversaries in partially competitive environments. LOQA assumes the opponent samples actions proportionally to their action-value function Q. Experimental results demonstrate the effectiveness of LOQA at achieving state-of-the-art performance in benchmark scenarios such as the Iterated Prisoner's Dilemma and the Coin Game. LOQA achieves these outcomes with a significantly reduced computational footprint, making it a promising approach for practical multi-agent applications.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01029">https://arxiv.org/abs/2405.01029</a></p>
  <p><b>作者</b>：Jianan Zhou,  Zhiguang Cao,  Yaoxin Wu,  Wen Song,  Yining Ma,  Jie Zhang,  Chi Xu</p>
  <p><b>备注</b>：Accepted at ICML 2024</p>
  <p><b>关键词</b>：Learning to solve, garnered much attention, solve vehicle routing, vehicle routing problems, solve vehicle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning to solve vehicle routing problems (VRPs) has garnered much attention. However, most neural solvers are only structured and trained independently on a specific problem, making them less generic and practical. In this paper, we aim to develop a unified neural solver that can cope with a range of VRP variants simultaneously. Specifically, we propose a multi-task vehicle routing solver with mixture-of-experts (MVMoE), which greatly enhances the model capacity without a proportional increase in computation. We further develop a hierarchical gating mechanism for the MVMoE, delivering a good trade-off between empirical performance and computational complexity. Experimentally, our method significantly promotes the zero-shot generalization performance on 10 unseen VRP variants, and showcases decent results on the few-shot setting and real-world benchmark instances. We further provide extensive studies on the effect of MoE configurations in solving VRPs. Surprisingly, the hierarchical gating can achieve much better out-of-distribution generalization performance. The source code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：UniGen: Universal Domain Generalization for Sentiment Classification via  Zero-shot Dataset Generation</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01022">https://arxiv.org/abs/2405.01022</a></p>
  <p><b>作者</b>：Juhwan Choi,  Yeonghwa Kim,  Seunguk Yu,  JungMin Yun,  YoungBin Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prompt-based few-shot learning, exhibited great flexibility, pre-trained language models, extensive parameter size, few-shot learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although pre-trained language models have exhibited great flexibility and versatility with prompt-based few-shot learning, they suffer from the extensive parameter size and limited applicability for inference. Recent studies have suggested that PLMs be used as dataset generators and a tiny task-specific model be trained to achieve efficient inference. However, their applicability to various domains is limited because they tend to generate domain-specific datasets. In this work, we propose a novel approach to universal domain generalization that generates a dataset regardless of the target domain. This allows for generalization of the tiny task model to any domain that shares the label space, thus enhancing the real-world applicability of the dataset generation paradigm. Our experiments indicate that the proposed method accomplishes generalizability across various domains while using a parameter set that is orders of magnitude smaller than PLMs.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Addressing Diverging Training Costs using Local Restoration for Precise  Bird's Eye View Map Construction</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01016">https://arxiv.org/abs/2405.01016</a></p>
  <p><b>作者</b>：Minsu Kim,  Giseop Kim,  Sunwook Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bird Eye View, Eye View, Bird Eye, demonstrated remarkable mapping, advancements in Bird</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in Bird's Eye View (BEV) fusion for map construction have demonstrated remarkable mapping of urban environments. However, their deep and bulky architecture incurs substantial amounts of backpropagation memory and computing latency. Consequently, the problem poses an unavoidable bottleneck in constructing high-resolution (HR) BEV maps, as their large-sized features cause significant increases in costs including GPU memory consumption and computing latency, named diverging training costs issue. Affected by the problem, most existing methods adopt low-resolution (LR) BEV and struggle to estimate the precise locations of urban scene components like road lanes, and sidewalks. As the imprecision leads to risky self-driving, the diverging training costs issue has to be resolved. In this paper, we address the issue with our novel Trumpet Neural Network (TNN) mechanism. The framework utilizes LR BEV space and outputs an up-sampled semantic BEV map to create a memory-efficient pipeline. To this end, we introduce Local Restoration of BEV representation. Specifically, the up-sampled BEV representation has severely aliased, blocky signals, and thick semantic labels. Our proposed Local Restoration restores the signals and thins (or narrows down) the width of the labels. Our extensive experiments show that the TNN mechanism provides a plug-and-play memory-efficient pipeline, thereby enabling the effective estimation of real-sized (or precise) semantic labels for BEV map construction.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Non-clairvoyant Scheduling with Partial Predictions</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01013">https://arxiv.org/abs/2405.01013</a></p>
  <p><b>作者</b>：Ziyad Benomar,  Vianney Perchet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-clairvoyant scheduling problem, quality guarantees, non-clairvoyant scheduling, scheduling problem, problem has gained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The non-clairvoyant scheduling problem has gained new interest within learning-augmented algorithms, where the decision-maker is equipped with predictions without any quality guarantees. In practical settings, access to predictions may be reduced to specific instances, due to cost or data limitations. Our investigation focuses on scenarios where predictions for only $B$ job sizes out of $n$ are available to the algorithm. We first establish near-optimal lower bounds and algorithms in the case of perfect predictions. Subsequently, we present a learning-augmented algorithm satisfying the robustness, consistency, and smoothness criteria, and revealing a novel tradeoff between consistency and smoothness inherent in the scenario with a restricted number of predictions.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Deep Learning Models in Speech Recognition: Measuring GPU Energy  Consumption, Impact of Noise and Model Quantization for Edge Deployment</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01004">https://arxiv.org/abs/2405.01004</a></p>
  <p><b>作者</b>：Aditya Chakravarty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved word-error rates, surpassing human annotator, extensive server resources, significant carbon footprints, Recent transformer-based ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent transformer-based ASR models have achieved word-error rates (WER) below 4%, surpassing human annotator accuracy, yet they demand extensive server resources, contributing to significant carbon footprints. The traditional server-based architecture of ASR also presents privacy concerns, alongside reliability and latency issues due to network dependencies. In contrast, on-device (edge) ASR enhances privacy, boosts performance, and promotes sustainability by effectively balancing energy use and accuracy for specific applications. This study examines the effects of quantization, memory demands, and energy consumption on the performance of various ASR model inference on the NVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models using FP32, FP16, and INT8 quantization on clean and noisy datasets, we highlight the crucial trade-offs between accuracy, speeds, quantization, energy efficiency, and memory needs. We found that changing precision from fp32 to fp16 halves the energy consumption for audio transcription across different models, with minimal performance degradation. A larger model size and number of parameters neither guarantees better resilience to noise, nor predicts the energy consumption for a given transcription load. These, along with several other findings offer novel insights for optimizing ASR systems within energy- and memory-limited environments, crucial for the development of efficient on-device ASR solutions. The code and input data needed to reproduce the results in this article are open sourced are available on [this https URL].</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Progressive Feedforward Collapse of ResNet Training</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00985">https://arxiv.org/abs/2405.00985</a></p>
  <p><b>作者</b>：Sicong Wang,  Kuo Gai,  Shihua Zhang</p>
  <p><b>备注</b>：14 pages, 5 figures</p>
  <p><b>关键词</b>：deep neural networks, simplex equiangular tight, equiangular tight frame, tight frame aligning, last-layer features collapse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural collapse (NC) is a simple and symmetric phenomenon for deep neural networks (DNNs) at the terminal phase of training, where the last-layer features collapse to their class means and form a simplex equiangular tight frame aligning with the classifier vectors. However, the relationship of the last-layer features to the data and intermediate layers during training remains unexplored. To this end, we characterize the geometry of intermediate layers of ResNet and propose a novel conjecture, progressive feedforward collapse (PFC), claiming the degree of collapse increases during the forward propagation of DNNs. We derive a transparent model for the well-trained ResNet according to that ResNet with weight decay approximates the geodesic curve in Wasserstein space at the terminal phase. The metrics of PFC indeed monotonically decrease across depth on various datasets. We propose a new surrogate model, multilayer unconstrained feature model (MUFM), connecting intermediate layers by an optimal transport regularizer. The optimal solution of MUFM is inconsistent with NC but is more concentrated relative to the input data. Overall, this study extends NC to PFC to model the collapse phenomenon of intermediate layers and its dependence on the input data, shedding light on the theoretical understanding of ResNet in classification problems.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Bayesian Optimization with LLM-Based Acquisition Functions for Natural  Language Preference Elicitation</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00981">https://arxiv.org/abs/2405.00981</a></p>
  <p><b>作者</b>：David Eric Austin,  Anton Korikov,  Armin Toroghi,  Scott Sanner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Designing preference elicitation, personalized conversational recommendation, user top item, top item preferences, quickly ascertain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing preference elicitation (PE) methodologies that can quickly ascertain a user's top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to generate NL queries which actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：CACTUS: Chemistry Agent Connecting Tool-Usage to Science</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00972">https://arxiv.org/abs/2405.00972</a></p>
  <p><b>作者</b>：Andrew D. McNaughton,  Gautham Ramalaxmi,  Agustin Kruel,  Carter R. Knutson,  Rohith A. Varikoti,  Neeraj Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Chemistry Agent Connecting, Large language models, shown remarkable potential, Agent Connecting Tool-Usage, Large language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee  Responses</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00970">https://arxiv.org/abs/2405.00970</a></p>
  <p><b>作者</b>：Jionghao Lin,  Zifei Han,  Danielle R. Thomas,  Ashish Gurung,  Shivang Gupta,  Vincent Aleven,  Kenneth R. Koedinger</p>
  <p><b>备注</b>：International Journal of Artificial Intelligence in Education</p>
  <p><b>关键词</b>：effective instructional method, qualified tutors, instructional method, qualified tutors remains, widely acknowledged</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One-on-one tutoring is widely acknowledged as an effective instructional method, conditioned on qualified tutors. However, the high demand for qualified tutors remains a challenge, often necessitating the training of novice tutors (i.e., trainees) to ensure effective tutoring. Research suggests that providing timely explanatory feedback can facilitate the training process for trainees. However, it presents challenges due to the time-consuming nature of assessing trainee performance by human experts. Inspired by the recent advancements of large language models (LLMs), our study employed the GPT-4 model to build an explanatory feedback system. This system identifies trainees' responses in binary form (i.e., correct/incorrect) and automatically provides template-based feedback with responses appropriately rephrased by the GPT-4 model. We conducted our study on 410 responses from trainees across three training lessons: Giving Effective Praise, Reacting to Errors, and Determining What Students Know. Our findings indicate that: 1) using a few-shot approach, the GPT-4 model effectively identifies correct/incorrect trainees' responses from three training lessons with an average F1 score of 0.84 and an AUC score of 0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases incorrect trainees' responses into desired responses, achieving performance comparable to that of human experts.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Efficient Compression of Multitask Multilingual Speech Models</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00966">https://arxiv.org/abs/2405.00966</a></p>
  <p><b>作者</b>：Thomas Palmeira Ferraz</p>
  <p><b>备注</b>：Master Thesis</p>
  <p><b>关键词</b>：speech model covering, model covering, ASR, languages, multilingual speech model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we examine its limitations, demonstrating the presence of speaker-related (gender, age) and model-related (resourcefulness and model size) bias. Despite that, we show that only model-related bias are amplified by quantization, impacting more low-resource languages and smaller models. Searching for a better compression approach, we propose DistilWhisper, an approach that is able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Foundations for Digital Twins</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00960">https://arxiv.org/abs/2405.00960</a></p>
  <p><b>作者</b>：Regina Hurley,  Dan Maxwell,  Jon McLellan,  Finn Wilson,  John Beverley</p>
  <p><b>备注</b>：14</p>
  <p><b>关键词</b>：semantic interoperability challenges, digital twins, Common Core Ontologies, Basic Formal Ontology, interoperability challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The growing reliance on digital twins across various industries and domains brings with it semantic interoperability challenges. Ontologies are a well-known strategy for addressing such challenges, though given the complexity of the phenomenon, there are risks of reintroducing the interoperability challenges at the level of ontology representations. In the interest of avoiding such pitfalls, we introduce and defend characterizations of digital twins within the context of the Common Core Ontologies, an extension of the widely-used Basic Formal Ontology. We provide a set of definitions and design patterns relevant to the domain of digital twins, highlighted by illustrative use cases of digital twins and their physical counterparts. In doing so, we provide a foundation on which to build more sophisticated ontological content related and connected to digital twins.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Generative manufacturing systems using diffusion models and ChatGPT</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00958">https://arxiv.org/abs/2405.00958</a></p>
  <p><b>作者</b>：Xingyu Li,  Fei Tao,  Wei Ye,  Aydin Nassehi,  John W. Sutherland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：coordinate autonomous manufacturing, introduce Generative Manufacturing, autonomous manufacturing assets, Generative Manufacturing Systems, GMS employs generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we introduce Generative Manufacturing Systems (GMS) as a novel approach to effectively manage and coordinate autonomous manufacturing assets, thereby enhancing their responsiveness and flexibility to address a wide array of production objectives and human preferences. Deviating from traditional explicit modeling, GMS employs generative AI, including diffusion models and ChatGPT, for implicit learning from envisioned futures, marking a shift from a model-optimum to a training-sampling decision-making. Through the integration of generative AI, GMS enables complex decision-making through interactive dialogue with humans, allowing manufacturing assets to generate multiple high-quality global decisions that can be iteratively refined based on human feedback. Empirical findings showcase GMS's substantial improvement in system resilience and responsiveness to uncertainties, with decision times reduced from seconds to milliseconds. The study underscores the inherent creativity and diversity in the generated solutions, facilitating human-centric decision-making through seamless and continuous human-machine interactions.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：IntraMix: Intra-Class Mixup Generation for Accurate Labels and Neighbors</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00957">https://arxiv.org/abs/2405.00957</a></p>
  <p><b>作者</b>：Shenghe Zheng,  Hongzhi Wang,  Xianglong Liu</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, aggregating neighborhood information, Insufficient High-Quality Labels, demonstrate excellent performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) demonstrate excellent performance on graphs, with their core idea about aggregating neighborhood information and learning from labels. However, the prevailing challenges in most graph datasets are twofold of Insufficient High-Quality Labels and Lack of Neighborhoods, resulting in weak GNNs. Existing data augmentation methods designed to address these two issues often tackle only one. They may either require extensive training of generators, rely on overly simplistic strategies, or demand substantial prior knowledge, leading to suboptimal generalization abilities. To simultaneously address both of these two challenges, we propose an elegant method called IntraMix. IntraMix innovatively employs Mixup among low-quality labeled data of the same class, generating high-quality labeled data at minimal cost. Additionally, it establishes neighborhoods for the generated data by connecting them with data from the same class with high confidence, thereby enriching the neighborhoods of graphs. IntraMix efficiently tackles both challenges faced by graphs and challenges the prior notion of the limited effectiveness of Mixup in node classification. IntraMix serves as a universal framework that can be readily applied to all GNNs. Extensive experiments demonstrate the effectiveness of IntraMix across various GNNs and datasets.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Provably Efficient Reinforcement Learning for Adversarial Restless  Multi-Armed Bandits with Unknown Transitions and Bandit Feedback</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00950">https://arxiv.org/abs/2405.00950</a></p>
  <p><b>作者</b>：Guojun Xiong,  Jian Li</p>
  <p><b>备注</b>：Accepted by ICML 2024</p>
  <p><b>关键词</b>：modeling sequential decision, sequential decision making, decision making problems, Restless multi-armed bandits, play a central</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Restless multi-armed bandits (RMAB) play a central role in modeling sequential decision making problems under an instantaneous activation constraint that at most B arms can be activated at any decision epoch. Each restless arm is endowed with a state that evolves independently according to a Markov decision process regardless of being activated or not. In this paper, we consider the task of learning in episodic RMAB with unknown transition functions and adversarial rewards, which can change arbitrarily across episodes. Further, we consider a challenging but natural bandit feedback setting that only adversarial rewards of activated arms are revealed to the decision maker (DM). The goal of the DM is to maximize its total adversarial rewards during the learning process while the instantaneous activation constraint must be satisfied in each decision epoch. We develop a novel reinforcement learning algorithm with two key contributors: a novel biased adversarial reward estimator to deal with bandit feedback and unknown transitions, and a low-complexity index policy to satisfy the instantaneous activation constraint. We show $\tilde{\mathcal{O}}(H\sqrt{T})$ regret bound for our algorithm, where $T$ is the number of episodes and $H$ is the episode length. To our best knowledge, this is the first algorithm to ensure $\tilde{\mathcal{O}}(\sqrt{T})$ regret for adversarial RMAB in our considered challenging settings.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：EchoScene: Indoor Scene Generation via Information Echo over Scene Graph  Diffusion</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00915">https://arxiv.org/abs/2405.00915</a></p>
  <p><b>作者</b>：Guangyao Zhai,  Evin Pınar Örnek,  Dave Zhenyu Chen,  Ruotong Liao,  Yan Di,  Nassir Navab,  Federico Tombari,  Benjamin Busam</p>
  <p><b>备注</b>：25 pages. 10 figures</p>
  <p><b>关键词</b>：controllable generative model, scene, present EchoScene, scene graphs, controllable generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present EchoScene, an interactive and controllable generative model that generates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch diffusion model that dynamically adapts to scene graphs. Existing methods struggle to handle scene graphs due to varying numbers of nodes, multiple edge combinations, and manipulator-induced node-edge operations. EchoScene overcomes this by associating each node with a denoising process and enables collaborative information exchange, enhancing controllable and consistent generation aware of global constraints. This is achieved through an information echo scheme in both shape and layout branches. At every denoising step, all processes share their denoising data with an information exchange unit that combines these updates using graph convolution. The scheme ensures that the denoising processes are influenced by a holistic understanding of the scene graph, facilitating the generation of globally coherent scenes. The resulting scenes can be manipulated during inference by editing the input scene graph and sampling the noise in the diffusion model. Extensive experiments validate our approach, which maintains scene controllability and surpasses previous methods in generation fidelity. Moreover, the generated scenes are of high quality and thus directly compatible with off-the-shelf texture generation. Code and trained models are open-sourced.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Transformer-Based Self-Supervised Learning for Histopathological  Classification of Ischemic Stroke Clot Origin</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00908">https://arxiv.org/abs/2405.00908</a></p>
  <p><b>作者</b>：K. Yeh,  M. S. Jabal,  V. Gupta,  D. F. Kallmes,  W. Brinjikji,  B. S. Erdal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Background and Purpose, ischemic stroke, ischemic stroke clot, thromboembolism source, crucial for treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background and Purpose: Identifying the thromboembolism source in ischemic stroke is crucial for treatment and secondary prevention yet is often undetermined. This study describes a self-supervised deep learning approach in digital pathology of emboli for classifying ischemic stroke clot origin from histopathological images. Methods: The dataset included whole slide images (WSI) from the STRIP AI Kaggle challenge, consisting of retrieved clots from ischemic stroke patients following mechanical thrombectomy. Transformer-based deep learning models were developed using transfer learning and self-supervised pretraining for classifying WSI. Customizations included an attention pooling layer, weighted loss function, and threshold optimization. Various model architectures were tested and compared, and model performances were primarily evaluated using weighted logarithmic loss. Results: The model achieved a logloss score of 0.662 in cross-validation and 0.659 on the test set. Different model backbones were compared, with the swin_large_patch4_window12_384 showed higher performance. Thresholding techniques for clot origin classification were employed to balance false positives and negatives. Conclusion: The study demonstrates the extent of efficacy of transformer-based deep learning models in identifying ischemic stroke clot origins from histopathological images and emphasizes the need for refined modeling techniques specifically adapted to thrombi WSI. Further research is needed to improve model performance, interpretability, validate its effectiveness. Future enhancement could include integrating larger patient cohorts, advanced preprocessing strategies, and exploring ensemble multimodal methods for enhanced diagnostic accuracy.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：LOTUS: Improving Transformer Efficiency with Sparsity Pruning and Data  Lottery Tickets</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00906">https://arxiv.org/abs/2405.00906</a></p>
  <p><b>作者</b>：Ojasw Upadhyay</p>
  <p><b>备注</b>：3 pages, 5 figures</p>
  <p><b>关键词</b>：demands present challenges, revolutionized computer vision, vision transformer training, computational demands present, vision transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformers have revolutionized computer vision, but their computational demands present challenges for training and deployment. This paper introduces LOTUS (LOttery Transformers with Ultra Sparsity), a novel method that leverages data lottery ticket selection and sparsity pruning to accelerate vision transformer training while maintaining accuracy. Our approach focuses on identifying and utilizing the most informative data subsets and eliminating redundant model parameters to optimize the training process. Through extensive experiments, we demonstrate the effectiveness of LOTUS in achieving rapid convergence and high accuracy with significantly reduced computational requirements. This work highlights the potential of combining data selection and sparsity techniques for efficient vision transformer training, opening doors for further research and development in this area.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：MESA: Cooperative Meta-Exploration in Multi-Agent Learning through  Exploiting State-Action Space Structure</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00902">https://arxiv.org/abs/2405.00902</a></p>
  <p><b>作者</b>：Zhicheng Zhang,  Yancheng Liang,  Yi Wu,  Fei Fang</p>
  <p><b>备注</b>：Accepted to AAMAS 2024. 15 pages</p>
  <p><b>关键词</b>：optimal Nash Equilibrium, Pareto optimal Nash, Nash Equilibrium, find strategies close, close to Pareto</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent reinforcement learning (MARL) algorithms often struggle to find strategies close to Pareto optimal Nash Equilibrium, owing largely to the lack of efficient exploration. The problem is exacerbated in sparse-reward settings, caused by the larger variance exhibited in policy learning. This paper introduces MESA, a novel meta-exploration method for cooperative multi-agent learning. It learns to explore by first identifying the agents' high-rewarding joint state-action subspace from training tasks and then learning a set of diverse exploration policies to "cover" the subspace. These trained exploration policies can be integrated with any off-policy MARL algorithm for test-time tasks. We first showcase MESA's advantage in a multi-step matrix game. Furthermore, experiments show that with learned exploration policies, MESA achieves significantly better performance in sparse-reward tasks in several multi-agent particle environments and multi-agent MuJoCo environments, and exhibits the ability to generalize to more challenging tasks at test time.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Characterising the Creative Process in Humans and Large Language Models</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00899">https://arxiv.org/abs/2405.00899</a></p>
  <p><b>作者</b>：Surabhi S. Nath,  Peter Dayan,  Claire Stevenson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, Large language, Verbal Fluency Task, performing on par, creativity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models appear quite creative, often performing on par with the average human on creative tasks. However, research on LLM creativity has focused solely on \textit{products}, with little attention on the creative \textit{process}. Process analyses of human creativity often require hand-coded categories or exploit response times, which do not apply to LLMs. We provide an automated method to characterise how humans and LLMs explore semantic spaces on the Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task. We use sentence embeddings to identify response categories and compute semantic similarities, which we use to generate jump profiles. Our results corroborate earlier work in humans reporting both persistent (deep search in few semantic spaces) and flexible (broad search across multiple semantic spaces) pathways to creativity, where both pathways lead to similar creativity scores. LLMs were found to be biased towards either persistent or flexible paths, that varied across tasks. Though LLMs as a population match human profiles, their relationship with creativity is different, where the more flexible models score higher on creativity. Our dataset and scripts are available on \href{this https URL}{GitHub}.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Wake Vision: A Large-scale, Diverse Dataset and Benchmark Suite for  TinyML Person Detection</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00892">https://arxiv.org/abs/2405.00892</a></p>
  <p><b>作者</b>：Colby Banbury,  Emil Njor,  Matthew Stewart,  Pete Warden,  Manjunath Kudlur,  Nat Jeffries,  Xenofon Fafoutis,  Vijay Janapa Reddi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine learning applications, tiny machine learning, extremely low-power devices, Machine learning, Wake Vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning applications on extremely low-power devices, commonly referred to as tiny machine learning (TinyML), promises a smarter and more connected world. However, the advancement of current TinyML research is hindered by the limited size and quality of pertinent datasets. To address this challenge, we introduce Wake Vision, a large-scale, diverse dataset tailored for person detection -- the canonical task for TinyML visual sensing. Wake Vision comprises over 6 million images, which is a hundredfold increase compared to the previous standard, and has undergone thorough quality filtering. Using Wake Vision for training results in a 2.41\% increase in accuracy compared to the established benchmark. Alongside the dataset, we provide a collection of five detailed benchmark sets that assess model performance on specific segments of the test data, such as varying lighting conditions, distances from the camera, and demographic characteristics of subjects. These novel fine-grained benchmarks facilitate the evaluation of model quality in challenging real-world scenarios that are often ignored when focusing solely on overall accuracy. Through an evaluation of a MobileNetV2 TinyML model on the benchmarks, we show that the input resolution plays a more crucial role than the model width in detecting distant subjects and that the impact of quantization on model robustness is minimal, thanks to the dataset quality. These findings underscore the importance of a detailed evaluation to identify essential factors for model development. The dataset, benchmark suite, code, and models are publicly available under the CC-BY 4.0 license, enabling their use for commercial use cases.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Markov flow policy -- deep MC</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00877">https://arxiv.org/abs/2405.00877</a></p>
  <p><b>作者</b>：Nitsan Soffair,  Gilad Katz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impose undesired temporal, undesired temporal discounts, encounter evaluation errors, evaluation errors due, short-term estimations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discounted algorithms often encounter evaluation errors due to their reliance on short-term estimations, which can impede their efficacy in addressing simple, short-term tasks and impose undesired temporal discounts (\(\gamma\)). Interestingly, these algorithms are often tested without applying a discount, a phenomenon we refer as the \textit{train-test bias}. In response to these challenges, we propose the Markov Flow Policy, which utilizes a non-negative neural network flow to enable comprehensive forward-view predictions. Through integration into the TD7 codebase and evaluation using the MuJoCo benchmark, we observe significant performance improvements, positioning MFP as a straightforward, practical, and easily implementable solution within the domain of average rewards algorithms.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Beyond Human Vision: The Role of Large Vision Language Models in  Microscope Image Analysis</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00876">https://arxiv.org/abs/2405.00876</a></p>
  <p><b>作者</b>：Prateek Verma,  Minh-Hao Van,  Xintao Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vision language models, Vision language, emerged and gained, gained the spotlight, dual modality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision language models (VLMs) have recently emerged and gained the spotlight for their ability to comprehend the dual modality of image and textual data. VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive performance on tasks such as natural image captioning, visual question answering (VQA), and spatial reasoning. Additionally, a universal segmentation model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance at isolating objects from unforeseen images. Since medical experts, biologists, and materials scientists routinely examine microscopy or medical images in conjunction with textual information in the form of captions, literature, or reports, and draw conclusions of great importance and merit, it is indubitably essential to test the performance of VLMs and foundation models such as SAM, on these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with classification, segmentation, counting, and VQA tasks on a variety of microscopy images. We observe that ChatGPT and Gemini are impressively able to comprehend the visual features in microscopy images, while SAM is quite capable at isolating artefacts in a general sense. However, the performance is not close to that of a domain expert - the models are readily encumbered by the introduction of impurities, defects, artefact overlaps and diversity present in the images.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Artificial intelligence for context-aware visual change detection in  software test automation</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00874">https://arxiv.org/abs/2405.00874</a></p>
  <p><b>作者</b>：Milad Moradi,  Ke Yan,  David Colwell,  Rhona Asgari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：software development process, development process, streamlining workflows, Automated software testing, visual change detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated software testing is integral to the software development process, streamlining workflows and ensuring product reliability. Visual testing within this context, especially concerning user interface (UI) and user experience (UX) validation, stands as one of crucial determinants of overall software quality. Nevertheless, conventional methods like pixel-wise comparison and region-based visual change detection fall short in capturing contextual similarities, nuanced alterations, and understanding the spatial relationships between UI elements. In this paper, we introduce a novel graph-based method for visual change detection in software test automation. Leveraging a machine learning model, our method accurately identifies UI controls from software screenshots and constructs a graph representing contextual and spatial relationships between the controls. This information is then used to find correspondence between UI controls within screenshots of different versions of a software. The resulting graph encapsulates the intricate layout of the UI and underlying contextual relations, providing a holistic and context-aware model. This model is finally used to detect and highlight visual regressions in the UI. Comprehensive experiments on different datasets showed that our change detector can accurately detect visual software changes in various simple and complex test scenarios. Moreover, it outperformed pixel-wise comparison and region-based baselines by a large margin in more complex testing scenarios. This work not only contributes to the advancement of visual change detection but also holds practical implications, offering a robust solution for real-world software test automation challenges, enhancing reliability, and ensuring the seamless evolution of software interfaces.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Can a Hallucinating Model help in Reducing Human "Hallucination"?</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00843">https://arxiv.org/abs/2405.00843</a></p>
  <p><b>作者</b>：Sowmya S Sundaram,  Balaji Alwar</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：presents substantial societal, substantial societal hurdles, spanning pseudoscience, unwarranted beliefs, conspiracy theories</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prevalence of unwarranted beliefs, spanning pseudoscience, logical fallacies, and conspiracy theories, presents substantial societal hurdles and the risk of disseminating misinformation. Utilizing established psychometric assessments, this study explores the capabilities of large language models (LLMs) vis-a-vis the average human in detecting prevalent logical pitfalls. We undertake a philosophical inquiry, juxtaposing the rationality of humans against that of LLMs. Furthermore, we propose methodologies for harnessing LLMs to counter misconceptions, drawing upon psychological models of persuasion such as cognitive dissonance theory and elaboration likelihood theory. Through this endeavor, we highlight the potential of LLMs as personalized misinformation debunking agents.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Sim-Grasp: Learning 6-DOF Grasp Policies for Cluttered Environments  Using a Synthetic Benchmark</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00841">https://arxiv.org/abs/2405.00841</a></p>
  <p><b>作者</b>：Juncheng Li,  David J. Cappelleri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：integrates advanced language, enhanced object manipulation, advanced language models, cluttered environments, two-finger grasping system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping system that integrates advanced language models for enhanced object manipulation in cluttered environments. We introduce the Sim-Grasp-Dataset, which includes 1,550 objects across 500 scenarios with 7.9 million annotated labels, and develop Sim-GraspNet to generate grasp poses from point clouds. The Sim-Grasp-Polices achieve grasping success rates of 97.14% for single objects and 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4 objects, respectively. By incorporating language models for target identification through text and box prompts, Sim-Grasp enables both object-agnostic and target picking, pushing the boundaries of intelligent robotic systems.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Communication-Efficient Training Workload Balancing for Decentralized  Multi-Agent Learning</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00839">https://arxiv.org/abs/2405.00839</a></p>
  <p><b>作者</b>：Seyed Mahmoud Sajjadi Mohammadabadi,  Lei Yang,  Feng Yan,  Junshan Zhang</p>
  <p><b>备注</b>：This paper has been accepted for presentation at ICDCS (44th IEEE International Conference on Distributed Computing Systems). Keywords: decentralized multi-agent learning, federated learning, edge computing, heterogeneous agents, workload balancing, and communication-efficient training )</p>
  <p><b>关键词</b>：Decentralized Multi-agent Learning, Multi-agent Learning, training time, training, Decentralized Multi-agent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized Multi-agent Learning (DML) enables collaborative model training while preserving data privacy. However, inherent heterogeneity in agents' resources (computation, communication, and task size) may lead to substantial variations in training time. This heterogeneity creates a bottleneck, lengthening the overall training time due to straggler effects and potentially wasting spare resources of faster agents. To minimize training time in heterogeneous environments, we present a Communication-Efficient Training Workload Balancing for Decentralized Multi-Agent Learning (ComDML), which balances the workload among agents through a decentralized approach. Leveraging local-loss split training, ComDML enables parallel updates, where slower agents offload part of their workload to faster agents. To minimize the overall training time, ComDML optimizes the workload balancing by jointly considering the communication and computation capacities of agents, which hinges upon integer programming. A dynamic decentralized pairing scheduler is developed to efficiently pair agents and determine optimal offloading amounts. We prove that in ComDML, both slower and faster agents' models converge, for convex and non-convex functions. Furthermore, extensive experimental results on popular datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-I.I.D. variants, with large models such as ResNet-56 and ResNet-110, demonstrate that ComDML can significantly reduce the overall training time while maintaining model accuracy, compared to state-of-the-art methods. ComDML demonstrates robustness in heterogeneous environments, and privacy measures can be seamlessly integrated for enhanced data protection.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace  Setting</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00823">https://arxiv.org/abs/2405.00823</a></p>
  <p><b>作者</b>：Olly Styles,  Sam Miller,  Patricio Cerda-Mardini,  Tanaya Guha,  Victor Sanchez,  Bertie Vidgen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmark dataset, dataset for evaluating, WorkBench, tasks, evaluating agents' ability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce WorkBench: a benchmark dataset for evaluating agents' ability to execute tasks in a workplace setting. WorkBench contains a sandbox environment with five databases, 26 tools, and 690 tasks. These tasks represent common business activities, such as sending emails and scheduling meetings. The tasks in WorkBench are challenging as they require planning, tool selection, and often multiple actions. If a task has been successfully executed, one (or more) of the database values may change. The correct outcome for each task is unique and unambiguous, which allows for robust, automated evaluation. We call this key contribution outcome-centric evaluation. We evaluate five existing ReAct agents on WorkBench, finding they successfully complete as few as 3% of tasks (Llama2-70B), and just 43% for the best-performing (GPT-4). We further find that agents' errors can result in the wrong action being taken, such as an email being sent to the wrong person. WorkBench reveals weaknesses in agents' ability to undertake common business activities, raising questions about their use in high-stakes workplace settings. WorkBench is publicly available as a free resource at this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Obtaining Favorable Layouts for Multiple Object Generation</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00791">https://arxiv.org/abs/2405.00791</a></p>
  <p><b>作者</b>：Barak Battash,  Amit Rozner,  Lior Wolf,  Ofir Lindenbaum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown remarkable success, remarkable success, generate high-quality, high-quality and diverse, shown remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale text-to-image models that can generate high-quality and diverse images based on textual prompts have shown remarkable success. These models aim ultimately to create complex scenes, and addressing the challenge of multi-subject generation is a critical step towards this goal. However, the existing state-of-the-art diffusion models face difficulty when generating images that involve multiple subjects. When presented with a prompt containing more than one subject, these models may omit some subjects or merge them together. To address this challenge, we propose a novel approach based on a guiding principle. We allow the diffusion model to initially propose a layout, and then we rearrange the layout grid. This is achieved by enforcing cross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels from latent maps to new locations determined by us. We introduce new loss terms aimed at reducing XAM entropy for clearer spatial definition of subjects, reduce the overlap between XAMs, and ensure that XAMs align with their respective masks. We contrast our approach with several alternative methods and show that it more faithfully captures the desired concepts across a variety of text prompts.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet  Module Accelerators</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00790">https://arxiv.org/abs/2405.00790</a></p>
  <p><b>作者</b>：Mohanad Odema,  Luke Chen,  Hyoukjun Kwon,  Mohammad Abdullah Al Faruque</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent large language, large language models, language models significantly, models significantly increased, heterogeneous dataflow MCM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emerging multi-model workloads with heavy models like recent large language models significantly increased the compute and memory demands on hardware. To address such increasing demands, designing a scalable hardware architecture became a key problem. Among recent solutions, the 2.5D silicon interposer multi-chip module (MCM)-based AI accelerator has been actively explored as a promising scalable solution due to their significant benefits in the low engineering cost and composability. However, previous MCM accelerators are based on homogeneous architectures with fixed dataflow, which encounter major challenges from highly heterogeneous multi-model workloads due to their limited workload adaptivity. Therefore, in this work, we explore the opportunity in the heterogeneous dataflow MCM AI accelerators. We identify the scheduling of multi-model workload on heterogeneous dataflow MCM AI accelerator is an important and challenging problem due to its significance and scale, which reaches O(10^18) scale even for a single model case on 6x6 chiplets. We develop a set of heuristics to navigate the huge scheduling space and codify them into a scheduler with advanced techniques such as inter-chiplet pipelining. Our evaluation on ten multi-model workload scenarios for datacenter multitenancy and AR/VR use-cases has shown the efficacy of our approach, achieving on average 35.3% and 31.4% less energy-delay product (EDP) for the respective applications settings compared to homogeneous baselines.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00760">https://arxiv.org/abs/2405.00760</a></p>
  <p><b>作者</b>：Xiaoshi Wu,  Yiming Hao,  Manyuan Zhang,  Keqiang Sun,  Zhaoyang Huang,  Guanglu Song,  Yu Liu,  Hongsheng Li</p>
  <p><b>备注</b>：N/A</p>
  <p><b>关键词</b>：underexplored research area, Deep Reward Tuning, research area, important but underexplored, underexplored research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimizing a text-to-image diffusion model with a given reward function is an important but underexplored research area. In this study, we propose Deep Reward Tuning (DRTune), an algorithm that directly supervises the final output image of a text-to-image diffusion model and back-propagates through the iterative sampling process to the input noise. We find that training earlier steps in the sampling process is crucial for low-level rewards, and deep supervision can be achieved efficiently and effectively by stopping the gradient of the denoising network input. DRTune is extensively evaluated on various reward models. It consistently outperforms other algorithms, particularly for low-level control signals, where all shallow supervision methods fail. Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0) model via DRTune to optimize Human Preference Score v2.1, resulting in the Favorable Diffusion XL 1.0 (FDXL 1.0) model. FDXL 1.0 significantly enhances image quality compared to SDXL 1.0 and reaches comparable quality compared with Midjourney v5.2.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：From Keyboard to Chatbot: An AI-powered Integration Platform with  Large-Language Models for Teaching Computational Thinking for Young Children</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00750">https://arxiv.org/abs/2405.00750</a></p>
  <p><b>作者</b>：Changjae Lee,  Jinjun Xiong</p>
  <p><b>备注</b>：26 pages, 11 figures</p>
  <p><b>关键词</b>：young children, enhance computational thinking, computational thinking, children, young</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Teaching programming in early childhood (4-9) to enhance computational thinking has gained popularity in the recent movement of computer science for all. However, current practices ignore some fundamental issues resulting from young children's developmental readiness, such as the sustained capability to keyboarding, the decomposition of complex tasks to small tasks, the need for intuitive mapping from abstract programming to tangible outcomes, and the limited amount of screen time exposure. To address these issues in this paper, we present a novel methodology with an AI-powered integration platform to effectively teach computational thinking for young children. The system features a hybrid pedagogy that supports both the top-down and bottom-up approach for teaching computational thinking. Young children can describe their desired task in natural language, while the system can respond with an easy-to-understand program consisting of the right level of decomposed sub-tasks. A tangible robot can immediately execute the decomposed program and demonstrate the program's outcomes to young children. The system is equipped with an intelligent chatbot that can interact with young children through natural languages, and children can speak to the chatbot to complete all the needed programming tasks, while the chatbot orchestrates the execution of the program onto the robot. This would completely eliminates the need of keyboards for young children to program. By developing such a system, we aim to make the concept of computational thinking more accessible to young children, fostering a natural understanding of programming concepts without the need of explicit programming skills. Through the interactive experience provided by the robotic agent, our system seeks to engage children in an effective manner, contributing to the field of educational technology for early childhood computer science education.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：ChatGPT in Data Visualization Education: A Student Perspective</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00748">https://arxiv.org/abs/2405.00748</a></p>
  <p><b>作者</b>：Nam Wook Kim,  Hyung-Kwon Ko,  Grace Myers,  Benjamin Bach</p>
  <p><b>备注</b>：12 pages; 3 figures</p>
  <p><b>关键词</b>：large-language model-driven chatbots, demonstrate remarkable versatility, solving complex problems, understanding advanced concepts, traditional educational chatbots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlike traditional educational chatbots that rely on pre-programmed responses, large-language model-driven chatbots, such as ChatGPT, demonstrate remarkable versatility and have the potential to serve as a dynamic resource for addressing student needs from understanding advanced concepts to solving complex problems. This work explores the impact of such technology on student learning in an interdisciplinary, project-oriented data visualization course. Throughout the semester, students engaged with ChatGPT across four distinct projects, including data visualizations and implementing them using a variety of tools including Tableau, D3, and Vega-lite. We collected conversation logs and reflection surveys from the students after each assignment. In addition, we conducted interviews with selected students to gain deeper insights into their overall experiences with ChatGPT. Our analysis examined the advantages and barriers of using ChatGPT, students' querying behavior, the types of assistance sought, and its impact on assignment outcomes and engagement. Based on the findings, we discuss design considerations for an educational solution that goes beyond the basic interface of ChatGPT, specifically tailored for data visualization education.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Soft Preference Optimization: Aligning Language Models to Expert  Distributions</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00747">https://arxiv.org/abs/2405.00747</a></p>
  <p><b>作者</b>：Arsalan Sharifnassab,  Sina Ghiassian,  Saber Salehkaleybar,  Surya Kanoria,  Dale Schuurmans</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Soft Preference Optimization, Large Language Models, propose Soft Preference, Large Language, propose Soft</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Soft Preference Optimization (SPO), a method for aligning generative models, such as Large Language Models (LLMs), with human preferences, without the need for a reward model. SPO optimizes model outputs directly over a preference dataset through a natural loss function that integrates preference loss with a regularization term across the model's entire output distribution rather than limiting it to the preference dataset. Although SPO does not require the assumption of an existing underlying reward model, we demonstrate that, under the Bradley-Terry (BT) model assumption, it converges to a softmax of scaled rewards, with the distribution's "softness" adjustable via the softmax exponent, an algorithm parameter. We showcase SPO's methodology, its theoretical foundation, and its comparative advantages in simplicity, computational efficiency, and alignment precision.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00746">https://arxiv.org/abs/2405.00746</a></p>
  <p><b>作者</b>：Calarina Muslimani,  Matthew E. Taylor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：create useful reinforcement, design a suitable, captures the nuances, reward, suitable reward function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To create useful reinforcement learning (RL) agents, step zero is to design a suitable reward function that captures the nuances of the task. However, reward engineering can be a difficult and time-consuming process. Instead, human-in-the-loop (HitL) RL allows agents to learn reward functions from human feedback. Despite recent successes, many of the HitL RL methods still require numerous human interactions to learn successful reward functions. To improve the feedback efficiency of HitL RL methods (i.e., require less feedback), this paper introduces Sub-optimal Data Pre-training, SDP, an approach that leverages reward-free, sub-optimal data to improve scalar- and preference-based HitL RL algorithms. In SDP, we start by pseudo-labeling all low-quality data with rewards of zero. Through this process, we obtain free reward labels to pre-train our reward model. This pre-training phase provides the reward model a head start in learning, whereby it can identify that low-quality transitions should have a low reward, all without any actual feedback. Through extensive experiments with a simulated teacher, we demonstrate that SDP can significantly improve or achieve competitive performance with state-of-the-art (SOTA) HitL RL algorithms across nine robotic manipulation and locomotion tasks.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Modeling Caption Diversity in Contrastive Vision-Language Pretraining</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00740">https://arxiv.org/abs/2405.00740</a></p>
  <p><b>作者</b>：Samuel Lavoie,  Polina Kirichenko,  Mark Ibrahim,  Mahmoud Assran,  Andrew Gordon Wildon,  Aaron Courville,  Nicolas Ballas</p>
  <p><b>备注</b>：14 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：Language Image Pretraining, Latent Language Image, Contrastive Language Pretraining, Language Pretraining, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are a thousand ways to caption an image. Contrastive Language Pretraining (CLIP) on the other hand, works by mapping an image and its caption to a single vector -- limiting how well CLIP-like models can represent the diverse ways to describe an image. In this work, we introduce Llip, Latent Language Image Pretraining, which models the diversity of captions that could match an image. Llip's vision encoder outputs a set of visual features that are mixed into a final representation by conditioning on information derived from the text. We show that Llip outperforms non-contextualized baselines like CLIP and SigLIP on a variety of tasks even with large-scale encoders. Llip improves zero-shot classification by an average of 2.9% zero-shot classification benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot top-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by 1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by 6.0%. We provide a comprehensive analysis of the components introduced by the method and demonstrate that Llip leads to richer visual representations.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level  Synthesis</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00738">https://arxiv.org/abs/2405.00738</a></p>
  <p><b>作者</b>：Andy He,  Darren Key,  Mason Bulling,  Andrew Chang,  Skyler Shapiro,  Everett Lee</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：Graphics Processing Units, Large Language Models, modern Large Language, Processing Units, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphics Processing Units (GPUs) have become the leading hardware accelerator for deep learning applications and are used widely in training and inference of transformers; transformers have achieved state-of-the-art performance in many areas of machine learning and are especially used in most modern Large Language Models (LLMs). However, GPUs require large amounts of energy, which poses environmental concerns, demands high operational costs, and causes GPUs to be unsuitable for edge computing. We develop an accelerator for transformers, namely, Llama 2, an open-source state-of-the-art LLM, using high level synthesis (HLS) on Field Programmable Gate Arrays (FPGAs). HLS allows us to rapidly prototype FPGA designs without writing code at the register-transfer level (RTL). We name our method HLSTransform, and the FPGA designs we synthesize with HLS achieve up to a 12.75x reduction and 8.25x reduction in energy used per token on the Xilinx Virtex UltraScale+ VU9P FPGA compared to an Intel Xeon Broadwell E5-2686 v4 CPU and NVIDIA RTX 3090 GPU respectively, while increasing inference speeds by up to 2.46x compared to CPU and maintaining 0.53x the speed of an RTX 3090 GPU despite the GPU's 4 times higher base clock rate. With the lack of existing open-source FPGA accelerators for transformers, we open-source our code and document our steps for synthesis. We hope this work will serve as a step in democratizing the use of FPGAs in transformer inference and inspire research into energy-efficient inference methods as a whole. The code can be found on this https URL.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00732">https://arxiv.org/abs/2405.00732</a></p>
  <p><b>作者</b>：Justin Zhao,  Timothy Wang,  Wael Abid,  Geoffrey Angus,  Arnav Garg,  Jeffery Kinnison,  Alex Sherstinsky,  Piero Molino,  Travis Addair,  Devvret Rishi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, Parameter Efficient Fine-Tuning, Low Rank Adaptation, widely adopted methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted methods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models (LLMs). LoRA reduces the number of trainable parameters and memory usage while achieving comparable performance to full fine-tuning. We aim to assess the viability of training and serving LLMs fine-tuned with LoRA in real-world applications. First, we measure the quality of LLMs fine-tuned with quantized low rank adapters across 10 base models and 31 tasks for a total of 310 models. We find that 4-bit LoRA fine-tuned models outperform base models by 34 points and GPT-4 by 10 points on average. Second, we investigate the most effective base models for fine-tuning and assess the correlative and predictive capacities of task complexity heuristics in forecasting the outcomes of fine-tuning. Finally, we evaluate the latency and concurrency capabilities of LoRAX, an open-source Multi-LoRA inference server that facilitates the deployment of multiple LoRA fine-tuned models on a single GPU using shared base model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA A100 GPU with 80GB memory. LoRA Land highlights the quality and cost-effectiveness of employing multiple specialized LLMs over a single, general-purpose LLM.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A  Comparative Study</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00728">https://arxiv.org/abs/2405.00728</a></p>
  <p><b>作者</b>：Dou Liu,  Ying Han,  Xiandi Wang,  Xiaomei Tan,  Di Liu,  Guangwu Qian,  Kang Li,  Dan Pu,  Rong Yin</p>
  <p><b>备注</b>：8 pages, 1 figure, conference(International Ergonomics Association)</p>
  <p><b>关键词</b>：Artificial Intelligence, Large Language Models, health outcomes, presents a transformative, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of Artificial Intelligence (AI) in healthcare presents a transformative potential for enhancing operational efficiency and health outcomes. Large Language Models (LLMs), such as ChatGPT, have shown their capabilities in supporting medical decision-making. Embedding LLMs in medical systems is becoming a promising trend in healthcare development. The potential of ChatGPT to address the triage problem in emergency departments has been examined, while few studies have explored its application in outpatient departments. With a focus on streamlining workflows and enhancing efficiency for outpatient triage, this study specifically aims to evaluate the consistency of responses provided by ChatGPT in outpatient guidance, including both within-version response analysis and between-version comparisons. For within-version, the results indicate that the internal response consistency for ChatGPT-4.0 is significantly higher than ChatGPT-3.5 (p=0.03) and both have a moderate consistency (71.2% for 4.0 and 59.6% for 3.5) in their top recommendation. However, the between-version consistency is relatively low (mean consistency score=1.43/3, median=1), indicating few recommendations match between the two versions. Also, only 50% top recommendations match perfectly in the comparisons. Interestingly, ChatGPT-3.5 responses are more likely to be complete than those from ChatGPT-4.0 (p=0.02), suggesting possible differences in information processing and response generation between the two versions. The findings offer insights into AI-assisted outpatient operations, while also facilitating the exploration of potentials and limitations of LLMs in healthcare utilization. Future research may focus on carefully optimizing LLMs and AI integration in healthcare systems based on ergonomic and human factors principles, precisely aligning with the specific needs of effective outpatient triage.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：LLMs for Generating and Evaluating Counterfactuals: A Comprehensive  Study</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00722">https://arxiv.org/abs/2405.00722</a></p>
  <p><b>作者</b>：Van Bach Nguyen,  Paul Youssef,  Jörg Schlötterer,  Christin Seifert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding their decisions, CFs, Large Language Models, NLP models, LLMs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As NLP models become more complex, understanding their decisions becomes more crucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's prediction, offer a way to explain these models. While Large Language Models (LLMs) have shown remarkable performance in NLP tasks, their efficacy in generating high-quality CFs remains uncertain. This work fills this gap by investigating how well LLMs generate CFs for two NLU tasks. We conduct a comprehensive comparison of several common LLMs, and evaluate their CFs, assessing both intrinsic metrics, and the impact of these CFs on data augmentation. Moreover, we analyze differences between human and LLM-generated CFs, providing insights for future research directions. Our results show that LLMs generate fluent CFs, but struggle to keep the induced changes minimal. Generating CFs for Sentiment Analysis (SA) is less challenging than NLI where LLMs show weaknesses in generating CFs that flip the original label. This also reflects on the data augmentation performance, where we observe a large gap between augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs' ability to assess CFs in a mislabelled data setting, and show that they have a strong bias towards agreeing with the provided labels. GPT4 is more robust against this bias and its scores correlate well with automatic metrics. Our findings reveal several limitations and point to potential future work directions.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Can't say cant? Measuring and Reasoning of Dark Jargons in Large  Language Models</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00718">https://arxiv.org/abs/2405.00718</a></p>
  <p><b>作者</b>：Xu Ji,  Jianyi Zhang,  Ziyin Zhou,  Zhangchi Zhao,  Qianqian Qiao,  Kaiying Han,  Md Imran Hossen,  Xiali Hei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, mitigating offensive responses, Large Language, resilience of Large, Ensuring the resilience</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensuring the resilience of Large Language Models (LLMs) against malicious exploitation is paramount, with recent focus on mitigating offensive responses. Yet, the understanding of cant or dark jargon remains unexplored. This paper introduces a domain-specific Cant dataset and CantCounter evaluation framework, employing Fine-Tuning, Co-Tuning, Data-Diffusion, and Data-Analysis stages. Experiments reveal LLMs, including ChatGPT, are susceptible to cant bypassing filters, with varying recognition accuracy influenced by question types, setups, and prompt clues. Updated models exhibit higher acceptance rates for cant queries. Moreover, LLM reactions differ across domains, e.g., reluctance to engage in racism versus LGBT topics. These findings underscore LLMs' understanding of cant and reflect training data characteristics and vendor approaches to sensitive topics. Additionally, we assess LLMs' ability to demonstrate reasoning capabilities. Access to our datasets and code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Exploring News Summarization and Enrichment in a Highly Resource-Scarce  Indian Language: A Case Study of Mizo</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00717">https://arxiv.org/abs/2405.00717</a></p>
  <p><b>作者</b>：Abhinaba Bala,  Ashok Urlana,  Rahul Mishra,  Parameswari Krishnamurthy</p>
  <p><b>备注</b>：Accepted at LREC-COLING2024 WILDRE Workshop</p>
  <p><b>关键词</b>：Obtaining sufficient information, Obtaining sufficient, mother tongue, tongue is crucial, crucial for satisfying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obtaining sufficient information in one's mother tongue is crucial for satisfying the information needs of the users. While high-resource languages have abundant online resources, the situation is less than ideal for very low-resource languages. Moreover, the insufficient reporting of vital national and international events continues to be a worry, especially in languages with scarce resources, like \textbf{Mizo}. In this paper, we conduct a study to investigate the effectiveness of a simple methodology designed to generate a holistic summary for Mizo news articles, which leverages English-language news to supplement and enhance the information related to the corresponding news events. Furthermore, we make available 500 Mizo news articles and corresponding enriched holistic summaries. Human evaluation confirms that our approach significantly enhances the information coverage of Mizo news articles. The mizo dataset and code can be accessed at \url{this https URL</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Large Language Models in Healthcare: A Comprehensive Benchmark</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00716">https://arxiv.org/abs/2405.00716</a></p>
  <p><b>作者</b>：Andrew Liu,  Hongjian Zhou,  Yining Hua,  Omid Rohanian,  Lei Clifton,  David A. Clifton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted remarkable attention, remarkable attention, adoption of large, assist clinicians, clinicians has attracted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the close-ended question-answering task with answer options for evaluation. However, in real clinical settings, many clinical decisions, such as treatment recommendations, involve answering open-ended questions without pre-set options. Meanwhile, existing studies mainly use accuracy to assess model performance. In this paper, we comprehensively benchmark diverse LLMs in healthcare, to clearly understand their strengths and weaknesses. Our benchmark contains seven tasks and thirteen datasets across medical language generation, understanding, and reasoning. We conduct a detailed evaluation of the existing sixteen LLMs in healthcare under both zero-shot and few-shot (i.e., 1,3,5-shot) learning settings. We report the results on five metrics (i.e. matching, faithfulness, comprehensiveness, generalizability, and robustness) that are critical in achieving trust from clinical users. We further invite medical experts to conduct human evaluation.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Towards Adapting Open-Source Large Language Models for Expert-Level  Clinical Note Generation</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00715">https://arxiv.org/abs/2405.00715</a></p>
  <p><b>作者</b>：Hanyin Wang,  Chufan Gao,  Bolun Liu,  Qiping Xu,  Guleid Hussein,  Mohamad El Labban,  Kingsley Iheasirim,  Hariprasad Korsapati,  Jimeng Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, shown promising capabilities, Large Language, Language Models, text summarization tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have shown promising capabilities in handling clinical text summarization tasks. In this study, we demonstrate that a small open-source LLM can be effectively trained to generate high-quality clinical notes from outpatient patient-doctor dialogues. We achieve this through a comprehensive domain- and task-specific adaptation process for the LLaMA-2 13 billion parameter model. This process incorporates continued pre-training, supervised fine-tuning, and reinforcement learning from both AI and human feedback. We introduced an enhanced approach, termed DistillDirect, for performing on-policy reinforcement learning with Gemini Pro serving as the teacher model. Our resulting model, LLaMA-Clinic, is capable of generating clinical notes that are comparable in quality to those authored by physicians. In a blinded physician reader study, the majority (90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as "acceptable" or higher across all three criteria: real-world readiness, completeness, and accuracy. Notably, in the more challenging "Assessment and Plan" section, LLaMA-Clinic scored higher (4.2/5) in real-world readiness compared to physician-authored notes (4.1/5). Additionally, we identified caveats in public clinical note datasets, such as ACI-BENCH. We highlight key considerations for future clinical note-generation tasks, emphasizing the importance of pre-defining a best-practice note format. Overall, our research demonstrates the potential and feasibility of training smaller, open-source LLMs to assist with clinical documentation, capitalizing on healthcare institutions' access to patient records and domain expertise. We have made our newly created synthetic clinic dialogue-note dataset and the physician feedback dataset publicly available to foster future research in this field.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of  Theories, Detection Methods, and Opportunities</b></summary>
  <p><b>编号</b>：[392]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00711">https://arxiv.org/abs/2405.00711</a></p>
  <p><b>作者</b>：Xiaomin Yu,  Yezhaohui Wang,  Yanfang Chen,  Zhen Tao,  Dinghao Xi,  Shichao Song,  Simin Niu,  Zhiyu Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Diffusion Models, artificial intelligence models, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, generative artificial intelligence models, represented by Large Language Models (LLMs) and Diffusion Models (DMs), have revolutionized content production methods. These artificial intelligence-generated content (AIGC) have become deeply embedded in various aspects of daily life and work, spanning texts, images, videos, and audio. The authenticity of AI-generated content is progressively enhancing, approaching human-level creative standards. However, these technologies have also led to the emergence of Fake Artificial Intelligence Generated Content (FAIGC), posing new challenges in distinguishing genuine information. It is crucial to recognize that AIGC technology is akin to a double-edged sword; its potent generative capabilities, while beneficial, also pose risks for the creation and dissemination of FAIGC. In this survey, We propose a new taxonomy that provides a more comprehensive breakdown of the space of FAIGC methods today. Next, we explore the modalities and generative technologies of FAIGC, categorized under AI-generated disinformation and AI-generated misinformation. From various perspectives, we then introduce FAIGC detection methods, including Deceptive FAIGC Detection, Deepfake Detection, and Hallucination-based FAIGC Detection. Finally, we discuss outstanding challenges and promising areas for future research.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Evaluating Tool-Augmented Agents in Remote Sensing Platforms</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00709">https://arxiv.org/abs/2405.00709</a></p>
  <p><b>作者</b>：Simranjit Singh,  Michael Fore,  Dimitrios Stamoulis</p>
  <p><b>备注</b>：ICLR 2024 Machine Learning for Remote Sensing (ML4RS) Workshop</p>
  <p><b>关键词</b>：Large Language Models, Tool-augmented Large Language, Language Models, shown impressive capabilities, Large Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user-grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask "Detect all objects here". Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., the live map positioning? To bridge this gap, we present GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights towards stronger agents for RS applications.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Interactive Analysis of LLMs using Meaningful Counterfactuals</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00708">https://arxiv.org/abs/2405.00708</a></p>
  <p><b>作者</b>：Furui Cheng,  Vilém Zouhar,  Robin Shing Moon Chan,  Daniel Fürst,  Hendrik Strobelt,  Mennatallah El-Assady</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：determining feature attributions, machine learning models, feature attributions, exploring the decision, decision boundaries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Counterfactual examples are useful for exploring the decision boundaries of machine learning models and determining feature attributions. How can we apply counterfactual-based methods to analyze and explain LLMs? We identify the following key challenges. First, the generated textual counterfactuals should be meaningful and readable to users and thus can be mentally compared to draw conclusions. Second, to make the solution scalable to long-form text, users should be equipped with tools to create batches of counterfactuals from perturbations at various granularity levels and interactively analyze the results. In this paper, we tackle the above challenges and contribute 1) a novel algorithm for generating batches of complete and meaningful textual counterfactuals by removing and replacing text segments in different granularities, and 2) LLM Analyzer, an interactive visualization tool to help users understand an LLM's behaviors by interactively inspecting and aggregating meaningful counterfactuals. We evaluate the proposed algorithm by the grammatical correctness of its generated counterfactuals using 1,000 samples from medical, legal, finance, education, and news datasets. In our experiments, 97.2% of the counterfactuals are grammatically correct. Through a use case, user studies, and feedback from experts, we demonstrate the usefulness and usability of the proposed interactive visualization tool.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Science Written by Generative AI is Perceived as Less Intelligent, but  More Credible and Trustworthy than Science Written by Humans</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00706">https://arxiv.org/abs/2405.00706</a></p>
  <p><b>作者</b>：David M. Markowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simplify science communication, enhance public trust, simplify science, science communication, evaluated the effectiveness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper evaluated the effectiveness of using generative AI to simplify science communication and enhance public trust in science. By comparing lay summaries of journal articles from PNAS, yoked to those generated by AI, this work assessed linguistic simplicity across such summaries and public perceptions. Study 1a analyzed simplicity features of PNAS abstracts (scientific summaries) and significance statements (lay summaries), observing that lay summaries were indeed linguistically simpler, but effect size differences were small. Study 1b used GPT-4 to create significance statements based on paper abstracts and this more than doubled the average effect size without fine-tuning. Finally, Study 2 experimentally demonstrated that simply-written GPT summaries facilitated more favorable public perceptions of scientists (their credibility, trustworthiness) than more complexly-written human PNAS summaries. AI has the potential to engage scientific communities and the public via a simple language heuristic, advocating for its integration into scientific dissemination for a more informed society.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：A Survey on the Real Power of ChatGPT</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00704">https://arxiv.org/abs/2405.00704</a></p>
  <p><b>作者</b>：Ming Liu,  Ran Liu,  Hua Wang,  Wray Buntine</p>
  <p><b>备注</b>：9 pages, 2 tables</p>
  <p><b>关键词</b>：active research line, active research, research line, ChatGPT, emphasize key challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>ChatGPT has changed the AI community and an active research line is the performance evaluation of ChatGPT. A key challenge for the evaluation is that ChatGPT is still closed-source and traditional benchmark datasets may have been used by ChatGPT as the training data. In this paper, (i) we survey recent studies which uncover the real performance levels of ChatGPT in seven categories of NLP tasks, (ii) review the social implications and safety issues of ChatGPT, and (iii) emphasize key challenges and opportunities for its evaluation. We hope our survey can shed some light on its blackbox manner, so that researchers are not misleaded by its surface generation.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Direct Training Needs Regularisation: Anytime Optimal Inference Spiking  Neural Network</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00699">https://arxiv.org/abs/2405.00699</a></p>
  <p><b>作者</b>：Dengyu Wu,  Yi Qi,  Kaiwen Cai,  Gaojie Jin,  Xinping Yi,  Xiaowei Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Neural Network, Spiking Neural Network, Neural Network, hold great promise, Artificial Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Network (SNN) is acknowledged as the next generation of Artificial Neural Network (ANN) and hold great promise in effectively processing spatial-temporal information. However, the choice of timestep becomes crucial as it significantly impacts the accuracy of the neural network training. Specifically, a smaller timestep indicates better performance in efficient computing, resulting in reduced latency and operations. While, using a small timestep may lead to low accuracy due to insufficient information presentation with few spikes. This observation motivates us to develop an SNN that is more reliable for adaptive timestep by introducing a novel regularisation technique, namely Spatial-Temporal Regulariser (STR). Our approach regulates the ratio between the strength of spikes and membrane potential at each timestep. This effectively balances spatial and temporal performance during training, ultimately resulting in an Anytime Optimal Inference (AOI) SNN. Through extensive experiments on frame-based and event-based datasets, our method, in combination with cutoff based on softmax output, achieves state-of-the-art performance in terms of both latency and accuracy. Notably, with STR and cutoff, SNN achieves 2.14 to 2.89 faster in inference compared to the pre-configured timestep with near-zero accuracy drop of 0.50% to 0.64% over the event-based datasets. Code available: this https URL</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Scenarios Engineering driven Autonomous Transportation in Open-Pit Mines</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00690">https://arxiv.org/abs/2405.00690</a></p>
  <p><b>作者</b>：Siyu Teng,  Xuan Li,  Yuchen Li,  Lingxi Li,  Yunfeng Ai,  Long Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prohibitively extreme scenarios, Scenario Feature Extractor, autonomous transportation, open-pit mines, critical bottleneck</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One critical bottleneck that impedes the development and deployment of autonomous transportation in open-pit mines is guaranteed robustness and trustworthiness in prohibitively extreme scenarios. In this research, a novel scenarios engineering (SE) methodology for the autonomous mining truck is proposed for open-pit mines. SE increases the trustworthiness and robustness of autonomous trucks from four key components: Scenario Feature Extractor, Intelligence & Index (I&I), Calibration & Certification (C&C), and Verification & Validation (V&V). Scenario feature extractor is a comprehensive pipeline approach that captures complex interactions and latent dependencies in complex mining scenarios. I&I effectively enhances the quality of the training dataset, thereby establishing a solid foundation for autonomous transportation in mining areas. C&C is grounded in the intrinsic regulation, capabilities, and contributions of the intelligent systems employed in autonomous transportation to align with traffic participants in the real world and ensure their performance through certification. V&V process ensures that the autonomous transportation system can be correctly implemented, while validation focuses on evaluating the ability of the well-trained model to operate efficiently in the complex and dynamic conditions of the open-pit mines. This methodology addresses the unique challenges of autonomous transportation in open-pit mining, promoting productivity, safety, and performance in mining operations.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Anti-Jamming Path Planning Using GCN for Multi-UAV</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00689">https://arxiv.org/abs/2405.00689</a></p>
  <p><b>作者</b>：Haechan Jeong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unmanned Aerial Vehicles, Unmanned Aerial, Aerial Vehicles, UAV swarms, UAV</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the increasing significance of UAVs (Unmanned Aerial Vehicles) and the emergence of UAV swarms for collaborative operations in various domains. However, the effectiveness of UAV swarms can be severely compromised by jamming technology, necessitating robust antijamming strategies. While existing methods such as frequency hopping and physical path planning have been explored, there remains a gap in research on path planning for UAV swarms when the jammer's location is unknown. To address this, a novel approach, where UAV swarms leverage collective intelligence to predict jamming areas, evade them, and efficiently reach target destinations, is proposed. This approach utilizes Graph Convolutional Networks (GCN) to predict the location and intensity of jamming areas based on information gathered from each UAV. A multi-agent control algorithm is then employed to disperse the UAV swarm, avoid jamming, and regroup upon reaching the target. Through simulations, the effectiveness of the proposed method is demonstrated, showcasing accurate prediction of jamming areas and successful evasion through obstacle avoidance algorithms, ultimately achieving the mission objective. Proposed method offers robustness, scalability, and computational efficiency, making it applicable across various scenarios where UAV swarms operate in potentially hostile environments.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Understanding Social Perception, Interactions, and Safety Aspects of  Sidewalk Delivery Robots Using Sentiment Analysis</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00688">https://arxiv.org/abs/2405.00688</a></p>
  <p><b>作者</b>：Yuchen Du,  Tho V. Le</p>
  <p><b>备注</b>：34 pages, 7 figures, 2 tables</p>
  <p><b>关键词</b>：Sidewalk Delivery Robots, Delivery Robots, Sidewalk Delivery, YouTube videos related, comprehensive sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article presents a comprehensive sentiment analysis (SA) of comments on YouTube videos related to Sidewalk Delivery Robots (SDRs). We manually annotated the collected YouTube comments with three sentiment labels: negative (0), positive (1), and neutral (2). We then constructed models for text sentiment classification and tested the models' performance on both binary and ternary classification tasks in terms of accuracy, precision, recall, and F1 score. Our results indicate that, in binary classification tasks, the Support Vector Machine (SVM) model using Term Frequency-Inverse Document Frequency (TF-IDF) and N-gram get the highest accuracy. In ternary classification tasks, the model using Bidirectional Encoder Representations from Transformers (BERT), Long Short-Term Memory Networks (LSTM) and Gated Recurrent Unit (GRU) significantly outperforms other machine learning models, achieving an accuracy, precision, recall, and F1 score of 0.78. Additionally, we employ the Latent Dirichlet Allocation model to generate 10 topics from the comments to explore the public's underlying views on SDRs. Drawing from these findings, we propose targeted recommendations for shaping future policies concerning SDRs. This work provides valuable insights for stakeholders in the SDR sector regarding social perception, interaction, and safety.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Technical Report on BaumEvA Evolutionary Optimization Python-Library  Testing</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00686">https://arxiv.org/abs/2405.00686</a></p>
  <p><b>作者</b>：Vadim Tynchenko,  Aleksei Kudryavtsev,  Vladimir Nelyub,  Aleksei Borodulin,  Andrei Gantimurov</p>
  <p><b>备注</b>：The paper consists of 30 pages, 37 figures, 5 tables</p>
  <p><b>关键词</b>：Python library BaumEvA, including computer vision, optimal model architectures, test results Python, results Python library</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report presents the test results Python library BaumEvA, which implements evolutionary algorithms for optimizing various types of problems, including computer vision tasks accompanied by the search for optimal model architectures. Testing was carried out to evaluate the effectiveness and reliability of the pro-posed methods, as well as to determine their applicability in various fields. Dur-ing testing, various test functions and parameters of evolutionary algorithms were used, which made it possible to evaluate their performance in a wide range of conditions. Test results showed that the library provides effective and reliable methods for solving optimization problems. However, some limitations were identified related to computational resources and execution time of algorithms on problems with large dimensions. The report includes a detailed description of the tests performed, the results obtained and conclusions about the applicability of the genetic algorithm in various tasks. Recommendations for choosing algorithm pa-rameters and using the library to achieve the best results are also provided. The report may be useful to developers involved in the optimization of complex com-puting systems, as well as to researchers studying the possibilities of using evo-lutionary algorithms in various fields of science and technology.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Exploring mechanisms of Neural Robustness: probing the bridge between  geometry and spectrum</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00679">https://arxiv.org/abs/2405.00679</a></p>
  <p><b>作者</b>：Konstantin Holzhausen,  Mia Merlid,  Håkon Olav Torvik,  Anders Malthe-Sørenssen,  Mikkel Elle Lepperød</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leading to unforeseen, affect their safety, unforeseen behaviors, behaviors that affect, Backpropagation-optimized artificial neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Backpropagation-optimized artificial neural networks, while precise, lack robustness, leading to unforeseen behaviors that affect their safety. Biological neural systems do solve some of these issues already. Thus, understanding the biological mechanisms of robustness is an important step towards building trustworthy and safe systems. Unlike artificial models, biological neurons adjust connectivity based on neighboring cell activity. Robustness in neural representations is hypothesized to correlate with the smoothness of the encoding manifold. Recent work suggests power law covariance spectra, which were observed studying the primary visual cortex of mice, to be indicative of a balanced trade-off between accuracy and robustness in representations. Here, we show that unsupervised local learning models with winner takes all dynamics learn such power law representations, providing upcoming studies a mechanistic model with that characteristic. Our research aims to understand the interplay between geometry, spectral properties, robustness, and expressivity in neural representations. Hence, we study the link between representation smoothness and spectrum by using weight, Jacobian and spectral regularization while assessing performance and adversarial robustness. Our work serves as a foundation for future research into the mechanisms underlying power law spectra and optimally smooth encodings in both biological and artificial systems. The insights gained may elucidate the mechanisms that realize robust neural networks in mammalian brains and inform the development of more stable and reliable artificial systems.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Qualia and the Formal Structure of Meaning</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.01148">https://arxiv.org/abs/2405.01148</a></p>
  <p><b>作者</b>：Xerxes D. Arsiwalla</p>
  <p><b>备注</b>：28 pages</p>
  <p><b>关键词</b>：attributed meaning constitutes, subjectively attributed meaning, phenomenal content, work explores, explores the hypothesis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work explores the hypothesis that subjectively attributed meaning constitutes the phenomenal content of conscious experience. That is, phenomenal content is semantic. This form of subjective meaning manifests as an intrinsic and non-representational character of qualia. Empirically, subjective meaning is ubiquitous in conscious experiences. We point to phenomenological studies that lend evidence to support this. Furthermore, this notion of meaning closely relates to what Frege refers to as "sense", in metaphysics and philosophy of language. It also aligns with Peirce's "interpretant", in semiotics. We discuss how Frege's sense can also be extended to the raw feels of consciousness. Sense and reference both play a role in phenomenal experience. Moreover, within the context of the mind-matter relation, we provide a formalization of subjective meaning associated to one's mental representations. Identifying the precise maps between the physical and mental domains, we argue that syntactic and semantic structures transcend language, and are realized within each of these domains. Formally, meaning is a relational attribute, realized via a map that interprets syntactic structures of a formal system within an appropriate semantic space. The image of this map within the mental domain is what is relevant for experience, and thus comprises the phenomenal content of qualia. We conclude with possible implications this may have for experience-based theories of consciousness.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：HMAMP: Hypervolume-Driven Multi-Objective Antimicrobial Peptides Design</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00753">https://arxiv.org/abs/2405.00753</a></p>
  <p><b>作者</b>：Li Wang,  Yiping Li,  Xiangzheng Fu,  Xiucai Ye,  Junfeng Shi,  Gary G. Yen,  Xiangxiang Zeng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：combating multidrug-resistant bacteria, exhibited unprecedented potential, Antimicrobial Peptide Design, multidrug-resistant bacteria, exhibited unprecedented</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Antimicrobial peptides (AMPs) have exhibited unprecedented potential as biomaterials in combating multidrug-resistant bacteria. Despite the increasing adoption of artificial intelligence for novel AMP design, challenges pertaining to conflicting attributes such as activity, hemolysis, and toxicity have significantly impeded the progress of researchers. This paper introduces a paradigm shift by considering multiple attributes in AMP design.
Presented herein is a novel approach termed Hypervolume-driven Multi-objective Antimicrobial Peptide Design (HMAMP), which prioritizes the simultaneous optimization of multiple attributes of AMPs. By synergizing reinforcement learning and a gradient descent algorithm rooted in the hypervolume maximization concept, HMAMP effectively expands exploration space and mitigates the issue of pattern collapse. This method generates a wide array of prospective AMP candidates that strike a balance among diverse attributes. Furthermore, we pinpoint knee points along the Pareto front of these candidate AMPs. Empirical results across five benchmark models substantiate that HMAMP-designed AMPs exhibit competitive performance and heightened diversity. A detailed analysis of the helical structures and molecular dynamics simulations for ten potential candidate AMPs validates the superiority of HMAMP in the realm of multi-objective AMP design. The ability of HMAMP to systematically craft AMPs considering multiple attributes marks a pioneering milestone, establishing a universal computational framework for the multi-objective design of AMPs.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：F$^3$low: Frame-to-Frame Coarse-grained Molecular Dynamics with SE(3)  Guided Flow Matching</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00751">https://arxiv.org/abs/2405.00751</a></p>
  <p><b>作者</b>：Shaoning Li,  Yusong Wang,  Mingyu Li,  Jian Zhang,  Bin Shao,  Nanning Zheng,  Jian Tang</p>
  <p><b>备注</b>：Accepted by ICLR 2024 GEM workshop</p>
  <p><b>关键词</b>：simulating biological systems, Molecular dynamics, biological systems, functions and properties, dynamic nature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Molecular dynamics (MD) is a crucial technique for simulating biological systems, enabling the exploration of their dynamic nature and fostering an understanding of their functions and properties. To address exploration inefficiency, emerging enhanced sampling approaches like coarse-graining (CG) and generative models have been employed. In this work, we propose a \underline{Frame-to-Frame} generative model with guided \underline{Flow}-matching (F$3$low) for enhanced sampling, which (a) extends the domain of CG modeling to the SE(3) Riemannian manifold; (b) retreating CGMD simulations as autoregressively sampling guided by the former frame via flow-matching models; (c) targets the protein backbone, offering improved insights into secondary structure formation and intricate folding pathways. Compared to previous methods, F$3$low allows for broader exploration of conformational space. The ability to rapidly generate diverse conformations via force-free generative paradigm on SE(3) paves the way toward efficient enhanced sampling methods.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Diagnosis of Parkinson's Disease Using EEG Signals and Machine Learning  Techniques: A Comprehensive Study</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00741">https://arxiv.org/abs/2405.00741</a></p>
  <p><b>作者</b>：Maryam Allahbakhshi,  Aylar Sadri,  Seyed Omid Shahdi</p>
  <p><b>备注</b>：9 pages, 2 tables, 10th International Conference on Artificial Intelligence and Robotics-QICAR2024 Qazvin Islamic Azad University, Feb. 29, 2024</p>
  <p><b>关键词</b>：widespread neurodegenerative condition, neurodegenerative condition necessitating, Parkinson disease, Support Vector Machine, condition necessitating early</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Parkinson's disease is a widespread neurodegenerative condition necessitating early diagnosis for effective intervention. This paper introduces an innovative method for diagnosing Parkinson's disease through the analysis of human EEG signals, employing a Support Vector Machine (SVM) classification model. this research presents novel contributions to enhance diagnostic accuracy and reliability. Our approach incorporates a comprehensive review of EEG signal analysis techniques and machine learning methods. Drawing from recent studies, we have engineered an advanced SVM-based model optimized for Parkinson's disease diagnosis. Utilizing cutting-edge feature engineering, extensive hyperparameter tuning, and kernel selection, our method achieves not only heightened diagnostic accuracy but also emphasizes model interpretability, catering to both clinicians and researchers. Moreover, ethical concerns in healthcare machine learning, such as data privacy and biases, are conscientiously addressed. We assess our method's performance through experiments on a diverse dataset comprising EEG recordings from Parkinson's disease patients and healthy controls, demonstrating significantly improved diagnostic accuracy compared to conventional techniques. In conclusion, this paper introduces an innovative SVM-based approach for diagnosing Parkinson's disease from human EEG signals. Building upon the IEEE framework and previous research, its novelty lies in the capacity to enhance diagnostic accuracy while upholding interpretability and ethical considerations for practical healthcare applications. These advances promise to revolutionize early Parkinson's disease detection and management, ultimately contributing to enhanced patient outcomes and quality of life.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based  Cross-Center Brain Disease Diagnosis under Unreliable Annotations</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00734">https://arxiv.org/abs/2405.00734</a></p>
  <p><b>作者</b>：Zhenxi Song,  Ruihan Qin,  Huixia Ren,  Zhen Liang,  Yi Guo,  Min Zhang,  Zhiguo Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unreliability significantly challenge, annotation unreliability significantly, significantly challenge, challenge the intelligent, intelligent diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-center data heterogeneity and annotation unreliability significantly challenge the intelligent diagnosis of diseases using brain signals. A notable example is the EEG-based diagnosis of neurodegenerative diseases, which features subtler abnormal neural dynamics typically observed in small-group settings. To advance this area, in this work, we introduce a transferable framework employing Manifold Attention and Confidence Stratification (MACS) to diagnose neurodegenerative disorders based on EEG signals sourced from four centers with unreliable annotations. The MACS framework's effectiveness stems from these features: 1) The Augmentor generates various EEG-represented brain variants to enrich the data space; 2) The Switcher enhances the feature space for trusted samples and reduces overfitting on incorrectly labeled samples; 3) The Encoder uses the Riemannian manifold and Euclidean metrics to capture spatiotemporal variations and dynamic synchronization in EEG; 4) The Projector, equipped with dual heads, monitors consistency across multiple brain variants and ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies learned samples by confidence levels throughout the training process; 6) Forward and backpropagation in MACS are constrained by confidence stratification to stabilize the learning system amid unreliable annotations. Our subject-independent experiments, conducted on both neurocognitive and movement disorders using cross-center corpora, have demonstrated superior performance compared to existing related algorithms. This work not only improves EEG-based diagnostics for cross-center and small-setting brain diseases but also offers insights into extending MACS techniques to other data analyses, tackling data heterogeneity and annotation unreliability in multimedia and multimodal content understanding.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Unveiling Thoughts: A Review of Advancements in EEG Brain Signal  Decoding into Text</b></summary>
  <p><b>编号</b>：[460]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00726">https://arxiv.org/abs/2405.00726</a></p>
  <p><b>作者</b>：Saydul Akbar Murad,  Nick Rahimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained significant traction, brain activity, gained significant, significant traction, decode EEG signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The conversion of brain activity into text using electroencephalography (EEG) has gained significant traction in recent years. Many researchers are working to develop new models to decode EEG signals into text form. Although this area has shown promising developments, it still faces numerous challenges that necessitate further improvement. It's important to outline this area's recent developments and future research directions. In this review article, we thoroughly summarize the progress in EEG-to-text conversion. Firstly, we talk about how EEG-to-text technology has grown and what problems we still face. Secondly, we discuss existing techniques used in this field. This includes methods for collecting EEG data, the steps to process these signals, and the development of systems capable of translating these signals into coherent text. We conclude with potential future research directions, emphasizing the need for enhanced accuracy, reduced system constraints, and the exploration of novel applications across varied sectors. By addressing these aspects, this review aims to contribute to developing more accessible and effective Brain-Computer Interface (BCI) technology for a broader user base.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：EEG_RL-Net: Enhancing EEG MI Classification through Reinforcement  Learning-Optimised Graph Neural Networks</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00723">https://arxiv.org/abs/2405.00723</a></p>
  <p><b>作者</b>：Htoo Wai Aung,  Jiao Jiao Li,  Yang An,  Steven W. Su</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Networks, accurately decoding electroencephalography, EEG, Brain-Computer Interfaces, outperform Convolutional Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain-Computer Interfaces (BCIs) rely on accurately decoding electroencephalography (EEG) motor imagery (MI) signals for effective device control. Graph Neural Networks (GNNs) outperform Convolutional Neural Networks (CNNs) in this regard, by leveraging the spatial relationships between EEG electrodes through adjacency matrices. The EEG_GLT-Net framework, featuring the state-of-the-art EEG_GLT adjacency matrix method, has notably enhanced EEG MI signal classification, evidenced by an average accuracy of 83.95% across 20 subjects on the PhysioNet dataset. This significantly exceeds the 76.10% accuracy rate achieved using the Pearson Correlation Coefficient (PCC) method within the same framework.
In this research, we advance the field by applying a Reinforcement Learning (RL) approach to the classification of EEG MI signals. Our innovative method empowers the RL agent, enabling not only the classification of EEG MI data points with higher accuracy, but effective identification of EEG MI data points that are less distinct. We present the EEG_RL-Net, an enhancement of the EEG_GLT-Net framework, which incorporates the trained EEG GCN Block from EEG_GLT-Net at an adjacency matrix density of 13.39% alongside the RL-centric Dueling Deep Q Network (Dueling DQN) block. The EEG_RL-Net model showcases exceptional classification performance, achieving an unprecedented average accuracy of 96.40% across 20 subjects within 25 milliseconds. This model illustrates the transformative effect of the RL in EEG MI time point classification.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：SynthBrainGrow: Synthetic Diffusion Brain Aging for Longitudinal MRI  Data Generation in Young People</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.00682">https://arxiv.org/abs/2405.00682</a></p>
  <p><b>作者</b>：Anna Zapaishchykova,  Benjamin H. Kann,  Divyanshu Tak,  Zezhong Ye,  Daphne A. Haas-Kogan,  Hugo J.W.L. Aerts</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：neurodegenerative conditions, efficient research, research on neurodevelopmental, neurodevelopmental and neurodegenerative, brain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthetic longitudinal brain MRI simulates brain aging and would enable more efficient research on neurodevelopmental and neurodegenerative conditions. Synthetically generated, age-adjusted brain images could serve as valuable alternatives to costly longitudinal imaging acquisitions, serve as internal controls for studies looking at the effects of environmental or therapeutic modifiers on brain development, and allow data augmentation for diverse populations. In this paper, we present a diffusion-based approach called SynthBrainGrow for synthetic brain aging with a two-year step. To validate the feasibility of using synthetically-generated data on downstream tasks, we compared structural volumetrics of two-year-aged brains against synthetically-aged brain MRI. Results show that SynthBrainGrow can accurately capture substructure volumetrics and simulate structural changes such as ventricle enlargement and cortical thinning. Our approach provides a novel way to generate longitudinal brain datasets from cross-sectional data to enable augmented training and benchmarking of computational tools for analyzing lifespan trajectories. This work signifies an important advance in generative modeling to synthesize realistic longitudinal data with limited lifelong MRI scans. The code is available at XXX.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html"><img class="next-cover" src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">🎨 Stable Diffusion 提示词指南书</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">💭这个人很懒，什么都没有留下</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2024-05-06)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2024-05-06)"/></a><div class="content"><a class="title" href="/2024/05/06/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2024-05-06)">Arxiv每日速递(2024-05-06)</a><time datetime="2024-05-06T00:38:55.907Z" title="发表于 2024-05-06 08:38:55">2024-05-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html" title="🎨 Stable Diffusion 提示词指南书"><img src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="🎨 Stable Diffusion 提示词指南书"/></a><div class="content"><a class="title" href="/2024/02/03/Stable%20Diffusion%20%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%8C%87%E5%8D%97%E4%B9%A6.html" title="🎨 Stable Diffusion 提示词指南书">🎨 Stable Diffusion 提示词指南书</a><time datetime="2024-02-03T06:57:45.000Z" title="发表于 2024-02-03 14:57:45">2024-02-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/22/Transformer%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E9%95%BF%E5%BA%A6%E5%A4%96%E6%8E%A8.html" title="Transformer语言模型的位置编码与长度外推"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/city.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer语言模型的位置编码与长度外推"/></a><div class="content"><a class="title" href="/2023/10/22/Transformer%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E9%95%BF%E5%BA%A6%E5%A4%96%E6%8E%A8.html" title="Transformer语言模型的位置编码与长度外推">Transformer语言模型的位置编码与长度外推</a><time datetime="2023-10-22T14:55:45.000Z" title="发表于 2023-10-22 22:55:45">2023-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度"/></a><div class="content"><a class="title" href="/2023/09/22/vLLM%EF%BC%9A%E5%88%A9%E7%94%A8%E5%88%86%E9%A1%B5%E7%BC%93%E5%AD%98%E5%92%8C%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C%E6%8F%90%E9%AB%98%E5%A4%A7%E6%A8%A1%E5%9E%8B2~4x%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6.html" title="vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><time datetime="2023-09-22T14:55:45.000Z" title="发表于 2023-09-22 22:55:45">2023-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prompt：大语言模型的执行指南"/></a><div class="content"><a class="title" href="/2023/09/06/Prompt%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%A7%E8%A1%8C%E6%8C%87%E5%8D%97.html" title="Prompt：大语言模型的执行指南">Prompt：大语言模型的执行指南</a><time datetime="2023-09-06T14:45:45.000Z" title="发表于 2023-09-06 22:45:45">2023-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (8)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt=""><img width="48" height="48" src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-05-19</span><a class="blog-slider__title" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/05/19/全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/cail2021.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-10-22</span><a class="blog-slider__title" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/10/22/中国法律智能技术评测(CAIL2021)：信息抽取(Rank2).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt=""><img width="48" height="48" src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-17</span><a class="blog-slider__title" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/17/2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖).html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww5.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-22</span><a class="blog-slider__title" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/22/vLLM：利用分页缓存和张量并行提高大模型2~4x推理速度.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/city.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-10-22</span><a class="blog-slider__title" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt="">Transformer语言模型的位置编码与长度外推</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/10/22/Transformer语言模型的位置编码与长度外推.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt=""><img width="48" height="48" src="https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_12_1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-03</span><a class="blog-slider__title" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt="">🎨 Stable Diffusion 提示词指南书</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2024/02/03/Stable Diffusion 提示词指南书.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/ww6.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-06</span><a class="blog-slider__title" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">Prompt：大语言模型的执行指南</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/09/06/Prompt：大语言模型的执行指南.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/11/26/升级深度学习开发环境全攻略.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/misc/cover/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-11-26</span><a class="blog-slider__title" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">升级深度学习开发环境全攻略</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/11/26/升级深度学习开发环境全攻略.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>