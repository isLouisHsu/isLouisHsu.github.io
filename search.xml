<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Install nVidia drivers on Ubuntu]]></title>
    <url>%2F2019%2F05%2F08%2FInstall-nVidia-drivers-on-Ubuntu%2F</url>
    <content type="text"><![CDATA[PPA安装 禁用nouveau驱动先将Ubuntu系统集成的显卡驱动程序nouveau从linux内核卸载 查看当前驱动状态123456789$ lsmod | grep nouveaunouveau 1851392 1mxm_wmi 16384 1 nouveaui2c_algo_bit 16384 2 i915,nouveauttm 110592 1 nouveaudrm_kms_helper 172032 2 i915,nouveaudrm 458752 8 drm_kms_helper,i915,ttm,nouveauwmi 24576 3 wmi_bmof,mxm_wmi,nouveauvideo 45056 3 thinkpad_acpi,i915,nouveau 添加黑名单1234567891011121314$ ll /etc/modprobe.d/blacklist.conf-rw-r--r-- 1 root root 1667 11月 13 05:54 /etc/modprobe.d/blacklist.conf$ sudo chmod 666 /etc/modprobe.d/blacklist.conf[sudo] password for louishsu: $ sudo vim /etc/modprobe.d/blacklist.conf $ sudo chmod 644 /etc/modprobe.d/blacklist.conf$ sudo update-initramfs -uupdate-initramfs: Generating /boot/initrd.img-4.18.0-17-generic...I: Set the RESUME variable to override this. 重启后查看驱动状态，无输出表示禁用成功1$ lsmod | grep nouveau 安装驱动 这里使用PPA方式安装，首先添加源12$ sudo add-apt-repository ppa:graphics-drivers/ppa$ sudo apt-get update 查看合适的驱动版本，如下recommended1$ ubuntu-drivers devices 按ctrl+alt+F1进入tty模式，关闭图形桌面显示管理器LightDM1$ service lightdm stop 安装驱动12$ sudo apt-get install nvidia-418$ sudo reboot 查看安装情况1234567891011121314151617181920$ sudo nvidia-smiWed May 8 20:22:55 2019 +------------------------------------------------------+ | NVIDIA-SMI 340.107 Driver Version: 340.107 | |-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 GeForce GT 730M Off | 0000:04:00.0 N/A | N/A || N/A 46C P0 N/A / N/A | 185MiB / 1023MiB | N/A Default |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Compute processes: GPU Memory || GPU PID Process name Usage ||=============================================================================|| 0 Not Supported |+-----------------------------------------------------------------------------+$ sudo nvidia-settings CUDA查看Ubuntu编译安装Tensorflow Reference ubuntu16.04下NVIDIA GTX965M显卡驱动PPA安装]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无所畏]]></title>
    <url>%2F2019%2F04%2F30%2F%E6%97%A0%E6%89%80%E7%95%8F%2F</url>
    <content type="text"><![CDATA[前言人与人之间的情感交流，一种叫抱怨，一种叫鸡汤。相比较而言，我更喜欢鸡汤。读冯唐的书，就像和长辈促膝交谈，所有放不下的、看不开的、心里郁结的、突然释然了。世间没有佛，但是有带着佛性的人。 精选壹 成功十要素一命二运三风水四积阴德五读书六名七相八敬神九交贵人十养生 曾几何时，我们除了未来一无所有，我们充满好奇，我们有使不完的力气，我们不怕失去，我们眼里有光，我们为建设祖国而读书，我们下身肿胀，我们激素吱吱作响，我们热爱姑娘，我们万物生长。 如何避免成为油腻中年男 不要成为胖子，曾经玉树临风，现在风狂树残； 不要停止学习，吹牛能让我们有瞬间快感，但不能改变我们对一些事物所知甚少的事实； 不要待着不动，说走就走，去散步，去旅行，也好； 不要当众谈性，关于眼神(盯着女生看)的告诫，也适用于权、钱等其他领域； 不要追忆从前，积攒唠叨从前的力气，再创业，再创造，再恋爱，我们还能攻城略地，杀伐战取； 不要教育晚辈，不愤不启； 不要给别人添麻烦； 不要停止购物，完全没了欲望，失去对美好事物的贪心，生命也就没有乐趣； 不要脏兮兮，少年时代的脏是不羁，中年时代的脏是真脏； 不要鄙视和年龄无关的人类习惯，所有的世道变坏，都是从鄙视文艺开始的； 因为苦逼而牛逼，因为逗逼而二逼，因为装逼而傻逼。愿我们原理油腻和猥琐，敬爱女生，过好余生，让世界更美好。 更可怕的是成为了油腻青年 装懂，多学习，多研究，对真正热爱之事，真正投入精力，向那些可以就防晒美白详细说出八种不同方法的女性好好学习； 着急，“夫水之己也不厚，其负大舟也无力”； 逐利，只有对钱的热忱却没有理想，即使站在了风口，也不会成为那只“会飞的猪”； 不要迷恋肉身； 迷恋手机，比起摸不到心爱的姑娘的手，摸不到自己的手机似乎要严重百倍； 不靠谱，将来总有一天，你会明白，困境、死境都是自己曾经立起又自己放倒的目标； 不敢真，对爱的人不敢说“爱”，对不爽的事不敢说“不”，不敢承认自己的处境，不敢承认失败然后从头再来。时过境迁，回过头来，要拿真心对世界的时候，大抵已经找不到心在哪儿了； 假佛系，假装自己无欲无求，其实只是懒得追求，你就不厌倦自己吗？ 审美差，如今担心会跟审美不好的人撞了女朋友的脸(整容)，哈哈哈哈； 不要“脸”，所谓“相由心生”，脸上的油光，就是心里的油渣； “极品”男人如何极致装逼 写信，比如冯唐、比如曾巩； 跑步； 喝茶； 古物，从骨子里明白拥有只是暂时，“欣于所遇，暂得于己，快然自足”； 言语，极致地吹牛逼也是极致装逼的一种，立言也是立德、立功、立言三不朽的一种； 读书； 情怀，极致装逼如下，“为天地立心，为生民立命，为往圣继绝学，为万世开太平”； 喝酒，和好玩儿的人喝，喝完能背出很多唐诗和楚辞； 养生，高逼格的养生是乐生，是在乐生的基础上长生。我老爸抽烟，从十二岁开始抽，现在八十三岁了，他的口头禅是：“天亮了，又赚了。” 修佛，高逼格的修佛是在日常的劳作里、阳光里、花花草草里、众生皆苦里、生命终极无意义里，试图体会到蹦蹦跳跳的快活； 其实，如果志存高远，“三观”正，逼格正，装逼装久了，就是身、心、灵的一部分了。装逼装极致了，就得大成就了。装逼的过程就是学习的过程，就是感受活着的过程，就是实现理想的过程。 那些爱我们或者爱过我们的女生，在她们的一生中要花很多时间陪护我们这些装腔犯，安静地、积极地、有创造力地陪我们装逼好多年。……。如果爱不在了，那就不用管上面说的一切了，让他找别的姑娘配他装逼陪他飞吧。 天天临深履薄，这辈子好惨，而且睡眠毁了、人毁了，也就什么都没了。我不想这样一辈子，我不想总梦见那些提心吊胆的事儿，我还想梦见我以前那些美丽的女朋友以及那些被梨花照过的时光，我提笔在笔记本的扉页上，郑重地写下了我的九字真言：“不着急，不害怕，不要脸。” 对时间的态度：不着急。有时候，关切是不问；有时候，不做比做什么都强； 对结果的态度：不害怕； 对他评的态度：不要脸。“是非审之于己，毁誉听之于人，得失安之于数”； 补充一点变成四点吧：不着急，不害怕，不要脸，不抱怨。 “这是最好的时代，这是最坏的时代；这是智慧的时代，这是愚蠢的时代；这是信仰的时期，这是怀疑的时期；这是光明的季节，这是黑暗的季节；这是希望之春，这是失望之冬；人们面前有着各样事物，人们面前一无所有；人们正在直登天堂，人们正在直下地狱。” 女生把自己整修得越来越像孪生姐妹，男生把自己禅修得越来越无聊。菜越来越没有菜味儿，肉越来越没有肉味儿，街上早就没有野花可以摘了，街上早就没有板砖可以拍了。 面对我们阻止不了的时代变化，多使用肉体，多去狂喜与伤心，多去创造，活出更多人样儿。 人类改变不了人性中的恶，创造完成后保护，保护不住后破坏，破坏后再创造，永陷轮回。 亲爱的，给我写首情诗好吗？越虐心越好。 降维攻击定义：你有道德我没道德，你死，我活；你我都是人你还要做人，我自降为禽兽，你死，我活。 贰 爱情如何对抗时间女人还是要自强不容易生病的身体够用的收入养心的爱好强大到浑蛋的小宇宙 男人同~ 再过一些年，或许宇宙这盆火也会最终熄灭，世界彻底安静下来，时间也瘫倒在空间里，仿佛一只死狗瘫倒在地板上。 爱情大概始于一些及其美妙的刹那。……。在刹那间，希望时间停滞，甚至无疾而终，在刹那间，就此死去。……。幸或者不幸的是，人想死的时候很难死掉，梦幻泡影、闪电烟花之后，生活继续。爱情如何对抗那些璀璨一刹那之外的漫长时间？ 你看他起高楼，你看他楼塌了。起高楼时，这个男的不一定能守得住底线；楼塌时，这个男的不一定能跑得了。 自己穿暖，才是真暖；自己真暖，才有资格相互温暖。 梦里三月桃花，二人一马。 身体极累的时候，心极伤的时候，身外有酒，白、黄、红，心里有姑娘，小鸟、小兽、小妖。白、黄、红流进身体，小鸟、小兽、小妖踏着云彩从心里溜达出来。身体更累，心更伤。风住了，风又起了。沿着伤口，就着酒，往下，再往下，潜水一样，掘井一样，运气好的时候，会看到世界里从来没有的景象。 男性在修炼成功之前(绝大多数在死前都没成功)，似乎总是有种不知进退而成为二逼的风险，过分执着到死拧，过分淡定到麻木，过分较真儿到迂腐，过分邋遢到鼻毛过唇。 只有克服了对于牛逼的过分追求，才能真正避免成为一个傻逼，特别是，随着年纪的增长，避免成为一个老傻逼。 叁 想起一生中后悔的事儿只花时间给三类人：好看的人，好玩的人，又好看又好玩的人。 同样吃一串葡萄，有人先从最好的一颗吃起，好处时每次都吃到可得的最好的一颗；有人先从最差的一颗吃起，好处是每次都能吃到比之前更好的一颗。 前半生认识的朋友来看我，是因为想看我而来看我，而不是因为我在某大机构任职或者刚得了一个世界第一、宇宙无敌的文艺大奖。 一个人在二十岁之前呆过十年的地方，就是他真正的故乡。之后无论他活多久，去过多少地方，故乡都在骨头和血液里，挥之不去。 其实，人一起生活过一段时间，就没了生死的界限，除非彼此的爱意已经被彻底忘记。 我回到您面前，您总会给我一杯热茶，然后也不说话，手指一下，茶在那儿。您走了之后我才明白，一杯热茶之前，要有被子、茶、热水，要问很久、很多次：我儿子什么时候回来啊？ 人皆草木不用成材。 万事都如甘蔗，哪有两头甜？ 因为手写有人味儿。……。手写信，给心里真正放不下的人，贴张邮票，去邮局寄了。 连续七天，口袋里，书包里，我天天带着这只鸟(玉)，手没事儿的时候就摸着它，睡觉的时候也攥着。……。到了第八个晚上，一模那只鸟不见了。我的酒一下醒了，我把行李拆了，没有；我把全身衣服拆了，没有；我把房间拆了，没有；我沿着进房间的路，原路返回到下出租车的那块砖，没有。……。我度过了一个非常清醒、哲学而又精疲力竭的夜晚，和初恋分手的第一晚也比这一晚好过很多。……。我醒来的时候，觉得比睡着之前还要累。我洗把脸，阳光从窗帘缝隙间洒下来，那只玉鸟就安静地待在酒店书桌地一个角落，栖息在酒店的便笺上 —— 应该是我脱裤子之前无意识地把它放到了最安全的地方。……。如果我把那只玉鸟抓过来摔碎，我就成佛了。实际发生的是，在一刹那，我找了根结实的绳儿，穿过玉鸟翅膀上面古老的打眼儿，把玉鸟牢牢地栓在我裤子的皮带扣上。 人生喜悦，失而复得； 太过珍惜，却弄丢了，是人性的矛盾； 愿意被找到的东西，一直在那；不愿意被找到的东西，丢了就丢了把； 为外物而悲喜，这是人性的桎梏。 肆 天用云作字在此刻，天用云作字。在未来某处，在未来某刻，天也用我作字，用我的手蘸着墨作字。 你耐心再看看，再看看，再看看。 如果你有一个期望，长年挥之不去，而且需要别人来满足，这个期望就是妄念。 自责是负能量最大的一种情绪。 任性是被低估的美德。 “事情过去好久了，话也没啥可说的了，但是有时想起你，还是真他妈的难过啊。” 饮酒到微醺，脸红脖子粗，脚下多了一截弹簧，整个人一蹦一跳的，似乎手不抓牢栏杆，身体就随着灵魂飞离地面。 饮酒的一个好处是，用肉的迷失换取灵的觉悟。放不下的、看不开的，几口下肚，眼清目明，仿佛都与自己无关了，不自觉地，脸上堆满了笑。 看看就得了，不要临。字写得漂亮的人太多了，万一你写得漂亮了，再写丑就太难了，你就不是你了，老天给你手上的那一丁丁点独特的东西就没了。 佛界易入，魔界难入。佛界和魔界都入入，人更知道什么是佛、什么是魔，人更容易平衡一点儿，在世上能走的更远点儿。]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>冯唐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[REPRODUCTION]A Recipe for Training Neural Networks]]></title>
    <url>%2F2019%2F04%2F29%2FREPRODUCTION-A-Recipe-for-Training-Neural-Networks%2F</url>
    <content type="text"><![CDATA[转载自Andrej Karpathy blog The recipeIn light of the above two facts, I have developed a specific process for myself that I follow when applying a neural net to a new problem, which I will try to describe. You will see that it takes the two principles above very seriously. In particular, it builds from simple to complex and at every step of the way we make concrete hypotheses about what will happen and then either validate them with an experiment or investigate until we find some issue. What we try to prevent very hard is the introduction of a lot of “unverified” complexity at once, which is bound to introduce bugs/misconfigurations that will take forever to find (if ever). If writing your neural net code was like training one, you’d want to use a very small learning rate and guess and then evaluate the full test set after every iteration. 1. Become one with the dataThe first step to training a neural net is to not touch any neural net code at all and instead begin by thoroughly inspecting your data. This step is critical. I like to spend copious amount of time (measured in units of hours) scanning through thousands of examples, understanding their distribution and looking for patterns. Luckily, your brain is pretty good at this. One time I discovered that the data contained duplicate examples. Another time I found corrupted images / labels. I look for data imbalances and biases. I will typically also pay attention to my own process for classifying the data, which hints at the kinds of architectures we’ll eventually explore. As an example - are very local features enough or do we need global context? How much variation is there and what form does it take? What variation is spurious and could be preprocessed out? Does spatial position matter or do we want to average pool it out? How much does detail matter and how far could we afford to downsample the images? How noisy are the labels? data contained duplicate examples corrupted images &amp; labels data imbalances and biases local features v.s. global context quantity &amp; form of variation preprocess out some variation spatial position v.s. average pool detail v.s. downsample labels are noisy? In addition, since the neural net is effectively a compressed/compiled version of your dataset, you’ll be able to look at your network (mis)predictions and understand where they might be coming from. And if your network is giving you some prediction that doesn’t seem consistent with what you’ve seen in the data, something is off. Once you get a qualitative sense it is also a good idea to write some simple code to search/filter/sort by whatever you can think of (e.g. type of label, size of annotations, number of annotations, etc.) and visualize their distributions and the outliers along any axis. The outliers especially almost always uncover some bugs in data quality or preprocessing. 2. Set up the end-to-end training/evaluation skeleton + get dumb baselinesNow that we understand our data can we reach for our super fancy Multi-scale ASPP FPN ResNet and begin training awesome models? For sure no. That is the road to suffering. Our next step is to set up a full training + evaluation skeleton and gain trust in its correctness via a series of experiments. At this stage it is best to pick some simple model that you couldn’t possibly have screwed up somehow - e.g. a linear classifier, or a very tiny ConvNet. We’ll want to train it, visualize the losses, any other metrics (e.g. accuracy), model predictions, and perform a series of ablation experiments with explicit hypotheses along the way. Tips &amp; tricks for this stage: fix random seed. Always use a fixed random seed to guarantee that when you run the code twice you will get the same outcome. This removes a factor of variation and will help keep you sane. simplify. Make sure to disable any unnecessary fanciness. As an example, definitely turn off any data augmentation at this stage. Data augmentation is a regularization strategy that we may incorporate later, but for now it is just another opportunity to introduce some dumb bug. add significant digits to your eval. When plotting the test loss run the evaluation over the entire (large) test set. Do not just plot test losses over batches and then rely on smoothing them in Tensorboard. We are in pursuit of correctness and are very willing to give up time for staying sane. verify loss @ init. Verify that your loss starts at the correct loss value. E.g. if you initialize your final layer correctly you should measure -log(1/n_classes) on a softmax at initialization. The same default values can be derived for L2 regression, Huber losses, etc. init well. Initialize the final layer weights correctly. E.g. if you are regressing some values that have a mean of 50 then initialize the final bias to 50. If you have an imbalanced dataset of a ratio 1:10 of positives:negatives, set the bias on your logits such that your network predicts probability of 0.1 at initialization. Setting these correctly will speed up convergence and eliminate “hockey stick” loss curves where in the first few iteration your network is basically just learning the bias. human baseline. Monitor metrics other than loss that are human interpretable and checkable (e.g. accuracy). Whenever possible evaluate your own (human) accuracy and compare to it. Alternatively, annotate the test data twice and for each example treat one annotation as prediction and the second as ground truth. input-indepent baseline. Train an input-independent baseline, (e.g. easiest is to just set all your inputs to zero). This should perform worse than when you actually plug in your data without zeroing it out. Does it? i.e. does your model learn to extract any information out of the input at all? overfit one batch. Overfit a single batch of only a few examples (e.g. as little as two). To do so we increase the capacity of our model (e.g. add layers or filters) and verify that we can reach the lowest achievable loss (e.g. zero). I also like to visualize in the same plot both the label and the prediction and ensure that they end up aligning perfectly once we reach the minimum loss. If they do not, there is a bug somewhere and we cannot continue to the next stage. verify decreasing training loss. At this stage you will hopefully be underfitting on your dataset because you’re working with a toy model. Try to increase its capacity just a bit. Did your training loss go down as it should? visualize just before the net. The unambiguously correct place to visualize your data is immediately before your y_hat = model(x) (or sess.run in tf). That is - you want to visualize exactly what goes into your network, decoding that raw tensor of data and labels into visualizations. This is the only “source of truth”. I can’t count the number of times this has saved me and revealed problems in data preprocessing and augmentation. visualize prediction dynamics. I like to visualize model predictions on a fixed test batch during the course of training. The “dynamics” of how these predictions move will give you incredibly good intuition for how the training progresses. Many times it is possible to feel the network “struggle” to fit your data if it wiggles too much in some way, revealing instabilities. Very low or very high learning rates are also easily noticeable in the amount of jitter. use backprop to chart dependencies. Your deep learning code will often contain complicated, vectorized, and broadcasted operations. A relatively common bug I’ve come across a few times is that people get this wrong (e.g. they use view instead of transpose/permute somewhere) and inadvertently mix information across the batch dimension. It is a depressing fact that your network will typically still train okay because it will learn to ignore data from the other examples. One way to debug this (and other related problems) is to set the loss for some example i to be 1.0, run the backward pass all the way to the input, and ensure that you get a non-zero gradient only on the i-th example. More generally, gradients give you information about what depends on what in your network, which can be useful for debugging. generalize a special case. This is a bit more of a general coding tip but I’ve often seen people create bugs when they bite off more than they can chew, writing a relatively general functionality from scratch. I like to write a very specific function to what I’m doing right now, get that to work, and then generalize it later making sure that I get the same result. Often this applies to vectorizing code, where I almost always write out the fully loopy version first and only then transform it to vectorized code one loop at a time. 固定随机种子，消除随机带来的误差 简单出发，先不使用数据集扩增 测试集不要画曲线，不然会疯的 评估起始损失值，-log(1/n_classes)，各类初始概率应大致相等；思路一致, $p\approx$ 初始化最后一层权重很重要；一般都是采用随机初始化方法？？ 评估人的准确性并与模型比较 设置一个独立于输入的baseline，观察网络是否提取了想要的特征 反复训练同一个批次的数据，使网络过拟合，查看损失最低能到多少；确定网络结构没有问题 试着增加模型capacity，观察训练集损失是否下降，以确定合适的网络容量；确定模型参数量 输入网络前，可视化数据，查看数据是否正确；确定输入数据没有问题 可视化一些相同数据的输出，观察输出波动；观察网络收敛情况 用反向传播debug网络；高级技能？技能点还不够 全循环慢慢改成矢量化代码；一些复杂的计算可参考 3. OverfitAt this stage we should have a good understanding of the dataset and we have the full training + evaluation pipeline working. For any given model we can (reproducibly) compute a metric that we trust. We are also armed with our performance for an input-independent baseline, the performance of a few dumb baselines (we better beat these), and we have a rough sense of the performance of a human (we hope to reach this). The stage is now set for iterating on a good model. The approach I like to take to finding a good model has two stages: first get a model large enough that it can overfit (i.e. focus on training loss) and then regularize it appropriately (give up some training loss to improve the validation loss). The reason I like these two stages is that if we are not able to reach a low error rate with any model at all that may again indicate some issues, bugs, or misconfiguration. A few tips &amp; tricks for this stage: picking the model. To reach a good training loss you’ll want to choose an appropriate architecture for the data. When it comes to choosing this my #1 advice is: Don’t be a hero. I’ve seen a lot of people who are eager to get crazy and creative in stacking up the lego blocks of the neural net toolbox in various exotic architectures that make sense to them. Resist this temptation strongly in the early stages of your project. I always advise people to simply find the most related paper and copy paste their simplest architecture that achieves good performance. E.g. if you are classifying images don’t be a hero and just copy paste a ResNet-50 for your first run. You’re allowed to do something more custom later and beat this. adam is safe. In the early stages of setting baselines I like to use Adam with a learning rate of 3e-4. In my experience Adam is much more forgiving to hyperparameters, including a bad learning rate. For ConvNets a well-tuned SGD will almost always slightly outperform Adam, but the optimal learning rate region is much more narrow and problem-specific. (Note: If you are using RNNs and related sequence models it is more common to use Adam. At the initial stage of your project, again, don’t be a hero and follow whatever the most related papers do.) complexify only one at a time. If you have multiple signals to plug into your classifier I would advise that you plug them in one by one and every time ensure that you get a performance boost you’d expect. Don’t throw the kitchen sink at your model at the start. There are other ways of building up complexity - e.g. you can try to plug in smaller images first and make them bigger later, etc. do not trust learning rate decay defaults. If you are re-purposing code from some other domain always be very careful with learning rate decay. Not only would you want to use different decay schedules for different problems, but - even worse - in a typical implementation the schedule will be based current epoch number, which can vary widely simply depending on the size of your dataset. E.g. ImageNet would decay by 10 on epoch 30. If you’re not training ImageNet then you almost certainly do not want this. If you’re not careful your code could secretely be driving your learning rate to zero too early, not allowing your model to converge. In my own work I always disable learning rate decays entirely (I use a constant LR) and tune this all the way at the very end. 不要逞强，搭建各种奇奇怪怪的模型。先从相近任务效果良好的网络结构出发，慢慢改进再击败它； Adam对参数敏感性低，SGD往往效果更好； 慢慢提高输入数据的复杂性，如输入数据的特征数、图像尺寸； 根据自己的学习任务，调整学习率衰减参数； 4. RegularizeIdeally, we are now at a place where we have a large model that is fitting at least the training set. Now it is time to regularize it and gain some validation accuracy by giving up some of the training accuracy. Some tips &amp; tricks: get more data. First, the by far best and preferred way to regularize a model in any practical setting is to add more real training data. It is a very common mistake to spend a lot engineering cycles trying to squeeze juice out of a small dataset when you could instead be collecting more data. As far as I’m aware adding more data is pretty much the only guaranteed way to monotonically improve the performance of a well-configured neural network almost indefinitely. The other would be ensembles (if you can afford them), but that tops out after ~5 models. data augment. The next best thing to real data is half-fake data - try out more aggressive data augmentation. creative augmentation. If half-fake data doesn’t do it, fake data may also do something. People are finding creative ways of expanding datasets; For example, domain randomization, use of simulation, clever hybrids such as inserting (potentially simulated) data into scenes, or even GANs. pretrain. It rarely ever hurts to use a pretrained network if you can, even if you have enough data. stick with supervised learning. Do not get over-excited about unsupervised pretraining. Unlike what that blog post from 2008 tells you, as far as I know, no version of it has reported strong results in modern computer vision (though NLP seems to be doing pretty well with BERT and friends these days, quite likely owing to the more deliberate nature of text, and a higher signal to noise ratio). smaller input dimensionality. Remove features that may contain spurious signal. Any added spurious input is just another opportunity to overfit if your dataset is small. Similarly, if low-level details don’t matter much try to input a smaller image. smaller model size. In many cases you can use domain knowledge constraints on the network to decrease its size. As an example, it used to be trendy to use Fully Connected layers at the top of backbones for ImageNet but these have since been replaced with simple average pooling, eliminating a ton of parameters in the process. decrease the batch size. Due to the normalization inside batch norm smaller batch sizes somewhat correspond to stronger regularization. This is because the batch empirical mean/std are more approximate versions of the full mean/std so the scale &amp; offset “wiggles” your batch around more. drop. Add dropout. Use dropout2d (spatial dropout) for ConvNets. Use this sparingly/carefully because dropout does not seem to play nice with batch normalization. weight decay. Increase the weight decay penalty. early stopping. Stop training based on your measured validation loss to catch your model just as it’s about to overfit. try a larger model. I mention this last and only after early stopping but I’ve found a few times in the past that larger models will of course overfit much more eventually, but their “early stopped” performance can often be much better than that of smaller models. Finally, to gain additional confidence that your network is a reasonable classifier, I like to visualize the network’s first-layer weights and ensure you get nice edges that make sense. If your first layer filters look like noise then something could be off. Similarly, activations inside the net can sometimes display odd artifacts and hint at problems. 略微升高一点训练数据的损失，换取验证集损失的下降。 扩大数据集；拼的就是算力和数据量 数据集扩增；来了 使用一些生成的虚假数据； 预训练模型，即使有足够的数据量； 监督性学习比非监督好； 减少数据特征的冗余性，如删减特征、降低图像分辨率；数据冗余容易过拟合 减少模型参数容量；过大可能过拟合 增大批数据量；梯度下降方向更准确 Dropout；BatchNorm效果更好？ 权重衰减；正则惩罚 Early stopping；提前中断训练防止过拟合 尝试更大的模型，有时候更大容易过拟合，但是提前中断训练效果会更好； 第一层网络的权值是否有可解释性；WTF? 5. TuneYou should now be “in the loop” with your dataset exploring a wide model space for architectures that achieve low validation loss. A few tips and tricks for this step: random over grid search. For simultaneously tuning multiple hyperparameters it may sound tempting to use grid search to ensure coverage of all settings, but keep in mind that it is best to use random search instead. Intuitively, this is because neural nets are often much more sensitive to some parameters than others. In the limit, if a parameter a matters but changing b has no effect then you’d rather sample a more throughly than at a few fixed points multiple times. hyper-parameter optimization. There is a large number of fancy bayesian hyper-parameter optimization toolboxes around and a few of my friends have also reported success with them, but my personal experience is that the state of the art approach to exploring a nice and wide space of models and hyperparameters is to use an intern :). Just kidding. 随机搜索超参数，对重要参数调整更多； 招募一个实习生帮助自己调参hhhhhh； 6. Squeeze out the juiceOnce you find the best types of architectures and hyper-parameters you can still use a few more tricks to squeeze out the last pieces of juice out of the system: ensembles. Model ensembles are a pretty much guaranteed way to gain 2% of accuracy on anything. If you can’t afford the computation at test time look into distilling your ensemble into a network using dark knowledge. leave it training. I’ve often seen people tempted to stop the model training when the validation loss seems to be leveling off. In my experience networks keep training for unintuitively long time. One time I accidentally left a model training during the winter break and when I got back in January it was SOTA (“state of the art”). 集成方法； 坚信模型能收敛并能取得良好的效果，不要手贱中断他。 ConclusionOnce you make it here you’ll have all the ingredients for success: You have a deep understanding of the technology, the dataset and the problem, you’ve set up the entire training/evaluation infrastructure and achieved high confidence in its accuracy, and you’ve explored increasingly more complex models, gaining performance improvements in ways you’ve predicted each step of the way. You’re now ready to read a lot of papers, try a large number of experiments, and get your SOTA results. Good luck!]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[在宇宙间不易被风吹散]]></title>
    <url>%2F2019%2F04%2F28%2F%E5%9C%A8%E5%AE%87%E5%AE%99%E9%97%B4%E4%B8%8D%E6%98%93%E8%A2%AB%E9%A3%8E%E5%90%B9%E6%95%A3%2F</url>
    <content type="text"><![CDATA[前言喜欢冯唐的文集，用他自己文章里写的句子描述，“毫不掩饰的小说”，露骨但是真实，文字如锦如绣，文字间有墨香、有美人、有Kindle、有古玉和瓷器。 你迷恋什么，什么就是你的障碍。有个笃定的核，在宇宙间不易被风吹散。 精选 人是需要有点精神的，有点通灵的精神，否则很容易出溜成行尸走肉，任由人性中暗黑的一面驱使自己禽兽一样的肉身，在世间做一些腐朽不堪的事情。 一杆进洞，四下无人，人生悲惨莫过于此。 一日茶，一夜酒，一部毫不掩饰的小说，一次没有目的的见面，一群不谈正经事的朋友，用美好的器物消磨必定留不住的时间。 做一个人性的矿工，挖一挖，再挖一挖，看看下面的下面还有什么。 我觉得眼睛看到的一切似乎想要告诉我世界是什么但是又不明说到底是什么。 在纸书里，在啤酒里，在阳光里，在暖气里，宅着，屌着，无所事事，随梦所之。 我的、我的、我的、我的，一瞬间的我执爆棚，真好。 宇宙间大多数现象超越人类的知识范围，不可解释的例子比比皆是，比如人骨骼为啥是206块骨头，比如我爱你你为什么不爱我。 人生苦短，不如不管，继续任性。 时间在床边和鬓边一路小跑，有些事物在不知不觉中浅吟低唱，明生暗长。 人又不是黄金，怎么能让所有人都喜欢？任何事做到顶尖，都是政治，都会被人妒忌；即使是黄金，也会被某些人说成是臭狗屎。 既然死了的人都没睡醒过，活着时候睡觉就是很吃亏的一件事。 白白的，小小的，紧紧的，香香的，佛说第一次触摸最接近佛。——《初恋》 有时候，人会因为一两个微不足道的美好，安安渴望一个巨大的负面，比如因为像有机会用一下图案撩骚的Zippo打火机而渴望抽烟，比如因为一把好乳或者一头长发而舍不得一个三观凌乱的悍妇，比如因为一个火炉而期待北京一个漫长而寒冷的冬天。 脱离长期背在身上的人的羁绊，让身体里的禽兽和仙人在山林里和酒里渐渐增加比例，裸奔、裸泳，在池塘里带着猴子捞月亮，在山顶问神仙：人到底是个什么东西？ 想起后半生最不靠谱的事儿，结论是：最靠谱的还是买个酒庄。 天大理比不过“我喜欢”。 涉及终极的事儿，听天，听命，让自己和身体尽人力，其他不必去想，多想无益，徒增烦恼。 全球化了，各国的建筑师都到处串了，各种时装杂志都到处发行了，各地的楼宇和姑娘越来越像，像到面目模糊，天下一城。 最后一个能想到的原因，是随身佩带之后，无时无刻不提醒自己一些必须珍惜的事物和必须坚守的品质。君子无辜，玉不去身，时刻提醒自己，不要吃喝嫖赌抽、坑蒙拐骗偷。 科技的快速进步让很多人变得过时，也让很多器物变得多余。 我会老到有一天，不需要手表告诉我，时间是如何自己消失，也不需要靠名牌手表告诉周围人类我的品味、格调、富裕程度和牛逼等级。我会根据四季里的光线的变化，大致推断现在是几点了，根据肠胃的叫声决定是否该去街口的小馆儿了。 男人要有些士的精神，有所不为，有所必为，活着不是唯一的追求和最终的底线。 女人一头长发，骑匹大马，很迷人，非常迷人，而且，她是来救你的，就无比迷人。无论她要带你去哪，你都不要拒绝，先上马，然后闭嘴，什么都不要问。 买件立领风衣，浓个眉大个眼，一直走，不要往两边看，还能再混几十年。 家庭太复杂，涉及太多硬件和软件、生理和心理、现在和未来，一篇文章不容易讲透。 上天下地，背山面海，每天看看不一样的云，想想昨晚的梦，和自己聊一会天，日子容易丰盛起来。 朋友们就散住在附近几个街区，不用提前约，菜香升起时，几个电话就能聚起几个人，酒量不同，酒品相近，术业不同，三观接近。菜一般，就多喝点酒；酒不好，就再多喝点，很快就能高兴起来。 一生中，除了做自己喜欢的事儿，剩下最重要的就是和相看两不厌的人待在一起。 不和这个世界争，也不和别人争，更不要和自己争。争的结果可能是一时牛逼，也可能是心脑血管意外，后者造成的持续影响大很多。 尽管没去过南极，但是也见过了风雨，俗事已经懒得分析，不如一起一边慢跑，一边咒骂彼此生活中奇葩一样摇曳的傻逼。 世界这么多凶狠，他人心里那么多地狱，内心没有一点混蛋，如何走的下去？ 其实我们跟鱼、植物甚至草履虫有很多相近的地方，人或如草木，人可以甚至应该偶尔禽兽。 如果没有真的存在，所谓的善只能是伪善，所谓的美也只能是妄美。 因为人是要死的，所以要常常叨念冯唐说的九字箴言：不着急，不害怕，不要脸。 钱超过一定数目就不是用来个人消费的了，个人能温饱就好。多处的个人欲望需要靠修行来消灭，而不能靠多花钱来满足。 有帽子是一种相，没帽子也是一种相。内心不必太执着于无帽子的相，也不必太执着于有帽子的相。有帽子，无帽子，都需要亲尝，皆为玩耍。 既然戴帽子是相，投射到不同人的心识里就是不同的相，何必强求赞美？何必强调一致？何必消除噪音？ “宇戴王冠，必承其重。不要低头，王冠会掉。不要哭泣，有人会笑。”这个态度也太励志、太谋权，放松，戴戴耍耍，不留神，王冠掉了，掉就掉了，掉了就索性长发飘飘。 能做到实事求是地自恋其实是自信和自尊。任何领域做到最好之后，人只能相信自己的判断，只能自恋。……。从这个意义上讲，自恋不应该是被诟病的对象，不能实事求是的傻逼才应该是被诟病的对象。……。实事求是地修炼，实事求是地恋他和自恋，让别人闹心去吧。 矮子更爱居高临下，傻子更容易认为自己充满道理。 非让矮子明白自己是矮子，非让傻子明白自己是傻子，也是很耗神费时的事儿。对付世间闹心的事儿，只需要搞清楚两件事，一件是“关我屁事”，另一件是“关你屁事”。 小孩在天地间疯跑，不知道名利为何物，学习基本常识，食蔬饮水，应付无聊的课程，傻愣愣地杀无聊的时间，骂所有看不上的人“傻逼”。本身近佛，不需要佛。 有多少似乎过不起的事儿过不去一年？有多少看上去的大事最后真是大事？名片上印不下的名头，敌不过左图且书、右琴与壶，抵不过不得不褪去时一颗好心脏、一个好女生。 这样简单下去，再简单下去，脑子没弯儿了，手脚有劲儿了，山顶慢慢低于脚面了，拉萨就在眼前了。你我竟然像山、云、湖水和星空一样，一直在老去，一直在变化，一直没问题。再简单下去，在这样下去，你我都是佛了。 我常年劳碌，尽管热爱妇女，但没时间，无法让任何妇女满意。情伤之后，“得不到”，“留不住”，“无可奈何，奈何奈何”，唯一疗伤的方式就是拿伤口当笔头，写几行诗，血干了，诗出了，心里放下了。 如果去一座荒岛，没电，没电视，没电脑，一片蛮荒。我想了想，如果只能带一个活物。我就带一个和我能聊很多天的女人；如果只能带一本书，我就带一本《唐诗三百首》。]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>冯唐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LDA]]></title>
    <url>%2F2019%2F04%2F22%2FLDA%2F</url>
    <content type="text"><![CDATA[前言在PCA中，介绍了无监督降维方法，主成分分析(Principal Components Analysis)。从投影后数据方差最大的角度出发，选取主轴。下面介绍一种有监督的降维方法，线性判别分析(Linear Discriminant Analysis)。 原理设有$n$维样本集$D=\{x^{(1)}, …, x^{(i)}, …, x^{(m)}\}$，所属类别数目为$C$，现求其第一投影轴$u_1$，即 \tilde{x}^{(i)}_1 = u_1^Tx^{(i)}现希望投影后，类内距离越小越好，类间距离越大越好，定义衡量指标 类内离差阵 S_W = \sum_{j=1}^C \frac{m_j}{m} \left[ \frac{1}{m_j} \sum_{i=1}^{m_j} (x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T \right] \tag{1} 即 S_W = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} (x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T \tag{1} 类间离差阵 S_B = \sum_{j=1}^C \frac{m_j}{m} (\mu^{(j)} - \mu) (\mu^{(j)} - \mu)^T \tag{2} 则投影到第一主轴$u_1$后数据的类内离差阵和类间离差阵为 \tilde{S_W} = \sum_{j=1}^C \frac{m_j}{m} \left[ \frac{1}{m_j} \sum_{i=1}^{m_j} (\tilde{x}^{(i)}_1 - \tilde{\mu}^{(j)}_1) (\tilde{x}^{(i)}_1 - \tilde{\mu}^{(j)}_1)^T \right] \tilde{S_B} = \sum_{j=1}^C \frac{m_j}{m} (\tilde{\mu}^{(j)}_1 - \tilde{\mu}_1) (\tilde{\mu}^{(j)}_1 - \tilde{\mu}_1)^T其中 \tilde{x}^{(i)}_1 = u_1^T x^{(i)} \tilde{\mu}^{(j)}_1 = u_1^T \mu^{(j)} \tilde{\mu}_1 = u_1^T \mu带入后得到 \tilde{S_W} = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} (u_1^T x^{(i)} - u_1^T \mu^{(j)}) (u_1^T x^{(i)} - u_1^T \mu^{(j)})^T = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} u_1^T(x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T u_1 = u_1^T S_W u_1同理 \tilde{S_B} = u_1^T S_B u_1定义优化目标 J = \min \left\{ \frac{\tilde{S_W}}{\tilde{S_B}} \right\} = \min \left\{ \frac{u_1^T S_W u_1}{u_1^T S_B u_1} \right\} \tag{3}取 L(u_1) = \frac{u_1^T S_W u_1}{u_1^T S_B u_1} \tag{4}则其极值为 \frac{∂L}{∂u_1} = \frac{2(u_1^T S_B u_1) S_W u_1 - 2(u_1^T S_W u_1) S_B u_1}{(u_1^T S_B u_1)^2} = 0得到 (u_1^T S_B u_1) S_W u_1 = (u_1^T S_W u_1) S_B u_1令$\lambda_1 = \frac{u_1^T S_B u_1}{u_1^T S_W u_1}$，有 S_B u_1 = \lambda_1 S_W u_1 \tag{5}当$m$较大时，$S_W$一般非奇异，故 S_W^{-1} S_B u_1 = \lambda_1 u_1 \tag{6}即$\{\lambda_1, u_1\}$为矩阵$S_W^{-1} S_B$的特征对。 更进一步，对于而分类问题，我们有 S_B = \sum_{j=1}^C \frac{m_j}{m} (\mu^{(j)} - \mu) (\mu^{(j)} - \mu)^T = \frac{m_1}{m} (\mu^{(1)} - \mu) (\mu^{(1)} - \mu)^T + \frac{m_2}{m} (\mu^{(2)} - \mu) (\mu^{(2)} - \mu)^T = \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - 2 \mu \left( \frac{m_1}{m} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)T} \right) + \mu \mu^T其中 \frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)} = \mu \tag{*1}所以$(7)$带入$S_B$化简得 S_B = \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - \mu \mu^T = \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - (\frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)}) (\frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)})^T = \frac{m_1}{m} \left(1-\frac{m_1}{m}\right) \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \left(1-\frac{m_2}{m}\right) \mu^{(2)} \mu^{(2)T} - \frac{m_1}{m} \frac{m_2}{m} \mu^{(2)} \mu^{(1)T} - \frac{m_1}{m} \frac{m_2}{m} \mu^{(1)} \mu^{(2)T} = \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T$S_B$带入式$(*)$，得 左边 = S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T u_1其中$\left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T u_1$为常数，记作$\alpha$，所以 u_1 = \frac{\alpha}{\lambda_1} S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \tag{*2}其中常数$\frac{\alpha}{\lambda_1}$不影响投影结果，如取$1$，则得到 u_1 = S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)同理，可求得第二、三主成分轴 计算步骤给定数据集矩阵 X = \left[ \begin{matrix} ... \\ x^{(i)T} \\ ... \end{matrix} \right]其中$x^{(i)} = \left[ x^{(i)}_1, …, x^{(i)}_j, … x^{(i)}_n \right]^T$ 计算类内离差阵$S_W$与类间离差阵$S_B$； 计算矩阵$S_W^{-1}S_B$的特征对$(\lambda_i, u_i)$； 按特征值从大到小排序，选取最大的特征值作为第一主轴； 将数据投影到主轴上； 应用LDA可用于分类，以二分类为例，在求取主轴$u_1$后，将各类中心投影到主轴上，即 \begin{cases} \tilde{\mu}^{(1)}_1 = u_1^T \mu^{(1)} \\ \tilde{\mu}^{(2)}_1 = u_1^T \mu^{(2)} \end{cases}选取阈值，如 \tilde{x}_1 = \frac{\tilde{\mu}^{(1)}_1 + \tilde{\mu}^{(2)}_1}{2}则预测时，判决方程为 \begin{cases} u_1^T x^{(i)} < \tilde{x}_1 \Rightarrow x^{(i)} \in \omega_1 \\ u_1^T x^{(i)} > \tilde{x}_1 \Rightarrow x^{(i)} \in \omega_2 \end{cases}代码详情查看Github 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788class LDA(object): """ 先行判别分析 Attributes: n_components: &#123;int&#125; 主成分个数 axis: &#123;ndarray(n_features, n_component)&#125; Notes: S_W = \frac&#123;1&#125;&#123;m&#125; \sum_&#123;j=1&#125;^C \sum_&#123;i=1&#125;^m_j (x^&#123;(i)&#125; - \mu^&#123;(j)&#125;) (x^&#123;(i)&#125; - \mu^&#123;(j)&#125;)^T S_B = \sum_&#123;j=1&#125;^C \frac&#123;m_j&#125;&#123;m&#125; (\mu^&#123;(j)&#125; - \mu) (\mu^&#123;(j)&#125; - \mu)^T Example: """ def __init__(self, n_components=-1): self.n_components = n_components self.axis = None def fit(self, X, y, prop=0.99): """ train the model Params: X: &#123;ndarray(n_samples, n_features)&#125; y: &#123;ndarray(n_samples)&#125; prop: &#123;float&#125;: 在[0, 1]范围内，表示取特征值之和占所有特征值的比重 Notes: - `prop`参数仅在`n_components=-1`时生效 """ labels = list(set(list(y))) n_class = len(labels) n_samples, n_feats = X.shape ## 计算 S_W, S_B S_W = np.zeros(shape=(n_feats, n_feats)) S_B = np.zeros(shape=(n_feats, n_feats)) mean_ = np.mean(X, axis=0) for i_class in range(n_class): X_ = X[y==labels[i_class]] weight = X_.shape[0] / n_samples means_ = np.mean(X_, axis=0) S_W += ((X_ - means_).T).dot(X_ - means_) / X_.shape[0] * weight S_B += (means_ - mean_).dot((means_ - mean_).T) * weight ## 计算特征对 eigVal, eigVec = np.linalg.eig(np.linalg.inv(S_W).dot(S_B)) order = np.argsort(eigVal)[::-1] eigVal = eigVal[order] eigVec = eigVec.T[order].T ## 选取主轴 if self.n_components == -1: sumOfEigVal = np.sum(eigVal) sum_tmp = 0 for k in range(eigVal.shape[0]): sum_tmp += eigVal[k] if sum_tmp &gt; prop * sumOfEigVal: self.n_components = k + 1 break self.axis = eigVec[:, :self.n_components] def transform(self, X): """ Params: X: &#123;ndarray(n_samples, n_features)&#125; Returns: X: &#123;ndarray(n_samples, n_components)&#125; """ X = X.dot(self.axis) return X def fit_transform(self, X, y, prop=0.99): """ Params: X: &#123;ndarray(n_samples, n_features)&#125; Returns: X: &#123;ndarray(n_samples, n_components)&#125; """ self.fit(X, y, prop=prop) X = self.transform(X) return X def transform_inv(self, X): """ Params: X: &#123;ndarray(n_samples, n_components)&#125; Returns: X: &#123;ndarray(n_samples, n_features)&#125; """ X = X.dot(self.axis.T) return X 与PCA投影结果对比如下 PCA LDA Reference 机器学习中的数学(4)-线性判别分析（LDA）, 主成分分析(PCA)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[N-dim Array PCA]]></title>
    <url>%2F2019%2F04%2F18%2Fn-dim-Array-PCA%2F</url>
    <content type="text"><![CDATA[前言在PCA中介绍了1维数据的主成分分析，那么对于多维数据，如何进行处理呢？有一种做法是，将单份的样本数据展开为1维向量，再进行PCA，例如著名的Eigenface，如图所示 这有一个缺点是，忽略了多维数据的空间信息，且计算时，若展开后维度过大，协方差矩阵的求逆过程非常耗时间，以下介绍多维主成分分析。 原理对于单维$n$维度数据$X = \left[\begin{matrix} x^{(1)} \\ x^{(2)} \\ … \\ x^{(N)} \end{matrix}\right]$，我们有 X' = XU其中，$x^{(i)}$为$n$维行向量，组成样本矩阵$X_{N×n}$，$U_{n×n_1}$为投影矩阵，$X’_{N×n_1}$为降维后的样本矩阵。 对于多(n)维样本张量数据$X_{N×n_{d_1}×n_{d_2}×…×n_{d_n}}$，指定各维度降维顺序，在$d_i$维度上，我们将张量在该维度上展开为$1$维向量 X_{N_{d_i}×n_{d_i}}其中 N_{d_i} = \prod_{j=0,j≠i}^n n_{d_j}然后在$d_i$维度上进行降维，即 X'_{N_{d_i}×n'_{d_i}} = X_{N_{d_i}×n_{d_i}} U^{d_i}其中$U^{d_i}$表示$d_i$维度的投影矩阵，其大小为$n_{d_i}×n’_{d_i}$，然后，将该张量其余维度恢复，得到 X^{d_i}_{N×n_{d_1}×..×n'_{d_i}×...×n_{d_n}}如此循环，在各维度进行降维，得到张量 X^{d_1, ..., d_n}_{N×n'_{d_1}×..×n'_{d_i}×...×n'_{d_n}}注意，不同的降维顺序得到的参数会存在差异。 以3维张量$X(H, W, C)$为例，指定降维顺序为$(d_1, d_2, d_3)$，其降维过程表示如图 在$H$维度上 在$W$维度上 在$C$维度上 代码实现同样的，以3维张量$X(H, W, C)$为例，指定降维顺序为$(d_1, d_2, d_3)$ 在$H$维度上 将该张量转置，得到$X^{T_{d_1d_3}}(C, W, H)$ 将其展开为$X_{flatten}(N_H×H)$，其中$N_H=C×W$ 降维得到$X’_{flatten}(N_H×H’)$ 重新将另外两维恢复，得到$X^{T_{d_1d_3}’}(C, W, H’)$ 将张量转置，得到$X^{d_1}(H’, W, C)$ 在$W$维度上 将$X^{d_1}(H’, W, C)$转置，得到$X^{T_{d_2d_3}}(H’, C, W)$ 将其展开为$X_{flatten}(N_W×W)$，其中$N_W=H’×C$ 降维得到$X’_{flatten}(N_W×W’)$ 重新将另外两维恢复，得到$X^{T_{d_2d_3}’}(H’, C, W’)$ 将张量转置，得到$X^{d_1d_2}(H’, W’, C)$ 在$C$维度上 将$X^{d_1d_2}(H’, W’, C)$展开为$X_{flatten}(N_C×C)$，其中$N_C=H’×W’$ 降维得到$X’_{flatten}(N_C×C’)$ 重新将另外两维恢复，得到$X^{d_1d_2d_3}(H’, W’, C’)$ 详细查看GitHub，其核心代码如下 12345678910111213141516171819202122232425262728def transform(self, X): """ Params: X: &#123;ndarray(n_samples, d0, d1, d2, ..., dn-1)&#125; n-dim array Returns: X: &#123;ndarray(n_samples, d0, d1, d2, ..., dn-1)&#125; n-dim array """ assert self.n_dims == len(X.shape) - 1, 'please check input dimension! ' idx = [i for i in range(len(X.shape))] # index of dimensions for i_dim in range(self.n_dims): ## transpose tensor idx[-1], idx[i_dim + 1] = idx[i_dim + 1], idx[-1] X = X.transpose(idx) shape = list(X.shape) # 1-dim pca X = X.reshape((-1, shape[-1])) X = self.decomposers[i_dim].transform(X) ## transpose tensor X = X.reshape(shape[:-1]+[X.shape[-1]]) X = X.transpose(idx) idx[-1], idx[i_dim + 1] = idx[i_dim + 1], idx[-1] return X 实验显示将2维数据降维，指定通道维度数目从$3$降至$1$，得到实验结果如下 原始数据 降维后数据 重建数据 Reference 特征脸 - 维基百科，自由的百科全书]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python字符串格式化]]></title>
    <url>%2F2019%2F02%2F19%2FPython%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%A0%BC%E5%BC%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言Python操作字符串行云流水，当然也支持格式化字符串。 通过格式符1print("我叫%s, 今年%d岁" % ('Louis Hsu', 18)) 或者使用字典进行值传递1print("我叫%(name), 今年%(age)岁" % &#123;'name': 'Louis Hsu', 'age': 18&#125;) typecode| 格式符 | 含义 || ——— | ——— || %s | 字符串 (采用str()的显示) || %r | 字符串 (采用repr()的显示) || %c | 单个字符 || %b | 二进制整数 || %d | 十进制整数 || %i | 十进制整数 || %o | 八进制整数 || %x | 十六进制整数 || %e | 指数 (基底写为e) || %E | 指数 (基底写为E) || %f | 浮点数 || %F | 浮点数，与上相同 || %g | 指数(e)或浮点数 (根据显示长度) || %G | 指数(E)或浮点数 (根据显示长度) || %% | 字符”%” | 高阶12345% [flags] [width].[precision] typecode- flags: '+'(右对齐), '-'(左对齐), ' '(左侧填充一个空格，与负数对齐), '0'(用0填充)- width: 显示宽度- precision: 小数精度位数，可使用'*'进行动态代入- typecode: 格式符 例如12345678910print('pi is %+2.2f' % (3.1415926)) -&gt; pi is +3.14print('pi is %-2.2f' % (3.1415926)) -&gt; pi is 3.14print('pi is % 2.2f' % (3.1415926)) -&gt; pi is 3.14print('pi is %02.2f' % (3.1415926)) -&gt; pi is 3.14# 同print('pi is %+*.*f' % (2, 2, 3.1415926))print('pi is %-*.*f' % (2, 2, 3.1415926))print('pi is % *.*f' % (2, 2, 3.1415926))print('pi is %0*.*f' % (2, 2, 3.1415926)) 通过format位置传递 使用位置参数 123456789&gt;&gt;&gt; li = ['hoho',18]&gt;&gt;&gt; 'my name is &#123;&#125; ,age &#123;&#125;'.format('hoho',18)'my name is hoho ,age 18'&gt;&gt;&gt; 'my name is &#123;1&#125; ,age &#123;0&#125;'.format(10,'hoho')'my name is hoho ,age 10'&gt;&gt;&gt; 'my name is &#123;1&#125; ,age &#123;0&#125; &#123;1&#125;'.format(10,'hoho')'my name is hoho ,age 10 hoho'&gt;&gt;&gt; 'my name is &#123;&#125; ,age &#123;&#125;'.format(*li)'my name is hoho ,age 18' 使用关键字参数 12345&gt;&gt;&gt; hash = &#123;'name':'hoho','age':18&#125;&gt;&gt;&gt; 'my name is &#123;name&#125;,age is &#123;age&#125;'.format(name='hoho',age=19)'my name is hoho,age is 19'&gt;&gt;&gt; 'my name is &#123;name&#125;,age is &#123;age&#125;'.format(**hash)'my name is hoho,age is 18' 格式限定基本格式如下12345&#123;[:pad][align][sign][typecode]&#125;- :pad : 填充字符，空白位用该字符填充- align: '^', '&lt;', '&gt;' 分别表示 '居中', '左对齐', '右对齐'(默认)，后面加宽度- sign : '+', '-' , ' ' 分别表示 '正', '负', '正数前加空格'- typecode: 'b', 'd', 'o', 'x', 'f', ',', '%', 'e' 分别表示 '二进制', '十进制', '八进制', '十六进制', '浮点数', '逗号分隔', '百分比格式', '指数记法' Reference python之字符串格式化(format) - benric - 博客园 https://www.cnblogs.com/benric/p/4965224.htmlPython format 格式化函数 | 菜鸟教程 http://www.runoob.com/python/att-string-format.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python命令行参数解析]]></title>
    <url>%2F2019%2F02%2F18%2FPython%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言C/C++的参数传递我们知道C/C++主函数形式如下12345int main(int argc,char * argv[],char * envp[])&#123; // do something return 0;&#125; 其中各参数含义如下 argc：argument count，表示参数数量 argv：argument value，表示参数值 最后一个元素存放了一个NULL的指针 envp：系统环境变量 最后一个元素存放了一个NULL的指针 例如12345678910111213141516171819#include&lt;stdio.h&gt;int main(int argc,char * argv[],char * envp[])&#123; printf("argc is %d \n", argc); int i; for (i=0; i&lt;argc; i++) &#123; printf("arcv[%d] is %s\n", i, argv[i]); &#125; for (i=0; envp[i]!=NULL; i++) &#123; printf("envp[%d] is %s\n", i, envp[i]); &#125; return 0;&#125; 测试平台为Windows10，执行编译和运行操作，结果如下:12345678910111213&gt; gcc main.c -o main.exe&gt; ./main.exe param1 param2 param3 param4argc is 5arcv[0] is C:\OneDrive\▒ĵ▒\Louis' Blog\source\_drafts\Python▒▒▒▒▒в▒▒▒▒▒▒▒\test.exearcv[1] is param1arcv[2] is param2arcv[3] is param3arcv[4] is param4envp[0] is ACLOCAL_PATH=C:\MyApplications\Git\mingw64\share\aclocal;C:\MyApplica tions\Git\usr\share\aclocalenvp[1] is ALLUSERSPROFILE=C:\ProgramData...(省略)envp[71] is WINDIR=C:\WINDOWSenvp[72] is _=./main.exe Python的参数传递可以使用sys模块得到命令行参数，主函数文件main.py如下1234import sysif __name__ == '__main__': print(sys.argv) 执行12&gt; python main.py param1 param2 pram3['main.py', 'param1', 'param2', 'pram3'] getopt1234567891011121314151617181920212223242526272829303132333435363738394041import sysimport getoptimport argparseif __name__ == '__main__': argv = sys.argv if len(argv) == 1: print( """ Usage: python main.py [option] -h or --help: 显示帮助信息 -v or --version: 显示版本 -i or --input: 指定输入文件路径 -o or --output: 指定输出文件路径 """ ) try: opts, args = getopt.getopt(args=argv[1:], shortopts='hvi:o:', longopts=['help', 'version', 'input=', 'output='] ) except getopt.GetoptError: print("argv error,please input") sys.exit(1) for cmd, arg in opts: if cmd in ['-h', '--help']: print("help info") sys.exit(0) elif cmd in ['-v', '--version']: print("main 1.0") sys.exit(0) if cmd in ['-i', '--input']: input = arg if cmd in ['-o', '--output']: output = arg 说明 args=sys.argv[1:] 传入的参数，除去sys.argv[0]，即主函数文件路径 shortopts=&#39;hvi:o:&#39; 字符串，支持形如-h的选项 若无需指定参数，形如c； 若必须指定参数，则需为c:； longopts=[&#39;help&#39;, &#39;version&#39;, &#39;input=&#39;, &#39;output=&#39;] 字符串列表，可选参数，是否支持形如--help的选项 若无需指定参数，形如cmd； 若必须指定参数，则需为cmd=； 执行12345678910111213141516171819&gt; python main.py Usage: python main.py [option] -h or --help: 显示帮助信息 -v or --version: 显示版本 -i or --input: 指定输入文件路径 -o or --output: 指定输出文件路径&gt; python main.py -hhelp info&gt; python main.py -vmain 1.0&gt; python main.py -iargv error,please input&gt; python main.py -i a.txt -o b.txt argsparse12345678910111213141516171819202122232425262728import argparsedef show_args(args): if args.opencv: print("opencv is used ") else: print("opencv is not used ") print(args.steps) print(args.file) print(args.data) if __name__ == '__main__': parser = argparse.ArgumentParser(description="learn to use `argparse`") # 标志位 parser.add_argument('--opencv', '-cv', action='store_true', help='use opencv if set ') # 必需参数 parser.add_argument('--steps', '-s', required=True, type=int, help='number of steps') # 默认参数 parser.add_argument('--file', '-f', default='a.txt') # 候选参数 parser.add_argument('--data', '-d', choices=['data1', 'data2']) args = parser.parse_args() show_args(args) 说明 帮助信息 参数help，用于显示在-h帮助信息中 标志位参数 参数action=&#39;store_true&#39;，即保存该参数为True 必需参数 置位required，即运行该程序必须带上该参数，否则报错 默认参数 参数default填写默认参数 候选参数 参数choices填写候选参数列表 运行1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 显示帮助信息&gt; python main.py -husage: main.py [-h] [--opencv] --steps STEPS [--file FILE] [--data &#123;data1,data2&#125;]learn to use `argparse`optional arguments: -h, --help show this help message and exit --opencv, -cv use opencv if set --steps STEPS, -s STEPS number of steps --file FILE, -f FILE --data &#123;data1,data2&#125;, -d &#123;data1,data2&#125;# 测试必须参数&gt; python main.pyusage: main.py [-h] [--opencv] --steps STEPS [--file FILE] [--data &#123;data1,data2&#125;]main.py: error: the following arguments are required: --steps/-s&gt; python main.py -s 100opencv is not used100a.txtNone# 测试标志位参数&gt; python main.py -s 100 -cvopencv is used100a.txtNone# 测试默认参数&gt; python main.py -s 100 -f b.txtopencv is not used100b.txtNone# 测试可选参数&gt; python main.py -s 100 -d data1opencv is not used100a.txtdata1&gt; python main.py -s 100 -d data0usage: main.py [-h] [--opencv] --steps STEPS [--file FILE] [--data &#123;data1,data2&#125;]main.py: error: argument --data/-d: invalid choice: 'data0' (choose from 'data1', 'data2') Reference Python命令行参数解析：getopt和argparse - 死胖子的博客 - CSDN博客 https://blog.csdn.net/lanzheng_1113/article/details/77574446Python模块之命令行参数解析 - 每天进步一点点！！！ - 博客园 https://www.cnblogs.com/madsnotes/articles/5687079.htmlPython解析命令行读取参数 — argparse模块 - Arkenstone - 博客园 https://www.cnblogs.com/arkenstone/p/6250782.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python生成词云图]]></title>
    <url>%2F2019%2F02%2F17%2FPython%E7%94%9F%E6%88%90%E8%AF%8D%E4%BA%91%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[前言一个没什么用的小技能 模块 wordcloud · PyPI https://pypi.org/project/wordcloud/ 安装该模块1&gt; pip install wordcloud 主要用到的为12345678wordcloud.WordCloud(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color='black', max_font_size=None, font_step=1, mode="RGB", relative_scaling='auto', regexp=None, collocations=True, colormap=None, normalize_plurals=True, contour_width=0, contour_color='black', repeat=False) 使用例程123456789101112131415161718192021222324import osimport cv2import numpy as npfrom wordcloud import WordCloudfont = 'C:/Windows/Fonts/SIMYOU.TTF' # 幼圆string = 'LouisHsu 单键 小叔叔 想静静 95后 傲娇 skrrrrrrr 大猫座 佛了 要秃 嘤嘤嘤 真香'mask = cv2.imread('./mask.jpg', cv2.IMREAD_GRAYSCALE)thresh, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)wc = WordCloud( font_path=font, background_color='white', color_func=lambda *args, **kwargs: (0,0,0), mask=mask, max_words=500, min_font_size=4, max_font_size=None, contour_width=1, repeat=True # 允许词重复 )wc.generate_from_text(string)wc.to_file('./wc.jpg') #保存图片 输入原图为 生成图像 Reference python WordCloud 简单实例 - 博客 - CSDN博客 https://blog.csdn.net/cy776719526/article/details/80171790]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Makefile简单教程]]></title>
    <url>%2F2019%2F01%2F05%2Fmakefile%E7%AE%80%E5%8D%95%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言准备源文件新建目录demo/，其结构如下123456789\-- demo \-- bin # 二进制文件，即可执行文件 \-- include # 头文件`.h` |-- hello.h \-- obj # 目标文件`.o` |-- *.o \-- src # 源文件`.c` |-- hello.c |-- test.c 编辑hello.h12345678#ifndef __HELLO_H#define __HELLO_H#include &lt;stdio.h&gt;void __hello();#endif 编辑hello.c123456#include "hello.h"void __hello()&#123; printf("Hello world!\n");&#125; 编辑test.h1234567#include "hello.h"int main()&#123; __hello(); return 0;&#125; 命令行编译1234567$ lshello.c hello.h makefile README.md test.c$ gcc test.c hello.c -o test$ lshello.c hello.h makefile README.md test test.c$ ./testHello world! 但是这样编译会每次都重新编译整个工程，时间比较长，所以可以先生成.o文件，当test.c代码改动后，重新生成test.o即可，hello.o不用重新编译12345678910$ lshello.c hello.h makefile README.md test.c$ gcc test.c hello.c -c$ lshello.c hello.h hello.o makefile README.md test.c test.o$ gcc test.o hello.o -o test$ lshello.c hello.h hello.o makefile README.md test test.c test.o$ ./testHello world! Makefile格式12&lt;target&gt;: &lt;dependencies&gt; &lt;command&gt; # [TAB]&lt;command&gt; 例如12test: test.c gcc test.c -o test 编辑Makefile12345678910111213141516171819202122232425262728# directories &amp; target nameDIR_INC = ./include DIR_SRC = ./srcDIR_OBJ = ./objDIR_BIN = ./binTARGET = test# compile macro CC = gccCFLAGS = -g -Wall -I$&#123;DIR_INC&#125; # `-g`表示调试选项，`-Wall`表示编译后显示所有警告# load source filesSRC = $(wildcard $&#123;DIR_SRC&#125;/*.c) # 匹配目录中所有的`.c`文件# build targetOBJ = $(patsubst %.c, $&#123;DIR_OBJ&#125;/%.o, $&#123;notdir $&#123;SRC&#125;&#125;) # 由`SRC`字符串内容，指定生成`.o`文件的名称与目录BIN = $&#123;DIR_BIN&#125;/$&#123;TARGET&#125; # 指定可执行文件名称与目录# build$&#123;BIN&#125;: $&#123;OBJ&#125; $(CC) $(OBJ) -o $@ # 即 `$ gcc ./obj/*.o -o ./bin/test`$&#123;DIR_OBJ&#125;/%.o: $&#123;DIR_SRC&#125;/%.c $(CC) $(CFLAGS) -c $&lt; -o $@ # 即 `$ gcc ./src/*.c -g -Wall -I./include -c ./obj/*.o`# clean.PHONY: clean # 伪目标clean: find $&#123;DIR_OBJ&#125; -name *.o -exec rm -rf &#123;&#125; \; 执行123456789101112131415$ makegcc -g -Wall -I./include -c src/hello.c -o obj/hello.ogcc -g -Wall -I./include -c src/test.c -o obj/test.ogcc ./obj/hello.o ./obj/test.o -o bin/test$ ls obj/hello.o test.o$ ls bin/test$ ./bin/test Hello world!$ make cleanfind ./obj -name *.o -exec rm -rf &#123;&#125; \;$ ls obj/$ ls bin/test 解释 符号 $@, $^, $&lt;，$? $@: 表示目标文件 $^: 表示所有的依赖文件 $&lt;: 表示第一个依赖文件 $?: 表示比目标还要新的依赖文件列表 wildcard，notdir，patsubst wildcard : 扩展通配符 SOURCES = $(wildcard *.c): 产生一个所有以 ’.c’ 结尾的文件的列表，然后存入变量 SOURCES 里。 notdir : 去除路径，可以在使用wildcard函数后，再配合使用notdir函数只得到文件名（不含路径）。 patsubst : 替换通配符，需要３个参数，第一个是个需要匹配的式样，第二个表示用什么来替换他，第三个是个需要被处理的由空格分隔的字列。 OBJS = $(patsubst %.c,%.o,$(SOURCES)) - 将处理所有在 SOURCES 字列中的字（一列文件名），如果他的 结尾是 `.c` ，就用 `.o` 把 `.c`取代 - 这里的 % 符号将匹配一个或多个字符，而他每次所匹配的字串叫做一个‘柄’(stem) - 在第二个参数里， %被解读成用第一参数所匹配的那个柄。 -I，-L，-l -I: 将指定目录作为第一个寻找头文件的目录 -L: 将指定目录作为第一个寻找库文件的目录 -l: 在库文件路径中寻找.so动态库文件（如果gcc编译选项中加入了-static表示寻找.a静态库文件） .PHONY后面的target表示的也是一个伪造的target, 而不是真实存在的文件target，注意Makefile的target默认是文件。 关于三个函数的使用123456789101112DIR_INC = ./includeDIR_SRC = ./srcDIR_OBJ = ./objSRC = $(wildcard $&#123;DIR_SRC&#125;/*.c) # 指定编译当前目录下所有`.c`文件，全路径`./src/*.c`DIR = $(notdir $&#123;SRC&#125;) # 去除路径名，只留下文件名`*.c`OBJ = $(patsubst %.c, $&#123;DIR_OBJ&#125;/%.o, $&#123;DIR&#125;) # 将`DIR`中匹配到的`%.c`，替换为`$&#123;DIR_OBJ&#125;/%.o`ALL: @echo $(SRC) @echo $(DIR) @echo $(OBJ) 执行1234$ make./src/hello.c ./src/test.chello.c test.c./obj/hello.o ./obj/test.o 注：若./src目录下还有子目录./src/inc，则12&gt; SRC = $(wildcard $&#123;DIR_SRC&#125;/*.c) $(wildcard $&#123;DIR_SRC&#125;/inc/*.c)&gt; Reference Makefile 使用总结 - wang_yb - 博客园 https://www.cnblogs.com/wang_yb/p/3990952.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CMake编译库文件]]></title>
    <url>%2F2019%2F01%2F05%2FCmake%E7%BC%96%E8%AF%91%E5%BA%93%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言库文件即源代码的二进制文件，我们通常把一些公用函数制作成函数库，供其它程序使用。函数库分为静态库和动态库两种。静态库在程序编译时会被连接到目标代码中，程序运行时将不再需要该静态库；动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此在程序运行时还需要动态库存在。 编译以DarkNet为例，我们将其源代码编译成.a静态库文件。 下载源码 YOLO: Real-Time Object Detection https://pjreddie.com/darknet/yolo/ 1$ git clone https://github.com/pjreddie/darknet 整理文件 我们将include/与src/目录复制到新建文件夹darknet/。目录结构如下 123456789101112darknet├── include│ └── darknet.h└── src ├── activation_kernels.cu ├── activation_layer.c ├── activation_layer.h ├── ... ├── utils.c ├── utils.h ├── yolo_layer.c └── yolo_layer.h 在darknet/目录下编写CmakeLists.txt文件，内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445CMAKE_MINIMUM_REQUIRED(VERSION 2.8) # cmake需要的最小版本号PROJECT(darknet) # 项目名MESSAGE(STATUS "----------------------------------------------------------------------")MESSAGE(STATUS "project name: " $&#123;PROJECT_NAME&#125; # cmake默认参数)MESSAGE(STATUS "source directory: " $&#123;PROJECT_SOURCE_DIR&#125; # cmake默认参数)MESSAGE(STATUS "binary directory: " $&#123;PROJECT_BINARY_DIR&#125; # cmake默认参数)MESSAGE(STATUS "----------------------------------------------------------------------")# ----------------------------------------------------------------------------------INCLUDE_DIRECTORIES( # 头文件目录 $&#123;PROJECT_SOURCE_DIR&#125;/include $&#123;PROJECT_SOURCE_DIR&#125;/src) AUX_SOURCE_DIRECTORY( # 源文件 $&#123;PROJECT_SOURCE_DIR&#125;/src lib_srcfile) SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_BINARY_DIR&#125;/lib) # 设置保存`.a`的目录# ----------------------------------------------------------------------------------ADD_LIBRARY( # 生成库文件，可选择`.a`或`.so` $&#123;PROJECT_NAME&#125; STATIC # `.a` # SHARED # `.so` $&#123;lib_srcfile&#125;) # ----------------------------------------------------------------------------------SET_TARGET_PROPERTIES( $&#123;PROJECT_NAME&#125; PROPERTIES LINKER_LANGUAGE C) 执行命令 我们在darknet/目录打开终端 123456789101112131415161718192021$ mkdir build$ cd build/build$ cmake ..-- The C compiler identification is GNU 7.4.0-- The CXX compiler identification is GNU 7.4.0 ...-- Configuring done-- Generating done-- Build files have been written to: /home/louishsu/Work/Codes/MTCNN_Darknet/darknet/build$ makeScanning dependencies of target darknet[ 2%] Building C object CMakeFiles/darknet.dir/src/activation_layer.c.o ...[ 97%] Building C object CMakeFiles/darknet.dir/src/yolo_layer.c.o[100%] Linking C shared library lib/libdarknet.so[100%] Built target darknet 在darknet/build/lib目录下即可找到libdarknet.a库文件，build目录结构如下123build└── lib └── libdarknet.so (*) 调用库函数为测试该库函数是否编译成功，编写测试代码，新建目录/test/，其文件结构为12345678test├── include│ └── test.h├── src│ └── test.c├── build│ └── test└── CMakeLists.txt 头文件/include/test.h内容为123456#ifndef TEST_H#define TEST_H#include "darknet.h"#endif 源文件/src/test.c内容如下123456789#include "test.h"int main()&#123; printf("Hello! Darknet!\n"); matrix M = make_matrix(4, 5); printf("The size of matrix M is %ld bytes\n", sizeof(M)); return 0;&#125; 编译文件CMakeLists.txt内容如下1234567891011121314151617181920212223242526CMAKE_MINIMUM_REQUIRED(VERSION 2.8) # cmake需要的最小版本号PROJECT(Test) # 项目名ADD_DEFINITIONS(-DOPENCV=1)# ----------------------------------------------------------------------------------SET(DARKNET ../darknet)INCLUDE_DIRECTORIES( # 头文件目录 $&#123;DARKNET&#125;/include $&#123;DARKNET&#125;/src) LINK_DIRECTORIES( # 库文件目录 $&#123;DARKNET&#125;/build/lib) # ----------------------------------------------------------------------------------INCLUDE_DIRECTORIES(./include) # 当前项目头文件目录AUX_SOURCE_DIRECTORY(./src SRC_FILES) # 当前项目源文件目录# ----------------------------------------------------------------------------------ADD_EXECUTABLE($&#123;PROJECT_NAME&#125; $&#123;SRC_FILES&#125;) # 添加可执行文件TARGET_LINK_LIBRARIES( # 引用库 $&#123;PROJECT_NAME&#125; darknet # darknet m # 数学函数库) 执行指令12345678910111213141516$ mkdir build$ cd build$ cmake ..-- The C compiler identification is GNU 5.4.0-- The CXX compiler identification is GNU 5.4.0...-- Configuring done-- Generating done-- Build files have been written to: /home/louishsu/Work/Codes/makefile/test/build$ makeScanning dependencies of target Test[ 50%] Building C object CMakeFiles/Test.dir/src/test.c.o[100%] Linking C executable Test[100%] Built target Test 运行可执行文件123$ ./TestHello! Darknet!The size of matrix M is 16 bytes 查看结构体matrix定义1234typedef struct matrix&#123; int rows, cols; float **vals;&#125; matrix; int占32bit，float*占64bit，故1(32bit * 2 + 64bit) / 8 = 16byte 运行成功。 Reference 静态库和动态库的优缺点 - 默默淡然 - 博客园 https://www.cnblogs.com/liangxiaofeng/p/3228145.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu编译安装Tensorflow]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Tensorflow%2F</url>
    <content type="text"><![CDATA[非常重要如果中途出现错误，xxxx文件找不到，不要怀疑！就是大天朝的网络问题！推荐科学上网！ 安装CUDA与CUDNN首先查看显卡是否支持CUDA加速，输入1$ nvidia-smi 在Ubuntu16.04 LTS下，推荐安装CUDA9.0和CUDNN 7。 CUDA CUDA Toolkit 9.0 Downloads | NVIDIA Developer https://developer.nvidia.com/cuda-90-download-archive 下载.run版本，安装方法如下 12$ sudo chmod +x cuda_9.0.176_384.81_linux.run $ sudo sh ./cuda_9.0.176_384.81_linux.run 服务条款很长。。。。 CUDNN NVIDIA cuDNN | NVIDIA Developer https://developer.nvidia.com/cudnn 1234$ tar -xzvf cudnn-9.0-linux-x64-v7.4.1.5.tgz$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 安装后进行验证 1234$ cp -r /usr/src/cudnn_samples_v7/ $HOME$ cd $HOME/cudnn_samples_v7/mnistCUDNN$ make clean &amp;&amp; make$ ./mnistCUDNN 编译Tensorflow(CPU version)由于训练代码使用Python实现，故C++版本的Tensorflow不使用GPU，仅实现预测代码即可。 bazel Installing Bazel on Ubuntu - Bazel https://docs.bazel.build/versions/master/install-ubuntu.html一定要用源码安装！！！ download the Bazel binary installer named bazel-&lt;version&gt;-installer-linux-x86_64.sh from the Bazel releases page on GitHub. 123456$ sudo apt-get install pkg-config zip g++ zlib1g-dev unzip python$ chmod +x bazel-&lt;version&gt;-installer-linux-x86_64.sh$ ./bazel-&lt;version&gt;-installer-linux-x86_64.sh --user$ sudo nano ~/.bashrc # export PATH="$PATH:$HOME/bin"$ source ~/.bashrc $ bazel version 编译CPU版本的CPU查看java版本1234$ java -versionopenjdk version "1.8.0_191"OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12)OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) 安装依赖软件包环境1234$ sudo apt install python3-dev$ pip3 install six$ pip3 install numpy$ pip3 instal wheel 下载Tensorflow源码1$ git clone https://github.com/tensorflow/tensorflow 编译与安装12$ cd tensorflow$ ./configure 配置选项如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command "bazel shutdown".INFO: Invocation ID: ce26fc12-2926-4ca7-8775-febc553c8ab5You have bazel 0.20.0 installed.Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3Found possible Python library paths: /usr/local/lib/python3.5/dist-packages /usr/lib/python3/dist-packagesPlease input the desired Python library path to use. Default is [/usr/local/lib/python3.5/dist-packages]Do you wish to build TensorFlow with XLA JIT support? [Y/n]: nNo XLA JIT support will be enabled for TensorFlow.Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: nNo OpenCL SYCL support will be enabled for TensorFlow.Do you wish to build TensorFlow with ROCm support? [y/N]: nNo ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y/N]: nNo CUDA support will be enabled for TensorFlow.Do you wish to download a fresh release of clang? (Experimental) [y/N]: nClang will not be downloaded.Do you wish to build TensorFlow with MPI support? [y/N]: nNo MPI support will be enabled for TensorFlow.Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native -Wno-sign-compare]: Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: nNot configuring the WORKSPACE for Android builds.Preconfigured Bazel build configs. You can use any of the below by adding "--config=&lt;&gt;" to your build command. See .bazelrc for more details. --config=mkl # Build with MKL support. --config=monolithic # Config for mostly static monolithic build. --config=gdr # Build with GDR support. --config=verbs # Build with libverbs support. --config=ngraph # Build with Intel nGraph support. --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects.Preconfigured Bazel build configs to DISABLE default on features: --config=noaws # Disable AWS S3 filesystem support. --config=nogcp # Disable GCP support. --config=nohdfs # Disable HDFS support. --config=noignite # Disable Apacha Ignite support. --config=nokafka # Disable Apache Kafka support. --config=nonccl # Disable NVIDIA NCCL support.Configuration finished 使用bazel编译1$ bazel build --config=opt //tensorflow:libtensorflow_cc.so 出现错误 TF failing to build on Bazel CI · Issue #19464 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/19464Failure to build TF 1.12 from source - multiple definitions in grpc · Issue #23402 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/23402#issuecomment-436932197Explicitly import tools/bazel.rc by meteorcloudy · Pull Request #23583 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583Explicitly import tools/bazel.rc by meteorcloudy · Pull Request #23583 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583/commits/03e63a291bc95dacaa821585f39a360b43465cb5 解决方法 方法1 方法2 将tools/bazel.rc中内容粘到.tf_configure.bazelrc中，每次重新配置后需要重新粘贴一次。 源码安装protobuf3.6.0 https://github.com/protocolbuffers/protobuf 1234./autogen.sh./configuremakemake install 下载其他文件 12$ ./tensorflow/contrib/makefile/download_dependencies.shmkdir /tmp/eigen 值得注意，download_dependencies.sh中下载依赖包时，需要用到curl，但是默认方式安装 1$ sudo apt install curl &gt; 现在是2018/12/19/02:48，被这个问题折腾了3个小时。 时不支持`https`协议，故需要安装`OpenSSL`，并源码安装，详细资料见[curl提示不支持https协议解决方法 - 标配的小号 - 博客园](https://www.cnblogs.com/biaopei/p/8669810.html) - 执行`./autogen.sh`时，发生错误`autoreconf: not found`，则安装 12$ sudo apt install autoconf aotomake libtool$ sudo apt install libffi-dev 源码安装Eigen 12345cd tensorflow/contrib/makefile/Downloads/eigenmkdir buildcd buildcmakemake install 调用C++版本的Tensorflow创建文件目录如下1234|-- tf_test |-- build |-- main.cpp |-- CMakeLists.txt main.cpp文件内容如下1234567891011121314151617181920212223#include "tensorflow/cc/client/client_session.h"#include "tensorflow/cc/ops/standard_ops.h"#include "tensorflow/core/framework/tensor.h"int main() &#123; using namespace tensorflow; using namespace tensorflow::ops; Scope root = Scope::NewRootScope(); // Matrix A = [3 2; -1 0] auto A = Const(root, &#123; &#123;3.f, 2.f&#125;, &#123;-1.f, 0.f&#125;&#125;); // Vector b = [3 5] auto b = Const(root, &#123; &#123;3.f, 5.f&#125;&#125;); // v = Ab^T auto v = MatMul(root.WithOpName("v"), A, b, MatMul::TransposeB(true)); std::vector&lt;Tensor&gt; outputs; ClientSession session(root); // Run and fetch v TF_CHECK_OK(session.Run(&#123;v&#125;, &amp;outputs)); // Expect outputs[0] == [19; -3] LOG(INFO) &lt;&lt; outputs[0].matrix&lt;float&gt;(); return 0;&#125; CMakeLists.txt内容如下12345678910111213141516171819202122232425262728293031cmake_minimum_required (VERSION 2.8.8)project (tf_example)set(CMAKE_CXX_FLAGS "$&#123;CMAKE_CXX_FLAGS&#125; -g -std=c++11 -W")set(EIGEN_DIR /usr/local/include/eigen3)set(PROTOBUF_DIR /usr/local/include/google/protobuf)set(TENSORFLOW_DIR /home/louishsu/install/tensorflow-1.12.0)include_directories( $&#123;EIGEN_DIR&#125; $&#123;PROTOBUF_DIR&#125; $&#123;TENSORFLOW_DIR&#125; $&#123;TENSORFLOW_DIR&#125;/bazel-genfiles $&#123;TENSORFLOW_DIR&#125;/tensorflow/contrib/makefile/downloads/absl)link_directories( /usr/local/lib)add_executable( tf_test main.cpp)target_link_libraries( tf_test tensorflow_cc tensorflow_framework) 123$ mkdir build &amp;&amp; cd build$ cmake .. &amp;&amp; make$ ./tf_test install tensorflow-gpu for python可使用pip指令安装，推荐下载安装包， tensorflow · PyPI https://pypi.org/project/tensorflow/ 12$ cd ~/Downloads$ pip3 --default-timeout=1000 install tensorflow_gpu-1.12.0-cp35-cp35m-manylinux1_x86_64.whl --user 安装后进行验证123456789101112131415161718192021222324252627$ python3Python 3.5.2 (default, Nov 12 2018, 13:43:14) [GCC 5.4.0 20160609] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.Session()2018-12-12 11:58:17.817417: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2018-12-12 11:58:17.953931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2018-12-12 11:58:17.954686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: GeForce GT 730M major: 3 minor: 5 memoryClockRate(GHz): 0.758pciBusID: 0000:04:00.0totalMemory: 983.44MiB freeMemory: 177.19MiB2018-12-12 11:58:17.954728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 02018-12-12 11:58:18.276013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:2018-12-12 11:58:18.276057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2018-12-12 11:58:18.276069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2018-12-12 11:58:18.276223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory) -&gt; physical GPU (device: 0, name: GeForce GT 730M, pci bus id: 0000:04:00.0, compute capability: 3.5)&gt;&gt;&gt; a = tf.Variable([233])&gt;&gt;&gt; init = tf.initialize_all_variables()WARNING:tensorflow:From /home/louishsu/.local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.Instructions for updating:Use `tf.global_variables_initializer` instead.&gt;&gt;&gt; sess.run(init)&gt;&gt;&gt; sess.run(a)array([233], dtype=int32)&gt;&gt;&gt; sess.close() 注意，如果异常中断程序，显存不会被释放，需要自行kill1$ nvidia-smi 获得PID序号，使用指令结束进程1$ kill -9 pid Reference TensorFlow C++动态库编译 - 简书 https://www.jianshu.com/p/d46596558640Tensorflow C++ 从训练到部署(1)：环境搭建 | 技术刘 http://www.liuxiao.org/2018/08/ubuntu-tensorflow-c-%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E9%A2%84%E6%B5%8B1%EF%BC%9A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/]]></content>
      <categories>
        <category>Linux</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu编译安装OpenCV]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85OpenCV%2F</url>
    <content type="text"><![CDATA[下载源码 OpenCV library https://opencv.org/ 编译安装依赖软件包12$ sudo apt install cmake$ sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff4.dev libswscale-dev libjasper-dev 编译12345$ unzip opencv-3.4.4.zip$ cd opencv-3.4.4$ mkdir build &amp;&amp; cd build$ cmake ..$ make -j4 安装123$ sudo make install$ sudo nano /etc/ld.so.conf.d/opencv.conf # add `/usr/local/lib`$ sudo ldconfig 验证OpenCV自带验证程序，在opencv-3.4.4/samples/cpp/example_cmake中可以找到 1234$ cd opencv-3.4.4/samples/cpp/example_cmake$ cmake .$ make$ ./opencv_example 如果没问题，可以看到你的大脸了~ Reference Ubuntu16.04安装openCV3.4.4 - 辣屁小心的学习笔记 - CSDN博客 https://blog.csdn.net/weixin_39992397/article/details/84345197]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python读写配置文件]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AF%BB%E5%86%99%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在深度学习中，有许多运行参数需要指定，有几种方法可以解决 定义.py文件存储变量 定义命名元组collections.namedtuple() 创建.config，.ini等配置文件 Python 读取写入配置文件很方便，使用内置模块configparser即可 读出首先创建文件test.config或test.ini，写入如下内容123456789[db]db_port = 3306db_user = rootdb_host = 127.0.0.1db_pass = test[concurrent]processor = 20thread = 10 读取操作如下1234567891011121314151617181920212223242526272829&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; configfile = "./test.config"&gt;&gt;&gt; inifile = "./test.ini"&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.read(configfile) # 读取文件内容&gt;&gt;&gt; &gt;&gt;&gt; sections = cf.sections() # 所有的section，以列表的形式返回&gt;&gt;&gt; sections['db', 'concurrent']&gt;&gt;&gt; &gt;&gt;&gt; options = cf.options('db') # 该section的所有option&gt;&gt;&gt; options['db_port', 'db_user', 'db_host', 'db_pass']&gt;&gt;&gt; &gt;&gt;&gt; items = cf.items('db') # 该section的所有键值对&gt;&gt;&gt; items[('db_port', '3306'), ('db_user', 'root'), ('db_host', '127.0.0.1'), ('db_pass', 'test')]&gt;&gt;&gt; &gt;&gt;&gt; db_user = cf.get('db', 'db_user') # section中option的值，返回为string类型&gt;&gt;&gt; db_user'root'&gt;&gt;&gt; &gt;&gt;&gt; db_port = cf.getint('db', 'db_port') # 得到section中option的值，返回为int类型&gt;&gt;&gt; # 类似的还有getboolean()与getfloat()&gt;&gt;&gt; db_port3306 写入12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.add_section('test1') # 新增section&gt;&gt;&gt; &gt;&gt;&gt; cf.set("test", "count", 1) # 新增option：错误示范Traceback (most recent call last): File "&lt;pyshell#7&gt;", line 1, in &lt;module&gt; cf.set("test", "count", 1) File "C:\MyApplications\Python3\lib\configparser.py", line 1192, in set self._validate_value_types(option=option, value=value) File "C:\MyApplications\Python3\lib\configparser.py", line 1177, in _validate_value_types raise TypeError("option values must be strings")TypeError: option values must be strings&gt;&gt;&gt; &gt;&gt;&gt; cf.set("test", "count", '1') # 新增option&gt;&gt;&gt; &gt;&gt;&gt; cf.set("test1", "opt1", 'ok') # 新增option&gt;&gt;&gt; cf.remove_option("test1", "opt1") # 删除optionTrue&gt;&gt;&gt; &gt;&gt;&gt; cf.add_section('test2') # 新增section&gt;&gt;&gt; cf.remove_section('test2') # 删除sectionTrue&gt;&gt;&gt; &gt;&gt;&gt; with open("./test_wr.config", 'w+') as f: cf.write(f) # 写入文件test_wr.config &gt;&gt;&gt; 现在目录已创建文件test_wr.config，打开可以看到12[test1]count = 1]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python更新安装的包]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E6%9B%B4%E6%96%B0%E5%AE%89%E8%A3%85%E7%9A%84%E5%8C%85%2F</url>
    <content type="text"><![CDATA[pip不提供升级全部已安装模块的方法，以下指令可查看更新信息1$ pip list --outdate 得到输出信息如下123456789101112131415161718192021222324Package Version Latest Type----------------- --------- ---------- -----absl-py 0.3.0 0.6.1 sdistautopep8 1.3.5 1.4.2 sdistbleach 2.1.4 3.0.2 wheelcertifi 2018.8.24 2018.10.15 wheeldask 0.20.0 0.20.1 wheelgrpcio 1.14.1 1.16.0 wheelipykernel 5.0.0 5.1.0 wheelipython 7.0.1 7.1.1 wheeljedi 0.12.1 0.13.1 wheeljupyter-console 5.2.0 6.0.0 wheelMarkdown 2.6.11 3.0.1 wheelMarkupSafe 1.0 1.1.0 wheelmatplotlib 2.2.2 3.0.2 wheelmistune 0.8.3 0.8.4 wheelnumpy 1.14.5 1.15.4 wheelopencv-python 3.4.2.17 3.4.3.18 wheelPillow 5.2.0 5.3.0 wheelprometheus-client 0.3.1 0.4.2 sdistpyparsing 2.2.0 2.3.0 wheelpython-dateutil 2.7.3 2.7.5 wheelpytz 2018.5 2018.7 wheelurllib3 1.23 1.24.1 wheel 以下提供一键升级的方法，可能比较久hhhh12345678from pip._internal.utils.misc import get_installed_distributionsfrom subprocess import call for dist in get_installed_distributions(): modulename = dist.project_name print('start processing module ' + modulename) call("pip install --upgrade " + modulename, shell=True) print('module ' + modulename + 'done!')]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python记录日志]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[前言日志可以用来记录应用程序的状态、错误和信息消息，也经常作为调试程序的工具。Python提供了一个标准的日志接口，就是logging模块。日志级别有DEBUG、INFO、WARNING、ERROR、CRITICAL五种。 logging — Logging facility for Python — Python 3.7.1 documentation 使用方法logger对象1234&gt;&gt;&gt; import logging&gt;&gt;&gt; logger = logging.getLogger(__name__)&gt;&gt;&gt; logger&lt;Logger __main__ (WARNING)&gt; 日志级别可输出五种不同的日志级别，分别为有DEBUG、INFO、WARNING、ERROR、CRITICAL12345678&gt;&gt;&gt; logger.debug('test log')&gt;&gt;&gt; logger.info('test log')&gt;&gt;&gt; logger.warning('test log')test log&gt;&gt;&gt; logger.error('test log')test log&gt;&gt;&gt; logger.critical('test log')test log 可以看到只有WARNING及以上级别日志被输出，这是由于默认的日志级别是WARNING ，所以低于此级别的日志不会记录。 基础配置1logging.basicConfig(**kwarg) **kwarg中部分参数如下 format 12345678910%(levelname)：日志级别的名字格式%(levelno)s：日志级别的数字表示%(name)s：日志名字%(funcName)s：函数名字%(asctime)：日志时间，可以使用datefmt去定义时间格式，如上图。%(pathname)：脚本的绝对路径%(filename)：脚本的名字%(module)：模块的名字%(thread)：thread id%(threadName)：线程的名字 datefmt 1'%Y-%m-%d %H:%M:%S' level 默认为ERROR 12345logging.DEBUGlogging.INFOlogging.WARNINGlogging.ERRORlogging.CRITICAL 例如12345678910111213141516&gt;&gt;&gt; # 未输出debug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug('test log')&gt;&gt;&gt; &gt;&gt;&gt; # 修改配置&gt;&gt;&gt; log_format = '%(filename)s [%(asctime)s] [%(levelname)s] %(message)s'&gt;&gt;&gt; log_datefmt = '%Y-%m-%d %H:%M:%S'&gt;&gt;&gt; log_level = logging.DEBUG&gt;&gt;&gt; logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level)&gt;&gt;&gt; &gt;&gt;&gt; # 输出debug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug('test log')&lt;pyshell#8&gt; [2018-11-13 11:59:52] [DEBUG] test log 输出到日志文件保存代码为文件log_test.py1234567891011121314151617181920import logginglog_format = '%(filename)s [%(asctime)s] [%(levelname)s] %(message)s'log_datefmt = '%Y-%m-%d %H:%M:%S'log_level = logging.DEBUGlog_filename = './test.log'log_filemode = 'a' # 也可以为'w', 'w+'等logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level, filename=log_filename, filemode=log_filemode)logger = logging.getLogger(__name__)logger.debug('test log')logger.info('test log')logger.warning('test log')logger.error('test log')logger.critical('test log') 运行完毕，打开log_test.log文件可以看到12345log_test.py [2018-11-13 12:11:04] [DEBUG] test loglog_test.py [2018-11-13 12:11:04] [INFO] test loglog_test.py [2018-11-13 12:11:04] [WARNING] test loglog_test.py [2018-11-13 12:11:04] [ERROR] test loglog_test.py [2018-11-13 12:11:04] [CRITICAL] test log]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github博客搭建]]></title>
    <url>%2F2019%2F01%2F04%2FGithub-Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前言那么问题来了，现有的博客还是现有的这篇文章呢？ 软件安装安装node.js, git, hexo 博客搭建初始化推荐使用git命令窗口，执行如下指令12345678910111213141516171819202122232425262728293031$ mkdir Blog$ cd Blog$ hexo initINFO Cloning hexo-starter to ~\Desktop\BlogCloning into 'C:\Users\LouisHsu\Desktop\Blog'...remote: Enumerating objects: 68, done.remote: Total 68 (delta 0), reused 0 (delta 0), pack-reused 68Unpacking objects: 100% (68/68), done.Submodule 'themes/landscape' (https://github.com/hexojs/hexo-theme-landscape.git) registered for path 'themes/landscape'Cloning into 'C:/Users/LouisHsu/Desktop/Blog/themes/landscape'...remote: Enumerating objects: 1, done.remote: Counting objects: 100% (1/1), done.remote: Total 867 (delta 0), reused 0 (delta 0), pack-reused 866Receiving objects: 100% (867/867), 2.55 MiB | 494.00 KiB/s, done.Resolving deltas: 100% (459/459), done.Submodule path 'themes/landscape': checked out '73a23c51f8487cfcd7c6deec96ccc7543960d350'[32mINFO [39m Install dependenciesnpm WARN deprecated titlecase@1.1.2: no longer maintainednpm WARN deprecated postinstall-build@5.0.3: postinstall-build's behavior is now built into npm! You should migrate off of postinstall-build and use the new `prepare` lifecycle script with npm 5.0.0 or greater.&gt; nunjucks@3.1.6 postinstall C:\Users\LouisHsu\Desktop\Blog\node_modules\nunjucks&gt; node postinstall-build.js srcnpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)added 422 packages from 501 contributors and audited 4700 packages in 59.195sfound 0 vulnerabilitiesINFO Start blogging with Hexo! 生成目录结构如下123456\-- scaffolds\-- source \-- _posts\-- themes|-- _config.yml|-- package.json 继续123456$ npm installnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)audited 4700 packages in 5.99sfound 0 vulnerabilities 现在该目录执行指令，开启hexo服务器123$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 生成目录和标签1234$ hexo n page about$ hexo n page archives$ hexo n page categories$ hexo n page tags 修改/source/tags/index.md，其他同理1234567891011121301| ---02| title: tags03| date: 2019-01-04 17:34:1504| ----&gt;01| ---02| title: tags03| date: 2019-01-04 17:34:1504| type: "tags"05| comments: false06| --- 关联Github在Github新建一个仓库，命名为username.github.io，例如isLouisHsu.github.io，新建时勾选Initialize this repository with a README，因为这个仓库必须不能为空。 打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下1234deploy: type: git repository: git@github.com:isLouisHsu/isLouisHsu.github.io.git branch: master 安装插件1$ npm install hexo-deployer-git --save 现在就可以将该目录内容推送到Github新建的仓库中了1$ hexo d 使用个人域名 在source目录下新建文件CNAME，输入解析后的个人域名 在Github主页修改域名 备份博客 没。没什么用我。我不备份了可以新建一个仓库专门保存文件试试 现在博客的源文件仅保存在PC上， 我们对它们进行备份，并将仓库作为博客文件夹 在仓库新建分支hexo，设置为默认分支 将仓库克隆至本地 1$ git clone https://github.com/isLouisHsu/isLouisHsu.github.io.git 克隆文件 将之前的Hexo文件夹中的 123456scffolds/source/themes/.gitignore_config.ymlpackage.json 复制到克隆下来的仓库文件夹isLouisHsu.github.io 安装包 123$ npm install$ npm install hexo --save$ npm install hexo-deployer-git --save 备份博客使用以下指令 123$ git add .$ git commit -m "backup"$ git push origin hexo 部署博客指令 1$ hexo g -d 单键提交 编写脚本commit.bat，双击即可 1234git add .git commit -m 'backup'git push origin hexohexo g -d 使用方法 目录结构 public 生成的网站文件，发布的站点文件。 source 资源文件夹，用于存放内容。 tag 标签文件夹。 archive 归档文件夹。 category分类文件夹。 downloads/code include code文件夹。 :lang i18n_dir 国际化文件夹。 _config.yml 配置文件 指令 123456789101112131415161718192021222324252627$ hexo helpUsage: hexo &lt;command&gt;Commands: clean Remove generated files and cache. config Get or set configurations. deploy Deploy your website. generate Generate static files. help Get help on a command. init Create a new Hexo folder. list List the information of the site migrate Migrate your site from other system to Hexo. new Create a new post. publish Moves a draft post from _drafts to _posts folder. render Render files with renderer plugins. server Start the server. version Display version information.Global Options: --config Specify config file instead of using _config.yml --cwd Specify the CWD --debug Display all verbose messages in the terminal --draft Display draft posts --safe Disable all plugins and scripts --silent Hide output on consoleFor more help, you can use 'hexo help [command]' for the detailed information or you can check the docs: http://hexo.io/docs/ 拓展功能支持插入图片1$ npm install hexo-asset-image --save 修改文件_config.yml1post_asset_folder: true 在执行$ hexo n [layout] &lt;title&gt;时会生成同名文件夹，把图片放在这个文件夹内，在.md文件中插入图片1![image_name](/title/image_name.png) 搜索功能12$ npm install hexo-generator-searchdb --save$ npm install hexo-generator-search --save 站点配置文件_config.yml中添加12345search: path: search.xml field: post format: html limit: 10000 修改主题配置文件/themes/xxx/_config.yml12local_search: enable: true 带过滤功能的首页插件在首页只显示指定分类下面的文章列表。12$ npm install hexo-generator-index2 --save$ npm uninstall hexo-generator-index --save 修改_config.yml1234567index_generator: per_page: 10 order_by: -date include: - category Web # 只包含Web分类下的文章 exclude: - tag Hexo # 不包含标签为Hexo的文章 数学公式支持hexo默认的渲染引擎是marked，但是marked不支持mathjax。kramed是在marked的基础上进行修改。1234$ npm uninstall hexo-math --save # 停止使用 hexo-math$ npm install hexo-renderer-mathjax --save # 安装hexo-renderer-mathjax包：$ npm uninstall hexo-renderer-marked --save # 卸载原来的渲染引擎$ npm install hexo-renderer-kramed --save # 安装新的渲染引擎 修改/node_modules/kramed/lib/rules/inline.js12345678911| escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,...20| em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,-&gt;11| escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,...20| em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 修改/node_modules/hexo-renderer-kramed/lib/renderer.js123456789101112131464| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed's rule: $$ + \1 + $$67| return text.replace(/`\$(.*?)\$`/g, '$$$$$1$$$$');68| &#125;-&gt;64| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed's rule: $$ + \1 + $$67| // return text.replace(/`\$(.*?)\$`/g, '$$$$$1$$$$');68| return text;69| &#125; 在主题中开启mathjax开关，例如next主题中1234# MathJax Supportmathjax: enable: true per_page: true 在文章中12345678---title: title.mddate: 2019-01-04 12:47:37categories:tags:mathjax: truetop:--- 测试 A = \left[\begin{matrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{matrix}\right]Reference 基于hexo+github搭建一个独立博客 - 牧云云 - 博客园 https://www.cnblogs.com/MuYunyun/p/5927491.htmlhexo+github pages轻松搭博客(1) | ex2tron’s Blog http://ex2tron.wang/hexo-blog-with-github-pages-1/hexo下LaTeX无法显示的解决方案 - crazy_scott的博客 - CSDN博客 https://blog.csdn.net/crazy_scott/article/details/79293576在Hexo中渲染MathJax数学公式 - 简书 https://www.jianshu.com/p/7ab21c7f0674怎么去备份你的Hexo博客 - 简书 https://www.jianshu.com/p/baab04284923Hexo中添加本地图片 - 蜕变C - 博客园 https://www.cnblogs.com/codehome/p/8428738.html?utm_source=debugrun&amp;utm_medium=referralhexo 搜索功能 - 阿甘的博客 - CSDN博客 https://blog.csdn.net/ganzhilin520/article/details/79047983]]></content>
      <categories>
        <category>Others</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[scikit-learn: 处理特征]]></title>
    <url>%2F2018%2F11%2F24%2Fscikit-learn-%E5%A4%84%E7%90%86%E7%89%B9%E5%BE%81%2F</url>
    <content type="text"><![CDATA[数据预处理(preprocessing)Module12345678910111213&gt;&gt;&gt; import sklearn.preprocessing as preprocessing&gt;&gt;&gt; dir(preprocessing)['Binarizer', 'CategoricalEncoder', 'FunctionTransformer', 'Imputer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MaxAbsScaler', 'MinMaxScaler', 'MultiLabelBinarizer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PolynomialFeatures', 'PowerTransformer', 'QuantileTransformer', 'RobustScaler', 'StandardScaler', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_discretization', '_encoders', '_function_transformer', 'add_dummy_feature', 'base', 'binarize', 'data', 'imputation', 'label', 'label_binarize', 'maxabs_scale', 'minmax_scale', 'normalize', 'power_transform', 'quantile_transform', 'robust_scale', 'scale'] 特征抽取(feature extraction)Module1234567&gt;&gt;&gt; import sklearn.feature_extraction as feature_extraction&gt;&gt;&gt; dir(feature_extraction)['DictVectorizer', 'FeatureHasher', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_hashing', 'dict_vectorizer', 'grid_to_graph', 'hashing', 'image', 'img_to_graph', 'stop_words', 'text'] 特征选择(feature selection)当数据预处理完成后，我们需要选择有意义的特征，将其输入到模型中训练，主要从两个方面考虑 特征是否发散 若一个特征不发散，其方差接近$0$，则表示该特征在各个样本上没有差别，对于样本的区分没什么用； 特征与目标的相关性 与目标(target)相关性高的特征，应当优先选择。 特征选择的方法可以根据特征选择的形式分为$3$种 过滤法(Filter) 按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。 包装法(Wrapper) 根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。 嵌入法(Embedded) 先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。 Filter移除低方差 Removing features with low variance 即移除那些方差较小的特征，当特征的取值都是离散型变量的时候这种方法才能用，如果是连续型变量，就需要将连续变量离散化之后才能用。 现实中这种方法作用不大，可以把它作为特征选择的预处理，先去掉那些取值变化小的特征，然后再从接下来提到的的特征选择方法中选择合适的进行进一步的特征选择。 1# class sklearn.feature_selection.VarianceThreshold(threshold=0.0) 调用例程如下12345678910111213141516&gt;&gt;&gt; X = [ [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], ]&gt;&gt;&gt; feature_selection.VarianceThreshold(threshold=(.8 * (1 - .8))).fit_transform(X) array([[0, 1], [1, 0], [0, 0], [1, 1], [1, 0], [1, 1]])&gt;&gt;&gt; # 选出了第2, 3列特征 单变量特征选择 Univariate feature selection 分别单独的计算每个变量的某个统计指标，根据该指标来判断哪些指标重要，剔除那些不重要的指标。 指标适用情况： 对于分类问题(target离散) 卡方检验，f_classif, mutual_info_classif，互信息 对于回归问题(target连续) 注：分类与回归在一定程度上可以互相转换， WrapperEmbeddedModule12345678910&gt;&gt;&gt; import sklearn.feature_selection as feature_selection&gt;&gt;&gt; dir(feature_selection)['GenericUnivariateSelect', 'RFE', 'RFECV', 'SelectFdr', 'SelectFpr', 'SelectFromModel', 'SelectFwe', 'SelectKBest', 'SelectPercentile', 'VarianceThreshold', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'chi2', 'f_classif', 'f_oneway', 'f_regression', 'from_model', 'mutual_info_', 'mutual_info_classif', 'mutual_info_regression', 'rfe', 'univariate_selection', 'variance_threshold'] 参考博客(reference) 使用sklearn优雅地进行数据挖掘 - jasonfreak - 博客园 http://www.cnblogs.com/jasonfreak/p/5448462.html特征选择 (feature_selection) - 会飞的蝸牛 - 博客园 https://www.cnblogs.com/stevenlk/p/6543628.html]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Metrics]]></title>
    <url>%2F2018%2F11%2F21%2FMetrics%2F</url>
    <content type="text"><![CDATA[回归(regression)评估指标解释方差(Explained Variance) EV(\hat{y}, y) = 1 - \frac{Var(y-\hat{y})}{Var(y)}解释方差越接近$1$表示回归效果越好。 平均绝对误差(Mean Absolute Error - MAE) MAE(\hat{y}, y) = E(||\hat{y} - y||_1) = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} |\hat{y}^{(i)} - y^{(i)}|$MAE$越小表示回归效果越好。 平均平方误差(Mean Squared Error - MSE)在线性回归一节，使用的损失函数即$MSE$ MSE(\hat{y}, y) = E(||\hat{y} - y||_2^2) = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} (\hat{y}^{(i)} - y^{(i)})^2其中$y$与$\hat{y}$均为$1$维向量，$MSE$越小表示回归效果越好。 其含义比较直观，即偏差的平方和。也可以从最小化方差的角度解释，定义误差向量 e = \hat{y} - y我们假定其期望为$0$，即 E(e) = 0 或 \overline{e} = 0那么误差的方差为 Var(e) = E[(e - \overline{e})^T (e - \overline{e})] = E(||e||_2^2)也即$MSE$。 均方根误差(Root Mean Squared Error - RMSE) RMSE(\hat{y}, y) = \sqrt{\frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} (\hat{y}^{(i)} - y^{(i)})^2}实质与$MSE$是一样的。只不过用于数据更好的描述，使计算得损失的值较小。$RMSE$越小表示回归效果越好。 均方对数误差(Mean Squard Logarithmic Error - MSLE) MSLE(\hat{y}, y) = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} \left[\log (1+y^{(i)}) - \log (1+\hat{y}^{(i)})\right]^2通常用于输出指数增长的模型，如，人口统计，商品的平均销售量，以及一段时间内的平均销售量等。注意，由对数性质，这一指标对过小的预测的惩罚大于预测过大的预测的惩罚。 中值绝对误差(Median Absolute Error - MedAE) MedAE(\hat{y}, y) = median(|y - \hat{y}|)R决定系数(R2)又称拟合优度，提供了一个衡量未来样本有多好的预测模型。最佳可能的分数是$1.0$，它可以是负的(因为模型可以任意恶化)。一个常数模型总是预测$y$的期望值，而不考虑输入特性，则得到$R^2$分数为$0.0$。 R^2(\hat{y}, y) = 1 - \frac{\sum_{i=1}^{n_{samples}} (y^{(i)} - \hat{y}^{(i)})^2}{\sum_{i=1}^{n_{samples}} (y^{(i)} - \overline{y})^2}其中 \overline{y} = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} y^{(i)}分类(classification)评估指标先作如下定义 准确率(Accuracy) Accuracy(y, \hat{y}) = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} 1(y^{(i)}=\hat{y}^{(i)})也即 Accuracy = \frac{TN+TP}{TN+TP+FN+FP}精度只是简单地计算出比例，但是没有对不同类别进行区分。因为不同类别错误代价可能不同。例如：判断这个病人是不是病危，如果不是病危错误判断为病危，那只是损失一点医务人员的时间和精力，如果是把病危的人判断为非病危状态，那损失的就是一条人命。他们之间存在重要性差异，这时候就不能用精度。对于样本不均衡的情况，也不是用精度来衡量。例如：有A类1000个，B类5个，如果我把这1005个样本都预测成A类，正确率=1000/1005=99.5%。 精确率(Precision)与召回率(Recall) 精确率(Precision) 即预测正样本中，实际为正样本的百分比，度量了分类器不会将真正的负样本错误地分为正样本的能力。 Precision = \frac{TP}{TP+FP} 召回率(Recall) 又称查全率，即实际正样本中，被预测为正样本的百分比，度量了分类器找到所有正样本的能力。 Recall = \frac{TP}{TP + FN} F度量 F1 score - Wikipedia $F_1$ 为精确率(Precision)与召回率(Recall)的调和均值(harmonic mean)。 \frac{1}{F_1} = \frac{1}{2} (\frac{1}{Precision} + \frac{1}{Recall}) 也即 F_1 = 2 · \frac{Precision·Recall}{Precision + Recall} $F_{\beta}$ 在$F_1$度量的基础上增加权值$\beta$，$\beta$越大，$Recall$的权重越大，否则$Precision$的权重越大。 \frac{1}{F_{\beta}} = \frac{1}{1+\beta^2} \frac{1}{Precision} + \frac{\beta^2}{1+\beta^2}\frac{1}{Recall} 也即 F_{\beta} = (1+\beta^2)·\frac{Precision·Recall}{(\beta^2·Precision) + Recall} 混淆矩阵Confusion matrix，也被称作错误矩阵(Error matrix)，是一个特别的表。无监督学习中，通常称作匹配矩阵(Matching matrix)。每一列表达了分类器对样本的类别预测，每一行表达了样本所属的真实类别。 例如我们有$27$个待分类样本，将其划分为Cat，Dog，Rabbit，讲实际标签与预测标签数目统计后填入混淆矩阵。 例如实际上有$8$个样本为Cat，而该分类器将其中$3$个划分为Dog，将$2$个为Dog的样本划分为Cat。我们可以根据上述混淆矩阵得出结论，该分类器对Dog和Cat分类能力较弱，而对Rabbit分类能力较强。而且正确预测的样本数目都在对角线上，很容易直观地检查表中的预测错误。 以下为scikit-learn中混淆矩阵的API1234567891011121314151617181920&gt;&gt;&gt; from sklearn.metrics import confusion_matrix&gt;&gt;&gt; &gt;&gt;&gt; y_true = [2, 0, 2, 2, 0, 1]&gt;&gt;&gt; y_pred = [0, 0, 2, 2, 0, 2]&gt;&gt;&gt; confusion_matrix(y_true, y_pred)array([[2, 0, 0], [0, 0, 1], [1, 0, 2]])&gt;&gt;&gt; &gt;&gt;&gt; y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]&gt;&gt;&gt; y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]&gt;&gt;&gt; confusion_matrix(y_true, y_pred, labels=["ant", "bird", "cat"])array([[2, 0, 0], [0, 0, 1], [1, 0, 2]])&gt;&gt;&gt; &gt;&gt;&gt; # In the binary case, we can extract true positives, etc as follows:&gt;&gt;&gt; tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()&gt;&gt;&gt; (tn, fp, fn, tp)(0, 2, 1, 1) ROC曲线Receiver Operating Characteristic，是根据一系列不同的二分类方式(分界值或决定阈)，以召回率(真正率TPR、灵敏度)为纵坐标，fall-out(假正率FPR、$1$-特异度)为横坐标绘制的曲线。 true positive rate - TPR 所有阳性样本中有多少正确的阳性结果。 TPR = \frac{TP}{P} = \frac{TP}{TP + FN} false positive rate - FPR 所有阴性样本中有多少不正确的阳性结果。 FPR = \frac{FP}{N} = \frac{FP}{FP + TN} ROC space 分别以FPR与TPR作为横纵轴(又称灵敏度-$1$特异度曲线sensitivity vs (1 − specificity) plot)； 每次预测结果或混淆矩阵的实例代表了ROC空间中的一个点； 例如上图中$A, B, C, C’$是以下表数据计算得到的点。 在ROC空间中最左上方的点$(0, 1)$称作完美分类器(perfect classification)； 随机分类器的结果分布在ROC space对角线$(0, 0)-(1, 1)$上，当实验次数足够多，其分区趋向$(0.5, 0.5)$; 对角线以上的点代表好的分类结果(比随机的好)；线下的点代表坏的结果(比随机的差)； 注意，持续不良分类器的输出可以简单地反转以获得一个好的分类器，反转后的分类器与原分类器在平面上关于对角线对称，例如点$C’$。 ROC曲线的绘制若训练集样本中，正样本与负样本以正态分布的形式分布在样本平面上，如下图，左峰为负样本，右峰为正样本，存在部分重叠(不然就不用搞这么多分类算法了)。 若假设正样本概率密度为$f_1(x)$，负样本的概率密度为$f_0(x)$，给定阈值$T$，则右 TPR(T) = \int_T^{\infty} f_1(x) dx FPR(T) = \int_T^{\infty} f_0(x) dx选取不同的阈值划分分类器输出，就能得到ROC曲线。 在基于有限样本作ROC图时，可以看到曲线每次都是一个“爬坡”，遇到正例往上爬一格$(1/m+)$，错了往右爬一格$(1/m-)$，显然往上爬对于算法性能来说是最好的。 Area Under the Curve - AUCROC曲线下的面积AUC物理意义为，任取一对正负样本，正样本的预测值大于负样本的预测值的概率。 A = \int_{-\infty}^{\infty} TPR(T) dFPR(T) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} I(T'> T) f_1(T') f_0(T) dT' dT = P(X_1 > X_0)同样的，在有限个样本下，其面积用累加的方法计算(梯形面积) AUC = \sum_{i=1}^{m-1} \frac{1}{2} (y_{i+1} + y_i)(x_{i+1} - x_i) $AUC = 1$，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。 $0.5 &lt; AUC &lt; 1$，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。 $AUC = 0.5$，跟随机猜测一样（例：丢铜板），模型没有预测价值。 $AUC &lt; 0.5$，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。 sklearn以下为scikit-learn中混淆矩阵的ROC曲线API。12345678910111213141516&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from sklearn import metrics&gt;&gt;&gt; &gt;&gt;&gt; y = np.array([1, 1, 2, 2])&gt;&gt;&gt; scores = np.array([0.1, 0.4, 0.35, 0.8])&gt;&gt;&gt; &gt;&gt;&gt; fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)&gt;&gt;&gt; fprarray([ 0. , 0.5, 0.5, 1. ])&gt;&gt;&gt; tprarray([ 0.5, 0.5, 1. , 1. ])&gt;&gt;&gt; thresholdsarray([ 0.8 , 0.4 , 0.35, 0.1 ])&gt;&gt;&gt; &gt;&gt;&gt; metrics.auc(fpr, tpr)0.75 聚类(clustering)评估指标 AI（005） - 笔记 - 聚类性能评估（Clustering Evaluation） - DarkRabbit的专栏 - CSDN博客 Wikipedia, the free encyclopedia 说明聚类性能比较好，就是聚类结果簇内相似度(intra-cluster similarity)高，而簇间相似度(inter-cluster similarity)低，即同一簇的样本尽可能的相似，不同簇的样本尽可能不同。 聚类性能的评估（度量）分为两大类： 外部评估(external evaluation)：将结果与某个参考模型(reference model)进行比较； 内部评估(internal evaluation)：直接考虑聚类结果而不利用任何参考模型。 将$n_{samples}$个样本$\{x^{(1)}, …, x^{(n_{samples})}\}$用待评估聚类算法划分为$K$个类$\{X_1, …, X_K\}$，假定参考模型将其划分为$L$类$\{Y_1, …, Y_L\}$，将样本两辆匹配 \begin{cases} a = |SS| & SS = \{(x^{(i)}, x^{(j)}) | x^{(i)}, x^{(j)} \in X_k; x^{(i)}, x^{(j)} \in Y_l\} \\ b = |SD| & SD = \{(x^{(i)}, x^{(j)}) | x^{(i)}, x^{(j)} \in X_k; x^{(i)} \in Y_{l1}, x^{(j)} \in Y_{l2}\} \\ c = |DS| & DS = \{(x^{(i)}, x^{(j)}) | x^{(i)} \in X_{k1}, x^{(j)} \in X_{k2}; x^{(i)}, x^{(j)} \in Y_l\} \\ d = |DD| & DD = \{(x^{(i)}, x^{(j)}) | x^{(i)} \in X_{k1}, x^{(j)} \in X_{k2}; x^{(i)} \in Y_{l1}, x^{(j)} \in Y_{l2}\} \end{cases}其中$k = 1, …, K; l = 1, …, L$ a + b + c + d = \left( \begin{matrix} n \\ 2 \end{matrix} \right) = \frac{n(n-1)}{2} $SS$包含两种划分中均属于同一类的样本对； $SD$包含用待评估聚类算法划分中属于同一类，而在参考模型中属于不同类的样本对； $DS$包含用待评估聚类算法划分中属于不同类，而在参考模型中属于同一类的样本对； $DD$包含两种划分中均不属于同一类的样本对。 常用外部评估(external evaluation)Rand Index(RI) Rand index - Wikipedia RI = \frac{a+d}{a + b + c + d} = \frac{a+d}{\left(\begin{matrix} n \\ 2 \end{matrix}\right)}显然，结果值在$[0,1]$之间，且值越大越好。 当为$0$时，两个聚类无重叠； 当为$1$时，两个聚类完全重叠。 Adjust Rand Index(ARI)让$RI$有了修正机会(corrected-for-chance)，在取值上从$[0,1]$变成$[-1, 1]$ 对于$X$与$Y$的重叠可以用一个列联表(contingency table)表示，记作$[n_{ij}]$，$n_{ij} = |X_i \bigcap Y_j|$ 则定义$ARI$如下 互信息与调整互信息(Adjusted Mutual Information - AMI) 关于互信息可查看熵一节说明。 $X_i$类别的概率定义为 P(k) = \frac{|X_k|}{N}则划分结果的熵定义为 H(X) = - \sum_k P(k) \log P(k)类似的 P'(l) = \frac{|Y_l|}{N} H(Y) = - \sum_j P'(l) \log P'(l)另外 P(k, l) = \frac{|X_k, Y_l|}{N}那么两种划分的互信息定义为 MI(X, Y) = \sum_{k, l} P(k, l) \log \frac{P(k, l)}{P(k) P'(l)}和$ARI$一样，我们对它进行调整。 E[MI(X, Y)] = \sum_k \sum_l \sum_{n_{kl} = \max\{1, a_k + b_l - N\}}^{\min \{a_k, b_l\}} \frac{n_{kl}}{N} \log \left( \frac{N·n_{kl}}{a_k b_l} \right) × \frac {a_k!b_l!(N-a_k)!(N-b_l)!} {N!n_{kl}!(a_k-n_{kl})!(b_l-n_{kl})!(N-a_k-b_l+n_{kl})!}最终$AMI$表达式为 AMI(X, Y) = \frac{MI(X, Y) - E[MI(X, Y)]}{\max \{H(X), H(Y)\} - E[MI(X, Y)]}同质性(Homogeneity)与完整性(Completeness)这两个类似分类种的的准确率(accuracy)与召回率(recall)。 同质性(Homogeneity) 即一个簇仅包含一个类别的样本 H = 1 - \frac{H(X|Y)}{H(X)} 其中$H(X|Y)$为条件熵 H(X|Y) = \sum_k \sum_l P(X_k, Y_l) \log \frac{P(Y_l)}{P(X_k, Y_l)} = \sum_k \sum_l \frac{n_{kl}}{N} \log \frac{n_{kl}}{N} 完整性(Completeness) 同类别样本被归类到相同簇中 C = 1 - \frac{H(Y|X)}{H(Y)} $V-measure$ Homogeneity和Completeness的调和平均 V = \frac{1}{\frac{1}{2} \left(\frac{1}{H} + \frac{1}{C}\right)} = \frac{2HC}{H + C} Fowlkes-Mallows index(FMI)成对精度和召回率的几何均值 Fowlkes–Mallows index - Wikipedia 定义 $TP$ as the number of points that are present in the same cluster in both $A_1$ and $A_2$. $FP$ as the number of points that are present in the same cluster in $A_1$ but not in $A_2$. $FN$ as the number of points that are present in the same cluster in $A_2$ but not in $A_1$. $TN$ as the number of points that are in different clusters in both $A_1$ and $A_2$. 则 TP + FP + TN + FN = \frac{n(n-1)}{2}定义 FMI = \sqrt{\frac{TP}{TP + FP} · \frac{TP}{TP + FN}}杰卡德系数(Jaccard Coefficient - JC) Jaccard index - Wikipedia 给定两个具有$n$个元素的集合$A, B$，定义 $M_{11}$ represents the total number of attributes where $A$ and $B$ both have a value of $1$. $M_{01}$ represents the total number of attributes where the attribute of $A$ is $0$ and the attribute of $B$ is $1$. $M_{10}$ represents the total number of attributes where the attribute of $A$ is $1$ and the attribute of $B$ is $0$. $M_{00}$ represents the total number of attributes where $A$ and $B$ both have a value of $0$. 则有 M_{11} + M_{01} + M_{10} + M_{00} = n Jaccard相似度系数 J = \frac{M_{11}}{M_{01} + M_{10} + M_{11}} 也即$J=\frac{A \cap B}{A \cup B}$ Jaccard距离 D_J = 1 - J 常用内部评估(internal evaluation)轮廓系数(Silhouette coefficient)又称侧影法，适用于实际类别信息未知的情况，对其中一个样本点$x^{(i)}$，记 $a(i)$：到本簇其他样本点的距离的平均值 $b(i)$：该点到其他各个簇的样本点的平均距离的最小值 定义轮廓系数 S(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}或者 S(i) = \begin{cases} 1 - \frac{a(i)}{b(i)} & a(i) < b(i) \\ 0 & a(i) = b(i) \\ \frac{b(i)}{a(i)} - 1 & a(i) > b(i) \end{cases}其含义如下 当$a(i) \ll b(i)$时，无限接近于$1$，则意味着聚类合适； 当$a(i) \gg b(i)$时，无限接近于$-1$，则意味着把样本i聚类到相邻簇中更合适； 当$a(i)\approxeq b(i)$时，无限接近于$0$，则意味着样本在两个簇交集处。 一般再对各个点的轮廓系数求均值 \overline{S} = \frac{1}{n_{samples}} \sum_{i=1}^{n_{samples}} S(i) 当$\overline{S} &gt; 0.5$，表示聚类合适； 当$\overline{S} &lt; 0.2$，表示表明数据不存在聚类特征 Calinski-Harabaz(CH)也适用于实际类别信息未知的情况，以$K$分类为例 类内散度$W$ W(K) = \sum_k \sum_{C(j)=k} ||x_j - \overline{x_k}||^2 类间散度$B$ B(K) = \sum_k a_k ||\overline{x_k} - \overline{x}||^2 $CH$ CH(K) = \frac{B(K)(N-K)}{W(K)(K-1)} Davies-Bouldin Index(DBI)定义 $c_k$：簇$C_k$的中心点 $\sigma_k$：簇$C_k$中所有元素到$c_k$的距离的均值 $d(c_i, c_j)$：簇中心$c_i$与$c_j$之间的距离 则 DBI = \frac{1}{K} \sum_{i=1}^K \max_{j \neq i} \left( \frac{\sigma_i + \sigma_j}{d(c_i, c_j)} \right)$DBI$越小越好 Dunn index(DI)定义 $d(i,j)$：两类簇的距离，定义方法多样，例如两类簇中心的距离； $d’(k)$：簇$C_k$的类内距离，同样的，可定义多种，例如簇$C_k$中任意两点距离的最大值。 则 DI = \frac{\min_{1 \leq i < j \leq K} d(i, j)}{\max_{1 \leq k \leq K} d'(k)}sklearn中的评价指标 3.3. Model evaluation: quantifying the quality of predictions — scikit-learn 0.19.0 documentation - ApacheCN 1234567891011121314151617181920212223242526&gt;&gt;&gt; from sklearn import metrics&gt;&gt;&gt; dir(metrics)['SCORERS', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'auc', 'average_precision_score', 'balanced_accuracy_score', 'base', 'brier_score_loss', 'calinski_harabaz_score', 'check_scoring', 'classification', 'classification_report', 'cluster', 'cohen_kappa_score', 'completeness_score', 'confusion_matrix', 'consensus_score', 'coverage_error', 'davies_bouldin_score', 'euclidean_distances', 'explained_variance_score', 'f1_score', 'fbeta_score', 'fowlkes_mallows_score', 'get_scorer', 'hamming_loss', 'hinge_loss', 'homogeneity_completeness_v_measure', 'homogeneity_score', 'jaccard_similarity_score', 'label_ranking_average_precision_score', 'label_ranking_loss', 'log_loss', 'make_scorer', 'matthews_corrcoef', 'mean_absolute_error', 'mean_squared_error', 'mean_squared_log_error', 'median_absolute_error', 'mutual_info_score', 'normalized_mutual_info_score', 'pairwise', 'pairwise_distances', 'pairwise_distances_argmin', 'pairwise_distances_argmin_min', 'pairwise_distances_chunked', 'pairwise_fast', 'pairwise_kernels', 'precision_recall_curve', 'precision_recall_fscore_support', 'precision_score', 'r2_score', 'ranking', 'recall_score', 'regression', 'roc_auc_score', 'roc_curve', 'scorer', 'silhouette_samples', 'silhouette_score', 'v_measure_score', 'zero_one_loss']]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Entropy]]></title>
    <url>%2F2018%2F11%2F21%2FEntropy%2F</url>
    <content type="text"><![CDATA[信息量概率$p$是对确定性的度量，那么信息量就是对不确定性的度量，公式定义为 I(x) = - \log p(x) \tag{1}信息量也被称为随机变量$x$的自信息(self-information) 底数为$2$时，单位为bit，底数为$e$时，单位为nat 信息熵信息熵(information entropy)定义为 H(X) = - \sum_{x} p(x) \log p(x) \tag{2}可看作信息量的期望,在$0-1$分布的信息熵为 H(p) = - p \log p - (1 - p) \log (1 - p)图像如下，可见在$p=0.5$时，熵最大。 函数$y=x \log x$的图像有 \lim_{x \rightarrow 0} y = \lim_{x \rightarrow 1} y = 0 联合熵根据信息熵的定义，推广到多维随机变量，就得到联合熵的定义式，以$2$维随机变量为例 H(X, Y) = - \sum_{x, y} p(x, y) \log p(x, y) \tag{3}可推广至多维。 交叉熵现在有关于样本集的两个概率分布$p(x)$和$q(x)$，其中$p(x)$为真实分布，$q(x)$非真实分布。 如果用真实分布$p(x)$来衡量识别别一个样本所需要编码长度的期望（平均编码长度）为: H(p) = - \sum_x p(x) \log p(x)如果用非真实分布$q(x)$来衡量识别别一个样本所需要编码长度的期望（平均编码长度）为: H(p, q) = - \sum_x p(x) \log q(x) \tag{4}注意 H(p, q) - H(p) = \sum_x p(x) \log \frac{p(x)}{q(x)} = D_{KL}(p||q)当用非真实分布$q(x)$得到的平均码长比真实分布$p(x)$得到的平均码长多出的比特数就是相对熵。我们希望通过最小化相对熵$D_{KL}(p||q)$使$q(x)$尽量趋近$p(x)$，即 q(x) = \arg \min_{q(x)} D_{KL} (p||q)而$H(p)$是样本集的熵，为固定的值，故 q(x) = \arg \min_{q(x)} H(p, q)即等价于最小化交叉熵。 条件熵条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。定义为在给定$X$下$Y$的条件概率分布的熵对$X$的期望，即 H(Y|X) = E_{p(x)} H(Y|X=x) = \sum_x p(x) H(Y|X=x) \tag{5}其中 H(Y|X=x) = - \sum_y p(y|x) \log p(y|x)故 H(Y|X) = \sum_x p(x) \left[- \sum_y p(y|x) \log p(y|x)\right] = - \sum_x \sum_y p(x, y) \log p(y|x)即 H(Y|X) = - \sum_{x, y} p(x, y) \log p(y|x) \tag{6}实际上，条件熵满足 H(Y|X) = H(X, Y) - H(X) \tag{7} 证明：已知 H(X, Y) = - \sum_{x, y} p(x, y) \log p(x, y) H(X) = - \sum_{x} p(x) \log p(x)则 H(X, Y) - H(X) = - \sum_{x, y} p(x, y) \log p(x, y) + \sum_{x} p(x) \log p(x) = - \sum_{x, y} p(x, y) \log p(x, y) + \sum_{x, y} p(x, y) \log p(x) = \sum_{x, y} p(x, y) \log \frac{p(x)}{p(x, y)} = \sum_{x, y} p(x, y) \log p(y|x) = H(Y|X) 相对熵相对熵(relative entropy)，又称KL散度(Kullback–Leibler divergence)。可以用来衡量两个概率分布之间的差异，就是求$p(x)$与$q(x)$之间的对数差在 pp 上的期望值。 D_{KL} (p||q) = E_{p(x)} \log \frac{p(x)}{q(x)} = \sum_x p(x) \log \frac{p(x)}{q(x)} \tag{8}注意 相对熵不具有对称性，即 D_{KL} (p||q) \neq D_{KL} (q||p) $D_{KL} (p||q) \geq 0$ 证明： D_{KL} (p||q) = \sum_x p(x) \log \frac{p(x)}{q(x)} = - \sum_x p(x) \log \frac{q(x)}{p(x)}由Jensen inequality \sum_x p(x) \log \frac{q(x)}{p(x)} \leq \log \sum_x p(x) \frac{q(x)}{p(x)} = \log \sum_x q(x)所以 D_{KL} (p||q) \geq - \log \sum_x q(x)而$0 \leq q(x) \leq 1$，故 D_{KL} (p||q) \geq 0]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Deep Learing</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Non-parameter Estimation]]></title>
    <url>%2F2018%2F11%2F19%2FNon-parameter-Estimation%2F</url>
    <content type="text"><![CDATA[前言若参数估计时我们不知道样本的分布形式，那么就无法确定需要估计的概率密度函数，无法用最大似然估计、贝叶斯估计等参数估计方法，应该用非参数估计方法。 需要知道的是，作为非参数方法的共同问题是对样本数量需求较大，只要样本数目足够大众可以保证收敛于任何复杂的位置密度，但是计算量和存储量都比较大。当样本数很少时，如果能够对密度函数有先验认识，则参数估计能取得更好的估计效果。 基本原理若有$M$个样本$x^{(1)}, …, x^{(M)}$，依概率密度函数$p(x)$独立同分布抽样得到。 一个样本$x$落在区域$R$中的概率$P$可表示为 P = \int_R p(x) dx \tag{1}我们通过计算$P$来估计概率密度$p(x)$。 $K$个样本落入区域$R$的概率$P_K$为二项分布，即$K \sim B(M, P)$ P_K = \left(\begin{matrix} M\\K \end{matrix}\right) P^K (1-P)^{M-K} \tag{2}则$K$的期望与方差分别为 E(K) = MP; D(K) = MP(1-P)样本个数$M$越多，$D(K)$越大，即$K$在期望附近的波峰越明显，因此样本足够多时，用$K/M$作为$P$的一个估计非常准确，即 P \approx \frac{K}{M} \tag{3}若我们假设$p(x)$是连续的，且区域$R$足够小，记其体积为$V$，那么有 P = \int_R p(x)dx \approx p(x) V \tag{4}所以根据$(3)(4)$，得到 p(x) \approx \frac{K/M}{V} \tag{*}但是我们获得的其实为平滑后的概率密度函数 \frac{P}{V} = \frac{\int_R p(x)dx}{\int_R dx}我们希望其尽可能地趋近$p(x)$，那么必须要求$V \rightarrow 0$，但是这样就可能不包含任何样本，那么$p(x)\approx 0$，这样估计的结果毫无意义。 所以在实际中，一般构造多个包含样本$x$的区域$R_1, …, R_i, …, R_n$，第$i$个区域使用$i$个样本，记$V_i$为$R_i$的体积，$M_i$为落在$R_i$中的样本个数，则对$p(x)$第$i$次估计$p_i(x)$表示为 p_i(x) \approx \frac{M_i / M}{V_i} \tag{5}若要求$p_i(x)$收敛到$p(x)$，则必须满足 $\lim_{i\rightarrow \infty} V_i = 0$ $\lim_{i\rightarrow \infty} M_i = 0$ $\lim_{i\rightarrow \infty} \frac{M_i}{M} = 0$ 直方图法记不记得小学时的直方图统计，直方图方法的思想就是这样，以$1$维样本为例，我们将$x$的取值范围平均等分为$K$个区间，统计每个区间内样本的个数，由此计算区间的概率密度。 原理若共有$N$维样本$M$组，在每个维度上$K$等分，就有$K^N$个小空间，每个小空间的体积$V_i$可以定义为 V_i = \prod_{n=1}^N d_n, i=1,...,K^N其中 d_n = \frac{\max x_n - \min x_n}{K}假设样本落到各个小空间的概率相同，若第$i$个小空间包含$M_i$个样本，则该空间的概率密度$\hat{p_i}$为 \hat{p_i} = \frac{M_i / M}{V_i} \tag{6}估计的效果与小区间的大小密切相连，如果区域选择过大，会导致最终估计出来的概率密度函数非常粗糙；如果区域的选择过小，可能会导致有些区域内根本没有样本或者样本非常少，这样会导致估计出来的概率密度函数很不连续。 代码@Github: Non-parametric Estmation 我们可以用matplotlib.pyplot.hist()或numpy.histogram()实现 matplotlib 1n, bins, patches = plt.hist(arr, bins=10, normed=0, facecolor='black', edgecolor='black',alpha=1，histtype='bar') Args 参数很多，选几个常用的讲解 arr: 需要计算直方图的一维数组 bins: 直方图的柱数，可选项，默认为10 normed: 是否将得到的直方图向量归一化。默认为0 facecolor: 直方图颜色 edgecolor: 直方图边框颜色 alpha: 透明度 histtype: 直方图类型，‘bar’, ‘barstacked’, ‘step’, ‘stepfilled’ Returns n: 直方图向量，是否归一化由参数normed设定 bins: 返回各个bin的区间范围 patches: 返回每个bin里面包含的数据，是一个list numpy 1hist, bin_edges = histogram(a, bins=10, range=None, normed=None, weights=None, density=None) 12345678910def histEstimate(X, n_bins, showfig=False): """ 直方图密度估计 Args: n_bins: &#123;int&#125; 直方图的条数 Returns: hist: &#123;ndarray(n_bins,)&#125; """ n, bins, patches = plt.hist(X, bins=n_bins, normed=1, facecolor='lightblue', edgecolor='white') if showfig: plt.show() return n, bins, patches matplotlib直方图显示如下 拟合各中心点显示如下 $K_n$近邻估计法随着样本数的增加，区域的体积应该尽可能小，同时又必须保证区域内有充分多的样本，但是每个区域的样本数有必须是总样本数的很小的一部分，而不是与直方图估计那样体积不变。 那么我们想，能否根据样本的分布调整分区大小呢，$K$近邻估计法就是一种采用可变大小区间的密度估计方法。 原理根据总样本确定参数$K_n$，在求样本$x$处的密度估计$\hat{p}(x)$时，调整区域体积$V(x)$，直到区域内恰好落入$K_n$个样本，估计公式为 \hat{p}(x) = \frac{K_n/M}{V(x)} \tag{7}一般指定超参数$a$，取 K_n = a × \sqrt{M} \tag{8} \hat{p}(x) = \frac{a × \sqrt{M} /M}{V(x)} = \frac{K_n'/M}{V'(x)}其中$K_n’ = a,V’(x) = V(x)×\frac{1}{\sqrt{M}}$ 在样本密度比较高的区域的体积就会比较小，而在密度低的区域的体积则会自动增大，这样就能够较好的兼顾在高密度区域估计的分辨率和在低密度区域估计的连续性。 Parzen窗法又称核密度估计。 原理我们暂时假设待估计点$x$的附近区间$R$为一个$N$维的超立方体，用$h$表示边的长度，那么 V_i = h^N即定义窗函数$\varphi(·)$，表示落入以$x$为中心的超立方体的区域的点 \varphi \left(\frac{x_i-x}{h}\right) = \begin{cases} 1 & \frac{|x_{in}-x_n|}{h} \leq \frac{1}{2}, n=1,...,N \\ 0 & otherwise \end{cases} \tag{9} \frac{|x_{in}-x_n|}{h} \leq \frac{1}{2} 即 (x_i-x)_n \leq \frac{h}{2}这里的$h$起到单位化的作用，便于推广 那么落入以$x$为中心的超立方体的区域的点的个数为 M_i = \sum_{i=1}^M \varphi \left(\frac{x_i-x}{h}\right) \tag{10}代入$p(x) \approx \frac{M_i/M}{V_i}$，我们得到 p(x) \approx \frac{\sum_{i=1}^M \varphi \left(\frac{x_i-x}{h}\right)/M}{V_i} = \frac{1}{M} \sum_{i=1}^M \frac{1}{V_i} \varphi \left(\frac{x_i-x}{h}\right) \tag{11}我们定义核函数(或称“窗函数”) \kappa(z) = \frac{1}{V_i} \varphi(z) \tag{12}核函数反应了一个观测样本$x_i$对在$x$处的概率密度估计的贡献，与样本$x_i$和$x$的距离有关。而概率密度估计就是在这一点上把所有观测样本的贡献进行平均 p(x) \approx \frac{1}{M} \sum_{i=1}^M \kappa\left(\frac{x_i-x}{h}\right) \tag{13}核函数核函数应满足概率密度的要求，即 \kappa(z) \geq 0 \And \int \kappa(z)dz = 1通常有以下几种核函数 均匀核 \kappa(z) = \begin{cases} 1 & |z_n| \leq \frac{1}{2}, n=1,...,N \\ 0 & otherwise \end{cases} 高斯核(正态核) 高斯核是将窗放大到整个空间，各个观测样本$x_i$对待观测点$x$的加权和(越远权值越小)。 \kappa(z) = \frac{1}{(2\pi)^{N/2}|\Sigma|^{1/2}} \exp \left(-\frac{1}{2} (z - \mu)^T \Sigma^{-1} (z - \mu)\right) 超球窗 \kappa(z) = \begin{cases} V^{-1} & ||z|| \leq 1 \\ 0 & otherwise \end{cases} $z=\frac{x_i-x}{h}$，故$||z||\leq 1$即$||x_i-x||^2\leq h^2$此时$h$表示超球体的半径 sklearnsklearn.neighbors.KernelDensity — scikit-learn 0.19.0 documentation - ApacheCN123456789101112131415161718&gt;&gt;&gt; from sklearn.neighbors import KernelDensity&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])&gt;&gt;&gt; kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)&gt;&gt;&gt; kde.score_samples(X)array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698, -0.41076071])&gt;&gt;&gt; kde.sample(10)array([[ 1.80042291, 1.1030739 ], [ 0.87299669, 1.0762352 ], [-2.40180586, -1.19554374], [-1.97985919, -1.19361193], [-2.95866231, -2.1972637 ], [-1.12739556, -0.80851063], [ 1.03756706, 1.24855099], [ 1.21729703, 1.02345815], [-2.11816867, -1.0486257 ], [-1.04875537, -0.89928711]]) 代码具体代码见@Github: Non-parametric Estmation 定义核函数如下1234# 高斯核gaussian = lambda z: np.exp(-0.5*(np.linalg.norm(z)**2)) / np.sqrt(2*np.pi)# 均匀核square = lambda z: 1 if (np.linalg.norm(z) &lt;= 0.5) else 0 密度估计函数如下，需要对连续范围内的各个点，即$x \in [min(X), max(X)]$进行估计获得p，作图显示$x-p$即可123456789101112131415161718192021def parzenEstimate(X, kernel, h, n_num=50): """ 核参数估计 Args: X: &#123;ndarray(n_samples,)&#125; kernel: &#123;function&#125; 可调用的核函数 h: &#123;float&#125; 核函数的参数 Returns: p: &#123;ndarray(n_num,)&#125; Notes: - 一维，故`V_i = h` - p(x) = \frac&#123;1&#125;&#123;M&#125; \sum_&#123;i=1&#125;^M \kappa \left( \frac&#123;x_i - x&#125;&#123;h&#125; \right) """ x = np.linspace(np.min(X), np.max(X), num=n_num) p = np.zeros(shape=(x.shape[0],)) z = lambda x, x_i, h: (x - x_i) / h V_i = h; n_samples = X.shape[0] for idx in range(x.shape[0]): for i in range(X.shape[0]): p[idx] += kernel(z(x[idx], X[i], h)) / V_i p[idx] /= n_samples return p 均匀核 $h=0.5$ $h=0.8$ $h=1.0$ $h=2.0$ 高斯核 $h=0.5$ $h=0.8$ $h=1.0$ $h=2.0$]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Parameter Estimation]]></title>
    <url>%2F2018%2F11%2F19%2FParameter-Estimation%2F</url>
    <content type="text"><![CDATA[贝叶斯学派与频率学派有何不同？ - 任坤的回答 - 知乎 引言参数估计(parameter estimation)，统计推断的一种。根据从总体中抽取的随机样书．来估计总体分布中未知参数的过程。主要介绍最大似然估计(MLE: Maximum Likelihood Estimation)，最大后验概率估计(MAP: Maximum A Posteriori Estimation)，贝叶斯估计(Bayesian Estimation)。 解释一下“似然函数”和“后验概率”，在贝叶斯决策一节，给出定义如下 P(c_k|x)=\frac{p(x|c_k)P(c_k)}{p(x)}上式中$ k=1,…,K $，各部分定义如下$P(c_k|x)$——后验概率(posteriori probability)$P(c_k)$——先验概率(priori probability)$p(x|c_k)$——$c_k$关于$x$的似然函数(likelihood)$p(x)$——证据因子(evidence) 引例以最经典的掷硬币实验为例，假设有一枚硬币，投掷一次出现正面记$”1”$，投掷$10$次的实验结果如下 \{ 0， 1， 1， 1， 1， 0， 1， 1， 1，0 \}记硬币投掷结果为随机变量$X$，且$ x \in \{0, 1\}$，硬币投掷一次服从二项分布，估计二项分布的参数$\theta$ 最大似然估计(MLE)似然函数 Likelihood function - Wikipedia 离散型 L(x | \theta) = p_{\theta}(x)=P_{\theta}(X = x) 连续型 L(x | \theta) = f_{\theta}(x) 很多人能讲出一大堆哲学理论来阐明这一对区别。但我觉得，从工程师角度来讲，这样理解就够了:频率 $vs$ 贝叶斯 = $P(X; w)$ $vs$ $P(X|w)$ 或 $P(X,w)$ 作者：许铁-巡洋舰科技链接：https://www.zhihu.com/question/20587681/answer/122348889来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 模型有数据集$D = \{x_1, x_2, …, x_N\}$，按$c$个类别分成$\{D_1, D_2, …, D_C\}$，各个类别服从的概率分布密度函数模型已给出，估计参数$\hat{\Theta} = \{\hat{\theta}_{c_1}, \hat{\theta}_{c_2}, …, \hat{\theta}_{c_C}\} $ 假定 类别间独立，且各自服从概率分布密度函数为$p(x|c_j)$ 各类别的概率密度$p(x|c_j)$以参数$\theta_{c_j}$确定，即$p(x|c_j; \theta_{c_j})$ 故似然函数为 L(D | \Theta) = P(x_1, x_2, ..., x_N | \Theta) = \prod_{i=1}^N p(x_i | \theta_{x_i \in c_j}) 理解为，在参数$\Theta$为何值的条件下，实验结果出现数据集$D$的概率最大 求取其极大值对应的参数即可 一般取对数似然函数\log L(D | \Theta) = \sum_{i=1}^N \log p(x_i | \theta_{x_i \in c_j}) 极大值即对应梯度为$\vec{0}$的位置，即 ∇_\Theta \log L(D | \Theta) = \vec{0} \Rightarrow \hat{\Theta} Some comments about ML ML estimation is usually simpler than alternative methods. Has good convergence properties as the number of training samples increases. If the model chosen for p(x|θ) is correct, and independence assumptions among variables are true, ML will give very good results. If the model is wrong, ML will give poor results. —— Zhao Haitao. Maximum Likelihood and Bayes Estimation 例：正态分布的最大似然估计数据集(单类别)服从高斯分布$N(\mu, \sigma^2)$时的的最大似然估计 P(x_i | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi} \sigma } e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}} L(D | \mu, \sigma^2) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi} \sigma } e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}} =\left( \frac{1}{\sqrt{2\pi} \sigma } \right)^N \prod_{i=1}^N e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}}取对数似然 \log L(D | \mu, \sigma^2) = - \frac{N}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (x_i - \mu)^21. 参数$\mu$的估计 \frac{∂}{∂\mu} L(D | \mu, \sigma^2) = \frac{1}{\sigma^2} (\sum_{i=1}^N x_i - N\mu) = 0 \Rightarrow \hat{\mu} = \frac{1}{N} \sum_{i=1}^N x_i2. 参数$\sigma^2$的估计 \frac{∂}{∂\sigma^2} \log L(D | \mu, \sigma^2) = - \frac{N}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^N (x_i - \mu)^2 = 0 \Rightarrow \hat{\sigma^2} = \frac{1}{N} \sum_{i=1}^N (x_i - \mu)^2 参数$\hat{\mu}, \hat{\sigma}^2$的值与样本均值和样本方差相等 最大后验概率估计(MAP) 模型最大似然估计是求参数$\theta$, 使似然函数$P(D | \theta)$最大，最大后验概率估计则是求$\theta$使$P(\theta | D)$最大 理解为，在已出现的实验样本$D$上，参数$\theta$取何值的概率最大 且注意到 P(\theta | D) = \frac{P(D | \theta)P(\theta)}{P(D)}故$MAP$不仅仅使似然函数$P(D | \theta)$最大，而且使$P(\theta)$最大，即 \theta = argmax L(\theta | D) L(\theta | D) = P(\theta) P(D | \theta) = P(\theta) \prod_{i=1}^N p(x_i | \theta) 比$ML$多了一项$P(\theta)$ 取对数后 \log L(\theta | D) = \sum_{i=1}^N \log p(x_i | \theta) + \log P(\theta) 求取极大值 ∇_\theta L(\theta | D) = 0 \Rightarrow \hat{\theta} $MAP$和$MLE$的区别：$MAP$允许我们把先验知识加入到估计模型中，这在样本很少的时候是很有用的，因为样本很少的时候我们的观测结果很可能出现偏差，此时先验知识会把估计的结果“拉”向先验，实际的预估结果将会在先验结果的两侧形成一个顶峰。通过调节先验分布的参数，比如beta分布的$\alpha, \beta$，我们还可以调节把估计的结果“拉”向先验的幅度，$\alpha, \beta$越大，这个顶峰越尖锐。这样的参数，我们叫做预估模型的“超参数”。极大似然估计，最大后验概率估计(MAP)，贝叶斯估计 - 李鑫o_O - CSDN博客 例：正态分布的最大后验概率估计数据集(单类别)服从高斯分布$N(\mu, \sigma^2)$时的最大后验概率估计 p(x_i | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi} \sigma } e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}} \log p(x_i | \mu, \sigma^2) = - \frac{1}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} (x_i - \mu)^2 1. 参数$\mu$的估计给定先验条件：$\mu$服从正态分布$N(\mu_0, \sigma_{\mu_0}^2)$，即 p(\mu) = \frac{1}{\sqrt{2\pi}\sigma_{\mu_0}} e^ {-\frac{(\mu - \mu_0)^2}{2\sigma_{\mu_0}^2}} \log p(\mu) = - \frac{1}{2} \log(2\pi \sigma_{\mu_0}^2) - \frac{1}{2\sigma_{\mu_0}^2} (\mu - \mu_0)^2 则 \log L(\mu, \sigma^2 | D) = - \frac{N}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (x_i - \mu)^2 - \frac{1}{2} \log(2\pi \sigma_{\mu_0}^2) - \frac{1}{2\sigma_{\mu_0}^2} (\mu - \mu_0)^2则 \frac{∂}{∂\mu} \log L(\mu, \sigma^2 | D) = \frac{1}{\sigma^2} \sum_{i=0}^N (x_i - \mu) - \frac{1}{\sigma_{\mu_0}^2} (\mu - \mu_0) = 0 \Rightarrow \hat{\mu} = \frac{\mu_0 \sigma^2 + \sigma_{\mu_0}^2 \sum_{i=0}^N x_i} {\sigma^2 + N \sigma_{\mu_0}^2} = \frac{\mu_0 + \frac{\sigma_{\mu_0}^2}{\sigma^2} \sum_{i=0}^N x_i} {1 + \frac{\sigma_{\mu_0}^2}{\sigma^2} N }2. 参数$\sigma^2$的估计给定先验条件：$\sigma^2$服从正态分布$N(\sigma_0^2, \sigma_{\sigma_0^2}^2)$，即 p(\sigma^2) = \frac{1}{\sqrt{2\pi} \sigma_{\sigma_0^2}} e^ {-\frac{(\sigma^2- \sigma_0^2)^2}{2 \sigma_{\sigma_0^2} ^2}} \log p(\sigma^2) = - \frac{1}{2} \log(2\pi \sigma_{\sigma_0}^2) - \frac{1}{2\sigma_{\sigma_0}^2} (\sigma - \sigma_0)^2 则 \log L(\mu, \sigma^2 | D) = - \frac{N}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^N (x_i - \mu)^2 - \frac{1}{2} \log(2\pi \sigma_{\sigma_0}^2) - \frac{1}{2\sigma_{\sigma_0}^2} (\sigma - \sigma_0)^2则 \frac{∂}{∂\sigma^2} \log L(\mu, \sigma^2 | D) = - \frac{N}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^N (x_i - \mu)^2 - \frac{1}{2\sigma_{\sigma_0}^2} \frac{\sigma - \sigma_0}{\sigma} \Rightarrow \hat{\sigma^2}(略) \frac{∂}{∂\sigma^2}(\sigma - \sigma_0)^2 = 2(\sigma - \sigma_0) \frac{∂}{∂\sigma^2} (\sigma - \sigma_0) = \frac{\sigma - \sigma_0}{\sigma} 贝叶斯估计模型 p(\theta | D) = \frac {P(D | \theta)p(\theta)} {P(D)} = a · p(\theta) \prod_{i=1}^N p(x_i | \theta)其中$a$是使 \int p(\theta | D) = 1利用“质心公式”求解贝叶斯的点估计 θ_{Bayes} = \int θ·p(θ|D) d θ例：正态分布的贝叶斯估计数据集(单类别)服从高斯分布$N(\mu, \sigma^2)$时的贝叶斯估计 p(x_i | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi} \sigma } e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}}参数$\mu$的估计给定先验条件：$\mu$服从正态分布$N(\mu_0, \sigma_{\mu_0}^2)$，即 p(\mu) = \frac{1}{\sqrt{2\pi}\sigma_{\mu_0}} e^ {-\frac{(\mu - \mu_0)^2}{2\sigma_{\mu_0}^2}}则 P(\mu | D) = a · p(\mu) \prod_{i=1}^N p(x_i | \mu) = a · \frac{1}{\sqrt{2\pi}\sigma_{\mu_0}} e^ {-\frac{(\mu - \mu_0)^2}{2\sigma_{\mu_0}^2}} \prod_{i=1}^N \frac{1}{\sqrt{2\pi} \sigma } e^ {-\frac{(x_i - \mu)^2}{2\sigma^2}} = a · \left( \frac{1}{\sqrt{2\pi}} \right)^{N + 1} \frac{1}{\sigma_{\mu_0} \sigma^N} e^ { -\frac{(\mu - \mu_0)^2}{2\sigma_{\mu_0}^2} -\sum_{i=1}^N \frac{(x_i - \mu)^2}{2\sigma^2} }易证 我已经想到了一个绝妙的证明,但是这台电脑的硬盘太小了,写不下。 p(\mu | D) = \frac{1}{\sqrt{2\pi}\sigma_N} e^ {-\frac{(\mu - \mu_N)^2}{2\sigma_N^2}}其中 \mu_N = \frac{N \sigma_0^2} {N \sigma_0^2 + \sigma^2} \frac{1}{N} \sum_{i=1}^N x_i +\frac{\sigma^2}{N \sigma_0^2 + \sigma^2} \mu_0 \sigma_N^2 = \frac{\sigma_0^2 \sigma^2} {N \sigma_0^2 + \sigma^2} 与$MLE$，$MAP$的区别 相比较$MLE$与$MAP$的点估计，贝叶斯估计得到的结果是参数$\theta$的密度函数$p(\theta | D)$ 最大后验概率估计为求取对应最大后验概率的点 \theta = argmax_\theta p(\theta | D) 贝叶斯估计为求取整个取值范围的概率密度$p(\theta | D)$，既然如此，必有 \int p(\theta | D) d\theta = 1 统计学习方法学习笔记（一）—极大似然估计与贝叶斯估计原理及区别 - YJ-20 - 博客园 p(\theta | D) = \frac {p(\theta) \prod_{i=1}^N p(x_i | \theta)} {\int_\theta p(\theta) \prod_{i=1}^N p(x_i | \theta) d\theta}由于$\theta$是满足一定概率分布的变量，所以在计算的时候需要将考虑所有$\theta$取值的情况，在计算过程中不可避免地高复杂度。所以计算时并不把所有地后验概率$p(\theta | D)$都找出来，而是采用类似于极大似然估计地思想，来极大化后验概率，得到这种有效的叫做$MAP$ 引例的求解已知硬币投掷结果服从$Bernoulli$分布 X 0 1 P 1-θ θ 或者 P(X_i) = \theta ^{X_i} (1 - \theta) ^{1 - X_i}最大似然估计实验结果中正面出现$7$次，反面出现$3$次，似然函数为 L(\theta) = \prod_{i=1}^{10} \theta ^{X_i} (1 - \theta) ^{1 - X_i} = \theta ^7 (1 - \theta) ^3取对数似然函数并求极大值 \log L(\theta) = 7 \log \theta + 3 \log (1 - \theta)令 \frac{∂}{∂ \theta} \log L(\theta) = \frac{7}{\theta} - \frac{3}{1-\theta} = 0解得 \theta = 0.7即硬币服从$B(1, 0.7)$的概率分布 做出$L(\theta)$图像验证，如下 最大后验概率估计给定先验条件 \theta \thicksim N(\theta_0, \sigma_{\theta_0}^2)则最大化 L(\theta | D) = \theta ^7 (1 - \theta) ^3 · \frac{1}{\sqrt{2\pi}\sigma_{\theta_0}} e^ {-\frac{(\theta - \theta_0)^2}{2\sigma_{\theta_0}^2}}取对数 \log L(\theta | D) = 7 \log \theta + 3 \log (1 - \theta) - \frac{1}{2} \log(2\pi \sigma_{\theta_0}^2) - \frac{1}{2\sigma_{\theta_0}^2} (\theta - \theta_0)^2求取极大值点 \frac{∂}{∂\theta} \log L(\theta | D) = \frac {7}{\theta} - \frac{3}{1-\theta} - \frac{\theta - \theta_0}{\sigma_{\theta_0}^2} = 0得到 \theta^3 - (\theta_0 + 1) \theta^2 + (\theta_0 - 10\sigma_{\theta_0}^2) \theta + 7\sigma_{\theta_0}^2 = 0以下为选取不同先验条件时的$L(\theta | D)$图像，用于对比 第一张图为极大似然估计$L(D|\theta)$ 第二张图为先验概率密度函数$P(\theta)$ 第三张图为最大后验概率估计$L(\theta | D)$，$\hat{\theta}$由查表法求解代码见仓库 $\theta_0 = 0.3, \sigma_{\theta_0} = 0.1$ $\Rightarrow$ $\hat{\theta} = 0.42$ $\theta_0 = 0.5, \sigma_{\theta_0} = 0.1$ $\Rightarrow$ $\hat{\theta} = 0.56$ $\theta_0 = 0.7, \sigma_{\theta_0} = 0.1$ $\Rightarrow$ $\hat{\theta} = 0.70$ $\theta_0 = 0.5, \sigma_{\theta_0} = 0.01$ $\Rightarrow$ $\hat{\theta} = 0.50$ $\theta_0 = 0.5, \sigma_{\theta_0} = 1.0$ $\Rightarrow$ $\hat{\theta} = 0.70$ 结论 由图$1, 2, 3$，可以看到当$\theta_0$偏移$0.7$时，$MAP$结果也相应偏移； 由图$2, 4, 5$，可以看到当$\sigma_{\theta_0}^2$越小，即越确定先验概率分布时，$MAP$结果也越趋向于先验概率分布。 贝叶斯估计先验条件为正态分布 \theta \thicksim N(\theta_0, \sigma_{\theta_0}^2) p(\theta | D) = a · p(\theta) \prod_{i=1}^N p(x_i | \theta) = a · \frac{1}{\sqrt{2\pi}\sigma_{\theta_0}} e^ {-\frac{(\theta - \theta_0)^2}{2\sigma_{\theta_0}^2}} · \theta ^7 (1 - \theta) ^3 参数$a$使用scipy.integrate.quad求解 选取不同先验条件时的$L(\theta | D)$图像，用于对比 $\theta_0 = 0.3, \sigma_{\theta_0} = 0.1$ $\theta_0 = 0.5, \sigma_{\theta_0} = 0.1$ $\theta_0 = 0.7, \sigma_{\theta_0} = 0.1$ $\theta_0 = 0.5, \sigma_{\theta_0} = 0.01$ $\theta_0 = 0.5, \sigma_{\theta_0} = 1.0$]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Clustering]]></title>
    <url>%2F2018%2F11%2F16%2FClustering%2F</url>
    <content type="text"><![CDATA[前言这是第一篇关于无监督学习的博文，无监督的学习则不是尝试预测任何东西，而是寻找数据中的特征，在无监督学习中，有一个重要的方法称为聚类，是把具有相同特征的数据聚集在一组。 基础知识距离度量方法机器学习中距离度量方法有很多，以下简单介绍几种。 机器学习常用的距离度量方法 - taotiezhengfeng的博客 - CSDN博客算法中的各种距离（欧式距离，马氏距离，闵可夫斯基距离……） - 啊哦123的博客 - CSDN博客 定义两个$n$维向量 x = [x_1, x_2, ..., x_n]^T y = [y_1, y_2, ..., y_n]^T 曼哈顿距离(Manhattan Distance) d = || x - y ||_1 = \sum_i |x_i - y_i| 欧氏距离(Euclidean Distance) d = || x - y ||_2 = \sqrt{\sum_i (x_i - y_i)^2} 闽可夫斯基距离(Minkowski Distance) d = || x - y ||_p = \left(\sum_i | x_i - y_i |^{p} \right)^{\frac{1}{p}} 当$p$取$1$时为曼哈顿距离，取$2$时为欧式距离。 余弦距离(Cosine) d = \frac{x^T y}{||x||_2 ||y||_2} = \frac{\sum_i x_i y_i}{\sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2}} 突然想到为什么向量的夹角余弦是怎么来的，高中学习一直背的公式，现在给一下证明。证明：向量的夹角公式 从余弦定理(余弦定理用几何即可)出发，有 \cos \theta = \frac{a^2+b^2-c^2}{2ab}其中 ||\vec{a}|| = \sqrt{x_1^2 + y_1^2} ||\vec{b}|| = \sqrt{x_2^2 + y_2^2} ||\vec{c}|| = \sqrt{(x_1 - x_2)^2 + (x_2 - y_2)^2}故 \cos \theta = \frac {(\sqrt{x_1^2 + y_1^2})^2 + (\sqrt{x_2^2 + y_2^2})^2 - (\sqrt{(x_1 - x_2)^2 + (x_2 - y_2))^2}} {2 \sqrt{x_1^2 + y_1^2} \sqrt{x_2^2 + y_2^2}} = \frac {x_1 x_2 + y_1 y_2} {\sqrt{x_1^2 + y_1^2} \sqrt{x_2^2 + y_2^2}} = \frac{a^T b}{||a||·||b||} hard vs. soft clustering 硬聚类(hard clustering) 计算的是一个硬分配(hard ssignment)过程,即每个样本仅仅属于一个簇。 软聚类(soft clustering) 分配过程是软的，即一个样本的分配结果是在所有簇上的一个分布，在软分配结果中，一个样本可能对多个簇都具有隶属度。 聚类方法的分类 划分方法 K-means，K-medoids，GMM等。 层次方法 AGNES，DIANA，BIRCH，CURE和CURE-NS等。 基于密度的方法 DBSCAN，OPTICS，DENCLUE等。 其他 如STING等。 常用聚类方法K均值(K-means)是最为经典的基于划分的聚类方法，是十大经典数据挖掘算法之一，通常用于寻找次优解，再通过其他算法(如GMM)寻找更优的聚类结果。 原理给定$N$维数据集 X = [x^{(1)}, x^{(2)}, ..., x^{(M)}]指定类别数$K$与初始中心点$\mu^{(0)}$，将样本划分到中心点距离其最近的簇中，再根据本次划分更新各簇的中心$\mu^{(t)}$，如此迭代直至得到最好的聚类结果。预测测试样本时，将其划分到中心点距其最近的簇，也可通过KNN等方法。 一般使用欧式距离度量样本到各中心点的距离，也可选择余弦距离等，这也是K-means算法的关键 D(x^{(i)}, \mu_k) = || x^{(i)} - \mu_k ||_2^2定义损失函数为 J(\Omega) = \sum_i \sum_k r^{(i)}_k D(x^{(i)}, \mu_k)其中 r^{(i)}_k = \begin{cases} 1 & x^{(i)} \in C_k \\ 0 & otherwise \end{cases}或表示为 r^{(i)} = [0, ..., 1_k, ..., 0]^T在迭代过程中，损失函数的值不断下降，优化目标为 \min J(\Omega)计算步骤 随机选取$K$个中心点； 遍历所有数据，计算每个点到各中心点的距离； 将每个数据划分到最近的中心点中； 计算每个聚类的平均值，作为新的中心点； 重复步骤2-步骤4，直到这k个中线点不再变化(收敛)，或执行了足够多的迭代； K-means更新迭代过程如下图 缺点与部分解决方法 局部最优 初值敏感 初始点的选择会影响K-means聚类的结果，即可能会陷入局部最优解，如下图 可通过如下方法解决 多次选择初始点运行K-means算法，选择最优的作为输出结果； K-means++ 需要定义mean，对于标称型(categorical)数据不适用 需要给定聚类簇数目$K$ 这里给出一种选择簇数目的方法，选择多个$K$值进行聚类，计算代价函数，做成折线图后如下，可以看到在$K=3$处损失值的变化率出现较大变化，则可选择簇的数目为$3$。 噪声数据干扰大 对于非凸集(non-convex)数据无能为力 谱聚类可解决非凸集数据的聚类问题。 改进 K-means++ 改进初始点选择方法，第$1$个中心点随机选择；之后的初始中心点根据前面选择的中心点决定，若已选取$n$个初始聚类中心$(0&lt;n&lt;K)$，选取第$n+1$个聚类中心时，距离当前$n$个聚类中心越远的点会有更高的概率被选为第$n+1$个聚类中心。 ISODATA 思想：当属于某个类别的样本数过少时把这个类别去除，当属于某个类别的样本数过多、分散程度较大时把这个类别分为两个子类别. Kernel K-means 参照支持向量机中核函数的思想，将所有样本映射到另外一个特征空间中再进行聚类。 类似的算法与K-means类似的算法有很多，例如 K-medoids K-means的取值范围可以是连续空间中的任意值，要求所有数据样本处在一个欧式空间中，对于有很多噪声的数据就会造成极大的误差。K-medoids的取值是数据样本范围中的样本，且可应用在非数值型数据样本上。 k-medians $K$中值，选择中位数更新各簇的中心点。 K-centers 混合类型数据的K-Centers聚类算法/The K-Centers Clustering Algorithm for Categorical and Mixe 代码@Github: K-Means12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class KMeans(): def __init__(self, n_cluster, mode): self.n_cluster = n_cluster # 簇的个数 self.mode = mode # 距离度量方式 self.centroids = None # 簇的中心 self.loss = float('inf') # 优化目标值 plt.ion() def fit(self, X, max_iter=5, min_move=0.1, display=False): def initializeCentroids(): ''' 选择初始点 ''' centroid = np.zeros(shape=(self.n_cluster, X.shape[1])) # 保存选出的点 pointIdx = [] # 保存已选出的点的索引 for n in range(self.n_cluster): idx = np.random.randint(0, X.shape[0]) # 随机选择一个点 while idx in pointIdx: # 若该点已选出，则丢弃重新选择 idx = np.random.randint(0, X.shape[0]) pointIdx.append(idx) centroid[n] = X[idx] return centroid def dist2Centroids(x, centroids, mode): ''' 返回向量x到k个中心点的距离值 ''' d = np.zeros(shape=(self.n_cluster,)) for n in range(self.n_cluster): d[n] = mathFunc.distance(x, centroids[n], mode) return d def nearestInfo(centroids, mode): ''' 每个点最近的簇中心索引、距离 ''' ctIdx = -np.ones(shape=(X.shape[0],), dtype=np.int8) # 每个点最近的簇中心索引，初始化为-1，可作为异常条件 ctDist = np.ones(shape=(X.shape[0],), dtype=np.float) # 每个点到最近簇中心的距离 for i in range(X.shape[0]): dists = dist2Centroids(X[i], centroids, mode) if mode == 'Euclidean': ctIdx[i] = np.argmin(dists) elif mode == 'Cosine': ctIdx[i] = np.argmax(dists) ctDist[i] = dists[ctIdx[i]] # 保存最相似的距离度量，用于计算loss return ctIdx, ctDist def updateCentroids(ctIdx): ''' 更新簇中心 ''' centroids = np.zeros(shape=(self.n_cluster, X.shape[1])) for n in range(self.n_cluster): X_ = X[ctIdx == n] # 筛选出离簇中心Cn最近的样本点 centroids[n] = np.mean(X_, axis=0) # 根据筛选出的样本点更新中心值 return centroids def loss(dist): return np.mean(dist**2) # ----------------------------------------- loss_min = float('inf') # 最优分类时的损失值，最小 n_iter = 0 while n_iter &lt; max_iter: # 每次迭代选择不同的初始点 n_iter += 1; isDone = False # 表示本次迭代是否已收敛 centroids_tmp = initializeCentroids() # 选择本次迭代的初始点 loss_last = float('inf') # 本次迭代中，中心点更新前的损失值 n_update = 0 # 本次迭代的更新次数计数 while not isDone: n_update += 1 ctIdx, ctDist = nearestInfo(centroids_tmp, mode=self.mode) centroids_tmp = updateCentroids(ctIdx) # 更新簇中心 # --- 可视化 --- if (display==True) and (X.shape[1] == 2): plt.ion() plt.figure(n_iter); plt.cla() plt.scatter(X[:, 0], X[:, 1], c=ctIdx) plt.scatter(centroids_tmp[:, 0], centroids_tmp[:, 1], c='r') plt.pause(0.5) # ------------- loss_now = loss(ctDist); moved = np.abs(loss_last - loss_now) if moved &lt; min_move: # 若移动过小，则本次迭代收敛 isDone = True print('第%d次迭代结束，中心点更新%d次' % (n_iter, n_update)) else: loss_last = loss_now if loss_now &lt; loss_min: self.centroids = centroids_tmp # 保存损失最小的模型(最优) loss_min = loss_now # print('聚类结果已更新') self.loss = loss_min print('=========== 迭代结束 ===========') def predict(self, X): ''' 各个样本的最近簇中心索引 ''' labels = -np.ones(shape=(X.shape[0],), dtype=np.int) # 初始化为-1，可用作异常条件 for i in range(X.shape[0]): dists_i = np.zeros(shape=(self.n_cluster,)) # 保存X[i]到中心点Cn的距离 for n in range(self.n_cluster): dists_i[n] = mathFunc.distance(X[i], self.centroids[n], mode=self.mode) if self.mode == 'Euclidean': labels[i] = np.argmin(dists_i) elif self.mode == 'Cosine': labels[i] = np.argmax(dists_i) return labels 簇数的选择代码如下123456789101112def chooseBestK(X, start, stop, step=1, mode='Euclidean'): Ks = np.arange(start, stop + 1, step, dtype=np.int) # 待选择的K Losses = np.zeros(shape=Ks.shape) # 保存不同K值时的最小损失值 for k in range(1, Ks.shape[0] + 1): # 对于不同的K，训练模型，计算损失 print('K = %d', k) estimator = KMeans(n_cluster=k, mode=mode) estimator.fit(X, max_iter=10, min_move=0.01, display=False) Losses[k - 1] = estimator.loss plt.ioff() plt.figure(); plt.xlabel('n_clusters'); plt.ylabel('loss') plt.plot(Ks, Losses) # 做出loss-K曲线 plt.show() 均值漂移(Meanshift)本质是一个迭代的过程，能够在一组数据的密度分布中寻找到局部极值，比较稳定，而且是无参密度估计(不需要事先知道样本数据的概率密度分布函数，完全依靠对样本点的计算)，而且在采样充分的情况下，一定会收敛，即可以对服从任意分布的数据进行密度估计。 原理有一个滑动窗口的思想，即利用当前中心点一定范围内(通常为球域)的点迭代更新中心点，重复移动窗口，直到满足收敛条件。简单的说，Meanshift就是沿着密度上升的方向寻找同属一个簇的数据点。 定义点$x_0$的$\epsilon$球域如下 S_h(x_0) = \{ x | (x - x_0)^T (x - x_0) \leq \epsilon \}若有$n$个点$(x_1, …, x_n)$落在中心点$ptCentroid$的邻域内，其分布如图 则偏移向量计算方式为 vecShift = \frac{1}{n} \sum_{i=1}^n (x_i - ptCentroid)中心点更新公式为 ptCentroid := ptCentroid + vecShift 展开后可发现，其更新公式即 vecShift = \frac{1}{n} \sum_{i=1}^n x_i - ptCentroid ptCentroid := \frac{1}{n} \sum_{i=1}^n x_i 一个滑动窗口的动态更新过程如下图初始化多个滑动窗口进行MeanShift算法，其更新过程如下，其中每个黑点代表滑动窗口的质心，每个灰点代表一个数据点 高斯权重基本思想是，距离当前中心点近的向量对更新结果权重大，而远的权重小，可减小远点的干扰，如下图，$vecShift_2$为高斯权重下的偏移向量 其偏移向量计算方式为 vecShift = \frac{1}{n} \sum_{i=1}^n w_i · (x_i - ptCentroid) w_i = \frac{\kappa(x_i - ptCentroid)}{\sum_j \kappa(x_j - ptCentroid)}其中 \kappa(z) = \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{||z||^2}{2\sigma^2} \right)中心点更新公式仍然为 ptCentroid := ptCentroid + vecShift 展开也可得到 ptCentroid := \frac{\sum_{i=1}^n w_i x_i}{\sum_j w_j} 计算步骤对于给定的$N$维数据集$X = (x^{(1)}, x^{(2)}, …, x^{(M)})$，指定邻域参数$\epsilon_0$，终止条件参数$\epsilon_1$，簇合并参数$\epsilon_2$，并指定样本距离度量方式，目标为将其划分为$K$个簇。 初始化： 在样本集中随机选择$K_0(K_0 \gg K)$个样本作为初始中心点，以邻域大小为$\epsilon_0$建立滑动窗口； 各个样本初始化一个标记向量，用于记录被各类别访问的次数； 以单个滑动窗口分析，记其中心点为$ptCentroid$，找到滑动窗口内的所有点，记作集合$M$，认为这些点属于该滑动窗口所属的簇类别，同时，这些点被该簇访问的次数$+1$； 以$ptCentroid$为中心，计算其到集合$M$中各个元素的向量，以这些向量计算得到偏移向量$vecShift$； 更新中心点：$ptCentroid = ptCentroid + vecShift$，即滑动窗口沿着$vecShift$方向移动，距离为$||vecShift||$； 重复步骤$2-4$，直到$||vecShift||&lt;\epsilon_1$，保存当前中心点； 如果收敛时当前簇$ptCentroid$与其它已经存在的簇的中心的距离小于阈值$\epsilon_2$，那么这两个簇合并。否则，把当前簇作为新的簇类，增加$1$类； 重复迭代直到所有的点都被标记访问； 根据每个样本被各簇的访问频率，取访问频率最大的那个簇类别作为当前点集的所属类。 即不同类型的滑窗沿着密度上升的方向进行移动，对各样本点进行标记，最后将样本划分为标记最多的类别；当两类非常接近时，合并为一类。 代码@Github: MeanShift 先定义了窗格对象1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class SlidingWindow(): """ Attributes: centroid: &#123;ndarray(n_features,)&#125; epsilon: &#123;float&#125; 滑动窗格大小，为半径的平方 sigma: &#123;float&#125; 高斯核函数的参数 label: &#123;int&#125; 该窗格的标记 X: &#123;ndarray(n_samples, n_features)&#125; containIdx: &#123;ndarray(n_contain,)&#125; 窗格内包含点的索引 """ def __init__(self, centroid, epsilon, sigma, label, X): self.centroid = centroid self.epsilon = epsilon self.sigma = sigma self.label = label self.containIdx = self.updateContain(X) def k(self, z): """ 高斯核函数 Args: z: &#123;ndarray(n_features,)&#125; Notes: - \kappa(z) = \frac&#123;1&#125;&#123;\sqrt&#123;2\pi&#125;&#125; \exp \left( - \frac&#123;||z||^2&#125;&#123;2\sigma^2&#125; \right) """ norm = np.linalg.norm(z) return np.exp(- 0.5 * (norm / self.sigma)**2) / np.sqrt(2*np.pi) def step(self, X): """ 更新滑动窗格的中心点和所包含点 Returns: &#123;float&#125; """ dshift = self.shift(X) self.containIdx = self.updateContain(X) return dshift def shift(self, X): """ 移动窗格 Args: vecShift: &#123;ndarray(n_features,)&#125; Returns: dshift: &#123;float&#125; 移动的距离 """ (n_samples, n_features) = X.shape n_contain = self.containIdx.shape[0] contain_weighted_sum = np.zeros(shape=(n_features, )) weight_sum = 0 # 按包含的点进行移动 for i_contain in range(n_contain): vector = X[self.containIdx[i_contain]] - self.centroid weight = self.k(vector) contain_weighted_sum += weight*X[self.containIdx[i_contain]] weight_sum += weight centroid = contain_weighted_sum / weight_sum # 计算移动的距离 dshift = np.linalg.norm(self.centroid - centroid) self.centroid = centroid return dshift def updateContain(self, X): """ 更新窗格内的点索引 Args: X: &#123;ndarray(n_samples, n_features)&#125; Notes: - 用欧式距离作为度量 """ d = lambda x_i, x_j: np.linalg.norm(x_i - x_j) n_samples = X.shape[0] containIdx = np.array([], dtype='int') for i_samples in range(n_samples): if d(X[i_samples], self.centroid) &lt; self.epsilon: containIdx = np.r_[containIdx, i_samples] return containIdx 聚类算法如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109class MeanShift(): """ Attributes: n_clusters: &#123;int&#125; 划分簇的个数 n_windows: &#123;int&#125; 滑动窗格的个数 epsilon: &#123;float&#125; 滑动窗格的大小 sigma: &#123;float&#125; &#123;float&#125; 高斯核参数 thresh: &#123;float&#125; 若两个窗格中心距离小于thresh，则合并两类簇 min_move: &#123;float&#125; 终止条件 windows: &#123;list[class SlidingWindow()]&#125; Note: - 假设所有点均被窗格划过 """ def __init__(self, n_clusters, n_windows=-1, epsilon=0.5, sigma=2, thresh=1e-2, min_move=1e-3): self.n_clusters = n_clusters self.n_windows = 5*n_clusters if (n_windows == -1) else n_windows self.epsilon = epsilon self.sigma = sigma self.thresh = thresh self.min_move = min_move self.windows = [] self.centroids = None def fit(self, X): (n_samples, n_features) = X.shape # 创建窗格 for i_windows in range(self.n_windows): idx = np.random.randint(n_samples) window = SlidingWindow(X[idx], self.epsilon, self.sigma, i_windows, X) # 将各窗格包含的点标记 n_contain = window.containIdx.shape[0] self.windows.append(window) dshift = float('inf') # 初始化为无穷大 plt.figure(); plt.ion() while dshift &gt; self.min_move: # ------ 做图显示 ------ plt.cla() plt.scatter(X[:, 0], X[:, 1], c='b') for i_windows in range(self.n_windows): centroid = self.windows[i_windows].centroid plt.scatter(centroid[0], centroid[1], c='r') plt.pause(0.5) # --------------------- dshift = self.step(X) plt.ioff() # 合并窗格 dists = np.zeros(shape=(self.n_windows, self.n_windows)) for i_windows in range(self.n_windows): for j_windows in range(i_windows): centroid_i = self.windows[i_windows].centroid centroid_j = self.windows[j_windows].centroid dists[i_windows, j_windows] = np.linalg.norm(centroid_i-centroid_j) dists[j_windows, i_windows] = dists[i_windows, j_windows] # 获得距离相近索引 index = np.where(dists&lt;self.thresh) # 用于标记类别 winlabel = np.zeros(shape=(self.n_windows,), dtype='int') label = 1; winlabel[0] = label for i_windows in range(self.n_windows): idx_row = index[0][i_windows] idx_col = index[1][i_windows] # 若其中一个点被标记，则将令一个点并入该类 if winlabel[idx_row]!=0: winlabel[idx_col] = winlabel[idx_row] elif winlabel[idx_col]!=0: winlabel[idx_row] = winlabel[idx_col] # 否则新创建类别 else: label += 1 winlabel[idx_row] = label winlabel[idx_col] = label # 将标签一样的窗格合并 labels = list(set(winlabel)) # 去重后的标签 n_labels = len(labels) # 标签种类数 self.centroids = np.zeros(shape=(n_labels, n_features)) # 记录最终聚类中心 for i_labels in range(n_labels): cnt = 0 for i_windows in range(self.n_windows): if winlabel[i_windows] == labels[i_labels]: self.centroids[i_labels] += self.windows[i_windows].centroid cnt += 1 self.centroids[i_labels] /= cnt # 取同类窗格中心点的均值 return self.centroids def step(self, X): """ update all sliding windows Returns: dshift: \sum_i^&#123;n_windows&#125; dshift_&#123;i&#125; """ dshift = 0 for i_windows in range(self.n_windows): dshift += self.windows[i_windows].step(X) # label the points n_contain = self.windows[i_windows].containIdx.shape[0] return dshift def predict(self, X): """ 简单的用近邻的方法求 """ (n_samples, n_features) = X.shape dists = np.zeros(shape=(n_samples, self.n_clusters)) for i_samples in range(n_samples): for i_clusters in range(self.n_clusters): dists[i_samples, i_clusters] = np.linalg.norm(X[i_samples]-self.centroids[i_clusters]) return np.argmin(dists, axis=1) 谱聚类(Spectral Clustering)谱聚类是从图论中演化出来的算法，后来在聚类中得到了广泛的应用，比起传统的K-Means算法，谱聚类对数据分布的适应性更强，聚类效果也很优秀，同时聚类的计算量也小很多。 原理 谱聚类（spectral clustering）原理总结 - 刘建平Pinard - 博客园 无向权重图我们用点的集合$V$和边的集合$E$描述一个图，即$G(V, E)$，其中$V$即数据集中的点 V = [v_1, v_2, ..., v_n]而点$v_i, v_j$间连接权值$w_{ij}$组成邻接矩阵$W$，由于为无向图，故满足$w_{ij}=w_{ji}$ W = \left[ \begin{matrix} w_{11} & ... & w_{1n} \\ ... & ... & ... \\ w_{n1} & ... & w_{nn} \\ \end{matrix} \right]对于图中的任意一个点$v_i$，定义其度$d_i$为 d_i = \sum_{j=1}^n w_{ij}则我们可以得到一个度矩阵$D=diag(d_1, …, d_n)$ D = \left[ \begin{matrix} d_1 & & \\ & ... & \\ & & d_n\\ \end{matrix} \right]除此之外，对于$V$中子集$V_{sub} \subset V$，定义子集$V_{sub}$点的个数为 |V_{sub}| := n_{sub}另外，定义该子集中点的度之和为 vol(V_{sub}) = \sum_{i \in V_{sub}} d_i相似矩阵上面讲到的邻接矩阵$W$可以指定权值，但对于数据量庞大的数据集，这显然不是一个$wise$的选择。我们可以用相似矩阵$S$来获得邻接矩阵$W$，基本思想是，距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重值较高。 构建邻接矩阵$W$的方法有三类：$\epsilon$-邻近法，$K$邻近法和全连接法，定义距离 d_{ij} = ||x^{(i)} - x^{(j)}||_2^2 $\epsilon$-邻近法 设置距离阈值$\epsilon$，用欧式距离度量两点的距离$d_{ij}$，然后通过下式确定邻接权值$w_{ij}$ w_{ij} = \begin{cases} 0 & d_{ij} > \epsilon \\ \epsilon & otherwise \end{cases} 两点间的权重要不就是$\epsilon$，要不就是0，距离远近度量很不精确，因此在实际应用中，我们很少使用$\epsilon$-邻近法。 $K$邻近法 第一种 只要一个点在另一个点的$K$近邻中，则保留$d_{ij}$ w_{ij} = \begin{cases} \exp \left( -\frac{d_{ij}}{2\sigma^2} \right) & x^{(i)} \in KNN(x^{(j)}) or x^{(j)} \in KNN(x^{(i)}) \\ 0 & otherwise \end{cases} 第二种 互为$K$近邻时保留$d_{ij}$ w_{ij} = \begin{cases} \exp \left( -\frac{d_{ij}}{2\sigma^2} \right) & x^{(i)} \in KNN(x^{(j)}) and x^{(j)} \in KNN(x^{(i)}) \\ 0 & otherwise \end{cases} 全连接法 可以选择不同的核函数来定义边权重，常用的有多项式核函数，高斯核函数和Sigmoid核函数。最常用的是高斯核函数RBF，此时相似矩阵和邻接矩阵相同 w_{ij} = \exp \left( -\frac{d_{ij}}{2\sigma^2} \right) 拉普拉斯矩阵(Graph Laplacians)定义 L = D - W正则化的拉普拉斯矩阵为 L = D^{-1} (D - W)具有的性质如下 $L^T = L$ 其特征值均为实数，即$\lambda_i \in \mathbb{R}$ 正定性：$\lambda_i \geq 0$ 对于任意向量$x$，都有 x^T L x = \frac{1}{2} \sum_{i,j} w_{ij} (x_i - x_j)^2 证明： x^T L x = x^T D x - x^T W x = \sum_i d_i > x_i^2 - \sum_{ij} w_{ij} x_i x_j = \frac{1}{2} \left[ \sum_i d_i x_i^2 - > 2\sum_{ij} w_{ij} x_i x_j + \sum_j d_j x_j^2 \right]其中$ d_i = \sum_j w_{ij} $，所以 x^T L x = \frac{1}{2} \sum_{i,j} w_{ij} (x_i - x_j)^2 无向图的切图cut我们希望把一张无向图$G(V, E)$按一定方法切成多个子图，各个子图间无连接，每个子图的点集为$V_1, …, V_K$，满足 $\bigcup_{k=1}^K V_k = V$ $V_i \cap V_j = \emptyset$ 定义两个子图点集合$A, B$之间的切图权重为 W(A, B) = \sum_{i \in A, j \in B} w_{ij} 共有$n_A × n_B$个权值作累加 那么对于$K$个子图点的集合$V_1, …, V_K$，定义切图为 cut(V_1, ..., V_K) = \frac{1}{2} \sum_{i=1}^K cut(V_i, \overline{V_i}) cut(V_i, \overline{V_i}) = W (V_i, \overline{V_i})其中$\overline{V_i}$表示$V_i$的补集，或者 \overline{V_i} = \bigcup_{k \neq i} V_k通过最小化$cut(V_1, …, V_K)$使子图内权重和大，而子图间权重和小。但是这种方法存在问题，如下图 选择一个权重最小的边缘的点，比如$C$和$H$之间进行$cut$，这样可以最小化$cut(V_1, …, V_K)$，但是却不是最优的切图。 为解决上述问题，需要对每个子图的规模做出限定，以下介绍两种切图方式。 Ratio Cut不仅考虑最小化$cut(V_1, …, V_K)$，而且最大化每个子图的点个数，即 RatioCut(V_1, ..., V_K) = \frac{1}{2} \sum_k \frac{cut(V_i, \overline{V_i})}{|V_k|} cut(V_i, \overline{V_i}) = W (V_i, \overline{V_i}) $W(V_k, \overline{V_k}) = \sum_{i \in V_k, j \in \overline{V_k}} w_{ij}$ $|V_k| = n_k$ 如果按照遍历的方法求解，由前面分析，$W(V_k, \overline{V_k})$需计算$n_{V_k} × n_{\overline{V_k}}$次累加，计算量庞大，那么如何求解呢？ 定义指示向量$h_k$，其构成矩阵$H$ H = [ h_1, ..., h_k, ..., h_K]其中 h_k = \left[h_{k1}, h_{k2}, , ..., h_{kM} \right]^T h_{ki} = \begin{cases} \frac{1}{\sqrt{|V_k|}} & x^{(i)}\in V_k \\ 0 & otherwise \end{cases} $h_k$为单位向量，且两两正交 h_i^T h_j = \begin{cases} \sum_{|V_i|} \frac{1}{|V_i|} = |V_i| · \frac{1}{|V_i|} = 1 & i = j \\ 0 & i \neq j \end{cases} 那么由拉式矩阵性质$4$ h_k^T L h_k = \frac{1}{2} \sum_{i,j} w_{ij} (h_{ki} - h_{kj})^2 = \frac{1}{2} [ \sum_{i \in V_k, j \in V_k} w_{ij} (h_{ki} - h_{kj})^2 + \sum_{i \notin V_k, j \in V_k} w_{ij} (h_{ki} - h_{kj})^2 + \sum_{i \in V_k, j \notin V_k} w_{ij} (h_{ki} - h_{kj})^2 + \sum_{i \notin V_k, j \notin V_k} w_{ij} (h_{ki} - h_{kj})^2 ] = \frac{1}{2} [ \sum_{i \in V_k, j \in V_k} w_{ij} (\frac{1}{\sqrt{|V_k|}} - \frac{1}{\sqrt{|V_k|}})^2 + \sum_{i \notin V_k, j \in V_k} w_{ij} (0 - \frac{1}{\sqrt{|V_k|}})^2 + \sum_{i \in V_k, j \notin V_k} w_{ij} (\frac{1}{\sqrt{|V_k|}} - 0)^2 + \sum_{i \notin V_k, j \notin V_k} w_{ij} (0 - 0)^2 ] = \frac{1}{2} [ \sum_{i \notin V_k, j \in V_k} w_{ij} \frac{1}{|V_k|} + \sum_{i \in V_k, j \notin V_k} w_{ij} \frac{1}{|V_k|} ] cut(V_i, \overline{V_i}) = W (V_i, \overline{V_i}) = \sum_{i \in V_k, j \in \overline{V_k}} w_{ij} h_k^T L h_k = \frac{1}{2} [\frac{1}{|V_k|} cut(V_k, \overline{V_k}) + \frac{1}{|V_k|} cut(V_k, \overline{V_k})] = \frac{1}{|V_k|} cut(V_k, \overline{V_k})推到这里就能理解为什么要定义$h_k$了 RatioCut(V_1, ..., V_K) = \frac{1}{2} \sum_k h_k^T L h_k并且 h_k^T L h_k = tr(H^T L H) H^T L H = \left[ \begin{matrix} — & h_1^T & — \\ & ... & \\ — & h_K^T & — \\ \end{matrix} \right] L \left[ \begin{matrix} | & & | \\ h_1 & ... & h_K \\ | & & | \end{matrix} \right] = \left[ \begin{matrix} h_1^T L h_1 & ... & h_1^T L h_K \\ ... & ... & ... \\ h_K^T L h_K & ... & h_K^T L h_K \\ \end{matrix} \right] 所以最终优化目标为 \min_H tr(H^T L H) s.t. H^T H = I H^T H = \left[ \begin{matrix} h_1^T h_1 & ... & h_1^T h_K \\ ... & ... & ... \\ h_K^T h_K & ... & h_K^T h_K \\ \end{matrix} \right] 而矩阵的正交相似变换$A = P \Lambda P^{-1}$满足 tr(A) = tr(\Lambda) = \sum_i \lambda_i故 tr(H^T L H) = tr(L) = \sum_{i=1}^M \lambda_i$\lambda_i$为矩阵$L$的特征值。 我们再进行维度规约，将维度从$M$降到$k_1$，即找到$k_1$个最小的特征值之和。 N Cut推导过程与RatioCut完全一致，只是将分母$|V_i|$换成$vol(V_i)$ NCut(V_1, ..., V_K) = \frac{1}{2} \sum_k \frac{cut(V_i, \overline{V_i})}{vol(V_i)} cut(V_i, \overline{V_i}) = W (V_i, \overline{V_i}) vol(V_{sub}) = \sum_{i \in V_{sub}} d_i 计算步骤对于给定的$N$维数据集$X = (x^{(1)}, x^{(2)}, …, x^{(M)})$，将其划分为$K$类$(C_1, …, C_K)$ 根据输入的相似矩阵的生成方式构建样本的相似矩阵$S_{M×M}$； 根据相似矩阵$S$构建邻接矩阵$W_{M×M}$； 构建度矩阵$D_{M×M}$； 计算拉普拉斯矩阵$L_{M×M}$，可进行规范化$ L := D^{-1}L $； 对$L$进行特征值分解(EVD)，得到特征对$ (\lambda_i, \alpha_i), i=1,…,M $； 指定超参数$K_1$，选取$K_1$个最小特征值对应的特征向量组成矩阵$F_{M×K_1}$，并将其按行标准化； 以$F$的行向量作为新的样本数($k_1$维，这里也有降维操作)进行聚类，划分为$K$类，可使用K-means； 聚类结果即为输出结果 注意是$K_1$个最小特征值对应的特征向量，别问我为什么知道。。。 代码@Github: Spectral Clustering1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class SpectralClustering(): """ Attributes: k: &#123;int&#125;, k &lt; n_samples sigma: &#123;float&#125; Notes: Steps: - similarity matrix [W_&#123;n×n&#125;] - diagonal matrix [D_&#123;n×n&#125;] is defined as D_&#123;ii&#125; = \begin&#123;cases&#125; \sum_j W_&#123;ij&#125; &amp; i \neq j \\ 0 &amp; i = j \end&#123;cases&#125; - Laplacian matrix [L_&#123;n×n&#125;], Laplacian matrix is defined as L = D - W or L = D^&#123;-1&#125; (D - W) - EVD: L \alpha_i = \lambda_i \alpha_i - takes the eigenvector corresponding to the largest eigenvalue as B_&#123;n×k&#125; = [\beta_1, \beta_2, ..., \beta_k] - apply K-Means to the row vectors of matrix B """ def __init__(self, k, n_clusters=2, sigma=1.0): self.kmeans = KMeans(n_clusters=n_clusters) self.k = k self.sigma = sigma def predict(self, X): n_samples = X.shape[0] # step 1 kernelGaussian = lambda z, sigma: np.exp(-0.5 * np.square(z/sigma)) W = np.zeros((n_samples, n_samples)) for i in range(n_samples): for j in range(i): W[i, j] = kernelGaussian(np.linalg.norm(X[i] - X[j]), self.sigma) W[j, i] = W[i, j] # step 2 D = np.diag(np.sum(W, axis=1)) # step 3 L = D - W L = np.linalg.inv(D).dot(L) # step 4 eigval, eigvec = np.linalg.eig(L) # step 5 order = np.argsort(eigval) eigvec = eigvec[:, order] beta = eigvec[:, :self.k] # step 6 self.kmeans.fit(beta) return self.kmeans.labels_ DBSCANDBSCAN(Density-Based Spatial Clustering of Applications with Noise)，具有噪声的基于密度的聚类方法。假定类别可以通过样本分布的紧密程度决定。同一类别的样本，他们之间的紧密相连的。 DBSCAN密度聚类算法 - 刘建平Pinard - 博客园 原理先介绍几个关于密度的概念 $\epsilon$-邻域 对于样本$x^{(i)}$，其$\epsilon$-邻域包含样本集中与$x^{(i)}$距离不大于$\epsilon$的子样本集，其样本个数记作$|N_{\epsilon}(x^{(i)})|$。 N_{\epsilon}(x^{(i)}) = \{ x^{(j)} | d_{ij} \leq \epsilon \} 核心对象 对于任一样本$x^{(i)}$，若其$\epsilon$-邻域$N_{\epsilon}(x^{(i)})$至少包含$minPts$个样本，则该样本为核心对象。如图，选择若选取$\epsilon=5$，则红点均为核心对象 密度直达 若样本$x^{(j)} \in N_{\epsilon}(x^{(i)})$，且$x^{(i)}$为核心对象，则称$x^{(j)}$由$x^{(i)}$密度直达。不满足对称性，即反之不一定成立，除非$x^{(j)}$也为核心对象。如图，$x^{(8)}$可由$x^{(6)}$密度直达，而反之$x^{(6)}$不可由$x^{(8)}$密度直达，因为$x^{(8)}$不为核心对象。 密度可达 若存在样本序列$p_1, p_2, …, p_T$，满足$p_1 = x^{(i)}, p_T = x^{(j)}$，且$p_{t+1}$可由$p_t$密度直达，也就是说$p_1, p_2, …, p_{T-1}$均为核心对象，则称$x^{(j)}$由$x^{(i)}$密度可达。也不满足对称性。如图，$x^{(4)}$可由$x^{(1)}$密度可达，而$x^{(2)}$不可由$x^{(4)}$密度可达，因为$x^{(4)}$不为核心对象。 密度相连 存在核心对象$x^{(k)}$，使得$x^{(i)}$与$x^{(j)}$均由$x^{(k)}$密度可达，则称$x^{(i)}$与$x^{(j)}$密度相连。注意密度相连满足对称性。如图，$x^{(8)}$与$x^{(4)}$均可由$x^{(1)}$密度可达，则$x^{(8)}$与$x^{(4)}$密度相连。 计算思想DBSCAN的聚类思想是，由密度可达关系导出的最大密度相连的样本集合，即为我们最终聚类的一个簇，这个簇里可能只有一个核心对象，也可能有多个核心对象，若有多个，则簇里的任意一个核心对象的$\epsilon$-邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。 另外，考虑以下三个问题 噪音点 一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，这些样本点标记为噪音点，with Noise就是这个意思。 距离的度量 一般采用最近邻思想，采用某一种距离度量来衡量样本距离，比如欧式距离。这和KNN算法的最近邻思想完全相同。对应少量的样本，寻找最近邻可以直接去计算所有样本的距离，如果样本量较大，则一般采用KDTree或者球树来快速的搜索最近邻。 类别重复时的判别 某些样本可能到两个核心对象的距离都小于$\epsilon$，但是这两个核心对象如下图所示，不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？ 一般来说，此时DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说BDSCAN不是完全稳定的算法。 算法步骤对于给定的$N$维数据集$X = (x^{(1)}, x^{(2)}, …, x^{(M)})$，指定邻域参数$(\epsilon, minPts)$与样本距离度量方式，将其划分为$K$类。 检测数据库中尚未检查过的对象$p$，如果$p$未被处理(归为某个簇或者标记为噪声)，则检查其邻域： 若包含的对象数不小于$minPts$，建立新簇$C$，将其中的所有点加入候选集$N$； 对候选集$N$中所有尚未被处理的对象$q$，检查其邻域： 若至少包含$minPts$个对象，则将这些对象加入$N$； 如果$q$未归入任何一个簇，则将$q$加入$C$； 重复步骤$2$，继续检查$N$中未处理的对象，直到当前候选集$N$为空； 重复步骤$1$-$3$，直到所有对象都归入了某个簇或标记为噪声。 高斯混合模型(GMM)详情查看EM算法 &amp; GMM模型。 层次聚类(Hierarchical Clustering)层次聚类更多的是一种思想，而不是方法，通过从下往上不断合并簇，或者从上往下不断分离簇形成嵌套的簇。例如上面讲到的DBSCAN最后簇的合并就有这种思想。 层次的类通过“树状图”来表示，如下 主要的思想或方法有两种 自底向上的凝聚方法(agglomerative hierarchical clustering) 如AGNES。 自上向下的分裂方法(divisive hierarchical clustering) 如DIANA。 图团体检测(Graph Community Detection)略]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[EM & GMM]]></title>
    <url>%2F2018%2F11%2F12%2FEM-GMM%2F</url>
    <content type="text"><![CDATA[EM算法Expectation Maximization Algorithm，是 Dempster, Laind, Rubin 于 1977 年提出的求参数极大似然估计的一种方法，它可以从非完整数据集中对参数进行 MLE 估计，是一种非常简单实用的学习算法。这种方法可以广泛地应用于处理缺损数据，截尾数据，带有噪声等所谓的不完全数据。 引例：先挖个坑给出李航《统计学习方法》的三硬币模型例子，假设有$3$枚硬币$A, B, C$，各自出现正面的概率分别为$\pi, p, q$，先进行如下实验：先投掷硬币$A$，若结果为正面，则选择硬币$B$投掷一次，否则选择$C$，记录投掷结果如下 1, 1, 0, 1, 0, 0, 1, 0, 1, 1只能观测到实验结果，而投掷过程未知，即硬币$A$的投掷结果未知，现欲估计三枚硬币的参数$\pi, p, q$。 解：根据题意可以得到三个随机变量$X_1, X_2, X_3$的概率分布如下 P(X_1) = \pi ^ {X_1} (1 - \pi) ^ {1 - X_1} P(X_2) = p ^ {X_2} (1 - p) ^ {1 - X_2} P(X_3) = q ^ {X_3} (1 - q) ^ {1 - X_3}定义随机变量$X$表示观测结果为正面，由全概率公式可以得到 P(X) = P(X|X_1)P(X_1) + P(X|\overline{X_1})P(\overline{X_1}) = \pi p + (1 - \pi) q P(\overline{X}) = P(\overline{X}|X_1)P(X_1) + P(\overline{X}|\overline{X_1})P(\overline{X_1}) = \pi (1 - p) + (1 - \pi) (1 - q)即 P(X) = [\pi p + (1 - \pi) q] ^ {X} [\pi (1 - p) + (1 - \pi) (1 - q)] ^ {1 - X}利用最大似然估计，有 \log L(D | \theta) = 6 \log [\pi p + (1 - \pi) q] + 4 \log [\pi (1 - p) + (1 - \pi) (1 - q)]至此，我们一定能想到通过求似然函数极值来求解参数 \frac{∂ }{∂ \pi} \log L = 0 \Rightarrow 5 \pi (p - q) + 5q - 3 = 0 \frac{∂ }{∂ p} \log L = 0 \Rightarrow 5 \pi (p - q) + 5q - 3 = 0 \frac{∂ }{∂ q} \log L = 0 \Rightarrow 5 \pi (p - q) + 5q - 3 = 0但是好像出了问题，并不能求解，所以我们引入EM算法迭代求解。 推导以$x^{(i)}$表示训练数据，$w_k$表示类别，设当前迭代参数为$\theta^{(t)}$，则下一次迭代应有 \theta^{(t+1)} = \arg \max \sum_i \log P(x^{(i)}|\theta) \tag{1}由边缘概率公式 \sum_i \log P(x^{(i)}|\theta) = \sum_i \log \sum_k P(x^{(i)}, w_k^{(i)}|\theta) \tag{2} $P(x^{(i)}, w_k^{(i)}|\theta) = P(x^{(i)} | w_k^{(i)}, \theta) P(w_k^{(i)}|x^{(i)}, \theta)$至此已得出引例中的表达式，其中$P(w_k^{(i)}|x^{(i)}, \theta)$与$P(x^{(i)} | w_k^{(i)}, \theta)$均未知，而通过求极值不能解得参数。 我们引入迭代参数$\theta^{(t)}$，即第$t$次迭代时的参数$\theta$，该参数为已知变量 \sum_i \log P(x^{(i)}|\theta) = \sum_i \log \sum_k P(x^{(i)}, w_k^{(i)}|\theta) \frac{P(w_k^{(i)} | \theta^{(t)})} {P(w_k^{(i)} | \theta^{(t)})} $P(w_k^{(i)}|\theta^{(t)})$表示样本$x^{(i)}$类别为$w_k^{(i)}$的概率，注意上标。 引入Jensen不等式： For a real convex function $\varphi$, numbers $x_1, …, x_n$ in its domain, and positive weights $a_i$, Jensen’s inequality can be stated as: \varphi\left(\frac{\sum a_i x_i}{\sum a_i}\right) \leq \frac{\sum a_i \varphi(x_i)}{\sum a_i}and the inquality is reversed if $\varphi$ is concave, which is \varphi\left(\frac{\sum a_i x_i}{\sum a_i}\right) \geq \frac{\sum a_i \varphi(x_i)}{\sum a_i}Equality holds if and only if $x_1 = … = x_n$ or $\varphi$ is linear. $\log(·)$为凹函数(concave)，且满足 \sum_k P(w_k^{(i)} | \theta^{(t)}) = 1所以有 \sum_i \log P(x^{(i)}|\theta) = \sum_i \log \sum_k P(x^{(i)}, w_k^{(i)}|\theta) \frac{P(w_k^{(i)}|\theta^{(t)})} {P(w_k^{(i)}|\theta^{(t)})} \geq \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta^{(t)})} \tag{3}此时我们得到似然函数$\sum_i \log P(x^{(i)}|\theta)$的一个下界，但必须保证这个下界是紧的，也就是至少有点能使等号成立 由Jensen不等式，当且仅当$ P(x^{(i)}, w_k^{(i)}|\theta)=C $时取等号 定义 L(\theta|\theta^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta^{(t)})} = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log P(x^{(i)}, w_k^{(i)}|\theta) - P(w_k^{(i)}|\theta^{(t)}) \log P(w_k^{(i)}|\theta^{(t)})其中第一项即期望 E_w\left[ \log P(X, w|\theta) | X, \theta^{(t)} \right] = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log P(x^{(i)}, w_k^{(i)}|\theta) \tag{4}第二项为$P(w | X, \theta^{(t)})$的信息熵 H[P(w | X, \theta^{(t)})] = - \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log P(w_k^{(i)}|\theta^{(t)}) \tag{5}即 L(\theta|\theta^{(t)}) = E_w\left[ \log P(X, w|\theta) | X, \theta^{(t)} \right] + H[P(w | X, \theta^{(t)})] \tag{E-step} 注意到$H[P(w | X, \theta^{(t)})]$项为常数，故也可设 Q(\theta|\theta^{(t)}) = E_w\left[ \log P(X, w|\theta) | X, \theta^{(t)} \right] 代回$(1)$，得到优化目标 \theta^{(t+1)} = \arg \max L(\theta|\theta^{(t)}) \tag{M-step}我们需要不断最大化$L(\theta | \theta^{(t)})$来不断优化，这就是所谓的EM算法，E-step是指求出期望，M-step是指迭代更新参数 伪代码如下123456According to prior knowledge set $\theta$Repeat until convergence&#123; E-step: The expectation of hidden variables M-step: Finding the maximum of likelihood function&#125; 实际上，从边缘概率与条件概率入手 \sum_i \log P(x^{(i)}|\theta) = \sum_i \log \sum_k P(x^{(i)}, w_k^{(i)}|\theta) = \sum_i \log \sum_k P(x^{(i)} | w_k^{(i)}, \theta) P(w_k^{(i)} | \theta) \geq \sum_i \sum_k P(w_k^{(i)} | \theta) \log P(x^{(i)} | w_k^{(i)}, \theta) \tag{Jensen inequality} = \sum_i \sum_k P(w_k^{(i)} | \theta) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta)}而由$(3)$，引入迭代变量可以得到 \sum_i \log P(x^{(i)}|\theta) \geq L(\theta|\theta^{(t)})其中 L(\theta|\theta^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta^{(t)})}则 \sum_i \log P(x^{(i)}|\theta) - L(\theta|\theta^{(t)}) = \sum_i \sum_k P(w_k^{(i)} | \theta) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta)} - \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log \frac{P(x^{(i)}, w_k^{(i)}|\theta)}{P(w_k^{(i)}|\theta^{(t)})} = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log \frac{P(w_k^{(i)}|\theta^{(t)})}{P(w_k^{(i)}|\theta)}而由KL散度( Kullback–Leibler divergence)(又称相对熵(relative entropy))定义 D(P||Q) = \sum P(x) \log \frac{P(x)}{Q(x)} 可知 \sum_i \log P(x^{(i)}|\theta) - L(\theta|\theta^{(t)}) = D\left[ P(w_k^{(i)}|\theta^{(t)}) || P(w_k^{(i)}|\theta) \right]即迭代的$P(w_k^{(i)}|\theta^{(t)})$与真实的$P(w_k^{(i)}|\theta)$之间的相对熵！ 这里关于K-L散度的困扰了$N$久，终于搞出来了。 引例的求解 $Q(\theta|\theta^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log P(x^{(i)}, w_k^{(i)}|\theta)$ 此题中 P(w_k|\pi) = \pi^{w_k}(1-\pi)^{1-w_k} P(x | w_1, p) = p^{x^{(i)}}(1-p)^{1-x^{(i)}} P(x | w_2, q) = q^{x^{(i)}}(1-q)^{1-x^{(i)}} $E-step$ Q(\pi, p, q | \pi^{(t)}, p^{(t)}, q^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)}) \log P(x^{(i)}, w_k^{(i)} | \pi, p, q) 先求$P(w_k^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)})$，即第一次投掷结果为$w_k$的概率 P(w_k^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)}) = \frac {\left[\pi^{(t)}p^{(t)x^{(i)}}(1-p^{(t)})^{1-x^{(i)}}\right]^{w_k} \left[(1-\pi^{(t)})q^{(t)x^{(i)}}(1-q^{(t)})^{1-x^{(i)}}\right]^{1-w_k}} {\sum_j \left[\pi^{(t)}p^{(t)x^{(i)}}(1-p^{(t)})^{1-x^{(i)}}\right]^{w_j} \left[(1-\pi^{(t)})q^{(t)x^{(i)}}(1-q^{(t)})^{1-x^{(i)}}\right]^{1-w_j}} 即 \begin{cases} P(w_1^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)}) = \frac {\pi^{(t)}p^{(t)x^{(i)}}(1-p^{(t)})^{1-x^{(i)}}} {\pi^{(t)}p^{(t)x^{(i)}}(1-p^{(t)})^{1-x^{(i)}} + (1-\pi^{(t)})q^{(t)x^{(i)}}(1-q^{(t)})^{1-x^{(i)}}} \\ P(w_2^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)}) = \frac {(1-\pi^{(t)})q^{(t)x^{(i)}}(1-q^{(t)})^{1-x^{(i)}}} {\pi^{(t)}p^{(t)x^{(i)}}(1-p^{(t)})^{1-x^{(i)}} + (1-\pi^{(t)})q^{(t)x^{(i)}}(1-q^{(t)})^{1-x^{(i)}}} \end{cases} 记 \mu_1^{(i)} = P(w_1^{(i)}|\pi^{(t)}, p^{(t)}, q^{(t)})\mu_2^{(i)} = 1 - \mu_1^{(i)} 注意$w^{(i)}_k$上标^{(i)} 再求$P(x^{(i)}, w_k^{(i)} | \pi, p, q)$，已知 P(x^{(i)}, w_k^{(i)} | \pi, p, q) = P(x^{(i)} | w_k^{(i)}, \pi, p, q) P(w_k^{(i)} | \pi, p, q) 所以 P(x^{(i)}, w_k^{(i)} | \pi, p,q) = \left[\pi p^{x^{(i)}}(1-p)^{1-x^{(i)}}\right]^{w_k} \left[(1-\pi)q^{x^{(i)}}(1-q)^{1-x^{(i)}}\right]^{1-w_k} 综上 Q(\pi, p, q | \pi^{(t)}, p^{(t)}, q^{(t)}) = \sum_i \sum_{k=1}^2 \mu^{(i)}_k \left[\pi p^{x^{(i)}}(1-p)^{1-x^{(i)}}\right]^{w_k} \left[(1-\pi)q^{x^{(i)}}(1-q)^{1-x^{(i)}}\right]^{1-w_k} = \sum_i \mu_1^{(i)} \log \pi p^{x^{(i)}}(1-p)^{1-x^{(i)}} + (1 - \mu_1^{(i)}) \log (1-\pi) q^{x^{(i)}}(1-q)^{1-x^{(i)}} $M-step$ $\frac{∂Q}{∂\pi} = 0$ \frac{∂Q}{∂\pi} = \sum_i \mu_1^{(i)} \frac {p^{x^{(i)}}(1-p)^{1-x^{(i)}}} {\pi p^{x^{(i)}}(1-p)^{1-x^{(i)}}} + (1 - \mu_1^{(i)}) \frac {- q^{x^{(i)}}(1-q)^{1-x^{(i)}}} {(1-\pi) q^{x^{(i)}}(1-q)^{1-x^{(i)}}} = \sum_i \frac{\mu_1^{(i)}}{\pi} + \frac{\mu_1^{(i)} - 1}{1 - \pi} = \sum_i \frac{\mu_1^{(i)} - \pi}{\pi(1 - \pi)} = \frac{\sum_i \mu_1^{(i)} - n\pi}{\pi(1 - \pi)} = 0 \Rightarrow \pi^{(t+1)} = \frac{1}{n} \sum_i \mu_1^{(i)} $\frac{∂Q}{∂p} = 0$ \frac{∂Q}{∂p} = \sum_i \mu_1^{(i)} \left[ \frac{x^{(i)}}{p} - \frac{1 - x^{(i)}}{1 - p} \right] = \frac{1}{p(1 - p)} \sum_i \mu_1^{(i)} (x^{(i)} - p) = \frac{1}{p(1 - p)} \left[ \sum_i \mu_1^{(i)} x^{(i)} - p \sum_i \mu_1^{(i)} \right] = 0 \Rightarrow p^{(t+1)} = \frac{\sum_i \mu_1^{(i)} x^{(i)}}{\sum_i \mu_1^{(i)}} $\frac{∂Q}{∂q} = 0$ \frac{∂Q}{∂q} = \sum_i (1 - \mu_1^{(i)}) \left[ \frac{x^{(i)}}{q} - \frac{1 - x^{(i)}}{1 - q} \right] = \frac{1}{q(1 - q)} \sum_i (1 - \mu_1^{(i)}) (x^{(i)} - q) = \frac{1}{q(1 - q)} \left[ \sum_i (1 - \mu_1^{(i)}) x^{(i)} - q \sum_i (1 - \mu_1^{(i)}) \right] = 0 \Rightarrow q^{(t+1)} = \frac{\sum_i (1 - \mu_1^{(i)}) x^{(i)}}{\sum_i (1 - \mu_1^{(i)})} 多次迭代即可求解，终止条件可设置为 || \theta^{(t+1)} - \theta^{(t)} || < \epsilon或 ||Q(\theta^{(t+1)} | \theta^{(t)}) - Q(\theta^{(t)} |\theta^{(t)})|| < \epsilonGMM模型Gaussian Mixture Model，是一种无监督学习算法，常用于聚类。当聚类问题中各个类别的尺寸不同、聚类间有相关关系的时候，往往使用GMM更合适。对一个样本来说，GMM得到的是其属于各个类的概率(通过计算后验概率得到)，而不是完全的属于某个类，这种聚类方法被成为软聚类。一般说来， 任意形状的概率分布都可以用多个高斯分布函数去近似，因而，GMM的应用也比较广泛。 高斯混合模型，指具有如下形式的概率分布模型： P(x|\mu_k, \Sigma_k) = \sum_{k=1}^K \pi_k N(x|\mu_k, \Sigma_k)其中 $\pi_k(0 \leq \pi_k \leq 1)$是系数，且$\sum_k \pi_k = 1$ $N(x|\mu_k, \Sigma_k)$为高斯密度函数 N(x|\mu_k, \Sigma_k) = \frac{1}{(2\pi)^{n/2}|\Sigma_k|^{1/2}} \exp \left[ -\frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) \right] 即多个高斯分布叠加出来的玩意； 现在我们需要求取系数$\pi_k$及高斯模型的参数$(\mu_k, \Sigma_k)$； 与K-Means等聚类方法区别是，GMM求出的是连续的分布模型，可计算出“归属于”哪一类的概率。 推导 \log P(X|\pi, \mu, \Sigma) = \sum_i \log \sum_k \pi_k N(x|\mu_k, \Sigma_k) s.t. \sum_k \pi_k = 1暴力求解以$1$维高斯分布为例 N(x|\mu_k, \sigma_k^2) = \frac{1}{\sqrt{2\pi}\sigma_k} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}}构造拉格朗日(Lagrange)函数 L(\pi, \mu, \sigma^2) = \sum_i \log \sum_k \pi_k N(x|\mu_k, \sigma_k^2) + \lambda \left(\sum_k \pi_k - 1 \right) \tag{5} \begin{cases} \frac{∂}{∂\pi_k} L(\pi, \mu, \sigma^2) = \sum_i \frac{N(x^{(i)}|\mu_k, \sigma_k^2)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} + \lambda \\ \frac{∂}{∂\mu_k} L(\pi, \mu, \sigma^2) = \sum_i \frac{\pi_k}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} \frac{∂}{∂\mu_k}N(x^{(i)}|\mu_k, \sigma_k^2) \\ \frac{∂}{∂\sigma_k^2} L(\pi, \mu, \sigma^2) = \sum_i \frac{\pi_k}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} \frac{∂}{∂\sigma_k^2}N(x^{(i)}|\mu_k, \sigma_k^2) \end{cases} \tag{6}其中 \frac{∂}{∂\mu_k} N(x|\mu_k, \sigma_k^2) = \frac{1}{\sqrt{2\pi}\sigma_k} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}} \frac{x-\mu_k}{\sigma_k^2} = N(x|\mu_k, \sigma_k^2) · \frac{x-\mu_k}{\sigma_k^2} \frac{∂}{∂\sigma_k^2} N(x|\mu_k, \sigma_k^2) = \frac{1}{\sqrt{2\pi}} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}} \frac{∂}{∂\sigma_k^2} \left(\frac{1}{\sigma_k}\right) + \frac{1}{\sqrt{2\pi}\sigma_k} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}} \left(-\frac{(x - \mu_k)^2}{2}\right) \frac{∂}{∂\sigma_k^2} \left(\frac{1}{\sigma_k^2}\right) $\frac{∂}{∂\sigma_k^2} \left(\frac{1}{\sigma_k}\right) = - \frac{\sigma_k^{-3}}{2}; \frac{∂}{∂\sigma_k^2} \left(\frac{1}{\sigma_k^2}\right) = - \frac{1}{\sigma_k^4}$ = \frac{1}{\sqrt{2\pi}} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}} \left(- \frac{\sigma_k^{-3}}{2}\right) + \frac{1}{\sqrt{2\pi}\sigma_k} e^{-\frac{(x - \mu_k)^2}{2\sigma_k^2}} \left(-\frac{(x - \mu_k)^2}{2}\right) \left(- \frac{1}{\sigma_k^4}\right) = N(x|\mu_k, \sigma_k^2) \left[ \frac{(x - \mu_k)^2}{\sigma_k^2} - 1 \right] \frac{1}{2 \sigma_k^2}代回$(6)$可以得到 \begin{cases} \frac{∂}{∂\pi_k} L(\pi, \mu, \sigma^2) = \sum_i \frac{N(x^{(i)}|\mu_k, \sigma_k^2)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} + \lambda \\ \frac{∂}{∂\mu_k} L(\pi, \mu, \sigma^2) = \sum_i \frac{\pi_k N(x^{(i)}|\mu_k, \sigma_k^2)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} \frac{x^{(i)}-\mu_k}{\sigma_k^2} \\ \frac{∂}{∂\sigma_k^2} L(\pi, \mu, \sigma^2) = \sum_i \frac{\pi_k N(x^{(i)}|\mu_k, \sigma_k^2)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} \left[ \frac{(x^{(i)} - \mu_k)^2}{\sigma_k^2} - 1 \right] \frac{1}{2 \sigma_k^2} \end{cases} \tag{7}令 \gamma^{(i)}_k = \frac{\pi_k N(x^{(i)}|\mu_k, \sigma_k^2)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \sigma_j^2)} \tag{8} 通俗理解：$\gamma^{(i)}_k$表示样本$x^{(i)}$中来自类别$w_k$的“贡献百分比” 令$\frac{∂}{∂\mu_k} \log P(X|\pi, \mu, \sigma^2) = 0$，整理得到 \sum_i \gamma^{(i)}_k (x^{(i)} - \mu_k) = 0 \Rightarrow \mu_k = \frac{\sum_i \gamma^{(i)}_k x^{(i)}}{\sum_i \gamma^{(i)}_k} 令$\frac{∂}{∂\sigma_k^2} \log P(X|\pi, \mu, \sigma^2) = 0$，整理得到 \sum_i \gamma^{(i)}_k \left[ \frac{(x^{(i)} - \mu_k)^2}{\sigma_k^2} - 1 \right] = 0 \Rightarrow \sigma_k^2 = \frac{\sum_i \gamma^{(i)}_k (x^{(i)} - \mu_k)^2}{\sum_i \gamma^{(i)}_k} 对于$\frac{∂}{∂\pi_k} \log P(X|\pi, \mu, \sigma^2) = 0$，需要做一点处理 两边同乘$\pi_k$，得到 \sum_i \gamma^{(i)}_k = - \lambda \pi_k \tag{9} 然后两边对$k$作累加 \sum_k \sum_i \gamma^{(i)}_k = - \lambda \sum_k \pi_k $\sum_k \sum_i \gamma^{(i)}_k = \sum_i \sum_k \gamma^{(i)}_k = N, \sum_k \pi_k = 1$ N = - \lambda 或 \lambda = -N \tag{10} 代回$(9)$，得到 \pi_k = \frac{\sum_i \gamma^{(i)}_k}{N} 综上，我们得到$4$个用于迭代的计算式，将其推广至多维即 \gamma^{(i)}_k = \frac{\pi_k N(x^{(i)}|\mu_k, \Sigma_k)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \Sigma_j)} \mu_k = \frac{\sum_i \gamma^{(i)}_k x^{(i)}}{\sum_i \gamma^{(i)}_k} \Sigma_k = \frac{\sum_i \gamma^{(i)}_k (x^{(i)} - \mu_k) (x^{(i)} - \mu_k)^T}{\sum_i \gamma^{(i)}_k} \pi_k = \frac{\sum_i \gamma^{(i)}_k}{N}用EM算法求解 $Q(\theta|\theta^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\theta^{(t)}) \log P(x^{(i)}, w_k^{(i)}|\theta)$ Q(\mu_k, \Sigma_k|\mu_k^{(t)}, \Sigma_k^{(t)}) = \sum_i \sum_k P(w_k^{(i)}|\mu_k^{(t)}, \Sigma_k^{(t)}) \log P(x^{(i)}, w_k^{(i)}|\mu_k, \Sigma_k) $ M-step $ P(w_k^{(i)}|\mu_k^{(t)}, \Sigma_k^{(t)}) = \frac{\pi_k N(x^{(i)}|\mu_k, \Sigma_k)}{\sum_j \pi_j N(x^{(i)}|\mu_j, \Sigma_j)} = \gamma^{(i)}_k P(x^{(i)}, w_k^{(i)}|\mu_k, \Sigma_k) = P(x^{(i)} | w_k^{(i)}, \mu_k, \Sigma_k) P(w_k^{(i)}|\mu_k, \Sigma_k) = \pi_k N(x^{(i)}|\mu_k, \Sigma_k) 故 Q(\mu_k, \Sigma_k|\mu_k^{(t)}, \Sigma_k^{(t)}) = \sum_i \sum_k \gamma^{(i)}_k \log \pi_k N(x^{(i)}|\mu_k, \Sigma_k) 通过求解极值可得到与$\underline{暴力求解}$一样的等式，即 \gamma^{(i)(t)}_k = \frac{\pi^{(t)}_k N(x^{(i)}|\mu_k^{(t)}, \Sigma_k^{(t)})}{\sum_j \pi_j^{(t)} N(x^{(i)}|\mu_j^{(t)}, \Sigma_j^{(t)})} \mu_k^{(t+1)} = \frac{\sum_i \gamma^{(i)(t)}_k x^{(i)}}{\sum_i \gamma^{(i)(t)}_k} \Sigma_k^{(t+1)} = \frac{\sum_i \gamma^{(i)(t)}_k (x^{(i)} - \mu_k) (x^{(i)} - \mu_k)^T}{\sum_i \gamma^{(i)(t)}_k} \pi_k^{(t+1)} = \frac{\sum_i \gamma^{(i)(t)}_k}{N} 伪代码为 123456789101112According to prior knowledge set \pi^&#123;(t)&#125;(n_clusters,) \mu^&#123;(t)&#125;(n_clusters, n_features) \Sigma^&#123;(t)&#125;(n_clusters, n_features, n_features)Repeat until convergence&#123; # E-step: calculate \gamma^&#123;(t)&#125; \gamma(n_samples, n_clusters) # M-step: update \pi, \mu, \Sigma \pi^&#123;(t+1)&#125;(n_clusters,) \mu^&#123;(t+1)&#125;(n_clusters, n_features) \Sigma^&#123;(t+1)&#125;(n_clusters, n_features, n_features)&#125; 初始点的选择可以随机选择，也可使用K-Means GMM算法收敛过程如下 代码@Github: GMM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class GMM(): """ Gaussian Mixture Model Attributes: n_clusters &#123;int&#125; prior &#123;ndarray(n_clusters,)&#125; mu &#123;ndarray(n_clusters, n_features)&#125; sigma &#123;ndarray(n_clusters, n_features, n_features)&#125; """ def __init__(self, n_clusters): self.n_clusters = n_clusters self.prior = None self.mu = None self.sigma = None def fit(self, X, delta=0.01): """ Args: X &#123;ndarray(n_samples, n_features)&#125; delta &#123;float&#125; Notes: - Initialize with k-means """ (n_samples, n_features) = X.shape # initialize with k-means clf = KMeans(n_clusters=self.n_clusters) clf.fit(X) self.mu = clf.cluster_centers_ self.prior = np.zeros(self.n_clusters) self.sigma = np.zeros((self.n_clusters, n_features, n_features)) for k in range(self.n_clusters): X_ = X[clf.labels_==k] self.prior[k] = X_.shape[0] / X_.shape[0] self.sigma[k] = np.cov(X_.T) while True: mu_ = self.mu.copy() # E-step: updata gamma gamma = np.zeros((n_samples, self.n_clusters)) for i in range(n_samples): for k in range(self.n_clusters): denominator = 0 for j in range(self.n_clusters): post = self.prior[k] *\ multiGaussian(X[i], self.mu[j], self.sigma[j]) denominator += post if j==k: numerator = post gamma[i, k] = numerator/denominator # M-step: updata prior, mu, sigma for k in range(self.n_clusters): sum1 = 0 sum2 = 0 sum3 = 0 for i in range(n_samples): sum1 += gamma[i, k] sum2 += gamma[i, k] * X[i] x_ = np.reshape(X[i] - self.mu[k], (n_features, 1)) sum3 += gamma[i, k] * x_.dot(x_.T) self.prior[k] = sum1 / n_samples self.mu[k] = sum2 / sum1 self.sigma[k] = sum3 / sum1 # to stop mu_delta = 0 for k in range(self.n_clusters): mu_delta += nl.norm(self.mu[k] - mu_[k]) print(mu_delta) if mu_delta &lt; delta: break return self.prior, self.mu, self.sigma def predict_proba(self, X): """ Args: X &#123;ndarray(n_samples, n_features)&#125; Returns: y_pred_proba &#123;ndarray(n_samples, n_clusters)&#125; """ (n_samples, n_features) = X.shape y_pred_proba = np.zeros((n_samples, self.n_clusters)) for i in range(n_samples): for k in range(self.n_clusters): y_pred_proba[i, k] = self.prior[k] *\ multiGaussian(X[i], self.mu[k], self.sigma[k]) return y_pred_proba def predict(self, X): """ Args: X &#123;ndarray(n_samples, n_features)&#125; Returns: y_pred_proba &#123;ndarray(n_samples,)&#125; """ y_pred_proba = self.predict_proba(X) return np.argmax(y_pred_proba, axis=1)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Data Augmentation]]></title>
    <url>%2F2018%2F11%2F02%2FData-Augmentation%2F</url>
    <content type="text"><![CDATA[“有时候不是由于算法好赢了。而是由于拥有很多其它的数据才赢了。” 数据集扩增在深度学习中,很多训练数据意味着能够用更深的网络，训练出更好的模型。既然这样，收集很多其它的数据不即可啦？假设能够收集很多其它能够用的数据当然好，比如ImageNet上图像数据量已达到$1400$万张，可是非常多时候，收集很多其它的数据意味着须要耗费很多其它的人力物力，这就需要使用一定的方法扩增数据集。 图像扩增大部分借助OpenCV库，这里推荐一位学长的博客，整理了大量的OpenCV使用方法. Ex2tron’s Blog TensorFlow也提供相应图像处理方法Module: tf.image | TensorFlow 需要注意的是，扩增过程中，需注意图像数据类型，可以将数据归一化到$(0, 1)$间再进行处理 翻转12345678def flip(image): """ Parameters: image &#123;ndarray(H, W, C)&#125; """ rand_var = np.random.random() image = image[:, ::-1, :] if rand_var &gt; 0.5 else image return image 旋转123456789101112def rotate(image, degree): """ Parameters: image &#123;ndarray(H, W, C)&#125; degree &#123;float&#125; """ (h, w) = image.shape[:2] center = (w // 2, h // 2) random_angel = np.random.randint(-degree, degree) M = cv2.getRotationMatrix2D(center, random_angel, 1.0) image = cv2.warpAffine(image, M, (w, h)) return image 噪声可手动实现，如椒盐噪声代码如下12345678910111213141516def saltnoise(image, salt=0.0): """ add salt &amp; pepper and gaussian noise Parameters: image &#123;ndarray(H, W, C)&#125; salt &#123;float(0, 1)&#125; number of salt pixel = salt*h*w Notes: TODO: gaussain noise """ (h, w) = image.shape[:2] n_salt = int(salt * h * w) for n in range(n_salt): hr = np.random.randint(0, h) wr = np.random.randint(0, w) issalt = (np.random.rand(1) &gt; 0.5) image[hr, wr] = 255 if issalt else 0 return image 也可调用scikit-image库，需要注意的是，skimage.util.random_noise()会将原图数据转换为$(0, 1)$间的浮点数1234567891011121314151617def noise(image, gaussian, salt, seed=None): """ add noise to image TODO Parameters: image &#123;ndarray(H, W, C)&#125; gaussian &#123;bool&#125;: salt &#123;bool&#125;: Notes: Function to add random noise of various types to a floating-point image. """ dtype = image.dtype if gaussian: image = skimage.util.random_noise(image, mode='gaussian', seed=seed) if salt: image = skimage.util.random_noise(image, mode='s&amp;p', seed=seed) image = (image * 255).astype(dtype) return image 亮度与对比度调整考虑到数据溢出，先转换为整形数据，再限制其值到$[0, 255]$ 注意数据类型 1234567891011def brightcontrast(image, brtadj=0, cstadj=1.0): """ adjust bright and contrast value Parameters: image &#123;ndarray(H, W, C)&#125; brtadj &#123;int&#125; if true, adjust bright cstadj &#123;float&#125; if true, adjust contrast """ dtype = image.dtype image = image.astype('int')*cstadj + brtadj image = np.clip(image, 0, 255).astype(dtype) return image 投射变换1234567891011121314151617181920212223242526def perspective(image, prop): """ 透射变换 Parameters: image &#123;ndarray(H, W, C)&#125; prop &#123;float&#125;: 在四个顶点多大的方格内选取新顶点，方格大小为(H*prop, W*prop) Notes: 在四个顶点周围随机选取新的点进行仿射变换，四个点对应左上、右上、左下、右下 """ (h, w) = image.shape[:2] ptsrc = np.zeros(shape=(4, 2)) ptdst = np.array([[0, 0], [0, w], [h, 0], [h, w]]) for i in range(4): hr = np.random.randint(0, int(h*prop)) wr = np.random.randint(0, int(w*prop)) if i == 0: ptsrc[i] = np.array([hr, wr]) elif i == 1: ptsrc[i] = np.array([hr, w - wr]) elif i == 2: ptsrc[i] = np.array([h - hr, wr]) elif i == 3: ptsrc[i] = np.array([h - hr, w - wr]) M = cv2.getPerspectiveTransform(ptsrc.astype('float32'), ptdst.astype('float32')) image = cv2.warpPerspective(image, M, (w, h)) return image]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二次入坑raspberry-pi]]></title>
    <url>%2F2018%2F10%2F29%2F%E4%BA%8C%E6%AC%A1%E5%85%A5%E5%9D%91raspberry-pi%2F</url>
    <content type="text"><![CDATA[前言距上一次搭建树莓派平台已经两年了，保存的镜像出了问题，重新搭建一下。 系统下载从官网下载树莓派系统镜像，有以下几种可选 Raspberry Pi — Teach, Learn, and Make with Raspberry Pi Raspbian &amp; Raspbian Lite，基于Debian Noobs &amp; Noobs Lite Ubuntu MATE Snappy Ubuntu Core Windows 10 IOT 其余不太了解，之前安装的是Raspbian，对于Debian各种不适，换上界面优雅的Ubuntu Mate玩一下老老实实玩Raspbian，笑脸:-) 安装比较简单，准备micro-SD卡，用Win32 Disk Imager烧写镜像 Win32 Disk Imager download | SourceForge.net 安装完软件后可点击Read备份自己的镜像。 注意第二次开机前需要配置config.txt文件，否则hdmi无法显示 树莓派配置文档 config.txt 说明 | 树莓派实验室 123456disable_overscan=1 hdmi_force_hotplug=1hdmi_group=2 # DMThdmi_mode=32 # 1280x960hdmi_drive=2config_hdmi_boost=4 修改交换分区Ubuntu Mate查看交换分区1$ free -m 未设置时如下1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 0 0 0 创建和挂载12345678910111213141516# 获取权限$ sudo -i# 创建目录$ mkdir /swap$ cd /swap# 指定一个大小为1G的名为“swap”的交换文件$ dd if=/dev/zero of=swap bs=1M count=1k# 创建交换文件$ mkswap swap# 挂载交换分区$ swapon swap# 卸载交换分区# $ swapoff swap 查看交换分区1$ free -m 未设置时如下1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 RaspbianWe will change the configuration in the file /etc/dphys-swapfile:1$ sudo nano /etc/dphys-swapfile The default value in Raspbian is:1CONF_SWAPSIZE=100 We will need to change this to:1CONF_SWAPSIZE=1024 Then you will need to stop and start the service that manages the swapfile own Rasbian:12$ sudo /etc/init.d/dphys-swapfile stop$ sudo /etc/init.d/dphys-swapfile start You can then verify the amount of memory + swap by issuing the following command:1$ free -m The output should look like:1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 软件安装指令 apt-get 安装软件apt-get install softname1 softname2 softname3 ... 卸载软件apt-get remove softname1 softname2 softname3 ... 卸载并清除配置apt-get remove --purge softname1 更新软件信息数据库apt-get update 进行系统升级apt-get upgrade 搜索软件包apt-cache search softname1 softname2 softname3 ... 修正（依赖关系）安装：apt-get -f insta dpkg 安装.deb软件包dpkg -i xxx.deb 删除软件包dpkg -r xxx.deb 连同配置文件一起删除dpkg -r --purge xxx.deb 查看软件包信息dpkg -info xxx.deb 查看文件拷贝详情dpkg -L xxx.deb 查看系统中已安装软件包信息dpkg -l 重新配置软件包dpkg-reconfigure xx 卸载软件包及其配置文件，但无法解决依赖关系！sudo dpkg -p package_name 卸载软件包及其配置文件与依赖关系包sudo aptitude purge pkgname 清除所有已删除包的残馀配置文件dpkg -l |grep ^rc|awk &#39;{print $2}&#39; |sudo xargs dpkg -P 软件源 备份原始文件 1$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup 修改文件并添加国内源 1$ vi /etc/apt/sources.list 注释元文件内的源并添加如下地址 123456789101112131415161718192021#Mirror.lupaworld.com 源更新服务器（浙江省杭州市双线服务器，网通同电信都可以用，亚洲地区官方更新服务器）：deb http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiverse#Ubuntu 官方源 deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse 或者 1234567891011121314151617181920212223#阿里云deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse#网易163deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse 放置非官方源的包不完整，可在为不添加官方源 1deb http://archive.ubuntu.org.cn/ubuntu-cn/ feisty main restricted universe multiverse 更新源 1$ sudo apt-get update 更新软件 1$ sudo apt-get dist-upgrade 常见的修复安装命令 1$ sudo apt-get -f install Python主要是Python和相关依赖包的安装，使用以下指令可导出已安装的依赖包1$ pip freeze &gt; requirements.txt 并使用指令安装到树莓派1$ pip install -r requirements.txt 注意pip更新1python -m pip install --upgrade pip 最新版本会报错1ImportError: cannot import name main 修改文件/usr/bin/pip123from pip import mainif __name__ == '__main__': sys.exit(main()) 改为123from pip import __main__if __name__ == '__main__': sys.exit(__main__._main()) 成功!!!失败了，笑脸:-)，手动安装吧。。。 部分包可使用pip3 123$ pip3 install numpy$ pip3 install pandas$ pip3 install sklearn 若需要权限，加入--user 部分包用apt-get，但是优先安装到Python2.7版本，笑脸:-) 123$ sudo apt-get install python-scipy$ sudo apt-get install python-matplotlib$ sudo apt-get install python-opencv 部分从PIPY下载.whl或.tar.gz文件 PyPI – the Python Package Index · PyPI tensorboardX-1.4-py2.py3-none-any.whl visdom-0.1.8.5.tar.gz 安装指令为 1$ pip3 install xxx.whl 12$ tar -zxvf xxx.tar.gz$ python setup.py install Pytorch源码安装 pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration 安装方法Installation - From Source 需要用到miniconda，安装方法如下，注意中间回车按慢一点，有两次输入。。。。。(行我慢慢看条款不行么。。笑脸:-)) 第一次是是否同意条款，yes 第二次是添加到环境变量，yes，否则自己修改/home/pi/.bashrc添加到环境变量 1234567891011$ wget http://repo.continuum.io/miniconda/Miniconda3-latest-Linux-armv7l.sh$ sudo md5sum Miniconda3-latest-Linux-armv7l.sh # (optional) check md5$ sudo /bin/bash Miniconda3-latest-Linux-armv7l.sh # -&gt; change default directory to /home/pi/miniconda3$ sudo nano /home/pi/.bashrc # -&gt; add: export PATH="/home/pi/miniconda3/bin:$PATH"$ sudo reboot -h now$ conda $ python --version$ sudo chown -R pi miniconda3 然后就可以安装了没有对应版本的mkl，笑脸:-) 12345678910111213export CMAKE_PREFIX_PATH="$(dirname $(which conda))/../" # [anaconda root directory]# Disable CUDAexport NO_CUDA=1# Install basic dependenciesconda install numpy pyyaml mkl mkl-include setuptools cmake cffi typingconda install -c mingfeima mkldnn# Install Pytorchgit clone --recursive https://github.com/pytorch/pytorchcd pytorchpython setup.py install tensorflow 安装tensorflow需要的一些依赖和工具 1234567$ sudo apt-get update# For Python 2.7$ sudo apt-get install python-pip python-dev# For Python 3.3+$ sudo apt-get install python3-pip python3-dev 安装tensorflow 若下载失败，手动打开下面网页下载.whl包 1234567# For Python 2.7$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp27-none-linux_armv7l.whl$ sudo pip install tensorflow-1.1.0-cp27-none-linux_armv7l.whl# For Python 3.4$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl$ sudo pip3 install tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl 卸载，重装mock 1234567# For Python 2.7$ sudo pip uninstall mock$ sudo pip install mock# For Python 3.3+$ sudo pip3 uninstall mock$ sudo pip3 install mock 安装的版本tensorflow v1.1.0没有models，因为1.0版本以后models就被Sam Abrahams独立出来了，例如classify_image.py就在models/tutorials/image/imagenet/里 tensorflow/models 其余 输入法 12$ sudo apt-get install fcitx fcitx-googlepinyin $ fcitx-module-cloudpinyin fcitx-sunpinyin git 1$ sudo apt-get install git 配置git和ssh 12345$ git config --global user.name "Louis Hsu"$ git config --global user.email is.louishsu@foxmail.com$ ssh-keygen -t rsa -C "is.louishsu@foxmail.com"$ cat ~/.ssh/id_rsa.pub # 添加到github]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Underfitting & Overfitting]]></title>
    <url>%2F2018%2F10%2F26%2FUnderfitting-Overfitting%2F</url>
    <content type="text"><![CDATA[原因分析放上一张非常经典的图，以下分别表示二分类模型中的欠拟合(underfit)、恰好(just right)、过拟合(overfit)，来自吴恩达课程笔记。 欠拟合的成因大多是模型不够复杂、拟合函数的能力不够； 过拟合成因是给定的数据集相对过于简单，使得模型在拟合函数时过分地考虑了噪声等不必要的数据间的关联，或者说相对于给定数据集，模型过于复杂、拟合能力过强。 判别方法学习曲线可通过学习曲线(Learning curve)进行欠拟合与过拟合的判别。 学习曲线就是通过画出不同训练集大小时训练集和交叉验证的准确率，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。 绘制横轴为训练样本的数量，纵轴为损失或其他评估准则。sklearn中学习曲线绘制例程如下1234567891011121314151617181920212223242526272829303132333435363738import numpy as npimport matplotlib.pyplot as pltfrom sklearn.naive_bayes import GaussianNBfrom sklearn.datasets import load_digitsfrom sklearn.model_selection import learning_curvefrom sklearn.model_selection import ShuffleSplitdigits = load_digits(); X, y = digits.data, digits.targetcv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)estimator = GaussianNB()train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=cv, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5))plt.figure()plt.title("Learning Curves (Naive Bayes)")plt.xlabel("Training examples")plt.ylabel("Score")train_scores_mean = np.mean(train_scores, axis=1)train_scores_std = np.std(train_scores, axis=1)test_scores_mean = np.mean(test_scores, axis=1)test_scores_std = np.std(test_scores, axis=1)plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")plt.grid(); plt.legend(loc="best")plt.show() 判别 欠拟合，即高偏差(high bias)，训练集和测试集的误差收敛但却很高； 过拟合，即高方差(high variance)，训练集和测试集的误差之间有大的差距。 欠拟合解决方法 增加迭代次数继续训练 增加模型复杂度 增加特征 减少正则化程度 采用Boosting等集成方法 此时增加数据集并不能改善欠拟合问题。 过拟合解决方法 提前停止训练 获取更多样本或数据扩增 重采样 上采样 增加随机噪声 GAN 图像数据的空间变换（平移旋转镜像） 尺度变换（缩放裁剪） 颜色变换 改变分辨率 对比度 亮度 降低模型复杂度 减少特征 增加正则化程度 神经网络可采用Dropout 多模型投票方法]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Cross Validation & Hyperparameter]]></title>
    <url>%2F2018%2F10%2F26%2FCross-Validation-Hyperparameter%2F</url>
    <content type="text"><![CDATA[交叉验证与超参数选择交叉验证以下简称交叉验证(Cross Validation)为CV.CV是用来验证分类器的性能一种统计分析方法,基本思想是把在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set),首先用训练集对分类器进行训练,在利用验证集来测试训练得到的模型(model),以此来做为评价分类器的性能指标。 交叉验证的几种方法 k折交叉验证(K-fold) 将全部训练集$S$分成$k$个不相交的子集，假设$S$中的训练样例个数为$m$，则每个子集中有$(\frac{m}{k})$个训练样例，相应子集称作$\{s_1, s_2, …, s_k\}$； 每次从分好的子集中，拿出$1$个作为测试集，其他$k-1$个作为训练集； 在$k-1$个训练集上训练出学习器模型，将模型放到测试集上，得到分类率； 计算k次求得的分类率平均值，作为该模型或者假设函数的真实分类率 留一法交叉验证(Leave One Out - LOO) 假设有$N$个样本，将每个样本作为测试样本，其他$(N-1)$个样本作为训练样本。这样得到$N$个分类器，$N$个测试结果。用这$N$个结果的平均值衡量模型的性能。 留P法交叉验证(Leave P Out - LPO) 将$P$个样本作为测试样本，其他$(N-P)$个样本作为训练样本。这样得到$\left(\begin{matrix} P \\ N \end{matrix}\right)$个训练测试对。当$P＞1$时，测试集会发生重叠。当$P=1$时，变成$LOO$。 scikit-learn中的交叉验证 K-fold 12345678&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from sklearn.model_selection import KFold&gt;&gt;&gt; X = ["a", "b", "c", "d"]&gt;&gt;&gt; kf = KFold(n_splits=2)&gt;&gt;&gt; for train, test in kf.split(X):... print("%s %s" % (train, test))[2 3] [0 1][0 1] [2 3] Leave One Out (LOO) 123456789&gt;&gt;&gt; from sklearn.model_selection import LeaveOneOut&gt;&gt;&gt; X = [1, 2, 3, 4]&gt;&gt;&gt; loo = LeaveOneOut()&gt;&gt;&gt; for train, test in loo.split(X):... print("%s %s" % (train, test))[1 2 3] [0][0 2 3] [1][0 1 3] [2][0 1 2] [3] Leave P Out (LPO) 1234567891011&gt;&gt;&gt; from sklearn.model_selection import LeavePOut&gt;&gt;&gt; X = np.ones(4)&gt;&gt;&gt; lpo = LeavePOut(p=2)&gt;&gt;&gt; for train, test in lpo.split(X):... print("%s %s" % (train, test))[2 3] [0 1][1 3] [0 2][1 2] [0 3][0 3] [1 2][0 2] [1 3][0 1] [2 3] 使用交叉验证调整超参数超参数的定义：在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。超参数例如 模型（SVM，Softmax，Multi-layer Neural Network,…)； 迭代算法（Adam, SGD, …)(不同的迭代算法还有各种不同的超参数，如beta1,beta2等等，但常见的做法是使用默认值，不进行调参）； 学习率（learning rate)； 正则化方程的选择(L0,L1,L2)，正则化系数； dropout的概率 … 确定调节范围超参数的种类多，调节范围大，需要先进行简单的测试确定调参范围。 模型选择 模型的选择很大程度上取决于具体的实际问题，但必须通过几项基本测试。 可以通过第一个epoch的loss，观察模型能否无BUG运行，注意此过程需要设置正则项系数为0，因为正则项引入的loss难以估算。 模型必须可以对于小数据集过拟合，否则应该尝试其他或者更复杂的模型。 若训练集与验证集loss均较大，则应该尝试其他或者更复杂的模型。 模型选择的方法为： 使用训练集训练出 10 个模型 用 10 个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值） 选取代价函数值最小的模型 用步骤 3 中选出的模型对测试集计算得出推广误差（代价函数的值） —— Andrew Ng, Stanford University 学习率 loss基本不变：学习率过低 loss波动明显或者溢出：学习率过高 正则项系数 val_acc与acc相差较大：正则项系数过小 loss逐渐增大：正则项系数过大 超参数的确定 先粗调，再细调 先通过数量少，间距大的粗调确定细调的大致范围。然后在小范围内部进行间距小，数量大的细调。 尝试在对数空间内进行调节 即在对数空间内部随机生成测试参数，而不是在原空间生成，通常用于学习率以及正则项系数等的调节。出发点是该超参数的指数项对于模型的结果影响更显著；而同阶的数据之间即便原域相差较大，对于模型结果的影响反而不如不同阶的数据差距大。 超参数搜索 随机搜索参数值，而不是网格搜索。 超参数搜索scikit-learn提供超参数搜索方法，可参考官方文档 网格搜索 3.2.1. Exhaustive Grid Search 调用例程如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npfrom time import timefrom scipy.stats import randint as sp_randintfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.datasets import load_digitsfrom sklearn.ensemble import RandomForestClassifier# get some datadigits = load_digits()X, y = digits.data, digits.target# build a classifierclf = RandomForestClassifier(n_estimators=20)# Utility function to report best scoresdef report(results, n_top=3): for i in range(1, n_top + 1): candidates = np.flatnonzero(results['rank_test_score'] == i) for candidate in candidates: print("Model with rank: &#123;0&#125;".format(i)) print("Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)".format( results['mean_test_score'][candidate], results['std_test_score'][candidate])) print("Parameters: &#123;0&#125;".format(results['params'][candidate])) print("")# use a full grid over all parametersparam_grid = &#123;"max_depth": [3, None], "max_features": [1, 3, 10], "min_samples_split": [2, 3, 10], "min_samples_leaf": [1, 3, 10], "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run grid searchgrid_search = GridSearchCV(clf, param_grid=param_grid)start = time()grid_search.fit(X, y)print("GridSearchCV took %.2f seconds for %d candidate parameter settings." % (time() - start, len(grid_search.cv_results_['params'])))report(grid_search.cv_results_) 随机搜索 3.2.2. Randomized Parameter Optimization 调用例程如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import numpy as npfrom time import timefrom scipy.stats import randint as sp_randintfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.datasets import load_digitsfrom sklearn.ensemble import RandomForestClassifier# get some datadigits = load_digits()X, y = digits.data, digits.target# build a classifierclf = RandomForestClassifier(n_estimators=20)# Utility function to report best scoresdef report(results, n_top=3): for i in range(1, n_top + 1): candidates = np.flatnonzero(results['rank_test_score'] == i) for candidate in candidates: print("Model with rank: &#123;0&#125;".format(i)) print("Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)".format( results['mean_test_score'][candidate], results['std_test_score'][candidate])) print("Parameters: &#123;0&#125;".format(results['params'][candidate])) print("")# specify parameters and distributions to sample fromparam_dist = &#123;"max_depth": [3, None], "max_features": sp_randint(1, 11), "min_samples_split": sp_randint(2, 11), "min_samples_leaf": sp_randint(1, 11), "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run randomized searchn_iter_search = 20random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search)start = time()random_search.fit(X, y)print("RandomizedSearchCV took %.2f seconds for %d candidates" " parameter settings." % ((time() - start), n_iter_search))report(random_search.cv_results_)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spam Classification]]></title>
    <url>%2F2018%2F10%2F26%2FSpam-Classification%2F</url>
    <content type="text"><![CDATA[踩坑？？？全部给我踩平！！！ 来自LintCode垃圾短信分类@Github: spam or ham 垒代码预处理及向量化观察各文本后，发现各文本中包含的单词多种多样，包含标点、数字等，例如123- Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...- XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here&gt;&gt; http://wap. - 07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. 且按空格分词后，部分单词中仍包含whitespace，故选择的预处理方案是，去除分词后文本中的标点、数字、空格等，并将单词中字母全部转为小写。 中文分词可采用jieba(街霸？) 预处理后，按当前的文本内容建立字典，并统计各样本的词数向量，详细代码如下12345678910111213141516171819202122232425262728293031323334353637383940414243class Words2Vector(): ''' 建立字典，将输入的词列表转换为向量，表示各词出现的次数 ''' def __init__(self): self.dict = None self.n_word = None def fit_transform(self, words): self.fit(words) return self.transform(words) def fit(self, words): """ @param &#123;list[list[str]]&#125; words """ words = _flatten(words) # 展开为1维列表 words = self.filt(words) # 滤除空格、数字、标点 self.word = list(set(words)) # 去重 self.n_word = len(set(words)) # 统计词的个数 self.dict = dict(zip(self.word, [_ for _ in range(self.n_word)])) # 各词在字典中的位置 def transform(self, words): """ @param &#123;list[list[str]]&#125; words @return &#123;ndarray&#125; retarray: vector """ retarray = np.zeros(shape=(len(words), self.n_word)) # 返回的词数向量 for i in range(len(words)): words[i] = self.filt(words[i]) # 滤除空格、数字、标点 for i in range(len(words)): for w in words[i]: if w in self.word: # 是否在训练集生成的字典中 retarray[i, self.dict[w]] += 1 # 查询字典，找到对应特征的下标 return retarray def filt(self, flattenWords): retWords = [] en_stops = set(stopwords.words('english')) # 停用词列表 for word in flattenWords: word = word.translate(str.maketrans('', '', string.whitespace)) # 去除空白 word = word.translate(str.maketrans('', '', string.punctuation)) # 去除标点 word = word.translate(str.maketrans('', '', string.digits)) # 去除数字 if word not in en_stops and (len(word) &gt; 1): # 删除停用词，并除去长度小于等于2的词 retWords.append(word.lower()) return retWords TF-IDF方法由词数向量可计算词频，但只用词频忽略了各文本在不同文档中的重要程度，关于TF-IDF，在另一篇博文中详细说明。 由于剔除了停用词等，部分向量不包含任何内容，即词数向量为$\vec{0}$，这时计算词频和单位化时，会出现nan的运算结果，故只对非空向量进行计算。 训练后需要保存的是IDF向量，TF向量在新样本输入后重新计算，故无需保存。 12345678910111213141516171819202122232425262728293031class TfidfVectorizer(): def __init__(self): self.idf = None def fit_transform(self, num_vec): self.fit(num_vec) return self.transform(num_vec) def fit(self, num_vec): """ @param &#123;ndarray&#125;: num_vec, shape(N_sample, N_feature) """ num_vec[num_vec&gt;0] = 1 n_doc = num_vec.shape[0] n_term = np.sum(num_vec, axis=0) # 各词出现过的文档次数 self.idf = np.log((n_doc + 1) / (n_term + 1)) + 1 return self.idf def transform(self, num_vec): """ @param &#123;ndarray&#125;: num_vec, shape(N_sample, N_feature) """ # 求解词频向量，由于部分向量为空，故下句会出现问题 # tf = num_vec / np.sum(num_vec, axis=1).reshape(-1, 1) =&gt; nan # 解决方法：只对非空向量进行词频计算 tf = np.zeros(shape=num_vec.shape) n_terms = np.sum(num_vec, axis=1); idx = (n_terms!=0) tf[idx] = num_vec[idx] / n_terms[idx].reshape(-1, 1) # 计算词频，只对非空向量进行 tfidf = tf * self.idf tfidf[idx] /= np.linalg.norm(tfidf, axis=1)[idx].reshape(-1, 1) # 单位化，只对非空向量进行 return tfidf 贝叶斯决策各文本向量化后，就可通过机器学习算法进行模型的训练和预测，这里采用的是贝叶斯决策的方法，需要注意的有以下几点 似然函数$p(x|c_k)$与贝叶斯决策文中例不同，这里宜采用高斯分布作为分布模型； 按朴素贝叶斯计算$p(x|c_k)$，但注意此处不能将各维特征单独训练$1$维高斯分布模型，然后计算预测样本似然函数值时进行累乘，如下 p(x|c_k) = \prod_{j=1}^{N_feature} p(x_j|c_k)因为特征维度特别高，各个特征单独用$1$维高斯分布描述，累乘计算会下溢，故这里采用多元高斯分布 p(x|c_k) = \frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma_k|^{\frac{1}{2}}} · e^{-\frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k)} 且经主成分分析后，各维度间线性相关性降低，故假定 \Sigma_k = diag\{\sigma_{k1}, ..., \sigma_{kn}\} 但分母$(2\pi)^{\frac{n}{2}}|\Sigma_k|^{\frac{1}{2}}$在计算时不稳定，且各特征标准差大小相差无几，故这里假定 \Sigma_k = I 最终简化后的似然函数计算方法为 p(x|c_k) = e^{-\frac{1}{2} (x - \mu_k)^T (x - \mu_k)} 贝叶斯决策模型训练基于上述假设，只需训练多元高斯分布的各维均值$\mu_j$ 1234567891011121314151617181920212223def fit(self, labels, text): """ @param &#123;ndarray&#125; labels: shape(N_samples, ), labels[i] \in &#123;0, 1&#125; @param &#123;list[list[str]]&#125; words """ labels = self.encodeLabel(labels); words = self.text2words(self.clean(text)) vecwords = self.numvectorizer.fit_transform(words) # 向量化 vecwords = self.tfidfvectorizer.fit_transform(vecwords) # tfidf, shape(N_samples, N_features) isnotEmpty = (np.sum(vecwords, axis=1)!=0) # 去掉空的样本 vecwords = vecwords[isnotEmpty]; labels = labels[isnotEmpty] # vecwords = self.reduce_dim.fit_transform(vecwords) # 降维，计算量太大 self.n_features = vecwords.shape[1] labels = OneHotEncoder().fit_transform(labels.reshape((-1, 1))).toarray() self.priori = np.mean(labels, axis=0) # 先验概率 self.likelihood_mu = np.zeros(shape=(2, vecwords.shape[1])) # 设似然函数p(x|c)为高斯分布 for i in range(2): vec = vecwords[labels[:, i]==1] self.likelihood_mu[i] = np.mean(vec, axis=0) 贝叶斯决策模型预测决策函数为 if p(x|c_i)P(c_i) > p(x|c_j)P(c_j), then x \in c_i但实际效果显示，等先验概率$P(c_j)$结果更好$(???)$ 123456789101112131415161718192021222324252627def multigaussian(self, x, mu): """ 简化 """ x = x - mu a = np.exp(-0.5 * x.T.dot(x)) return adef predict(self, text): """ @param &#123;list[list[str]]&#125; words @note: p(x|c)P(c) P(c|x) = ------------ p(x) """ pred_porba = np.ones(shape=(len(self.clean(text)), 2)) words = self.text2words(text) vecwords = self.tfidfvectorizer.transform( self.numvectorizer.transform(words)) # 向量化 for i in range(vecwords.shape[0]): for c in range(2): # pred_porba[i, c] = self.priori[c] * self.multigaussian(vecwords[i], self.likelihood_mu[c]) pred_porba[i, c] = self.multigaussian(vecwords[i], self.likelihood_mu[c]) pred = np.argmax(pred_porba, axis=1) return self.decodeLabel(pred) 调包主要用到了scikit-learn机器学习包以下几个功能 sklearn.feature_extraction.text.TfidfVectorizer() sklearn.decomposition.PCA() sklearn.naive_bayes.BernoulliNB() 最终准确率在$97\%$左右，代码比较简单，不进行说明。 采用sklearn.linear_model import.LogisticRegressionCV()效果更佳 123456789101112131415161718192021222324252627282930def main(): trainfile = "./data/train.csv" testfile = "./data/test.csv" # 读取原始数据 data_train = pd.read_csv(trainfile, names=['Label', 'Text']) txt_train = list(data_train['Text'])[1: ]; label_train = list(data_train['Label'])[1: ] drop(txt_train) # 删除数字和标点 txt_test = list(pd.read_csv(testfile, names=['Text'])['Text'])[1: ] drop(txt_test) # 删除数字和标点 # 训练 vectorizer = TfidfVectorizer(stop_words='english') # 删除英文停用词 vec_train = vectorizer.fit_transform(txt_train).toarray() # 提取文本特征向量 # reduce_dim = PCA(n_components = 4096) # vec_train = reduce_dim.fit_transform(vec_train) estimator = BernoulliNB() estimator.fit(vec_train, label_train) # 训练朴素贝叶斯模型 # 测试 label_train_pred = estimator.predict(vec_train) acc = np.mean((label_train_pred==label_train).astype('float')) # 预测 vec_test = vectorizer.transform(txt_test).toarray() # vec_test = reduce_dim.transform(vec_test) label_test_pred = estimator.predict(vec_test) with open('./data/sampleSubmission.txt', 'w') as f: for i in range(label_test_pred.shape[0]): f.write(label_test_pred[i] + '\n')]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TF-IDF]]></title>
    <url>%2F2018%2F10%2F25%2FTF-IDF%2F</url>
    <content type="text"><![CDATA[引言正在做LintCode上的垃圾邮件分类，使用朴素贝叶斯方法解决，涉及到文本特征的提取。TF-IDF（词频-逆文档频率）算法是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。 计算步骤词频(TF)Term Frequency，就是某个关键字出现的频率，具体来讲，就是词库中的某个词在当前文章中出现的频率。那么我们可以写出它的计算公式： TF_{ij} = \frac{n_{ij}}{\sum_k n_{i, k}}其中，$n_{ij}$表示关键词$j$在文档$i$中的出现次数。 单纯使用TF来评估关键词的重要性忽略了常用词的干扰。常用词就是指那些文章中大量用到的，但是不能反映文章性质的那种词，比如：因为、所以、因此等等的连词，在英文文章里就体现为and、the、of等等的词。这些词往往拥有较高的TF，所以仅仅使用TF来考察一个词的关键性，是不够的。 逆文档频率(IDF)Inverse Document Frequency，文档频率就是一个词在整个文库词典中出现的频率，逆文档频率用下式计算 IDF_j = \log \frac{|D|}{|D_j| + 1}其中，$|D|$表示总的文档数目，$|D_j|$表示关键词$j$出现过的文档数目 scikit-learn内为 IDF_j = \log \frac{|D| + 1}{|D_j| + 1} + 1 词频-逆文档频率(TF-IDF) TF-IDF_{i} = TF_i × IDF举例例如有如下$3$个文本123文本1：My dog ate my homework.文本2：My cat ate the sandwich.文本3：A dolphin ate the homework. 提取字典，一般需要处理大小写、去除停用词a，处理结果为1ate, cat, dog, dolphin, homework, my, sandwich, the 故各个文本的词数向量为123文本1：[1, 0, 1, 0, 1, 2, 0, 0]文本2：[1, 1, 0, 0, 0, 1, 1, 1]文本3：[1, 0, 0, 1, 1, 0, 0, 1] 各个文本的词频向量(TF)123文本1：[0.2 , 0. , 0.2 , 0. , 0.2 , 0.4 , 0. , 0. ]文本2：[0.2 , 0.2 , 0. , 0. , 0. , 0.2 , 0.2 , 0.2 ]文本3：[0.25, 0. , 0. , 0.25, 0.25, 0. , 0. , 0.25] 各词出现过的文档次数1[3, 1, 1, 1, 2, 2, 1, 2] 总文档数为$3$，各词的逆文档频率(IDF)向量 这里使用scikit-learn内的方法求解 1[1. , 1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.28768207, 1.69314718, 1.28768207] 故各文档的TF-IDF向量为123456文本1：[0.2 , 0. , 0.33862944, 0. , 0.25753641, 0.51507283, 0. , 0. ]文本2：[0.2 , 0.33862944, 0. , 0. , 0. , 0.25753641, 0.33862944, 0.25753641]文本3：[0.25 , 0. , 0. , 0.4232868 , 0.32192052, 0. , 0. , 0.32192052] 经单位化后，有123456文本1：[0.28680065, 0. , 0.48559571, 0. , 0.36930805, 0.73861611, 0. , 0. ]文本2：[0.31544415, 0.53409337, 0. , 0. , 0. , 0.40619178, 0.53409337, 0.40619178]文本3：[0.37311881, 0. , 0. , 0.63174505, 0.4804584 , 0. , 0. , 0.4804584 ] 123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; vec_num = np.array([ [1, 0, 1, 0, 1, 2, 0, 0], [1, 1, 0, 0, 0, 1, 1, 1], [1, 0, 0, 1, 1, 0, 0, 1] ])&gt;&gt;&gt; vec_tf = vec_num / np.sum(vec_num, axis=1).reshape(-1, 1)&gt;&gt;&gt; vec_tfarray([[0.2 , 0. , 0.2 , 0. , 0.2 , 0.4 , 0. , 0. ], [0.2 , 0.2 , 0. , 0. , 0. , 0.2 , 0.2 , 0.2 ], [0.25, 0. , 0. , 0.25, 0.25, 0. , 0. , 0.25]])&gt;&gt;&gt; vec_num[vec_num&gt;0] = 1&gt;&gt;&gt; n_showup = np.sum(vec_num, axis=0)&gt;&gt;&gt; n_showuparray([3, 1, 1, 1, 2, 2, 1, 2])&gt;&gt;&gt; d = 3&gt;&gt;&gt; vec_idf = np.log((d + 1) / (n_showup + 1)) + 1&gt;&gt;&gt; vec_idfarray([1. , 1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.28768207, 1.69314718, 1.28768207])&gt;&gt;&gt; vec_tfidf = vec_tf * vec_idf&gt;&gt;&gt; vec_tfidfarray([[0.2 , 0. , 0.33862944, 0. , 0.25753641, 0.51507283, 0. , 0. ], [0.2 , 0.33862944, 0. , 0. , 0. , 0.25753641, 0.33862944, 0.25753641], [0.25 , 0. , 0. , 0.4232868 , 0.32192052, 0. , 0. , 0.32192052]])&gt;&gt;&gt; vec_tfidf = vec_tfidf / np.linalg.norm(vec_tfidf, axis=1).reshape((-1, 1))&gt;&gt;&gt; vec_tfidfarray([[0.28680065, 0. , 0.48559571, 0. , 0.36930805, 0.73861611, 0. , 0. ], [0.31544415, 0.53409337, 0. , 0. , 0. , 0.40619178, 0.53409337, 0.40619178], [0.37311881, 0. , 0. , 0.63174505, 0.4804584 , 0. , 0. , 0.4804584 ]]) 验证使用scikit-learn机器学习包计算结果123456789101112&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfVectorizer&gt;&gt;&gt; vectorizer = TfidfVectorizer()&gt;&gt;&gt; text = [ "My dog ate my homework", "My cat ate the sandwich", "A dolphin ate the homework"]&gt;&gt;&gt; vectorizer.fit_transform(text).toarray()array([[0.28680065, 0. , 0.48559571, 0. , 0.36930805, 0.73861611, 0. , 0. ], [0.31544415, 0.53409337, 0. , 0. , 0. , 0.40619178, 0.53409337, 0.40619178], [0.37311881, 0. , 0. , 0.63174505, 0.4804584 , 0. , 0. , 0.4804584 ]])&gt;&gt;&gt; vectorizer.get_feature_names()['ate', 'cat', 'dog', 'dolphin', 'homework', 'my', 'sandwich', 'the']]]></content>
      <categories>
        <category>Practice</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SVD]]></title>
    <url>%2F2018%2F10%2F23%2FSVD%2F</url>
    <content type="text"><![CDATA[引言奇异值分解Singular Value Decomposition是线性代数中一种重要的矩阵分解，奇异值分解则是特征分解在任意矩阵上的推广。在信号处理、统计学等领域有重要应用。 原理从特征值分解(EVD)讲起我们知道对于一个$n$阶方阵$A_{n×n}$，有 A\alpha_i = \lambda_i \alpha_i i = 1, ..., n取 P = \left[\alpha_1, \alpha_2, ..., \alpha_n\right]有下式成立 AP = P\Lambda其中 \Lambda = \left[ \begin{matrix} \lambda_1 & & \\ & ... & \\ & & \lambda_n \\ \end{matrix} \right] 特征值一般从大到小排列 利用该式可将方阵$A_{n×n}$化作对角阵$\Lambda_{n×n}$ \Lambda = P^{-1}AP或者 A = P \Lambda P^{-1} = \sum_{i=1}^n \lambda_i (P_{,i})(P_{,i})^{-1} “$_{i}$”表示第$i$行，“$_{,i}$”表示第$i$列 这样我们就可以理解为，矩阵$A$是由$n$个$n$阶矩阵$P_{,i}P^{-1}_{i}$加权组成，特征值$\lambda_i$即为权重。 以上为个人理解，不妥之处可以指出。 奇异值分解(SVD)定义对于长方阵$A_{m×n}$，不能进行特征值分解，可进行如下分解 A_{m×n} = U_{m×m} \Sigma_{m×n} V_{n×n}^T其中$U \in \mathbb{R}^{m×m}, V \in \mathbb{R}^{n×n}$，均为正交矩阵。矩阵$\Sigma_{m×n}$如下 对于$m&gt;n$ \Sigma_{m×n} = \left[ \begin{matrix} S_{n×n} \\ --- \\ O_{(m-n)×n} \end{matrix} \right] 对于$m&lt;n$ \Sigma_{m×n} = \left[ \begin{matrix} S_{m×m} & | & O_{m×(n-m)} \end{matrix} \right] 矩阵$S_{n×n}$为对角阵，对角元素从大到小排列 S_{n×n} = \left[ \begin{matrix} \sigma_1 & & \\ & ... & \\ & & \sigma_n\\ \end{matrix} \right]直观表示SVD分解如下 当取$r&lt;n$时，有部分奇异值分解，可用于降维 A_{m×n} = U_{m×r} \Sigma_{r×r} V_{r×n}^T计算 以下仅考虑$m&gt;n$的情况 令矩阵$A^T$与$A$相乘，有 A^TA = (U \Sigma V^T)^T (U \Sigma V^T) = V \Sigma^T U^T U \Sigma V^T A^TA = V \Sigma^T \Sigma V^T 矩阵$U$为正交阵，即满足$U^TU=I$ 其中 \Sigma^T \Sigma = \left[ \begin{matrix} S^T_{n×n} & | & O^T_{n×(m-n)} \end{matrix} \right] \left[ \begin{matrix} S_{n×n} \\ --- \\ O_{(m-n)×n} \end{matrix} \right] = S_{n×n}^2 = \left[ \begin{matrix} \sigma_1^2 & & \\ & ... & \\ & & \sigma_n^2\\ \end{matrix} \right] 则 A^T A = V S^2 V^T 即矩阵$A^T A$相似对角化为$S^2$，对角元素$\sigma_i^2$与矩阵$V$的列向量$v_i(i=1, …, n)$为矩阵$A^T A$的特征对。 那么对矩阵$A^T A$进行特征值分解，有 (A^T A) \alpha^{(1)}_i = \lambda^{(1)}_i \alpha^{(1)}_i 则 v_i = \alpha^{(1)}_i \sigma_i = \sqrt{\lambda^{(1)}_i} 注：对于二次型$x^T (A^T A) x$ x^T (A^T A) x = (Ax)^T(Ax) \geq 0故矩阵$A^T A$半正定，$\sigma_i = \sqrt{\lambda_i}$有解 同理，令矩阵$A$与$A^T$相乘，可证得 A A^T = U \Sigma \Sigma^T U^T 其中 \Sigma \Sigma^T = \left[ \begin{matrix} S_{n×n} \\ --- \\ O_{(m-n)×n} \end{matrix} \right] \left[ \begin{matrix} S^T_{n×n} & | & O^T_{n×(m-n)} \end{matrix} \right] = \left[ \begin{matrix} S^2_{n×n} & O_{n×(m-n)} \\ O_{(m-n)×n} & O_{(m-n)×(m-n)} \end{matrix} \right] 即矩阵$A A^T$相似对角化，对角元素$\sigma_i^2$与矩阵$U$的列向量$u_i(i=1, …, m)$为矩阵$A A^T$的特征对。 对矩阵$A A^T$进行特征值分解，有 (A^T A) \alpha^{(2)}_i = \lambda^{(2)}_i \alpha^{(2)}_i 则 u_i = \alpha^{(2)}_i \sigma_i = \sqrt{\lambda^{(2)}_i} 同理可证得$A A^T$半正定，略。 一般来说，为减少计算量，计算奇异值分解只进行一次特征值分解，如对于矩阵$X_{m×n}(m&gt;n)$，选取$n$阶矩阵$X^T X$进行特征值分解计算$v_i$，计算$u_i$方法下面介绍。 根据前面推导，我们有特征值分解 (A^T A) \alpha^{(1)}_i = \lambda^{(1)}_i \alpha^{(1)}_i (A A^T) \alpha^{(2)}_i = \lambda^{(2)}_i \alpha^{(2)}_i其中$\lambda^{(1)}_i = \lambda^{(2)}_i = \sigma_i^2$，$v_i = \alpha^{(1)}_i$，$u_i = \alpha^{(2)}_i$，即 A^T A v_i = \sigma_i^2 v_i \tag{1} A A^T u_i = \sigma_i^2 u_i \tag{2}$(1)$式左右乘$A$，有 A A^T A v_i = \sigma_i^2 A v_i发现什么？这是另一个特征值分解的表达式！ (A A^T) (A v_i) = \sigma_i^2 (A v_i)故 u_i \propto A v_i 或 u_i = k · A v_i \tag{3}现在求解系数$k$，根据定义 A = U \Sigma V^T \Rightarrow AV = U \Sigma则 A v_i = \sigma_i u_i \Rightarrow u_i = \frac{1}{\sigma_i} A v_i或者 U = A V \Sigma^{-1} 注：只能求前$n$个$u_i$，之后的需要列写方程求解 举栗将矩阵$A$进行分解 A = \left[ \begin{matrix} 0 & 1 \\ 1 & 1 \\ 1 & 0 \end{matrix} \right]为减少计算量，取$A^T A$计算 A^T A = \left[ \begin{matrix} 2 & 1 \\ 1 & 2 \end{matrix} \right]特征值分解，有 A\left[ \begin{matrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{matrix} \right] = \left[ \begin{matrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{matrix} \right] \left[ \begin{matrix} 3 & \\ & 1 \end{matrix} \right]故 \Sigma = \left[ \begin{matrix} \sqrt{3} & \\ & 1 \end{matrix} \right] V = \left[ \begin{matrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{matrix} \right] U = A V \Sigma^{-1} = \left[ \begin{matrix} \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{2}} \\ \frac{2}{\sqrt{6}} & 0 \\ \frac{1}{\sqrt{6}} & -\frac{1}{\sqrt{2}} \end{matrix} \right]123456789101112131415161718192021222324&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; A = np.array([ [0, 1], [1, 1], [1, 0] ])&gt;&gt;&gt; ATA = A.T.dot(A)&gt;&gt;&gt; eigval, eigvec= np.linalg.eig(ATA)&gt;&gt;&gt; V = eigvec.copy()&gt;&gt;&gt; S = np.diag(np.sqrt(eigval))&gt;&gt;&gt; U = A.dot(V).dot(np.linalg.inv(S))&gt;&gt;&gt; Uarray([[ 0.40824829, 0.70710678], [ 0.81649658, 0. ], [ 0.40824829, -0.70710678]])&gt;&gt;&gt; Sarray([[1.73205081, 0. ], [0. , 1. ]])&gt;&gt;&gt; Varray([[ 0.70710678, -0.70710678], [ 0.70710678, 0.70710678]])&gt;&gt;&gt; # 验证&gt;&gt;&gt; U.dot(S).dot(V.T)array([[-2.23711432e-17, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, -2.23711432e-17]]) 理解展开表达式，取$r \leq n$时， A = U_{m×r} \Sigma_{r×r} V_{r×n}^T = \sum_{i=1}^r \sigma_i (U_{,i}) (V_{,i})^T就得到与PCA相同的结论，矩阵$A$可由$r$个$m×n$的矩阵$(U_{,i}) (V_{,i})^T$加权组成。一般来说，前$10\%$甚至$1\%$的奇异值就占了全部奇异值之和的$99\%$，极大地保留了信息，而大大减少了存储空间。 以图片为例，若原有24bit图片，其大小为(1024, 768)，则不计图片信息，仅仅数据共占1024×768×3 B，或2.25 MB。用奇异值分解进行压缩，保留$60\%$的奇异值，可达到几乎无损的程度，此时需要保存向量矩阵$U_{1024×60}$，$V_{60×768}$以及$60$个奇异值，以浮点数float32存储，一共占420 KB即可。 (1024 × 60 + 60 × 768 + 60) × 4 / 2^{10} = 420.23说句题外话，存储量的压缩必然以计算量的增大为代价，相反亦然，所以需要协调好RAM与ROM容量，考虑计算机的计算速度。换句话说，空间和时间上必然是互补的，哲学的味道hhhh。 分解结果的信息保留分解后各样本间的欧式距离与角度信息应不变，给出证明如下设有$m$组$n$维样本样本 X_{n×m} = [X^{(1)}, X^{(2)}, ..., X^{(m)}]经奇异值分解，有 X_{n×m} = U_{n×r} \Sigma_{r×r} V_{r×m}^T记 Z_{r×m} = \Sigma V^T = [Z^{(1)}, Z^{(2)}, ..., Z^{(N)}]有 X = U Z 欧式距离 || X^{(i)} - X^{(j)} ||_2^2 = || U (Z^{(i)} - Z^{(j)}) ||_2^2 = \left[ U (Z^{(i)} - Z^{(j)}) \right]^T \left[ U (Z^{(i)} - Z^{(j)}) \right] = (Z^{(i)} - Z^{(j)})^T U^T U (Z^{(i)} - Z^{(j)}) = || Z^{(i)} - Z^{(j)} ||_2^2 即 || X^{(i)} - X^{(j)} ||_2^2 = || Z^{(i)} - Z^{(j)} ||_2^2 角度信息 \frac{X^{(i)T}X^{(j)}}{||X^{(i)}||_2||X^{(j)}||_2} = \frac{(UZ^{(i)})^T(UZ^{(j)})}{||UZ^{(i)}||_2||UZ^{(j)}||_2} = \frac{(UZ^{(i)})^T(UZ^{(j)})}{\sqrt{(UZ^{(i)})^T(UZ^{(i)})} \sqrt{(UZ^{(j)})^T(UZ^{(j)})}} = \frac{Z^{(i)T}Z^{(j)}}{||Z^{(i)}||_2||Z^{(j)}||_2} 即 \frac{X^{(i)T}X^{(j)}}{||X^{(i)}||_2||X^{(j)}||_2} = \frac{Z^{(i)T}Z^{(j)}}{||Z^{(i)}||_2||Z^{(j)}||_2} 代码@Github: Code of SVD对图片进行了分解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798class SVD(): """ Singular Value Decomposition Attributes: m &#123;int&#125; n &#123;int&#125; r &#123;int&#125;: if r == -1, then r = n isTrains &#123;bool&#125;: isTrains = True if input.shape[0] &lt; input.shape[1] U &#123;ndarray(m, r)&#125; S &#123;ndarray(r, )&#125; V &#123;ndarray(n, r)&#125; Notes: - Transpose input matrix if m &lt; n, and m, n := n, m - Reassign r if eigvals contains zero - Singular values are stored in a 1-dim array `S` - X' = U S V^T """ def __init__(self, r=-1): self.m = None self.n = None self.r = r self.isTrans = False self.U = None self.S = None self.V = None def fit(self, X): """ calculate components Notes: - Transpose input matrix if m &lt; n, and m, n := n, m - reassign self.r if eigvals contains zero """ (self.m, self.n) = X.shape if self.m &lt; self.n: X = X.T self.m, self.n = self.n, self.m self.isTrans = True self.r = self.n if (self.r == -1) else self.r XTX = X.T.dot(X) eigval, eigvec = np.linalg.eig(X.T.dot(X)) eigval, eigvec = np.real(eigval), np.real(eigvec) self.S = np.sqrt(np.clip(eigval, 0, float('inf'))) self.S = self.S[self.S &gt; 0] self.r = min(self.r, self.S.shape[0]) # reassign self.r order = np.argsort(eigval)[::-1][: self.r] # sort eigval from large to small eigval = eigval[order]; eigvec = eigvec[:, order] self.V = eigvec.copy() self.U = X.dot(self.V).dot( np.linalg.inv(np.diag(self.S))) return self.U, self.S, self.V def compose(self, r=-1): """ merge first r components Parameters: r &#123;int&#125;: if r==-1, merge all components Returns: X &#123;ndarray(m, n)&#125; """ if r == -1: X = self.U.dot(np.diag(self.S)).dot(self.V.T) X = X.T if self.isTrans else X else: (m, n) = (self.n, self.m) if self.isTrans else (self.m, self.n) X = np.zeros(shape=(m, n)) for i in range(r): X += self.__getitem__(i) return X def __getitem__(self, idx): """ get a component Parameters: index &#123;int&#125;: range from (0, self.r) """ u = self.U[:, idx] v = self.V[:, idx] s = self.S[idx] x = s * u.reshape(self.m, 1).\ dot(v.reshape(1, self.n)) x = x.T if self.isTrans else x return x def showComponets(self, r=-1): """ display components Notes: - Resize components' shape into (40, 30) """ m, n = self.m, self.n r = self.r if r==-1 else r n_images = 10; m_images = r // n_images + 1 m_size, n_size = 40, 30 showfig = np.zeros(shape=(m_images*m_size, n_images*n_size)) for i in range(r): m_pos = i // n_images n_pos = i % n_images component = self.__getitem__(i) component = component.T if self.isTrans else component component = cv2.resize(component, (30, 40)) showfig[m_pos*m_size: (m_pos+1)*m_size, n_pos*n_size: (n_pos+1)*n_size] = component plt.figure('components') plt.imshow(showfig) plt.show() 用上面的代码进行实验1234567891011121314# 读取一张图片X = load_images()[0].reshape((32, 32))showmat2d(X)# 对图片进行奇异值分解decomposer = SVD(r=-1)decomposer.fit(X)# 显示一下分量decomposer.showComponets(r=-1)# 将全部分量组合，并显示X_ = decomposer.compose(r=-1)showmat2d(X_)# 将前5个分量组合，并显示X_ = decomposer.compose(r=5)showmat2d(X_) 载入原图如下 分量显示如下 组合分量显示如下 组合全部 组合前5个分量]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[删除停用词]]></title>
    <url>%2F2018%2F10%2F23%2F%E5%88%A0%E9%99%A4%E5%81%9C%E7%94%A8%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[删除停用词 - Python文本处理教程™ 停用词是对句子没有多大意义的英语单词。 在不牺牲句子含义的情况下，可以安全地忽略它们。 例如，the, he, have等等的单词已经在名为语料库的语料库中捕获了这些单词。 下载语料库 安装nltk模块 1pip install nltk 下载语料库 12import nltknltk.download('stopwords') 使用库料库 验证停用词 123456789101112131415161718192021222324252627&gt;&gt;&gt; from nltk.corpus import stopwords&gt;&gt;&gt; stopwords.words('english')['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she',"she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when','where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn',"mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"] 除了英语之外，具有这些停用词的各种语言如下。 12345&gt;&gt;&gt; stopwords.fileids()['arabic', 'azerbaijani', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian','spanish', 'swedish', 'turkish'] 示例 从单词列表中删除停用词。 12345678910111213&gt;&gt;&gt; from nltk.corpus import stopwords&gt;&gt;&gt; en_stops = set(stopwords.words('english'))&gt;&gt;&gt; &gt;&gt;&gt; all_words = ['There', 'is', 'a', 'tree','near','the','river']&gt;&gt;&gt; for word in all_words: if word not in en_stops: print(word) Theretreenearriver]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PCA]]></title>
    <url>%2F2018%2F10%2F22%2FPCA%2F</url>
    <content type="text"><![CDATA[引言PCA全称Principal Component Analysis，即主成分分析，是一种常用的数据降维方法。它可以通过线性变换将原始数据变换为一组各维度线性无关的表示，以此来提取数据的主要线性分量。 向量的投影现有两个任意不共线向量$\vec{u}, \vec{v}$，将$\vec{u}$投射到$\vec{v}$上 投影后，可以得到两个正交向量 \vec{u}' · (\vec{u} - \vec{u}') = 0我们设 \vec{u}' = \mu \vec{v} \tag{1}代入后有 \mu \vec{v} · (\vec{u} - \mu \vec{v}) = 0引入矩阵运算，即 (\mu v)^T (u - \mu v) = 0有 v^T u = \mu v^T v则得到$u’$以$v$为基向量的坐标 \mu = (v^T v)^{-1} v^T u \tag{2}所以得到 u' = v (v^T v)^{-1} v^T u \tag{*} 坐标变换求解投影向量：$u’$可视作$u$经坐标变换$u’ = P u$得到，所以 P = v (v^T v)^{-1} v^T 推广至多个向量的投影，即得到 P = X (X^T X)^{-1} X^T这与线性回归中得到的结论一致。 实际上 u' = v (v^T v)^{-1} v^T u = \frac{v}{||v||} (\frac{v}{||v||})^T u记单位向量$\frac{v}{||v||}$为$v_0$，得到 u' = v_0 v_0^T u由几何关系，可以计算得投影后的长度为 d = ||u|| \cos \theta = ||u|| \frac{v^T u}{||u||||v||} = v_0^T u所以在向量投影中，$u^T v_0$表示以$v_0$为基向量的坐标。 PCA现在有$N$维数据集$D=\{x^{(1)}, x^{(2)}, …, x^{(M)}\}$，其中$x^{(i)} = \left[x^{(i)}_1, x^{(i)}_2, …, x^{(i)}_N\right]^T$，各维特征$D_{j}$间存在线性相关性，利用主成分分析可使 数据维度降低； 提取主成分，且各成分间不相关。 说明 由于选取的特征轴是正交的，所以计算结果线性无关； 提取了方差较大的几个特征，为主要线性分量。 以二维空间中的数据$x^{(i)} = \left[\begin{matrix} x^{(i)}_1 \\ x^{(i)}_2\end{matrix}\right]$为例，维度可降至一维，如下图所示。 主轴可有无穷多种选择，那么问题就是如何选取最优的主轴。先给出PCA的计算步骤。 计算步骤输入的$M$个$N$维样本，有样本矩阵 X_{N×M} = \left[x^{(1)}, x^{(2)}, ..., x^{(M)} \right] = \left[ \begin{matrix} x^{(1)}_1 & x^{(2)}_1 & ... & x^{(M)}_1 \\ x^{(1)}_2 & x^{(2)}_2 & ... & x^{(M)}_2 \\ ... \\ x^{(1)}_N & x^{(2)}_N & ... & x^{(M)}_N \\ \end{matrix} \right]投影 对每个维度(行)进行去均值化 X_j := X_j - \mu_j 其中$\mu_j = \overline{X_j}$，$j = 1, 2, …, N$ 求各维度间的协方差矩阵$\Sigma_{N×N}$ \Sigma_{ij} = Cov(x_i, x_j) 或 \Sigma = \frac{1}{M} X X^T 注： X X^T = \left[ \begin{matrix} \sum_{i=1}^M x^{(i)}_1 x^{(i)}_1 & \sum_{i=1}^M x^{(i)}_1 x^{(i)}_2 & ... & \sum_{i=1}^M x^{(i)}_1 x^{(i)}_N \\ \sum_{i=1}^M x^{(i)}_2 x^{(i)}_1 & \sum_{i=1}^M x^{(i)}_2 x^{(i)}_2 & ... & \sum_{i=1}^M x^{(i)}_2 x^{(i)}_N \\ ... & ... & ... & ... \\ \sum_{i=1}^M x^{(i)}_N x^{(i)}_1 & \sum_{i=1}^M x^{(i)}_N x^{(i)}_2 & ... & \sum_{i=1}^M x^{(i)}_N x^{(i)}_N \end{matrix} \right] = \sum_{i=1}^M \left[ \begin{matrix} x^{(i)}_1 x^{(i)}_1 & x^{(i)}_1 x^{(i)}_2 & ... & x^{(i)}_1 x^{(i)}_N \\ x^{(i)}_2 x^{(i)}_1 & x^{(i)}_2 x^{(i)}_2 & ... & x^{(i)}_2 x^{(i)}_N \\ ... & ... & ... & ... \\ x^{(i)}_N x^{(i)}_1 & x^{(i)}_N x^{(i)}_2 & ... & x^{(i)}_N x^{(i)}_N \end{matrix} \right] = \sum_{i=1}^M x^{(i)} x^{(i)T} 协方差定义式 Cov(x,y)≝\frac{1}{n-1} ∑_{i=1}^n (x_i−\overline{x})^T(y_i−\overline{y})其中$x=[x_1, x_2, …, x_n]^T, y=[y_1, y_2, …, y_n]^T$ 求协方差矩阵$\Sigma$的特征值$λ_i$及其对应特征向量$α_i$，$i=1, …, N$； 按照特征值从大到小排列特征对$(λ_i,α_i)$，选取$K$个最大特征值对应的特征向量作为降维后的主轴$ \beta_1, \beta_2, …, \beta_K $，其中$\beta_k$为单位向量 \beta_k = \left[ \beta_{k1}, \beta_{k2}, ..., \beta_{kN} \right]^T记 B_{N×K} = \left[ \beta_1, \beta_2, ..., \beta_K \right]$K$的选取方法有如下两种： 指定选取$K$个主轴 保留$99\%$的方差\frac{\sum_{i=1}^K \lambda_i}{\sum_{j=1}^N \lambda_j} > 0.99 将样本点投射到$K$维坐标系上 样本$X^{(i)}$投射到主成分轴$\beta_k$上，其坐标表示为向量，为 S^{(i)}_k = X^{(i)T}\beta_k 注意此时的基座标为$\beta_k$，或者说$X’^{(i)} = S^{(i)} \frac{\beta_k}{||\beta_k||}$ 所有样本在主轴$\beta_k$上的投影坐标即 S = B^T X 其中$S_{K×M}$，$B_{N×K}$，$X_{N×M}$ 注：若取$K=N$，可重建数据，如下 复原第$5$步中，样本点向量$X^{(i)}$的主要分量投射到$K$个$N$维向量上，投影坐标为$S^{(i)}_k$，即 X^{(i)} \approx \sum_{k=1}^K S^{(i)}_k \beta_k以上就是样本点的复原公式，矩阵形式即 \hat{X} = BS其中$\hat{X}_{N×M}$，$B_{N×K}$，$S_{K×M}$ 考虑到已去均值化，故 \hat{X}_j \approx \hat{X}_j + \mu_j证明 投影向量的$2$范数最大，或者说，投影后的坐标平方和最大 当所有样本$X$投射到第一主轴$\beta_1$上，其坐标为 S_1 = X^T \beta_1所有元素的平方和，或向量$S_1$的$2$范数为 ||S_1||_2^2 = S_1^T S_1 = \beta_1^T X X^T \beta_1 \tag{1}即优化目标为 \max ||S_1||_2^2 s.t. ||\beta_1||_2^2 = 1矩阵$C=XX^T$为对称矩阵，故可单位正交化 C = W \Lambda W^T W = \left[\begin{matrix} | & & |\\ w_1 & ... & w_M\\ | & & |\\ \end{matrix}\right] \Lambda = \left[\begin{matrix} \lambda_1 & & \\ & ... & \\ & & \lambda_M\\ \end{matrix}\right]其中$\lambda_1 &gt; …&gt; \lambda_M$，$w_i(i=1,…,M)$为矩阵$C$的特征向量(单位向量，互相正交) 实际上$R(C) \leq (n-1)$，即最多有$(n-1)$个特征值大于$0$。 ||S_1||_2^2 = \beta_1^T W \Lambda W^T \beta_1 \tag{2}令$\alpha_1 = W^T \beta_1, \beta_1 = W \alpha_1$，可得 ||S_1||_2^2 = \alpha_1^T \Lambda \alpha_1 \tag{3}即 ||S_1||_2^2 = \sum_{i=1}^M \lambda_i \alpha_{1i}^2 \tag{4}进一步 \sum_{i=1}^M \lambda_i \alpha_{1i}^2 \leq \lambda_1 \sum_{i=1}^M \alpha_{1i}^2 \tag{5}且由于$\beta_1^T\beta_1 = 1$，故 1 = \beta_1^T\beta_1 = \alpha_1^T W^T W \alpha = \alpha^T \alpha = \sum_{i=1}^M \alpha_{1i}^2可得 ||S_1||_2^2 = \sum_{i=1}^M \lambda_i \alpha_{1i}^2 \leq \lambda_1 \tag{6}为使$(6)$取等号，即达最大值，可使 \begin{cases} \alpha_{11} = 1 \\ \alpha_{12} = ... = \alpha_{1M} = 0 \end{cases}即令 \beta_1 = W \alpha_1 = w_1 $\alpha_1 = [1, 0, …, 0]^T$ 所以$\beta_1$对应矩阵$C=XX^T$的特征向量$w_1$，且有 ||S_1||_2^2 = \lambda_1 或者第一主成分的证明也可以这样，建立优化目标 \beta_1 = \arg \max ||S_1||_2^2s.t. ||\beta_1||_2^2 = 1构造拉格朗日函数 L(\beta_1, \lambda_1) = ||S_1||_2^2 + \lambda_1 (1 - ||\beta_1||_2^2)也即 L(\beta_1, \lambda_1) = \beta_1^T X X^T \beta_1 + \lambda_1 (1 - \beta_1^T \beta_1)求其极值点 ▽_{\beta_1}L(\beta_1) = 2 X X^T \beta_1 - 2 \lambda_1 \beta_1 = 0有 X X^T \beta_1 = \lambda_1 \beta_1可见$\beta_1$即方阵$X X^T$的特征向量 当我们希望用更多的主成分刻画数据，如已经求得主成分$\beta_1, …, \beta_{r-1}$，先需求解$\beta_r$，引入正交约束$\beta_r^T \beta_i = 0$，即目标函数为 ||S_r||_2^2 = \beta_r^T C \beta_r s.t. \beta_r^T \beta_i = 0, i = 1, ..., r-1 ||\beta_r||_2^2 = 1令$\beta_r = W \alpha_r$，则 ||S_r||_2^2 = \alpha_r^T \Lambda \alpha_r = \sum_i \lambda_i \alpha_{ri}^2而根据正交约束 0 = \beta_r^T \beta_i = \alpha_r^T W^T w_i = \alpha_{ri}, i = 1, ..., r-1 $ W^T w_i = \left[0, …, 1_i, …, 0\right]^T$ 所以 ||S_r||_2^2 = \sum_i \lambda_i \alpha_{ri}^2 = \lambda_r \alpha_{rr}^2 \tag{5}又因为$\beta_r^T \beta_r = 1$(单位向量)，故 \beta_r^T \beta_r = \alpha_r^T W^T W \alpha_r = \alpha_r^T \alpha_r = \sum_i \alpha_{ri}^2 = 1于是类似的，为使$(5)$取最大，取 \begin{cases} \alpha_{rr} = 1\\ \alpha_{ri} = 0, i = 1, ..., M, i \neq r \end{cases} $\alpha_r = [0, …, 1_r, …, 0]$ 则此时 \beta_r = W \alpha_r = w_r且有 ||S_r||_2^2 = \lambda_r证毕。 白化(whitening)whitening的目的是去掉数据之间的相关联度，是很多算法进行预处理的步骤。比如说当训练图片数据时，由于图片中相邻像素值有一定的关联，所以很多信息是冗余的。这时候去相关的操作就可以采用白化操作。 数据的whitening必须满足两个条件： 不同特征间相关性最小，接近$0$； 所有特征的方差相等（不一定为$1$）。 常见的白化操作有PCA whitening和ZCA whitening。 Whitening - Ufldl PCA whitening PCA whitening指将数据$X$经过PCA降维为$S$后，可以看出$S$中每一维是独立的，满足whitening的第一个条件，这是只需要将$S$中的每一维都除以标准差就得到了每一维的方差为$1$，也就是说方差相等。 X_{PCAwhite, j} = \frac{X_{rot, j}}{\sqrt{\lambda_j}} ZCA whitening ZCA whitening是指数据$X$先经过PCA变换为$S$，但是并不降维，因为这里是把所有的成分都选进去了。这是也同样满足whtienning的第一个条件，特征间相互独立。然后同样进行方差为$1$的操作，最后将得到的矩阵左乘一个特征向量矩阵$U$即可。 X_{ZCAwhite} = U · X_{PCAwhite} Kernel PCAKernel PCA的思想是在高维的特征空间中求解协方差矩阵 \Sigma = \frac{1}{M} \sum_{i=1}^M \Phi(X^{(i)}) \Phi(X^{(i)})^T其中$\Phi(X^{(i)})$表示将样本$i$映射到高维空间后中的向量，即 \Phi(X^{(i)}) = \left[ \phi^{(i)}_1, \phi^{(i)}_2, ..., \phi^{(i)}_{N'} \right]^T其中$N’ &gt; N$，由于$\Phi(X^{(i)})$为隐式的，故设置核函数求解，记 \kappa(i, j) = \Phi(X^{(i)}) \Phi(X^{(i)})^T 关于核技巧，移步非线性支持向量机 应用可利用PCA与线性回归求解$3$维空间中平面的法向量 利用PCA重建数据(不降维，此时为$3$维)，此时第$1, 2$主成分轴可张成所求平面，即该平面可表示为 \Pi = span \{ \beta_1, \beta_2 \} 就是说，第一、二主成分是这些点“拉伸”最大的方向 :-)，好懂不？ 由正交投影可知，平面外一点$y$可通过最小二乘(线性回归)的方法投射到平面上，向量运算，不考虑偏置项，即 \hat{y} = \theta_1 x_1 + \theta_2 x_2 \tag{*} 其中$x_1, x_2$表示第一、第二主成分$\beta_1, \beta_2$，为$3$维向量 \hat{y} = \left[ \begin{matrix} \hat{y_1} \\ \hat{y_2} \\ \hat{y_3} \\ \end{matrix} \right] x_i = \left[ \begin{matrix} x_{i1} \\ x_{i2} \\ x_{i3} \\ \end{matrix} \right] 可利用公式求解回归参数$\theta$ \theta = (X^TX+\lambda I)^{-1} X^T y 注意：$X(n_samples, n_features)$，这里把$(x_{1j}, x_{2j}, y_{j})作为一组样本$ 此时该参数表示在主轴上的坐标$(\theta_1, \theta_2)$，带回$(*))$即可解得$\hat{y}$ \hat{y} = \theta_1 \beta_1 + \theta_2 \beta_2 \tag{*} 通俗理解，一掌把$y$拍平在了平面$\Pi$上，变成了$\hat{y}$，但是哪有这么好拍。。。这个时候刺在掌心里一定有一个垂直的向量分量，即为该平面的法向量 \vec{n} = y - \hat{y} 也可使用粗暴一点的方法，直接将第三主成分作为法向量。 或者直接上投影公式： \hat{y} = Py P = X (X^TX+\lambda I)^{-1} X^T ![projection](/PCA/projection.jpg) 总体的运算流程如下 - 利用所有样本点(近似平面)计算主成分，第一、二主成分张成平面$\Pi$； - 选出其中一个样本点，将平行于平面$\Pi$的成分投射到$\Pi$上； - 该样本点剩余分量即法向量； - 一般来说，取所有点法向量的均值。 程序@Github: PCA 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class PrincipalComponentAnalysis(): def __init__(self, n_component=-1): self.n_component = n_component self.meanVal = None self.axis = None def fit(self, X, prop=0.99): ''' the parameter 'prop' is only for 'n_component = -1' ''' # 第一步: 归一化 self.meanVal = np.mean(X, axis=0) # 训练样本每个特征上的的均值 X_normalized = (X - self.meanVal) # 归一化训练样本 # 第二步：计算协方差矩阵 # cov = X_normalized.T.dot(X_normalized) cov = np.cov(X_normalized.T) # 协方差矩阵 eigVal, eigVec = np.linalg.eig(cov) # EVD order = np.argsort(eigVal)[::-1] # 从大到小排序 eigVal = eigVal[order] eigVec = eigVec.T[order].T # 选择主成分的数量 if self.n_component == -1: sumOfEigVal = np.sum(eigVal) sum_tmp = 0 for k in range(eigVal.shape[0]): sum_tmp += eigVal[k] if sum_tmp &gt; prop * sumOfEigVal: # 平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的 K 值 self.n_component = k + 1 break # 选择投影坐标轴 self.axis = eigVec[:, :self.n_component] # 选择前n_component个特征向量作为投影坐标轴 def transform(self, X): # 第一步：归一化 X_normalized = (X - self.meanVal) # 归一化测试样本 # 第二步：投影 X_nxk · V_kxk' = X'_nxk' X_transformed = X_normalized.dot(self.axis) return X_transformed def fit_transform(self, X, prop=0.99): self.fit(X, prop=prop) return self.transform(X) def transform_inv(self, X_transformed): # 视投影向量长度为一个单位长度，投影结果为投影向量上的坐标 # X'_nxk' · V_kxk'.T = X''_nxk X_restructed = X_transformed.dot(self.axis.T) # 还原数据 X_restructed = X_restructed + self.meanVal return X_restructed 实验结果 Demo1: PCA applied on 2-d datasets Demo2: PCA applied on wild face origin reduced restructured]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activate Functions]]></title>
    <url>%2F2018%2F10%2F20%2FActivate-Functions%2F</url>
    <content type="text"><![CDATA[SigAI 理解神经网络的激活函数机器学习笔记：形象的解释神经网络激活函数的作用是什么？ - 不说话的汤姆猫 - 博客园 激活函数的作用复合函数神经网络可以看作一个多层复合函数，以下图隐含层的激活函数为例，讲解其非线性作用。 记激活函数为$\sigma(·)$，上图神经网络各层间具有如下关系 a = \sigma(w^{(1)}_{11}x + w^{(1)}_{12}y + b^{(1)}_1)b = \sigma(w^{(1)}_{21}x + w^{(1)}_{22}y + b^{(1)}_2)c = \sigma(w^{(1)}_{31}x + w^{(1)}_{32}y + b^{(1)}_3)输出层采用线性单元 A = w^{(2)}_{1}a + w^{(2)}_{2}b + w^{(2)}_{3}c + b^{(2)} 为便于作图，固定参数 W^{(1)} = \left[ \begin{matrix} 1 & 1 \\ 0.1 & -1 \\ 1 & -1 \end{matrix} \right], b^{(1)} = \left[ \begin{matrix} -2 \\ 1.5 \\ -1 \end{matrix} \right] W^{(2)} = \left[ \begin{matrix} 1 & 2 & 3 \end{matrix} \right], b^{(2)} = \left[ \begin{matrix} -1 \end{matrix} \right] 线性单元作为激活函数 此时神经网络的输出为 A = (x + y - 2) + 2 (0.1x - y + 1.5) + 3 (x - y - 1)- 1 可见仍为线性函数，做出图像如下所示 非线性单元作为激活函数 此时神经网络的输出为 A = \sigma(x + y - 2) + 2 \sigma(0.1x - y + 1.5) + 3 \sigma(x - y - 1)- 1 激活函数选择Sigmoid，做出图像如下所示 分割平面神经网络可实现逻辑运算，各个神经元视作分割超平面时，可分割出不同形状的平面，在线性和非线性激活函数时分割效果如图。当神经元组合的情况更复杂时，表达能力就会更强。 激活函数的性质已经证明，只要激活函数选择得当，神经元个数足够多，使用3层即包含一个隐含层的神经网络就可以实现对任何一个从输入向量到输出向量的连续映射函数的逼近，这个结论称为万能逼近（universal approximation）定理。 如果$\varphi(x)$是一个非常数、有界、单调递增的连续函数，$I_{m}$是$m$维的单位立方体，$I_{m}$中的连续函数空间为$C(I_{m})$。对于任意$\varepsilon&gt;0$以及函数$f\in C(I_{m})$，存在整数$N$，实数$v_{i},b_{i}$，实向量$w_{i}\in R^{m}$，通过它们构造函数$F(x)$作为函数$f$的逼近： F(x) = \sum_{i=1}^N v_i \varphi(w_i^T x + b_i)对任意的$X\in I_{m}$满足： | F(x) - f(x) | < \varepsilonCybenko, G. Approximation by superpositions of a sigmoid function. Mathematics of Control, Signals, and Systems, 2, 303-314, 1989. 这个定理对激活函数的要求是必须非常数、有界、单调递增，并且连续。 神经网络的训练使用梯度下降法进行求解，需要计算损失函数对参数的梯度值，涉及到计算激活函数的导数，因此激活函数必须是可导的。实际应用时并不要求它在定义域内处处可导，只要是几乎处处可导即可。 定义$R$为一维欧氏空间，$E\subset R$是它的一个子集，$mE$为点集$E$的Lebesgue测度。如果$E$为$R$中的可测集，$f(x)$为定义在上$E$的实函数，如果存在$N\subset E$，满足：$mN=0$，对于任意的$x_{0}\in E/N$函数$f(x)$在$x_{0}$处都可导，则称$f(x)$在$E$上几乎处处可导。 如果将激活函数输入值$x$看做是随机变量，则它落在这些不可导点处的概率是$0$。在计算机实现时，因此有一定的概率会落在不可导点处，但概率非常小。 例如ReLU函数在$x=0$处不可导 f(x) = \begin{cases} x & x \geq 0 \\ 0 & x < 0 \end{cases} 常用的激活函数]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Deep Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Feedforward Neural Network]]></title>
    <url>%2F2018%2F10%2F20%2FFeedforward-Neural-Network%2F</url>
    <content type="text"><![CDATA[前言前馈神经网络是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层．各层间没有反馈。是目前应用最广泛、发展最迅速的人工神经网络之一，既可以用于解决分类问题，也可以用于解决回归问题。 简介前馈神经网络也叫作多层感知机，包含输入层，隐含层和输出层三个部分。它的目的是为了实现输入到输出的映射。 y = f(x;W)由于各层采用了非线性激活函数，神经网络具有良好的非线性特性，如下图所示。 激活函数为线性单元 激活函数为非线性单元 前馈神经网络可用于解决非线性的分类或回归问题，参数通过反向传播算法(Back Propagation)学习。 结构神经元与网络结构图单个神经元的示意图如下，输入为前一层的输出参数$X^{(l-1)}$ h_{w, b}(x) = \sigma (WX + b)$\sigma(·)$表示激活函数。 以下为典型的神经网络结构图 第一层为输入层input layer，一般不设置权值，预处理在输入网络前完成； 最后一层为输出层output layer； 其余层称为隐藏层hidden layer，隐藏层用于提取数据特征，隐藏层层数与各层神经元个数为超参数。 神经元权值取值不同，可实现不同的逻辑运算，单个超平面只能进行二元划分，利用逻辑运算可将多个超平面划分的区域拼接起来，如图 以下说明逻辑运算的实现方法其中 f(z) = \begin{cases} 1 & z \geq 0 \\ 0 & otherwise \end{cases} 与运算 $a ∧ b$ w_1 = 20, w_2 = 20, b = -30 或运算 $a ∧ b$ w_1 = 20, w_2 = 20, b = -10 非运算 $a = \overline{b}$ w_1 = -20, w_2 = 0, b = 0 异或运算 $a \bigoplus b$，可通过组合运算实现 a \bigoplus b = (\overline{a} ∧ b) ∨ (a ∧ \overline{b}) 激活函数 隐藏层的激活函数，详情可查看另一篇博文：神经网络的激活函数； 输出层的激活函数 回归问题时，采用线性单元即可 f(x) = x 分类问题时，一般有以下几种选择 单类别概率输出 即每个神经元的输出对应该类别的$0-1$分布输出，这就需要将输出值限制在$[0, 1]$内，例如 P(y=1|x )= max\{0, min\{1, z\}\} 但是可以看到，当$(w^Tx+b)$处于单位区间外时，模型的输出对它的参数的梯度都将为$0$ ，不利于网络的训练，故采用$S$形函数Sigmoid(详情) P(y=1|x ) = \frac{1}{1+e^{-(w^Tx+b)}} $(1)$ Sigmoid函数定义域为$(-\infty, \infty)$，值域为$(0, 1)$，且在整个定义域上单调递增，即为单值函数，故可将线性输出单元的结果映射到$(0, 1)$范围内；$(2)$ 在定义域上处处可导。 多类别的概率输出 即每个神经元的输出对应判别为该类别的概率，且有 \sum_{i=1}^C y_i = 1 例如 y_i = \frac{z_i}{\sum_j z_j} 但是分式求导异常麻烦，故采用Softmax函数(详情)作为输出结点的激活函数，该函数求导结果比较简洁，且可利用输出计算导数，计算量减少。 Softmax(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right] 损失函数 回归问题 常见的用于回归问题的损失函数为MSE，即 L(y, \hat{y}) = \frac{1}{2M} \sum_{i=1}^M (\hat{y}^{(i)} - y^{(i)})^2 分类问题 一般采用交叉熵作为损失函数，如下 L(\hat{y}, y) = - \frac{1}{M} \sum_{i=1}^M 1\{y^{(i)}_j=k\} \log (\hat{y}^{(i)}_j) 1\{y^{(i)}_j=k\} = \begin{cases} 1 & y^{(i)}_j = k \\ 0 & y^{(i)}_j \neq k \end{cases} j = 1, ..., N 或者 L(\hat{y}, y) = - \frac{1}{M} \sum_{i=1}^M y^{(i)T} \log (\hat{y}^{(i)}) 其中$y^{(i)}, \hat{y}^{(i)}$均表示向量，采用one-hot编码。 梯度推导以上内容网上资料一大堆，进入重点，反向传播时的梯度推导，给出网络结构如下。 回归与分类在输出层有所区别； 各层激活函数的输入变量以$z^{(l)}$表示，输出变量均以$x^{(l)}$表示； $W^{(l)}$表示从第$l$层到第$(l+1)$层的权值矩阵，则$w^{(l)}_{ij}$表示第$l$层第$j$个神经元到$(l+1)$层第$i$个神经元的连接权值； $b^{(l)}$表示第$l$层到第$(l+1)$层的偏置，则$b^{(l)}_i$表示到第$(l+1)$层第$i$个神经元的偏置值； 各层变量维度推广为输入$d_{i}$，中间层$d_{h}$，输出层$d_{o}$； 全连接，部分线条已省略，激活函数已省略； 则各层参数矩阵为 W^{(1)} = \left[ \begin{matrix} w^{(1)}_{11} & ... & w^{(1)}_{1d_i} \\ ... & ... & ... \\ w^{(1)}_{d_h1} & ... & w^{(1)}_{d_hd_i} \end{matrix} \right] b^{(1)} = \left[ \begin{matrix} b^{(1)}_{1} \\ ... \\ b^{(1)}_{d_h} \end{matrix} \right] W^{(2)} = \left[ \begin{matrix} w^{(2)}_{11} & ... & w^{(2)}_{1d_h} \\ ... & ... & ... \\ w^{(2)}_{d_o1} & ... & w^{(2)}_{d_od_h} \end{matrix} \right] b^{(2)} = \left[ \begin{matrix} b^{(2)}_{1} \\ ... \\ b^{(2)}_{d_o} \end{matrix} \right]有 Z^{(2)} = W^{(1)} X^{(1)} + b^{(1)} X^{(2)} = \sigma_1 (Z^{(2)}) Z^{(3)} = W^{(2)} X^{(2)} + b^{(2)} X^{(3)} = \sigma_2 (Z^{(3)}) X^{(1)} = X \hat{Y} = X^{(3)}回归问题损失函数采用MSE，即 L(Y, \hat{Y}) = \frac{1}{M} \sum_{i=1}^M L(Y^{(i)}, \hat{Y}^{(i)}) L(Y^{(i)}, \hat{Y}^{(i)}) = \frac{1}{2} || \hat{Y}^{(i)} - Y^{(i)} ||_2^2 = \frac{1}{2} \sum_{d_2=1}^{d_o} (\hat{y}^{(i)}_{d_2} - y^{(i)}_{d_2})^2下面推导单个样本的损失函数的梯度，该批数据的梯度为均值。 省略样本标记$^{(i)}$ 隐含层到输出层 对权值矩阵的梯度 \frac{∂L}{∂w^{(2)}_{ij}} = \frac{∂}{∂w^{(2)}_{ij}} \frac{1}{2} \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2})^2 = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \frac{∂}{∂w^{(2)}_{ij}} \hat{y}_{d_2} \tag{1} 其中 \begin{cases} \hat{y}_{d_2} = \sigma_2 (z_{d_2}^{(3)}) \\ z_{d_2}^{(3)} = \sum_{d_1=1}^{d_h} w^{(2)}_{d_2 d_1} x^{(2)}_{d_1} + b^{(2)}_{d_2} \end{cases} 且 \frac{∂}{∂w^{(2)}_{ij}} \hat{y}_{d_2} = \sigma_2' (z_{d_2}^{(3)}) \frac{∂z_{d_2}^{(3)}}{∂w^{(2)}_{ij}} \tag{2} \frac{∂}{∂w^{(2)}_{ij}} z_{d_2}^{(3)} = \begin{cases} x^{(2)}_{d_1} & d_1 = j, d_2 = i \\ 0 & otherwise \end{cases} \tag{3} $(3)$代入$(2)$，再代入$(1)$可得到 \frac{∂L}{∂w^{(2)}_{ij}} = (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) x^{(2)}_{d_1} | _{d_1=j, d_2=i} = (\hat{y}_{i} - y_{i}) \sigma_2' (z_{i}^{(3)}) x^{(2)}_{j} \tag{*1} 对偏置矩阵的梯度 \frac{∂L}{∂b^{(2)}_i} = \frac{∂}{∂b^{(2)}_i} \frac{1}{2} \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2})^2 = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \frac{∂}{∂b^{(2)}_i} \hat{y}_{d_2} \tag{4} 其中 \begin{cases} \hat{y}_{d_2} = \sigma_2 (z_{d_2}^{(3)}) \\ z_{d_2}^{(3)} = \sum_{d_1=1}^{d_h} w^{(2)}_{d_2 d_1} x^{(2)}_{d_1} + b^{(2)}_{d_2} \end{cases} 有 \frac{∂}{∂b^{(2)}_i} z_{d_2}^{(3)} = \begin{cases} 1 & d_2 = i \\ 0 & otherwise \end{cases} \tag{5} 所以 \frac{∂L}{∂b^{(2)}_i} = (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) | _{d_2=i} = (\hat{y}_{i} - y_{i}) \sigma_2' (z_i^{(3)}) \tag{*2} 输入层到隐含层 对权值矩阵的梯度 \frac{∂L}{∂w^{(1)}_{ij}} = \frac{∂}{∂w^{(1)}_{ij}} \frac{1}{2} \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2})^2 = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \frac{∂}{∂w^{(1)}_{ij}} \hat{y}_{d_2} \tag{6} 其中 \begin{cases} \hat{y}_{d_2} = \sigma_2 (z_{d_2}^{(3)}) \\ z_{d_2}^{(3)} = \sum_{d_1=1}^{d_h} w^{(2)}_{d_2 d_1} x^{(2)}_{d_1} + b^{(2)}_{d_2} \\ x^{(2)}_{d_1} = \sigma_1 (z_{d_1}^{(2)}) \\ z_{d_1}^{(2)} = \sum_{d_0=1}^{d_i} w^{(1)}_{d_1 d_0} x^{(1)}_{d_0} + b^{(1)}_{d_1} \end{cases} 故 \frac{∂}{∂w^{(1)}_{ij}} \hat{y}_{d_2} = \frac{∂\hat{y}_{d_2}}{∂z_{d_2}^{(3)}} \frac{∂z_{d_2}^{(3)}}{∂w^{(1)}_{ij}} \tag{7} 其中 \frac{∂\hat{y}_{d_2}}{∂z_{d_2}^{(3)}} = \sigma_2' (z_{d_2}^{(3)}) \tag{8} \frac{∂z_{d_2}^{(3)}}{∂w^{(1)}_{ij}} = \sum_{d1=1}^{d_h} w^{(2)}_{d_2 d_1} \frac{∂x^{(2)}_{d_1}}{∂w^{(1)}_{ij}} \tag{9} \frac{∂x^{(2)}_{d_1}}{∂w^{(1)}_{ij}} = \frac{∂x^{(2)}_{d_1}}{∂z_{d_1}^{(2)}} \frac{∂z_{d_1}^{(2)}}{∂w^{(1)}_{ij}} \tag{10} 而其中 \frac{∂x^{(2)}_{d_1}}{∂z_{d_1}^{(2)}} = x^{(2)}_{d_1} = \sigma_1' (z_{d_1}^{(2)}) \tag{11} \frac{∂z_{d_1}^{(2)}}{∂w^{(1)}_{ij}} = \begin{cases} x^{(1)}_{d_0} & d_1 = i, d_0 = j\\ 0 & otherwise \end{cases} \tag{12} $(11),(12)$代入$(10)$得到 \frac{∂x^{(2)}_{d_1}}{∂w^{(1)}_{ij}} = \sigma_1' (z_{d_1}^{(2)}) x^{(1)}_{d_0} | _{d_1 = i, d_0 = j} \tag{13} $(13)$代回$(9)$，有 \frac{∂z_{d_2}^{(3)}}{∂w^{(1)}_{ij}} = \sum_{d1=1}^{d_h} \left[ w^{(2)}_{d_2 d_1} \sigma_1' (z_{d_1}^{(2)}) x^{(1)}_{d_0} \right] | _{d_1 = i, d_0 = j} = w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j \tag{14} 将$(8),(14)$代入$(7)$得到 \frac{∂}{∂w^{(1)}_{ij}} \hat{y}_{d_2} = \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j \tag{15} $(15)$代入$(6)$有 \frac{∂L}{∂w^{(1)}_{ij}} = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j \tag{*3} 对偏置矩阵的梯度 \frac{∂L}{∂b^{(1)}_i} = \frac{∂}{∂b^{(1)}_i} \frac{1}{2} \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2})^2 = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \frac{∂}{∂b^{(1)}_i} \hat{y}_{d_2} \tag{16} 同理可得 \frac{∂}{∂b^{(1)}_i} \hat{y}_{d_2} = \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) \tag{17} 所以 \frac{∂L}{∂b^{(1)}_i} = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) \tag{*4} 综上所述 \frac{∂L}{∂w^{(2)}_{ij}} = (\hat{y}_{i} - y_{i}) \sigma_2' (z_{i}^{(3)}) x^{(2)}_{j} \frac{∂L}{∂b^{(2)}_i} = (\hat{y}_{i} - y_{i}) \sigma_2' (z_i^{(3)}) \frac{∂L}{∂w^{(1)}_{ij}} = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j \frac{∂L}{∂b^{(1)}_i} = \sum_{d_2=1}^{d_o} (\hat{y}_{d_2} - y_{d_2}) \sigma_2' (z_{d_2}^{(3)}) w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)})令 \begin{cases} \delta^{(2)}_i = (\hat{y}_{i} - y_{i}) \sigma_2' (z_i^{(3)}) \\ \delta^{(1)}_i = \sum_{d_2=1}^{d_o} \delta^{(2)}_{d_2} w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) \end{cases}有 \begin{cases} \frac{∂L}{∂w^{(2)}_{ij}} = \delta^{(2)}_i x^{(2)}_{j}\\ \frac{∂L}{∂b^{(2)}_i} = \delta^{(2)}_i\\ \frac{∂L}{∂w^{(1)}_{ij}} = \delta^{(1)}_i x^{(1)}_j\\ \frac{∂L}{∂b^{(1)}_i} = \delta^{(1)}_i \end{cases}至此推导完毕。 当隐藏层采用Sigmoid函数，输出层采用线性单元，可得到 \sigma_1' (z_i^{(2)}) = \sigma_1 (z_i^{(2)}) \left[1 - \sigma_1 (z_i^{(2)}) \right] = x_i^{(2)} (1 - x_i^{(2)}) \sigma_2' (z_i^{(3)}) = z_i^{(3)}此时 \begin{cases} \frac{∂L}{∂w^{(2)}_{ij}} = (\hat{y}_{i} - y_{i}) z_i^{(3)} x^{(2)}_{j} \\ \frac{∂L}{∂b^{(2)}_i} = (\hat{y}_{i} - y_{i}) z_i^{(3)} \\ \frac{∂L}{∂w^{(1)}_{ij}} = \sum_{d_2=1}^{d_o} \delta^{(2)}_{d_2} w^{(2)}_{d_2 i} z_i^{(2)} x^{(1)}_j \\ \frac{∂L}{∂b^{(1)}_i} = \sum_{d_2=1}^{d_o} \delta^{(2)}_{d_2} w^{(2)}_{d_2 i} z_i^{(2)} \end{cases}可以看到，计算梯度时使用的数据在上一次前向传播时已计算得，故可减少计算量。 分类问题损失函数采用Cross Entropy，即 L(\hat{y}, y) = \frac{1}{M} \sum_{i=1}^M L(\hat{y}^{(i)}, y^{(i)}) L(\hat{y}^{(i)}, y^{(i)}) = - y^{(i)T} \log (\hat{y}^{(i)})上式中，$y^{(i)}, \hat{y}^{(i)}$均为列向量，且$y^{(i)}$表示one-hot编码后的标签向量，也可写作 L(\hat{y}^{(i)}, y^{(i)}) = - \log \hat{y}^{(i)}_{y^{(i)}} 由该式可以看出，若输出层激活函数采用Sigmoid作为激活函数，则隐藏层——输出层之间权值矩阵$W^{(2)}$只会更新$w^{(i)}_{y^{(i)} d_1}, d_1 = 1, …, d_h$； 一般采用SoftMax作为输出层激活函数，Sigmoid下面不作推导。 关于SoftMax的梯度，移步SoftMax Regression中查看详细推导过程，这里直接给出结论。对于 S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]其梯度为 \frac{∂S(x)}{∂x_i}_{K×1} = \left[ \begin{matrix} 0\\ ...\\ p_i\\ ...\\ 0 \end{matrix} \right] - \left[ \begin{matrix} p_i p_1\\ ...\\ p_i^2\\ ...\\ p_i p_K \end{matrix} \right] = \left( \left[ \begin{matrix} 0 \\ ...\\ 1\\ ...\\ 0 \end{matrix} \right] - p \right)p_i省略样本标记$^{(i)}$ 隐含层到输出层 对权值矩阵的梯度 \frac{∂L}{∂w^{(2)}_{ij}} = - \frac{∂}{∂w^{(2)}_{ij}} \log \hat{y}_{y} = - \frac{1}{\hat{y}_y} \frac{∂\hat{y}_{y}}{∂w^{(2)}_{ij}} \tag{18} 其中$\hat{y}_{y}$与$z^{(3)}_{d_2}(d_2 = 1, …, d_o) $均有联系，故 \frac{∂\hat{y}_{y}}{∂w^{(2)}_{ij}} = \sum_{d2=1}^{d_o} \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} \frac{∂z^{(3)}_{d_2}}{∂w^{(2)}_{ij}} \tag{19} 而 \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} = \begin{cases} \hat{y}_{y} (1 - \hat{y}_{d_2}) & d_2 = y \\ - \hat{y}_{y} \hat{y}_{d_2} & otherwise \end{cases} \frac{∂z^{(3)}_{d_2}}{∂w^{(2)}_{ij}} = \begin{cases} x^{(2)}_{d_1} & i = d_2, j = d_1 \\ 0 & otherwise \end{cases} $z^{(3)}_{d_2} = \sum_{d_1=0}^{d_h} w^{(2)}_{d_2d_1} x^{(2)}_{d_1} + b^{(2)}_{d_2}$ 代回$(19)$，再带回$(18)$，有 \frac{∂L}{∂w^{(2)}_{ij}} = - \frac{1}{\hat{y}_{y}} \sum_{d_2=1}^{d_o} \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} x^{(2)}_{d_1} | _{d_2=i, d_1=j} = \begin{cases} - \frac{1}{\hat{y}_{y}} \hat{y}_{y} (1 - \hat{y}_i) x^{(2)}_j & i = y \\ - \frac{1}{\hat{y}_{y}} (- \hat{y}_{y} \hat{y}_i) x^{(2)}_j & otherwise \end{cases} = \begin{cases} (\hat{y}_i - 1) x^{(2)}_j & i = y \\ \hat{y}_i x^{(2)}_j & otherwise \end{cases} 即 \frac{∂L}{∂w^{(2)}_{ij}} = (\hat{y}_i - y_i) x^{(2)}_j \tag{*5} 对偏置矩阵的梯度 \frac{∂L}{∂b^{(2)}_i} = \hat{y}_i - y_i \tag{*6} 输入层到隐含层 对权值矩阵的梯度 \frac{∂L}{∂w^{(1)}_{ij}} = - \frac{∂}{∂w^{(1)}_{ij}} \log \hat{y}_{y} = - \frac{1}{\hat{y}_{y}} \frac{∂\hat{y}_{y}}{∂w^{(1)}_{ij}} \tag{20} 其中 \frac{∂\hat{y}_{y}}{∂w^{(1)}_{ij}} = \sum_{d_2=1}^{d_o} \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} \frac{∂z^{(3)}_{d_2}}{∂w^{(1)}_{ij}} \tag{21} $\frac{∂z^{(3)}_{d_2}}{∂w^{(1)}_{ij}}$部分与回归相同，有 \frac{∂z_{d_2}^{(3)}}{∂w^{(1)}_{ij}} = w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j 由上面分析可得 \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} = \begin{cases} \hat{y}_{y} (1 - \hat{y}_{d_2}) & d_2 = y \\ - \hat{y}_{y} \hat{y}_{d_2} & otherwise \end{cases} 故代回$(20)$可得到 \frac{∂L}{∂w^{(1)}_{ij}} = - \frac{1}{\hat{y}_{y}} \sum_{d_2=1}^{d_o} \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} \frac{∂z^{(3)}_{d_2}}{∂w^{(1)}_{ij}} = - \frac{1}{\hat{y}_{y}} \sum_{d_2=1}^{d_o} \frac{∂\hat{y}_{y}}{∂z^{(3)}_{d_2}} w^{(2)}_{d_2 i} \sigma_1' (z_i^{(2)}) x^{(1)}_j = \left[ \sum_{d_2=1, d_2 \neq y}^{d_o} \hat{y}_{d_2} w^{(2)}_{d_2 i} + (\hat{y}_y - 1) w^{(2)}_{y i} \right] \sigma_1' (z_i^{(2)}) x^{(1)}_j = \left[ \sum_{d_2=1}^{d_o} \hat{y}_{d_2} w^{(2)}_{d_2 i} - w^{(2)}_{y i} \right] \sigma_1' (z_i^{(2)}) x^{(1)}_j \tag{*7} 对偏置矩阵的梯度 \frac{∂L}{∂b^{(1)}_i} = \left[ \sum_{d_2=1}^{d_o} \hat{y}_{d_2} w^{(2)}_{d_2 i} - w^{(2)}_{y i} \right] \sigma_1' (z_i^{(2)}) \tag{*8} 至此推导完毕。 这个推导，仅供参考 过拟合问题和其他算法一样，前馈神经网络也存在过拟合的问题，解决方法有以下几种 正则化 与线性回归类似，神经网络也可以加入范数惩罚项，以下$C$表示普通的损失函数，$\lambda$为惩罚系数，$n$为样本数目，$w$表示权值参数。 L1正则化 惩罚项为网络所有权值的绝对值之和。 C = C_0 + \frac{\lambda}{n} \sum_w |w| L2正则化 又称权值衰减weights decay，惩罚项为网络所有权值的平方和。 C = C_0 + \frac{\lambda}{2n} \sum_w w^2 Dropout 以概率大小为p使部分神经元输出值直接为0，如此可以使反向传播时相关权值系数不做更新，只有被保留下来的权值和偏置值会被更新。 增加训练数据大小 可在原数据上加以变换或噪声，图像的扩增方法可查看图像数据集扩增。 程序@Github: Code of Neural Network 使用PyTorch实现神经网络，以下为模型定义123456789101112131415class AnnNet(nn.Module): def __init__(self): super(AnnNet, self).__init__() self.input_size = 28 * 28 self.hidden_size = 100 self.output_size = 10 self.fc1 = nn.Linear(self.input_size, self.hidden_size) # input - hidden self.fc2 = nn.Linear(self.hidden_size, self.output_size ) # hidden - output # self.activate = nn.Sigmoid() # 参数更新非常慢，特别是层数多时 self.activate = nn.ReLU() # 事实证明ReLU作为激活函数更加合适 self.softmax = nn.Softmax() def forward(self, X): h = self.activate(self.fc1(X)) y_pred = self.softmax(self.fc2(h)) return y_pred]]></content>
  </entry>
  <entry>
    <title><![CDATA[分类问题的决策平面]]></title>
    <url>%2F2018%2F10%2F19%2F%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%86%B3%E7%AD%96%E5%B9%B3%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[引言对于分类问题，计算结果一般为概率值，那么如何根据计算得的概率进行判别分类呢？ 这部分理解后，Logistic回归与Softmax回归的模型就很容易推得。 判别函数对于一个类别为$K$的分类问题，如果对于所有的$ i,j=1,…,K, j\neq i$，有 g_i(x) > g_j(x)则此分类器将这个样本对应的特征向量$x$判别为$w_i$，则此分类器的作用是，计算$K$个判别函数并选取与最大判别值最大对应的类别。 判别函数的形式并不唯一，可以将所有的判别函数乘上相同的正常数或者加上一个相同的常量而不影响其判决结果。更一般的情况下，我们使用单调递增函数$f(·)$进行映射，将每一个$g_i(x)$替换成$f(g_i(x))$，分类结果不变。 ——《模式识别原理与应用课程笔记》 例如最小风险贝叶斯决策 正态分布下的判别函数 多元高斯分布（The Multivariate normal distribution） - bingjianing - 博客园 由大数定理可知，在样本足够的情况下，数据服从正态分布。多元正态分布形式如下 f(x) = \frac{1}{ (2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}}} exp(-\frac{1}{2} (x-\mu)^T \Sigma^{-1} (x-\mu))其中 x = [x_1, ..., x_n]^T\mu = [\mu_1, ..., \mu_n]^T\Sigma_{ij} = cov(x_i, x_j) 在最小错误率判别时 g_i(x) = P(x|c_i)P(c_i)即 g_i(x) = \frac{1}{ (2\pi)^{\frac{n}{2}} |\Sigma_i|^{\frac{1}{2}}} exp(-\frac{1}{2} (x-\mu_i)^T \Sigma^{-1} (x-\mu_i)) · P(c_i)取对数运算，并舍去常数项，展开整理得 g_i(x) = -\frac{1}{2}x^T \Sigma_i ^{-1} x + \mu_i^T \Sigma_i ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma_i ^{-1} \mu_i + ln P(c_i) \tag{0} 注： 协方差矩阵 $ \Sigma^T = \Sigma $ 1. $\Sigma_i = \sigma^2 I$$\Sigma_i^{-1} = \frac{1}{\sigma^2} I$代入$(0)$，有 g_i(x) = \frac{1}{\sigma^2}\mu_i^T x - \frac{1}{2\sigma^2} (x^Tx + \mu_i ^T \mu_i) + ln P(c_i)\tag{1}定义 w_i = \frac{1}{\sigma^2}\mu_i^Tw_0 = - \frac{1}{2\sigma^2} (x^Tx + \mu_i ^T \mu_i) + ln P(c_i)有一般形式如下，表示取$c_i$的概率 g_i(x) = w_i x + w_0\tag{2}设决策平面为 w^T (x−x_0)=0\tag{3}决策平面上，取$c_i$和$c_j$的概率相等，即 g_i(x) = g_j(x)可得 (\mu_i - \mu_j)^Tx = \frac{1}{2} (\mu_i ^T \mu_i - \mu_j ^T \mu_j) -ln \frac{P(c_i)}{P(c_j)} \tag{4} 推导过程如下，将$(1)$代入上式$ \frac{1}{\sigma^2}\mu_i^T x - \frac{1}{2\sigma^2} (x^Tx + \mu_i ^T \mu_i) + ln P(c_i) = \frac{1}{\sigma^2}\mu_j^T x - \frac{1}{2\sigma^2} (x^Tx + \mu_j ^T \mu_j) + ln P(c_j) $$ \mu_i^T x - \frac{1}{2} \mu_i ^T \mu_i + ln P(c_i) = \mu_j^T x - \frac{1}{2} \mu_j ^T \mu_j + ln P(c_j) $$ (\mu_i - \mu_j)^Tx = \frac{1}{2} (\mu_i ^T \mu_i - \mu_j ^T \mu_j) -ln \frac{P(c_i)}{P(c_j)} $ 由$(3)$$(4)$，利用待定系数法，可得 w = \mu_i - \mu_j w^T x_0 = \frac{1}{2} (\mu_i ^T \mu_i - \mu_j ^T \mu_j) -ln \frac{P(c_i)}{P(c_j)}特别地，当等先验概率时，即$P(c_i) = P(c_j)$时 w^T x_0 = \frac{1}{2} (\mu_i ^T \mu_i - \mu_j ^T \mu_j)故 x_0 = \frac{1}{2}(\mu_i + \mu_j)结论：等先验概率时超平面$ w^T (x−x_0)=0 $平分判别空间 $\mu_i$与$\mu_j$分别表示两个类别的中心，由向量运算，$x_0$为两类中心的连线的中点。 2. $\Sigma_i = \Sigma$代入$(0)$后可得 g_i(x) = \mu_i^T \Sigma ^{-1} x - \frac{1}{2}x^T \Sigma ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma ^{-1} \mu_i + ln P(c_i) \tag{5}定义 w_i = \mu_i^T \Sigma ^{-1}w_0 = - \frac{1}{2}x^T \Sigma ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma ^{-1} \mu_i + ln P(c_i)有一般形式如下，表示取$c_i$的概率 g_i(x) = w_i x + w_0\tag{6}同样的，设决策平面为 w^T (x−x_0)=0\tag{7}决策平面上，取$c_i$和$c_j$的概率相等，即 g_i(x) = g_j(x)有 (\mu_i - \mu_j)^T \Sigma ^{-1} x = \frac{1}{2} (\mu_i - \mu_j)^T \Sigma ^{-1} (\mu_i - \mu_j) - ln \frac{P(c_i)}{P(c_j)} $ \mu_i^T \Sigma ^{-1} x - \frac{1}{2}x^T \Sigma ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma ^{-1} \mu_i + ln P(c_i) = \mu_j^T \Sigma ^{-1} x - \frac{1}{2}x^T \Sigma ^{-1} x -\frac{1}{2} \mu_j ^T \Sigma ^{-1} \mu_j + ln P(c_j) $$ \mu_i^T \Sigma ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma ^{-1} \mu_i + ln P(c_i) = \mu_j^T \Sigma ^{-1} x -\frac{1}{2} \mu_j ^T \Sigma ^{-1} \mu_j + ln P(c_j) $$ (\mu_i - \mu_j)^T \Sigma ^{-1} x = \frac{1}{2} (\mu_i ^T \Sigma ^{-1} \mu_i + \mu_j ^T \Sigma ^{-1} \mu_j) - ln \frac{P(c_i)}{P(c_j)} $ 特别的，当取等先验概率时 (\mu_i - \mu_j)^T \Sigma ^{-1} x = \frac{1}{2} (\mu_i ^T \Sigma ^{-1} \mu_i + \mu_j ^T \Sigma ^{-1} \mu_j)由$(7)$$(8)$，利用待定系数法 w^T = (\mu_i - \mu_j)^T \Sigma^{-1}w^T x_0 = \frac{1}{2} (\mu_i ^T \Sigma ^{-1} \mu_i + \mu_j ^T \Sigma ^{-1} \mu_j) 注： 协方差矩阵 $ \Sigma^T = \Sigma $ w = \Sigma^{-1}(\mu_i - \mu_j)x_0 = \frac{1}{2} (\mu_i + \mu_j)由于通常$w=Σ^{−1}(μ_i−μ_j)$并非朝着$(μ_i−μ_j)$的方向，因而通常分离两类的超平面也并非与均值的连线垂直正交。但是， 如果先验概率相等，其判定面确实是与均值连线交于中点$x_0$处的。如果先验概率不等，最优边界超平面将远离可能性较大的均值。同前，如果偏移量足够大，判定面可以不落在两个均值向量之间。 3. $\Sigma_i = \Sigma_i(∀) $g_i(x) = -\frac{1}{2}x^T \Sigma_i ^{-1} x + \mu_i^T \Sigma_i ^{-1} x -\frac{1}{2} \mu_i ^T \Sigma_i ^{-1} \mu_i + ln P(c_i)定义 W_i = -\frac{1}{2} \Sigma_i ^{-1}w_i = \mu_i^T \Sigma_i ^{-1}w_0 = -\frac{1}{2} \mu_i ^T \Sigma_i ^{-1} \mu_i + ln P(c_i)有 g_i(x) = x^TW_ix + w_ix + w_0]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Bayes Decision]]></title>
    <url>%2F2018%2F10%2F18%2FBayes-Decision%2F</url>
    <content type="text"><![CDATA[原理基于贝叶斯公式 P(c_k|x)=\frac{p(x|c_k)P(c_k)}{p(x)}P(x)=\sum_j p(x|c_j)P(c_j)几种常用的贝叶斯决策最小错误率贝叶斯决策在分类问题中，我们往往希望尽可能减少分类错误，即目标是追求最小错误率。假设有$K$分类问题，由贝叶斯公式 P(c_k|x)=\frac{p(x|c_k)P(c_k)}{p(x)}上式中$ k=1,…,K $，各部分定义如下 $P(c_k|x)$——后验概率(posteriori probability)$P(c_k)$——先验概率(priori probability)，$p(x|c_k)$——$c_k$关于$x$的似然函数(likelihood)，$p(x)$——证据因子(evidence)， 证据因子由下式计算 p(x)=\sum_{j=0}^K p(x|c_j)P(c_j)以上就是从样本中训练的参数，在预测阶段，定义决策规则为 $if$ $P(c_i|x)&gt;P(c_j|x)$, $then$ $ x \in c_i $ 由于分母为标量，对于任意输入的样本特征$x$，$P(x)$一定，故决策规则可简化为 $if$ $P(x|c_i)P(c_i)&gt;P(x|c_j)P(c_j)$, $then$ $ x \in c_i $ 而对于分类错误的样本，如样本$x$属于分类$c_i$，但错误分类为$c_{err}, err \neq i$，样本的错误分类概率为 P(error|x) = P(c_{err}|x)上式被称作误差概率，某类后验概率越大，则相应的误差概率就越小，定义平均误差概率 P_{mean} = \int P(error|x)P(x)dx带有拒绝域的最小错误率贝叶斯决策一些情况下，某样本对应特征$x$计算结果中，属于各类别的概率没有显著比较大的数值，换句话说都比较小，那么对这次的判别就不太信任，选择拒绝决策结果。将决策平面划分为两个区域 Acquired = \{x|max_j P(c_j|x)\geq 1-t\}Rejected = \{x|max_j P(c_j|x) < 1-t\}其中$t$为阈值，$t$越小时，拒绝域$Rejected$越大，当满足 1-t \leq \frac{1}{K}或者 t \geq \frac{K-1}{K}此时拒绝域为 Rejected = \{x|max_j P(c_j|x) < \frac{1}{K}\}而当且仅当各分类概率相等时才有 $ max_j P(c_j|x) = \frac{1}{K} $，因此此时拒绝域为空，接受所有决策结果 最小风险贝叶斯决策在决策过程中，不同类型的决策错误所产生的代价是不同的。引入风险函数 \lambda_{i, j} = \lambda (\alpha_i|c_j)表示实际类别为$c_j$时，采取错误判断为$c_i$的行为$\alpha_i$所产生的损失。该函数称为损失函数，通常它可以用表格的形式给出，叫做决策表，形如定义条件风险 R(\alpha_i|c_j) = \sum_j \lambda (\alpha_i|c_j) P(c_j|x)特别地，取$0-1$损失时，即最小错误率贝叶斯决策 \lambda (\alpha_i|c_j) = \begin{cases} 0 & i = j \\ 1 & i \neq j \end{cases} 可能比较抽象，这里举了一个例子 关于判别函数可查看分类问题的决策平面 程序 为帮助理解，先手动计算一遍结果 先验概率(priori probability):$ P(Y = -1) = \frac{6}{15} $$ P(Y = 1) = \frac{9}{15} $似然函数(likelihood)$ P(X^{(1)} = 1|Y=-1) = \frac{3}{6}$$ P(X^{(1)} = 2|Y=-1) = \frac{2}{6}$$ P(X^{(1)} = 3|Y=-1) = \frac{1}{6}$$ P(X^{(2)} = S|Y=-1) = \frac{3}{6}$$ P(X^{(2)} = M|Y=-1) = \frac{2}{6}$$ P(X^{(2)} = L|Y=-1) = \frac{1}{6}$$ P(X^{(1)} = 1|Y=1) = \frac{2}{9}$$ P(X^{(1)} = 2|Y=1) = \frac{3}{9}$$ P(X^{(1)} = 3|Y=1) = \frac{4}{9}$$ P(X^{(2)} = S|Y=1) = \frac{1}{9}$$ P(X^{(2)} = M|Y=1) = \frac{4}{9}$$ P(X^{(2)} = L|Y=1) = \frac{4}{9}$ 注意：证据因子(evidence)不能用如下朴素贝叶斯求解 P(X) = P(X^{(1)}) P(X^{(2)})而是 P(X) = P(X^{(1)}|Y=-1)P(Y = -1) + P(X^{(2)}|Y=-1)P(Y = -1)一般分子用朴素贝叶斯求解 P(X|Y) = P(X^{(1)}|Y) P(X^{(2)}|Y)将其加和作为分母 c_k: P(X)_k = \sum_{k=0}^2 P(X^{(1)}|Y=k) P(X^{(2)}|Y=k)P(Y_k|X) = \frac{P(X|Y_k)P(Y_k)}{P(X)_k}选取最大概率的$ k $类别作为判别类别 k = argmax_k P(Y_k|X)代码@Github: Code for Naive Bayes Decision training step12345678910def fit(self, X, y): X_encoded = self.featureEncoder.fit_transform(X).toarray() y_encoded = OneHotEncoder().fit_transform(y.reshape((-1, 1))).toarray() self.P_X = np.mean(X_encoded, axis=0) # one-hot编码下，各列的均值即各特征的概率 self.P_Y = np.mean(y_encoded, axis=0) # one-hot编码下，各列的均值即各了别的概率 self.n_labels, self.n_features = y_encoded.shape[1], X_encoded.shape[1] self.P_X_Y = np.zeros(shape=(self.n_labels, self.n_features)) # 各个类别下，分别统计各特征的概率 for i in range(self.n_labels): X_encoded_of_yi = X_encoded[y_encoded[:, i]==1] # 取出属于i类别的样本 self.P_X_Y[i] = np.mean(X_encoded_of_yi, axis=0) # one-hot编码下，各列的均值即各特征的概率 predict step1234567891011def predict(self, X): X_encoded = self.featureEncoder.transform(X).toarray() n_samples = X_encoded.shape[0] y_pred_prob = np.zeros(shape=(n_samples, self.n_labels)) for i in range(n_samples): for j in range(self.n_labels): P_Xi_encoded_Yj = X_encoded[i] * self.P_X_Y[j] # 在Yj类别下，选出输入样本Xi对应的条件概率 P_Xi_encoded_Yj[P_Xi_encoded_Yj==0.0] = 1.0 # 将为0值替换为1，便于求解ΠP(Xi|yc)，只要将各元素累乘即可 y_pred_prob[i, j] = self.P_Y[j] * P_Xi_encoded_Yj.prod() y_pred_prob[i] /= np.sum(y_pred_prob[i]) # 分母一般是将分子加和，不能假定各特征独立并用朴素贝叶斯计算分母 return np.argmax(y_pred_prob, axis=1) main123456789101112X = [ [1, 0], [1, 1], [1, 1], [1, 0], [1, 0], [2, 0], [2, 1], [2, 1], [2, 2], [2, 2], [3, 2], [3, 1], [3, 2], [3, 2], [3, 2]]y = [0 ,0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]estimator = NaiveBayes()estimator.fit(X, y)X_test = np.array([[2, 0], [1, 1]])y_pred = estimator.predict(X_test)]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Softmax Regression]]></title>
    <url>%2F2018%2F10%2F18%2FSoftmax-Regression%2F</url>
    <content type="text"><![CDATA[Unsupervised Feature Learning and Deep Learning Tutorial 引言Logistic Regression中采用的非线性函数为Sigmoid，将输出值映射到$(0, 1)$之间作为概率输出，处理的是二分类问题，那么对于多分类的问题怎么处理呢？ 模型 由Logistic回归推广而来 SoftmaxSoftmax在机器学习和深度学习中有着非常广泛的应用。尤其在处理多分类$(K&gt;2)$问题，分类器最后的输出单元需要Softmax函数进行数值处理。 S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]其中$x$为矩阵形式的向量，其维度为$(K×1)$，$K$为类别数目。Softmax的输出向量维度与$x$相同，各元素$x_i$加和为$1$，可用于表示取各个类别的概率。 注意到，对于函数$e^x$ \lim_{x \rightarrow - \infty} e^x = 0\lim_{x \rightarrow + \infty} e^x = +\infty 假设所有的$x_i$等于某常数$c$，理论上对所有$x_i$上式结果为$\frac{1}{n}$ 若$c$为很小的负数，$e^c$下溢，结果为$NaN$； 若$c$量级很大，$e^c$上溢，结果为$NaN$。 在数值计算时并不稳定，但是Softmax所有输入增加同一常数时，输出不变，得稳定版本： S(x) := S(x - max(x_i)) e^{x_{max} - max(x_i)} = 1 减去最大值导致$e^x$最大为$1$，排除上溢； 分母中至少有一项为$1$，排除分母下溢导致处以$0$的情况。 其对数 log S(x)_i = x_i - log ({\sum_{k=1}^K exp(x_k)}) 注意到，第一项表示输入$x_i$总是对代价函数有直接的贡献。这一项不会饱和，所以即使$x_i$对上式的第二项的贡献很小，学习依然可以进行； 当最大化对数似然时，第一项鼓励$x_i$被推高，而第二项则鼓励所有的$x$被压低； 第二项$log ({\sum_{k=1}^K exp(x_k)})$可以大致近似为$max(x_k)$，这种近似是基于对任何明显小于$max(x_k)$的$x_k$都是不重要的，负对数似然代价函数总是强烈地惩罚最活跃的不正确预测 除了对数似然之外的许多目标函数对 softmax 函数不起作用。具体来说，那些不使用对数来抵消 softmax 中的指数的目标函数，当指数函数的变量取非常小的负值时会造成梯度消失，从而无法学习 作者：NirHeavenX来源：CSDN原文：https://blog.csdn.net/qsczse943062710/article/details/61912464版权声明：本文为博主原创文章，转载请附上博文链接！ Softmax解决多分类问题对于具有$K$个分类的问题，每个类别训练一组参数$ w_k $ z_k^{(i)} = w_k^Tx^{(i)}或写作矩阵形式 z^{(i)} = W^Tx^{(i)}其中 x^{(i)} = \left[ \begin{matrix} x_0^{(i)}\\ x_1^{(i)}\\ ...\\ x_n^{(i)} \end{matrix} \right]_{n×1}, x_0^{(i)}=1 W = [w_1, w_2, ..., w_K]_{(n+1)×K} w_i = \left[ \begin{matrix} w_{i0}\\ w_{i1}\\ ...\\ w_{in} \end{matrix} \right]_{n×1}最终各类别输出概率为 \hat{y}^{(i)} = Softmax(z^{(i)}) 产生了一个奇怪的脑洞。。。二分类问题 p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} } = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } }定义二分类线性单元输出的差值为 z = x_1 - x_2得到 p(x_1) = \frac{1}{1 + e^{-z}}以$x_1 = [x_{11}, x_{12}]^T$为例(二维特征)，取$w_1=1, w_2=2, b=3$ p(x_1) = \frac{1}{1 + e^{-(w_1 x_{11} + w_2 x_{12} + b)}} 而多分类问题，以$3$分类为例 p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} + e^{x_3}} = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } + e^{ - (x_1 - x_3)} }定义线性单元输出的差值为 z_{12} = x_1 - x_2 z_{13} = x_1 - x_3 p(x_1) = \frac{ 1 }{ 1 + e^{ - z_{12} } + e^{ - z_{13}} }做出图像为 损失函数由交叉熵理解CrossEnt = \sum_j p_j log \frac{1}{q_j}而对于样本$ (X^{(i)}, y^{(i)}) $，为确定事件，故标签概率各元素的取值$p_j$为$ y^{(i)}_j ∈ \{0,1\}$，$ q_j即预测输出的概率值\hat{y}^{(i)}_j$ 一般取各个样本损失的均值$(\frac{1}{N})$ L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N 1\{y^{(i)}_j=k\} log (\hat{y}^{(i)}_j) 1\{y^{(i)}_j=k\} = \begin{cases} 1 & y^{(i)}_j = k \\ 0 & y^{(i)}_j \neq k \end{cases}可对实际标签$y^{(i)}$采取One-Hot编码，便于计算 y^{(i)} = \left[ \begin{matrix} 0, ..., 1_{y^{(i)}}, ..., 0 \end{matrix} \right]^T则 L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N y^{(i)T} log (\hat{y}^{(i)})由决策平面理解从贝叶斯决策和分类问题的决策平面可知，对于类别$c_i$，有 P(c_i|x) = \frac{P(x|c_i)}{\sum_{j=0}^KP(x|c_j)} 假设每个类别的样本服从正态分布，先验概率相等，各类别样本特征间协方差相等。证明略. 梯度推导Softmax函数的导数对于 S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]一般输出作为概率值，记 P = S(x)p_i = S(x)_i对向量$x$中某元素求导 \frac{∂S(x)}{∂x_i} = \frac{∂}{∂x_i} \left[ \begin{matrix} ...\\ \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}\\ ...\\ \end{matrix} \right] $(1)$ $i=k$$\frac{∂}{∂x_i} \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{exp’(x_i)·\sum_{j=1}^K exp(x_j) - exp(x_i)·(\sum_{j=1}^K exp(x_j))’}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)·\sum_{j=1}^K exp(x_j) - exp^2(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)} -(\frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)})^2$$ = p_i (1 - p_i)$ $(2)$ $i\neq k$$\frac{∂}{∂x_i} \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{exp’(x_k)·\sum_{j=1}^K exp(x_j) - exp(x_k)·(\sum_{j=1}^K exp(x_j))’}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{- exp(x_k)exp(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$= - p_i p_k$ 综上 \frac{∂S(x)}{∂x_i}_{K×1} = \left[ \begin{matrix} 0\\ ...\\ p_i\\ ...\\ 0 \end{matrix} \right] - \left[ \begin{matrix} p_i p_1\\ ...\\ p_i^2\\ ...\\ p_i p_K \end{matrix} \right] = \left( \left[ \begin{matrix} 0\\ ...\\ 1\\ ...\\ 0 \end{matrix} \right] - p \right)p_i 损失函数梯度在OneHot编码下，损失函数形式为 L(\hat{y},y) = \frac{1}{N} \sum_{i=1}^N L (y^{(i)}, \hat{y}^{(i)}) L (y^{(i)}, \hat{y}^{(i)}) = - y^{(i)T} log \hat{y}^{(i)} \hat{y}^{(i)} = S(z^{(i)}) z^{(i)} = W^T x^{(i)}即只考虑实际分类对应的概率值 L (y^{(i)}, \hat{y}^{(i)}) = - log \hat{y}^{(i)}_{y^{(i)}} 由于 $S(z^{(i)})_{t^{(i)}}$与$z^{(i)}$向量各个元素都有关，由链式求导法则 \frac{∂ L^{(i)} }{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } ( \sum_{k=1}^K \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k} \frac{∂z^{(i)}_k}{∂w_{pq}} )$1.$ 考察 $\frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k}$ \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k} = ​ \begin{cases} ​ \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_k) & k=y^{(i)} \\ ​ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_k & k \neq y^{(i)} ​ \end{cases}$2.$ 考察 $\frac{∂z^{(i)}_k}{∂w_{pq}}$ \frac{∂z^{(i)}_k}{∂w_{pq}} = \begin{cases} \frac{∂z^{(i)}_k}{∂w_{pq}} = x^{(i)}_p & k=q\\ \frac{∂z^{(i)}_k}{∂w_{pq}} = 0 & k \neq q \end{cases} 综上所述 \frac{∂ L^{(i)} }{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} \frac{∂z^{(i)}_q}{∂w_{pq}}其中 \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} = \begin{cases} \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_q) & q = y^{(i)}\\ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_q & q \neq y^{(i)} \end{cases} \frac{∂z^{(i)}_q}{∂w_{pq}} = x^{(i)}_p故对于单个样本$(X^{(i)}, y^{(i)})$，当样本标签采用$OneHot$编码时 \frac{∂L^{(i)}}{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} x^{(i)}_p = \begin{cases} (\hat{y}^{(i)}_q - 1)x^{(i)}_p & q = y^{(i)}\\ \hat{y}^{(i)}_qx^{(i)}_p & q \neq y^{(i)} \end{cases} 注： 这里可以约分去掉$\hat{y}^{(i)}_{y^{(i)}}$ \frac{∂L^{(i)}}{∂w_{pq}} = ( \hat{y}^{(i)}_q - y^{(i)}_q) x^{(i)}_p更一般的，写成矩阵形式，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) ∇_W L = X^T(\hat{Y} - Y) 用线性模型解决分类和回归问题时，形式竟如此统一! 至此为止，梯度推导结束，利用梯度下降法迭代求解参数矩阵$W$即可。 W := W - \alpha ∇_W L代码@GitHub: Code of Softmax Regression Softmax12345678def softmax(X): """ 数值计算稳定版本的softmax函数 @param &#123;ndarray&#125; X: shape(batch_size, n_labels) """ X_max = np.max(X, axis=1).reshape((-1, 1)) # 每行的最大值 X = X - X_max # 每行减去最大值 X = np.exp(X) return X / np.sum(X, axis=1).reshape((-1, 1)) cost function1234567891011def crossEnt(self, y_label_true, y_prob_pred): """ 计算交叉熵损失函数 @param &#123;ndarray&#125; y_label_true: 真实标签 shape(batch_size,) @param &#123;ndarray&#125; y_prob_pred: 预测输出 shape(batch_size, n_labels) """ mask = self.encoder.transform(y_label_true.reshape(-1, 1)).toarray() # shape(batch_size, n_labels) y_prob_masked = np.sum(mask * y_prob_pred, axis=1) # 每行真实标签对应的预测输出值 y_prob_masked[y_prob_masked==0.] = 1. y_loss = np.log(y_prob_masked) loss = - np.mean(y_loss) # 求各样本损失的均值 return loss gradient12345678910def grad(self, X_train, y_train, y_prob_pred): """ 计算梯度 \frac &#123;∂L&#125; &#123;∂W_&#123;pq&#125;&#125; @param X_train: 训练集特征 @param y_train: 训练集标签 @param y_prob_pred: 训练集预测概率输出 @param y_label_pred: 训练集预测标签输出 """ y_train = self.encoder.transform(y_train) dW = X_train.T.dot(y_prob_pred - y_train) return dW training step省略可视化和验证部分的代码123456789101112131415161718192021222324252627282930313233343536def fit(self, X_train, X_valid, y_train, y_valid, min_acc=0.95, max_epoch=20, batch_size=20): """ 训练 """ # 添加首1列，输入到偏置w0 X_train = np.c_[np.ones(shape=(X_train.shape[0],)), X_train] X_valid = np.c_[np.ones(shape=(X_valid.shape[0],)), X_valid] X_train = self.scaler.fit_transform(X_train) # 尺度归一化 X_valid = self.scaler.transform(X_valid) # 尺度归一化 self.encoder.fit(y_train.reshape(-1, 1)) self.n_features = X_train.shape[1] self.n_labels = self.encoder.transform(y_train).shape[1] # 初始化参数 self.W = np.random.normal(loc=0, scale=1.0, size=(self.n_features, self.n_labels)) n_batch = X_train.shape[0] // batch_size # 可视化相关 plt.ion() plt.figure('loss'); plt.figure('accuracy') loss_train_epoch = []; loss_valid_epoch = [] acc_train_epoch = []; acc_valid_epoch = [] for i_epoch in range(max_epoch): for i_batch in range(n_batch): # 批处理梯度下降 n1, n2 = i_batch * batch_size, (i_batch + 1) * batch_size X_train_batch, y_train_batch = X_train[n1: n2], y_train[n1: n2] # 预测 y_prob_train = self.predict(X_train_batch, preprocessed=True) # 计算损失 loss_train_batch = self.crossEnt(y_train_batch, y_prob_train) # 计算准确率 y_label_train = np.argmax(y_prob_train, axis=1) a = y_train_batch.reshape((-1,)) acc_train_batch = np.mean((y_label_train == y_train_batch.reshape((-1,))).astype('float')) # 计算梯度 dW dW = self.grad(X_train_batch, y_train_batch, y_prob_train) # 更新参数 self.W -= self.lr * dW predict step123456789101112def predict(self, X, preprocessed=False): """ 对输入的样本进行预测，输出标签 @param &#123;ndarray&#125; X: shape(batch_size, n_features) @return &#123;ndarray&#125; y_prob: probability, shape(batch_size, n_labels) &#123;ndarray&#125; y_label: labels, shape(batch_size,) """ if not preprocessed: # 训练过程中调用此函数时，不用加首1列 X = np.c_[np.ones(shape=(X.shape[0],)), X] # 添加首1项，输入到偏置w0 X = self.scaler.transform(X) y_prob = softmax(X.dot(self.W)) # 预测概率值 shape(batch_size, n_labels) return y_prob 实验结果以下蓝线为训练集参数，红线为验证集参数，若稳定训练(如batch_size = 20的结果)，最终准确率在$80\%$左右。 由于随机梯度下降(SGD)遍历次数太多，运行较慢，没有用SGD方法训练，就前几个epoch来看，效果没有batch_size = 20的好； 添加隐含层形成三层结构的前馈神经网络，可提高准确率； 还有一点，使用批处理梯度下降(n_batch = 1)训练时，可以看到损失值已经趋于$0$，但准确率却很低，说明已经陷入局部最优解。 batch size = 20 损失 准确率 batch_size = 200 损失 准确率 n_batch = 1 损失 准确率 感悟推公式要我老命。。。。 Softmax回归可以视作不含隐含层的前馈神经网络。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLogistic-Regression%2F</url>
    <content type="text"><![CDATA[引言逻辑回归（Logistic Regression）是用于处理因变量为分类变量的回归问题，常见的是二分类或二项分布问题，也可以处理多分类问题，它实际上是属于一种分类方法。 模型先给出模型，推导过程稍后给出，逻辑回归包含Sigmoid函数 f(z) = \frac{1}{1+e^{-z}}其图像如下 定义 z = w^Tx其中$x=[x_0, x_1, …, x_n]^T, x_0=1$ h_w(x) = g(z) = \frac{1}{1+e^{-z}}损失函数由最大似然估计推导对于二元分类问题，其取值作为随机变量，服从二项分布 $B(1, p)$，其中$p$即为预测输出概率$\hat{y}$ P(y_i^{(i)}) = (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}由极大似然估计 L = \prod_{i=0}^N P(y_i^{(i)}) = \prod_{i=0}^N (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}取对数似然函数 logL = \sum_{i=0}^N [y_i^{(i)} log \hat{y}_i^{(i)} + (1-y_i^{(i)}) log (1-\hat{y}_i^{(i)})]优化目标是 w = argmax_w logL优化问题一般表述成minimize问题，添加负号，构成Neg Log Likelihood损失 w = argmin_w (-logL)一般取均值 L(\hat{y}, y)=- \frac{1}{N} \sum_i [y_i^{(i)} log(\hat{y}_i^{(i)})+(1 - y_i^{(i)})log(1-\hat{y}_i^{(i)})]其中$y_i$表示真实值，$\hat{y}_i$表示预测值 从交叉熵理解已知交叉熵cross entropy定义如下 CrossEnt = \sum_i p_i log \frac{1}{q_i}而对于样本$ (X_i, y_i) $，为确定事件，故标签概率的取值为$ p_i = y_i ∈ \{0,1\}$，$ q_i即预测输出的概率值\hat{y}_i $，可得到与上面相同的推导结论 从决策平面和贝叶斯决策理解相关内容查看分类问题的决策平面和贝叶斯决策，逻辑回归考虑的一般是等先验概率问题，故决策函数定义为 $if$ $P(c_i|x)&gt;P(c_j|x)$ $then$ $ x \in c_i $, $ i, j = 1, 2 $ 从贝叶斯决策可知，对于类别$c_1$，有 P(c_1|x) = \frac{P(x|c_1)}{P(x|c_1) + P(x|c_2)}设在各个类别下，特征$x$服从正态分布 P(x|c_i) = \frac{1}{ (2\pi)^{\frac{n}{2}} |\Sigma_i|^{\frac{1}{2}}} exp(-\frac{1}{2} (x-\mu_i)^T \Sigma^{-1} (x-\mu_i))则 P(c_1|x) = \frac {1} { 1 + exp(-z) } P(c_2|x) = 1 - P(c_1|x) = \frac{exp(-z)}{1+exp(-z)} $P(c_1|x) = \frac{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1) + exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}$ $P(c_1|x) = \frac{1}{1 + \frac{exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}}$ 假定各分类的样本方差相等，$ \Sigma_1 = \Sigma_2 = \sigma^2 I $ $ P(c_1|x) = \frac {1}{1 + exp(- [ \frac{1}{\sigma^2} (\mu_1-\mu_2)^T x - \frac{1}{2 \sigma^2} (\mu_1^T\mu_1 - \mu_2^T\mu_2) ])}$ 令 w = \frac{1}{\sigma^2} (\mu_1 -\mu_2)b = - \frac{1}{2\sigma^2}(\mu_1^T \mu_1 - \mu_2^T \mu_2)即可得到 P(c_1|x) = \frac {1} { 1 + exp(-z) }其中 z = w^T x + b 梯度推导先推导Sigmoid函数的导数 f'(z) = (1 - f(z))f(z)值得注意的是，从$f’(z)$的图像可以看到，在$ x=0 $处$f’(z)$取极大值，且 f'(z)_{max} = f'(z)|_{z=0} = 0.25 \lim_{z \rightarrow \infty} f'(z) = 0在多层神经网络反向传播更新参数时，由于梯度多次累乘，Sigmoid作为激活函数会存在“梯度消失”的问题，使得参数更新非常缓慢。 $ f’(z) $$ = (\frac{1}{1+e^{-z}})’ $$ = \frac​ {-(1+e^{-z})’}​ {(1+e^{-z})^2} $$ = \frac​ {e^{-z}}​ {(1+e^{-z})^2} $$ = \frac​ {e^{-z}}​ {1+e^{-z}}​ \frac​ {1}​ {1+e^{-z}}$$ = (1 - f(z))f(z)$ 利用链式求导法则可得 $\frac{∂L}{∂w_j}$$= -\frac{∂}{∂w_j} \frac{1}{N} \sum_i [y^{(i)} log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\frac{∂}{∂w_j}\hat{y}^{(i)}-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\frac{∂}{∂w_j}\hat{y}^{(i)}]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j]$$= - \frac{1}{N} \sum_i [y^{(i)} (1-\hat{y}^{(i)})w_j-(1-y^{(i)}) y^{(i)} w_j]$$= \frac{1}{N} \sum_i (\hat{y}^{(i)} - y^{(i)})w_j $ 写作矩阵形式，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) ∇_w L = X^T (\hat{Y} - Y)训练和线性回归一样，采用梯度下降法求解 w := w - \alpha ∇_w L处理多分类问题假设有$K$个类别，则依次以类别$c_i$为正样本训练模型，一共训练$K$个。测试样本在每个模型上计算，最终将概率最大的作为分类结果。 这样划分数据集，会使训练集正负样本数目严重不对称，特别是类别很多的情况，对结果会产生影响。可推广至softmax回归解决这个问题。 程序代码@Github: Code for Logistic Regression cost function123456789101112131415def lossFunctionDerivative(self, X, theta, y_true): ''' 计算损失函数对参数theta的梯度 对theta[j]的梯度为：(y_pred - y_true)*x[j] ''' err = self.predict_prob(X, theta) - y_true return X.T.dot(err)/y_true.shape[0]def lossFunction(self, y_pred_prob, y_true): ''' 未使用 计算损失值: Cross-Entropy y_pred_prob, y_true: NumPy array, shape=(n,) ''' tmp = y_true*np.log(y_pred_prob) + (1 - y_true)*np.log(1 - y_pred_prob) return np.mean(-tmp) training step123456789101112131415161718192021def gradDescent(self, min_acc, learning_rate=0.01, max_iter=10000): acc = 0; n_iter = 0 for n_iter in range(max_iter): for n in range(self.n_batch): X_batch = self.X[n*self.batch_size:(n+1)*self.batch_size] t_batch = self.t[n*self.batch_size:(n+1)*self.batch_size] grad = self.lossFunctionDerivative(X_batch, self.theta, t_batch) self.theta -= learning_rate * grad # 梯度下降 acc = self.accuracyRate(self.predict_prob(self.X, self.theta), self.t) if acc &gt; min_acc: print('第%d次迭代, 第%d批数据' % (n_iter, n)) print("当前总体样本准确率为: ", acc) print("当前参数值为: ", self.theta) return self.theta if n_iter%100 == 0: print('第%d次迭代' % n_iter) print('准确率： ', acc) print("超过迭代次数") print("当前总体样本准确率为: ", acc) print("当前参数值为: ", self.theta) return self.theta 实验结果]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linear Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLinear-Regression%2F</url>
    <content type="text"><![CDATA[引言线性回归可以说是机器学习最基础的算法 模型\hat{y}^{(i)} = w^Tx^{(i)}其中 x^{(i)}=[x_0^{(i)}, x_1^{(i)}, ..., x_n^{(i)}]^T, x_0^{(i)}=1这里$x_0^{(i)}=1$表示偏置$b$，即$b=w_0$ \hat{y}^{(i)} = w^Tx^{(i)} + b 注：对于非线性的数据，可构造高次特征。 损失函数定义误差e^{(i)} = \hat{y}^{(i)} - y^{(i)}其中$y^{(i)}$表示真实值 定义损失函数单个样本的误差定义为 L_{single}(\hat{y}^{(i)}, y^{(i)})=\frac{1}{2}||e^{(i)}||_2^2=\frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2所有样本的误差定义为 L(y, t)=\frac{1}{2N}\sum_i (\hat{y}^{(i)}-y^{(i)})^2也可以定义为误差的和而不是均值，对结果无影响，可视作学习率$α$除去一个常数 梯度推导 $\frac{∂L}{∂w_j}$$= \frac{∂}{∂w_j}\frac{1}{2N}\sum_i(\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{2N} \sum_i \frac{∂}{∂w_j} (\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) \frac{∂t^{(i)}}{∂w_j}$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)}$ 或者使用矩阵推导，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) L = \frac{1}{2}(Xw-Y)^T(Xw-Y) ∇_w L = X^T(\hat{Y}-Y) $∇_w L$$= \frac{1}{2} ∇_w (w^TX^TXw - Y^TXw - w^TX^TY + Y^TY)$$= \frac{1}{2} (2X^TXw - X^TY - X^TY)$$= X^T(Xw-Y) $ 在梯度为$\vec{0}$的点，即$∇_w L = \vec{0}$时对应最优解 X^T(Xw-Y) = 0 令X^T(Xw-Y) = 0 有X^TXw = X^TY w^*=(X^TX+\lambda I)^{-1}X^TY 其中$X^+=(X^TX+\lambda I)^{-1}X^T$，表示矩阵$X_{m×n}$的伪逆 训练采用梯度下降法求解 w := w - \alpha ∇_w L其中$w$表示参数向量 进一步思考：为什么使用梯度下降可以求取最优解呢？ ∇_w^2 L = ∇_w X^T(Xw-Y) = X^TX而对于矩阵 $ X^TX $ u^T(X^TX)u = (Xu)^T(Xu) \geq 0即损失函数的Hessian矩阵$∇_w^2 L$为正定矩阵，$L$为凸函数，存在全局最优解 从投影的角度理解线性回归 线性回归的正则化为克服过拟合问题，可加入正则化项$||w||_2^2$，此时损失函数定义为 L(\hat{y}, y)=\frac{1}{2N} ||\hat{y}^{(i)}-y^{(i)}||_2^2 + \lambda ||w||_2^2或者 L(\hat{y}, y)=\frac{1}{2N} \sum_i (\hat{y}^{(i)}-y^{(i)})^2 + \frac{\lambda}{2N}\sum_j w_j^2其中$i = 1, …, N_{sample}; j = 1, …, N_{feature},j&gt;0 $ 此时梯度为 \frac{∂L}{∂w_j} = \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)} + \frac{\lambda}{N}w_j其中$j = 1, …, N_{feature},j&gt;0 $ 局部加权线性回归目标函数定义为 L(y, t)=\frac{1}{2N}\sum_i w^{(i)} (\hat{y}^{(i)}-y^{(i)})^2其中 w^{(i)} = e^{-\frac{(x^{(i)}-x)^2}{2\tau^2}}$x$表示输入的预测样本，$x^{(i)}$表示训练样本 离很近的样本，权值接近于1，而对于离很远的样本，此时权值接近于0，这样就是在局部构成线性回归，它依赖的也只是周边的点。 对于线性回归算法，一旦拟合出适合训练数据的参数$w$，保存这些参数$w$，对于之后的预测，不需要再使用原始训练数据集，所以是参数学习算法。而对于局部加权线性回归算法，每次进行预测都需要全部的训练数据（每次进行的预测得到不同的参数$w$），没有固定的参数$w$，所以是非参数算法。 代码@Github: Code for Linear Regression training step12345678910111213141516171819202122232425262728293031323334353637383940414243def fit(self, X, y, learning_rate=0.01, max_iter=5000, min_loss=10): # --------------- 数据预处理部分 --------------- # 加入全1列 X = np.c_[np.ones(shape=(X.shape[0])), X] # 构造高次特征 if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] # ---------------- 参数迭代部分 ---------------- # 初始化参数 self.theta = np.random.uniform(-1, 1, size=(X.shape[1],)) # 数据批次 n_batch = X.shape[0] if self.n_batch==-1 else self.n_batch batch_size = X.shape[0] // n_batch # 停止条件 n_iter = 0; loss = float('inf') # 开始迭代 for n_iter in range(max_iter): for n in range(n_batch): n1, n2 = n*batch_size, (n+1)*batch_size X_batch = X[n1: n2]; y_batch = y[n1: n2] grad = self.lossFunctionDerivative(X_batch, y_batch) self.theta -= learning_rate * grad loss = self.score(y_batch, self.predict(X_batch)) if loss &lt; min_loss: print('第%d次迭代, 第%d批数据' % (n_iter, n)) print("当前总体样本损失为: ", loss) return self.theta if n_iter%100 == 0: print('第%d次迭代' % n_iter) print("当前总体样本损失为: ", loss) print("超过迭代次数") print("当前总体样本损失为: ", loss) return self.thetadef lossFunctionDerivative(self, X, y): y_pred = self.predict(X) # theta = self.theta; # ！注意：theta = self.theta 不仅仅是赋值，类似引用，修改theta会影响self.theta theta = self.theta.copy() theta[0] = 0 # θ0不需要正则化 return (X.T.dot(y_pred - y) + self.regularize * theta) / X.shape[0] predict step123456789def predict(self, X, preprocessed=False): if preprocessed: # 加入全1列 X = np.c_[np.ones(shape=(X.shape[0])), X] # 构造高次特征 if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] return X.dot(self.theta) 运行结果 无正则化 正则化]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
</search>
