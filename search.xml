<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Ubuntuç¼–è¯‘å®‰è£…Tensorflow]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Tensorflow%2F</url>
    <content type="text"><![CDATA[éžå¸¸é‡è¦å¦‚æžœä¸­é€”å‡ºçŽ°é”™è¯¯ï¼Œxxxxæ–‡ä»¶æ‰¾ä¸åˆ°ï¼Œä¸è¦æ€€ç–‘ï¼å°±æ˜¯å¤§å¤©æœçš„ç½‘ç»œé—®é¢˜ï¼æŽ¨èç§‘å­¦ä¸Šç½‘ï¼ å®‰è£…CUDAä¸ŽCUDNNé¦–å…ˆæŸ¥çœ‹æ˜¾å¡æ˜¯å¦æ”¯æŒCUDAåŠ é€Ÿï¼Œè¾“å…¥1$ nvidia-smi åœ¨Ubuntu16.04 LTSä¸‹ï¼ŒæŽ¨èå®‰è£…CUDA9.0å’ŒCUDNN 7ã€‚ CUDA CUDA Toolkit 9.0 Downloads | NVIDIA Developer https://developer.nvidia.com/cuda-90-download-archive ä¸‹è½½.runç‰ˆæœ¬ï¼Œå®‰è£…æ–¹æ³•å¦‚ä¸‹ 12$ sudo chmod +x cuda_9.0.176_384.81_linux.run $ sudo sh ./cuda_9.0.176_384.81_linux.run æœåŠ¡æ¡æ¬¾å¾ˆé•¿ã€‚ã€‚ã€‚ã€‚ CUDNN NVIDIA cuDNN | NVIDIA Developer https://developer.nvidia.com/cudnn 1234$ tar -xzvf cudnn-9.0-linux-x64-v7.4.1.5.tgz$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* å®‰è£…åŽè¿›è¡ŒéªŒè¯ 1234$ cp -r /usr/src/cudnn_samples_v7/ $HOME$ cd $HOME/cudnn_samples_v7/mnistCUDNN$ make clean &amp;&amp; make$ ./mnistCUDNN ç¼–è¯‘Tensorflow(CPU version)ç”±äºŽè®­ç»ƒä»£ç ä½¿ç”¨Pythonå®žçŽ°ï¼Œæ•…C++ç‰ˆæœ¬çš„Tensorflowä¸ä½¿ç”¨GPUï¼Œä»…å®žçŽ°é¢„æµ‹ä»£ç å³å¯ã€‚ bazel Installing Bazel on Ubuntu - Bazel https://docs.bazel.build/versions/master/install-ubuntu.htmlä¸€å®šè¦ç”¨æºç å®‰è£…ï¼ï¼ï¼ download the Bazel binary installer named bazel-&lt;version&gt;-installer-linux-x86_64.sh from the Bazel releases page on GitHub. 123456$ sudo apt-get install pkg-config zip g++ zlib1g-dev unzip python$ chmod +x bazel-&lt;version&gt;-installer-linux-x86_64.sh$ ./bazel-&lt;version&gt;-installer-linux-x86_64.sh --user$ sudo nano ~/.bashrc # export PATH=&quot;$PATH:$HOME/bin&quot;$ source ~/.bashrc $ bazel version ç¼–è¯‘CPUç‰ˆæœ¬çš„CPUæŸ¥çœ‹javaç‰ˆæœ¬1234$ java -versionopenjdk version &quot;1.8.0_191&quot;OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12)OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) å®‰è£…ä¾èµ–è½¯ä»¶åŒ…çŽ¯å¢ƒ1234$ sudo apt install python3-dev$ pip3 install six$ pip3 install numpy$ pip3 instal wheel ä¸‹è½½Tensorflowæºç 1$ git clone https://github.com/tensorflow/tensorflow ç¼–è¯‘ä¸Žå®‰è£…12$ cd tensorflow$ ./configure é…ç½®é€‰é¡¹å¦‚ä¸‹1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command &quot;bazel shutdown&quot;.INFO: Invocation ID: ce26fc12-2926-4ca7-8775-febc553c8ab5You have bazel 0.20.0 installed.Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3Found possible Python library paths: /usr/local/lib/python3.5/dist-packages /usr/lib/python3/dist-packagesPlease input the desired Python library path to use. Default is [/usr/local/lib/python3.5/dist-packages]Do you wish to build TensorFlow with XLA JIT support? [Y/n]: nNo XLA JIT support will be enabled for TensorFlow.Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: nNo OpenCL SYCL support will be enabled for TensorFlow.Do you wish to build TensorFlow with ROCm support? [y/N]: nNo ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y/N]: nNo CUDA support will be enabled for TensorFlow.Do you wish to download a fresh release of clang? (Experimental) [y/N]: nClang will not be downloaded.Do you wish to build TensorFlow with MPI support? [y/N]: nNo MPI support will be enabled for TensorFlow.Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native -Wno-sign-compare]: Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: nNot configuring the WORKSPACE for Android builds.Preconfigured Bazel build configs. You can use any of the below by adding &quot;--config=&lt;&gt;&quot; to your build command. See .bazelrc for more details. --config=mkl # Build with MKL support. --config=monolithic # Config for mostly static monolithic build. --config=gdr # Build with GDR support. --config=verbs # Build with libverbs support. --config=ngraph # Build with Intel nGraph support. --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects.Preconfigured Bazel build configs to DISABLE default on features: --config=noaws # Disable AWS S3 filesystem support. --config=nogcp # Disable GCP support. --config=nohdfs # Disable HDFS support. --config=noignite # Disable Apacha Ignite support. --config=nokafka # Disable Apache Kafka support. --config=nonccl # Disable NVIDIA NCCL support.Configuration finished ä½¿ç”¨bazelç¼–è¯‘1$ bazel build --config=opt //tensorflow:libtensorflow_cc.so å‡ºçŽ°é”™è¯¯ TF failing to build on Bazel CI Â· Issue #19464 Â· tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/19464Failure to build TF 1.12 from source - multiple definitions in grpc Â· Issue #23402 Â· tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/23402#issuecomment-436932197Explicitly import tools/bazel.rc by meteorcloudy Â· Pull Request #23583 Â· tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583Explicitly import tools/bazel.rc by meteorcloudy Â· Pull Request #23583 Â· tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583/commits/03e63a291bc95dacaa821585f39a360b43465cb5 è§£å†³æ–¹æ³• æ–¹æ³•1 æ–¹æ³•2 å°†tools/bazel.rcä¸­å†…å®¹ç²˜åˆ°.tf_configure.bazelrcä¸­ï¼Œæ¯æ¬¡é‡æ–°é…ç½®åŽéœ€è¦é‡æ–°ç²˜è´´ä¸€æ¬¡ã€‚ æºç å®‰è£…protobuf3.6.0 https://github.com/protocolbuffers/protobuf 1234./autogen.sh./configuremakemake install ä¸‹è½½å…¶ä»–æ–‡ä»¶ 12$ ./tensorflow/contrib/makefile/download_dependencies.shmkdir /tmp/eigen å€¼å¾—æ³¨æ„ï¼Œdownload_dependencies.shä¸­ä¸‹è½½ä¾èµ–åŒ…æ—¶ï¼Œéœ€è¦ç”¨åˆ°curlï¼Œä½†æ˜¯é»˜è®¤æ–¹å¼å®‰è£… 1$ sudo apt install curl &gt; çŽ°åœ¨æ˜¯2018/12/19/02:48ï¼Œè¢«è¿™ä¸ªé—®é¢˜æŠ˜è…¾äº†3ä¸ªå°æ—¶ã€‚ æ—¶ä¸æ”¯æŒ`https`åè®®ï¼Œæ•…éœ€è¦å®‰è£…`OpenSSL`ï¼Œå¹¶æºç å®‰è£…ï¼Œè¯¦ç»†èµ„æ–™è§[curlæç¤ºä¸æ”¯æŒhttpsåè®®è§£å†³æ–¹æ³• - æ ‡é…çš„å°å· - åšå®¢å›­](https://www.cnblogs.com/biaopei/p/8669810.html) - æ‰§è¡Œ`./autogen.sh`æ—¶ï¼Œå‘ç”Ÿé”™è¯¯`autoreconf: not found`ï¼Œåˆ™å®‰è£… 12$ sudo apt install autoconf aotomake libtool$ sudo apt install libffi-dev æºç å®‰è£…Eigen 12345cd tensorflow/contrib/makefile/Downloads/eigenmkdir buildcd buildcmakemake install è°ƒç”¨C++ç‰ˆæœ¬çš„Tensorflowåˆ›å»ºæ–‡ä»¶ç›®å½•å¦‚ä¸‹1234|-- tf_test |-- build |-- main.cpp |-- CMakeLists.txt main.cppæ–‡ä»¶å†…å®¹å¦‚ä¸‹1234567891011121314151617181920212223#include &quot;tensorflow/cc/client/client_session.h&quot;#include &quot;tensorflow/cc/ops/standard_ops.h&quot;#include &quot;tensorflow/core/framework/tensor.h&quot;int main() &#123; using namespace tensorflow; using namespace tensorflow::ops; Scope root = Scope::NewRootScope(); // Matrix A = [3 2; -1 0] auto A = Const(root, &#123; &#123;3.f, 2.f&#125;, &#123;-1.f, 0.f&#125;&#125;); // Vector b = [3 5] auto b = Const(root, &#123; &#123;3.f, 5.f&#125;&#125;); // v = Ab^T auto v = MatMul(root.WithOpName(&quot;v&quot;), A, b, MatMul::TransposeB(true)); std::vector&lt;Tensor&gt; outputs; ClientSession session(root); // Run and fetch v TF_CHECK_OK(session.Run(&#123;v&#125;, &amp;outputs)); // Expect outputs[0] == [19; -3] LOG(INFO) &lt;&lt; outputs[0].matrix&lt;float&gt;(); return 0;&#125; CMakeLists.txtå†…å®¹å¦‚ä¸‹12345678910111213141516171819202122232425262728293031cmake_minimum_required (VERSION 2.8.8)project (tf_example)set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -g -std=c++11 -W&quot;)set(EIGEN_DIR /usr/local/include/eigen3)set(PROTOBUF_DIR /usr/local/include/google/protobuf)set(TENSORFLOW_DIR /home/louishsu/install/tensorflow-1.12.0)include_directories( $&#123;EIGEN_DIR&#125; $&#123;PROTOBUF_DIR&#125; $&#123;TENSORFLOW_DIR&#125; $&#123;TENSORFLOW_DIR&#125;/bazel-genfiles $&#123;TENSORFLOW_DIR&#125;/tensorflow/contrib/makefile/downloads/absl)link_directories( /usr/local/lib)add_executable( tf_test main.cpp)target_link_libraries( tf_test tensorflow_cc tensorflow_framework) 123$ mkdir build &amp;&amp; cd build$ cmake .. &amp;&amp; make$ ./tf_test install tensorflow-gpu for pythonå¯ä½¿ç”¨pipæŒ‡ä»¤å®‰è£…ï¼ŒæŽ¨èä¸‹è½½å®‰è£…åŒ…ï¼Œ tensorflow Â· PyPI https://pypi.org/project/tensorflow/ 12$ cd ~/Downloads$ pip3 --default-timeout=1000 install tensorflow_gpu-1.12.0-cp35-cp35m-manylinux1_x86_64.whl --user å®‰è£…åŽè¿›è¡ŒéªŒè¯123456789101112131415161718192021222324252627$ python3Python 3.5.2 (default, Nov 12 2018, 13:43:14) [GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.Session()2018-12-12 11:58:17.817417: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2018-12-12 11:58:17.953931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2018-12-12 11:58:17.954686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: GeForce GT 730M major: 3 minor: 5 memoryClockRate(GHz): 0.758pciBusID: 0000:04:00.0totalMemory: 983.44MiB freeMemory: 177.19MiB2018-12-12 11:58:17.954728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 02018-12-12 11:58:18.276013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:2018-12-12 11:58:18.276057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2018-12-12 11:58:18.276069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2018-12-12 11:58:18.276223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory) -&gt; physical GPU (device: 0, name: GeForce GT 730M, pci bus id: 0000:04:00.0, compute capability: 3.5)&gt;&gt;&gt; a = tf.Variable([233])&gt;&gt;&gt; init = tf.initialize_all_variables()WARNING:tensorflow:From /home/louishsu/.local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.Instructions for updating:Use `tf.global_variables_initializer` instead.&gt;&gt;&gt; sess.run(init)&gt;&gt;&gt; sess.run(a)array([233], dtype=int32)&gt;&gt;&gt; sess.close() æ³¨æ„ï¼Œå¦‚æžœå¼‚å¸¸ä¸­æ–­ç¨‹åºï¼Œæ˜¾å­˜ä¸ä¼šè¢«é‡Šæ”¾ï¼Œéœ€è¦è‡ªè¡Œkill1$ nvidia-smi èŽ·å¾—PIDåºå·ï¼Œä½¿ç”¨æŒ‡ä»¤ç»“æŸè¿›ç¨‹1$ kill -9 pid Reference TensorFlow C++åŠ¨æ€åº“ç¼–è¯‘ - ç®€ä¹¦ https://www.jianshu.com/p/d46596558640Tensorflow C++ ä»Žè®­ç»ƒåˆ°éƒ¨ç½²(1)ï¼šçŽ¯å¢ƒæ­å»º | æŠ€æœ¯åˆ˜ http://www.liuxiao.org/2018/08/ubuntu-tensorflow-c-%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E9%A2%84%E6%B5%8B1%EF%BC%9A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/]]></content>
      <categories>
        <category>Linux</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntuç¼–è¯‘å®‰è£…OpenCV]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85OpenCV%2F</url>
    <content type="text"><![CDATA[ä¸‹è½½æºç  OpenCV library https://opencv.org/ ç¼–è¯‘å®‰è£…ä¾èµ–è½¯ä»¶åŒ…12$ sudo apt install cmake$ sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff4.dev libswscale-dev libjasper-dev ç¼–è¯‘12345$ unzip opencv-3.4.4.zip$ cd opencv-3.4.4$ mkdir build &amp;&amp; cd build$ cmake ..$ make -j4 å®‰è£…123$ sudo make install$ sudo nano /etc/ld.so.conf.d/opencv.conf # add `/usr/local/lib`$ sudo ldconfig éªŒè¯OpenCVè‡ªå¸¦éªŒè¯ç¨‹åºï¼Œåœ¨opencv-3.4.4/samples/cpp/example_cmakeä¸­å¯ä»¥æ‰¾åˆ° 1234$ cd opencv-3.4.4/samples/cpp/example_cmake$ cmake .$ make$ ./opencv_example å¦‚æžœæ²¡é—®é¢˜ï¼Œå¯ä»¥çœ‹åˆ°ä½ çš„å¤§è„¸äº†~ Reference Ubuntu16.04å®‰è£…openCV3.4.4 - è¾£å±å°å¿ƒçš„å­¦ä¹ ç¬”è®° - CSDNåšå®¢ https://blog.csdn.net/weixin_39992397/article/details/84345197]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pythonè¯»å†™é…ç½®æ–‡ä»¶]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AF%BB%E5%86%99%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæœ‰è®¸å¤šè¿è¡Œå‚æ•°éœ€è¦æŒ‡å®šï¼Œæœ‰å‡ ç§æ–¹æ³•å¯ä»¥è§£å†³ å®šä¹‰.pyæ–‡ä»¶å­˜å‚¨å˜é‡ å®šä¹‰å‘½åå…ƒç»„collections.namedtuple() åˆ›å»º.configï¼Œ.iniç­‰é…ç½®æ–‡ä»¶ Python è¯»å–å†™å…¥é…ç½®æ–‡ä»¶å¾ˆæ–¹ä¾¿ï¼Œä½¿ç”¨å†…ç½®æ¨¡å—configparserå³å¯ è¯»å‡ºé¦–å…ˆåˆ›å»ºæ–‡ä»¶test.configæˆ–test.iniï¼Œå†™å…¥å¦‚ä¸‹å†…å®¹123456789[db]db_port = 3306db_user = rootdb_host = 127.0.0.1db_pass = test[concurrent]processor = 20thread = 10 è¯»å–æ“ä½œå¦‚ä¸‹1234567891011121314151617181920212223242526272829&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; configfile = &quot;./test.config&quot;&gt;&gt;&gt; inifile = &quot;./test.ini&quot;&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.read(configfile) # è¯»å–æ–‡ä»¶å†…å®¹&gt;&gt;&gt; &gt;&gt;&gt; sections = cf.sections() # æ‰€æœ‰çš„sectionï¼Œä»¥åˆ—è¡¨çš„å½¢å¼è¿”å›ž&gt;&gt;&gt; sections[&apos;db&apos;, &apos;concurrent&apos;]&gt;&gt;&gt; &gt;&gt;&gt; options = cf.options(&apos;db&apos;) # è¯¥sectionçš„æ‰€æœ‰option&gt;&gt;&gt; options[&apos;db_port&apos;, &apos;db_user&apos;, &apos;db_host&apos;, &apos;db_pass&apos;]&gt;&gt;&gt; &gt;&gt;&gt; items = cf.items(&apos;db&apos;) # è¯¥sectionçš„æ‰€æœ‰é”®å€¼å¯¹&gt;&gt;&gt; items[(&apos;db_port&apos;, &apos;3306&apos;), (&apos;db_user&apos;, &apos;root&apos;), (&apos;db_host&apos;, &apos;127.0.0.1&apos;), (&apos;db_pass&apos;, &apos;test&apos;)]&gt;&gt;&gt; &gt;&gt;&gt; db_user = cf.get(&apos;db&apos;, &apos;db_user&apos;) # sectionä¸­optionçš„å€¼ï¼Œè¿”å›žä¸ºstringç±»åž‹&gt;&gt;&gt; db_user&apos;root&apos;&gt;&gt;&gt; &gt;&gt;&gt; db_port = cf.getint(&apos;db&apos;, &apos;db_port&apos;) # å¾—åˆ°sectionä¸­optionçš„å€¼ï¼Œè¿”å›žä¸ºintç±»åž‹&gt;&gt;&gt; # ç±»ä¼¼çš„è¿˜æœ‰getboolean()ä¸Žgetfloat()&gt;&gt;&gt; db_port3306 å†™å…¥12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.add_section(&apos;test1&apos;) # æ–°å¢žsection&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test&quot;, &quot;count&quot;, 1) # æ–°å¢žoptionï¼šé”™è¯¯ç¤ºèŒƒTraceback (most recent call last): File &quot;&lt;pyshell#7&gt;&quot;, line 1, in &lt;module&gt; cf.set(&quot;test&quot;, &quot;count&quot;, 1) File &quot;C:\MyApplications\Python3\lib\configparser.py&quot;, line 1192, in set self._validate_value_types(option=option, value=value) File &quot;C:\MyApplications\Python3\lib\configparser.py&quot;, line 1177, in _validate_value_types raise TypeError(&quot;option values must be strings&quot;)TypeError: option values must be strings&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test&quot;, &quot;count&quot;, &apos;1&apos;) # æ–°å¢žoption&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test1&quot;, &quot;opt1&quot;, &apos;ok&apos;) # æ–°å¢žoption&gt;&gt;&gt; cf.remove_option(&quot;test1&quot;, &quot;opt1&quot;) # åˆ é™¤optionTrue&gt;&gt;&gt; &gt;&gt;&gt; cf.add_section(&apos;test2&apos;) # æ–°å¢žsection&gt;&gt;&gt; cf.remove_section(&apos;test2&apos;) # åˆ é™¤sectionTrue&gt;&gt;&gt; &gt;&gt;&gt; with open(&quot;./test_wr.config&quot;, &apos;w+&apos;) as f: cf.write(f) # å†™å…¥æ–‡ä»¶test_wr.config &gt;&gt;&gt; çŽ°åœ¨ç›®å½•å·²åˆ›å»ºæ–‡ä»¶test_wr.configï¼Œæ‰“å¼€å¯ä»¥çœ‹åˆ°12[test1]count = 1]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Pythonæ›´æ–°å®‰è£…çš„åŒ…]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E6%9B%B4%E6%96%B0%E5%AE%89%E8%A3%85%E7%9A%84%E5%8C%85%2F</url>
    <content type="text"><![CDATA[pipä¸æä¾›å‡çº§å…¨éƒ¨å·²å®‰è£…æ¨¡å—çš„æ–¹æ³•ï¼Œä»¥ä¸‹æŒ‡ä»¤å¯æŸ¥çœ‹æ›´æ–°ä¿¡æ¯1$ pip list --outdate å¾—åˆ°è¾“å‡ºä¿¡æ¯å¦‚ä¸‹123456789101112131415161718192021222324Package Version Latest Type----------------- --------- ---------- -----absl-py 0.3.0 0.6.1 sdistautopep8 1.3.5 1.4.2 sdistbleach 2.1.4 3.0.2 wheelcertifi 2018.8.24 2018.10.15 wheeldask 0.20.0 0.20.1 wheelgrpcio 1.14.1 1.16.0 wheelipykernel 5.0.0 5.1.0 wheelipython 7.0.1 7.1.1 wheeljedi 0.12.1 0.13.1 wheeljupyter-console 5.2.0 6.0.0 wheelMarkdown 2.6.11 3.0.1 wheelMarkupSafe 1.0 1.1.0 wheelmatplotlib 2.2.2 3.0.2 wheelmistune 0.8.3 0.8.4 wheelnumpy 1.14.5 1.15.4 wheelopencv-python 3.4.2.17 3.4.3.18 wheelPillow 5.2.0 5.3.0 wheelprometheus-client 0.3.1 0.4.2 sdistpyparsing 2.2.0 2.3.0 wheelpython-dateutil 2.7.3 2.7.5 wheelpytz 2018.5 2018.7 wheelurllib3 1.23 1.24.1 wheel ä»¥ä¸‹æä¾›ä¸€é”®å‡çº§çš„æ–¹æ³•ï¼Œå¯èƒ½æ¯”è¾ƒä¹…hhhh12345678from pip._internal.utils.misc import get_installed_distributionsfrom subprocess import call for dist in get_installed_distributions(): modulename = dist.project_name print(&apos;start processing module &apos; + modulename) call(&quot;pip install --upgrade &quot; + modulename, shell=True) print(&apos;module &apos; + modulename + &apos;done!&apos;)]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Pythonè®°å½•æ—¥å¿—]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[å‰è¨€æ—¥å¿—å¯ä»¥ç”¨æ¥è®°å½•åº”ç”¨ç¨‹åºçš„çŠ¶æ€ã€é”™è¯¯å’Œä¿¡æ¯æ¶ˆæ¯ï¼Œä¹Ÿç»å¸¸ä½œä¸ºè°ƒè¯•ç¨‹åºçš„å·¥å…·ã€‚Pythonæä¾›äº†ä¸€ä¸ªæ ‡å‡†çš„æ—¥å¿—æŽ¥å£ï¼Œå°±æ˜¯loggingæ¨¡å—ã€‚æ—¥å¿—çº§åˆ«æœ‰DEBUGã€INFOã€WARNINGã€ERRORã€CRITICALäº”ç§ã€‚ logging â€” Logging facility for Python â€” Python 3.7.1 documentation ä½¿ç”¨æ–¹æ³•loggerå¯¹è±¡1234&gt;&gt;&gt; import logging&gt;&gt;&gt; logger = logging.getLogger(__name__)&gt;&gt;&gt; logger&lt;Logger __main__ (WARNING)&gt; æ—¥å¿—çº§åˆ«å¯è¾“å‡ºäº”ç§ä¸åŒçš„æ—¥å¿—çº§åˆ«ï¼Œåˆ†åˆ«ä¸ºæœ‰DEBUGã€INFOã€WARNINGã€ERRORã€CRITICAL12345678&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&gt;&gt;&gt; logger.info(&apos;test log&apos;)&gt;&gt;&gt; logger.warning(&apos;test log&apos;)test log&gt;&gt;&gt; logger.error(&apos;test log&apos;)test log&gt;&gt;&gt; logger.critical(&apos;test log&apos;)test log å¯ä»¥çœ‹åˆ°åªæœ‰WARNINGåŠä»¥ä¸Šçº§åˆ«æ—¥å¿—è¢«è¾“å‡ºï¼Œè¿™æ˜¯ç”±äºŽé»˜è®¤çš„æ—¥å¿—çº§åˆ«æ˜¯WARNING ï¼Œæ‰€ä»¥ä½ŽäºŽæ­¤çº§åˆ«çš„æ—¥å¿—ä¸ä¼šè®°å½•ã€‚ åŸºç¡€é…ç½®1logging.basicConfig(**kwarg) **kwargä¸­éƒ¨åˆ†å‚æ•°å¦‚ä¸‹ format 12345678910%(levelname)ï¼šæ—¥å¿—çº§åˆ«çš„åå­—æ ¼å¼%(levelno)sï¼šæ—¥å¿—çº§åˆ«çš„æ•°å­—è¡¨ç¤º%(name)sï¼šæ—¥å¿—åå­—%(funcName)sï¼šå‡½æ•°åå­—%(asctime)ï¼šæ—¥å¿—æ—¶é—´ï¼Œå¯ä»¥ä½¿ç”¨datefmtåŽ»å®šä¹‰æ—¶é—´æ ¼å¼ï¼Œå¦‚ä¸Šå›¾ã€‚%(pathname)ï¼šè„šæœ¬çš„ç»å¯¹è·¯å¾„%(filename)ï¼šè„šæœ¬çš„åå­—%(module)ï¼šæ¨¡å—çš„åå­—%(thread)ï¼šthread id%(threadName)ï¼šçº¿ç¨‹çš„åå­— datefmt 1&apos;%Y-%m-%d %H:%M:%S&apos; level é»˜è®¤ä¸ºERROR 12345logging.DEBUGlogging.INFOlogging.WARNINGlogging.ERRORlogging.CRITICAL ä¾‹å¦‚12345678910111213141516&gt;&gt;&gt; # æœªè¾“å‡ºdebug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&gt;&gt;&gt; &gt;&gt;&gt; # ä¿®æ”¹é…ç½®&gt;&gt;&gt; log_format = &apos;%(filename)s [%(asctime)s] [%(levelname)s] %(message)s&apos;&gt;&gt;&gt; log_datefmt = &apos;%Y-%m-%d %H:%M:%S&apos;&gt;&gt;&gt; log_level = logging.DEBUG&gt;&gt;&gt; logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level)&gt;&gt;&gt; &gt;&gt;&gt; # è¾“å‡ºdebug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&lt;pyshell#8&gt; [2018-11-13 11:59:52] [DEBUG] test log è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ä¿å­˜ä»£ç ä¸ºæ–‡ä»¶log_test.py1234567891011121314151617181920import logginglog_format = &apos;%(filename)s [%(asctime)s] [%(levelname)s] %(message)s&apos;log_datefmt = &apos;%Y-%m-%d %H:%M:%S&apos;log_level = logging.DEBUGlog_filename = &apos;./test.log&apos;log_filemode = &apos;a&apos; # ä¹Ÿå¯ä»¥ä¸º&apos;w&apos;, &apos;w+&apos;ç­‰logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level, filename=log_filename, filemode=log_filemode)logger = logging.getLogger(__name__)logger.debug(&apos;test log&apos;)logger.info(&apos;test log&apos;)logger.warning(&apos;test log&apos;)logger.error(&apos;test log&apos;)logger.critical(&apos;test log&apos;) è¿è¡Œå®Œæ¯•ï¼Œæ‰“å¼€log_test.logæ–‡ä»¶å¯ä»¥çœ‹åˆ°12345log_test.py [2018-11-13 12:11:04] [DEBUG] test loglog_test.py [2018-11-13 12:11:04] [INFO] test loglog_test.py [2018-11-13 12:11:04] [WARNING] test loglog_test.py [2018-11-13 12:11:04] [ERROR] test loglog_test.py [2018-11-13 12:11:04] [CRITICAL] test log]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Githubåšå®¢æ­å»º]]></title>
    <url>%2F2019%2F01%2F04%2FGithub-Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[å‰è¨€é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼ŒçŽ°æœ‰çš„åšå®¢è¿˜æ˜¯çŽ°æœ‰çš„è¿™ç¯‡æ–‡ç« å‘¢ï¼Ÿ è½¯ä»¶å®‰è£…å®‰è£…node.js, git, hexo åšå®¢æ­å»ºåˆå§‹åŒ–æŽ¨èä½¿ç”¨gitå‘½ä»¤çª—å£ï¼Œæ‰§è¡Œå¦‚ä¸‹æŒ‡ä»¤12345678910111213141516171819202122232425262728293031$ mkdir Blog$ cd Blog$ hexo initINFO Cloning hexo-starter to ~\Desktop\BlogCloning into &apos;C:\Users\LouisHsu\Desktop\Blog&apos;...remote: Enumerating objects: 68, done.remote: Total 68 (delta 0), reused 0 (delta 0), pack-reused 68Unpacking objects: 100% (68/68), done.Submodule &apos;themes/landscape&apos; (https://github.com/hexojs/hexo-theme-landscape.git) registered for path &apos;themes/landscape&apos;Cloning into &apos;C:/Users/LouisHsu/Desktop/Blog/themes/landscape&apos;...remote: Enumerating objects: 1, done.remote: Counting objects: 100% (1/1), done.remote: Total 867 (delta 0), reused 0 (delta 0), pack-reused 866Receiving objects: 100% (867/867), 2.55 MiB | 494.00 KiB/s, done.Resolving deltas: 100% (459/459), done.Submodule path &apos;themes/landscape&apos;: checked out &apos;73a23c51f8487cfcd7c6deec96ccc7543960d350&apos;[32mINFO [39m Install dependenciesnpm WARN deprecated titlecase@1.1.2: no longer maintainednpm WARN deprecated postinstall-build@5.0.3: postinstall-build&apos;s behavior is now built into npm! You should migrate off of postinstall-build and use the new `prepare` lifecycle script with npm 5.0.0 or greater.&gt; nunjucks@3.1.6 postinstall C:\Users\LouisHsu\Desktop\Blog\node_modules\nunjucks&gt; node postinstall-build.js srcnpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)added 422 packages from 501 contributors and audited 4700 packages in 59.195sfound 0 vulnerabilitiesINFO Start blogging with Hexo! ç”Ÿæˆç›®å½•ç»“æž„å¦‚ä¸‹123456\-- scaffolds\-- source \-- _posts\-- themes|-- _config.yml|-- package.json ç»§ç»­123456$ npm installnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)audited 4700 packages in 5.99sfound 0 vulnerabilities çŽ°åœ¨è¯¥ç›®å½•æ‰§è¡ŒæŒ‡ä»¤ï¼Œå¼€å¯hexoæœåŠ¡å™¨123$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. å…³è”Githubåœ¨Githubæ–°å»ºä¸€ä¸ªä»“åº“ï¼Œå‘½åä¸ºusername.github.ioï¼Œä¾‹å¦‚isLouisHsu.github.ioï¼Œæ–°å»ºæ—¶å‹¾é€‰Initialize this repository with a READMEï¼Œå› ä¸ºè¿™ä¸ªä»“åº“å¿…é¡»ä¸èƒ½ä¸ºç©ºã€‚ æ‰“å¼€åšå®¢ç›®å½•ä¸‹çš„_config.ymlé…ç½®æ–‡ä»¶ï¼Œå®šä½åˆ°æœ€åŽçš„deployé€‰é¡¹ï¼Œä¿®æ”¹å¦‚ä¸‹1234deploy: type: git repository: git@github.com:isLouisHsu/isLouisHsu.github.io.git branch: master å®‰è£…æ’ä»¶1$ npm install hexo-deployer-git --save çŽ°åœ¨å°±å¯ä»¥å°†è¯¥ç›®å½•å†…å®¹æŽ¨é€åˆ°Githubæ–°å»ºçš„ä»“åº“ä¸­äº†1$ hexo d ä½¿ç”¨ä¸ªäººåŸŸå åœ¨sourceç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶CNAMEï¼Œè¾“å…¥è§£æžåŽçš„ä¸ªäººåŸŸå åœ¨Githubä¸»é¡µä¿®æ”¹åŸŸå å¤‡ä»½åšå®¢ æ²¡ã€‚æ²¡ä»€ä¹ˆç”¨æˆ‘ã€‚æˆ‘ä¸å¤‡ä»½äº†å¯ä»¥æ–°å»ºä¸€ä¸ªä»“åº“ä¸“é—¨ä¿å­˜æ–‡ä»¶è¯•è¯• çŽ°åœ¨åšå®¢çš„æºæ–‡ä»¶ä»…ä¿å­˜åœ¨PCä¸Šï¼Œ æˆ‘ä»¬å¯¹å®ƒä»¬è¿›è¡Œå¤‡ä»½ï¼Œå¹¶å°†ä»“åº“ä½œä¸ºåšå®¢æ–‡ä»¶å¤¹ åœ¨ä»“åº“æ–°å»ºåˆ†æ”¯hexoï¼Œè®¾ç½®ä¸ºé»˜è®¤åˆ†æ”¯ å°†ä»“åº“å…‹éš†è‡³æœ¬åœ° 1$ git clone https://github.com/isLouisHsu/isLouisHsu.github.io.git å…‹éš†æ–‡ä»¶ å°†ä¹‹å‰çš„Hexoæ–‡ä»¶å¤¹ä¸­çš„ 123456scffolds/source/themes/.gitignore_config.ymlpackage.json å¤åˆ¶åˆ°å…‹éš†ä¸‹æ¥çš„ä»“åº“æ–‡ä»¶å¤¹isLouisHsu.github.io å®‰è£…åŒ… 123$ npm install$ npm install hexo --save$ npm install hexo-deployer-git --save å¤‡ä»½åšå®¢ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤ 123$ git add .$ git commit -m &quot;backup&quot;$ git push origin hexo éƒ¨ç½²åšå®¢æŒ‡ä»¤ 1$ hexo g -d å•é”®æäº¤ ç¼–å†™è„šæœ¬commit.batï¼ŒåŒå‡»å³å¯ 1234git add .git commit -m &apos;backup&apos;git push origin hexohexo g -d ä½¿ç”¨æ–¹æ³• ç›®å½•ç»“æž„ public ç”Ÿæˆçš„ç½‘ç«™æ–‡ä»¶ï¼Œå‘å¸ƒçš„ç«™ç‚¹æ–‡ä»¶ã€‚ source èµ„æºæ–‡ä»¶å¤¹ï¼Œç”¨äºŽå­˜æ”¾å†…å®¹ã€‚ tag æ ‡ç­¾æ–‡ä»¶å¤¹ã€‚ archive å½’æ¡£æ–‡ä»¶å¤¹ã€‚ categoryåˆ†ç±»æ–‡ä»¶å¤¹ã€‚ downloads/code include codeæ–‡ä»¶å¤¹ã€‚ :lang i18n_dir å›½é™…åŒ–æ–‡ä»¶å¤¹ã€‚ _config.yml é…ç½®æ–‡ä»¶ æŒ‡ä»¤ 123456789101112131415161718192021222324252627$ hexo helpUsage: hexo &lt;command&gt;Commands: clean Remove generated files and cache. config Get or set configurations. deploy Deploy your website. generate Generate static files. help Get help on a command. init Create a new Hexo folder. list List the information of the site migrate Migrate your site from other system to Hexo. new Create a new post. publish Moves a draft post from _drafts to _posts folder. render Render files with renderer plugins. server Start the server. version Display version information.Global Options: --config Specify config file instead of using _config.yml --cwd Specify the CWD --debug Display all verbose messages in the terminal --draft Display draft posts --safe Disable all plugins and scripts --silent Hide output on consoleFor more help, you can use &apos;hexo help [command]&apos; for the detailed information or you can check the docs: http://hexo.io/docs/ æ‹“å±•åŠŸèƒ½æ”¯æŒæ’å…¥å›¾ç‰‡1$ npm install hexo-asset-image --save ä¿®æ”¹æ–‡ä»¶_config.yml1post_asset_folder: true åœ¨æ‰§è¡Œ$ hexo n [layout] &lt;title&gt;æ—¶ä¼šç”ŸæˆåŒåæ–‡ä»¶å¤¹ï¼ŒæŠŠå›¾ç‰‡æ”¾åœ¨è¿™ä¸ªæ–‡ä»¶å¤¹å†…ï¼Œåœ¨.mdæ–‡ä»¶ä¸­æ’å…¥å›¾ç‰‡1![image_name](/title/image_name.png) æœç´¢åŠŸèƒ½12$ npm install hexo-generator-searchdb --save$ npm install hexo-generator-search --save ç«™ç‚¹é…ç½®æ–‡ä»¶_config.ymlä¸­æ·»åŠ 12345search: path: search.xml field: post format: html limit: 10000 ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶/themes/xxx/_config.yml12local_search: enable: true å¸¦è¿‡æ»¤åŠŸèƒ½çš„é¦–é¡µæ’ä»¶åœ¨é¦–é¡µåªæ˜¾ç¤ºæŒ‡å®šåˆ†ç±»ä¸‹é¢çš„æ–‡ç« åˆ—è¡¨ã€‚12$ npm install hexo-generator-index2 --save$ npm uninstall hexo-generator-index --save ä¿®æ”¹_config.yml1234567index_generator: per_page: 10 order_by: -date include: - category Web # åªåŒ…å«Webåˆ†ç±»ä¸‹çš„æ–‡ç«  exclude: - tag Hexo # ä¸åŒ…å«æ ‡ç­¾ä¸ºHexoçš„æ–‡ç«  æ•°å­¦å…¬å¼æ”¯æŒhexoé»˜è®¤çš„æ¸²æŸ“å¼•æ“Žæ˜¯markedï¼Œä½†æ˜¯markedä¸æ”¯æŒmathjaxã€‚kramedæ˜¯åœ¨markedçš„åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹ã€‚1234$ npm uninstall hexo-math --save # åœæ­¢ä½¿ç”¨ hexo-math$ npm install hexo-renderer-mathjax --save # å®‰è£…hexo-renderer-mathjaxåŒ…ï¼š$ npm uninstall hexo-renderer-marked --save # å¸è½½åŽŸæ¥çš„æ¸²æŸ“å¼•æ“Ž$ npm install hexo-renderer-kramed --save # å®‰è£…æ–°çš„æ¸²æŸ“å¼•æ“Ž ä¿®æ”¹/node_modules/kramed/lib/rules/inline.js12345678911| escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,...20| em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,-&gt;11| escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,...20| em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, ä¿®æ”¹/node_modules/hexo-renderer-kramed/lib/renderer.js123456789101112131464| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed&apos;s rule: $$ + \1 + $$67| return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);68| &#125;-&gt;64| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed&apos;s rule: $$ + \1 + $$67| // return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);68| return text;69| &#125; åœ¨ä¸»é¢˜ä¸­å¼€å¯mathjaxå¼€å…³ï¼Œä¾‹å¦‚nextä¸»é¢˜ä¸­1234# MathJax Supportmathjax: enable: true per_page: true åœ¨æ–‡ç« ä¸­12345678---title: title.mddate: 2019-01-04 12:47:37categories:tags:mathjax: truetop:--- æµ‹è¯• A = \left[\begin{matrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{matrix}\right]Reference åŸºäºŽhexo+githubæ­å»ºä¸€ä¸ªç‹¬ç«‹åšå®¢ - ç‰§äº‘äº‘ - åšå®¢å›­ https://www.cnblogs.com/MuYunyun/p/5927491.htmlhexo+github pagesè½»æ¾æ­åšå®¢(1) | ex2tronâ€™s Blog http://ex2tron.wang/hexo-blog-with-github-pages-1/hexoä¸‹LaTeXæ— æ³•æ˜¾ç¤ºçš„è§£å†³æ–¹æ¡ˆ - crazy_scottçš„åšå®¢ - CSDNåšå®¢ https://blog.csdn.net/crazy_scott/article/details/79293576åœ¨Hexoä¸­æ¸²æŸ“MathJaxæ•°å­¦å…¬å¼ - ç®€ä¹¦ https://www.jianshu.com/p/7ab21c7f0674æ€Žä¹ˆåŽ»å¤‡ä»½ä½ çš„Hexoåšå®¢ - ç®€ä¹¦ https://www.jianshu.com/p/baab04284923Hexoä¸­æ·»åŠ æœ¬åœ°å›¾ç‰‡ - èœ•å˜C - åšå®¢å›­ https://www.cnblogs.com/codehome/p/8428738.html?utm_source=debugrun&amp;utm_medium=referralhexo æœç´¢åŠŸèƒ½ - é˜¿ç”˜çš„åšå®¢ - CSDNåšå®¢ https://blog.csdn.net/ganzhilin520/article/details/79047983]]></content>
      <categories>
        <category>Others</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[äºŒæ¬¡å…¥å‘raspberry-pi]]></title>
    <url>%2F2018%2F10%2F29%2F%E4%BA%8C%E6%AC%A1%E5%85%A5%E5%9D%91raspberry-pi%2F</url>
    <content type="text"><![CDATA[å‰è¨€è·ä¸Šä¸€æ¬¡æ­å»ºæ ‘èŽ“æ´¾å¹³å°å·²ç»ä¸¤å¹´äº†ï¼Œä¿å­˜çš„é•œåƒå‡ºäº†é—®é¢˜ï¼Œé‡æ–°æ­å»ºä¸€ä¸‹ã€‚ ç³»ç»Ÿä¸‹è½½ä»Žå®˜ç½‘ä¸‹è½½æ ‘èŽ“æ´¾ç³»ç»Ÿé•œåƒï¼Œæœ‰ä»¥ä¸‹å‡ ç§å¯é€‰ Raspberry Pi â€” Teach, Learn, and Make with Raspberry Pi Raspbian &amp; Raspbian Liteï¼ŒåŸºäºŽDebian Noobs &amp; Noobs Lite Ubuntu MATE Snappy Ubuntu Core Windows 10 IOT å…¶ä½™ä¸å¤ªäº†è§£ï¼Œä¹‹å‰å®‰è£…çš„æ˜¯Raspbianï¼Œå¯¹äºŽDebianå„ç§ä¸é€‚ï¼Œæ¢ä¸Šç•Œé¢ä¼˜é›…çš„Ubuntu MateçŽ©ä¸€ä¸‹è€è€å®žå®žçŽ©Raspbianï¼Œç¬‘è„¸:-) å®‰è£…æ¯”è¾ƒç®€å•ï¼Œå‡†å¤‡micro-SDå¡ï¼Œç”¨Win32 Disk Imagerçƒ§å†™é•œåƒ Win32 Disk Imager download | SourceForge.net å®‰è£…å®Œè½¯ä»¶åŽå¯ç‚¹å‡»Readå¤‡ä»½è‡ªå·±çš„é•œåƒã€‚ æ³¨æ„ç¬¬äºŒæ¬¡å¼€æœºå‰éœ€è¦é…ç½®config.txtæ–‡ä»¶ï¼Œå¦åˆ™hdmiæ— æ³•æ˜¾ç¤º æ ‘èŽ“æ´¾é…ç½®æ–‡æ¡£ config.txt è¯´æ˜Ž | æ ‘èŽ“æ´¾å®žéªŒå®¤ 123456disable_overscan=1 hdmi_force_hotplug=1hdmi_group=2 # DMThdmi_mode=32 # 1280x960hdmi_drive=2config_hdmi_boost=4 ä¿®æ”¹äº¤æ¢åˆ†åŒºUbuntu MateæŸ¥çœ‹äº¤æ¢åˆ†åŒº1$ free -m æœªè®¾ç½®æ—¶å¦‚ä¸‹1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 0 0 0 åˆ›å»ºå’ŒæŒ‚è½½12345678910111213141516# èŽ·å–æƒé™$ sudo -i# åˆ›å»ºç›®å½•$ mkdir /swap$ cd /swap# æŒ‡å®šä¸€ä¸ªå¤§å°ä¸º1Gçš„åä¸ºâ€œswapâ€çš„äº¤æ¢æ–‡ä»¶$ dd if=/dev/zero of=swap bs=1M count=1k# åˆ›å»ºäº¤æ¢æ–‡ä»¶$ mkswap swap# æŒ‚è½½äº¤æ¢åˆ†åŒº$ swapon swap# å¸è½½äº¤æ¢åˆ†åŒº# $ swapoff swap æŸ¥çœ‹äº¤æ¢åˆ†åŒº1$ free -m æœªè®¾ç½®æ—¶å¦‚ä¸‹1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 RaspbianWe will change the configuration in the file /etc/dphys-swapfile:1$ sudo nano /etc/dphys-swapfile The default value in Raspbian is:1CONF_SWAPSIZE=100 We will need to change this to:1CONF_SWAPSIZE=1024 Then you will need to stop and start the service that manages the swapfile own Rasbian:12$ sudo /etc/init.d/dphys-swapfile stop$ sudo /etc/init.d/dphys-swapfile start You can then verify the amount of memory + swap by issuing the following command:1$ free -m The output should look like:1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 è½¯ä»¶å®‰è£…æŒ‡ä»¤ apt-get å®‰è£…è½¯ä»¶apt-get install softname1 softname2 softname3 ... å¸è½½è½¯ä»¶apt-get remove softname1 softname2 softname3 ... å¸è½½å¹¶æ¸…é™¤é…ç½®apt-get remove --purge softname1 æ›´æ–°è½¯ä»¶ä¿¡æ¯æ•°æ®åº“apt-get update è¿›è¡Œç³»ç»Ÿå‡çº§apt-get upgrade æœç´¢è½¯ä»¶åŒ…apt-cache search softname1 softname2 softname3 ... ä¿®æ­£ï¼ˆä¾èµ–å…³ç³»ï¼‰å®‰è£…ï¼šapt-get -f insta dpkg å®‰è£….debè½¯ä»¶åŒ…dpkg -i xxx.deb åˆ é™¤è½¯ä»¶åŒ…dpkg -r xxx.deb è¿žåŒé…ç½®æ–‡ä»¶ä¸€èµ·åˆ é™¤dpkg -r --purge xxx.deb æŸ¥çœ‹è½¯ä»¶åŒ…ä¿¡æ¯dpkg -info xxx.deb æŸ¥çœ‹æ–‡ä»¶æ‹·è´è¯¦æƒ…dpkg -L xxx.deb æŸ¥çœ‹ç³»ç»Ÿä¸­å·²å®‰è£…è½¯ä»¶åŒ…ä¿¡æ¯dpkg -l é‡æ–°é…ç½®è½¯ä»¶åŒ…dpkg-reconfigure xx å¸è½½è½¯ä»¶åŒ…åŠå…¶é…ç½®æ–‡ä»¶ï¼Œä½†æ— æ³•è§£å†³ä¾èµ–å…³ç³»ï¼sudo dpkg -p package_name å¸è½½è½¯ä»¶åŒ…åŠå…¶é…ç½®æ–‡ä»¶ä¸Žä¾èµ–å…³ç³»åŒ…sudo aptitude purge pkgname æ¸…é™¤æ‰€æœ‰å·²åˆ é™¤åŒ…çš„æ®‹é¦€é…ç½®æ–‡ä»¶dpkg -l |grep ^rc|awk &#39;{print $2}&#39; |sudo xargs dpkg -P è½¯ä»¶æº å¤‡ä»½åŽŸå§‹æ–‡ä»¶ 1$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup ä¿®æ”¹æ–‡ä»¶å¹¶æ·»åŠ å›½å†…æº 1$ vi /etc/apt/sources.list æ³¨é‡Šå…ƒæ–‡ä»¶å†…çš„æºå¹¶æ·»åŠ å¦‚ä¸‹åœ°å€ 123456789101112131415161718192021#Mirror.lupaworld.com æºæ›´æ–°æœåŠ¡å™¨ï¼ˆæµ™æ±Ÿçœæ­å·žå¸‚åŒçº¿æœåŠ¡å™¨ï¼Œç½‘é€šåŒç”µä¿¡éƒ½å¯ä»¥ç”¨ï¼Œäºšæ´²åœ°åŒºå®˜æ–¹æ›´æ–°æœåŠ¡å™¨ï¼‰ï¼šdeb http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiverse#Ubuntu å®˜æ–¹æº deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse æˆ–è€… 1234567891011121314151617181920212223#é˜¿é‡Œäº‘deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse#ç½‘æ˜“163deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse æ”¾ç½®éžå®˜æ–¹æºçš„åŒ…ä¸å®Œæ•´ï¼Œå¯åœ¨ä¸ºä¸æ·»åŠ å®˜æ–¹æº 1deb http://archive.ubuntu.org.cn/ubuntu-cn/ feisty main restricted universe multiverse æ›´æ–°æº 1$ sudo apt-get update æ›´æ–°è½¯ä»¶ 1$ sudo apt-get dist-upgrade å¸¸è§çš„ä¿®å¤å®‰è£…å‘½ä»¤ 1$ sudo apt-get -f install Pythonä¸»è¦æ˜¯Pythonå’Œç›¸å…³ä¾èµ–åŒ…çš„å®‰è£…ï¼Œä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤å¯å¯¼å‡ºå·²å®‰è£…çš„ä¾èµ–åŒ…1$ pip freeze &gt; requirements.txt å¹¶ä½¿ç”¨æŒ‡ä»¤å®‰è£…åˆ°æ ‘èŽ“æ´¾1$ pip install -r requirements.txt æ³¨æ„pipæ›´æ–°1python -m pip install --upgrade pip æœ€æ–°ç‰ˆæœ¬ä¼šæŠ¥é”™1ImportError: cannot import name main ä¿®æ”¹æ–‡ä»¶/usr/bin/pip123from pip import mainif __name__ == &apos;__main__&apos;: sys.exit(main()) æ”¹ä¸º123from pip import __main__if __name__ == &apos;__main__&apos;: sys.exit(__main__._main()) æˆåŠŸ!!!å¤±è´¥äº†ï¼Œç¬‘è„¸:-)ï¼Œæ‰‹åŠ¨å®‰è£…å§ã€‚ã€‚ã€‚ éƒ¨åˆ†åŒ…å¯ä½¿ç”¨pip3 123$ pip3 install numpy$ pip3 install pandas$ pip3 install sklearn è‹¥éœ€è¦æƒé™ï¼ŒåŠ å…¥--user éƒ¨åˆ†åŒ…ç”¨apt-getï¼Œä½†æ˜¯ä¼˜å…ˆå®‰è£…åˆ°Python2.7ç‰ˆæœ¬ï¼Œç¬‘è„¸:-) 123$ sudo apt-get install python-scipy$ sudo apt-get install python-matplotlib$ sudo apt-get install python-opencv éƒ¨åˆ†ä»ŽPIPYä¸‹è½½.whlæˆ–.tar.gzæ–‡ä»¶ PyPI â€“ the Python Package Index Â· PyPI tensorboardX-1.4-py2.py3-none-any.whl visdom-0.1.8.5.tar.gz å®‰è£…æŒ‡ä»¤ä¸º 1$ pip3 install xxx.whl 12$ tar -zxvf xxx.tar.gz$ python setup.py install Pytorchæºç å®‰è£… pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration å®‰è£…æ–¹æ³•Installation - From Source éœ€è¦ç”¨åˆ°minicondaï¼Œå®‰è£…æ–¹æ³•å¦‚ä¸‹ï¼Œæ³¨æ„ä¸­é—´å›žè½¦æŒ‰æ…¢ä¸€ç‚¹ï¼Œæœ‰ä¸¤æ¬¡è¾“å…¥ã€‚ã€‚ã€‚ã€‚ã€‚(è¡Œæˆ‘æ…¢æ…¢çœ‹æ¡æ¬¾ä¸è¡Œä¹ˆã€‚ã€‚ç¬‘è„¸:-)) ç¬¬ä¸€æ¬¡æ˜¯æ˜¯å¦åŒæ„æ¡æ¬¾ï¼Œyes ç¬¬äºŒæ¬¡æ˜¯æ·»åŠ åˆ°çŽ¯å¢ƒå˜é‡ï¼Œyesï¼Œå¦åˆ™è‡ªå·±ä¿®æ”¹/home/pi/.bashrcæ·»åŠ åˆ°çŽ¯å¢ƒå˜é‡ 1234567891011$ wget http://repo.continuum.io/miniconda/Miniconda3-latest-Linux-armv7l.sh$ sudo md5sum Miniconda3-latest-Linux-armv7l.sh # (optional) check md5$ sudo /bin/bash Miniconda3-latest-Linux-armv7l.sh # -&gt; change default directory to /home/pi/miniconda3$ sudo nano /home/pi/.bashrc # -&gt; add: export PATH=&quot;/home/pi/miniconda3/bin:$PATH&quot;$ sudo reboot -h now$ conda $ python --version$ sudo chown -R pi miniconda3 ç„¶åŽå°±å¯ä»¥å®‰è£…äº†æ²¡æœ‰å¯¹åº”ç‰ˆæœ¬çš„mklï¼Œç¬‘è„¸:-) 12345678910111213export CMAKE_PREFIX_PATH=&quot;$(dirname $(which conda))/../&quot; # [anaconda root directory]# Disable CUDAexport NO_CUDA=1# Install basic dependenciesconda install numpy pyyaml mkl mkl-include setuptools cmake cffi typingconda install -c mingfeima mkldnn# Install Pytorchgit clone --recursive https://github.com/pytorch/pytorchcd pytorchpython setup.py install tensorflow å®‰è£…tensorflowéœ€è¦çš„ä¸€äº›ä¾èµ–å’Œå·¥å…· 1234567$ sudo apt-get update# For Python 2.7$ sudo apt-get install python-pip python-dev# For Python 3.3+$ sudo apt-get install python3-pip python3-dev å®‰è£…tensorflow è‹¥ä¸‹è½½å¤±è´¥ï¼Œæ‰‹åŠ¨æ‰“å¼€ä¸‹é¢ç½‘é¡µä¸‹è½½.whlåŒ… 1234567# For Python 2.7$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp27-none-linux_armv7l.whl$ sudo pip install tensorflow-1.1.0-cp27-none-linux_armv7l.whl# For Python 3.4$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl$ sudo pip3 install tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl å¸è½½ï¼Œé‡è£…mock 1234567# For Python 2.7$ sudo pip uninstall mock$ sudo pip install mock# For Python 3.3+$ sudo pip3 uninstall mock$ sudo pip3 install mock å®‰è£…çš„ç‰ˆæœ¬tensorflow v1.1.0æ²¡æœ‰modelsï¼Œå› ä¸º1.0ç‰ˆæœ¬ä»¥åŽmodelså°±è¢«Sam Abrahamsç‹¬ç«‹å‡ºæ¥äº†ï¼Œä¾‹å¦‚classify_image.pyå°±åœ¨models/tutorials/image/imagenet/é‡Œ tensorflow/models å…¶ä½™ è¾“å…¥æ³• 12$ sudo apt-get install fcitx fcitx-googlepinyin $ fcitx-module-cloudpinyin fcitx-sunpinyin git 1$ sudo apt-get install git é…ç½®gitå’Œssh 12345$ git config --global user.name &quot;Louis Hsu&quot;$ git config --global user.email is.louishsu@foxmail.com$ ssh-keygen -t rsa -C &quot;is.louishsu@foxmail.com&quot;$ cat ~/.ssh/id_rsa.pub # æ·»åŠ åˆ°github]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softmax Regression]]></title>
    <url>%2F2018%2F10%2F18%2FSoftmax-Regression%2F</url>
    <content type="text"><![CDATA[Unsupervised Feature Learning and Deep Learning Tutorial å¼•è¨€Logistic Regressionä¸­é‡‡ç”¨çš„éžçº¿æ€§å‡½æ•°ä¸ºSigmoidï¼Œå°†è¾“å‡ºå€¼æ˜ å°„åˆ°$(0, 1)$ä¹‹é—´ä½œä¸ºæ¦‚çŽ‡è¾“å‡ºï¼Œå¤„ç†çš„æ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œé‚£ä¹ˆå¯¹äºŽå¤šåˆ†ç±»çš„é—®é¢˜æ€Žä¹ˆå¤„ç†å‘¢ï¼Ÿ æ¨¡åž‹ ç”±Logisticå›žå½’æŽ¨å¹¿è€Œæ¥ SoftmaxSoftmaxåœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­æœ‰ç€éžå¸¸å¹¿æ³›çš„åº”ç”¨ã€‚å°¤å…¶åœ¨å¤„ç†å¤šåˆ†ç±»$(K&gt;2)$é—®é¢˜ï¼Œåˆ†ç±»å™¨æœ€åŽçš„è¾“å‡ºå•å…ƒéœ€è¦Softmaxå‡½æ•°è¿›è¡Œæ•°å€¼å¤„ç†ã€‚ S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]å…¶ä¸­$x$ä¸ºçŸ©é˜µå½¢å¼çš„å‘é‡ï¼Œå…¶ç»´åº¦ä¸º$(KÃ—1)$ï¼Œ$K$ä¸ºç±»åˆ«æ•°ç›®ã€‚Softmaxçš„è¾“å‡ºå‘é‡ç»´åº¦ä¸Ž$x$ç›¸åŒï¼Œå„å…ƒç´ $x_i$åŠ å’Œä¸º$1$ï¼Œå¯ç”¨äºŽè¡¨ç¤ºå–å„ä¸ªç±»åˆ«çš„æ¦‚çŽ‡ã€‚ æ³¨æ„åˆ°ï¼Œå¯¹äºŽå‡½æ•°$e^x$ \lim_{x \rightarrow - \infty} e^x = 0\lim_{x \rightarrow + \infty} e^x = +\infty å‡è®¾æ‰€æœ‰çš„$x_i$ç­‰äºŽæŸå¸¸æ•°$c$ï¼Œç†è®ºä¸Šå¯¹æ‰€æœ‰$x_i$ä¸Šå¼ç»“æžœä¸º$\frac{1}{n}$ è‹¥$c$ä¸ºå¾ˆå°çš„è´Ÿæ•°ï¼Œ$e^c$ä¸‹æº¢ï¼Œç»“æžœä¸º$NaN$ï¼› è‹¥$c$é‡çº§å¾ˆå¤§ï¼Œ$e^c$ä¸Šæº¢ï¼Œç»“æžœä¸º$NaN$ã€‚ åœ¨æ•°å€¼è®¡ç®—æ—¶å¹¶ä¸ç¨³å®šï¼Œä½†æ˜¯Softmaxæ‰€æœ‰è¾“å…¥å¢žåŠ åŒä¸€å¸¸æ•°æ—¶ï¼Œè¾“å‡ºä¸å˜ï¼Œå¾—ç¨³å®šç‰ˆæœ¬ï¼š S(x) := S(x - max(x_i)) e^{x_{max} - max(x_i)} = 1 å‡åŽ»æœ€å¤§å€¼å¯¼è‡´$e^x$æœ€å¤§ä¸º$1$ï¼ŒæŽ’é™¤ä¸Šæº¢ï¼› åˆ†æ¯ä¸­è‡³å°‘æœ‰ä¸€é¡¹ä¸º$1$ï¼ŒæŽ’é™¤åˆ†æ¯ä¸‹æº¢å¯¼è‡´å¤„ä»¥$0$çš„æƒ…å†µã€‚ å…¶å¯¹æ•° log S(x)_i = x_i - log ({\sum_{k=1}^K exp(x_k)}) æ³¨æ„åˆ°ï¼Œç¬¬ä¸€é¡¹è¡¨ç¤ºè¾“å…¥$x_i$æ€»æ˜¯å¯¹ä»£ä»·å‡½æ•°æœ‰ç›´æŽ¥çš„è´¡çŒ®ã€‚è¿™ä¸€é¡¹ä¸ä¼šé¥±å’Œï¼Œæ‰€ä»¥å³ä½¿$x_i$å¯¹ä¸Šå¼çš„ç¬¬äºŒé¡¹çš„è´¡çŒ®å¾ˆå°ï¼Œå­¦ä¹ ä¾ç„¶å¯ä»¥è¿›è¡Œï¼› å½“æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶æ—¶ï¼Œç¬¬ä¸€é¡¹é¼“åŠ±$x_i$è¢«æŽ¨é«˜ï¼Œè€Œç¬¬äºŒé¡¹åˆ™é¼“åŠ±æ‰€æœ‰çš„$x$è¢«åŽ‹ä½Žï¼› ç¬¬äºŒé¡¹$log ({\sum_{k=1}^K exp(x_k)})$å¯ä»¥å¤§è‡´è¿‘ä¼¼ä¸º$max(x_k)$ï¼Œè¿™ç§è¿‘ä¼¼æ˜¯åŸºäºŽå¯¹ä»»ä½•æ˜Žæ˜¾å°äºŽ$max(x_k)$çš„$x_k$éƒ½æ˜¯ä¸é‡è¦çš„ï¼Œè´Ÿå¯¹æ•°ä¼¼ç„¶ä»£ä»·å‡½æ•°æ€»æ˜¯å¼ºçƒˆåœ°æƒ©ç½šæœ€æ´»è·ƒçš„ä¸æ­£ç¡®é¢„æµ‹ é™¤äº†å¯¹æ•°ä¼¼ç„¶ä¹‹å¤–çš„è®¸å¤šç›®æ ‡å‡½æ•°å¯¹ softmax å‡½æ•°ä¸èµ·ä½œç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œé‚£äº›ä¸ä½¿ç”¨å¯¹æ•°æ¥æŠµæ¶ˆ softmax ä¸­çš„æŒ‡æ•°çš„ç›®æ ‡å‡½æ•°ï¼Œå½“æŒ‡æ•°å‡½æ•°çš„å˜é‡å–éžå¸¸å°çš„è´Ÿå€¼æ—¶ä¼šé€ æˆæ¢¯åº¦æ¶ˆå¤±ï¼Œä»Žè€Œæ— æ³•å­¦ä¹  ä½œè€…ï¼šNirHeavenXæ¥æºï¼šCSDNåŽŸæ–‡ï¼šhttps://blog.csdn.net/qsczse943062710/article/details/61912464ç‰ˆæƒå£°æ˜Žï¼šæœ¬æ–‡ä¸ºåšä¸»åŽŸåˆ›æ–‡ç« ï¼Œè½¬è½½è¯·é™„ä¸Šåšæ–‡é“¾æŽ¥ï¼ Softmaxè§£å†³å¤šåˆ†ç±»é—®é¢˜å¯¹äºŽå…·æœ‰$K$ä¸ªåˆ†ç±»çš„é—®é¢˜ï¼Œæ¯ä¸ªç±»åˆ«è®­ç»ƒä¸€ç»„å‚æ•°$ w_k $ z_k^{(i)} = w_k^Tx^{(i)}æˆ–å†™ä½œçŸ©é˜µå½¢å¼ z^{(i)} = W^Tx^{(i)}å…¶ä¸­ x^{(i)} = \left[ \begin{matrix} x_0^{(i)}\\ x_1^{(i)}\\ ...\\ x_n^{(i)} \end{matrix} \right]_{nÃ—1}, x_0^{(i)}=1 W = [w_1, w_2, ..., w_K]_{(n+1)Ã—K} w_i = \left[ \begin{matrix} w_{i0}\\ w_{i1}\\ ...\\ w_{in} \end{matrix} \right]_{nÃ—1}æœ€ç»ˆå„ç±»åˆ«è¾“å‡ºæ¦‚çŽ‡ä¸º \hat{y}^{(i)} = Softmax(z^{(i)}) äº§ç”Ÿäº†ä¸€ä¸ªå¥‡æ€ªçš„è„‘æ´žã€‚ã€‚ã€‚äºŒåˆ†ç±»é—®é¢˜ p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} } = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } }å®šä¹‰äºŒåˆ†ç±»çº¿æ€§å•å…ƒè¾“å‡ºçš„å·®å€¼ä¸º z = x_1 - x_2å¾—åˆ° p(x_1) = \frac{1}{1 + e^{-z}}ä»¥$x_1 = [x_{11}, x_{12}]^T$ä¸ºä¾‹(äºŒç»´ç‰¹å¾)ï¼Œå–$w_1=1, w_2=2, b=3$ p(x_1) = \frac{1}{1 + e^{-(w_1 x_{11} + w_2 x_{12} + b)}} è€Œå¤šåˆ†ç±»é—®é¢˜ï¼Œä»¥$3$åˆ†ç±»ä¸ºä¾‹ p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} + e^{x_3}} = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } + e^{ - (x_1 - x_3)} }å®šä¹‰çº¿æ€§å•å…ƒè¾“å‡ºçš„å·®å€¼ä¸º z_{12} = x_1 - x_2 z_{13} = x_1 - x_3 p(x_1) = \frac{ 1 }{ 1 + e^{ - z_{12} } + e^{ - z_{13}} }åšå‡ºå›¾åƒä¸º æŸå¤±å‡½æ•°ç”±äº¤å‰ç†µç†è§£CrossEnt = \sum_j p_j log \frac{1}{q_j}è€Œå¯¹äºŽæ ·æœ¬$ (X^{(i)}, y^{(i)}) $ï¼Œä¸ºç¡®å®šäº‹ä»¶ï¼Œæ•…æ ‡ç­¾æ¦‚çŽ‡å„å…ƒç´ çš„å–å€¼$p_j$ä¸º$ y^{(i)}_j âˆˆ \{0,1\}$ï¼Œ$ q_jå³é¢„æµ‹è¾“å‡ºçš„æ¦‚çŽ‡å€¼\hat{y}^{(i)}_j$ ä¸€èˆ¬å–å„ä¸ªæ ·æœ¬æŸå¤±çš„å‡å€¼$(\frac{1}{N})$ L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N 1\{y^{(i)}_j=k\} log (\hat{y}^{(i)}_j) 1\{y^{(i)}_j=k\} = \begin{cases} 1 & y^{(i)}_j = k \\ 0 & y^{(i)}_j \neq k \end{cases}å¯å¯¹å®žé™…æ ‡ç­¾$y^{(i)}$é‡‡å–One-Hotç¼–ç ï¼Œä¾¿äºŽè®¡ç®— y^{(i)} = \left[ \begin{matrix} 0, ..., 1_{y^{(i)}}, ..., 0 \end{matrix} \right]^Tåˆ™ L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N y^{(i)T} log (\hat{y}^{(i)})ç”±å†³ç­–å¹³é¢ç†è§£ä»Žè´å¶æ–¯å†³ç­–å’Œåˆ†ç±»é—®é¢˜çš„å†³ç­–å¹³é¢å¯çŸ¥ï¼Œå¯¹äºŽç±»åˆ«$c_i$ï¼Œæœ‰ P(c_i|x) = \frac{P(x|c_i)}{\sum_{j=0}^KP(x|c_j)} å‡è®¾æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æœä»Žæ­£æ€åˆ†å¸ƒï¼Œå…ˆéªŒæ¦‚çŽ‡ç›¸ç­‰ï¼Œå„ç±»åˆ«æ ·æœ¬ç‰¹å¾é—´åæ–¹å·®ç›¸ç­‰ã€‚è¯æ˜Žç•¥. æ¢¯åº¦æŽ¨å¯¼Softmaxå‡½æ•°çš„å¯¼æ•°å¯¹äºŽ S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]ä¸€èˆ¬è¾“å‡ºä½œä¸ºæ¦‚çŽ‡å€¼ï¼Œè®° P = S(x)p_i = S(x)_iå¯¹å‘é‡$x$ä¸­æŸå…ƒç´ æ±‚å¯¼ \frac{âˆ‚S(x)}{âˆ‚x_i} = \frac{âˆ‚}{âˆ‚x_i} \left[ \begin{matrix} ...\\ \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}\\ ...\\ \end{matrix} \right] $(1)$ $i=k$$\frac{âˆ‚}{âˆ‚x_i} \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{expâ€™(x_i)Â·\sum_{j=1}^K exp(x_j) - exp(x_i)Â·(\sum_{j=1}^K exp(x_j))â€™}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)Â·\sum_{j=1}^K exp(x_j) - exp^2(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)} -(\frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)})^2$$ = p_i (1 - p_i)$ $(2)$ $i\neq k$$\frac{âˆ‚}{âˆ‚x_i} \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{expâ€™(x_k)Â·\sum_{j=1}^K exp(x_j) - exp(x_k)Â·(\sum_{j=1}^K exp(x_j))â€™}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{- exp(x_k)exp(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$= - p_i p_k$ ç»¼ä¸Š \frac{âˆ‚S(x)}{âˆ‚x_i}_{KÃ—1} = \left[ \begin{matrix} 0\\ ...\\ p_i\\ ...\\ 0 \end{matrix} \right] - \left[ \begin{matrix} p_i p_1\\ ...\\ p_i^2\\ ...\\ p_i p_K \end{matrix} \right] = \left( \left[ \begin{matrix} 0\\ ...\\ 1\\ ...\\ 0 \end{matrix} \right] - p \right)p_i æŸå¤±å‡½æ•°æ¢¯åº¦åœ¨OneHotç¼–ç ä¸‹ï¼ŒæŸå¤±å‡½æ•°å½¢å¼ä¸º L(\hat{y},y) = \frac{1}{N} \sum_{i=1}^N L (y^{(i)}, \hat{y}^{(i)}) L (y^{(i)}, \hat{y}^{(i)}) = - y^{(i)T} log \hat{y}^{(i)} \hat{y}^{(i)} = S(z^{(i)}) z^{(i)} = W^T x^{(i)}å³åªè€ƒè™‘å®žé™…åˆ†ç±»å¯¹åº”çš„æ¦‚çŽ‡å€¼ L (y^{(i)}, \hat{y}^{(i)}) = - log \hat{y}^{(i)}_{y^{(i)}} ç”±äºŽ $S(z^{(i)})_{t^{(i)}}$ä¸Ž$z^{(i)}$å‘é‡å„ä¸ªå…ƒç´ éƒ½æœ‰å…³ï¼Œç”±é“¾å¼æ±‚å¯¼æ³•åˆ™ \frac{âˆ‚ L^{(i)} }{âˆ‚w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } ( \sum_{k=1}^K \frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_k} \frac{âˆ‚z^{(i)}_k}{âˆ‚w_{pq}} )$1.$ è€ƒå¯Ÿ $\frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_k}$ \frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_k} = â€‹ \begin{cases} â€‹ \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_k) & k=y^{(i)} \\ â€‹ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_k & k \neq y^{(i)} â€‹ \end{cases}$2.$ è€ƒå¯Ÿ $\frac{âˆ‚z^{(i)}_k}{âˆ‚w_{pq}}$ \frac{âˆ‚z^{(i)}_k}{âˆ‚w_{pq}} = \begin{cases} \frac{âˆ‚z^{(i)}_k}{âˆ‚w_{pq}} = x^{(i)}_p & k=q\\ \frac{âˆ‚z^{(i)}_k}{âˆ‚w_{pq}} = 0 & k \neq q \end{cases} ç»¼ä¸Šæ‰€è¿° \frac{âˆ‚ L^{(i)} }{âˆ‚w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_q} \frac{âˆ‚z^{(i)}_q}{âˆ‚w_{pq}}å…¶ä¸­ \frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_q} = \begin{cases} \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_q) & q = y^{(i)}\\ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_q & q \neq y^{(i)} \end{cases} \frac{âˆ‚z^{(i)}_q}{âˆ‚w_{pq}} = x^{(i)}_pæ•…å¯¹äºŽå•ä¸ªæ ·æœ¬$(X^{(i)}, y^{(i)})$ï¼Œå½“æ ·æœ¬æ ‡ç­¾é‡‡ç”¨$OneHot$ç¼–ç æ—¶ \frac{âˆ‚L^{(i)}}{âˆ‚w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{âˆ‚ \hat{y}^{(i)}_{y^{(i)}} }{âˆ‚z^{(i)}_q} x^{(i)}_p = \begin{cases} (\hat{y}^{(i)}_q - 1)x^{(i)}_p & q = y^{(i)}\\ \hat{y}^{(i)}_qx^{(i)}_p & q \neq y^{(i)} \end{cases} æ³¨ï¼š è¿™é‡Œå¯ä»¥çº¦åˆ†åŽ»æŽ‰$\hat{y}^{(i)}_{y^{(i)}}$ \frac{âˆ‚L^{(i)}}{âˆ‚w_{pq}} = ( \hat{y}^{(i)}_q - y^{(i)}_q) x^{(i)}_pæ›´ä¸€èˆ¬çš„ï¼Œå†™æˆçŸ©é˜µå½¢å¼ï¼Œè®°$X = [x_1, x_2, â€¦, x_m]^T$ï¼Œ$x_i$ä¸ºæ ·æœ¬ç‰¹å¾(åˆ—å‘é‡) âˆ‡_W L = X^T(\hat{Y} - Y) ç”¨çº¿æ€§æ¨¡åž‹è§£å†³åˆ†ç±»å’Œå›žå½’é—®é¢˜æ—¶ï¼Œå½¢å¼ç«Ÿå¦‚æ­¤ç»Ÿä¸€! è‡³æ­¤ä¸ºæ­¢ï¼Œæ¢¯åº¦æŽ¨å¯¼ç»“æŸï¼Œåˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿­ä»£æ±‚è§£å‚æ•°çŸ©é˜µ$W$å³å¯ã€‚ W := W - \alpha âˆ‡_W Lä»£ç @GitHub: Code of Softmax Regression Softmax12345678def softmax(X): &quot;&quot;&quot; æ•°å€¼è®¡ç®—ç¨³å®šç‰ˆæœ¬çš„softmaxå‡½æ•° @param &#123;ndarray&#125; X: shape(batch_size, n_labels) &quot;&quot;&quot; X_max = np.max(X, axis=1).reshape((-1, 1)) # æ¯è¡Œçš„æœ€å¤§å€¼ X = X - X_max # æ¯è¡Œå‡åŽ»æœ€å¤§å€¼ X = np.exp(X) return X / np.sum(X, axis=1).reshape((-1, 1)) cost function1234567891011def crossEnt(self, y_label_true, y_prob_pred): &quot;&quot;&quot; è®¡ç®—äº¤å‰ç†µæŸå¤±å‡½æ•° @param &#123;ndarray&#125; y_label_true: çœŸå®žæ ‡ç­¾ shape(batch_size,) @param &#123;ndarray&#125; y_prob_pred: é¢„æµ‹è¾“å‡º shape(batch_size, n_labels) &quot;&quot;&quot; mask = self.encoder.transform(y_label_true.reshape(-1, 1)).toarray() # shape(batch_size, n_labels) y_prob_masked = np.sum(mask * y_prob_pred, axis=1) # æ¯è¡ŒçœŸå®žæ ‡ç­¾å¯¹åº”çš„é¢„æµ‹è¾“å‡ºå€¼ y_prob_masked[y_prob_masked==0.] = 1. y_loss = np.log(y_prob_masked) loss = - np.mean(y_loss) # æ±‚å„æ ·æœ¬æŸå¤±çš„å‡å€¼ return loss gradient12345678910def grad(self, X_train, y_train, y_prob_pred): &quot;&quot;&quot; è®¡ç®—æ¢¯åº¦ \frac &#123;âˆ‚L&#125; &#123;âˆ‚W_&#123;pq&#125;&#125; @param X_train: è®­ç»ƒé›†ç‰¹å¾ @param y_train: è®­ç»ƒé›†æ ‡ç­¾ @param y_prob_pred: è®­ç»ƒé›†é¢„æµ‹æ¦‚çŽ‡è¾“å‡º @param y_label_pred: è®­ç»ƒé›†é¢„æµ‹æ ‡ç­¾è¾“å‡º &quot;&quot;&quot; y_train = self.encoder.transform(y_train) dW = X_train.T.dot(y_prob_pred - y_train) return dW training stepçœç•¥å¯è§†åŒ–å’ŒéªŒè¯éƒ¨åˆ†çš„ä»£ç 123456789101112131415161718192021222324252627282930313233343536def fit(self, X_train, X_valid, y_train, y_valid, min_acc=0.95, max_epoch=20, batch_size=20): &quot;&quot;&quot; è®­ç»ƒ &quot;&quot;&quot; # æ·»åŠ é¦–1åˆ—ï¼Œè¾“å…¥åˆ°åç½®w0 X_train = np.c_[np.ones(shape=(X_train.shape[0],)), X_train] X_valid = np.c_[np.ones(shape=(X_valid.shape[0],)), X_valid] X_train = self.scaler.fit_transform(X_train) # å°ºåº¦å½’ä¸€åŒ– X_valid = self.scaler.transform(X_valid) # å°ºåº¦å½’ä¸€åŒ– self.encoder.fit(y_train.reshape(-1, 1)) self.n_features = X_train.shape[1] self.n_labels = self.encoder.transform(y_train).shape[1] # åˆå§‹åŒ–å‚æ•° self.W = np.random.normal(loc=0, scale=1.0, size=(self.n_features, self.n_labels)) n_batch = X_train.shape[0] // batch_size # å¯è§†åŒ–ç›¸å…³ plt.ion() plt.figure(&apos;loss&apos;); plt.figure(&apos;accuracy&apos;) loss_train_epoch = []; loss_valid_epoch = [] acc_train_epoch = []; acc_valid_epoch = [] for i_epoch in range(max_epoch): for i_batch in range(n_batch): # æ‰¹å¤„ç†æ¢¯åº¦ä¸‹é™ n1, n2 = i_batch * batch_size, (i_batch + 1) * batch_size X_train_batch, y_train_batch = X_train[n1: n2], y_train[n1: n2] # é¢„æµ‹ y_prob_train = self.predict(X_train_batch, preprocessed=True) # è®¡ç®—æŸå¤± loss_train_batch = self.crossEnt(y_train_batch, y_prob_train) # è®¡ç®—å‡†ç¡®çŽ‡ y_label_train = np.argmax(y_prob_train, axis=1) a = y_train_batch.reshape((-1,)) acc_train_batch = np.mean((y_label_train == y_train_batch.reshape((-1,))).astype(&apos;float&apos;)) # è®¡ç®—æ¢¯åº¦ dW dW = self.grad(X_train_batch, y_train_batch, y_prob_train) # æ›´æ–°å‚æ•° self.W -= self.lr * dW predict step123456789101112def predict(self, X, preprocessed=False): &quot;&quot;&quot; å¯¹è¾“å…¥çš„æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºæ ‡ç­¾ @param &#123;ndarray&#125; X: shape(batch_size, n_features) @return &#123;ndarray&#125; y_prob: probability, shape(batch_size, n_labels) &#123;ndarray&#125; y_label: labels, shape(batch_size,) &quot;&quot;&quot; if not preprocessed: # è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼Œä¸ç”¨åŠ é¦–1åˆ— X = np.c_[np.ones(shape=(X.shape[0],)), X] # æ·»åŠ é¦–1é¡¹ï¼Œè¾“å…¥åˆ°åç½®w0 X = self.scaler.transform(X) y_prob = softmax(X.dot(self.W)) # é¢„æµ‹æ¦‚çŽ‡å€¼ shape(batch_size, n_labels) return y_prob å®žéªŒç»“æžœä»¥ä¸‹è“çº¿ä¸ºè®­ç»ƒé›†å‚æ•°ï¼Œçº¢çº¿ä¸ºéªŒè¯é›†å‚æ•°ï¼Œè‹¥ç¨³å®šè®­ç»ƒ(å¦‚batch_size = 20çš„ç»“æžœ)ï¼Œæœ€ç»ˆå‡†ç¡®çŽ‡åœ¨$80\%$å·¦å³ã€‚ ç”±äºŽéšæœºæ¢¯åº¦ä¸‹é™(SGD)éåŽ†æ¬¡æ•°å¤ªå¤šï¼Œè¿è¡Œè¾ƒæ…¢ï¼Œæ²¡æœ‰ç”¨SGDæ–¹æ³•è®­ç»ƒï¼Œå°±å‰å‡ ä¸ªepochæ¥çœ‹ï¼Œæ•ˆæžœæ²¡æœ‰batch_size = 20çš„å¥½ï¼› æ·»åŠ éšå«å±‚å½¢æˆä¸‰å±‚ç»“æž„çš„å‰é¦ˆç¥žç»ç½‘ç»œï¼Œå¯æé«˜å‡†ç¡®çŽ‡ï¼› è¿˜æœ‰ä¸€ç‚¹ï¼Œä½¿ç”¨æ‰¹å¤„ç†æ¢¯åº¦ä¸‹é™(n_batch = 1)è®­ç»ƒæ—¶ï¼Œå¯ä»¥çœ‹åˆ°æŸå¤±å€¼å·²ç»è¶‹äºŽ$0$ï¼Œä½†å‡†ç¡®çŽ‡å´å¾ˆä½Žï¼Œè¯´æ˜Žå·²ç»é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚ batch size = 20 æŸå¤± å‡†ç¡®çŽ‡ batch_size = 200 æŸå¤± å‡†ç¡®çŽ‡ n_batch = 1 æŸå¤± å‡†ç¡®çŽ‡ æ„Ÿæ‚ŸæŽ¨å…¬å¼è¦æˆ‘è€å‘½ã€‚ã€‚ã€‚ã€‚ Softmaxå›žå½’å¯ä»¥è§†ä½œä¸å«éšå«å±‚çš„å‰é¦ˆç¥žç»ç½‘ç»œã€‚]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLogistic-Regression%2F</url>
    <content type="text"><![CDATA[å¼•è¨€é€»è¾‘å›žå½’ï¼ˆLogistic Regressionï¼‰æ˜¯ç”¨äºŽå¤„ç†å› å˜é‡ä¸ºåˆ†ç±»å˜é‡çš„å›žå½’é—®é¢˜ï¼Œå¸¸è§çš„æ˜¯äºŒåˆ†ç±»æˆ–äºŒé¡¹åˆ†å¸ƒé—®é¢˜ï¼Œä¹Ÿå¯ä»¥å¤„ç†å¤šåˆ†ç±»é—®é¢˜ï¼Œå®ƒå®žé™…ä¸Šæ˜¯å±žäºŽä¸€ç§åˆ†ç±»æ–¹æ³•ã€‚ æ¨¡åž‹å…ˆç»™å‡ºæ¨¡åž‹ï¼ŒæŽ¨å¯¼è¿‡ç¨‹ç¨åŽç»™å‡ºï¼Œé€»è¾‘å›žå½’åŒ…å«Sigmoidå‡½æ•° f(z) = \frac{1}{1+e^{-z}}å…¶å›¾åƒå¦‚ä¸‹ å®šä¹‰ z = w^Txå…¶ä¸­$x=[x_0, x_1, â€¦, x_n]^T, x_0=1$ h_w(x) = g(z) = \frac{1}{1+e^{-z}}æŸå¤±å‡½æ•°ç”±æœ€å¤§ä¼¼ç„¶ä¼°è®¡æŽ¨å¯¼å¯¹äºŽäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œå…¶å–å€¼ä½œä¸ºéšæœºå˜é‡ï¼Œæœä»ŽäºŒé¡¹åˆ†å¸ƒ $B(1, p)$ï¼Œå…¶ä¸­$p$å³ä¸ºé¢„æµ‹è¾“å‡ºæ¦‚çŽ‡$\hat{y}$ P(y_i^{(i)}) = (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}ç”±æžå¤§ä¼¼ç„¶ä¼°è®¡ L = \prod_{i=0}^N P(y_i^{(i)}) = \prod_{i=0}^N (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}å–å¯¹æ•°ä¼¼ç„¶å‡½æ•° logL = \sum_{i=0}^N [y_i^{(i)} log \hat{y}_i^{(i)} + (1-y_i^{(i)}) log (1-\hat{y}_i^{(i)})]ä¼˜åŒ–ç›®æ ‡æ˜¯ w = argmax_w logLä¼˜åŒ–é—®é¢˜ä¸€èˆ¬è¡¨è¿°æˆminimizeé—®é¢˜ï¼Œæ·»åŠ è´Ÿå·ï¼Œæž„æˆNeg Log LikelihoodæŸå¤± w = argmin_w (-logL)ä¸€èˆ¬å–å‡å€¼ L(\hat{y}, y)=- \frac{1}{N} \sum_i [y_i^{(i)} log(\hat{y}_i^{(i)})+(1 - y_i^{(i)})log(1-\hat{y}_i^{(i)})]å…¶ä¸­$y_i$è¡¨ç¤ºçœŸå®žå€¼ï¼Œ$\hat{y}_i$è¡¨ç¤ºé¢„æµ‹å€¼ ä»Žäº¤å‰ç†µç†è§£å·²çŸ¥äº¤å‰ç†µcross entropyå®šä¹‰å¦‚ä¸‹ CrossEnt = \sum_i p_i log \frac{1}{q_i}è€Œå¯¹äºŽæ ·æœ¬$ (X_i, y_i) $ï¼Œä¸ºç¡®å®šäº‹ä»¶ï¼Œæ•…æ ‡ç­¾æ¦‚çŽ‡çš„å–å€¼ä¸º$ p_i = y_i âˆˆ \{0,1\}$ï¼Œ$ q_iå³é¢„æµ‹è¾“å‡ºçš„æ¦‚çŽ‡å€¼\hat{y}_i $ï¼Œå¯å¾—åˆ°ä¸Žä¸Šé¢ç›¸åŒçš„æŽ¨å¯¼ç»“è®º ä»Žå†³ç­–å¹³é¢å’Œè´å¶æ–¯å†³ç­–ç†è§£ç›¸å…³å†…å®¹æŸ¥çœ‹åˆ†ç±»é—®é¢˜çš„å†³ç­–å¹³é¢å’Œè´å¶æ–¯å†³ç­–ï¼Œé€»è¾‘å›žå½’è€ƒè™‘çš„ä¸€èˆ¬æ˜¯ç­‰å…ˆéªŒæ¦‚çŽ‡é—®é¢˜ï¼Œæ•…å†³ç­–å‡½æ•°å®šä¹‰ä¸º $if$ $P(c_i|x)&gt;P(c_j|x)$ $then$ $ x \in c_i $, $ i, j = 1, 2 $ ä»Žè´å¶æ–¯å†³ç­–å¯çŸ¥ï¼Œå¯¹äºŽç±»åˆ«$c_1$ï¼Œæœ‰ P(c_1|x) = \frac{P(x|c_1)}{P(x|c_1) + P(x|c_2)}è®¾åœ¨å„ä¸ªç±»åˆ«ä¸‹ï¼Œç‰¹å¾$x$æœä»Žæ­£æ€åˆ†å¸ƒ P(x|c_i) = \frac{1}{ (2\pi)^{\frac{n}{2}} |\Sigma_i|^{\frac{1}{2}}} exp(-\frac{1}{2} (x-\mu_i)^T \Sigma^{-1} (x-\mu_i))åˆ™ P(c_1|x) = \frac {1} { 1 + exp(-z) } P(c_2|x) = 1 - P(c_1|x) = \frac{exp(-z)}{1+exp(-z)} $P(c_1|x) = \frac{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1) + exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}$ $P(c_1|x) = \frac{1}{1 + \frac{exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}}$ å‡å®šå„åˆ†ç±»çš„æ ·æœ¬æ–¹å·®ç›¸ç­‰ï¼Œ$ \Sigma_1 = \Sigma_2 = \sigma^2 I $ $ P(c_1|x) = \frac {1}{1 + exp(- [ \frac{1}{\sigma^2} (\mu_1-\mu_2)^T x - \frac{1}{2 \sigma^2} (\mu_1^T\mu_1 - \mu_2^T\mu_2) ])}$ ä»¤ w = \frac{1}{\sigma^2} (\mu_1 -\mu_2)b = - \frac{1}{2\sigma^2}(\mu_1^T \mu_1 - \mu_2^T \mu_2)å³å¯å¾—åˆ° P(c_1|x) = \frac {1} { 1 + exp(-z) }å…¶ä¸­ z = w^T x + b æ¢¯åº¦æŽ¨å¯¼å…ˆæŽ¨å¯¼Sigmoidå‡½æ•°çš„å¯¼æ•° f'(z) = (1 - f(z))f(z)å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä»Ž$fâ€™(z)$çš„å›¾åƒå¯ä»¥çœ‹åˆ°ï¼Œåœ¨$ x=0 $å¤„$fâ€™(z)$å–æžå¤§å€¼ï¼Œä¸” f'(z)_{max} = f'(z)|_{z=0} = 0.25 \lim_{z \rightarrow \infty} f'(z) = 0åœ¨å¤šå±‚ç¥žç»ç½‘ç»œåå‘ä¼ æ’­æ›´æ–°å‚æ•°æ—¶ï¼Œç”±äºŽæ¢¯åº¦å¤šæ¬¡ç´¯ä¹˜ï¼ŒSigmoidä½œä¸ºæ¿€æ´»å‡½æ•°ä¼šå­˜åœ¨â€œæ¢¯åº¦æ¶ˆå¤±â€çš„é—®é¢˜ï¼Œä½¿å¾—å‚æ•°æ›´æ–°éžå¸¸ç¼“æ…¢ã€‚ $ fâ€™(z) $$ = (\frac{1}{1+e^{-z}})â€™ $$ = \fracâ€‹ {-(1+e^{-z})â€™}â€‹ {(1+e^{-z})^2} $$ = \fracâ€‹ {e^{-z}}â€‹ {(1+e^{-z})^2} $$ = \fracâ€‹ {e^{-z}}â€‹ {1+e^{-z}}â€‹ \fracâ€‹ {1}â€‹ {1+e^{-z}}$$ = (1 - f(z))f(z)$ åˆ©ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™å¯å¾— $\frac{âˆ‚L}{âˆ‚w_j}$$= -\frac{âˆ‚}{âˆ‚w_j} \frac{1}{N} \sum_i [y^{(i)} log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\frac{âˆ‚}{âˆ‚w_j}\hat{y}^{(i)}-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\frac{âˆ‚}{âˆ‚w_j}\hat{y}^{(i)}]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j]$$= - \frac{1}{N} \sum_i [y^{(i)} (1-\hat{y}^{(i)})w_j-(1-y^{(i)}) y^{(i)} w_j]$$= \frac{1}{N} \sum_i (\hat{y}^{(i)} - y^{(i)})w_j $ å†™ä½œçŸ©é˜µå½¢å¼ï¼Œè®°$X = [x_1, x_2, â€¦, x_m]^T$ï¼Œ$x_i$ä¸ºæ ·æœ¬ç‰¹å¾(åˆ—å‘é‡) âˆ‡_w L = X^T (\hat{Y} - Y)è®­ç»ƒå’Œçº¿æ€§å›žå½’ä¸€æ ·ï¼Œé‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£ w := w - \alpha âˆ‡_w Lå¤„ç†å¤šåˆ†ç±»é—®é¢˜å‡è®¾æœ‰$K$ä¸ªç±»åˆ«ï¼Œåˆ™ä¾æ¬¡ä»¥ç±»åˆ«$c_i$ä¸ºæ­£æ ·æœ¬è®­ç»ƒæ¨¡åž‹ï¼Œä¸€å…±è®­ç»ƒ$K$ä¸ªã€‚æµ‹è¯•æ ·æœ¬åœ¨æ¯ä¸ªæ¨¡åž‹ä¸Šè®¡ç®—ï¼Œæœ€ç»ˆå°†æ¦‚çŽ‡æœ€å¤§çš„ä½œä¸ºåˆ†ç±»ç»“æžœã€‚ è¿™æ ·åˆ’åˆ†æ•°æ®é›†ï¼Œä¼šä½¿è®­ç»ƒé›†æ­£è´Ÿæ ·æœ¬æ•°ç›®ä¸¥é‡ä¸å¯¹ç§°ï¼Œç‰¹åˆ«æ˜¯ç±»åˆ«å¾ˆå¤šçš„æƒ…å†µï¼Œå¯¹ç»“æžœä¼šäº§ç”Ÿå½±å“ã€‚å¯æŽ¨å¹¿è‡³softmaxå›žå½’è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ ç¨‹åºä»£ç @Github: Code for Logistic Regression cost function123456789101112131415def lossFunctionDerivative(self, X, theta, y_true): &apos;&apos;&apos; è®¡ç®—æŸå¤±å‡½æ•°å¯¹å‚æ•°thetaçš„æ¢¯åº¦ å¯¹theta[j]çš„æ¢¯åº¦ä¸ºï¼š(y_pred - y_true)*x[j] &apos;&apos;&apos; err = self.predict_prob(X, theta) - y_true return X.T.dot(err)/y_true.shape[0]def lossFunction(self, y_pred_prob, y_true): &apos;&apos;&apos; æœªä½¿ç”¨ è®¡ç®—æŸå¤±å€¼: Cross-Entropy y_pred_prob, y_true: NumPy array, shape=(n,) &apos;&apos;&apos; tmp = y_true*np.log(y_pred_prob) + (1 - y_true)*np.log(1 - y_pred_prob) return np.mean(-tmp) training step123456789101112131415161718192021def gradDescent(self, min_acc, learning_rate=0.01, max_iter=10000): acc = 0; n_iter = 0 for n_iter in range(max_iter): for n in range(self.n_batch): X_batch = self.X[n*self.batch_size:(n+1)*self.batch_size] t_batch = self.t[n*self.batch_size:(n+1)*self.batch_size] grad = self.lossFunctionDerivative(X_batch, self.theta, t_batch) self.theta -= learning_rate * grad # æ¢¯åº¦ä¸‹é™ acc = self.accuracyRate(self.predict_prob(self.X, self.theta), self.t) if acc &gt; min_acc: print(&apos;ç¬¬%dæ¬¡è¿­ä»£, ç¬¬%dæ‰¹æ•°æ®&apos; % (n_iter, n)) print(&quot;å½“å‰æ€»ä½“æ ·æœ¬å‡†ç¡®çŽ‡ä¸º: &quot;, acc) print(&quot;å½“å‰å‚æ•°å€¼ä¸º: &quot;, self.theta) return self.theta if n_iter%100 == 0: print(&apos;ç¬¬%dæ¬¡è¿­ä»£&apos; % n_iter) print(&apos;å‡†ç¡®çŽ‡ï¼š &apos;, acc) print(&quot;è¶…è¿‡è¿­ä»£æ¬¡æ•°&quot;) print(&quot;å½“å‰æ€»ä½“æ ·æœ¬å‡†ç¡®çŽ‡ä¸º: &quot;, acc) print(&quot;å½“å‰å‚æ•°å€¼ä¸º: &quot;, self.theta) return self.theta å®žéªŒç»“æžœ]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linear Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLinear-Regression%2F</url>
    <content type="text"><![CDATA[å¼•è¨€çº¿æ€§å›žå½’å¯ä»¥è¯´æ˜¯æœºå™¨å­¦ä¹ æœ€åŸºç¡€çš„ç®—æ³• æ¨¡åž‹\hat{y}^{(i)} = w^Tx^{(i)}å…¶ä¸­ x^{(i)}=[x_0^{(i)}, x_1^{(i)}, ..., x_n^{(i)}]^T, x_0^{(i)}=1è¿™é‡Œ$x_0^{(i)}=1$è¡¨ç¤ºåç½®$b$ï¼Œå³$b=w_0$ \hat{y}^{(i)} = w^Tx^{(i)} + b æ³¨ï¼šå¯¹äºŽéžçº¿æ€§çš„æ•°æ®ï¼Œå¯æž„é€ é«˜æ¬¡ç‰¹å¾ã€‚ æŸå¤±å‡½æ•°å®šä¹‰è¯¯å·®e^{(i)} = \hat{y}^{(i)} - y^{(i)}å…¶ä¸­$y^{(i)}$è¡¨ç¤ºçœŸå®žå€¼ å®šä¹‰æŸå¤±å‡½æ•°å•ä¸ªæ ·æœ¬çš„è¯¯å·®å®šä¹‰ä¸º L_{single}(\hat{y}^{(i)}, y^{(i)})=\frac{1}{2}||e^{(i)}||_2^2=\frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2æ‰€æœ‰æ ·æœ¬çš„è¯¯å·®å®šä¹‰ä¸º L(y, t)=\frac{1}{2N}\sum_i (\hat{y}^{(i)}-y^{(i)})^2ä¹Ÿå¯ä»¥å®šä¹‰ä¸ºè¯¯å·®çš„å’Œè€Œä¸æ˜¯å‡å€¼ï¼Œå¯¹ç»“æžœæ— å½±å“ï¼Œå¯è§†ä½œå­¦ä¹ çŽ‡$Î±$é™¤åŽ»ä¸€ä¸ªå¸¸æ•° æ¢¯åº¦æŽ¨å¯¼ $\frac{âˆ‚L}{âˆ‚w_j}$$= \frac{âˆ‚}{âˆ‚w_j}\frac{1}{2N}\sum_i(\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{2N} \sum_i \frac{âˆ‚}{âˆ‚w_j} (\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) \frac{âˆ‚t^{(i)}}{âˆ‚w_j}$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)}$ æˆ–è€…ä½¿ç”¨çŸ©é˜µæŽ¨å¯¼ï¼Œè®°$X = [x_1, x_2, â€¦, x_m]^T$ï¼Œ$x_i$ä¸ºæ ·æœ¬ç‰¹å¾(åˆ—å‘é‡) L = \frac{1}{2}(Xw-Y)^T(Xw-Y) âˆ‡_w L = X^T(\hat{Y}-Y) $âˆ‡_w L$$= \frac{1}{2} âˆ‡_w (w^TX^TXw - Y^TXw - w^TX^TY + Y^TY)$$= \frac{1}{2} (2X^TXw - X^TY - X^TY)$$= X^T(Xw-Y) $ åœ¨æ¢¯åº¦ä¸º$\vec{0}$çš„ç‚¹ï¼Œå³$âˆ‡_w L = \vec{0}$æ—¶å¯¹åº”æœ€ä¼˜è§£ X^T(Xw-Y) = 0 ä»¤X^T(Xw-Y) = 0 æœ‰X^TXw = X^TY w^*=(X^TX+\lambda I)^{-1}X^TY å…¶ä¸­$X^+=(X^TX+\lambda I)^{-1}X^T$ï¼Œè¡¨ç¤ºçŸ©é˜µ$X_{mÃ—n}$çš„ä¼ªé€† è®­ç»ƒé‡‡ç”¨æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£ w := w - \alpha âˆ‡_w Lå…¶ä¸­$w$è¡¨ç¤ºå‚æ•°å‘é‡ è¿›ä¸€æ­¥æ€è€ƒï¼šä¸ºä»€ä¹ˆä½¿ç”¨æ¢¯åº¦ä¸‹é™å¯ä»¥æ±‚å–æœ€ä¼˜è§£å‘¢ï¼Ÿ âˆ‡_w^2 L = âˆ‡_w X^T(Xw-Y) = X^TXè€Œå¯¹äºŽçŸ©é˜µ $ X^TX $ u^T(X^TX)u = (Xu)^T(Xu) \geq 0å³æŸå¤±å‡½æ•°çš„HessiançŸ©é˜µ$âˆ‡_w^2 L$ä¸ºæ­£å®šçŸ©é˜µï¼Œ$L$ä¸ºå‡¸å‡½æ•°ï¼Œå­˜åœ¨å…¨å±€æœ€ä¼˜è§£ ä»ŽæŠ•å½±çš„è§’åº¦ç†è§£çº¿æ€§å›žå½’ çº¿æ€§å›žå½’çš„æ­£åˆ™åŒ–ä¸ºå…‹æœè¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¯åŠ å…¥æ­£åˆ™åŒ–é¡¹$||w||_2^2$ï¼Œæ­¤æ—¶æŸå¤±å‡½æ•°å®šä¹‰ä¸º L(\hat{y}, y)=\frac{1}{2N} ||\hat{y}^{(i)}-y^{(i)}||_2^2 + \lambda ||w||_2^2æˆ–è€… L(\hat{y}, y)=\frac{1}{2N} \sum_i (\hat{y}^{(i)}-y^{(i)})^2 + \frac{\lambda}{2N}\sum_j w_j^2å…¶ä¸­$i = 1, â€¦, N_{sample}; j = 1, â€¦, N_{feature},j&gt;0 $ æ­¤æ—¶æ¢¯åº¦ä¸º \frac{âˆ‚L}{âˆ‚w_j} = \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)} + \frac{\lambda}{N}w_jå…¶ä¸­$j = 1, â€¦, N_{feature},j&gt;0 $ å±€éƒ¨åŠ æƒçº¿æ€§å›žå½’ç›®æ ‡å‡½æ•°å®šä¹‰ä¸º L(y, t)=\frac{1}{2N}\sum_i w^{(i)} (\hat{y}^{(i)}-y^{(i)})^2å…¶ä¸­ w^{(i)} = e^{-\frac{(x^{(i)}-x)^2}{2\tau^2}}$x$è¡¨ç¤ºè¾“å…¥çš„é¢„æµ‹æ ·æœ¬ï¼Œ$x^{(i)}$è¡¨ç¤ºè®­ç»ƒæ ·æœ¬ ç¦»å¾ˆè¿‘çš„æ ·æœ¬ï¼Œæƒå€¼æŽ¥è¿‘äºŽ1ï¼Œè€Œå¯¹äºŽç¦»å¾ˆè¿œçš„æ ·æœ¬ï¼Œæ­¤æ—¶æƒå€¼æŽ¥è¿‘äºŽ0ï¼Œè¿™æ ·å°±æ˜¯åœ¨å±€éƒ¨æž„æˆçº¿æ€§å›žå½’ï¼Œå®ƒä¾èµ–çš„ä¹Ÿåªæ˜¯å‘¨è¾¹çš„ç‚¹ã€‚ å¯¹äºŽçº¿æ€§å›žå½’ç®—æ³•ï¼Œä¸€æ—¦æ‹Ÿåˆå‡ºé€‚åˆè®­ç»ƒæ•°æ®çš„å‚æ•°$w$ï¼Œä¿å­˜è¿™äº›å‚æ•°$w$ï¼Œå¯¹äºŽä¹‹åŽçš„é¢„æµ‹ï¼Œä¸éœ€è¦å†ä½¿ç”¨åŽŸå§‹è®­ç»ƒæ•°æ®é›†ï¼Œæ‰€ä»¥æ˜¯å‚æ•°å­¦ä¹ ç®—æ³•ã€‚è€Œå¯¹äºŽå±€éƒ¨åŠ æƒçº¿æ€§å›žå½’ç®—æ³•ï¼Œæ¯æ¬¡è¿›è¡Œé¢„æµ‹éƒ½éœ€è¦å…¨éƒ¨çš„è®­ç»ƒæ•°æ®ï¼ˆæ¯æ¬¡è¿›è¡Œçš„é¢„æµ‹å¾—åˆ°ä¸åŒçš„å‚æ•°$w$ï¼‰ï¼Œæ²¡æœ‰å›ºå®šçš„å‚æ•°$w$ï¼Œæ‰€ä»¥æ˜¯éžå‚æ•°ç®—æ³•ã€‚ ä»£ç @Github: Code for Linear Regression training step12345678910111213141516171819202122232425262728293031323334353637383940414243def fit(self, X, y, learning_rate=0.01, max_iter=5000, min_loss=10): # --------------- æ•°æ®é¢„å¤„ç†éƒ¨åˆ† --------------- # åŠ å…¥å…¨1åˆ— X = np.c_[np.ones(shape=(X.shape[0])), X] # æž„é€ é«˜æ¬¡ç‰¹å¾ if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] # ---------------- å‚æ•°è¿­ä»£éƒ¨åˆ† ---------------- # åˆå§‹åŒ–å‚æ•° self.theta = np.random.uniform(-1, 1, size=(X.shape[1],)) # æ•°æ®æ‰¹æ¬¡ n_batch = X.shape[0] if self.n_batch==-1 else self.n_batch batch_size = X.shape[0] // n_batch # åœæ­¢æ¡ä»¶ n_iter = 0; loss = float(&apos;inf&apos;) # å¼€å§‹è¿­ä»£ for n_iter in range(max_iter): for n in range(n_batch): n1, n2 = n*batch_size, (n+1)*batch_size X_batch = X[n1: n2]; y_batch = y[n1: n2] grad = self.lossFunctionDerivative(X_batch, y_batch) self.theta -= learning_rate * grad loss = self.score(y_batch, self.predict(X_batch)) if loss &lt; min_loss: print(&apos;ç¬¬%dæ¬¡è¿­ä»£, ç¬¬%dæ‰¹æ•°æ®&apos; % (n_iter, n)) print(&quot;å½“å‰æ€»ä½“æ ·æœ¬æŸå¤±ä¸º: &quot;, loss) return self.theta if n_iter%100 == 0: print(&apos;ç¬¬%dæ¬¡è¿­ä»£&apos; % n_iter) print(&quot;å½“å‰æ€»ä½“æ ·æœ¬æŸå¤±ä¸º: &quot;, loss) print(&quot;è¶…è¿‡è¿­ä»£æ¬¡æ•°&quot;) print(&quot;å½“å‰æ€»ä½“æ ·æœ¬æŸå¤±ä¸º: &quot;, loss) return self.thetadef lossFunctionDerivative(self, X, y): y_pred = self.predict(X) # theta = self.theta; # ï¼æ³¨æ„ï¼štheta = self.theta ä¸ä»…ä»…æ˜¯èµ‹å€¼ï¼Œç±»ä¼¼å¼•ç”¨ï¼Œä¿®æ”¹thetaä¼šå½±å“self.theta theta = self.theta.copy() theta[0] = 0 # Î¸0ä¸éœ€è¦æ­£åˆ™åŒ– return (X.T.dot(y_pred - y) + self.regularize * theta) / X.shape[0] predict step123456789def predict(self, X, preprocessed=False): if preprocessed: # åŠ å…¥å…¨1åˆ— X = np.c_[np.ones(shape=(X.shape[0])), X] # æž„é€ é«˜æ¬¡ç‰¹å¾ if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] return X.dot(self.theta) è¿è¡Œç»“æžœ æ— æ­£åˆ™åŒ– æ­£åˆ™åŒ–]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
</search>
