<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Ubuntu编译安装Tensorflow]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Tensorflow%2F</url>
    <content type="text"><![CDATA[非常重要如果中途出现错误，xxxx文件找不到，不要怀疑！就是大天朝的网络问题！推荐科学上网！ 安装CUDA与CUDNN首先查看显卡是否支持CUDA加速，输入1$ nvidia-smi 在Ubuntu16.04 LTS下，推荐安装CUDA9.0和CUDNN 7。 CUDA CUDA Toolkit 9.0 Downloads | NVIDIA Developer https://developer.nvidia.com/cuda-90-download-archive 下载.run版本，安装方法如下 12$ sudo chmod +x cuda_9.0.176_384.81_linux.run $ sudo sh ./cuda_9.0.176_384.81_linux.run 服务条款很长。。。。 CUDNN NVIDIA cuDNN | NVIDIA Developer https://developer.nvidia.com/cudnn 1234$ tar -xzvf cudnn-9.0-linux-x64-v7.4.1.5.tgz$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 安装后进行验证 1234$ cp -r /usr/src/cudnn_samples_v7/ $HOME$ cd $HOME/cudnn_samples_v7/mnistCUDNN$ make clean &amp;&amp; make$ ./mnistCUDNN 编译Tensorflow(CPU version)由于训练代码使用Python实现，故C++版本的Tensorflow不使用GPU，仅实现预测代码即可。 bazel Installing Bazel on Ubuntu - Bazel https://docs.bazel.build/versions/master/install-ubuntu.html一定要用源码安装！！！ download the Bazel binary installer named bazel-&lt;version&gt;-installer-linux-x86_64.sh from the Bazel releases page on GitHub. 123456$ sudo apt-get install pkg-config zip g++ zlib1g-dev unzip python$ chmod +x bazel-&lt;version&gt;-installer-linux-x86_64.sh$ ./bazel-&lt;version&gt;-installer-linux-x86_64.sh --user$ sudo nano ~/.bashrc # export PATH=&quot;$PATH:$HOME/bin&quot;$ source ~/.bashrc $ bazel version 编译CPU版本的CPU查看java版本1234$ java -versionopenjdk version &quot;1.8.0_191&quot;OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12)OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) 安装依赖软件包环境1234$ sudo apt install python3-dev$ pip3 install six$ pip3 install numpy$ pip3 instal wheel 下载Tensorflow源码1$ git clone https://github.com/tensorflow/tensorflow 编译与安装12$ cd tensorflow$ ./configure 配置选项如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command &quot;bazel shutdown&quot;.INFO: Invocation ID: ce26fc12-2926-4ca7-8775-febc553c8ab5You have bazel 0.20.0 installed.Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3Found possible Python library paths: /usr/local/lib/python3.5/dist-packages /usr/lib/python3/dist-packagesPlease input the desired Python library path to use. Default is [/usr/local/lib/python3.5/dist-packages]Do you wish to build TensorFlow with XLA JIT support? [Y/n]: nNo XLA JIT support will be enabled for TensorFlow.Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: nNo OpenCL SYCL support will be enabled for TensorFlow.Do you wish to build TensorFlow with ROCm support? [y/N]: nNo ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y/N]: nNo CUDA support will be enabled for TensorFlow.Do you wish to download a fresh release of clang? (Experimental) [y/N]: nClang will not be downloaded.Do you wish to build TensorFlow with MPI support? [y/N]: nNo MPI support will be enabled for TensorFlow.Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native -Wno-sign-compare]: Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: nNot configuring the WORKSPACE for Android builds.Preconfigured Bazel build configs. You can use any of the below by adding &quot;--config=&lt;&gt;&quot; to your build command. See .bazelrc for more details. --config=mkl # Build with MKL support. --config=monolithic # Config for mostly static monolithic build. --config=gdr # Build with GDR support. --config=verbs # Build with libverbs support. --config=ngraph # Build with Intel nGraph support. --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects.Preconfigured Bazel build configs to DISABLE default on features: --config=noaws # Disable AWS S3 filesystem support. --config=nogcp # Disable GCP support. --config=nohdfs # Disable HDFS support. --config=noignite # Disable Apacha Ignite support. --config=nokafka # Disable Apache Kafka support. --config=nonccl # Disable NVIDIA NCCL support.Configuration finished 使用bazel编译1$ bazel build --config=opt //tensorflow:libtensorflow_cc.so 出现错误 TF failing to build on Bazel CI · Issue #19464 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/19464Failure to build TF 1.12 from source - multiple definitions in grpc · Issue #23402 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/issues/23402#issuecomment-436932197Explicitly import tools/bazel.rc by meteorcloudy · Pull Request #23583 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583Explicitly import tools/bazel.rc by meteorcloudy · Pull Request #23583 · tensorflow/tensorflow https://github.com/tensorflow/tensorflow/pull/23583/commits/03e63a291bc95dacaa821585f39a360b43465cb5 解决方法 方法1 方法2 将tools/bazel.rc中内容粘到.tf_configure.bazelrc中，每次重新配置后需要重新粘贴一次。 源码安装protobuf3.6.0 https://github.com/protocolbuffers/protobuf 1234./autogen.sh./configuremakemake install 下载其他文件 12$ ./tensorflow/contrib/makefile/download_dependencies.shmkdir /tmp/eigen 值得注意，download_dependencies.sh中下载依赖包时，需要用到curl，但是默认方式安装 1$ sudo apt install curl &gt; 现在是2018/12/19/02:48，被这个问题折腾了3个小时。 时不支持`https`协议，故需要安装`OpenSSL`，并源码安装，详细资料见[curl提示不支持https协议解决方法 - 标配的小号 - 博客园](https://www.cnblogs.com/biaopei/p/8669810.html) - 执行`./autogen.sh`时，发生错误`autoreconf: not found`，则安装 12$ sudo apt install autoconf aotomake libtool$ sudo apt install libffi-dev 源码安装Eigen 12345cd tensorflow/contrib/makefile/Downloads/eigenmkdir buildcd buildcmakemake install 调用C++版本的Tensorflow创建文件目录如下1234|-- tf_test |-- build |-- main.cpp |-- CMakeLists.txt main.cpp文件内容如下1234567891011121314151617181920212223#include &quot;tensorflow/cc/client/client_session.h&quot;#include &quot;tensorflow/cc/ops/standard_ops.h&quot;#include &quot;tensorflow/core/framework/tensor.h&quot;int main() &#123; using namespace tensorflow; using namespace tensorflow::ops; Scope root = Scope::NewRootScope(); // Matrix A = [3 2; -1 0] auto A = Const(root, &#123; &#123;3.f, 2.f&#125;, &#123;-1.f, 0.f&#125;&#125;); // Vector b = [3 5] auto b = Const(root, &#123; &#123;3.f, 5.f&#125;&#125;); // v = Ab^T auto v = MatMul(root.WithOpName(&quot;v&quot;), A, b, MatMul::TransposeB(true)); std::vector&lt;Tensor&gt; outputs; ClientSession session(root); // Run and fetch v TF_CHECK_OK(session.Run(&#123;v&#125;, &amp;outputs)); // Expect outputs[0] == [19; -3] LOG(INFO) &lt;&lt; outputs[0].matrix&lt;float&gt;(); return 0;&#125; CMakeLists.txt内容如下12345678910111213141516171819202122232425262728293031cmake_minimum_required (VERSION 2.8.8)project (tf_example)set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -g -std=c++11 -W&quot;)set(EIGEN_DIR /usr/local/include/eigen3)set(PROTOBUF_DIR /usr/local/include/google/protobuf)set(TENSORFLOW_DIR /home/louishsu/install/tensorflow-1.12.0)include_directories( $&#123;EIGEN_DIR&#125; $&#123;PROTOBUF_DIR&#125; $&#123;TENSORFLOW_DIR&#125; $&#123;TENSORFLOW_DIR&#125;/bazel-genfiles $&#123;TENSORFLOW_DIR&#125;/tensorflow/contrib/makefile/downloads/absl)link_directories( /usr/local/lib)add_executable( tf_test main.cpp)target_link_libraries( tf_test tensorflow_cc tensorflow_framework) 123$ mkdir build &amp;&amp; cd build$ cmake .. &amp;&amp; make$ ./tf_test install tensorflow-gpu for python可使用pip指令安装，推荐下载安装包， tensorflow · PyPI https://pypi.org/project/tensorflow/ 12$ cd ~/Downloads$ pip3 --default-timeout=1000 install tensorflow_gpu-1.12.0-cp35-cp35m-manylinux1_x86_64.whl --user 安装后进行验证123456789101112131415161718192021222324252627$ python3Python 3.5.2 (default, Nov 12 2018, 13:43:14) [GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.Session()2018-12-12 11:58:17.817417: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2018-12-12 11:58:17.953931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2018-12-12 11:58:17.954686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: GeForce GT 730M major: 3 minor: 5 memoryClockRate(GHz): 0.758pciBusID: 0000:04:00.0totalMemory: 983.44MiB freeMemory: 177.19MiB2018-12-12 11:58:17.954728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 02018-12-12 11:58:18.276013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:2018-12-12 11:58:18.276057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2018-12-12 11:58:18.276069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2018-12-12 11:58:18.276223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory) -&gt; physical GPU (device: 0, name: GeForce GT 730M, pci bus id: 0000:04:00.0, compute capability: 3.5)&gt;&gt;&gt; a = tf.Variable([233])&gt;&gt;&gt; init = tf.initialize_all_variables()WARNING:tensorflow:From /home/louishsu/.local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.Instructions for updating:Use `tf.global_variables_initializer` instead.&gt;&gt;&gt; sess.run(init)&gt;&gt;&gt; sess.run(a)array([233], dtype=int32)&gt;&gt;&gt; sess.close() 注意，如果异常中断程序，显存不会被释放，需要自行kill1$ nvidia-smi 获得PID序号，使用指令结束进程1$ kill -9 pid Reference TensorFlow C++动态库编译 - 简书 https://www.jianshu.com/p/d46596558640Tensorflow C++ 从训练到部署(1)：环境搭建 | 技术刘 http://www.liuxiao.org/2018/08/ubuntu-tensorflow-c-%E4%BB%8E%E8%AE%AD%E7%BB%83%E5%88%B0%E9%A2%84%E6%B5%8B1%EF%BC%9A%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/]]></content>
      <categories>
        <category>Linux</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu编译安装OpenCV]]></title>
    <url>%2F2019%2F01%2F04%2FUbuntu%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85OpenCV%2F</url>
    <content type="text"><![CDATA[下载源码 OpenCV library https://opencv.org/ 编译安装依赖软件包12$ sudo apt install cmake$ sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff4.dev libswscale-dev libjasper-dev 编译12345$ unzip opencv-3.4.4.zip$ cd opencv-3.4.4$ mkdir build &amp;&amp; cd build$ cmake ..$ make -j4 安装123$ sudo make install$ sudo nano /etc/ld.so.conf.d/opencv.conf # add `/usr/local/lib`$ sudo ldconfig 验证OpenCV自带验证程序，在opencv-3.4.4/samples/cpp/example_cmake中可以找到 1234$ cd opencv-3.4.4/samples/cpp/example_cmake$ cmake .$ make$ ./opencv_example 如果没问题，可以看到你的大脸了~ Reference Ubuntu16.04安装openCV3.4.4 - 辣屁小心的学习笔记 - CSDN博客 https://blog.csdn.net/weixin_39992397/article/details/84345197]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python读写配置文件]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AF%BB%E5%86%99%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在深度学习中，有许多运行参数需要指定，有几种方法可以解决 定义.py文件存储变量 定义命名元组collections.namedtuple() 创建.config，.ini等配置文件 Python 读取写入配置文件很方便，使用内置模块configparser即可 读出首先创建文件test.config或test.ini，写入如下内容123456789[db]db_port = 3306db_user = rootdb_host = 127.0.0.1db_pass = test[concurrent]processor = 20thread = 10 读取操作如下1234567891011121314151617181920212223242526272829&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; configfile = &quot;./test.config&quot;&gt;&gt;&gt; inifile = &quot;./test.ini&quot;&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.read(configfile) # 读取文件内容&gt;&gt;&gt; &gt;&gt;&gt; sections = cf.sections() # 所有的section，以列表的形式返回&gt;&gt;&gt; sections[&apos;db&apos;, &apos;concurrent&apos;]&gt;&gt;&gt; &gt;&gt;&gt; options = cf.options(&apos;db&apos;) # 该section的所有option&gt;&gt;&gt; options[&apos;db_port&apos;, &apos;db_user&apos;, &apos;db_host&apos;, &apos;db_pass&apos;]&gt;&gt;&gt; &gt;&gt;&gt; items = cf.items(&apos;db&apos;) # 该section的所有键值对&gt;&gt;&gt; items[(&apos;db_port&apos;, &apos;3306&apos;), (&apos;db_user&apos;, &apos;root&apos;), (&apos;db_host&apos;, &apos;127.0.0.1&apos;), (&apos;db_pass&apos;, &apos;test&apos;)]&gt;&gt;&gt; &gt;&gt;&gt; db_user = cf.get(&apos;db&apos;, &apos;db_user&apos;) # section中option的值，返回为string类型&gt;&gt;&gt; db_user&apos;root&apos;&gt;&gt;&gt; &gt;&gt;&gt; db_port = cf.getint(&apos;db&apos;, &apos;db_port&apos;) # 得到section中option的值，返回为int类型&gt;&gt;&gt; # 类似的还有getboolean()与getfloat()&gt;&gt;&gt; db_port3306 写入12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; import os&gt;&gt;&gt; import configparser&gt;&gt;&gt; &gt;&gt;&gt; cf = configparser.ConfigParser()&gt;&gt;&gt; cf.add_section(&apos;test1&apos;) # 新增section&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test&quot;, &quot;count&quot;, 1) # 新增option：错误示范Traceback (most recent call last): File &quot;&lt;pyshell#7&gt;&quot;, line 1, in &lt;module&gt; cf.set(&quot;test&quot;, &quot;count&quot;, 1) File &quot;C:\MyApplications\Python3\lib\configparser.py&quot;, line 1192, in set self._validate_value_types(option=option, value=value) File &quot;C:\MyApplications\Python3\lib\configparser.py&quot;, line 1177, in _validate_value_types raise TypeError(&quot;option values must be strings&quot;)TypeError: option values must be strings&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test&quot;, &quot;count&quot;, &apos;1&apos;) # 新增option&gt;&gt;&gt; &gt;&gt;&gt; cf.set(&quot;test1&quot;, &quot;opt1&quot;, &apos;ok&apos;) # 新增option&gt;&gt;&gt; cf.remove_option(&quot;test1&quot;, &quot;opt1&quot;) # 删除optionTrue&gt;&gt;&gt; &gt;&gt;&gt; cf.add_section(&apos;test2&apos;) # 新增section&gt;&gt;&gt; cf.remove_section(&apos;test2&apos;) # 删除sectionTrue&gt;&gt;&gt; &gt;&gt;&gt; with open(&quot;./test_wr.config&quot;, &apos;w+&apos;) as f: cf.write(f) # 写入文件test_wr.config &gt;&gt;&gt; 现在目录已创建文件test_wr.config，打开可以看到12[test1]count = 1]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python更新安装的包]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E6%9B%B4%E6%96%B0%E5%AE%89%E8%A3%85%E7%9A%84%E5%8C%85%2F</url>
    <content type="text"><![CDATA[pip不提供升级全部已安装模块的方法，以下指令可查看更新信息1$ pip list --outdate 得到输出信息如下123456789101112131415161718192021222324Package Version Latest Type----------------- --------- ---------- -----absl-py 0.3.0 0.6.1 sdistautopep8 1.3.5 1.4.2 sdistbleach 2.1.4 3.0.2 wheelcertifi 2018.8.24 2018.10.15 wheeldask 0.20.0 0.20.1 wheelgrpcio 1.14.1 1.16.0 wheelipykernel 5.0.0 5.1.0 wheelipython 7.0.1 7.1.1 wheeljedi 0.12.1 0.13.1 wheeljupyter-console 5.2.0 6.0.0 wheelMarkdown 2.6.11 3.0.1 wheelMarkupSafe 1.0 1.1.0 wheelmatplotlib 2.2.2 3.0.2 wheelmistune 0.8.3 0.8.4 wheelnumpy 1.14.5 1.15.4 wheelopencv-python 3.4.2.17 3.4.3.18 wheelPillow 5.2.0 5.3.0 wheelprometheus-client 0.3.1 0.4.2 sdistpyparsing 2.2.0 2.3.0 wheelpython-dateutil 2.7.3 2.7.5 wheelpytz 2018.5 2018.7 wheelurllib3 1.23 1.24.1 wheel 以下提供一键升级的方法，可能比较久hhhh12345678from pip._internal.utils.misc import get_installed_distributionsfrom subprocess import call for dist in get_installed_distributions(): modulename = dist.project_name print(&apos;start processing module &apos; + modulename) call(&quot;pip install --upgrade &quot; + modulename, shell=True) print(&apos;module &apos; + modulename + &apos;done!&apos;)]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python记录日志]]></title>
    <url>%2F2019%2F01%2F04%2FPython%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[前言日志可以用来记录应用程序的状态、错误和信息消息，也经常作为调试程序的工具。Python提供了一个标准的日志接口，就是logging模块。日志级别有DEBUG、INFO、WARNING、ERROR、CRITICAL五种。 logging — Logging facility for Python — Python 3.7.1 documentation 使用方法logger对象1234&gt;&gt;&gt; import logging&gt;&gt;&gt; logger = logging.getLogger(__name__)&gt;&gt;&gt; logger&lt;Logger __main__ (WARNING)&gt; 日志级别可输出五种不同的日志级别，分别为有DEBUG、INFO、WARNING、ERROR、CRITICAL12345678&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&gt;&gt;&gt; logger.info(&apos;test log&apos;)&gt;&gt;&gt; logger.warning(&apos;test log&apos;)test log&gt;&gt;&gt; logger.error(&apos;test log&apos;)test log&gt;&gt;&gt; logger.critical(&apos;test log&apos;)test log 可以看到只有WARNING及以上级别日志被输出，这是由于默认的日志级别是WARNING ，所以低于此级别的日志不会记录。 基础配置1logging.basicConfig(**kwarg) **kwarg中部分参数如下 format 12345678910%(levelname)：日志级别的名字格式%(levelno)s：日志级别的数字表示%(name)s：日志名字%(funcName)s：函数名字%(asctime)：日志时间，可以使用datefmt去定义时间格式，如上图。%(pathname)：脚本的绝对路径%(filename)：脚本的名字%(module)：模块的名字%(thread)：thread id%(threadName)：线程的名字 datefmt 1&apos;%Y-%m-%d %H:%M:%S&apos; level 默认为ERROR 12345logging.DEBUGlogging.INFOlogging.WARNINGlogging.ERRORlogging.CRITICAL 例如12345678910111213141516&gt;&gt;&gt; # 未输出debug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&gt;&gt;&gt; &gt;&gt;&gt; # 修改配置&gt;&gt;&gt; log_format = &apos;%(filename)s [%(asctime)s] [%(levelname)s] %(message)s&apos;&gt;&gt;&gt; log_datefmt = &apos;%Y-%m-%d %H:%M:%S&apos;&gt;&gt;&gt; log_level = logging.DEBUG&gt;&gt;&gt; logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level)&gt;&gt;&gt; &gt;&gt;&gt; # 输出debug&gt;&gt;&gt; logger = logging.getLogger()&gt;&gt;&gt; logger.debug(&apos;test log&apos;)&lt;pyshell#8&gt; [2018-11-13 11:59:52] [DEBUG] test log 输出到日志文件保存代码为文件log_test.py1234567891011121314151617181920import logginglog_format = &apos;%(filename)s [%(asctime)s] [%(levelname)s] %(message)s&apos;log_datefmt = &apos;%Y-%m-%d %H:%M:%S&apos;log_level = logging.DEBUGlog_filename = &apos;./test.log&apos;log_filemode = &apos;a&apos; # 也可以为&apos;w&apos;, &apos;w+&apos;等logging.basicConfig(format=log_format, datefmt=log_datefmt, level=log_level, filename=log_filename, filemode=log_filemode)logger = logging.getLogger(__name__)logger.debug(&apos;test log&apos;)logger.info(&apos;test log&apos;)logger.warning(&apos;test log&apos;)logger.error(&apos;test log&apos;)logger.critical(&apos;test log&apos;) 运行完毕，打开log_test.log文件可以看到12345log_test.py [2018-11-13 12:11:04] [DEBUG] test loglog_test.py [2018-11-13 12:11:04] [INFO] test loglog_test.py [2018-11-13 12:11:04] [WARNING] test loglog_test.py [2018-11-13 12:11:04] [ERROR] test loglog_test.py [2018-11-13 12:11:04] [CRITICAL] test log]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github博客搭建]]></title>
    <url>%2F2019%2F01%2F04%2FGithub-Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前言那么问题来了，现有的博客还是现有的这篇文章呢？ 软件安装安装node.js, git, hexo 博客搭建初始化推荐使用git命令窗口，执行如下指令12345678910111213141516171819202122232425262728293031$ mkdir Blog$ cd Blog$ hexo initINFO Cloning hexo-starter to ~\Desktop\BlogCloning into &apos;C:\Users\LouisHsu\Desktop\Blog&apos;...remote: Enumerating objects: 68, done.remote: Total 68 (delta 0), reused 0 (delta 0), pack-reused 68Unpacking objects: 100% (68/68), done.Submodule &apos;themes/landscape&apos; (https://github.com/hexojs/hexo-theme-landscape.git) registered for path &apos;themes/landscape&apos;Cloning into &apos;C:/Users/LouisHsu/Desktop/Blog/themes/landscape&apos;...remote: Enumerating objects: 1, done.remote: Counting objects: 100% (1/1), done.remote: Total 867 (delta 0), reused 0 (delta 0), pack-reused 866Receiving objects: 100% (867/867), 2.55 MiB | 494.00 KiB/s, done.Resolving deltas: 100% (459/459), done.Submodule path &apos;themes/landscape&apos;: checked out &apos;73a23c51f8487cfcd7c6deec96ccc7543960d350&apos;[32mINFO [39m Install dependenciesnpm WARN deprecated titlecase@1.1.2: no longer maintainednpm WARN deprecated postinstall-build@5.0.3: postinstall-build&apos;s behavior is now built into npm! You should migrate off of postinstall-build and use the new `prepare` lifecycle script with npm 5.0.0 or greater.&gt; nunjucks@3.1.6 postinstall C:\Users\LouisHsu\Desktop\Blog\node_modules\nunjucks&gt; node postinstall-build.js srcnpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)added 422 packages from 501 contributors and audited 4700 packages in 59.195sfound 0 vulnerabilitiesINFO Start blogging with Hexo! 生成目录结构如下123456\-- scaffolds\-- source \-- _posts\-- themes|-- _config.yml|-- package.json 继续123456$ npm installnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.4 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.4: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)audited 4700 packages in 5.99sfound 0 vulnerabilities 现在该目录执行指令，开启hexo服务器123$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 关联Github在Github新建一个仓库，命名为username.github.io，例如isLouisHsu.github.io，新建时勾选Initialize this repository with a README，因为这个仓库必须不能为空。 打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下1234deploy: type: git repository: git@github.com:isLouisHsu/isLouisHsu.github.io.git branch: master 安装插件1$ npm install hexo-deployer-git --save 现在就可以将该目录内容推送到Github新建的仓库中了1$ hexo d 使用个人域名 在source目录下新建文件CNAME，输入解析后的个人域名 在Github主页修改域名 备份博客 没。没什么用我。我不备份了可以新建一个仓库专门保存文件试试 现在博客的源文件仅保存在PC上， 我们对它们进行备份，并将仓库作为博客文件夹 在仓库新建分支hexo，设置为默认分支 将仓库克隆至本地 1$ git clone https://github.com/isLouisHsu/isLouisHsu.github.io.git 克隆文件 将之前的Hexo文件夹中的 123456scffolds/source/themes/.gitignore_config.ymlpackage.json 复制到克隆下来的仓库文件夹isLouisHsu.github.io 安装包 123$ npm install$ npm install hexo --save$ npm install hexo-deployer-git --save 备份博客使用以下指令 123$ git add .$ git commit -m &quot;backup&quot;$ git push origin hexo 部署博客指令 1$ hexo g -d 单键提交 编写脚本commit.bat，双击即可 1234git add .git commit -m &apos;backup&apos;git push origin hexohexo g -d 使用方法 目录结构 public 生成的网站文件，发布的站点文件。 source 资源文件夹，用于存放内容。 tag 标签文件夹。 archive 归档文件夹。 category分类文件夹。 downloads/code include code文件夹。 :lang i18n_dir 国际化文件夹。 _config.yml 配置文件 指令 123456789101112131415161718192021222324252627$ hexo helpUsage: hexo &lt;command&gt;Commands: clean Remove generated files and cache. config Get or set configurations. deploy Deploy your website. generate Generate static files. help Get help on a command. init Create a new Hexo folder. list List the information of the site migrate Migrate your site from other system to Hexo. new Create a new post. publish Moves a draft post from _drafts to _posts folder. render Render files with renderer plugins. server Start the server. version Display version information.Global Options: --config Specify config file instead of using _config.yml --cwd Specify the CWD --debug Display all verbose messages in the terminal --draft Display draft posts --safe Disable all plugins and scripts --silent Hide output on consoleFor more help, you can use &apos;hexo help [command]&apos; for the detailed information or you can check the docs: http://hexo.io/docs/ 拓展功能支持插入图片1$ npm install hexo-asset-image --save 修改文件_config.yml1post_asset_folder: true 在执行$ hexo n [layout] &lt;title&gt;时会生成同名文件夹，把图片放在这个文件夹内，在.md文件中插入图片1![image_name](/title/image_name.png) 搜索功能12$ npm install hexo-generator-searchdb --save$ npm install hexo-generator-search --save 站点配置文件_config.yml中添加12345search: path: search.xml field: post format: html limit: 10000 修改主题配置文件/themes/xxx/_config.yml12local_search: enable: true 带过滤功能的首页插件在首页只显示指定分类下面的文章列表。12$ npm install hexo-generator-index2 --save$ npm uninstall hexo-generator-index --save 修改_config.yml1234567index_generator: per_page: 10 order_by: -date include: - category Web # 只包含Web分类下的文章 exclude: - tag Hexo # 不包含标签为Hexo的文章 数学公式支持hexo默认的渲染引擎是marked，但是marked不支持mathjax。kramed是在marked的基础上进行修改。1234$ npm uninstall hexo-math --save # 停止使用 hexo-math$ npm install hexo-renderer-mathjax --save # 安装hexo-renderer-mathjax包：$ npm uninstall hexo-renderer-marked --save # 卸载原来的渲染引擎$ npm install hexo-renderer-kramed --save # 安装新的渲染引擎 修改/node_modules/kramed/lib/rules/inline.js12345678911| escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,...20| em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,-&gt;11| escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,...20| em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 修改/node_modules/hexo-renderer-kramed/lib/renderer.js123456789101112131464| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed&apos;s rule: $$ + \1 + $$67| return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);68| &#125;-&gt;64| // Change inline math rule65| function formatText(text) &#123;66| // Fit kramed&apos;s rule: $$ + \1 + $$67| // return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);68| return text;69| &#125; 在主题中开启mathjax开关，例如next主题中1234# MathJax Supportmathjax: enable: true per_page: true 在文章中12345678---title: title.mddate: 2019-01-04 12:47:37categories:tags:mathjax: truetop:--- 测试 A = \left[\begin{matrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{matrix}\right]Reference 基于hexo+github搭建一个独立博客 - 牧云云 - 博客园 https://www.cnblogs.com/MuYunyun/p/5927491.htmlhexo+github pages轻松搭博客(1) | ex2tron’s Blog http://ex2tron.wang/hexo-blog-with-github-pages-1/hexo下LaTeX无法显示的解决方案 - crazy_scott的博客 - CSDN博客 https://blog.csdn.net/crazy_scott/article/details/79293576在Hexo中渲染MathJax数学公式 - 简书 https://www.jianshu.com/p/7ab21c7f0674怎么去备份你的Hexo博客 - 简书 https://www.jianshu.com/p/baab04284923Hexo中添加本地图片 - 蜕变C - 博客园 https://www.cnblogs.com/codehome/p/8428738.html?utm_source=debugrun&amp;utm_medium=referralhexo 搜索功能 - 阿甘的博客 - CSDN博客 https://blog.csdn.net/ganzhilin520/article/details/79047983]]></content>
      <categories>
        <category>Others</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二次入坑raspberry-pi]]></title>
    <url>%2F2018%2F10%2F29%2F%E4%BA%8C%E6%AC%A1%E5%85%A5%E5%9D%91raspberry-pi%2F</url>
    <content type="text"><![CDATA[前言距上一次搭建树莓派平台已经两年了，保存的镜像出了问题，重新搭建一下。 系统下载从官网下载树莓派系统镜像，有以下几种可选 Raspberry Pi — Teach, Learn, and Make with Raspberry Pi Raspbian &amp; Raspbian Lite，基于Debian Noobs &amp; Noobs Lite Ubuntu MATE Snappy Ubuntu Core Windows 10 IOT 其余不太了解，之前安装的是Raspbian，对于Debian各种不适，换上界面优雅的Ubuntu Mate玩一下老老实实玩Raspbian，笑脸:-) 安装比较简单，准备micro-SD卡，用Win32 Disk Imager烧写镜像 Win32 Disk Imager download | SourceForge.net 安装完软件后可点击Read备份自己的镜像。 注意第二次开机前需要配置config.txt文件，否则hdmi无法显示 树莓派配置文档 config.txt 说明 | 树莓派实验室 123456disable_overscan=1 hdmi_force_hotplug=1hdmi_group=2 # DMThdmi_mode=32 # 1280x960hdmi_drive=2config_hdmi_boost=4 修改交换分区Ubuntu Mate查看交换分区1$ free -m 未设置时如下1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 0 0 0 创建和挂载12345678910111213141516# 获取权限$ sudo -i# 创建目录$ mkdir /swap$ cd /swap# 指定一个大小为1G的名为“swap”的交换文件$ dd if=/dev/zero of=swap bs=1M count=1k# 创建交换文件$ mkswap swap# 挂载交换分区$ swapon swap# 卸载交换分区# $ swapoff swap 查看交换分区1$ free -m 未设置时如下1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 RaspbianWe will change the configuration in the file /etc/dphys-swapfile:1$ sudo nano /etc/dphys-swapfile The default value in Raspbian is:1CONF_SWAPSIZE=100 We will need to change this to:1CONF_SWAPSIZE=1024 Then you will need to stop and start the service that manages the swapfile own Rasbian:12$ sudo /etc/init.d/dphys-swapfile stop$ sudo /etc/init.d/dphys-swapfile start You can then verify the amount of memory + swap by issuing the following command:1$ free -m The output should look like:1234total used free shared buffers cachedMem: 435 56 379 0 3 16-/+ buffers/cache: 35 399Swap: 1023 0 1023 软件安装指令 apt-get 安装软件apt-get install softname1 softname2 softname3 ... 卸载软件apt-get remove softname1 softname2 softname3 ... 卸载并清除配置apt-get remove --purge softname1 更新软件信息数据库apt-get update 进行系统升级apt-get upgrade 搜索软件包apt-cache search softname1 softname2 softname3 ... 修正（依赖关系）安装：apt-get -f insta dpkg 安装.deb软件包dpkg -i xxx.deb 删除软件包dpkg -r xxx.deb 连同配置文件一起删除dpkg -r --purge xxx.deb 查看软件包信息dpkg -info xxx.deb 查看文件拷贝详情dpkg -L xxx.deb 查看系统中已安装软件包信息dpkg -l 重新配置软件包dpkg-reconfigure xx 卸载软件包及其配置文件，但无法解决依赖关系！sudo dpkg -p package_name 卸载软件包及其配置文件与依赖关系包sudo aptitude purge pkgname 清除所有已删除包的残馀配置文件dpkg -l |grep ^rc|awk &#39;{print $2}&#39; |sudo xargs dpkg -P 软件源 备份原始文件 1$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup 修改文件并添加国内源 1$ vi /etc/apt/sources.list 注释元文件内的源并添加如下地址 123456789101112131415161718192021#Mirror.lupaworld.com 源更新服务器（浙江省杭州市双线服务器，网通同电信都可以用，亚洲地区官方更新服务器）：deb http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-security main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-updates main restricted universe multiversedeb-src http://mirror.lupaworld.com/ubuntu gutsy-backports main restricted universe multiverse#Ubuntu 官方源 deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse 或者 1234567891011121314151617181920212223#阿里云deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse#网易163deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse 放置非官方源的包不完整，可在为不添加官方源 1deb http://archive.ubuntu.org.cn/ubuntu-cn/ feisty main restricted universe multiverse 更新源 1$ sudo apt-get update 更新软件 1$ sudo apt-get dist-upgrade 常见的修复安装命令 1$ sudo apt-get -f install Python主要是Python和相关依赖包的安装，使用以下指令可导出已安装的依赖包1$ pip freeze &gt; requirements.txt 并使用指令安装到树莓派1$ pip install -r requirements.txt 注意pip更新1python -m pip install --upgrade pip 最新版本会报错1ImportError: cannot import name main 修改文件/usr/bin/pip123from pip import mainif __name__ == &apos;__main__&apos;: sys.exit(main()) 改为123from pip import __main__if __name__ == &apos;__main__&apos;: sys.exit(__main__._main()) 成功!!!失败了，笑脸:-)，手动安装吧。。。 部分包可使用pip3 123$ pip3 install numpy$ pip3 install pandas$ pip3 install sklearn 若需要权限，加入--user 部分包用apt-get，但是优先安装到Python2.7版本，笑脸:-) 123$ sudo apt-get install python-scipy$ sudo apt-get install python-matplotlib$ sudo apt-get install python-opencv 部分从PIPY下载.whl或.tar.gz文件 PyPI – the Python Package Index · PyPI tensorboardX-1.4-py2.py3-none-any.whl visdom-0.1.8.5.tar.gz 安装指令为 1$ pip3 install xxx.whl 12$ tar -zxvf xxx.tar.gz$ python setup.py install Pytorch源码安装 pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration 安装方法Installation - From Source 需要用到miniconda，安装方法如下，注意中间回车按慢一点，有两次输入。。。。。(行我慢慢看条款不行么。。笑脸:-)) 第一次是是否同意条款，yes 第二次是添加到环境变量，yes，否则自己修改/home/pi/.bashrc添加到环境变量 1234567891011$ wget http://repo.continuum.io/miniconda/Miniconda3-latest-Linux-armv7l.sh$ sudo md5sum Miniconda3-latest-Linux-armv7l.sh # (optional) check md5$ sudo /bin/bash Miniconda3-latest-Linux-armv7l.sh # -&gt; change default directory to /home/pi/miniconda3$ sudo nano /home/pi/.bashrc # -&gt; add: export PATH=&quot;/home/pi/miniconda3/bin:$PATH&quot;$ sudo reboot -h now$ conda $ python --version$ sudo chown -R pi miniconda3 然后就可以安装了没有对应版本的mkl，笑脸:-) 12345678910111213export CMAKE_PREFIX_PATH=&quot;$(dirname $(which conda))/../&quot; # [anaconda root directory]# Disable CUDAexport NO_CUDA=1# Install basic dependenciesconda install numpy pyyaml mkl mkl-include setuptools cmake cffi typingconda install -c mingfeima mkldnn# Install Pytorchgit clone --recursive https://github.com/pytorch/pytorchcd pytorchpython setup.py install tensorflow 安装tensorflow需要的一些依赖和工具 1234567$ sudo apt-get update# For Python 2.7$ sudo apt-get install python-pip python-dev# For Python 3.3+$ sudo apt-get install python3-pip python3-dev 安装tensorflow 若下载失败，手动打开下面网页下载.whl包 1234567# For Python 2.7$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp27-none-linux_armv7l.whl$ sudo pip install tensorflow-1.1.0-cp27-none-linux_armv7l.whl# For Python 3.4$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.1.0/tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl$ sudo pip3 install tensorflow-1.1.0-cp34-cp34m-linux_armv7l.whl 卸载，重装mock 1234567# For Python 2.7$ sudo pip uninstall mock$ sudo pip install mock# For Python 3.3+$ sudo pip3 uninstall mock$ sudo pip3 install mock 安装的版本tensorflow v1.1.0没有models，因为1.0版本以后models就被Sam Abrahams独立出来了，例如classify_image.py就在models/tutorials/image/imagenet/里 tensorflow/models 其余 输入法 12$ sudo apt-get install fcitx fcitx-googlepinyin $ fcitx-module-cloudpinyin fcitx-sunpinyin git 1$ sudo apt-get install git 配置git和ssh 12345$ git config --global user.name &quot;Louis Hsu&quot;$ git config --global user.email is.louishsu@foxmail.com$ ssh-keygen -t rsa -C &quot;is.louishsu@foxmail.com&quot;$ cat ~/.ssh/id_rsa.pub # 添加到github]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softmax Regression]]></title>
    <url>%2F2018%2F10%2F18%2FSoftmax-Regression%2F</url>
    <content type="text"><![CDATA[Unsupervised Feature Learning and Deep Learning Tutorial 引言Logistic Regression中采用的非线性函数为Sigmoid，将输出值映射到$(0, 1)$之间作为概率输出，处理的是二分类问题，那么对于多分类的问题怎么处理呢？ 模型 由Logistic回归推广而来 SoftmaxSoftmax在机器学习和深度学习中有着非常广泛的应用。尤其在处理多分类$(K&gt;2)$问题，分类器最后的输出单元需要Softmax函数进行数值处理。 S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]其中$x$为矩阵形式的向量，其维度为$(K×1)$，$K$为类别数目。Softmax的输出向量维度与$x$相同，各元素$x_i$加和为$1$，可用于表示取各个类别的概率。 注意到，对于函数$e^x$ \lim_{x \rightarrow - \infty} e^x = 0\lim_{x \rightarrow + \infty} e^x = +\infty 假设所有的$x_i$等于某常数$c$，理论上对所有$x_i$上式结果为$\frac{1}{n}$ 若$c$为很小的负数，$e^c$下溢，结果为$NaN$； 若$c$量级很大，$e^c$上溢，结果为$NaN$。 在数值计算时并不稳定，但是Softmax所有输入增加同一常数时，输出不变，得稳定版本： S(x) := S(x - max(x_i)) e^{x_{max} - max(x_i)} = 1 减去最大值导致$e^x$最大为$1$，排除上溢； 分母中至少有一项为$1$，排除分母下溢导致处以$0$的情况。 其对数 log S(x)_i = x_i - log ({\sum_{k=1}^K exp(x_k)}) 注意到，第一项表示输入$x_i$总是对代价函数有直接的贡献。这一项不会饱和，所以即使$x_i$对上式的第二项的贡献很小，学习依然可以进行； 当最大化对数似然时，第一项鼓励$x_i$被推高，而第二项则鼓励所有的$x$被压低； 第二项$log ({\sum_{k=1}^K exp(x_k)})$可以大致近似为$max(x_k)$，这种近似是基于对任何明显小于$max(x_k)$的$x_k$都是不重要的，负对数似然代价函数总是强烈地惩罚最活跃的不正确预测 除了对数似然之外的许多目标函数对 softmax 函数不起作用。具体来说，那些不使用对数来抵消 softmax 中的指数的目标函数，当指数函数的变量取非常小的负值时会造成梯度消失，从而无法学习 作者：NirHeavenX来源：CSDN原文：https://blog.csdn.net/qsczse943062710/article/details/61912464版权声明：本文为博主原创文章，转载请附上博文链接！ Softmax解决多分类问题对于具有$K$个分类的问题，每个类别训练一组参数$ w_k $ z_k^{(i)} = w_k^Tx^{(i)}或写作矩阵形式 z^{(i)} = W^Tx^{(i)}其中 x^{(i)} = \left[ \begin{matrix} x_0^{(i)}\\ x_1^{(i)}\\ ...\\ x_n^{(i)} \end{matrix} \right]_{n×1}, x_0^{(i)}=1 W = [w_1, w_2, ..., w_K]_{(n+1)×K} w_i = \left[ \begin{matrix} w_{i0}\\ w_{i1}\\ ...\\ w_{in} \end{matrix} \right]_{n×1}最终各类别输出概率为 \hat{y}^{(i)} = Softmax(z^{(i)}) 产生了一个奇怪的脑洞。。。二分类问题 p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} } = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } }定义二分类线性单元输出的差值为 z = x_1 - x_2得到 p(x_1) = \frac{1}{1 + e^{-z}}以$x_1 = [x_{11}, x_{12}]^T$为例(二维特征)，取$w_1=1, w_2=2, b=3$ p(x_1) = \frac{1}{1 + e^{-(w_1 x_{11} + w_2 x_{12} + b)}} 而多分类问题，以$3$分类为例 p(x_1) = \frac{ e^{x_1} }{ e^{x_1} + e^{x_2} + e^{x_3}} = \frac{ 1 }{ 1 + e^{ - (x_1 - x_2) } + e^{ - (x_1 - x_3)} }定义线性单元输出的差值为 z_{12} = x_1 - x_2 z_{13} = x_1 - x_3 p(x_1) = \frac{ 1 }{ 1 + e^{ - z_{12} } + e^{ - z_{13}} }做出图像为 损失函数由交叉熵理解CrossEnt = \sum_j p_j log \frac{1}{q_j}而对于样本$ (X^{(i)}, y^{(i)}) $，为确定事件，故标签概率各元素的取值$p_j$为$ y^{(i)}_j ∈ \{0,1\}$，$ q_j即预测输出的概率值\hat{y}^{(i)}_j$ 一般取各个样本损失的均值$(\frac{1}{N})$ L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N 1\{y^{(i)}_j=k\} log (\hat{y}^{(i)}_j) 1\{y^{(i)}_j=k\} = \begin{cases} 1 & y^{(i)}_j = k \\ 0 & y^{(i)}_j \neq k \end{cases}可对实际标签$y^{(i)}$采取One-Hot编码，便于计算 y^{(i)} = \left[ \begin{matrix} 0, ..., 1_{y^{(i)}}, ..., 0 \end{matrix} \right]^T则 L(\hat{y}, y) = - \frac{1}{N} \sum_{i=1}^N y^{(i)T} log (\hat{y}^{(i)})由决策平面理解从贝叶斯决策和分类问题的决策平面可知，对于类别$c_i$，有 P(c_i|x) = \frac{P(x|c_i)}{\sum_{j=0}^KP(x|c_j)} 假设每个类别的样本服从正态分布，先验概率相等，各类别样本特征间协方差相等。证明略. 梯度推导Softmax函数的导数对于 S(x) = \frac {1} {\sum_{k=1}^K exp(x_k)} \left[ \begin{matrix} exp(x_1)\\ exp(x_2)\\ ...\\ exp(x_K) \end{matrix} \right]一般输出作为概率值，记 P = S(x)p_i = S(x)_i对向量$x$中某元素求导 \frac{∂S(x)}{∂x_i} = \frac{∂}{∂x_i} \left[ \begin{matrix} ...\\ \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}\\ ...\\ \end{matrix} \right] $(1)$ $i=k$$\frac{∂}{∂x_i} \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{exp’(x_i)·\sum_{j=1}^K exp(x_j) - exp(x_i)·(\sum_{j=1}^K exp(x_j))’}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)·\sum_{j=1}^K exp(x_j) - exp^2(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)} -(\frac{exp(x_i)}{\sum_{j=1}^K exp(x_j)})^2$$ = p_i (1 - p_i)$ $(2)$ $i\neq k$$\frac{∂}{∂x_i} \frac{exp(x_k)}{\sum_{j=1}^K exp(x_j)}$$ = \frac{exp’(x_k)·\sum_{j=1}^K exp(x_j) - exp(x_k)·(\sum_{j=1}^K exp(x_j))’}{(\sum_{j=1}^K exp(x_j))^2}$$ = \frac{- exp(x_k)exp(x_i)}{(\sum_{j=1}^K exp(x_j))^2}$$= - p_i p_k$ 综上 \frac{∂S(x)}{∂x_i}_{K×1} = \left[ \begin{matrix} 0\\ ...\\ p_i\\ ...\\ 0 \end{matrix} \right] - \left[ \begin{matrix} p_i p_1\\ ...\\ p_i^2\\ ...\\ p_i p_K \end{matrix} \right] = \left( \left[ \begin{matrix} 0\\ ...\\ 1\\ ...\\ 0 \end{matrix} \right] - p \right)p_i 损失函数梯度在OneHot编码下，损失函数形式为 L(\hat{y},y) = \frac{1}{N} \sum_{i=1}^N L (y^{(i)}, \hat{y}^{(i)}) L (y^{(i)}, \hat{y}^{(i)}) = - y^{(i)T} log \hat{y}^{(i)} \hat{y}^{(i)} = S(z^{(i)}) z^{(i)} = W^T x^{(i)}即只考虑实际分类对应的概率值 L (y^{(i)}, \hat{y}^{(i)}) = - log \hat{y}^{(i)}_{y^{(i)}} 由于 $S(z^{(i)})_{t^{(i)}}$与$z^{(i)}$向量各个元素都有关，由链式求导法则 \frac{∂ L^{(i)} }{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } ( \sum_{k=1}^K \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k} \frac{∂z^{(i)}_k}{∂w_{pq}} )$1.$ 考察 $\frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k}$ \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_k} = ​ \begin{cases} ​ \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_k) & k=y^{(i)} \\ ​ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_k & k \neq y^{(i)} ​ \end{cases}$2.$ 考察 $\frac{∂z^{(i)}_k}{∂w_{pq}}$ \frac{∂z^{(i)}_k}{∂w_{pq}} = \begin{cases} \frac{∂z^{(i)}_k}{∂w_{pq}} = x^{(i)}_p & k=q\\ \frac{∂z^{(i)}_k}{∂w_{pq}} = 0 & k \neq q \end{cases} 综上所述 \frac{∂ L^{(i)} }{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} \frac{∂z^{(i)}_q}{∂w_{pq}}其中 \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} = \begin{cases} \hat{y}^{(i)}_{y^{(i)}} (1 - \hat{y}^{(i)}_q) & q = y^{(i)}\\ - \hat{y}^{(i)}_{y^{(i)}} \hat{y}^{(i)}_q & q \neq y^{(i)} \end{cases} \frac{∂z^{(i)}_q}{∂w_{pq}} = x^{(i)}_p故对于单个样本$(X^{(i)}, y^{(i)})$，当样本标签采用$OneHot$编码时 \frac{∂L^{(i)}}{∂w_{pq}} = - \frac{1}{ \hat{y}^{(i)}_{y^{(i)}} } \frac{∂ \hat{y}^{(i)}_{y^{(i)}} }{∂z^{(i)}_q} x^{(i)}_p = \begin{cases} (\hat{y}^{(i)}_q - 1)x^{(i)}_p & q = y^{(i)}\\ \hat{y}^{(i)}_qx^{(i)}_p & q \neq y^{(i)} \end{cases} 注： 这里可以约分去掉$\hat{y}^{(i)}_{y^{(i)}}$ \frac{∂L^{(i)}}{∂w_{pq}} = ( \hat{y}^{(i)}_q - y^{(i)}_q) x^{(i)}_p更一般的，写成矩阵形式，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) ∇_W L = X^T(\hat{Y} - Y) 用线性模型解决分类和回归问题时，形式竟如此统一! 至此为止，梯度推导结束，利用梯度下降法迭代求解参数矩阵$W$即可。 W := W - \alpha ∇_W L代码@GitHub: Code of Softmax Regression Softmax12345678def softmax(X): &quot;&quot;&quot; 数值计算稳定版本的softmax函数 @param &#123;ndarray&#125; X: shape(batch_size, n_labels) &quot;&quot;&quot; X_max = np.max(X, axis=1).reshape((-1, 1)) # 每行的最大值 X = X - X_max # 每行减去最大值 X = np.exp(X) return X / np.sum(X, axis=1).reshape((-1, 1)) cost function1234567891011def crossEnt(self, y_label_true, y_prob_pred): &quot;&quot;&quot; 计算交叉熵损失函数 @param &#123;ndarray&#125; y_label_true: 真实标签 shape(batch_size,) @param &#123;ndarray&#125; y_prob_pred: 预测输出 shape(batch_size, n_labels) &quot;&quot;&quot; mask = self.encoder.transform(y_label_true.reshape(-1, 1)).toarray() # shape(batch_size, n_labels) y_prob_masked = np.sum(mask * y_prob_pred, axis=1) # 每行真实标签对应的预测输出值 y_prob_masked[y_prob_masked==0.] = 1. y_loss = np.log(y_prob_masked) loss = - np.mean(y_loss) # 求各样本损失的均值 return loss gradient12345678910def grad(self, X_train, y_train, y_prob_pred): &quot;&quot;&quot; 计算梯度 \frac &#123;∂L&#125; &#123;∂W_&#123;pq&#125;&#125; @param X_train: 训练集特征 @param y_train: 训练集标签 @param y_prob_pred: 训练集预测概率输出 @param y_label_pred: 训练集预测标签输出 &quot;&quot;&quot; y_train = self.encoder.transform(y_train) dW = X_train.T.dot(y_prob_pred - y_train) return dW training step省略可视化和验证部分的代码123456789101112131415161718192021222324252627282930313233343536def fit(self, X_train, X_valid, y_train, y_valid, min_acc=0.95, max_epoch=20, batch_size=20): &quot;&quot;&quot; 训练 &quot;&quot;&quot; # 添加首1列，输入到偏置w0 X_train = np.c_[np.ones(shape=(X_train.shape[0],)), X_train] X_valid = np.c_[np.ones(shape=(X_valid.shape[0],)), X_valid] X_train = self.scaler.fit_transform(X_train) # 尺度归一化 X_valid = self.scaler.transform(X_valid) # 尺度归一化 self.encoder.fit(y_train.reshape(-1, 1)) self.n_features = X_train.shape[1] self.n_labels = self.encoder.transform(y_train).shape[1] # 初始化参数 self.W = np.random.normal(loc=0, scale=1.0, size=(self.n_features, self.n_labels)) n_batch = X_train.shape[0] // batch_size # 可视化相关 plt.ion() plt.figure(&apos;loss&apos;); plt.figure(&apos;accuracy&apos;) loss_train_epoch = []; loss_valid_epoch = [] acc_train_epoch = []; acc_valid_epoch = [] for i_epoch in range(max_epoch): for i_batch in range(n_batch): # 批处理梯度下降 n1, n2 = i_batch * batch_size, (i_batch + 1) * batch_size X_train_batch, y_train_batch = X_train[n1: n2], y_train[n1: n2] # 预测 y_prob_train = self.predict(X_train_batch, preprocessed=True) # 计算损失 loss_train_batch = self.crossEnt(y_train_batch, y_prob_train) # 计算准确率 y_label_train = np.argmax(y_prob_train, axis=1) a = y_train_batch.reshape((-1,)) acc_train_batch = np.mean((y_label_train == y_train_batch.reshape((-1,))).astype(&apos;float&apos;)) # 计算梯度 dW dW = self.grad(X_train_batch, y_train_batch, y_prob_train) # 更新参数 self.W -= self.lr * dW predict step123456789101112def predict(self, X, preprocessed=False): &quot;&quot;&quot; 对输入的样本进行预测，输出标签 @param &#123;ndarray&#125; X: shape(batch_size, n_features) @return &#123;ndarray&#125; y_prob: probability, shape(batch_size, n_labels) &#123;ndarray&#125; y_label: labels, shape(batch_size,) &quot;&quot;&quot; if not preprocessed: # 训练过程中调用此函数时，不用加首1列 X = np.c_[np.ones(shape=(X.shape[0],)), X] # 添加首1项，输入到偏置w0 X = self.scaler.transform(X) y_prob = softmax(X.dot(self.W)) # 预测概率值 shape(batch_size, n_labels) return y_prob 实验结果以下蓝线为训练集参数，红线为验证集参数，若稳定训练(如batch_size = 20的结果)，最终准确率在$80\%$左右。 由于随机梯度下降(SGD)遍历次数太多，运行较慢，没有用SGD方法训练，就前几个epoch来看，效果没有batch_size = 20的好； 添加隐含层形成三层结构的前馈神经网络，可提高准确率； 还有一点，使用批处理梯度下降(n_batch = 1)训练时，可以看到损失值已经趋于$0$，但准确率却很低，说明已经陷入局部最优解。 batch size = 20 损失 准确率 batch_size = 200 损失 准确率 n_batch = 1 损失 准确率 感悟推公式要我老命。。。。 Softmax回归可以视作不含隐含层的前馈神经网络。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Logistic Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLogistic-Regression%2F</url>
    <content type="text"><![CDATA[引言逻辑回归（Logistic Regression）是用于处理因变量为分类变量的回归问题，常见的是二分类或二项分布问题，也可以处理多分类问题，它实际上是属于一种分类方法。 模型先给出模型，推导过程稍后给出，逻辑回归包含Sigmoid函数 f(z) = \frac{1}{1+e^{-z}}其图像如下 定义 z = w^Tx其中$x=[x_0, x_1, …, x_n]^T, x_0=1$ h_w(x) = g(z) = \frac{1}{1+e^{-z}}损失函数由最大似然估计推导对于二元分类问题，其取值作为随机变量，服从二项分布 $B(1, p)$，其中$p$即为预测输出概率$\hat{y}$ P(y_i^{(i)}) = (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}由极大似然估计 L = \prod_{i=0}^N P(y_i^{(i)}) = \prod_{i=0}^N (\hat{y}_i^{(i)})^{y_i^{(i)}}(1-\hat{y}_i^{(i)})^{1-y_i^{(i)}}取对数似然函数 logL = \sum_{i=0}^N [y_i^{(i)} log \hat{y}_i^{(i)} + (1-y_i^{(i)}) log (1-\hat{y}_i^{(i)})]优化目标是 w = argmax_w logL优化问题一般表述成minimize问题，添加负号，构成Neg Log Likelihood损失 w = argmin_w (-logL)一般取均值 L(\hat{y}, y)=- \frac{1}{N} \sum_i [y_i^{(i)} log(\hat{y}_i^{(i)})+(1 - y_i^{(i)})log(1-\hat{y}_i^{(i)})]其中$y_i$表示真实值，$\hat{y}_i$表示预测值 从交叉熵理解已知交叉熵cross entropy定义如下 CrossEnt = \sum_i p_i log \frac{1}{q_i}而对于样本$ (X_i, y_i) $，为确定事件，故标签概率的取值为$ p_i = y_i ∈ \{0,1\}$，$ q_i即预测输出的概率值\hat{y}_i $，可得到与上面相同的推导结论 从决策平面和贝叶斯决策理解相关内容查看分类问题的决策平面和贝叶斯决策，逻辑回归考虑的一般是等先验概率问题，故决策函数定义为 $if$ $P(c_i|x)&gt;P(c_j|x)$ $then$ $ x \in c_i $, $ i, j = 1, 2 $ 从贝叶斯决策可知，对于类别$c_1$，有 P(c_1|x) = \frac{P(x|c_1)}{P(x|c_1) + P(x|c_2)}设在各个类别下，特征$x$服从正态分布 P(x|c_i) = \frac{1}{ (2\pi)^{\frac{n}{2}} |\Sigma_i|^{\frac{1}{2}}} exp(-\frac{1}{2} (x-\mu_i)^T \Sigma^{-1} (x-\mu_i))则 P(c_1|x) = \frac {1} { 1 + exp(-z) } P(c_2|x) = 1 - P(c_1|x) = \frac{exp(-z)}{1+exp(-z)} $P(c_1|x) = \frac{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1) + exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}$ $P(c_1|x) = \frac{1}{1 + \frac{exp(-\frac{1}{2} (x-\mu_2)^T \Sigma_2^{-1} (x-\mu_2)}{exp(-\frac{1}{2} (x-\mu_1)^T \Sigma_1^{-1} (x-\mu_1)}}$ 假定各分类的样本方差相等，$ \Sigma_1 = \Sigma_2 = \sigma^2 I $ $ P(c_1|x) = \frac {1}{1 + exp(- [ \frac{1}{\sigma^2} (\mu_1-\mu_2)^T x - \frac{1}{2 \sigma^2} (\mu_1^T\mu_1 - \mu_2^T\mu_2) ])}$ 令 w = \frac{1}{\sigma^2} (\mu_1 -\mu_2)b = - \frac{1}{2\sigma^2}(\mu_1^T \mu_1 - \mu_2^T \mu_2)即可得到 P(c_1|x) = \frac {1} { 1 + exp(-z) }其中 z = w^T x + b 梯度推导先推导Sigmoid函数的导数 f'(z) = (1 - f(z))f(z)值得注意的是，从$f’(z)$的图像可以看到，在$ x=0 $处$f’(z)$取极大值，且 f'(z)_{max} = f'(z)|_{z=0} = 0.25 \lim_{z \rightarrow \infty} f'(z) = 0在多层神经网络反向传播更新参数时，由于梯度多次累乘，Sigmoid作为激活函数会存在“梯度消失”的问题，使得参数更新非常缓慢。 $ f’(z) $$ = (\frac{1}{1+e^{-z}})’ $$ = \frac​ {-(1+e^{-z})’}​ {(1+e^{-z})^2} $$ = \frac​ {e^{-z}}​ {(1+e^{-z})^2} $$ = \frac​ {e^{-z}}​ {1+e^{-z}}​ \frac​ {1}​ {1+e^{-z}}$$ = (1 - f(z))f(z)$ 利用链式求导法则可得 $\frac{∂L}{∂w_j}$$= -\frac{∂}{∂w_j} \frac{1}{N} \sum_i [y^{(i)} log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\frac{∂}{∂w_j}\hat{y}^{(i)}-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\frac{∂}{∂w_j}\hat{y}^{(i)}]$$= - \frac{1}{N} \sum_i [y^{(i)} \frac{1}{\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j-(1-y^{(i)})\frac{1}{1-\hat{y}^{(i)}}\hat{y}^{(i)}(1-\hat{y}^{(i)})w_j]$$= - \frac{1}{N} \sum_i [y^{(i)} (1-\hat{y}^{(i)})w_j-(1-y^{(i)}) y^{(i)} w_j]$$= \frac{1}{N} \sum_i (\hat{y}^{(i)} - y^{(i)})w_j $ 写作矩阵形式，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) ∇_w L = X^T (\hat{Y} - Y)训练和线性回归一样，采用梯度下降法求解 w := w - \alpha ∇_w L处理多分类问题假设有$K$个类别，则依次以类别$c_i$为正样本训练模型，一共训练$K$个。测试样本在每个模型上计算，最终将概率最大的作为分类结果。 这样划分数据集，会使训练集正负样本数目严重不对称，特别是类别很多的情况，对结果会产生影响。可推广至softmax回归解决这个问题。 程序代码@Github: Code for Logistic Regression cost function123456789101112131415def lossFunctionDerivative(self, X, theta, y_true): &apos;&apos;&apos; 计算损失函数对参数theta的梯度 对theta[j]的梯度为：(y_pred - y_true)*x[j] &apos;&apos;&apos; err = self.predict_prob(X, theta) - y_true return X.T.dot(err)/y_true.shape[0]def lossFunction(self, y_pred_prob, y_true): &apos;&apos;&apos; 未使用 计算损失值: Cross-Entropy y_pred_prob, y_true: NumPy array, shape=(n,) &apos;&apos;&apos; tmp = y_true*np.log(y_pred_prob) + (1 - y_true)*np.log(1 - y_pred_prob) return np.mean(-tmp) training step123456789101112131415161718192021def gradDescent(self, min_acc, learning_rate=0.01, max_iter=10000): acc = 0; n_iter = 0 for n_iter in range(max_iter): for n in range(self.n_batch): X_batch = self.X[n*self.batch_size:(n+1)*self.batch_size] t_batch = self.t[n*self.batch_size:(n+1)*self.batch_size] grad = self.lossFunctionDerivative(X_batch, self.theta, t_batch) self.theta -= learning_rate * grad # 梯度下降 acc = self.accuracyRate(self.predict_prob(self.X, self.theta), self.t) if acc &gt; min_acc: print(&apos;第%d次迭代, 第%d批数据&apos; % (n_iter, n)) print(&quot;当前总体样本准确率为: &quot;, acc) print(&quot;当前参数值为: &quot;, self.theta) return self.theta if n_iter%100 == 0: print(&apos;第%d次迭代&apos; % n_iter) print(&apos;准确率： &apos;, acc) print(&quot;超过迭代次数&quot;) print(&quot;当前总体样本准确率为: &quot;, acc) print(&quot;当前参数值为: &quot;, self.theta) return self.theta 实验结果]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linear Regression]]></title>
    <url>%2F2018%2F10%2F18%2FLinear-Regression%2F</url>
    <content type="text"><![CDATA[引言线性回归可以说是机器学习最基础的算法 模型\hat{y}^{(i)} = w^Tx^{(i)}其中 x^{(i)}=[x_0^{(i)}, x_1^{(i)}, ..., x_n^{(i)}]^T, x_0^{(i)}=1这里$x_0^{(i)}=1$表示偏置$b$，即$b=w_0$ \hat{y}^{(i)} = w^Tx^{(i)} + b 注：对于非线性的数据，可构造高次特征。 损失函数定义误差e^{(i)} = \hat{y}^{(i)} - y^{(i)}其中$y^{(i)}$表示真实值 定义损失函数单个样本的误差定义为 L_{single}(\hat{y}^{(i)}, y^{(i)})=\frac{1}{2}||e^{(i)}||_2^2=\frac{1}{2}(\hat{y}^{(i)}-y^{(i)})^2所有样本的误差定义为 L(y, t)=\frac{1}{2N}\sum_i (\hat{y}^{(i)}-y^{(i)})^2也可以定义为误差的和而不是均值，对结果无影响，可视作学习率$α$除去一个常数 梯度推导 $\frac{∂L}{∂w_j}$$= \frac{∂}{∂w_j}\frac{1}{2N}\sum_i(\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{2N} \sum_i \frac{∂}{∂w_j} (\hat{y}^{(i)}-y^{(i)})^2$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) \frac{∂t^{(i)}}{∂w_j}$$= \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)}$ 或者使用矩阵推导，记$X = [x_1, x_2, …, x_m]^T$，$x_i$为样本特征(列向量) L = \frac{1}{2}(Xw-Y)^T(Xw-Y) ∇_w L = X^T(\hat{Y}-Y) $∇_w L$$= \frac{1}{2} ∇_w (w^TX^TXw - Y^TXw - w^TX^TY + Y^TY)$$= \frac{1}{2} (2X^TXw - X^TY - X^TY)$$= X^T(Xw-Y) $ 在梯度为$\vec{0}$的点，即$∇_w L = \vec{0}$时对应最优解 X^T(Xw-Y) = 0 令X^T(Xw-Y) = 0 有X^TXw = X^TY w^*=(X^TX+\lambda I)^{-1}X^TY 其中$X^+=(X^TX+\lambda I)^{-1}X^T$，表示矩阵$X_{m×n}$的伪逆 训练采用梯度下降法求解 w := w - \alpha ∇_w L其中$w$表示参数向量 进一步思考：为什么使用梯度下降可以求取最优解呢？ ∇_w^2 L = ∇_w X^T(Xw-Y) = X^TX而对于矩阵 $ X^TX $ u^T(X^TX)u = (Xu)^T(Xu) \geq 0即损失函数的Hessian矩阵$∇_w^2 L$为正定矩阵，$L$为凸函数，存在全局最优解 从投影的角度理解线性回归 线性回归的正则化为克服过拟合问题，可加入正则化项$||w||_2^2$，此时损失函数定义为 L(\hat{y}, y)=\frac{1}{2N} ||\hat{y}^{(i)}-y^{(i)}||_2^2 + \lambda ||w||_2^2或者 L(\hat{y}, y)=\frac{1}{2N} \sum_i (\hat{y}^{(i)}-y^{(i)})^2 + \frac{\lambda}{2N}\sum_j w_j^2其中$i = 1, …, N_{sample}; j = 1, …, N_{feature},j&gt;0 $ 此时梯度为 \frac{∂L}{∂w_j} = \frac{1}{N} \sum_i (\hat{y}^{(i)}-y^{(i)}) x_j^{(i)} + \frac{\lambda}{N}w_j其中$j = 1, …, N_{feature},j&gt;0 $ 局部加权线性回归目标函数定义为 L(y, t)=\frac{1}{2N}\sum_i w^{(i)} (\hat{y}^{(i)}-y^{(i)})^2其中 w^{(i)} = e^{-\frac{(x^{(i)}-x)^2}{2\tau^2}}$x$表示输入的预测样本，$x^{(i)}$表示训练样本 离很近的样本，权值接近于1，而对于离很远的样本，此时权值接近于0，这样就是在局部构成线性回归，它依赖的也只是周边的点。 对于线性回归算法，一旦拟合出适合训练数据的参数$w$，保存这些参数$w$，对于之后的预测，不需要再使用原始训练数据集，所以是参数学习算法。而对于局部加权线性回归算法，每次进行预测都需要全部的训练数据（每次进行的预测得到不同的参数$w$），没有固定的参数$w$，所以是非参数算法。 代码@Github: Code for Linear Regression training step12345678910111213141516171819202122232425262728293031323334353637383940414243def fit(self, X, y, learning_rate=0.01, max_iter=5000, min_loss=10): # --------------- 数据预处理部分 --------------- # 加入全1列 X = np.c_[np.ones(shape=(X.shape[0])), X] # 构造高次特征 if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] # ---------------- 参数迭代部分 ---------------- # 初始化参数 self.theta = np.random.uniform(-1, 1, size=(X.shape[1],)) # 数据批次 n_batch = X.shape[0] if self.n_batch==-1 else self.n_batch batch_size = X.shape[0] // n_batch # 停止条件 n_iter = 0; loss = float(&apos;inf&apos;) # 开始迭代 for n_iter in range(max_iter): for n in range(n_batch): n1, n2 = n*batch_size, (n+1)*batch_size X_batch = X[n1: n2]; y_batch = y[n1: n2] grad = self.lossFunctionDerivative(X_batch, y_batch) self.theta -= learning_rate * grad loss = self.score(y_batch, self.predict(X_batch)) if loss &lt; min_loss: print(&apos;第%d次迭代, 第%d批数据&apos; % (n_iter, n)) print(&quot;当前总体样本损失为: &quot;, loss) return self.theta if n_iter%100 == 0: print(&apos;第%d次迭代&apos; % n_iter) print(&quot;当前总体样本损失为: &quot;, loss) print(&quot;超过迭代次数&quot;) print(&quot;当前总体样本损失为: &quot;, loss) return self.thetadef lossFunctionDerivative(self, X, y): y_pred = self.predict(X) # theta = self.theta; # ！注意：theta = self.theta 不仅仅是赋值，类似引用，修改theta会影响self.theta theta = self.theta.copy() theta[0] = 0 # θ0不需要正则化 return (X.T.dot(y_pred - y) + self.regularize * theta) / X.shape[0] predict step123456789def predict(self, X, preprocessed=False): if preprocessed: # 加入全1列 X = np.c_[np.ones(shape=(X.shape[0])), X] # 构造高次特征 if self.n_ploy &gt; 1: for i in range(2, self.n_ploy + 1): X = np.c_[X, X[:, 1]**i] return X.dot(self.theta) 运行结果 无正则化 正则化]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
</search>
